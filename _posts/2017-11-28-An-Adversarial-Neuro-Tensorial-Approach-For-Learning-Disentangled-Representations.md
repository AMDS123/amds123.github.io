---
layout: post
title: "An Adversarial Neuro-Tensorial Approach For Learning Disentangled Representations"
date: 2017-11-28 16:57:21
categories: arXiv_CV
tags: arXiv_CV Adversarial Face Classification Deep_Learning
author: Mengjiao Wang, Zhixin Shu, Yannis Panagakis, Dimitris Samaras, Stefanos Zafeiriou
mathjax: true
---

* content
{:toc}

##### Abstract
Several factors contribute to the appearance of an object in a visual scene, including pose, illumination, and deformation, to mention a few. Each factor accounts for a source of variability in the data, while the multiplicative interactions of these factors emulate the entangled variability, giving rise to the rich structure of visual object appearance. Disentangling such unobserved factors from visual data is a challenging task, especially when the data have been captured in uncontrolled recording conditions (also refereed to as "in-the-wild") and label information is not available. In this paper, we propose the first unsupervised deep learning method for disentangling multiple latent factors of variation in face images captured in-the-wild. To this end, we propose a deep latent variable model, where the multiplicative interactions of multiple latent factors of variation are explicitly modelled by means of multilinear (tensor) structure. We demonstrate that the proposed approach indeed learns disentangled representations of facial expressions and pose, which can be used in various applications, including face editing, as well as 3D face reconstruction and classification of facial expression, identity and pose.

##### Abstract (translated by Google)
有几个因素会影响视觉场景中物体的外观，包括姿势，照明和变形等等。每个因素都是数据中可变性的来源，而这些因素的乘法相互作用模拟了纠缠的变化性，引起了视觉对象外观的丰富结构。从视觉数据中去除这些未观察到的因素是一项具有挑战性的任务，特别是当数据在不受控制的记录条件下被捕获（也被称为“在野外”）并且标签信息不可用时。在本文中，我们提出了第一个无监督的深度学习方法，以解决在野外拍摄的人脸图像中的多个潜在因素的变化。为此，我们提出了一个深潜变量模型，其中多变量的潜在因子的乘性相互作用是通过多线性（张量）结构来显式建模的。我们证明了所提出的方法确实学习了面部表情和姿态的解构表示，其可以用于各种应用，包括面部编辑，以及面部表情，身份和姿势的3D面部重建和分类。

##### URL
[https://arxiv.org/abs/1711.10402](https://arxiv.org/abs/1711.10402)

##### PDF
[https://arxiv.org/pdf/1711.10402](https://arxiv.org/pdf/1711.10402)

