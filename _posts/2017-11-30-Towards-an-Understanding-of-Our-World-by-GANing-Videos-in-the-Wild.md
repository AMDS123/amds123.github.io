---
layout: post
title: "Towards an Understanding of Our World by GANing Videos in the Wild"
date: 2017-11-30 14:55:16
categories: arXiv_CV
tags: arXiv_CV Knowledge GAN Prediction
author: Bernhard Kratzwald, Zhiwu Huang, Danda Pani Paudel, Luc Van Gool
mathjax: true
---

* content
{:toc}

##### Abstract
Existing generative video models work well only for videos with a static background. For dynamic scenes, applications of these models demand an extra pre-processing step of background stabilization. In fact, the task of background stabilization may very often prove impossible for videos in the wild. To the best of our knowledge, we present the first video generation framework that works in the wild, without making any assumption on the videos' content. This allows us to avoid the background stabilization step, completely. The proposed method also outperforms the state-of-the-art methods even when the static background assumption is valid. This is achieved by designing a robust one-stream video generation architecture by exploiting Wasserstein GAN frameworks for better convergence. Since the proposed architecture is one-stream, which does not formally distinguish between fore- and background, it can generate - and learn from - videos with dynamic backgrounds. The superiority of our model is demonstrated by successfully applying it to three challenging problems: video colorization, video inpainting, and future prediction.

##### Abstract (translated by Google)
现有的生成视频模型只适用于静态背景的视频。对于动态场景，这些模型的应用需要额外的预处理背景稳定步骤。事实上，背景稳定的任务经常被证明是不可能的。据我们所知，我们提出了第一个在野外工作的视频生成框架，而不对视频的内容做任何假设。这使我们完全避免了后台稳定步骤。即使静态背景假设是有效的，所提出的方法也优于最先进的方法。这是通过利用Wasserstein GAN框架来设计一个强大的单流视频生成架构来实现的，从而实现更好的融合。由于提出的体系结构是单流的，不能正式区分前景和背景，因此可以生成并学习具有动态背景的视频。我们的模型的优越性通过成功地应用于三个具有挑战性的问题来证明：视频着色，视频修补和未来预测。

##### URL
[https://arxiv.org/abs/1711.11453](https://arxiv.org/abs/1711.11453)

##### PDF
[https://arxiv.org/pdf/1711.11453](https://arxiv.org/pdf/1711.11453)

