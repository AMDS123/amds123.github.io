---
layout: post
title: "Towards a Grounded Dialog Model for Explainable Artificial Intelligence"
date: 2018-06-21 03:22:54
categories: arXiv_AI
tags: arXiv_AI Relation
author: Prashan Madumal, Tim Miller, Frank Vetere, Liz Sonenberg
mathjax: true
---

* content
{:toc}

##### Abstract
To generate trust with their users, Explainable Artificial Intelligence (XAI) systems need to include an explanation model that can communicate the internal decisions, behaviours and actions to the interacting humans. Successful explanation involves both cognitive and social processes. In this paper we focus on the challenge of meaningful interaction between an explainer and an explainee and investigate the structural aspects of an explanation in order to propose a human explanation dialog model. We follow a bottom-up approach to derive the model by analysing transcripts of 398 different explanation dialog types. We use grounded theory to code and identify key components of which an explanation dialog consists. We carry out further analysis to identify the relationships between components and sequences and cycles that occur in a dialog. We present a generalized state model obtained by the analysis and compare it with an existing conceptual dialog model of explanation.

##### Abstract (translated by Google)
为了与用户产生信任，可解释的人工智能（XAI）系统需要包含一个解释模型，可以将内部决策，行为和行为传达给相互作用的人类。成功的解释涉及认知和社会过程。在本文中，我们将重点放在解释者和解释者之间有意义互动的挑战上，并研究解释的结构方面以提出一个人类解释对话模型。我们采用自下而上的方法通过分析398种不同解释对话类型的成绩单来推导出模型。我们使用扎根理论来编码和识别解释对话所包含的关键组成部分。我们进行进一步的分析以确定组件和序列之间的关系以及在对话中发生的周期。我们提出了一个通过分析获得的广义状态模型，并将其与现有的概念对话模型的解释进行比较。

##### URL
[http://arxiv.org/abs/1806.08055](http://arxiv.org/abs/1806.08055)

##### PDF
[http://arxiv.org/pdf/1806.08055](http://arxiv.org/pdf/1806.08055)

