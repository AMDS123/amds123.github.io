---
layout: post
title: "Gender-preserving Debiasing for Pre-trained Word Embeddings"
date: 2019-06-03 12:26:25
categories: arXiv_CL
tags: arXiv_CL Embedding Relation
author: Masahiro Kaneko, Danushka Bollegala
mathjax: true
---

* content
{:toc}

##### Abstract
Word embeddings learnt from massive text collections have demonstrated significant levels of discriminative biases such as gender, racial or ethnic biases, which in turn bias the down-stream NLP applications that use those word embeddings. Taking gender-bias as a working example, we propose a debiasing method that preserves non-discriminative gender-related information, while removing stereotypical discriminative gender biases from pre-trained word embeddings. Specifically, we consider four types of information: \emph{feminine}, \emph{masculine}, \emph{gender-neutral} and \emph{stereotypical}, which represent the relationship between gender vs. bias, and propose a debiasing method that (a) preserves the gender-related information in feminine and masculine words, (b) preserves the neutrality in gender-neutral words, and (c) removes the biases from stereotypical words. Experimental results on several previously proposed benchmark datasets show that our proposed method can debias pre-trained word embeddings better than existing SoTA methods proposed for debiasing word embeddings while preserving gender-related but non-discriminative information.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.00742](http://arxiv.org/abs/1906.00742)

##### PDF
[http://arxiv.org/pdf/1906.00742](http://arxiv.org/pdf/1906.00742)

