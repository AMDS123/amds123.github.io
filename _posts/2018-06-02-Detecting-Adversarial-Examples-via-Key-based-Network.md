---
layout: post
title: "Detecting Adversarial Examples via Key-based Network"
date: 2018-06-02 04:13:02
categories: arXiv_CV
tags: arXiv_CV Adversarial Knowledge Classification Detection
author: Pinlong Zhao, Zhouyu Fu, Ou wu, Qinghua Hu, Jun Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Though deep neural networks have achieved state-of-the-art performance in visual classification, recent studies have shown that they are all vulnerable to the attack of adversarial examples. Small and often imperceptible perturbations to the input images are sufficient to fool the most powerful deep neural networks. Various defense methods have been proposed to address this issue. However, they either require knowledge on the process of generating adversarial examples, or are not robust against new attacks specifically designed to penetrate the existing defense. In this work, we introduce key-based network, a new detection-based defense mechanism to distinguish adversarial examples from normal ones based on error correcting output codes, using the binary code vectors produced by multiple binary classifiers applied to randomly chosen label-sets as signatures to match normal images and reject adversarial examples. In contrast to existing defense methods, the proposed method does not require knowledge of the process for generating adversarial examples and can be applied to defend against different types of attacks. For the practical black-box and gray-box scenarios, where the attacker does not know the encoding scheme, we show empirically that key-based network can effectively detect adversarial examples generated by several state-of-the-art attacks.

##### Abstract (translated by Google)
尽管深度神经网络在视觉分类方面已经取得了最先进的表现，但最近的研究表明，它们都容易受到敌对性例子的攻击。对输入图像的小且往往微不足道的干扰足以欺骗最强大的深层神经网络。已经提出了各种防御方法来解决这个问题。但是，他们要么需要知道产生敌对案例的过程，要么不需要针对专门用于渗透现有防御的新攻击。在这项工作中，我们引入了基于密钥的网络，一种基于检测的新型防御机制，用于将基于纠错输出码的对抗性例子与普通例子区分开来，使用多个二元分类器产生的二值码矢量应用于随机选择的标签集签名匹配正常图像并拒绝敌对的例子。与现有的防御方法相比，所提出的方法不需要知道生成敌对示例的过程，并且可以应用于抵御不同类型的攻击。对于攻击者不知道编码方案的实际黑盒和灰盒方案，我们凭经验证明基于密钥的网络可以有效检测由几种最先进的攻击产生的对抗性例子。

##### URL
[http://arxiv.org/abs/1806.00580](http://arxiv.org/abs/1806.00580)

##### PDF
[http://arxiv.org/pdf/1806.00580](http://arxiv.org/pdf/1806.00580)

