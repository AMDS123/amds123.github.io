---
layout: post
title: "Beyond RGB: Very High Resolution Urban Remote Sensing With Multimodal Deep Networks"
date: 2017-11-23 13:10:24
categories: arXiv_CV
tags: arXiv_CV CNN
author: Nicolas Audebert (OBELIX, Palaiseau), Bertrand Le Saux (Palaiseau), Sébastien Lefèvre (OBELIX)
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we investigate various methods to deal with semantic labeling of very high resolution multi-modal remote sensing data. Especially, we study how deep fully convolutional networks can be adapted to deal with multi-modal and multi-scale remote sensing data for semantic labeling. Our contributions are threefold: a) we present an efficient multi-scale approach to leverage both a large spatial context and the high resolution data, b) we investigate early and late fusion of Lidar and multispectral data, c) we validate our methods on two public datasets with state-of-the-art results. Our results indicate that late fusion make it possible to recover errors steaming from ambiguous data, while early fusion allows for better joint-feature learning but at the cost of higher sensitivity to missing data.

##### Abstract (translated by Google)
在这项工作中，我们研究了各种方法来处理超高分辨率多模式遥感数据的语义标注。尤其是我们研究了完全卷积网络如何适应处理多模态和多尺度遥感数据的语义标注。我们的贡献有三个方面：a）我们提出了一个有效的多尺度方法来利用大的空间背景和高分辨率的数据，b）我们研究激光雷达和多光谱数据的早期和晚期融合，c）我们验证两个方法公共数据集与最先进的结果。我们的结果表明，后期融合使得恢复模糊数据中出现的错误成为可能，而早期融合允许更好的联合特征学习，但是以对缺失数据更高敏感度为代价。

##### URL
[https://arxiv.org/abs/1711.08681](https://arxiv.org/abs/1711.08681)

##### PDF
[https://arxiv.org/pdf/1711.08681](https://arxiv.org/pdf/1711.08681)

