---
layout: post
title: "LEPOR: An Augmented Machine Translation Evaluation Metric"
date: 2017-03-26 00:30:38
categories: arXiv_SD
tags: arXiv_SD
author: Aaron Li-Feng Han
mathjax: true
---

* content
{:toc}

##### Abstract
Machine translation (MT) was developed as one of the hottest research topics in the natural language processing (NLP) literature. One important issue in MT is that how to evaluate the MT system reasonably and tell us whether the translation system makes an improvement or not. The traditional manual judgment methods are expensive, time-consuming, unrepeatable, and sometimes with low agreement. On the other hand, the popular automatic MT evaluation methods have some weaknesses. Firstly, they tend to perform well on the language pairs with English as the target language, but weak when English is used as source. Secondly, some methods rely on many additional linguistic features to achieve good performance, which makes the metric unable to replicate and apply to other language pairs easily. Thirdly, some popular metrics utilize incomprehensive factors, which result in low performance on some practical tasks. In this thesis, to address the existing problems, we design novel MT evaluation methods and investigate their performances on different languages. Firstly, we design augmented factors to yield highly accurate evaluation.Secondly, we design a tunable evaluation model where weighting of factors can be optimised according to the characteristics of languages. Thirdly, in the enhanced version of our methods, we design concise linguistic feature using POS to show that our methods can yield even higher performance when using some external linguistic resources. Finally, we introduce the practical performance of our metrics in the ACL-WMT workshop shared tasks, which show that the proposed methods are robust across different languages.

##### Abstract (translated by Google)
机器翻译（MT）是自然语言处理（NLP）文献中最热门的研究课题之一。 MT中的一个重要问题是如何合理评估MT系统，并告诉我们翻译系统是否有所改进。传统的手工判断方法费用昂贵，费时费力，不可重复，有时甚至达不成一致。另一方面，流行的自动MT评估方法也有一些缺点。首先，他们倾向于在英语作为目标语言的语言对上表现良好，而以英语作为源语言则表现不佳。其次，一些方法依赖于许多额外的语言特征来实现良好的性能，这使得该度量不能复制并容易地应用于其他语言对。第三，一些流行的指标利用不全面的因素，导致一些实际任务的表现不佳。本论文针对存在的问题，设计了新的MT评价方法，并对其在不同语言中的表现进行了考察。首先，我们设计了增强因子来进行高度准确的评估。其次，设计了一个可调整的评估模型，根据语言的特点对因素权重进行优化。第三，在我们的方法的增强版本中，我们使用POS来设计简洁的语言特征，表明当使用一些外部语言资源时，我们的方法可以产生更高的性能。最后，我们介绍了我们的指标在ACL-WMT研讨会共享任务中的实际性能，这表明所提出的方法在不同的语言中是健壮的。

##### URL
[https://arxiv.org/abs/1703.08748](https://arxiv.org/abs/1703.08748)

##### PDF
[https://arxiv.org/pdf/1703.08748](https://arxiv.org/pdf/1703.08748)

