---
layout: post
title: "Enhanced Attacks on Defensively Distilled Deep Neural Networks"
date: 2017-11-16 05:37:14
categories: arXiv_CV
tags: arXiv_CV Adversarial Face Image_Classification Classification Detection Recognition Face_Recognition
author: Yujia Liu, Weiming Zhang, Shaohua Li, Nenghai Yu
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks (DNNs) have achieved tremendous success in many tasks of machine learning, such as the image classification. Unfortunately, researchers have shown that DNNs are easily attacked by adversarial examples, slightly perturbed images which can mislead DNNs to give incorrect classification results. Such attack has seriously hampered the deployment of DNN systems in areas where security or safety requirements are strict, such as autonomous cars, face recognition, malware detection. Defensive distillation is a mechanism aimed at training a robust DNN which significantly reduces the effectiveness of adversarial examples generation. However, the state-of-the-art attack can be successful on distilled networks with 100% probability. But it is a white-box attack which needs to know the inner information of DNN. Whereas, the black-box scenario is more general. In this paper, we first propose the epsilon-neighborhood attack, which can fool the defensively distilled networks with 100% success rate in the white-box setting, and it is fast to generate adversarial examples with good visual quality. On the basis of this attack, we further propose the region-based attack against defensively distilled DNNs in the black-box setting. And we also perform the bypass attack to indirectly break the distillation defense as a complementary method. The experimental results show that our black-box attacks have a considerable success rate on defensively distilled networks.

##### Abstract (translated by Google)
深度神经网络（DNNs）在许多机器学习任务中取得了巨大的成功，如图像分类。不幸的是，研究人员已经表明，DNN很容易受敌对的例子攻击，微扰图像会误导DNNs给出不正确的分类结果。这种攻击严重阻碍了DNN系统在安全或安全要求严格的地区的部署，如自动汽车，人脸识别，恶意软件检测等。防御性蒸馏是一种旨在训练强大的DNN的机制，其显着降低了对抗性示例生成的有效性。然而，最先进的攻击可能在100％概率的蒸馏网络上成功。但是这是一个需要了解DNN内部信息的白盒攻击。而黑匣子的情况则更为一般。在本文中，我们首先提出了ε邻域攻击，它可以在白盒设置中以100％的成功率欺骗防御性被蒸馏的网络，并且生成具有良好视觉质量的对抗性示例是快速的。在这个攻击的基础上，我们进一步提出了在黑盒子里对防御蒸馏的DNNs的区域攻击。而且我们也进行了旁路攻击，间接打破了蒸馏防御的一种补充方法。实验结果表明，我们的黑盒攻击在防御性被蒸馏的网络上有相当大的成功率。

##### URL
[https://arxiv.org/abs/1711.05934](https://arxiv.org/abs/1711.05934)

##### PDF
[https://arxiv.org/pdf/1711.05934](https://arxiv.org/pdf/1711.05934)

