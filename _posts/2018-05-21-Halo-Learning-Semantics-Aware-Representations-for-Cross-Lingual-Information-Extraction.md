---
layout: post
title: "Halo: Learning Semantics-Aware Representations for Cross-Lingual Information Extraction"
date: 2018-05-21 19:57:23
categories: arXiv_CL
tags: arXiv_CL
author: Hongyuan Mei, Sheng Zhang, Kevin Duh, Benjamin Van Durme
mathjax: true
---

* content
{:toc}

##### Abstract
Cross-lingual information extraction (CLIE) is an important and challenging task, especially in low resource scenarios. To tackle this challenge, we propose a training method, called Halo, which enforces the local region of each hidden state of a neural model to only generate target tokens with the same semantic structure tag. This simple but powerful technique enables a neural model to learn semantics-aware representations that are robust to noise, without introducing any extra parameter, thus yielding better generalization in both high and low resource settings.

##### Abstract (translated by Google)
跨语言信息提取（CLIE）是一项重要且具有挑战性的任务，特别是在低资源情况下。为了应对这一挑战，我们提出了一种名为Halo的训练方法，该方法强制神经模型的每个隐藏状态的局部区域仅生成具有相同语义结构标记的目标令牌。这种简单而强大的技术使得神经模型能够学习对噪声强健的语义感知表示，而不需要引入任何额外的参数，从而在高和低资源设置中产生更好的泛化。

##### URL
[https://arxiv.org/abs/1805.08271](https://arxiv.org/abs/1805.08271)

##### PDF
[https://arxiv.org/pdf/1805.08271](https://arxiv.org/pdf/1805.08271)

