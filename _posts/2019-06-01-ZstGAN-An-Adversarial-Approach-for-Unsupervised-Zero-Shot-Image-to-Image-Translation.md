---
layout: post
title: "ZstGAN: An Adversarial Approach for Unsupervised Zero-Shot Image-to-Image Translation"
date: 2019-06-01 08:43:44
categories: arXiv_CV
tags: arXiv_CV Adversarial Knowledge GAN Inference
author: Jianxin Lin, Yingce Xia, Sen Liu, Tao Qin, Zhibo Chen
mathjax: true
---

* content
{:toc}

##### Abstract
Image-to-image translation models have shown remarkable ability on transferring images among different domains. Most of existing work follows the setting that the source domain and target domain keep the same at training and inference phases, which cannot be generalized to the scenarios for translating an image from an unseen domain to an another unseen domain. In this work, we propose the Unsupervised Zero-Shot Image-to-image Translation (UZSIT) problem, which aims to learn a model that can transfer translation knowledge from seen domains to unseen domains. Accordingly, we propose a framework called ZstGAN: By introducing an adversarial training scheme, ZstGAN learns to model each domain with domain-specific feature distribution that is semantically consistent on vision and attribute modalities. Then the domain-invariant features are disentangled with an shared encoder for image generation. We carry out extensive experiments on CUB and FLO datasets, and the results demonstrate the effectiveness of proposed method on UZSIT task. Moreover, ZstGAN shows significant accuracy improvements over state-of-the-art zero-shot learning methods on CUB and FLO.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.00184](http://arxiv.org/abs/1906.00184)

##### PDF
[http://arxiv.org/pdf/1906.00184](http://arxiv.org/pdf/1906.00184)

