---
layout: post
title: "Expressive Speech Synthesis via Modeling Expressions with Variational Autoencoder"
date: 2018-06-27 06:42:35
categories: arXiv_CL
tags: arXiv_CL
author: Kei Akuzawa, Yusuke Iwasawa, Yutaka Matsuo
mathjax: true
---

* content
{:toc}

##### Abstract
Recent advances in neural autoregressive models have improve the performance of speech synthesis (SS). However, as they lack the ability to model global characteristics of speech (such as speaker individualities or speaking styles), particularly when these characteristics have not been labeled, making neural autoregressive SS systems more expressive is still an open issue. In this paper, we propose to combine VoiceLoop, an autoregressive SS model, with Variational Autoencoder (VAE). This approach, unlike traditional autoregressive SS systems, uses VAE to model the global characteristics explicitly, enabling the expressiveness of the synthesized speech to be controlled in an unsupervised manner. Experiments using the VCTK and Blizzard2012 datasets show the VAE helps VoiceLoop to generate higher quality speech and to control the expressions in its synthesized speech by incorporating global characteristics into the speech generating process.

##### Abstract (translated by Google)
神经自回归模型的最新进展提高了语音合成（SS）的性能。然而，由于他们缺乏对言语的全球特征进行建模的能力（例如说话者的个性或说话风格），特别是当这些特征没有被标记时，使神经自回归SS系统更具表现力仍然是一个悬而未决的问题。在本文中，我们建议将VoiceLoop（一种自回归SS模型）与Variational Autoencoder（VAE）结合起来。与传统的自回归SS系统不同，这种方法使用VAE来明确地模拟全局特征，使合成语音的表现能够以无监督的方式被控制。使用VCTK和Blizzard2012数据集进行的实验表明，VAE有助于VoiceLoop生成更高质量的语音，并通过将全局特征整合到语音生成过程中来控制其合成语音中的表达。

##### URL
[http://arxiv.org/abs/1804.02135](http://arxiv.org/abs/1804.02135)

##### PDF
[http://arxiv.org/pdf/1804.02135](http://arxiv.org/pdf/1804.02135)

