---
layout: post
title: "Variational Bi-domain Triplet Autoencoder"
date: 2018-06-22 13:58:42
categories: arXiv_CV
tags: arXiv_CV Relation
author: Rita Kuznetsova, Oleg Bakhteev
mathjax: true
---

* content
{:toc}

##### Abstract
We investigate deep generative models, which allow us to use training data from one domain to build a model for another domain. We consider domains to have similar structure (texts, images). We propose the Variational Bi-domain Triplet Autoencoder (VBTA) that learns a joint distribution of objects from different domains. There are many cases when obtaining any supervision (e.g. paired data) is difficult or ambiguous. For such cases we can seek a method that is able to the information about data relation and structure from the latent space. We extend the VBTAs objective function by the relative constraints or triplets that sampled from the shared latent space across domains. In other words, we combine the deep generative model with a metric learning ideas in order to improve the final objective with the triplets information. We demonstrate the performance of the VBTA model on different tasks: bi-directional image generation, image-to-image translation, even on unpaired data. We also provide the qualitative analysis. We show that VBTA model is comparable and outperforms some of the existing generative models.

##### Abstract (translated by Google)
我们调查深层生成模型，它允许我们使用来自一个域的训练数据为另一个域建立一个模型。我们认为域名具有相似的结构（文本，图片）。我们提出变换双域三重自动编码器（VBTA），它学习来自不同域的对象的联合分布。有很多情况下，获得任何监督（例如配对资料）都很困难或模棱两可。对于这种情况，我们可以寻找一种能够从潜在空间获得关于数据关系和结构的信息的方法。我们通过跨领域的共享潜在空间抽样的相对约束或三元组来扩展VBTA的目标函数。换句话说，我们将深度生成模型与度量学习想法结合起来，以提高三胞胎信息的最终目标。我们演示了VBTA模型在不同任务上的性能：双向图像生成，图像到图像转换，甚至是未配对的数据。我们也提供定性分析。我们表明，VBTA模型是可比的，并胜过一些现有的生成模型。

##### URL
[http://arxiv.org/abs/1806.08672](http://arxiv.org/abs/1806.08672)

##### PDF
[http://arxiv.org/pdf/1806.08672](http://arxiv.org/pdf/1806.08672)

