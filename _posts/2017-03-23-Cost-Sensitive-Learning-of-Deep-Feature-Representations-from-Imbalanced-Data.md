---
layout: post
title: "Cost Sensitive Learning of Deep Feature Representations from Imbalanced Data"
date: 2017-03-23 10:57:10
categories: arXiv_CV
tags: arXiv_CV Object_Detection Image_Classification Classification Detection
author: Salman H. Khan, Munawar Hayat, Mohammed Bennamoun, Ferdous Sohel, Roberto Togneri
mathjax: true
---

* content
{:toc}

##### Abstract
Class imbalance is a common problem in the case of real-world object detection and classification tasks. Data of some classes is abundant making them an over-represented majority, and data of other classes is scarce, making them an under-represented minority. This imbalance makes it challenging for a classifier to appropriately learn the discriminating boundaries of the majority and minority classes. In this work, we propose a cost sensitive deep neural network which can automatically learn robust feature representations for both the majority and minority classes. During training, our learning procedure jointly optimizes the class dependent costs and the neural network parameters. The proposed approach is applicable to both binary and multi-class problems without any modification. Moreover, as opposed to data level approaches, we do not alter the original data distribution which results in a lower computational cost during the training process. We report the results of our experiments on six major image classification datasets and show that the proposed approach significantly outperforms the baseline algorithms. Comparisons with popular data sampling techniques and cost sensitive classifiers demonstrate the superior performance of our proposed method.

##### Abstract (translated by Google)
在实际物体检测和分类任务的情况下，类别不平衡是常见的问题。一些阶层的数据丰富，使得他们占多数，其他阶层的数据稀缺，使他们成为少数派。这种不平衡使分类者难以适当地学习大多数和少数民族的歧视性界限。在这项工作中，我们提出了一个成本敏感的深度神经网络，可以自动学习大多数和少数类的强大的特征表示。在训练期间，我们的学习过程共同优化类相关成本和神经网络参数。所提出的方法适用于二元和多类问题而无需任何修改。而且，与数据级方法相反，我们不改变原始数据分布，这在训练过程中导致较低的计算成本。我们在六个主要的图像分类数据集上报告了我们的实验结果，并且表明所提出的方法明显优于基线算法。与流行的数据采样技术和成本敏感的分类器的比较证明了我们提出的方法的优越性能。

##### URL
[https://arxiv.org/abs/1508.03422](https://arxiv.org/abs/1508.03422)

##### PDF
[https://arxiv.org/pdf/1508.03422](https://arxiv.org/pdf/1508.03422)

