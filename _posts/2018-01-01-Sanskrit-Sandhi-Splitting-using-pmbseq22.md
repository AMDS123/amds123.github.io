---
layout: post
title: "Sanskrit Sandhi Splitting using $pmb{seq2^2}$"
date: 2018-01-01 11:27:05
categories: arXiv_CL
tags: arXiv_CL Knowledge RNN Deep_Learning
author: Neelamadhav Gantayat, Rahul A R, Naveen Panwar, Anush Sankaran, Senthil Mani
mathjax: true
---

* content
{:toc}

##### Abstract
In Sanskrit, small words (morphemes) are combined through a morphophonological process called Sandhi to form compound words. Sandhi splitting is the process of splitting a given compound word into its constituent morphemes. Although rules governing the splitting of words exist, it is highly challenging to identify the location of the splits in a compound word, as the same compound word might be broken down in multiple ways to provide syntactically correct splits. % it is highly challenging to identify where the split(s) occur, as the same compound word might be broken down in multiple ways to provide partly correct splits. Existing systems explore incorporating these pre-defined splitting rules, but have low accuracy since they don't address the fundamental problem of identifying the split location. 
 With this work, we propose a novel Double Decoder RNN (DD-RNN) architecture which i) predicts the location of the split(s) with an accuracy of 95\% and ii) predicts the constituent words (i.e. learning the Sandhi splitting rules) with an accuracy of 79.5\%. To the best of our knowledge, deep learning techniques have never been applied to the Sandhi splitting problem before. We further demonstrate that our model out-performs the previous state-of-the-art significantly.

##### Abstract (translated by Google)
在梵文中，小词（词素）通过称为桑希的形态学过程组合形成复合词。散文分裂是将一个特定的复合词分解成其组成语素的过程。尽管存在分裂词语的规则，但是鉴别分词在复合词中的位置是非常具有挑战性的，因为相同的复合词可能以多种方式分解以提供句法上正确的分裂。 ％鉴别分裂的位置是非常具有挑战性的，因为同一个复合词可能以多种方式分解以提供部分正确的分裂。现有系统探索纳入这些预定义的分割规则，但由于没有解决识别分割位置的基本问题，因此具有较低的准确性。
 通过这项工作，我们提出了一种新颖的双解码器RNN（DD-RNN）架构，其中i）以95％的准确度预测分裂的位置，并且ii）预测组成词（即学习分散规则），准确率为79.5％。就我们所知，深度学习技术从来没有被应用于以前的“分散”问题。我们进一步证明，我们的模型显着地超越了以前的技术水平。

##### URL
[http://arxiv.org/abs/1801.00428](http://arxiv.org/abs/1801.00428)

##### PDF
[http://arxiv.org/pdf/1801.00428](http://arxiv.org/pdf/1801.00428)

