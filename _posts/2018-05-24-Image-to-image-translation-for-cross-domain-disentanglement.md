---
layout: post
title: "Image-to-image translation for cross-domain disentanglement"
date: 2018-05-24 15:30:23
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Abel Gonzalez-Garcia, Joost van de Weijer, Yoshua Bengio
mathjax: true
---

* content
{:toc}

##### Abstract
Deep image translation methods have recently shown excellent results, outputting high-quality images covering multiple modes of the data distribution. There has also been increased interest in disentangling the internal representations learned by deep methods to further improve their performance and achieve a finer control. In this paper, we bridge these two objectives and introduce the concept of cross-domain disentanglement. We aim to separate the internal representation into three parts. The shared part contains information for both domains. The exclusive parts, on the other hand, contain only factors of variation that are particular to each domain. We achieve this through bidirectional image translation based on Generative Adversarial Networks and cross-domain autoencoders, a novel network component. The obtained model offers multiple advantages. We can output diverse samples covering multiple modes of the distributions of both domains. We can perform cross-domain retrieval without the need of labeled data. Finally, we can perform domain-specific image transfer and interpolation. We compare our model to the state-of-the-art in multi-modal image translation and achieve better results.

##### Abstract (translated by Google)
最近，深度图像转换方法显示出优异的结果，输出覆盖多种数据分布模式的高质量图像。人们对解决深层方法所学的内部表示以进一步改善其表现和实现更好的控制也越来越感兴趣。在本文中，我们弥合了这两个目标，并引入了跨域解开的概念。我们旨在将内部表示分成三部分。共享部分包含两个域的信息。另一方面，专有部分仅包含每个域特有的变化因素。我们通过基于生成敌对网络和跨域自动编码器（一种新颖的网络组件）的双向图像转换来实现这一目标。所获得的模型提供了多个优点。我们可以输出涵盖这两个域的多种分布模式的不同样本。我们可以在不需要标记数据的情况下执行跨域检索。最后，我们可以执行特定领域的图像传输和插值。我们将我们的模型与多模态图像转换中的最新技术进行比较，并获得更好的结果。

##### URL
[http://arxiv.org/abs/1805.09730](http://arxiv.org/abs/1805.09730)

##### PDF
[http://arxiv.org/pdf/1805.09730](http://arxiv.org/pdf/1805.09730)

