---
layout: post
title: "Single-Shot Multi-Person 3D Pose Estimation From Monocular RGB"
date: 2018-08-28 16:48:16
categories: arXiv_CV
tags: arXiv_CV Pose_Estimation Inference Prediction
author: Dushyant Mehta, Oleksandr Sotnychenko, Franziska Mueller, Weipeng Xu, Srinath Sridhar, Gerard Pons-Moll, Christian Theobalt
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a new single-shot method for multi-person 3D pose estimation in general scenes from a monocular RGB camera. Our approach uses novel occlusion-robust pose-maps (ORPM) which enable full body pose inference even under strong partial occlusions by other people and objects in the scene. ORPM outputs a fixed number of maps which encode the 3D joint locations of all people in the scene. Body part associations allow us to infer 3D pose for an arbitrary number of people without explicit bounding box prediction. To train our approach we introduce MuCo-3DHP, the first large scale training data set showing real images of sophisticated multi-person interactions and occlusions. We synthesize a large corpus of multi-person images by compositing images of individual people (with ground truth from mutli-view performance capture). We evaluate our method on our new challenging 3D annotated multi-person test set MuPoTs-3D where we achieve state-of-the-art performance. To further stimulate research in multi-person 3D pose estimation, we will make our new datasets, and associated code publicly available for research purposes.

##### Abstract (translated by Google)
我们提出了一种新的单镜头方法，用于在单目RGB相机的一般场景中进行多人3D姿态估计。我们的方法使用新颖的遮挡 - 鲁棒姿势图（ORPM），即使在场景中的其他人和物体的强烈部分遮挡下也能够进行全身姿势推理。 ORPM输出固定数量的地图，这些地图编码场景中所有人的3D关节位置。身体部位关联允许我们在没有显式边界框预测的情况下推断任意数量的人的3D姿势。为了训练我们的方法，我们引入了MuCo-3DHP，这是第一个大规模训练数据集，显示了复杂的多人交互和遮挡的真实图像。我们通过合成个人的图像来合成大量的多人图像（具有来自多视图性能捕获的基本事实）。我们在新的具有挑战性的3D注释多人测试集MuPoTs-3D上评估我们的方法，我们在这里实现了最先进的性能。为了进一步激发多人3D姿态估计的研究，我们将使我们的新数据集和相关代码公开用于研究目的。

##### URL
[http://arxiv.org/abs/1712.03453](http://arxiv.org/abs/1712.03453)

##### PDF
[http://arxiv.org/pdf/1712.03453](http://arxiv.org/pdf/1712.03453)

