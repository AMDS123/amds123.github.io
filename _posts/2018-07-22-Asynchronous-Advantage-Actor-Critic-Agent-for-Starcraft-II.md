---
layout: post
title: "Asynchronous Advantage Actor-Critic Agent for Starcraft II"
date: 2018-07-22 01:07:43
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Transfer_Learning
author: Basel Alghanem, Keerthana P G
mathjax: true
---

* content
{:toc}

##### Abstract
Deep reinforcement learning, and especially the Asynchronous Advantage Actor-Critic algorithm, has been successfully used to achieve super-human performance in a variety of video games. Starcraft II is a new challenge for the reinforcement learning community with the release of pysc2 learning environment proposed by Google Deepmind and Blizzard Entertainment. Despite being a target for several AI developers, few have achieved human level performance. In this project we explain the complexities of this environment and discuss the results from our experiments on the environment. We have compared various architectures and have proved that transfer learning can be an effective paradigm in reinforcement learning research for complex scenarios requiring skill transfer.

##### Abstract (translated by Google)
深度强化学习，尤其是Asynchronous Advantage Actor-Critic算法，已成功用于在各种视频游戏中实现超人类表现。随着Google Deepmind和暴雪娱乐提出的pysc2学习环境的发布，星际争霸II对强化学习社区来说是一个新的挑战。尽管是几个AI开发人员的目标，但很少有人达到人类水平的表现。在这个项目中，我们解释了这种环境的复杂性，并讨论了我们的环境实验结果。我们比较了各种架构，并证明了转移学习可以成为需要技能转移的复杂场景的强化学习研究的有效范例。

##### URL
[http://arxiv.org/abs/1807.08217](http://arxiv.org/abs/1807.08217)

##### PDF
[http://arxiv.org/pdf/1807.08217](http://arxiv.org/pdf/1807.08217)

