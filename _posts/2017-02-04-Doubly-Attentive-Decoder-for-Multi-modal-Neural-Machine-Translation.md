---
layout: post
title: "Doubly-Attentive Decoder for Multi-modal Neural Machine Translation"
date: 2017-02-04 13:46:53
categories: arXiv_SD
tags: arXiv_SD Image_Caption Attention CNN
author: Iacer Calixto, Qun Liu, Nick Campbell
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a Multi-modal Neural Machine Translation model in which a doubly-attentive decoder naturally incorporates spatial visual features obtained using pre-trained convolutional neural networks, bridging the gap between image description and translation. Our decoder learns to attend to source-language words and parts of an image independently by means of two separate attention mechanisms as it generates words in the target language. We find that our model can efficiently exploit not just back-translated in-domain multi-modal data but also large general-domain text-only MT corpora. We also report state-of-the-art results on the Multi30k data set.

##### Abstract (translated by Google)
我们介绍一种多模态神经机器翻译模型，其中双注意解码器自然地结合使用预先训练的卷积神经网络获得的空间视觉特征，弥补了图像描述和翻译之间的差距。我们的解码器通过两种单独的注意机制独立地学习源语言单词和图像的某些部分，因为它会以目标语言生成单词。我们发现，我们的模型可以有效地利用不仅仅是背部翻译的域内多模式数据，而且还有大型的通用域文本只有MT语料库。我们也报告了Multi30k数据集的最新成果。

##### URL
[https://arxiv.org/abs/1702.01287](https://arxiv.org/abs/1702.01287)

##### PDF
[https://arxiv.org/pdf/1702.01287](https://arxiv.org/pdf/1702.01287)

