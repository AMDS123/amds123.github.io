---
layout: post
title: "Hindsight policy gradients"
date: 2018-06-21 14:11:06
categories: arXiv_AI
tags: arXiv_AI Sparse Reinforcement_Learning
author: Paulo Rauber, Avinash Ummadisingu, Filipe Mutz, Juergen Schmidhuber
mathjax: true
---

* content
{:toc}

##### Abstract
A reinforcement learning agent that needs to pursue different goals across episodes requires a goal-conditional policy. In addition to their potential to generalize desirable behavior to unseen goals, such policies may also enable higher-level planning based on subgoals. In sparse-reward environments, the capacity to exploit information about the degree to which an arbitrary goal has been achieved while another goal was intended appears crucial to enable sample efficient learning. However, reinforcement learning agents have only recently been endowed with such capacity for hindsight. In this paper, we demonstrate how hindsight can be introduced to policy gradient methods, generalizing this idea to a broad class of successful algorithms. Our experiments on a diverse selection of sparse-reward environments show that hindsight leads to a remarkable increase in sample efficiency.

##### Abstract (translated by Google)
一个强化学习代理需要在不同情节中追求不同的目标，这需要有目标有条件的策略。除了可能将理想行为推广到看不见的目标之外，此类政策还可以实现基于子目标的更高层次的规划。在稀疏奖励环境中，利用有关实现任意目标的程度的信息的能力，同时实现另一个目标对于实现样本高效学习至关重要。但是，强化学习机构最近才被赋予了这种后见之明的能力。在本文中，我们演示了如何引入策略梯度方法，将这个思想推广到一大类成功的算法。我们对多种稀疏奖励环境的实验表明，事后看来导致样本效率显着提高。

##### URL
[http://arxiv.org/abs/1711.06006](http://arxiv.org/abs/1711.06006)

##### PDF
[http://arxiv.org/pdf/1711.06006](http://arxiv.org/pdf/1711.06006)

