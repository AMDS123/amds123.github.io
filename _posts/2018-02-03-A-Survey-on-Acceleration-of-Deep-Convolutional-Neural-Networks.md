---
layout: post
title: "A Survey on Acceleration of Deep Convolutional Neural Networks"
date: 2018-02-03 08:52:12
categories: arXiv_CV
tags: arXiv_CV Survey CNN Deep_Learning
author: Jian Cheng, Peisong Wang, Gang Li, Qinghao Hu, Hanqing Lu
mathjax: true
---

* content
{:toc}

##### Abstract
Deep Neural Networks have achieved remarkable progress during the past few years and are currently the fundamental tools of many intelligent systems. At the same time, the computational complexity and resource consumption of these networks are also continuously increasing. This will pose a significant challenge to the deployment of such networks, especially for real-time applications or on resource-limited devices. Thus, network acceleration have become a hot topic within the deep learning community. As for hardware implementation of deep neural networks, a batch of accelerators based on FPGA/ASIC have been proposed these years. In this paper, we provide a comprehensive survey about the recent advances on network acceleration, compression and accelerator design from both algorithm and hardware side. Specifically, we provide thorough analysis for each of the following topics: network pruning, low-rank approximation, network quantization, teacher-student networks, compact network design and hardware accelerator. Finally, we make a discussion and introduce a few possible future directions.

##### Abstract (translated by Google)
深度神经网络在过去几年中取得了显着的进步，目前是许多智能系统的基本工具。同时，这些网络的计算复杂度和资源消耗也在不断增加。这将对这种网络的部署构成重大挑战，特别是对于实时应用或资源有限的设备。因此，网络加速已成为深度学习社区的热门话题。对于深度神经网络的硬件实现，近年来提出了一批基于FPGA / ASIC的加速器。在本文中，我们从算法和硬件两方面对网络加速，压缩和加速器设计的最新进展进行了全面的调查。具体而言，我们针对以下主题进行深入分析：网络修剪，低阶逼近，网络量化，师生网络，紧凑型网络设计和硬件加速器。最后，我们进行讨论，并介绍几个可能的未来方向。

##### URL
[http://arxiv.org/abs/1802.00939](http://arxiv.org/abs/1802.00939)

##### PDF
[http://arxiv.org/pdf/1802.00939](http://arxiv.org/pdf/1802.00939)

