---
layout: post
title: "Weakly-Supervised Attention and Relation Learning for Facial Action Unit Detection"
date: 2018-08-10 08:51:30
categories: arXiv_CV
tags: arXiv_CV Knowledge Attention Detection Relation
author: Zhiwen Shao, Zhilei Liu, Jianfei Cai, Yunsheng Wu, Lizhuang Ma
mathjax: true
---

* content
{:toc}

##### Abstract
Attention mechanism has recently attracted increasing attentions in the field of facial action unit (AU) detection. By finding the region of interest (ROI) of each AU with the attention mechanism, AU related local features can be captured. Most existing AU detection works design fixed attentions based on the prior knowledge, without considering the nonrigidity of AUs and relations among AUs. In this paper, we propose a novel end-to-end weakly-supervised attention and relation learning framework for AU detection, which has not been explored before. In particular, to select and extract AU related features, both channel-wise attentions and spatial attentions are learned with AU labels only. Moreover, pixel-level relations for AUs are learned to refine spatial attentions and extract more accurate local features. A multi-scale local region learning method is further proposed to adapt multi-scale AUs in different locations, which can facilitate the weakly-supervised attention and relation learning. Extensive experiments on BP4D and DISFA benchmarks demonstrate that our framework (i) outperforms the state-of-the-art methods for AU detection, and (ii) also achieves superior performance of AU intensity estimation with a simple extension.

##### Abstract (translated by Google)
注意机制最近在面部动作单元（AU）检测领域引起了越来越多的关注。通过利用关注机制找到每个AU的感兴趣区域（ROI），可以捕获AU相关的局部特征。大多数现有的AU检测工作基于先验知识设计固定的注意事项，而不考虑AU的非爬行性和AU之间的关系。在本文中，我们提出了一种新的端到端弱监督注意和关联学习框架的AU检测，这在以前没有被探索过。特别地，为了选择和提取AU相关特征，仅使用AU标签来学习频道注意和空间注意。此外，学习AU的像素级关系以改善空间注意力并提取更准确的局部特征。进一步提出了一种多尺度局部区域学习方法，以适应不同位置的多尺度AU，这可以促进弱监督的关注和关系学习。对BP4D和DISFA基准测试的广泛实验表明，我们的框架（i）优于最先进的AU检测方法，（ii）通过简单的扩展也实现了AU强度估计的卓越性能。

##### URL
[http://arxiv.org/abs/1808.03457](http://arxiv.org/abs/1808.03457)

##### PDF
[http://arxiv.org/pdf/1808.03457](http://arxiv.org/pdf/1808.03457)

