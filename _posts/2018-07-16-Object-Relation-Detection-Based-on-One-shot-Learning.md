---
layout: post
title: "Object Relation Detection Based on One-shot Learning"
date: 2018-07-16 13:42:28
categories: arXiv_CV
tags: arXiv_CV Image_Caption Attention Deep_Learning Detection Relation Recognition
author: Li Zhou, Jian Zhao, Jianshu Li, Li Yuan, Jiashi Feng
mathjax: true
---

* content
{:toc}

##### Abstract
Detecting the relations among objects, such as "cat on sofa" and "person ride horse", is a crucial task in image understanding, and beneficial to bridging the semantic gap between images and natural language. Despite the remarkable progress of deep learning in detection and recognition of individual objects, it is still a challenging task to localize and recognize the relations between objects due to the complex combinatorial nature of various kinds of object relations. Inspired by the recent advances in one-shot learning, we propose a simple yet effective Semantics Induced Learner (SIL) model for solving this challenging task. Learning in one-shot manner can enable a detection model to adapt to a huge number of object relations with diverse appearance effectively and robustly. In addition, the SIL combines bottom-up and top-down attention mech- anisms, therefore enabling attention at the level of vision and semantics favorably. Within our proposed model, the bottom-up mechanism, which is based on Faster R-CNN, proposes objects regions, and the top-down mechanism selects and integrates visual features according to semantic information. Experiments demonstrate the effectiveness of our framework over other state-of-the-art methods on two large-scale data sets for object relation detection.

##### Abstract (translated by Google)
检测物体之间的关系，如“沙发上的猫”和“人骑马”，是图像理解中的一项重要任务，有利于弥合图像与自然语言之间的语义鸿沟。尽管深度学习在检测和识别单个对象方面取得了显着进步，但由于各种对象关系的复杂组合性质，定位和识别对象之间的关系仍然是一项具有挑战性的任务。受到最近一次性学习的进步的启发，我们提出了一种简单而有效的语义诱导学习者（SIL）模型来解决这一具有挑战性的任务。以一次性方式学习可以使检测模型有效且鲁棒地适应具有不同外观的大量对象关系。此外，SIL结合了自下而上和自上而下的注意力机制，因此有利于在视觉和语义层面上获得关注。在我们提出的模型中，基于Faster R-CNN的自下而上机制提出了对象区域，而自上而下机制根据语义信息选择和集成了视觉特征。实验证明了我们的框架相对于其他最先进的方法在两个用于对象关系检测的大规模数据集上的有效性。

##### URL
[http://arxiv.org/abs/1807.05857](http://arxiv.org/abs/1807.05857)

##### PDF
[http://arxiv.org/pdf/1807.05857](http://arxiv.org/pdf/1807.05857)

