---
layout: post
title: "Learning to Plan via Neural Exploration-Exploitation Trees"
date: 2019-02-28 20:53:13
categories: arXiv_RO
tags: arXiv_RO
author: Binghong Chen, Bo Dai, Le Song
mathjax: true
---

* content
{:toc}

##### Abstract
Sampling-based algorithms such as RRT and its variants are powerful tools for path planning problems in high-dimensional continuous state and action spaces. While these algorithms perform systematic exploration of the state space, they do not fully exploit past planning experiences from similar environments. In this paper, we design a meta path planning algorithm, called \emph{Neural Exploration-Exploitation Trees} (NEXT), which can exploit past experience to drastically reduce the sample requirement for solving new path planning problems. More specifically, NEXT contains a novel neural architecture which can learn from experiences the dependency between task structures and promising path search directions. Then this learned prior is integrated with a UCB-type algorithm to achieve an online balance between \emph{exploration} and \emph{exploitation} when solving a new problem. Empirically, we show that NEXT can complete the planning tasks with very small searching trees and significantly outperforms previous state-of-the-arts on several benchmark problems.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.00070](http://arxiv.org/abs/1903.00070)

##### PDF
[http://arxiv.org/pdf/1903.00070](http://arxiv.org/pdf/1903.00070)

