---
layout: post
title: "Improving Image Captioning with Conditional Generative Adversarial Nets"
date: 2018-05-18 09:31:53
categories: arXiv_CV
tags: arXiv_CV Image_Caption Adversarial Reinforcement_Learning Caption RNN
author: Chen Chen, Shuai Mu, Wanpeng Xiao, Zexiong Ye, Liesi Wu, Fuming Ma, Qi Ju
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a novel conditional generative adversarial nets based image captioning framework as an extension of traditional reinforcement learning (RL) based encoder-decoder architecture. To deal with the inconsistent evaluation problem between objective language metrics and subjective human judgements, we are inspired to design some "discriminator" networks to automatically and progressively determine whether generated caption is human described or machine generated. Two kinds of discriminator architecture (CNN and RNN based structures) are introduced since each has its own advantages. The proposed algorithm is generic so that it can enhance any existing encoder-decoder based image captioning model and we show that conventional RL training method is just a special case of our framework. Empirically, we show consistent improvements over all language evaluation metrics for different stage-of-the-art image captioning models.

##### Abstract (translated by Google)
在本文中，我们提出了一种新的基于条件生成对抗网络的图像字幕框架作为传统强化学习（RL）编码器 - 解码器架构的扩展。为了处理客观语言度量与主观人类判断之间不一致的评估问题，我们受到启发，设计了一些“鉴别器”网络，以自动逐步确定生成的标题是人为描述还是机器生成。引入两种鉴别器结构（基于CNN和RNN的结构），因为每种结构都有其自身的优点。所提出的算法是通用的，因此它可以增强任何现有的基于编码器 - 解码器的图像字幕模型，并且我们表明传统的RL训练方法只是我们框架的一个特例。根据经验，我们对不同最先进的图像字幕模型的所有语言评估指标进行了一致的改进。

##### URL
[https://arxiv.org/abs/1805.07112](https://arxiv.org/abs/1805.07112)

##### PDF
[https://arxiv.org/pdf/1805.07112](https://arxiv.org/pdf/1805.07112)

