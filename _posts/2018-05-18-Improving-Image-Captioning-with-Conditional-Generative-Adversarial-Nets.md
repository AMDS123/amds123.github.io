---
layout: post
title: "Improving Image Captioning with Conditional Generative Adversarial Nets"
date: 2018-05-18 09:31:53
categories: arXiv_CV
tags: arXiv_CV Image_Caption Adversarial Reinforcement_Learning Caption RNN
author: Chen Chen, Shuai Mu, Wanpeng Xiao, Zexiong Ye, Liesi Wu, Fuming Ma, Qi Ju
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a novel conditional generative adversarial nets based image captioning framework as an extension of traditional reinforcement learning (RL) based encoder-decoder architecture. To deal with the inconsistent evaluation problem between objective language metrics and subjective human judgements, we are inspired to design some "discriminator" networks to automatically and progressively determine whether generated caption is human described or machine generated. Two kinds of discriminator architecture (CNN and RNN based structures) are introduced since each has its own advantages. The proposed algorithm is generic so that it can enhance any existing encoder-decoder based image captioning model and we show that conventional RL training method is just a special case of our framework. Empirically, we show consistent improvements over all language evaluation metrics for different stage-of-the-art image captioning models.

##### Abstract (translated by Google)
在本文中，我们提出了一种基于传统强化学习（RL）的编码器 - 解码器架构的新型条件生成对抗网络图像字幕框架。为了处理客观语言指标与主观人类判断之间不一致的评估问题，我们鼓励设计一些“鉴别器”网络，以自动和逐步确定生成的字幕是由人类描述还是由机器生成。由于各自具有各自的优点，因此引入了两种鉴别器体系结构（基于CNN和RNN的结构）。所提出的算法是通用的，因此它可以增强任何现有的基于编码器 - 解码器的图像字幕模型，并且我们展示传统的RL训练方法仅仅是我们框架的特例。从经验上讲，我们针对不同阶段的最先进的图像字幕模型显示了所有语言评估指标的持续改进。

##### URL
[http://arxiv.org/abs/1805.07112](http://arxiv.org/abs/1805.07112)

##### PDF
[http://arxiv.org/pdf/1805.07112](http://arxiv.org/pdf/1805.07112)

