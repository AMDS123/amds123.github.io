---
layout: post
title: "Contribution of Glottal Waveform in Speech Emotion: A Comparative Pairwise Investigation"
date: 2018-08-30 07:09:04
categories: arXiv_SD
tags: arXiv_SD Classification
author: Zhongzhe Xiao, Ying Chen, Zhi Tao
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we investigated the contribution of the glottal waveform in human vocal emotion expressing. Seven emotional states including moderate and intense versions of three emotional families as anger, joy, and sadness, plus a neutral state are considered, with speech samples in Mandarin Chinese. The glottal waveform extracted from speech samples of different emotion states are first analyzed in both time domain and frequency domain to discover their differences. Comparative emotion classifications are then taken out based on features extracted from original whole speech signal and only glottal wave signal. In experiments of generation of a performance-driven hierarchical classifier architecture, and pairwise classification on individual emotional states, the low difference between accuracies obtained from speech signal and glottal signal proved that a majority of emotional cues in speech could be conveyed through glottal waveform. The best distinguishable emotional pair by glottal waveform is intense anger against moderate sadness, with the accuracy of 92.45%. It is also concluded in this work that glottal waveform represent better valence cues than arousal cues of emotion.

##### Abstract (translated by Google)
在这项工作中，我们调查了声门波形在人类声乐表达中的贡献。七种情绪状态，包括三种情绪家庭的中度和强烈版本，如愤怒，喜悦和悲伤，加上中立状态，用普通话语言样本进行考虑。首先在时域和频域分析从不同情绪状态的语音样本中提取的声门波形，以发现它们的差异。然后基于从原始整个语音信号中提取的特征和仅声门波信号来取出比较情感分类。在产生性能驱动的分层分类器结构的实验中，以及对个体情绪状态的成对分类，从语音信号和声门信号获得的精度之间的低差异证明了语音中的大多数情绪提示可以通过声门波形传达。声门波形的最佳可区分情绪对是对温和悲伤的强烈愤怒，准确度为92.45％。在这项工作中还得出结论，声门波形代表比情绪觉醒提示更好的价态线索。

##### URL
[http://arxiv.org/abs/1808.10144](http://arxiv.org/abs/1808.10144)

##### PDF
[http://arxiv.org/pdf/1808.10144](http://arxiv.org/pdf/1808.10144)

