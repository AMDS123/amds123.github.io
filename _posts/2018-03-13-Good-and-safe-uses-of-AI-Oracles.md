---
layout: post
title: "Good and safe uses of AI Oracles"
date: 2018-03-13 16:06:38
categories: arXiv_AI
tags: arXiv_AI
author: Stuart Armstrong
mathjax: true
---

* content
{:toc}

##### Abstract
An Oracle is a design for potentially high power artificial intelligences (AIs), where the AI is made safe by restricting it to only answer questions. Unfortunately most designs cause the Oracle to be motivated to manipulate humans with the contents of their answers, and Oracles of potentially high intelligence might be very successful at this. Solving that problem, without compromising the accuracy of the answer, is tricky. This paper reduces the issue to a cryptographic-style problem of Alice ensuring that her Oracle answers her questions while not providing key information to an eavesdropping Eve. Two Oracle designs solve this problem, one counterfactual (the Oracle answers as if it expected its answer to never be read) and one on-policy, but limited by the quantity of information it can transmit.

##### Abstract (translated by Google)
甲骨文是一种潜在的高功率人工智能（AI）设计，AI通过限制它回答问题而变得安全。不幸的是，大多数设计都会导致甲骨文被动员操纵人的答案内容，并且潜在的高智商的神谕可能会非常成功。在不影响答案准确性的情况下解决这个问题是棘手的。本文将这个问题归结为Alice的密码风格问题，以确保她的Oracle回答她的问题，同时不会向窃听前夕提供关键信息。两个Oracle设计解决了这个问题，一个是反事实（甲骨文的答案好像它预计其答案永远不会被阅读）和一个在线政策，但受限于其可传输信息的数量。

##### URL
[http://arxiv.org/abs/1711.05541](http://arxiv.org/abs/1711.05541)

##### PDF
[http://arxiv.org/pdf/1711.05541](http://arxiv.org/pdf/1711.05541)

