---
layout: post
title: "Enhanced Word Representations for Bridging Anaphora Resolution"
date: 2018-03-13 13:33:06
categories: arXiv_CL
tags: arXiv_CL Knowledge Embedding
author: Yufang Hou
mathjax: true
---

* content
{:toc}

##### Abstract
Most current models of word representations(e.g.,GloVe) have successfully captured fine-grained semantics. However, semantic similarity exhibited in these word embeddings is not suitable for resolving bridging anaphora, which requires the knowledge of associative similarity (i.e., relatedness) instead of semantic similarity information between synonyms or hypernyms. We create word embeddings (embeddings_PP) to capture such relatedness by exploring the syntactic structure of noun phrases. We demonstrate that using embeddings_PP alone achieves around 30% of accuracy for bridging anaphora resolution on the ISNotes corpus. Furthermore, we achieve a substantial gain over the state-of-the-art system (Hou et al., 2013) for bridging antecedent selection.

##### Abstract (translated by Google)
大多数当前的词表示模型（例如，GloVe）已经成功地捕获了细粒度的语义。然而，这些词嵌入中表现出的语义相似性不适用于解决桥接照应，这需要关联相似性（即相关性）的知识而不是同义词或上位词之间的语义相似性信息。我们通过探索名词短语的句法结构来创建词嵌入（embeddings_PP）来捕捉这种相关性。我们证明，单独使用embeddings_PP可以在ISNotes语料库上实现桥接回指分辨率的约30％的准确度。此外，我们在最先进的系统（Hou et al。，2013）上取得了实质性的收益，以弥合先前的选择。

##### URL
[http://arxiv.org/abs/1803.04790](http://arxiv.org/abs/1803.04790)

##### PDF
[http://arxiv.org/pdf/1803.04790](http://arxiv.org/pdf/1803.04790)

