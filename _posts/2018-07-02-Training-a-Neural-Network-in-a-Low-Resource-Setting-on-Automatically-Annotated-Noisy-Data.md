---
layout: post
title: "Training a Neural Network in a Low-Resource Setting on Automatically Annotated Noisy Data"
date: 2018-07-02 15:35:02
categories: arXiv_CL
tags: arXiv_CL
author: Michael A. Hedderich, Dietrich Klakow
mathjax: true
---

* content
{:toc}

##### Abstract
Manually labeled corpora are expensive to create and often not available for low-resource languages or domains. Automatic labeling approaches are an alternative way to obtain labeled data in a quicker and cheaper way. However, these labels often contain more errors which can deteriorate a classifier's performance when trained on this data. We propose a noise layer that is added to a neural network architecture. This allows modeling the noise and train on a combination of clean and noisy data. We show that in a low-resource NER task we can improve performance by up to 35% by using additional, noisy data and handling the noise.

##### Abstract (translated by Google)
手动标记的语料库创建起来很昂贵，而且通常不适用于低资源语言或域。自动标记方法是以更快和更便宜的方式获得标记数据的替代方法。但是，这些标签通常包含更多错误，这些错误会在对此数据进行培训时降低分类器的性能。我们提出了一个添加到神经网络架构的噪声层。这样可以对噪声进行建模，并在干净和嘈杂的数据组合上进行训练。我们表明，在资源较少的NER任务中，我们可以通过使用额外的噪声数据和处理噪声来将性能提高多达35％。

##### URL
[http://arxiv.org/abs/1807.00745](http://arxiv.org/abs/1807.00745)

##### PDF
[http://arxiv.org/pdf/1807.00745](http://arxiv.org/pdf/1807.00745)

