---
layout: post
title: "Ordered Pooling of Optical Flow Sequences for Action Recognition"
date: 2017-04-06 05:27:03
categories: arXiv_CV
tags: arXiv_CV Summarization Action_Recognition CNN Recognition
author: Jue Wang, Anoop Cherian, Fatih Porikli
mathjax: true
---

* content
{:toc}

##### Abstract
Training of Convolutional Neural Networks (CNNs) on long video sequences is computationally expensive due to the substantial memory requirements and the massive number of parameters that deep architectures demand. Early fusion of video frames is thus a standard technique, in which several consecutive frames are first agglomerated into a compact representation, and then fed into the CNN as an input sample. For this purpose, a summarization approach that represents a set of consecutive RGB frames by a single dynamic image to capture pixel dynamics is proposed recently. In this paper, we introduce a novel ordered representation of consecutive optical flow frames as an alternative and argue that this representation captures the action dynamics more effectively than RGB frames. We provide intuitions on why such a representation is better for action recognition. We validate our claims on standard benchmark datasets and demonstrate that using summaries of flow images lead to significant improvements over RGB frames while achieving accuracy comparable to the state-of-the-art on UCF101 and HMDB datasets.

##### Abstract (translated by Google)
对长视频序列的卷积神经网络（CNN）的训练在计算上是昂贵的，因为需要大量的存储器需求以及深度架构所需的大量参数。因此，视频帧的早期融合是一种标准技术，其中几个连续的帧首先被聚集成一个紧凑的表示，然后作为输入样本被馈送到CNN。为此，最近提出了一种通过单个动态图像来表示一组连续的RGB帧以便捕获像素动态的总结方法。在本文中，我们引入了连续光流帧的一种新颖的有序表示作为替代，并且认为这种表示比RGB帧更有效地捕获动作动态。我们提供直觉来解释为什么这样的表示更适合于行为识别。我们验证了我们对标准基准数据集的要求，并证明使用流图的摘要可以显着改善RGB帧，同时达到与UCF101和HMDB数据集的最新水平相当的精确度。

##### URL
[https://arxiv.org/abs/1701.03246](https://arxiv.org/abs/1701.03246)

##### PDF
[https://arxiv.org/pdf/1701.03246](https://arxiv.org/pdf/1701.03246)

