---
layout: post
title: "Adaptations of ROUGE and BLEU to Better Evaluate Machine Reading Comprehension Task"
date: 2018-06-10 03:50:10
categories: arXiv_CL
tags: arXiv_CL
author: An Yang, Kai Liu, Jing Liu, Yajuan Lyu, Sujian Li
mathjax: true
---

* content
{:toc}

##### Abstract
Current evaluation metrics to question answering based machine reading comprehension (MRC) systems generally focus on the lexical overlap between the candidate and reference answers, such as ROUGE and BLEU. However, bias may appear when these metrics are used for specific question types, especially questions inquiring yes-no opinions and entity lists. In this paper, we make adaptations on the metrics to better correlate n-gram overlap with the human judgment for answers to these two question types. Statistical analysis proves the effectiveness of our approach. Our adaptations may provide positive guidance for the development of real-scene MRC systems.

##### Abstract (translated by Google)
目前对基于问答的机器阅读理解（MRC）系统的评估指标一般侧重于候选和参考答案（如ROUGE和BLEU）之间的词汇重叠。但是，如果将这些指标用于特定问题类型，特别是询问是否意见和实体列表的问题，则可能会出现偏差。在本文中，我们对度量进行了修改，以更好地将n-gram重叠与人类判断相关联，以解答这两个问题类型的答案。统计分析证明了我们方法的有效性。我们的改编可能为现场MRC系统的开发提供积极的指导。

##### URL
[http://arxiv.org/abs/1806.03578](http://arxiv.org/abs/1806.03578)

##### PDF
[http://arxiv.org/pdf/1806.03578](http://arxiv.org/pdf/1806.03578)

