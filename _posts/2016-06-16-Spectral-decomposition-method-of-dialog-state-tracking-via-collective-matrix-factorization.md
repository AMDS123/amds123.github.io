---
layout: post
title: "Spectral decomposition method of dialog state tracking via collective matrix factorization"
date: 2016-06-16 17:31:13
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition Tracking Inference Prediction Recognition
author: Julien Perez
mathjax: true
---

* content
{:toc}

##### Abstract
The task of dialog management is commonly decomposed into two sequential subtasks: dialog state tracking and dialog policy learning. In an end-to-end dialog system, the aim of dialog state tracking is to accurately estimate the true dialog state from noisy observations produced by the speech recognition and the natural language understanding modules. The state tracking task is primarily meant to support a dialog policy. From a probabilistic perspective, this is achieved by maintaining a posterior distribution over hidden dialog states composed of a set of context dependent variables. Once a dialog policy is learned, it strives to select an optimal dialog act given the estimated dialog state and a defined reward function. This paper introduces a novel method of dialog state tracking based on a bilinear algebric decomposition model that provides an efficient inference schema through collective matrix factorization. We evaluate the proposed approach on the second Dialog State Tracking Challenge (DSTC-2) dataset and we show that the proposed tracker gives encouraging results compared to the state-of-the-art trackers that participated in this standard benchmark. Finally, we show that the prediction schema is computationally efficient in comparison to the previous approaches.

##### Abstract (translated by Google)
对话管理的任务通常分解为两个连续的子任务：对话状态跟踪和对话策略学习。在一个端到端的对话系统中，对话状态跟踪的目的是通过语音识别和自然语言理解模块产生的噪声观测，准确地估计真实的对话状态。状态跟踪任务主要是为了支持对话政策。从概率的角度来看，这是通过维持由一组依赖于上下文的变量组成的隐藏对话状态的后验分布来实现的。一旦学习了对话策略，它就会努力根据估计的对话状态和一个确定的奖励函数来选择一个最佳对话行为。本文介绍了一种基于双线性代数分解模型的对话状态追踪新方法，通过集体矩阵分解提供了一个有效的推理模式。我们在第二次对话状态跟踪挑战（DSTC-2）数据集上评估了所提出的方法，并且我们显示，与参与该标准基准的最先进的跟踪器相比，所提出的跟踪器给出了令人鼓舞的结果。最后，我们表明预测模式与先前的方法相比在计算上是有效的。

##### URL
[https://arxiv.org/abs/1606.05286](https://arxiv.org/abs/1606.05286)

##### PDF
[https://arxiv.org/pdf/1606.05286](https://arxiv.org/pdf/1606.05286)

