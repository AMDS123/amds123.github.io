---
layout: post
title: "Geometric Hypergraph Learning for Visual Tracking"
date: 2016-03-18 17:32:30
categories: arXiv_CV
tags: arXiv_CV Tracking Relation
author: Dawei Du, Honggang Qi, Longyin Wen, Qi Tian, Qingming Huang, Siwei Lyu
mathjax: true
---

* content
{:toc}

##### Abstract
Graph based representation is widely used in visual tracking field by finding correct correspondences between target parts in consecutive frames. However, most graph based trackers consider pairwise geometric relations between local parts. They do not make full use of the target's intrinsic structure, thereby making the representation easily disturbed by errors in pairwise affinities when large deformation and occlusion occur. In this paper, we propose a geometric hypergraph learning based tracking method, which fully exploits high-order geometric relations among multiple correspondences of parts in consecutive frames. Then visual tracking is formulated as the mode-seeking problem on the hypergraph in which vertices represent correspondence hypotheses and hyperedges describe high-order geometric relations. Besides, a confidence-aware sampling method is developed to select representative vertices and hyperedges to construct the geometric hypergraph for more robustness and scalability. The experiments are carried out on two challenging datasets (VOT2014 and Deform-SOT) to demonstrate that the proposed method performs favorable against other existing trackers.

##### Abstract (translated by Google)
基于图的表示法被广泛用于视觉跟踪领域，通过找出连续帧中的目标部分之间的正确对应。然而，大多数基于图的追踪器考虑了局部部分之间的成对几何关系。他们没有充分利用目标的内在结构，从而使表示很容易被错误的成对亲和力，当大的变形和闭塞发生。在本文中，我们提出了一种基于几何超图学习的跟踪方法，充分利用了连续帧中多个部件对应关系之间的高阶几何关系。然后将视觉追踪公式化为超图的模式寻求问题，其中顶点代表对应假设，超图则描述高阶几何关系。此外，还开发了一种置信度的抽样方法来选择代表性的顶点和超形式来构建几何超图，以提高鲁棒性和可扩展性。在两个具有挑战性的数据集（VOT2014和Deform-SOT）上进行实验以证明所提出的方法对其他现有的跟踪器有利。

##### URL
[https://arxiv.org/abs/1603.05930](https://arxiv.org/abs/1603.05930)

##### PDF
[https://arxiv.org/pdf/1603.05930](https://arxiv.org/pdf/1603.05930)

