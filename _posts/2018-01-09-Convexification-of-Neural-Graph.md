---
layout: post
title: "Convexification of Neural Graph"
date: 2018-01-09 11:57:41
categories: arXiv_AI
tags: arXiv_AI Optimization
author: Han Xiao
mathjax: true
---

* content
{:toc}

##### Abstract
Traditionally, most complex intelligence architectures are extremely non-convex, which could not be well performed by convex optimization. However, this paper decomposes complex structures into three types of nodes: operators, algorithms and functions. Further, iteratively propagating from node to node along edge, we prove that "regarding the neural graph without triangles, it is nearly convex in each variable, when the other variables are fixed." In fact, the non-convex properties stem from triangles and functions, which could be transformed to be convex with our proposed \textit{\textbf{convexification inequality}}. In conclusion, we generally depict the landscape for the objective of neural graph and propose the methodology to convexify neural graph.

##### Abstract (translated by Google)
传统上，大多数复杂的智能体系结构是非常非凸的，不能通过凸优化来很好地执行。然而，本文将复杂结构分解为三类节点：运算符，算法和函数。进一步，沿着边缘从一个节点到另一个节点进行迭代传播，我们证明：“关于没有三角形的神经图，当其他变量固定时，每个变量都是近似凸的。事实上，非凸性来源于三角形和函数，可以用我们提出的\ textit {\ textbf {凸性不等式}来变换为凸形。总之，我们一般以神经图的目标描述景观，提出了神经图的凸显方法。

##### URL
[http://arxiv.org/abs/1801.02901](http://arxiv.org/abs/1801.02901)

##### PDF
[http://arxiv.org/pdf/1801.02901](http://arxiv.org/pdf/1801.02901)

