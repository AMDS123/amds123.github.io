---
layout: post
title: "Automatic Recognition of Facial Displays of Unfelt Emotions"
date: 2018-01-09 11:44:01
categories: arXiv_CV
tags: arXiv_CV Recognition
author: Kaustubh Kulkarni, Ciprian Adrian Corneanu, Ikechukwu Ofodile, Sergio Escalera, Xavier Baro, Sylwia Hyniewska, Juri Allik, Gholamreza Anbarjafari
mathjax: true
---

* content
{:toc}

##### Abstract
Humans modify their facial expressions in order to communicate their internal states and sometimes to mislead observers regarding their true emotional states. Evidence in experimental psychology shows that discriminative facial responses are short and subtle. This suggests that such behavior would be easier to distinguish when captured in high resolution at an increased frame rate. We are proposing SASE-FE, the first dataset of facial expressions that are either congruent or incongruent with underlying emotion states. We show that overall the problem of recognizing whether facial movements are expressions of authentic emotions or not can be successfully addressed by learning spatio-temporal representations of the data. For this purpose, we propose a method that aggregates features along fiducial trajectories in a deeply learnt space. Performance of the proposed model shows that on average it is easier to distinguish among genuine facial expressions of emotion than among unfelt facial expressions of emotion and that certain emotion pairs such as contempt and disgust are more difficult to distinguish than the rest. Furthermore, the proposed methodology improves state of the art results on CK+ and OULU-CASIA datasets for video emotion recognition, and achieves competitive results when classifying facial action units on BP4D datase.

##### Abstract (translated by Google)
人类修改他们的面部表情以传达其内部状态，有时会误导观察者关于他们的真实情绪状态。实验心理学的证据表明，有区别的面部反应是短暂而微妙的。这表明，当以高分辨率以更高的帧速率捕获时，这样的行为将更容易区分。我们提出的SASE-FE是面部表情的第一个数据集，它与基础情感状态一致或不一致。我们通过学习数据的时空表示来证明整体上识别面部运动是否是真实情绪的表达的问题可以被成功解决。为此，我们提出了一个在深度学习空间中沿着基准轨迹聚合特征的方法。该模型的性能表明，平均情况下真正的情绪面部表情比不情绪的面部表情更容易区分，而蔑视和厌恶等情感对比其他情绪更难区分。此外，所提出的方法改进了用于视频情感识别的CK +和OULU-CASIA数据集的最新结果，并且在将面部动作单元分类为BP4D数据时实现了竞争结果。

##### URL
[http://arxiv.org/abs/1707.04061](http://arxiv.org/abs/1707.04061)

##### PDF
[http://arxiv.org/pdf/1707.04061](http://arxiv.org/pdf/1707.04061)

