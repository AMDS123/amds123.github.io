---
layout: post
title: "Neural Net Models for Open-Domain Discourse Coherence"
date: 2017-09-24 01:38:11
categories: arXiv_CL
tags: arXiv_CL
author: Jiwei Li, Dan Jurafsky
mathjax: true
---

* content
{:toc}

##### Abstract
Discourse coherence is strongly associated with text quality, making it important to natural language generation and understanding. Yet existing models of coherence focus on measuring individual aspects of coherence (lexical overlap, rhetorical structure, entity centering) in narrow domains. In this paper, we describe domain-independent neural models of discourse coherence that are capable of measuring multiple aspects of coherence in existing sentences and can maintain coherence while generating new sentences. We study both discriminative models that learn to distinguish coherent from incoherent discourse, and generative models that produce coherent text, including a novel neural latent-variable Markovian generative model that captures the latent discourse dependencies between sentences in a text. Our work achieves state-of-the-art performance on multiple coherence evaluations, and marks an initial step in generating coherent texts given discourse contexts.

##### Abstract (translated by Google)
语篇连贯性与文本质量密切相关，对于自然语言的生成和理解非常重要。然而，现有的一致性模型着重于在狭窄的领域中测量连贯性的单个方面（词汇重叠，修辞结构，实体居中）。在本文中，我们描述了与领域无关的话语连贯神经模型，它们能够测量现有语句中的连贯性的多个方面，并能够在产生新的句子的同时保持连贯性。我们研究了区分连贯语言和不连贯语篇的区分模型，以及产生连贯文本的生成模型，包括一个新颖的神经潜变量马尔可夫生成模型，捕捉文本句子之间潜在的语篇依赖关系。我们的作品在多重连贯性评估方面取得了最先进的成果，标志着在给定语篇背景下产生连贯文本的第一步。

##### URL
[https://arxiv.org/abs/1606.01545](https://arxiv.org/abs/1606.01545)

##### PDF
[https://arxiv.org/pdf/1606.01545](https://arxiv.org/pdf/1606.01545)

