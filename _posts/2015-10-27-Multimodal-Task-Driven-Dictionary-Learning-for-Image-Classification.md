---
layout: post
title: "Multimodal Task-Driven Dictionary Learning for Image Classification"
date: 2015-10-27 07:26:59
categories: arXiv_CV
tags: arXiv_CV Sparse Face Action_Recognition Image_Classification Classification Recognition Face_Recognition
author: Soheil Bahrampour, Nasser M. Nasrabadi, Asok Ray, W. Kenneth Jenkins
mathjax: true
---

* content
{:toc}

##### Abstract
Dictionary learning algorithms have been successfully used for both reconstructive and discriminative tasks, where an input signal is represented with a sparse linear combination of dictionary atoms. While these methods are mostly developed for single-modality scenarios, recent studies have demonstrated the advantages of feature-level fusion based on the joint sparse representation of the multimodal inputs. In this paper, we propose a multimodal task-driven dictionary learning algorithm under the joint sparsity constraint (prior) to enforce collaborations among multiple homogeneous/heterogeneous sources of information. In this task-driven formulation, the multimodal dictionaries are learned simultaneously with their corresponding classifiers. The resulting multimodal dictionaries can generate discriminative latent features (sparse codes) from the data that are optimized for a given task such as binary or multiclass classification. Moreover, we present an extension of the proposed formulation using a mixed joint and independent sparsity prior which facilitates more flexible fusion of the modalities at feature level. The efficacy of the proposed algorithms for multimodal classification is illustrated on four different applications -- multimodal face recognition, multi-view face recognition, multi-view action recognition, and multimodal biometric recognition. It is also shown that, compared to the counterpart reconstructive-based dictionary learning algorithms, the task-driven formulations are more computationally efficient in the sense that they can be equipped with more compact dictionaries and still achieve superior performance.

##### Abstract (translated by Google)
字典学习算法已经成功地用于重建和区分性任务，其中输入信号由字典原子的稀疏线性组合表示。虽然这些方法大多是针对单一模式情景而开发的，但最近的研究已经证明了基于多模态输入的联合稀疏表示的特征级融合的优点。在本文中，我们提出了一个在联合稀疏约束下的多模式任务驱动的字典学习算法，以加强多个同类/异类信息源之间的协作。在这个任务驱动的表述中，多模态词典与其相应的分类器同时学习。由此产生的多模态字典可以从数据中生成有区别的潜在特征（稀疏代码），这些特征是针对给定任务（如二元或多类分类）优化的。此外，我们提出了使用混合联合和独立稀疏度的推荐公式的扩展，这有助于更加灵活地融合特征级别的模式。所提出的多模式分类算法的功效在四种不同的应用 - 多模式人脸识别，多视图人脸识别，多视角动作识别和多模态生物特征识别中示出。还表明，与对应的基于重建的字典学习算法相比，任务驱动的配方在计算上更有效率，因为它们可以配备更紧凑的字典并且仍然实现优越的性能。

##### URL
[https://arxiv.org/abs/1502.01094](https://arxiv.org/abs/1502.01094)

##### PDF
[https://arxiv.org/pdf/1502.01094](https://arxiv.org/pdf/1502.01094)

