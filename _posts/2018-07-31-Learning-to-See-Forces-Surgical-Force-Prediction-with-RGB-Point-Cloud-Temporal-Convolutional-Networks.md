---
layout: post
title: "Learning to See Forces: Surgical Force Prediction with RGB-Point Cloud Temporal Convolutional Networks"
date: 2018-07-31 20:04:54
categories: arXiv_CV
tags: arXiv_CV GAN CNN Deep_Learning Prediction
author: Cong Gao, Xingtong Liu, Michael Peven, Mathias Unberath, Austin Reiter
mathjax: true
---

* content
{:toc}

##### Abstract
Robotic surgery has been proven to offer clear advantages during surgical procedures, however, one of the major limitations is obtaining haptic feedback. Since it is often challenging to devise a hardware solution with accurate force feedback, we propose the use of "visual cues" to infer forces from tissue deformation. Endoscopic video is a passive sensor that is freely available, in the sense that any minimally-invasive procedure already utilizes it. To this end, we employ deep learning to infer forces from video as an attractive low-cost and accurate alternative to typically complex and expensive hardware solutions. First, we demonstrate our approach in a phantom setting using the da Vinci Surgical System affixed with an OptoForce sensor. Second, we then validate our method on an ex vivo liver organ. Our method results in a mean absolute error of 0.814 N in the ex vivo study, suggesting that it may be a promising alternative to hardware based surgical force feedback in endoscopic procedures.

##### Abstract (translated by Google)
机器人手术已被证明在外科手术过程中具有明显的优势，但是，主要限制之一是获得触觉反馈。由于设计具有精确力反馈的硬件解决方案通常具有挑战性，因此我们建议使用“视觉提示”来推断组织变形的力。内窥镜视频是一种可自由使用的无源传感器，因为任何微创手术都可以利用它。为此，我们采用深度学习来推断视频中的力量，这是通常复杂且昂贵的硬件解决方案的有吸引力的低成本和准确的替代方案。首先，我们使用附有OptoForce传感器的达芬奇手术系统在幻像设置中演示我们的方法。其次，我们在离体肝脏器官上验证我们的方法。我们的方法在离体研究中导致平均绝对误差为0.814N，这表明它可能是内窥镜手术中基于硬件的手术力反馈的有前途的替代方案。

##### URL
[https://arxiv.org/abs/1808.00057](https://arxiv.org/abs/1808.00057)

##### PDF
[https://arxiv.org/pdf/1808.00057](https://arxiv.org/pdf/1808.00057)

