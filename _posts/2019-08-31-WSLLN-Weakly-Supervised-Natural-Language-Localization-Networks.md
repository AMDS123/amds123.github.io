---
layout: post
title: "WSLLN: Weakly Supervised Natural Language Localization Networks"
date: 2019-08-31 16:30:28
categories: arXiv_CV
tags: arXiv_CV Weakly_Supervised Caption
author: Mingfei Gao, Larry S. Davis, Richard Socher, Caiming Xiong
mathjax: true
---

* content
{:toc}

##### Abstract
We propose weakly supervised language localization networks (WSLLN) to detect events in long, untrimmed videos given language queries. To learn the correspondence between visual segments and texts, most previous methods require temporal coordinates (start and end times) of events for training, which leads to high costs of annotation. WSLLN relieves the annotation burden by training with only video-sentence pairs without accessing to temporal locations of events. With a simple end-to-end structure, WSLLN measures segment-text consistency and conducts segment selection (conditioned on the text) simultaneously. Results from both are merged and optimized as a video-sentence matching problem. Experiments on ActivityNet Captions and DiDeMo demonstrate that WSLLN achieves state-of-the-art performance.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1909.00239](http://arxiv.org/abs/1909.00239)

##### PDF
[http://arxiv.org/pdf/1909.00239](http://arxiv.org/pdf/1909.00239)

