---
layout: post
title: "An Error-Oriented Approach to Word Embedding Pre-Training"
date: 2017-07-21 11:06:12
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Youmna Farag, Marek Rei, Ted Briscoe
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel word embedding pre-training approach that exploits writing errors in learners' scripts. We compare our method to previous models that tune the embeddings based on script scores and the discrimination between correct and corrupt word contexts in addition to the generic commonly-used embeddings pre-trained on large corpora. The comparison is achieved by using the aforementioned models to bootstrap a neural network that learns to predict a holistic score for scripts. Furthermore, we investigate augmenting our model with error corrections and monitor the impact on performance. Our results show that our error-oriented approach outperforms other comparable ones which is further demonstrated when training on more data. Additionally, extending the model with corrections provides further performance gains when data sparsity is an issue.

##### Abstract (translated by Google)
我们提出了一种新颖的词嵌入预训练方法，利用学习者脚本中的书写错误。我们比较我们的方法，以前的模型，调整嵌入基于脚本分数和正确和腐败的语境之间的歧视，除了在大型语料库预先训练的通用的通用嵌入。通过使用上述模型来启动一个神经网络来学习预测脚本的整体评分，从而实现比较。此外，我们调查增加我们的模型与纠错，并监测对性能的影响。我们的研究结果表明，我们的错误导向的方法胜过其他类似的进一步证明，当更多的数据训练。另外，当数据稀疏是一个问题时，用更正扩展模型可以进一步提高性能。

##### URL
[https://arxiv.org/abs/1707.06841](https://arxiv.org/abs/1707.06841)

##### PDF
[https://arxiv.org/pdf/1707.06841](https://arxiv.org/pdf/1707.06841)

