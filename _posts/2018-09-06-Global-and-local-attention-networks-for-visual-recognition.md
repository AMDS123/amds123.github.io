---
layout: post
title: "Global-and-local attention networks for visual recognition"
date: 2018-09-06 15:36:34
categories: arXiv_CV
tags: arXiv_CV Salient Attention CNN Recognition
author: Drew Linsley, Dan Shiebler, Sven Eberhardt, Thomas Serre
mathjax: true
---

* content
{:toc}

##### Abstract
State-of-the-art deep convolutional networks (DCNs) such as squeeze-and- excitation (SE) residual networks implement a form of attention, also known as contextual guidance, which is derived from global image features. Here, we explore a complementary form of attention, known as visual saliency, which is derived from local image features. We extend the SE module with a novel global-and-local attention (GALA) module which combines both forms of attention -- resulting in state-of-the-art accuracy on ILSVRC. We further describe ClickMe.ai, a large-scale online experiment designed for human participants to identify diagnostic image regions to co-train a GALA network. Adding humans-in-the-loop is shown to significantly improve network accuracy, while also yielding visual features that are more interpretable and more similar to those used by human observers.

##### Abstract (translated by Google)
诸如挤压和激励（SE）残余网络之类的现有技术的深度卷积网络（DCN）实现了一种注意形式，也称为上下文引导，其源自全局图像特征。在这里，我们探索一种互补的注意形式，称为视觉显着性，它源自当地的图像特征。我们通过一种新颖的全球和本地关注（GALA）模块扩展了SE模块，该模块结合了两种形式的关注 - 从而在ILSVRC上实现了最先进的准确性。我们进一步描述了ClickMe.ai，这是一个大规模的在线实验，旨在为人类参与者识别诊断图像区域，以共同训练GALA网络。添加人在环中显示出显着提高网络准确性，同时还产生更易于解释且与人类观察者使用的视觉特征更相似的视觉特征。

##### URL
[http://arxiv.org/abs/1805.08819](http://arxiv.org/abs/1805.08819)

##### PDF
[http://arxiv.org/pdf/1805.08819](http://arxiv.org/pdf/1805.08819)

