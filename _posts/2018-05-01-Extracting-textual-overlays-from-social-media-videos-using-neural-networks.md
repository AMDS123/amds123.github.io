---
layout: post
title: "Extracting textual overlays from social media videos using neural networks"
date: 2018-05-01 17:35:47
categories: arXiv_CV
tags: arXiv_CV CNN Classification Detection Recognition
author: Adam Słucki, Tomasz Trzcinski, Adam Bielski, Paweł Cyrta
mathjax: true
---

* content
{:toc}

##### Abstract
Textual overlays are often used in social media videos as people who watch them without the sound would otherwise miss essential information conveyed in the audio stream. This is why extraction of those overlays can serve as an important meta-data source, e.g. for content classification or retrieval tasks. In this work, we present a robust method for extracting textual overlays from videos that builds up on multiple neural network architectures. The proposed solution relies on several processing steps: keyframe extraction, text detection and text recognition. The main component of our system, i.e. the text recognition module, is inspired by a convolutional recurrent neural network architecture and we improve its performance using synthetically generated dataset of over 600,000 images with text prepared by authors specifically for this task. We also develop a filtering method that reduces the amount of overlapping text phrases using Levenshtein distance and further boosts system's performance. The final accuracy of our solution reaches over 80A% and is au pair with state-of-the-art methods.

##### Abstract (translated by Google)
在社交媒体视频中经常使用文本叠加，因为没有声音观看它们的人将会遗漏在音频流中传达的重要信息。这就是为什么提取这些覆盖图可以用作重要的元数据源，例如用于内容分类或检索任务。在这项工作中，我们提出了一种强大的方法，用于从多个神经网络体系结构上构建的视频中提取文本叠加层。所提出的解决方案依赖于几个处理步骤：关键帧提取，文本检测和文本识别。我们系统的主要组成部分，即文本识别模块，受卷积循环神经网络架构的启发，我们使用合成生成的超过600,000个图像的数据集以及由作者专门为此任务准备的文本来提高其性能。我们还开发了一种过滤方法，使用Levenshtein距离减少重叠文本短语的数量，并进一步提高系统的性能。我们解决方案的最终准确度达到了80％以上，并且采用了最先进的方法。

##### URL
[https://arxiv.org/abs/1804.10687](https://arxiv.org/abs/1804.10687)

##### PDF
[https://arxiv.org/pdf/1804.10687](https://arxiv.org/pdf/1804.10687)

