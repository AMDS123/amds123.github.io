---
layout: post
title: "Attacking Object Detectors via Imperceptible Patches on Background"
date: 2018-09-16 22:06:17
categories: arXiv_CV
tags: arXiv_CV Adversarial Object_Detection Detection
author: Yuezun Li, Xian Bian, Siwei Lyu
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks have been proven vulnerable against adversarial perturbations. Recent works succeeded to generate adversarial perturbations on either the entire image or on the target of interests to corrupt object detectors. In this paper, we investigate the vulnerability of object detectors from a new perspective --- adding minimal perturbations on small background patches outside of targets to fail the detection results. Our work focuses on attacking the common component in the state-of-the-art detectors (e.g. Faster R-CNN), Region Proposal Networks (RPNs). As the receptive fields generated by RPN is often larger than the proposals themselves, we propose a novel method to generate background perturbation patches, and show that the perturbations solely outside of the targets can severely damage the performance of multiple types of detectors by simultaneously decreasing the true positives and increasing the false positives. We demonstrate the efficacy of our method on 5 different state-of-the-art object detectors on MS COCO 2014 dataset.

##### Abstract (translated by Google)
已经证明深度神经网络易受对抗性扰动的影响。最近的工作成功地在整个图像上或在感兴趣的目标上产生对抗扰动以破坏物体检测器。在本文中，我们从一个新的角度研究了物体探测器的脆弱性 - 在目标外的小背景片上添加最小的扰动，使检测结果失败。我们的工作重点是攻击最先进的探测器（例如，更快的R-CNN），区域提议网络（RPN）中的公共组件。由于RPN产生的感受野通常大于建议本身，我们提出了一种新的方法来产生背景扰动斑块，并表明仅在目标之外的扰动会严重损害多种类型探测器的性能，同时减少真正的积极因素和增加误报。我们在MS COCO 2014数据集上展示了我们的方法对5种不同的最先进物体探测器的功效。

##### URL
[http://arxiv.org/abs/1809.05966](http://arxiv.org/abs/1809.05966)

##### PDF
[http://arxiv.org/pdf/1809.05966](http://arxiv.org/pdf/1809.05966)

