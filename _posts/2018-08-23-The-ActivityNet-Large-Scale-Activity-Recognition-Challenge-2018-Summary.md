---
layout: post
title: "The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary"
date: 2018-08-23 04:28:38
categories: arXiv_CV
tags: arXiv_CV GAN Caption Recognition
author: Bernard Ghanem, Juan Carlos Niebles, Cees Snoek, Fabian Caba Heilbron, Humam Alwassel, Victor Escorcia, Ranjay Krishna, Shyamal Buch, Cuong Duc Dao
mathjax: true
---

* content
{:toc}

##### Abstract
The 3rd annual installment of the ActivityNet Large- Scale Activity Recognition Challenge, held as a full-day workshop in CVPR 2018, focused on the recognition of daily life, high-level, goal-oriented activities from user-generated videos as those found in internet video portals. The 2018 challenge hosted six diverse tasks which aimed to push the limits of semantic visual understanding of videos as well as bridge visual content with human captions. Three out of the six tasks were based on the ActivityNet dataset, which was introduced in CVPR 2015 and organized hierarchically in a semantic taxonomy. These tasks focused on tracing evidence of activities in time in the form of proposals, class labels, and captions. In this installment of the challenge, we hosted three guest tasks to enrich the understanding of visual information in videos. The guest tasks focused on complementary aspects of the activity recognition problem at large scale and involved three challenging and recently compiled datasets: the Kinetics-600 dataset from Google DeepMind, the AVA dataset from Berkeley and Google, and the Moments in Time dataset from MIT and IBM Research.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1808.03766](https://arxiv.org/abs/1808.03766)

##### PDF
[https://arxiv.org/pdf/1808.03766](https://arxiv.org/pdf/1808.03766)

