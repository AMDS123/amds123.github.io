---
layout: post
title: "Meta-Learning via Learned Loss"
date: 2019-06-12 20:55:18
categories: arXiv_RO
tags: arXiv_RO Sparse Reinforcement_Learning
author: Yevgen Chebotar, Artem Molchanov, Sarah Bechtle, Ludovic Righetti, Franziska Meier, Gaurav Sukhatme
mathjax: true
---

* content
{:toc}

##### Abstract
We present a meta-learning approach based on learning an adaptive, high-dimensional loss function that can generalize across multiple tasks and different model architectures. We develop a fully differentiable pipeline for learning a loss function targeted at maximizing the performance of an optimizee trained using this loss function. We observe that the loss landscape produced by our learned loss significantly improves upon the original task-specific loss. We evaluate our method on supervised and reinforcement learning tasks. Furthermore, we show that our pipeline is able to operate in sparse reward and self-supervised reinforcement learning scenarios.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1906.05374](https://arxiv.org/abs/1906.05374)

##### PDF
[https://arxiv.org/pdf/1906.05374](https://arxiv.org/pdf/1906.05374)

