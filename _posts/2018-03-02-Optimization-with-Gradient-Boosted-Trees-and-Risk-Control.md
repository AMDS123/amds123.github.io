---
layout: post
title: "Optimization with Gradient-Boosted Trees and Risk Control"
date: 2018-03-02 17:10:21
categories: arXiv_AI
tags: arXiv_AI Sparse Optimization
author: Miten Mistry, Dimitrios Letsios, Ruth Misener, Gerhard Krennrich, Robert M. Lee
mathjax: true
---

* content
{:toc}

##### Abstract
Decision trees effectively represent the sparse, high dimensional and noisy nature of chemical data from experiments. Having learned a function from this data, we may want to thereafter optimize the function, e.g., picking the best chemical process catalyst. In this way, we may repurpose legacy predictive models. This work studies a large-scale, industrially-relevant mixed-integer quadratic optimization problem involving: (i) gradient-boosted pre-trained regression trees modeling catalyst behavior, (ii) penalty functions mitigating risk, and (iii) penalties enforcing composition constraints. We develop heuristic methods and an exact, branch-and-bound algorithm leveraging structural properties of gradient-boosted trees and penalty functions. We numerically test our methods on an industrial instance.

##### Abstract (translated by Google)
决策树有效地代表了来自实验的化学数据的稀疏，高维和嘈杂的性质。在从这些数据中学习功能之后，我们可能希望此后优化功能，例如选择最好的化学处理催化剂。通过这种方式，我们可以重新利用传统的预测模型。这项工作研究了一个大规模，工业相关的混合整数二次优化问题，其中包括：（i）梯度推进的预先训练的回归树建模催化剂行为，（ii）惩罚函数减轻风险，和（iii）惩罚实施组成约束。我们开发了启发式方法和精确的分支定界算法，利用梯度提升树和罚函数的结构特性。我们在工业实例上对我们的方法进行数值测试。

##### URL
[http://arxiv.org/abs/1803.00952](http://arxiv.org/abs/1803.00952)

##### PDF
[http://arxiv.org/pdf/1803.00952](http://arxiv.org/pdf/1803.00952)

