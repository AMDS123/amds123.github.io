---
layout: post
title: "Topic-based Evaluation for Conversational Bots"
date: 2018-01-11 03:20:02
categories: arXiv_AI
tags: arXiv_AI Attention Classification
author: Fenfei Guo, Angeliki Metallinou, Chandra Khatri, Anirudh Raju, Anu Venkatesh, Ashwin Ram
mathjax: true
---

* content
{:toc}

##### Abstract
Dialog evaluation is a challenging problem, especially for non task-oriented dialogs where conversational success is not well-defined. We propose to evaluate dialog quality using topic-based metrics that describe the ability of a conversational bot to sustain coherent and engaging conversations on a topic, and the diversity of topics that a bot can handle. To detect conversation topics per utterance, we adopt Deep Average Networks (DAN) and train a topic classifier on a variety of question and query data categorized into multiple topics. We propose a novel extension to DAN by adding a topic-word attention table that allows the system to jointly capture topic keywords in an utterance and perform topic classification. We compare our proposed topic based metrics with the ratings provided by users and show that our metrics both correlate with and complement human judgment. Our analysis is performed on tens of thousands of real human-bot dialogs from the Alexa Prize competition and highlights user expectations for conversational bots.

##### Abstract (translated by Google)
对话评估是一个具有挑战性的问题，特别是对于非面向任务的对话，对话成功没有明确定义。我们建议使用基于主题的度量来评估对话质量，这些度量描述了对话机器人能够保持对话题的连贯和引人入胜的对话以及机器人可以处理的主题的多样性。为了检测每个话题的会话主题，我们采用深度平均网络（DAN），并对分类为多个主题的各种问题和查询数据进行主题分类器训练。我们提出了一个新颖的DAN扩展，增加了一个主题词注意表，允许系统共同捕捉话题中的话题关键词并进行主题分类。我们将提出的基于主题的指标与用户提供的评分进行比较，表明我们的指标既与人为判断相关联，又与人为判断相辅相成。我们的分析是基于Alexa Prize竞赛中数以万计的真实人机对话进行的，并强调用户对对话机器人的期望。

##### URL
[http://arxiv.org/abs/1801.03622](http://arxiv.org/abs/1801.03622)

##### PDF
[http://arxiv.org/pdf/1801.03622](http://arxiv.org/pdf/1801.03622)

