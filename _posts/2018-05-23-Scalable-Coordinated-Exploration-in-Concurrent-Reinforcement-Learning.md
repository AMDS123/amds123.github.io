---
layout: post
title: "Scalable Coordinated Exploration in Concurrent Reinforcement Learning"
date: 2018-05-23 03:36:01
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Maria Dimakopoulou, Ian Osband, Benjamin Van Roy
mathjax: true
---

* content
{:toc}

##### Abstract
We consider a team of reinforcement learning agents that concurrently operate in a common environment, and we develop an approach to efficient coordinated exploration that is suitable for problems of practical scale. Our approach builds on seed sampling (Dimakopoulou and Van Roy, 2018) and randomized value function learning (Osband et al., 2016). We demonstrate that, for simple tabular contexts, the approach is competitive with previously proposed tabular model learning methods (Dimakopoulou and Van Roy, 2018). With a higher-dimensional problem and a neural network value function representation, the approach learns quickly with far fewer agents than alternative exploration schemes.

##### Abstract (translated by Google)
我们认为一组强化学习机构同时在一个共同的环境中运行，并且我们开发一种适用于实际规模问题的高效协调探索方法。我们的方法建立在种子抽样（Dimakopoulou和Van Roy，2018）和随机价值函数学习（Osband等，2016）上。我们证明，对于简单的表格语境，该方法与以前提出的表格模型学习方法相竞争（Dimakopoulou和Van Roy，2018）。随着高维问题和神经网络价值函数的表示，该方法的学习速度比替代勘探方案少得多。

##### URL
[http://arxiv.org/abs/1805.08948](http://arxiv.org/abs/1805.08948)

##### PDF
[http://arxiv.org/pdf/1805.08948](http://arxiv.org/pdf/1805.08948)

