---
layout: post
title: "The AdobeIndoorNav Dataset: Towards Deep Reinforcement Learning based Real-world Indoor Robot Visual Navigation"
date: 2018-02-24 09:42:18
categories: arXiv_RO
tags: arXiv_RO Reinforcement_Learning
author: Kaichun Mo, Haoxiang Li, Zhe Lin, Joon-Young Lee
mathjax: true
---

* content
{:toc}

##### Abstract
Deep reinforcement learning (DRL) demonstrates its potential in learning a model-free navigation policy for robot visual navigation. However, the data-demanding algorithm relies on a large number of navigation trajectories in training. Existing datasets supporting training such robot navigation algorithms consist of either 3D synthetic scenes or reconstructed scenes. Synthetic data suffers from domain gap to the real-world scenes while visual inputs rendered from 3D reconstructed scenes have undesired holes and artifacts. In this paper, we present a new dataset collected in real-world to facilitate the research in DRL based visual navigation. Our dataset includes 3D reconstruction for real-world scenes as well as densely captured real 2D images from the scenes. It provides high-quality visual inputs with real-world scene complexity to the robot at dense grid locations. We further study and benchmark one recent DRL based navigation algorithm and present our attempts and thoughts on improving its generalizability to unseen test targets in the scenes.

##### Abstract (translated by Google)
深度强化学习（DRL）展示了其学习机器人视觉导航的无模型导航策略的潜力。然而，数据要求较高的算法依赖于训练中的大量导航轨迹。支持训练此类机器人导航算法的现有数据集由3D合成场景或重构场景组成。合成数据遭受领域与现实世界场景的差距，而从3D重建场景渲染的视觉输入具有不期望的洞和伪影。在本文中，我们提出了一个新的数据集收集在现实世界中，以促进基于DRL的视觉导航的研究。我们的数据集包括真实场景的3D重建以及从场景中密集捕获的真实2D图像。它为密集的网格位置上的机器人提供高质量的视觉输入，并且具有真实的场景复杂性。我们进一步研究和测试一个最新的基于DRL的导航算法，并提出我们的尝试和想法，以改善其在场景中看不见的测试目标的普遍性。

##### URL
[http://arxiv.org/abs/1802.08824](http://arxiv.org/abs/1802.08824)

##### PDF
[http://arxiv.org/pdf/1802.08824](http://arxiv.org/pdf/1802.08824)

