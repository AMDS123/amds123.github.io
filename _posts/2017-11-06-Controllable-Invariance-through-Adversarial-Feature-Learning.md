---
layout: post
title: "Controllable Invariance through Adversarial Feature Learning"
date: 2017-11-06 17:47:33
categories: arXiv_CL
tags: arXiv_CL Adversarial Image_Classification Represenation_Learning Classification Prediction
author: Qizhe Xie, Zihang Dai, Yulun Du, Eduard Hovy, Graham Neubig
mathjax: true
---

* content
{:toc}

##### Abstract
Learning meaningful representations that maintain the content necessary for a particular task while filtering away detrimental variations is a problem of great interest in machine learning. In this paper, we tackle the problem of learning representations invariant to a specific factor or trait of data. The representation learning process is formulated as an adversarial minimax game. We analyze the optimal equilibrium of such a game and find that it amounts to maximizing the uncertainty of inferring the detrimental factor given the representation while maximizing the certainty of making task-specific predictions. On three benchmark tasks, namely fair and bias-free classification, language-independent generation, and lighting-independent image classification, we show that the proposed framework induces an invariant representation, and leads to better generalization evidenced by the improved performance.

##### Abstract (translated by Google)
学习有意义的表示，这些表示维护了特定任务所需的内容，同时滤除了有害的变化，这是机器学习非常重要的问题。在本文中，我们解决了学习表示不变的特定因素或数据特征的问题。表示学习过程被制定为对抗性极小极小游戏。我们分析了这种博弈的最优均衡，并发现它最大化了给定表达的推断有害因素的不确定性，同时最大化做出特定任务的预测的确定性。在公平和无偏分类，独立于语言的生成以及独立于光照的图像分类三个基准任务上，我们表明所提出的框架引入了一个不变的表示，并且导致了更好的泛化能力。

##### URL
[https://arxiv.org/abs/1705.11122](https://arxiv.org/abs/1705.11122)

##### PDF
[https://arxiv.org/pdf/1705.11122](https://arxiv.org/pdf/1705.11122)

