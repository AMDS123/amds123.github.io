---
layout: post
title: "Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent Unit for Summarization"
date: 2016-07-04 01:55:17
categories: arXiv_CL
tags: arXiv_CL Summarization RNN
author: Minsoo Kim, Moirangthem Dennis Singh, Minho Lee
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we introduce temporal hierarchies to the sequence to sequence (seq2seq) model to tackle the problem of abstractive summarization of scientific articles. The proposed Multiple Timescale model of the Gated Recurrent Unit (MTGRU) is implemented in the encoder-decoder setting to better deal with the presence of multiple compositionalities in larger texts. The proposed model is compared to the conventional RNN encoder-decoder, and the results demonstrate that our model trains faster and shows significant performance gains. The results also show that the temporal hierarchies help improve the ability of seq2seq models to capture compositionalities better without the presence of highly complex architectural hierarchies.

##### Abstract (translated by Google)
在这项工作中，我们引入时序层次序列（seq2seq）模型来解决科学论文抽象概括的问题。所提出的门控重复单元（MTGRU）的多时间尺度模型是在编码器 - 解码器设置中实现的，以更好地处理较大文本中多重组合的存在。所提出的模型与传统的RNN编码器 - 解码器进行比较，结果表明，我们的模型训练速度更快，并显示出显着的性能增益。结果还表明，时间层次有助于提高seq2seq模型在不存在高度复杂的架构层次结构的情况下更好地捕获成分的能力。

##### URL
[https://arxiv.org/abs/1607.00718](https://arxiv.org/abs/1607.00718)

##### PDF
[https://arxiv.org/pdf/1607.00718](https://arxiv.org/pdf/1607.00718)

