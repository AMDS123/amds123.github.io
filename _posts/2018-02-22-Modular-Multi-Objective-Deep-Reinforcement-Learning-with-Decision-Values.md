---
layout: post
title: "Modular Multi-Objective Deep Reinforcement Learning with Decision Values"
date: 2018-02-22 19:13:06
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Tomasz Tajmajer
mathjax: true
---

* content
{:toc}

##### Abstract
In this work we present a method for using Deep Q-Networks (DQNs) in multi-objective environments. Deep Q-Networks provide remarkable performance in single objective problems learning from high-level visual state representations. However, in many scenarios (e.g in robotics, games), the agent needs to pursue multiple objectives simultaneously. We propose an architecture in which separate DQNs are used to control the agent's behaviour with respect to particular objectives. In this architecture we introduce decision values to improve the scalarization of multiple DQNs into a single action. Our architecture enables the decomposition of the agent's behaviour into controllable and replaceable sub-behaviours learned by distinct modules. Moreover, it allows to change the priorities of particular objectives post-learning, while preserving the overall performance of the agent. To evaluate our solution we used a game-like simulator in which an agent - provided with high-level visual input - pursues multiple objectives in a 2D world.

##### Abstract (translated by Google)
在这项工作中，我们提出了一个在多目标环境中使用Deep Q-Networks（DQN）的方法。 Deep Q-Networks在从高级视觉状态表示中学习单一目标问题方面提供了卓越的性能。但是，在许多情况下（例如在机器人，游戏中），代理需要同时追求多个目标。我们提出了一种架构，其中使用单独的DQN来控制代理人针对特定目标的行为。在这种体系结构中，我们引入决策值来改进多个DQN的标量化为单一行为。我们的架构能够将代理行为分解为不同模块可学习和可替换的子行为。此外，它允许在学习后改变特定目标的优先级，同时保持代理的整体性能。为了评估我们的解决方案，我们使用了一个类似游戏的模拟器，在该模拟器中，提供高级视觉输入的代理在2D世界中追求多个目标。

##### URL
[http://arxiv.org/abs/1704.06676](http://arxiv.org/abs/1704.06676)

##### PDF
[http://arxiv.org/pdf/1704.06676](http://arxiv.org/pdf/1704.06676)

