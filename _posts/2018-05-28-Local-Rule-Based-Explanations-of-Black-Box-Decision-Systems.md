---
layout: post
title: "Local Rule-Based Explanations of Black Box Decision Systems"
date: 2018-05-28 08:56:40
categories: arXiv_AI
tags: arXiv_AI
author: Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, Fosca Giannotti
mathjax: true
---

* content
{:toc}

##### Abstract
The recent years have witnessed the rise of accurate but obscure decision systems which hide the logic of their internal decision processes to the users. The lack of explanations for the decisions of black box systems is a key ethical issue, and a limitation to the adoption of machine learning components in socially sensitive and safety-critical contexts. %Therefore, we need explanations that reveals the reasons why a predictor takes a certain decision. In this paper we focus on the problem of black box outcome explanation, i.e., explaining the reasons of the decision taken on a specific instance. We propose LORE, an agnostic method able to provide interpretable and faithful explanations. LORE first leans a local interpretable predictor on a synthetic neighborhood generated by a genetic algorithm. Then it derives from the logic of the local interpretable predictor a meaningful explanation consisting of: a decision rule, which explains the reasons of the decision; and a set of counterfactual rules, suggesting the changes in the instance's features that lead to a different outcome. Wide experiments show that LORE outperforms existing methods and baselines both in the quality of explanations and in the accuracy in mimicking the black box.

##### Abstract (translated by Google)
近年来，准确但模糊的决策系统出现了，这些决策系统隐藏了用户内部决策过程的逻辑。缺乏对黑匣子系统决策的解释是一个关键的道德问题，也是在社会敏感和安全关键环境中采用机器学习组件的局限性。 ％因此，我们需要解释，揭示预测因素为什么会做出某个决定。在本文中，我们着重讨论黑匣子结果解释的问题，即解释对特定实例作出决定的原因。我们提出LORE，这是一种不可知论的方法，能够提供可解释和忠实的解释。 LORE首先在由遗传算法产生的合成邻域上倾斜本地可解释的预测变量。然后它从局部可解释预测器的逻辑推导出一个有意义的解释，包括：一个决定规则，它解释了决定的原因;和一组反事实规则，暗示实例特征的变化导致了不同的结果。大量实验表明，LORE在解释质量和模拟黑匣子的准确性方面都优于现有的方法和基线。

##### URL
[http://arxiv.org/abs/1805.10820](http://arxiv.org/abs/1805.10820)

##### PDF
[http://arxiv.org/pdf/1805.10820](http://arxiv.org/pdf/1805.10820)

