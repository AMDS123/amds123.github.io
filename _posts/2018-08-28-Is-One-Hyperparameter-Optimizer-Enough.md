---
layout: post
title: "Is One Hyperparameter Optimizer Enough?"
date: 2018-08-28 17:33:25
categories: arXiv_AI
tags: arXiv_AI Optimization Prediction
author: Huy Tu, Vivek Nair, Tim Menzies
mathjax: true
---

* content
{:toc}

##### Abstract
Hyperparameter tuning is the black art of automatically finding a good combination of control parameters for a data miner. While widely applied in empirical Software Engineering, there has not been much discussion on which hyperparameter tuner is best for software analytics. To address this gap in the literature, this paper applied a range of hyperparameter optimizers (grid search, random search, differential evolution, and Bayesian optimization) to defect prediction problem. Surprisingly, no hyperparameter optimizer was observed to be `best' and, for one of the two evaluation measures studied here (F-measure), hyperparameter optimization, in 50\% cases, was no better than using default configurations. 
 We conclude that hyperparameter optimization is more nuanced than previously believed. While such optimization can certainly lead to large improvements in the performance of classifiers used in software analytics, it remains to be seen which specific optimizers should be applied to a new dataset.

##### Abstract (translated by Google)
超参数调整是自动为数据挖掘器找到控制参数的良好组合的黑色技术。虽然在经验软件工程中得到广泛应用，但对于哪种超参数调谐器最适合软件分析的讨论并不多。为了解决文献中的这一差距，本文将一系列超参数优化器（网格搜索，随机搜索，差分进化和贝叶斯优化）应用于缺陷预测问题。令人惊讶的是，没有观察到超参数优化器是“最佳”的，并且对于这里研究的两个评估测量之一（F-measure），在50％的情况下，超参数优化并不比使用默认配置更好。
 我们得出结论，超参数优化比以前认为的更细微。虽然这种优化肯定会导致软件分析中使用的分类器性能的大幅提升，但仍有待观察哪些特定的优化器应该应用于新的数据集。

##### URL
[http://arxiv.org/abs/1807.11112](http://arxiv.org/abs/1807.11112)

##### PDF
[http://arxiv.org/pdf/1807.11112](http://arxiv.org/pdf/1807.11112)

