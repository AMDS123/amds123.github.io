---
layout: post
title: "Deep Descriptor Transforming for Image Co-Localization"
date: 2017-05-08 06:52:44
categories: arXiv_CV
tags: arXiv_CV Object_Detection CNN Detection Relation
author: Xiu-Shen Wei, Chen-Lin Zhang, Yao Li, Chen-Wei Xie, Jianxin Wu, Chunhua Shen, Zhi-Hua Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
Reusable model design becomes desirable with the rapid expansion of machine learning applications. In this paper, we focus on the reusability of pre-trained deep convolutional models. Specifically, different from treating pre-trained models as feature extractors, we reveal more treasures beneath convolutional layers, i.e., the convolutional activations could act as a detector for the common object in the image co-localization problem. We propose a simple but effective method, named Deep Descriptor Transforming (DDT), for evaluating the correlations of descriptors and then obtaining the category-consistent regions, which can accurately locate the common object in a set of images. Empirical studies validate the effectiveness of the proposed DDT method. On benchmark image co-localization datasets, DDT consistently outperforms existing state-of-the-art methods by a large margin. Moreover, DDT also demonstrates good generalization ability for unseen categories and robustness for dealing with noisy data.

##### Abstract (translated by Google)
随着机器学习应用的迅速扩展，可重复使用的模型设计也将变得可取。在本文中，我们关注预先训练的深度卷积模型的可重用性。具体而言，与将预训练模型作为特征提取器处理不同，我们在卷积层下揭示更多的宝藏，即卷积激活可以充当图像共定位问题中的共同对象的检测器。我们提出了一种简单而有效的方法，称为深描述符变换（Deep Descriptor Transforming，DDT），用于评估描述符之间的相关性，然后得到类别一致性区域，从而能够准确地定位一组图像中的共同对象。实证研究验证了所提出的DDT方法的有效性。在基准图像共定位数据集上，DDT始终大大优于现有的最先进的方法。此外，滴滴涕还表现出良好的看不见的类别泛泛能力和鲁棒性处理嘈杂的数据。

##### URL
[https://arxiv.org/abs/1705.02758](https://arxiv.org/abs/1705.02758)

##### PDF
[https://arxiv.org/pdf/1705.02758](https://arxiv.org/pdf/1705.02758)

