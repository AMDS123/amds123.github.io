---
layout: post
title: "Graph Distillation for Action Detection with Privileged Modalities"
date: 2018-07-27 22:03:03
categories: arXiv_CV
tags: arXiv_CV Transfer_Learning Classification Detection
author: Zelun Luo, Jun-Ting Hsieh, Lu Jiang, Juan Carlos Niebles, Li Fei-Fei
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a technique that tackles action detection in multimodal videos under a realistic and challenging condition in which only limited training data and partially observed modalities are available. Common methods in transfer learning do not take advantage of the extra modalities potentially available in the source domain. On the other hand, previous work on multimodal learning only focuses on a single domain or task and does not handle the modality discrepancy between training and testing. In this work, we propose a method termed graph distillation that incorporates rich privileged information from a large-scale multimodal dataset in the source domain, and improves the learning in the target domain where training data and modalities are scarce. We evaluate our approach on action classification and detection tasks in multimodal videos, and show that our model outperforms the state-of-the-art by a large margin on the NTU RGB+D and PKU-MMD benchmarks. The code is released at <a href="http://alan.vision/eccv18_graph/.">this http URL</a>

##### Abstract (translated by Google)
我们提出了一种技术，在现实和具有挑战性的条件下解决多模态视频中的动作检测，其中只有有限的训练数据和部分观察到的模态。转移学习中的常用方法没有利用源域中可能提供的额外模态。另一方面，以前关于多模式学习的工作仅关注单个领域或任务，并不处理训练和测试之间的模态差异。在这项工作中，我们提出了一种称为图形蒸馏的方法，该方法结合了源域中大规模多模态数据集的丰富特权信息，并改善了训练数据和模态稀缺的目标领域的学习。我们评估了我们在多模态视频中的动作分类和检测任务的方法，并表明我们的模型在NTU RGB + D和PKU-MMD基准测试中大大优于最先进的技术。该代码在<a href="http://alan.vision/eccv18_graph/.">此http网址</a>上发布

##### URL
[http://arxiv.org/abs/1712.00108](http://arxiv.org/abs/1712.00108)

##### PDF
[http://arxiv.org/pdf/1712.00108](http://arxiv.org/pdf/1712.00108)

