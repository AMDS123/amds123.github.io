---
layout: post
title: "From Third Person to First Person: Dataset and Baselines for Synthesis and Retrieval"
date: 2018-12-01 00:10:03
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Relation
author: Mohamed Elfeki, Krishna Regmi, Shervin Ardeshir, Ali Borji
mathjax: true
---

* content
{:toc}

##### Abstract
First-person (egocentric) and third person (exocentric) videos are drastically different in nature. The relationship between these two views have been studied in recent years, however, it has yet to be fully explored. In this work, we introduce two datasets (synthetic and natural/real) containing simultaneously recorded egocentric and exocentric videos. We also explore relating the two domains (egocentric and exocentric) in two aspects. First, we synthesize images in the egocentric domain from the exocentric domain using a conditional generative adversarial network (cGAN). We show that with enough training data, our network is capable of hallucinating how the world would look like from an egocentric perspective, given an exocentric video. Second, we address the cross-view retrieval problem across the two views. Given an egocentric query frame (or its momentary optical flow), we retrieve its corresponding exocentric frame (or optical flow) from a gallery set. We show that using synthetic data could be beneficial in retrieving real data. We show that performing domain adaptation from the synthetic domain to the natural/real domain, is helpful in tasks such as retrieval. We believe that the presented datasets and the proposed baselines offer new opportunities for further research in this direction. The code and dataset are publicly available.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.00104](http://arxiv.org/abs/1812.00104)

##### PDF
[http://arxiv.org/pdf/1812.00104](http://arxiv.org/pdf/1812.00104)

