---
layout: post
title: "Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering"
date: 2018-06-12 04:48:06
categories: arXiv_CL
tags: arXiv_CL Inference RNN
author: Wuwei Lan, Wei Xu
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we analyze several neural network designs (and their variations) for sentence pair modeling and compare their performance extensively across eight datasets, including paraphrase identification, semantic textual similarity, natural language inference, and question answering tasks. Although most of these models have claimed state-of-the-art performance, the original papers often reported on only one or two selected datasets. We provide a systematic study and show that (i) encoding contextual information by LSTM and inter-sentence interactions are critical, (ii) Tree-LSTM does not help as much as previously claimed but surprisingly improves performance on Twitter datasets, (iii) the Enhanced Sequential Inference Model is the best so far for larger datasets, while the Pairwise Word Interaction Model achieves the best performance when less data is available. We release our implementations as an open-source toolkit.

##### Abstract (translated by Google)
在本文中，我们分析了句子对建模的几种神经网络设计（及其变体），并在八个数据集中广泛比较它们的性能，包括释义识别，语义文本相似性，自然语言推理和问题回答任务。尽管这些模型中的大多数都声称具有最先进的性能，但原始报告通常只报告一个或两个选定的数据集。我们提供了一个系统的研究，并表明（一）编码上下文信息的LSTM和句子间的互动是至关重要的，（二）树木LSTM不像以前声称的帮助，但令人惊讶地提高性能Twitter数据集，（三）对于较大的数据集，增强的顺序推理模型是迄今为止最好的，而当数据较少时，成对词互作用模型达到最佳性能。我们将我们的实现作为开源工具包发布。

##### URL
[http://arxiv.org/abs/1806.04330](http://arxiv.org/abs/1806.04330)

##### PDF
[http://arxiv.org/pdf/1806.04330](http://arxiv.org/pdf/1806.04330)

