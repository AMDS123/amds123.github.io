---
layout: post
title: "A Human-Grounded Evaluation Benchmark for Local Explanations of Machine Learning"
date: 2018-01-16 00:14:43
categories: arXiv_AI
tags: arXiv_AI Quantitative
author: Sina Mohseni, Eric D. Ragan
mathjax: true
---

* content
{:toc}

##### Abstract
In order for people to be able to trust and take advantage of the results of advanced machine learning and artificial intelligence solutions for real decision making, people need to be able to understand the machine rationale for given output. Research in explain artificial intelligence (XAI) addresses the aim, but there is a need for evaluation of human relevance and understandability of explanations. Our work contributes a novel methodology for evaluating the quality or human interpretability of explanations for machine learning models. We present an evaluation benchmark for instance explanations from text and image classifiers. The explanation meta-data in this benchmark is generated from user annotations of image and text samples. We describe the benchmark and demonstrate its utility by a quantitative evaluation on explanations generated from a recent machine learning algorithm. This research demonstrates how human-grounded evaluation could be used as a measure to qualify local machine-learning explanations.

##### Abstract (translated by Google)
为了让人们能够信任并利用先进的机器学习和人工智能解决方案的结果来做出真正的决策，人们需要能够理解给定输出的机器基本原理。在解释人工智能（XAI）的研究解决了这个目标，但是需要评估人的相关性和解释的可理解性。我们的工作为评估机器学习模型解释的质量或人类可解释性提供了一种新颖的方法。我们提供了一个评估基准，用于从文本和图像分类器中进行实例解释。此基准中的解释元数据是从图像和文本样本的用户注释生成的。我们描述基准，并通过对最近机器学习算法产生的解释进行定量评估来证明其效用。这项研究表明，如何以人为本的评估作为衡量本地机器学习解释的标准。

##### URL
[http://arxiv.org/abs/1801.05075](http://arxiv.org/abs/1801.05075)

##### PDF
[http://arxiv.org/pdf/1801.05075](http://arxiv.org/pdf/1801.05075)

