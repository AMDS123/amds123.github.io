---
layout: post
title: "3D Convolutional Neural Networks for Cross Audio-Visual Matching Recognition"
date: 2017-08-13 02:20:41
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition CNN Relation Recognition
author: Amirsina Torfi, Seyed Mehdi Iranmanesh, Nasser M. Nasrabadi, Jeremy Dawson
mathjax: true
---

* content
{:toc}

##### Abstract
Audio-visual recognition (AVR) has been considered as a solution for speech recognition tasks when the audio is corrupted, as well as a visual recognition method used for speaker verification in multi-speaker scenarios. The approach of AVR systems is to leverage the extracted information from one modality to improve the recognition ability of the other modality by complementing the missing information. The essential problem is to find the correspondence between the audio and visual streams, which is the goal of this work. We propose the use of a coupled 3D Convolutional Neural Network (3D-CNN) architecture that can map both modalities into a representation space to evaluate the correspondence of audio-visual streams using the learned multimodal features. The proposed architecture will incorporate both spatial and temporal information jointly to effectively find the correlation between temporal information for different modalities. By using a relatively small network architecture and much smaller dataset for training, our proposed method surpasses the performance of the existing similar methods for audio-visual matching which use 3D CNNs for feature representation. We also demonstrate that an effective pair selection method can significantly increase the performance. The proposed method achieves relative improvements over 20% on the Equal Error Rate (EER) and over 7% on the Average Precision (AP) in comparison to the state-of-the-art method.

##### Abstract (translated by Google)
音频视觉识别（AVR）被认为是音频损坏时的语音识别任务的解决方案，以及用于多扬声器场景中的说话者验证的视觉识别方法。 AVR系统的方法是利用一种模式提取的信息，通过补充缺失信息来提高另一种模式的识别能力。根本问题是找到音频和视频流之间的对应关系，这是这项工作的目标。我们提出使用耦合的3D卷积神经网络（3D-CNN）架构，其可以将两种模态映射到表示空间，以使用学习的多模态特征来评估音频 - 视频流的对应关系。所提出的架构将结合空间和时间信息共同有效地发现不同模态的时间信息之间的相关性。通过使用相对较小的网络结构和更小的数据集进行训练，我们提出的方法超越了现有的使用3D CNN进行特征表示的类似视听匹配方法的性能。我们还证明了一种有效的对选择方法可以显着提高性能。与最先进的方法相比，所提出的方法在等误差率（EER）方面达到20％以上，在平均精度（AP）方面达到7％以上。

##### URL
[https://arxiv.org/abs/1706.05739](https://arxiv.org/abs/1706.05739)

##### PDF
[https://arxiv.org/pdf/1706.05739](https://arxiv.org/pdf/1706.05739)

