---
layout: post
title: "Three-Stage Speaker Verification Architecture in Emotional Talking Environments"
date: 2018-09-03 09:25:35
categories: arXiv_AI
tags: arXiv_AI
author: Ismail Shahin, Ali Bou Nassif
mathjax: true
---

* content
{:toc}

##### Abstract
Speaker verification performance in neutral talking environment is usually high, while it is sharply decreased in emotional talking environments. This performance degradation in emotional environments is due to the problem of mismatch between training in neutral environment while testing in emotional environments. In this work, a three-stage speaker verification architecture has been proposed to enhance speaker verification performance in emotional environments. This architecture is comprised of three cascaded stages: gender identification stage followed by an emotion identification stage followed by a speaker verification stage. The proposed framework has been evaluated on two distinct and independent emotional speech datasets: in-house dataset and Emotional Prosody Speech and Transcripts dataset. Our results show that speaker verification based on both gender information and emotion information is superior to each of speaker verification based on gender information only, emotion information only, and neither gender information nor emotion information. The attained average speaker verification performance based on the proposed framework is very alike to that attained in subjective assessment by human listeners.

##### Abstract (translated by Google)
在中立的谈话环境中的说话者验证性能通常较高，而在情绪化的谈话环境中则大幅下降。情绪环境中的这种性能下降是由于在情绪环境中进行测试时中性环境中的训练之间的不匹配问题。在这项工作中，已经提出了一种三阶段说话者验证架构，以增强情绪环境中的说话者验证性能。该架构由三个级联阶段组成：性别识别阶段，然后是情绪识别阶段，然后是说话者验证阶段。所提出的框架已经在两个独立且独立的情绪语音数据集上进行了评估：内部数据集和情绪韵律语音和转录数据集。我们的研究结果表明，基于性别信息和情感信息的说话人验证优于仅基于性别信息的说话者验证，仅基于情感信息，且不包括性别信息和情绪信息。基于所提出的框架获得的平均说话者验证性能与人类听众在主观评估中获得的性能非常相似。

##### URL
[http://arxiv.org/abs/1809.01721](http://arxiv.org/abs/1809.01721)

##### PDF
[http://arxiv.org/pdf/1809.01721](http://arxiv.org/pdf/1809.01721)

