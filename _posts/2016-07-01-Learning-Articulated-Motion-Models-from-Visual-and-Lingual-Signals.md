---
layout: post
title: "Learning Articulated Motion Models from Visual and Lingual Signals"
date: 2016-07-01 14:53:28
categories: arXiv_CL
tags: arXiv_CL Knowledge Embedding Language_Model
author: Zhengyang Wu, Mohit Bansal, Matthew R. Walter
mathjax: true
---

* content
{:toc}

##### Abstract
In order for robots to operate effectively in homes and workplaces, they must be able to manipulate the articulated objects common within environments built for and by humans. Previous work learns kinematic models that prescribe this manipulation from visual demonstrations. Lingual signals, such as natural language descriptions and instructions, offer a complementary means of conveying knowledge of such manipulation models and are suitable to a wide range of interactions (e.g., remote manipulation). In this paper, we present a multimodal learning framework that incorporates both visual and lingual information to estimate the structure and parameters that define kinematic models of articulated objects. The visual signal takes the form of an RGB-D image stream that opportunistically captures object motion in an unprepared scene. Accompanying natural language descriptions of the motion constitute the lingual signal. We present a probabilistic language model that uses word embeddings to associate lingual verbs with their corresponding kinematic structures. By exploiting the complementary nature of the visual and lingual input, our method infers correct kinematic structures for various multiple-part objects on which the previous state-of-the-art, visual-only system fails. We evaluate our multimodal learning framework on a dataset comprised of a variety of household objects, and demonstrate a 36% improvement in model accuracy over the vision-only baseline.

##### Abstract (translated by Google)
为了使机器人能够在家庭和工作场所有效地操作，他们必须能够操纵在为人类和为人类建造的环境中常见的关节物体。以前的工作是从视觉演示中学习规定这种操作的运动学模型。诸如自然语言描述和指令之类的语言信号提供了表达这种操纵模型的知识的补充手段，并适用于广泛的交互（例如远程操纵）。在本文中，我们提出了一个多模态的学习框架，其中包含视觉和语言信息来估计结构和参数，定义运动学模型的关节物体。视觉信号采取RGB-D图像流的形式，在没有准备的场景中机会捕捉物体的运动。伴随着运动的自然语言描述构成语言信号。我们提出了一个概率性的语言模型，使用词嵌入关联舌动词与其相应的运动结构。通过利用视觉和语言输入的互补性，我们的方法推导出正确的运动学结构的各种多部分的对象，其中以前的最先进的，可视化的系统失败。我们评估我们的多模式学习框架在由多种家庭对象组成的数据集上，并且在仅仅基于视觉的基线上显示出模型精度提高了36％。

##### URL
[https://arxiv.org/abs/1511.05526](https://arxiv.org/abs/1511.05526)

##### PDF
[https://arxiv.org/pdf/1511.05526](https://arxiv.org/pdf/1511.05526)

