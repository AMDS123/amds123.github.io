---
layout: post
title: "FANet: Quality-Aware Feature Aggregation Network for RGB-T Tracking"
date: 2018-11-24 16:54:28
categories: arXiv_CV
tags: arXiv_CV Tracking
author: Yabin Zhu, Chenglong Li, Yijuan Lu, Liang Lin, Bin Luo, Jin Tang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper investigates how to perform robust visual tracking in adverse and challenging conditions using complementary visual and thermal infrared data (RGB-T tracking). We propose a novel deep network architecture "quality-aware Feature Aggregation Network (FANet)" to achieve quality-aware aggregations of both hierarchical features and multimodal information for robust online RGB-T tracking. Unlike existing works that directly concatenate hierarchical deep features, our FANet learns the layer weights to adaptively aggregate them to handle the challenge of significant appearance changes caused by deformation, abrupt motion, background clutter and occlusion within each modality. Moreover, we employ the operations of max pooling, interpolation upsampling and convolution to transform these hierarchical and multi-resolution features into a uniform space at the same resolution for more effective feature aggregation. In different modalities, we elaborately design a multimodal aggregation sub-network to integrate all modalities collaboratively based on the predicted reliability degrees. Extensive experiments on large-scale benchmark datasets demonstrate that our FANet significantly outperforms other state-of-the-art RGB-T tracking methods.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1811.09855](https://arxiv.org/abs/1811.09855)

##### PDF
[https://arxiv.org/pdf/1811.09855](https://arxiv.org/pdf/1811.09855)

