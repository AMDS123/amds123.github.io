---
layout: post
title: "Learning to Teach in Cooperative Multiagent Reinforcement Learning"
date: 2018-08-31 18:36:15
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning
author: Shayegan Omidshafiei, Dong-Ki Kim, Miao Liu, Gerald Tesauro, Matthew Riemer, Christopher Amato, Murray Campbell, Jonathan P. How
mathjax: true
---

* content
{:toc}

##### Abstract
Collective human knowledge has clearly benefited from the fact that innovations by individuals are taught to others through communication. Similar to human social groups, agents in distributed learning systems would likely benefit from communication to share knowledge and teach skills. The problem of teaching to improve agent learning has been investigated by prior works, but these approaches make assumptions that prevent application of teaching to general multiagent problems, or require domain expertise for problems they can apply to. This learning to teach problem has inherent complexities related to measuring long-term impacts of teaching that compound the standard multiagent coordination challenges. In contrast to existing works, this paper presents the first general framework and algorithm for intelligent agents to learn to teach in a multiagent environment. Our algorithm, Learning to Coordinate and Teach Reinforcement (LeCTR), addresses peer-to-peer teaching in cooperative multiagent reinforcement learning. Each agent in our approach learns both when and what to advise, then uses the received advice to improve local learning. Importantly, these roles are not fixed; these agents learn to assume the role of student and/or teacher at the appropriate moments, requesting and providing advice in order to improve teamwide performance and learning. Empirical comparisons against state-of-the-art teaching methods show that our teaching agents not only learn significantly faster, but also learn to coordinate in tasks where existing methods fail.

##### Abstract (translated by Google)
集体人类知识显然得益于个人的创新通过交流传授给他人这一事实。与人类社会群体类似，分布式学习系统中的代理人可能会从沟通中受益，以分享知识和教授技能。先前的工作已经研究了改进代理学习的教学问题，但是这些方法做出的假设阻止了教学应用于一般多代理问题，或者需要领域专业知识来解决他们可以应用的问题。这种学习教学问题具有与测量教学的长期影响相关的固有复杂性，这加剧了标准的多智能体协调挑战。与现有工作相比，本文提出了智能代理在多代理环境中学习教学的第一个通用框架和算法。我们的算法，学习协调和教学强化（LeCTR），解决了合作多智能体强化学习中的点对点教学。我们的方法中的每个代理都会学习何时何地提供建议，然后使用收到的建议来改善本地学习。重要的是，这些角色并不固定;这些代理人学会在适当的时刻承担学生和/或教师的角色，请求并提供建议，以提高整个团队的绩效和学习。与最先进的教学方法的实证比较表明，我们的教学代理人不仅学得更快，而且学会协调现有方法失败的任务。

##### URL
[http://arxiv.org/abs/1805.07830](http://arxiv.org/abs/1805.07830)

##### PDF
[http://arxiv.org/pdf/1805.07830](http://arxiv.org/pdf/1805.07830)

