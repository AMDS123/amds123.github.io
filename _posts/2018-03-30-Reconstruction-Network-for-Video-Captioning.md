---
layout: post
title: "Reconstruction Network for Video Captioning"
date: 2018-03-30 13:09:30
categories: arXiv_CV
tags: arXiv_CV Video_Caption Caption
author: Bairui Wang, Lin Ma, Wei Zhang, Wei Liu
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, the problem of describing visual contents of a video sequence with natural language is addressed. Unlike previous video captioning work mainly exploiting the cues of video contents to make a language description, we propose a reconstruction network (RecNet) with a novel encoder-decoder-reconstructor architecture, which leverages both the forward (video to sentence) and backward (sentence to video) flows for video captioning. Specifically, the encoder-decoder makes use of the forward flow to produce the sentence description based on the encoded video semantic features. Two types of reconstructors are customized to employ the backward flow and reproduce the video features based on the hidden state sequence generated by the decoder. The generation loss yielded by the encoder-decoder and the reconstruction loss introduced by the reconstructor are jointly drawn into training the proposed RecNet in an end-to-end fashion. Experimental results on benchmark datasets demonstrate that the proposed reconstructor can boost the encoder-decoder models and leads to significant gains in video caption accuracy.

##### Abstract (translated by Google)
在本文中，解决了用自然语言描述视频序列的视觉内容的问题。与以前主要利用视频内容提示进行语言描述的视频字幕工作不同，我们提出了一种具有新颖的编码器 - 解码器 - 重构器架构的重建网络（RecNet），它利用前向（视频到句子）和后向（句子）用于视频字幕的视频流。具体地，编码器 - 解码器利用前向流来基于编码的视频语义特征产生句子描述。定制两种类型的重建器以使用后向流并基于由解码器生成的隐藏状态序列来再现视频特征。由编码器 - 解码器产生的生成损失和由重建器引入的重建损失共同被绘制为以端到端方式训练所提出的RecNet。基准数据集上的实验结果表明，所提出的重构器可以增强编码器 - 解码器模型，并导致视频字幕准确性的显着提高。

##### URL
[https://arxiv.org/abs/1803.11438](https://arxiv.org/abs/1803.11438)

##### PDF
[https://arxiv.org/pdf/1803.11438](https://arxiv.org/pdf/1803.11438)

