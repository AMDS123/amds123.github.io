---
layout: post
title: "End-to-end Text-to-speech for Low-resource Languages by Cross-Lingual Transfer Learning"
date: 2019-04-13 08:51:11
categories: arXiv_CL
tags: arXiv_CL Knowledge Transfer_Learning
author: Tao Tu, Yuan-Jui Chen, Cheng-chieh Yeh, Hung-yi Lee
mathjax: true
---

* content
{:toc}

##### Abstract
End-to-end text-to-speech (TTS) has shown great success on large quantities of paired text plus speech data. However, laborious data collection remains difficult for at least 95% of the languages over the world, which hinders the development of TTS in different languages. In this paper, we aim to build TTS systems for such low-resource (target) languages where only very limited paired data are available. We show such TTS can be effectively constructed by transferring knowledge from a high-resource (source) language. Since the model trained on source language cannot be directly applied to target language due to input space mismatch, we propose a method to learn a mapping between source and target linguistic symbols. Benefiting from this learned mapping, pronunciation information can be preserved throughout the transferring procedure. Preliminary experiments show that we only need around 15 minutes of paired data to obtain a relatively good TTS system. Furthermore, analytic studies demonstrated that the automatically discovered mapping correlate well with the phonetic expertise.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.06508](http://arxiv.org/abs/1904.06508)

##### PDF
[http://arxiv.org/pdf/1904.06508](http://arxiv.org/pdf/1904.06508)

