---
layout: post
title: "Cats and Captions vs. Creators and the Clock: Comparing Multimodal Content to Context in Predicting Relative Popularity"
date: 2017-03-06 04:56:19
categories: arXiv_CV
tags: arXiv_CV Attention Caption
author: Jack Hessel, Lillian Lee, David Mimno
mathjax: true
---

* content
{:toc}

##### Abstract
The content of today's social media is becoming more and more rich, increasingly mixing text, images, videos, and audio. It is an intriguing research question to model the interplay between these different modes in attracting user attention and engagement. But in order to pursue this study of multimodal content, we must also account for context: timing effects, community preferences, and social factors (e.g., which authors are already popular) also affect the amount of feedback and reaction that social-media posts receive. In this work, we separate out the influence of these non-content factors in several ways. First, we focus on ranking pairs of submissions posted to the same community in quick succession, e.g., within 30 seconds, this framing encourages models to focus on time-agnostic and community-specific content features. Within that setting, we determine the relative performance of author vs. content features. We find that victory usually belongs to "cats and captions," as visual and textual features together tend to outperform identity-based features. Moreover, our experiments show that when considered in isolation, simple unigram text features and deep neural network visual features yield the highest accuracy individually, and that the combination of the two modalities generally leads to the best accuracies overall.

##### Abstract (translated by Google)
今天社交媒体的内容变得越来越丰富，越来越多地混合文本，图像，视频和音频。模拟这些不同模式之间的相互作用来吸引用户的注意力和参与度是一个有趣的研究问题。但是，为了进行多模态内容的研究，我们还必须考虑背景：时间效应，社区偏好和社会因素（例如，哪些作者已经受欢迎）也会影响社交媒体帖子收到的反馈和反应的数量。在这项工作中，我们以几种方式将这些非内容因素的影响分开。首先，我们专注于快速连续发布到同一社区的提交对，例如，在30秒内，这种框架鼓励模型专注于时间不可知和社区特定的内容功能。在该设置中，我们确定作者与内容特征的相对性能。我们发现胜利通常属于“猫和字幕”，因为视觉和文字特征一起倾向于优于基于身份的特征。此外，我们的实验表明，当单独考虑时，简单的单字组文本特征和深度神经网络视觉特征单独产生最高精度，并且两种模态的组合通常总体上导致最佳精度。

##### URL
[https://arxiv.org/abs/1703.01725](https://arxiv.org/abs/1703.01725)

##### PDF
[https://arxiv.org/pdf/1703.01725](https://arxiv.org/pdf/1703.01725)

