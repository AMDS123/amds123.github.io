---
layout: post
title: "Open the Black Box Data-Driven Explanation of Black Box Decision Systems"
date: 2018-06-26 12:14:44
categories: arXiv_AI
tags: arXiv_AI Inference
author: Dino Pedreschi, Fosca Giannotti, Riccardo Guidotti, Anna Monreale, Luca Pappalardo, Salvatore Ruggieri, Franco Turini
mathjax: true
---

* content
{:toc}

##### Abstract
Black box systems for automated decision making, often based on machine learning over (big) data, map a user's features into a class or a score without exposing the reasons why. This is problematic not only for lack of transparency, but also for possible biases hidden in the algorithms, due to human prejudices and collection artifacts hidden in the training data, which may lead to unfair or wrong decisions. We introduce the local-to-global framework for black box explanation, a novel approach with promising early results, which paves the road for a wide spectrum of future developments along three dimensions: (i) the language for expressing explanations in terms of highly expressive logic-based rules, with a statistical and causal interpretation; (ii) the inference of local explanations aimed at revealing the logic of the decision adopted for a specific instance by querying and auditing the black box in the vicinity of the target instance; (iii), the bottom-up generalization of the many local explanations into simple global ones, with algorithms that optimize the quality and comprehensibility of explanations.

##### Abstract (translated by Google)
用于自动决策的黑匣子系统通常基于对大数据的机器学习，将用户的功能映射到班级或乐谱中，而不会暴露原因。这不仅因为缺乏透明度，而且由于隐藏在训练数据中的人类偏见和集合伪迹可能导致算法中隐藏的偏差，这可能导致不公正或错误的决定。我们介绍了黑箱解释的地方到全球框架，这是一种有前途的早期成果的新颖方法，为三方面的广泛未来发展铺平了道路：（i）用高度表达方式表达解释的语言基于逻辑的规则，有统计和因果解释; （ii）通过查询和审计目标实例附近的黑匣子来推断当地的解释，旨在揭示针对特定实例采用的决定的逻辑; （iii），将许多局部解释自下而上地概括为简单的全局解释，并使用算法优化解释的质量和可理解性。

##### URL
[http://arxiv.org/abs/1806.09936](http://arxiv.org/abs/1806.09936)

##### PDF
[http://arxiv.org/pdf/1806.09936](http://arxiv.org/pdf/1806.09936)

