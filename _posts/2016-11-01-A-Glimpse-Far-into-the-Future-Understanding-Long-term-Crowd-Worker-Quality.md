---
layout: post
title: "A Glimpse Far into the Future: Understanding Long-term Crowd Worker Quality"
date: 2016-11-01 17:34:10
categories: arXiv_CV
tags: arXiv_CV
author: Kenji Hata, Ranjay Krishna, Li Fei-Fei, Michael S. Bernstein
mathjax: true
---

* content
{:toc}

##### Abstract
Microtask crowdsourcing is increasingly critical to the creation of extremely large datasets. As a result, crowd workers spend weeks or months repeating the exact same tasks, making it necessary to understand their behavior over these long periods of time. We utilize three large, longitudinal datasets of nine million annotations collected from Amazon Mechanical Turk to examine claims that workers fatigue or satisfice over these long periods, producing lower quality work. We find that, contrary to these claims, workers are extremely stable in their quality over the entire period. To understand whether workers set their quality based on the task's requirements for acceptance, we then perform an experiment where we vary the required quality for a large crowdsourcing task. Workers did not adjust their quality based on the acceptance threshold: workers who were above the threshold continued working at their usual quality level, and workers below the threshold self-selected themselves out of the task. Capitalizing on this consistency, we demonstrate that it is possible to predict workers' long-term quality using just a glimpse of their quality on the first five tasks.

##### Abstract (translated by Google)
Microtask众包对于创建超大型数据集日益重要。结果，围观工作者花费数周或数月重复完成相同的任务，因此有必要了解他们在这段长时间内的行为。我们利用从亚马逊机械土耳其收集到的900万注释中的三个大的纵向数据集来检查工人在这些长时间内疲劳或满意的说法，从而导致质量较差的工作。我们发现，与这些说法相反，工人在整个期间的质量极其稳定。为了了解工人是否根据任务的接受要求来设定他们的质量，我们接着进行了一个实验，在这个实验中，我们改变了大型众包任务所需的质量。工人并没有根据接受门槛来调整他们的质量：高于门槛的员工继续以通常的质量水平工作，低于门槛的员工自行选择了自己的工作。利用这种一致性，我们可以证明，只需在前五项任务中对其质量进行一瞥即可预测员工的长期质量。

##### URL
[https://arxiv.org/abs/1609.04855](https://arxiv.org/abs/1609.04855)

##### PDF
[https://arxiv.org/pdf/1609.04855](https://arxiv.org/pdf/1609.04855)

