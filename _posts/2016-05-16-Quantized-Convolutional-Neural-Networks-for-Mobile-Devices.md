---
layout: post
title: "Quantized Convolutional Neural Networks for Mobile Devices"
date: 2016-05-16 00:37:35
categories: arXiv_CV
tags: arXiv_CV CNN Classification
author: Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, Jian Cheng
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, convolutional neural networks (CNN) have demonstrated impressive performance in various computer vision tasks. However, high performance hardware is typically indispensable for the application of CNN models due to the high computation complexity, which prohibits their further extensions. In this paper, we propose an efficient framework, namely Quantized CNN, to simultaneously speed-up the computation and reduce the storage and memory overhead of CNN models. Both filter kernels in convolutional layers and weighting matrices in fully-connected layers are quantized, aiming at minimizing the estimation error of each layer's response. Extensive experiments on the ILSVRC-12 benchmark demonstrate 4~6x speed-up and 15~20x compression with merely one percentage loss of classification accuracy. With our quantized CNN model, even mobile devices can accurately classify images within one second.

##### Abstract (translated by Google)
最近，卷积神经网络（CNN）在各种计算机视觉任务中表现出令人印象深刻的性能。然而，由于高计算复杂性，高性能硬件通常对于CNN模型的应用是不可或缺的，这阻碍了它们的进一步扩展。在本文中，我们提出了一个有效的框架，即量化CNN，同时加速计算，减少CNN模型的存储和内存开销。量化卷积层中的滤波核和完全连接层中的加权矩阵，以最小化每层响应的估计误差。在ILSVRC-12基准测试中进行了大量的实验，证明了4〜6倍的加速和15〜20倍的压缩，仅仅有一个百分比的分类精度损失。利用我们量化的CNN模型，即使是移动设备也能在一秒内准确地对图像进行分类。

##### URL
[https://arxiv.org/abs/1512.06473](https://arxiv.org/abs/1512.06473)

##### PDF
[https://arxiv.org/pdf/1512.06473](https://arxiv.org/pdf/1512.06473)

