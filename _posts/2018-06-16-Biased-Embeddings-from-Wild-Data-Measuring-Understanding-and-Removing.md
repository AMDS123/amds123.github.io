---
layout: post
title: "Biased Embeddings from Wild Data: Measuring, Understanding and Removing"
date: 2018-06-16 21:46:59
categories: arXiv_AI
tags: arXiv_AI Embedding
author: Adam Sutton, Thomas Lansdall-Welfare, Nello Cristianini
mathjax: true
---

* content
{:toc}

##### Abstract
Many modern Artificial Intelligence (AI) systems make use of data embeddings, particularly in the domain of Natural Language Processing (NLP). These embeddings are learnt from data that has been gathered "from the wild" and have been found to contain unwanted biases. In this paper we make three contributions towards measuring, understanding and removing this problem. We present a rigorous way to measure some of these biases, based on the use of word lists created for social psychology applications; we observe how gender bias in occupations reflects actual gender bias in the same occupations in the real world; and finally we demonstrate how a simple projection can significantly reduce the effects of embedding bias. All this is part of an ongoing effort to understand how trust can be built into AI systems.

##### Abstract (translated by Google)
许多现代人工智能（AI）系统利用数据嵌入，特别是在自然语言处理（NLP）领域。这些嵌入是从“从野外”收集的数据中获得的，并且已经发现它们含有不需要的偏见。在本文中，我们对衡量，理解和解决这个问题做出了三个贡献。我们提出了一种严格的方法来衡量这些偏见中的一些，基于使用为社会心理学应用创建的单词列表;我们观察职业中的性别偏见如何反映现实世界同一职业中的实际性别偏见;最后我们演示一个简单的投影如何显着减少嵌入偏差的影响。所有这些都是了解AI系统如何构建信任的持续努力的一部分。

##### URL
[http://arxiv.org/abs/1806.06301](http://arxiv.org/abs/1806.06301)

##### PDF
[http://arxiv.org/pdf/1806.06301](http://arxiv.org/pdf/1806.06301)

