---
layout: post
title: "Learning to Grasp from 2.5D images: a Deep Reinforcement Learning Approach"
date: 2019-08-08 07:53:24
categories: arXiv_RO
tags: arXiv_RO Knowledge Face Reinforcement_Learning
author: Alessia Bertugli, Paolo Galeone
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a deep reinforcement learning (DRL) solution to the grasping problem using 2.5D images as the only source of information. In particular, we developed a simulated environment where a robot equipped with a vacuum gripper has the aim of reaching blocks with planar surfaces. These blocks can have different dimensions, shapes, position and orientation. Unity 3D allowed us to simulate a real-world setup, where a depth camera is placed in a fixed position and the stream of images is used by our policy network to learn how to solve the task. We explored different DRL algorithms and problem configurations. The experiments demonstrated the effectiveness of the proposed DRL algorithm applied to grasp tasks guided by visual depth camera inputs. When using the proper policy, the proposed method estimates a robot tool configuration that reaches the object surface with negligible position and orientation errors. This is, to the best of our knowledge, the first successful attempt of using 2.5D images only as of the input of a DRL algorithm, to solve the grasping problem regressing 3D world coordinates.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.03440](http://arxiv.org/abs/1908.03440)

##### PDF
[http://arxiv.org/pdf/1908.03440](http://arxiv.org/pdf/1908.03440)

