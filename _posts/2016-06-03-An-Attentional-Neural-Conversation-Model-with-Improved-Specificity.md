---
layout: post
title: "An Attentional Neural Conversation Model with Improved Specificity"
date: 2016-06-03 22:26:01
categories: arXiv_CL
tags: arXiv_CL Attention
author: Kaisheng Yao, Baolin Peng, Geoffrey Zweig, Kam-Fai Wong
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we propose a neural conversation model for conducting dialogues. We demonstrate the use of this model to generate help desk responses, where users are asking questions about PC applications. Our model is distinguished by two characteristics. First, it models intention across turns with a recurrent network, and incorporates an attention model that is conditioned on the representation of intention. Secondly, it avoids generating non-specific responses by incorporating an IDF term in the objective function. The model is evaluated both as a pure generation model in which a help-desk response is generated from scratch, and as a retrieval model with performance measured using recall rates of the correct response. Experimental results indicate that the model outperforms previously proposed neural conversation architectures, and that using specificity in the objective function significantly improves performances for both generation and retrieval.

##### Abstract (translated by Google)
在本文中，我们提出了一个进行对话的神经对话模型。我们演示了如何使用这个模型来生成帮助台响应，用户在这里询问有关PC应用程序的问题。我们的模型有两个特点。首先，它用轮回网络模拟意图，并结合以意图表示为基础的注意模式。其次，它通过在目标函数中引入一个IDF项来避免产生非特定的响应。该模型被评估为纯粹的一代模型，其中从头开始生成帮助台响应，并且作为具有使用正确响应的召回率测量的性能的检索模型。实验结果表明，该模型胜过先前提出的神经对话体系结构，并且在目标函数中使用特异性显着提高了生成和检索的性能。

##### URL
[https://arxiv.org/abs/1606.01292](https://arxiv.org/abs/1606.01292)

##### PDF
[https://arxiv.org/pdf/1606.01292](https://arxiv.org/pdf/1606.01292)

