---
layout: post
title: "Reinforcement Learning Based Emotional Editing Constraint Conversation Generation"
date: 2019-04-17 03:01:16
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning Language_Model
author: Jia Li, Xiao Sun, Xing Wei, Changliang Li, Jianhua Tao
mathjax: true
---

* content
{:toc}

##### Abstract
In recent years, the generation of conversation content based on deep neural networks has attracted many researchers. However, traditional neural language models tend to generate general replies, lacking logical and emotional factors. This paper proposes a conversation content generation model that combines reinforcement learning with emotional editing constraints to generate more meaningful and customizable emotional replies. The model divides the replies into three clauses based on pre-generated keywords and uses the emotional editor to further optimize the final reply. The model combines multi-task learning with multiple indicator rewards to comprehensively optimize the quality of replies. Experiments shows that our model can not only improve the fluency of the replies, but also significantly enhance the logical relevance and emotional relevance of the replies.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.08061](http://arxiv.org/abs/1904.08061)

##### PDF
[http://arxiv.org/pdf/1904.08061](http://arxiv.org/pdf/1904.08061)

