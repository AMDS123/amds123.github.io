---
layout: post
title: "Drug Similarity Integration Through Attentive Multi-view Graph Auto-Encoders"
date: 2018-04-28 22:14:29
categories: arXiv_AI
tags: arXiv_AI Relation
author: Tengfei Ma, Cao Xiao, Jiayu Zhou, Fei Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Drug similarity has been studied to support downstream clinical tasks such as inferring novel properties of drugs (e.g. side effects, indications, interactions) from known properties. The growing availability of new types of drug features brings the opportunity of learning a more comprehensive and accurate drug similarity that represents the full spectrum of underlying drug relations. However, it is challenging to integrate these heterogeneous, noisy, nonlinear-related information to learn accurate similarity measures especially when labels are scarce. Moreover, there is a trade-off between accuracy and interpretability. In this paper, we propose to learn accurate and interpretable similarity measures from multiple types of drug features. In particular, we model the integration using multi-view graph auto-encoders, and add attentive mechanism to determine the weights for each view with respect to corresponding tasks and features for better interpretability. Our model has flexible design for both semi-supervised and unsupervised settings. Experimental results demonstrated significant predictive accuracy improvement. Case studies also showed better model capacity (e.g. embed node features) and interpretability.

##### Abstract (translated by Google)
已经研究药物相似性以支持下游临床任务，例如从已知性质推断药物的新性质（例如副作用，适应症，相互作用）。新类型的药物特征越来越多的可用性带来了学习更全面和准确的药物相似性的机会，这种相似性代表了全面的药物关系。然而，要集成这些异构的，噪杂的非线性相关信息来学习准确的相似性度量，特别是在标签稀缺的时候，这是具有挑战性的。此外，在准确性和可解释性之间有一个折衷。在本文中，我们建议从多种类型的药物特征中学习准确和可解释的相似性度量。具体而言，我们使用多视图图形自动编码器对集成进行建模，并添加细致的机制来确定每个视图相对于相应任务和特征的权重，以获得更好的可解释性。我们的模型对于半监督和非监督设置都有灵活的设计。实验结果表明显着提高了预测准确度。案例研究还显示了更好的模型容量（例如嵌入节点功能）和可解释性。

##### URL
[https://arxiv.org/abs/1804.10850](https://arxiv.org/abs/1804.10850)

##### PDF
[https://arxiv.org/pdf/1804.10850](https://arxiv.org/pdf/1804.10850)

