---
layout: post
title: "Improving speaker turn embedding by crossmodal transfer learning from face embedding"
date: 2017-07-10 08:51:53
categories: arXiv_CV
tags: arXiv_CV Knowledge Face Embedding Transfer_Learning
author: Nam Le, Jean-Marc Odobez
mathjax: true
---

* content
{:toc}

##### Abstract
Learning speaker turn embeddings has shown considerable improvement in situations where conventional speaker modeling approaches fail. However, this improvement is relatively limited when compared to the gain observed in face embedding learning, which has been proven very successful for face verification and clustering tasks. Assuming that face and voices from the same identities share some latent properties (like age, gender, ethnicity), we propose three transfer learning approaches to leverage the knowledge from the face domain (learned from thousands of images and identities) for tasks in the speaker domain. These approaches, namely target embedding transfer, relative distance transfer, and clustering structure transfer, utilize the structure of the source face embedding space at different granularities to regularize the target speaker turn embedding space as optimizing terms. Our methods are evaluated on two public broadcast corpora and yield promising advances over competitive baselines in verification and audio clustering tasks, especially when dealing with short speaker utterances. The analysis of the results also gives insight into characteristics of the embedding spaces and shows their potential applications.

##### Abstract (translated by Google)
在传统的扬声器建模方法失败的情况下，学习扬声器转向嵌入已经显示出相当大的改进然而，与面孔嵌入学习相比，这种改进相对有限，这在面部验证和聚类任务中被证明是非常成功的。假设来自相同身份的人脸和声音具有一些潜在属性（如年龄，性别，种族），我们提出了三种转移学习方法来利用人脸知识（从成千上万的图像和身份学习）域。这些方法，即目标嵌入转移，相对距离转移和聚类结构转移，利用不同粒度下的源面嵌入空间结构，将目标说话人转向嵌入空间调整为优化项。我们的方法在两个公共广播语料库上进行评估，并且在验证和音频聚类任务中的竞争基线方面取得了有希望的进展，尤其是在处理短语者话语时。结果的分析也提供了洞察嵌入空间的特征并展示其潜在的应用。

##### URL
[https://arxiv.org/abs/1707.02749](https://arxiv.org/abs/1707.02749)

##### PDF
[https://arxiv.org/pdf/1707.02749](https://arxiv.org/pdf/1707.02749)

