---
layout: post
title: "AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks"
date: 2017-11-28 18:59:50
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, Xiaodong He
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose an Attentional Generative Adversarial Network (AttnGAN) that allows attention-driven, multi-stage refinement for fine-grained text-to-image generation. With a novel attentional generative network, the AttnGAN can synthesize fine-grained details at different subregions of the image by paying attentions to the relevant words in the natural language description. In addition, a deep attentional multimodal similarity model is proposed to compute a fine-grained image-text matching loss for training the generator. The proposed AttnGAN significantly outperforms the previous state of the art, boosting the best reported inception score by 14.14% on the CUB dataset and 170.25% on the more challenging COCO dataset. A detailed analysis is also performed by visualizing the attention layers of the AttnGAN. It for the first time shows that the layered attentional GAN is able to automatically select the condition at the word level for generating different parts of the image.

##### Abstract (translated by Google)
在本文中，我们提出了一个注意力生成对抗网络（AttnGAN），允许注意力驱动，多阶段细化的细粒度文本到图像的生成。在一个新颖的注意力生成网络中，AttnGAN可以通过关注自然语言描述中的相关词汇，在图像的不同子区域合成细粒度的细节。此外，还提出了深度注意的多模式相似度模型来计算训练发生器的细粒度图像文本匹配损失。所提出的AttnGAN显着优于先前的技术水平，在CUB数据集上提高了14.14％的最佳报告初始分数，在更具挑战性的COCO数据集上提高了170.25％。通过可视化AttnGAN的关注层来执行详细的分析。它首次表明，分层注意的GAN能够自动选择字级的条件来生成图像的不同部分。

##### URL
[https://arxiv.org/abs/1711.10485](https://arxiv.org/abs/1711.10485)

##### PDF
[https://arxiv.org/pdf/1711.10485](https://arxiv.org/pdf/1711.10485)

