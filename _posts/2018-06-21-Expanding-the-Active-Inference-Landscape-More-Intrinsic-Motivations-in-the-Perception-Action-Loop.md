---
layout: post
title: "Expanding the Active Inference Landscape: More Intrinsic Motivations in the Perception-Action Loop"
date: 2018-06-21 06:53:45
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Inference
author: Martin Biehl (1), Christian Guckelsberger (2), Christoph Salge (3 and 4), Sim&#xf3;n C. Smith (4 and 5), Daniel Polani (4) ((1) Araya Inc., Tokyo, Japan, (2) Computational Creativity Group, Department of Computing, Goldsmiths, University of London, London, UK, (3) Game Innovation Lab, Department of Computer Science and Engineering, New York University, New York City, NY, USA, (4) Sepia Lab, Adaptive Systems Research Group, Department of Computer Science, University of Hertfordshire, Hatfield, UK, (5) Institute of Perception, Action and Behaviour, School of Informatics, The University of Edinburgh, UK)
mathjax: true
---

* content
{:toc}

##### Abstract
Active inference is an ambitious theory that treats perception, inference and action selection of autonomous agents under the heading of a single principle. It suggests biologically plausible explanations for many cognitive phenomena, including consciousness. In active inference, action selection is driven by an objective function that evaluates possible future actions with respect to current, inferred beliefs about the world. Active inference at its core is independent from extrinsic rewards, resulting in a high level of robustness across e.g.\ different environments or agent morphologies. In the literature, paradigms that share this independence have been summarised under the notion of intrinsic motivations. In general and in contrast to active inference, these models of motivation come without a commitment to particular inference and action selection mechanisms. In this article, we study if the inference and action selection machinery of active inference can also be used by alternatives to the originally included intrinsic motivation. The perception-action loop explicitly relates inference and action selection to the environment and agent memory, and is consequently used as foundation for our analysis. We reconstruct the active inference approach, locate the original formulation within, and show how alternative intrinsic motivations can be used while keeping many of the original features intact. Furthermore, we illustrate the connection to universal reinforcement learning by means of our formalism. Active inference research may profit from comparisons of the dynamics induced by alternative intrinsic motivations. Research on intrinsic motivations may profit from an additional way to implement intrinsically motivated agents that also share the biological plausibility of active inference.

##### Abstract (translated by Google)
积极推理是一种雄心勃勃的理论，它在单一原则的标题下处理自主智能体的感知，推理和行为选择。它为许多认知现象，包括意识，提出了生物学上合理的解释。在积极推理中，行动选择是由一个目标函数驱动的，该目标函数评估可能的未来行为与当前推断出的关于世界的信念。其核心的主动推断独立于外在奖励，从而在例如\不同环境或代理形态学中具有高水平的鲁棒性。在文献中，分享这种独立性的范式已经在内在动机的概念下进行了总结。一般而言，与主动推论相反，这些动机模型没有对特定推理和行动选择机制的承诺。在这篇文章中，我们研究主动推断的推理和行动选择机制是否也可以用原来包含的内在动机的替代方法来使用。感知 - 行动循环将推理和行动选择明确地与环境和行动记忆联系起来，因此被用作我们分析的基础。我们重建主动推理方法，找到原始公式，并展示如何使用替代内在动机，同时保持许多原始特征完好无损。此外，我们通过我们的形式主义来说明与通用强化学习的联系。积极的推理研究可能会从其他内在动机所引发的动力学比较中获益。对内在动机的研究可能会从另外一种方式中获益，以实现具有内在动机的因素，这些因素也具有主动推论的生物合理性。

##### URL
[http://arxiv.org/abs/1806.08083](http://arxiv.org/abs/1806.08083)

##### PDF
[http://arxiv.org/pdf/1806.08083](http://arxiv.org/pdf/1806.08083)

