---
layout: post
title: "MUSE: Modularizing Unsupervised Sense Embeddings"
date: 2018-06-30 06:20:34
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning Embedding Represenation_Learning
author: Guang-He Lee, Yun-Nung Chen
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes to address the word sense ambiguity issue in an unsupervised manner, where word sense representations are learned along a word sense selection mechanism given contexts. Prior work focused on designing a single model to deliver both mechanisms, and thus suffered from either coarse-grained representation learning or inefficient sense selection. The proposed modular approach, MUSE, implements flexible modules to optimize distinct mechanisms, achieving the first purely sense-level representation learning system with linear-time sense selection. We leverage reinforcement learning to enable joint training on the proposed modules, and introduce various exploration techniques on sense selection for better robustness. The experiments on benchmark data show that the proposed approach achieves the state-of-the-art performance on synonym selection as well as on contextual word similarities in terms of MaxSimC.

##### Abstract (translated by Google)
本文提出以无监督的方式解决词义模糊问题，其中词义表示是在给定上下文的词义选择机制下学习的。先前的工作集中在设计单个模型以提供两种机制，因此遭受粗粒度表示学习或低效感觉选择。所提出的模块化方法MUSE实现了灵活的模块以优化不同的机制，实现了第一个具有线性时间感知选择的纯感知级表示学习系统。我们利用强化学习来对所提出的模块进行联合培训，并在感知选择上引入各种探索技术以获得更好的稳健性。基准数据的实验表明，所提出的方法在同义词选择以及MaxSimC方面的语境相似性方面达到了最先进的性能。

##### URL
[http://arxiv.org/abs/1704.04601](http://arxiv.org/abs/1704.04601)

##### PDF
[http://arxiv.org/pdf/1704.04601](http://arxiv.org/pdf/1704.04601)

