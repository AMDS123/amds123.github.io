---
layout: post
title: "Deep Short Text Classification with Knowledge Powered Attention"
date: 2019-02-21 13:50:56
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention Text_Classification Classification
author: Jindong Chen, Yizhou Hu, Jingping Liu, Yanghua Xiao, Haiyun Jiang
mathjax: true
---

* content
{:toc}

##### Abstract
Short text classification is one of important tasks in Natural Language Processing (NLP). Unlike paragraphs or documents, short texts are more ambiguous since they have not enough contextual information, which poses a great challenge for classification. In this paper, we retrieve knowledge from external knowledge source to enhance the semantic representation of short texts. We take conceptual information as a kind of knowledge and incorporate it into deep neural networks. For the purpose of measuring the importance of knowledge, we introduce attention mechanisms and propose deep Short Text Classification with Knowledge powered Attention (STCKA). We utilize Concept towards Short Text (C- ST) attention and Concept towards Concept Set (C-CS) attention to acquire the weight of concepts from two aspects. And we classify a short text with the help of conceptual information. Unlike traditional approaches, our model acts like a human being who has intrinsic ability to make decisions based on observation (i.e., training data for machines) and pays more attention to important knowledge. We also conduct extensive experiments on four public datasets for different tasks. The experimental results and case studies show that our model outperforms the state-of-the-art methods, justifying the effectiveness of knowledge powered attention.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.08050](http://arxiv.org/abs/1902.08050)

##### PDF
[http://arxiv.org/pdf/1902.08050](http://arxiv.org/pdf/1902.08050)

