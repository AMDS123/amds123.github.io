---
layout: post
title: "Teaching Machines to Read and Comprehend"
date: 2015-11-19 15:43:23
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention
author: Karl Moritz Hermann, Tomáš Kočiský, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, Phil Blunsom
mathjax: true
---

* content
{:toc}

##### Abstract
Teaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. In this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. This allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure.

##### Abstract (translated by Google)
阅读自然语言文件的教学机器仍然是一个难以捉摸的挑战。机器阅读系统可以测试他们回答他们已经看到的文件内容提出的问题的能力，但是到目前为止，这种类型的评估缺少大规模的培训和测试数据集。在这项工作中，我们定义了一种新的方法来解决这个瓶颈，并提供大规模的监督阅读理解数据。这使我们能够开发一类基于注意力的深度神经网络，学习阅读真实的文件，并用最少的语言结构知识来回答复杂的问题。

##### URL
[https://arxiv.org/abs/1506.03340](https://arxiv.org/abs/1506.03340)

##### PDF
[https://arxiv.org/pdf/1506.03340](https://arxiv.org/pdf/1506.03340)

