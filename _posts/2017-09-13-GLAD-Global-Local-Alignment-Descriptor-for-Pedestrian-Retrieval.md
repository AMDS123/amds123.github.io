---
layout: post
title: "GLAD: Global-Local-Alignment Descriptor for Pedestrian Retrieval"
date: 2017-09-13 13:44:46
categories: arXiv_CV
tags: arXiv_CV Re-identification Person_Re-identification Represenation_Learning
author: Longhui Wei, Shiliang Zhang, Hantao Yao, Wen Gao, Qi Tian
mathjax: true
---

* content
{:toc}

##### Abstract
The huge variance of human pose and the misalignment of detected human images significantly increase the difficulty of person Re-Identification (Re-ID). Moreover, efficient Re-ID systems are required to cope with the massive visual data being produced by video surveillance systems. Targeting to solve these problems, this work proposes a Global-Local-Alignment Descriptor (GLAD) and an efficient indexing and retrieval framework, respectively. GLAD explicitly leverages the local and global cues in human body to generate a discriminative and robust representation. It consists of part extraction and descriptor learning modules, where several part regions are first detected and then deep neural networks are designed for representation learning on both the local and global regions. A hierarchical indexing and retrieval framework is designed to eliminate the huge redundancy in the gallery set, and accelerate the online Re-ID procedure. Extensive experimental results show GLAD achieves competitive accuracy compared to the state-of-the-art methods. Our retrieval framework significantly accelerates the online Re-ID procedure without loss of accuracy. Therefore, this work has potential to work better on person Re-ID tasks in real scenarios.

##### Abstract (translated by Google)
人体姿态的巨大变化和检测到的人体图像的错位显着增加了人员重新识别（Re-ID）的难度。而且，需要有效的Re-ID系统来处理由视频监视系统产生的大量视频数据。针对这些问题，本文分别提出了一个全局局部对齐描述符（GLAD）和一个有效的索引检索框架。 GLAD明确地利用人体内的局部和全局线索来生成一个有区别的，健壮的表示。它由部分提取和描述符学习模块组成，首先检测几个部分区域，然后在本地和全球区域设计深度神经网络进行表示学习。设计了分级索引和检索框架，以消除库集中的巨大冗余，并加速在线Re-ID过程。广泛的实验结果表明，与最先进的方法相比，GLAD具有竞争力的准确性。我们的检索框架显着加速了在线Re-ID程序，而不会降低准确性。因此，这项工作有可能在实际情况下更好地处理人员重新识别任务。

##### URL
[https://arxiv.org/abs/1709.04329](https://arxiv.org/abs/1709.04329)

##### PDF
[https://arxiv.org/pdf/1709.04329](https://arxiv.org/pdf/1709.04329)

