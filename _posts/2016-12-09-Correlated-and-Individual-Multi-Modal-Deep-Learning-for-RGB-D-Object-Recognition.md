---
layout: post
title: "Correlated and Individual Multi-Modal Deep Learning for RGB-D Object Recognition"
date: 2016-12-09 13:56:02
categories: arXiv_CV
tags: arXiv_CV CNN Deep_Learning Recognition
author: Ziyan Wang, Jiwen Lu, Ruogu Lin, Jianjiang Feng, Jie zhou
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a new correlated and individual multi-modal deep learning (CIMDL) method for RGB-D object recognition. Unlike most conventional RGB-D object recognition methods which extract features from the RGB and depth channels individually, our CIMDL jointly learns feature representations from raw RGB-D data with a pair of deep neural networks, so that the sharable and modal-specific information can be simultaneously exploited. Specifically, we construct a pair of deep convolutional neural networks (CNNs) for the RGB and depth data, and concatenate them at the top layer of the network with a loss function which learns a new feature space where both correlated part and the individual part of the RGB-D information are well modelled. The parameters of the whole networks are updated by using the back-propagation criterion. Experimental results on two widely used RGB-D object image benchmark datasets clearly show that our method outperforms state-of-the-arts.

##### Abstract (translated by Google)
在本文中，我们提出了一种新的相关和独立的多模态深度学习（CIMDL）方法的RGB-D目标识别。与大多数从RGB和深度通道中分别提取特征的常规RGB-D对象识别方法不同，我们的CIMDL通过一对深度神经网络从原始RGB-D数据中共同学习特征表示，以便可共享和模态特定的信息同时被利用。具体而言，我们为RGB和深度数据构建了一对深度卷积神经网络（CNN），并将它们连接在网络的顶层，具有损失函数，学习一个新的特征空间，其中相关部​​分和RGB-D信息很好地建模。整个网络的参数使用反向传播准则进行更新。在两个广泛使用的RGB-D目标图像基准数据集上的实验结果清楚地表明，我们的方法优于现有技术。

##### URL
[https://arxiv.org/abs/1604.01655](https://arxiv.org/abs/1604.01655)

##### PDF
[https://arxiv.org/pdf/1604.01655](https://arxiv.org/pdf/1604.01655)

