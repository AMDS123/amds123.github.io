---
layout: post
title: "Domain Adaptation of Recurrent Neural Networks for Natural Language Understanding"
date: 2016-08-10 02:53:00
categories: arXiv_SD
tags: arXiv_SD RNN
author: Aaron Jaech, Larry Heck, Mari Ostendorf
mathjax: true
---

* content
{:toc}

##### Abstract
The goal of this paper is to use multi-task learning to efficiently scale slot filling models for natural language understanding to handle multiple target tasks or domains. The key to scalability is reducing the amount of training data needed to learn a model for a new task. The proposed multi-task model delivers better performance with less data by leveraging patterns that it learns from the other tasks. The approach supports an open vocabulary, which allows the models to generalize to unseen words, which is particularly important when very little training data is used. A newly collected crowd-sourced data set, covering four different domains, is used to demonstrate the effectiveness of the domain adaptation and open vocabulary techniques.

##### Abstract (translated by Google)
本文的目标是使用多任务学习来有效地扩展槽口填充模型的自然语言理解，以处理多个目标任务或领域。可伸缩性的关键在于减少学习新任务模型所需的训练数据量。提出的多任务模型通过利用从其他任务中学习的模式，以较少的数据提供更好的性能。该方法支持开放的词汇表，它允许模型推广到看不见的单词，这在使用非常少的训练数据时特别重要。新收集的来自四个不同领域的众包数据集用于证明领域适应和开放词汇技术的有效性。

##### URL
[https://arxiv.org/abs/1604.00117](https://arxiv.org/abs/1604.00117)

##### PDF
[https://arxiv.org/pdf/1604.00117](https://arxiv.org/pdf/1604.00117)

