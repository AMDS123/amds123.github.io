---
layout: post
title: "Crowdsourcing Multiple Choice Science Questions"
date: 2017-07-19 17:28:46
categories: arXiv_CL
tags: arXiv_CL
author: Johannes Welbl, Nelson F. Liu, Matt Gardner
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel method for obtaining high-quality, domain-targeted multiple choice questions from crowd workers. Generating these questions can be difficult without trading away originality, relevance or diversity in the answer options. Our method addresses these problems by leveraging a large corpus of domain-specific text and a small set of existing questions. It produces model suggestions for document selection and answer distractor choice which aid the human question generation process. With this method we have assembled SciQ, a dataset of 13.7K multiple choice science exam questions (Dataset available at this http URL). We demonstrate that the method produces in-domain questions by providing an analysis of this new dataset and by showing that humans cannot distinguish the crowdsourced questions from original questions. When using SciQ as additional training data to existing questions, we observe accuracy improvements on real science exams.

##### Abstract (translated by Google)
我们提出了一个新的方法来获得高质量的，从众多的工作人员的领域为目标的选择题。生成这些问题可能是困难的，而不用交换原创性，相关性或答案选项的多样性。我们的方法通过利用大量的领域特定文本和一小组现有问题来解决这些问题。它提供了文件选择的模型建议和回答分心的选择，这有助于人类问题的产生过程。通过这种方法，我们已经组装了SciQ，一个13.7K多选科学考试题（数据集可在这个http URL）的数据集。我们证明，该方法通过提供这个新的数据集的分析，并通过显示人类无法区分来自原始问题的众包的问题，​​产生领域的问题。当使用SciQ作为现有问题的附加训练数据时，我们观察到对真实科学考试的准确度提高。

##### URL
[https://arxiv.org/abs/1707.06209](https://arxiv.org/abs/1707.06209)

##### PDF
[https://arxiv.org/pdf/1707.06209](https://arxiv.org/pdf/1707.06209)

