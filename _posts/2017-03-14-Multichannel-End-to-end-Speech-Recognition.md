---
layout: post
title: "Multichannel End-to-end Speech Recognition"
date: 2017-03-14 22:28:51
categories: arXiv_SD
tags: arXiv_SD Attention Speech_Recognition Language_Model Recognition
author: Tsubasa Ochiai, Shinji Watanabe, Takaaki Hori, John R. Hershey
mathjax: true
---

* content
{:toc}

##### Abstract
The field of speech recognition is in the midst of a paradigm shift: end-to-end neural networks are challenging the dominance of hidden Markov models as a core technology. Using an attention mechanism in a recurrent encoder-decoder architecture solves the dynamic time alignment problem, allowing joint end-to-end training of the acoustic and language modeling components. In this paper we extend the end-to-end framework to encompass microphone array signal processing for noise suppression and speech enhancement within the acoustic encoding network. This allows the beamforming components to be optimized jointly within the recognition architecture to improve the end-to-end speech recognition objective. Experiments on the noisy speech benchmarks (CHiME-4 and AMI) show that our multichannel end-to-end system outperformed the attention-based baseline with input from a conventional adaptive beamformer.

##### Abstract (translated by Google)
语音识别领域正处于一个范式转变之中：端到端的神经网络正在挑战作为核心技术的隐马尔可夫模型的主导地位。在经常性的编码器 - 解码器架构中使用注意机制解决了动态时间对准问题，允许对声学和语言建模组件进行联合端对端训练。在本文中，我们扩展了端到端框架，以涵盖声学编码网络内的噪声抑制和语音增强的麦克风阵列信号处理。这允许波束成形部件在识别架构内被共同优化，以改进端到端语音识别目标。在噪声话音基准测试（CHiME-4和AMI）上的实验表明，我们的多通道端到端系统比传统自适应波束形成器的输入优于基于注意的基线。

##### URL
[https://arxiv.org/abs/1703.04783](https://arxiv.org/abs/1703.04783)

##### PDF
[https://arxiv.org/pdf/1703.04783](https://arxiv.org/pdf/1703.04783)

