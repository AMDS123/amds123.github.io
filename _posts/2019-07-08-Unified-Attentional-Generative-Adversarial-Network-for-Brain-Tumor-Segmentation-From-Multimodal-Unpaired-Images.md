---
layout: post
title: "Unified Attentional Generative Adversarial Network for Brain Tumor Segmentation From Multimodal Unpaired Images"
date: 2019-07-08 12:12:59
categories: arXiv_CV
tags: arXiv_CV Adversarial Segmentation Attention GAN
author: Wenguang Yuan, Jia Wei, Jiabing Wang, Qianli Ma, Tolga Tasdizen
mathjax: true
---

* content
{:toc}

##### Abstract
In medical applications, the same anatomical structures may be observed in multiple modalities despite the different image characteristics. Currently, most deep models for multimodal segmentation rely on paired registered images. However, multimodal paired registered images are difficult to obtain in many cases. Therefore, developing a model that can segment the target objects from different modalities with unpaired images is significant for many clinical applications. In this work, we propose a novel two-stream translation and segmentation unified attentional generative adversarial network (UAGAN), which can perform any-to-any image modality translation and segment the target objects simultaneously in the case where two or more modalities are available. The translation stream is used to capture modality-invariant features of the target anatomical structures. In addition, to focus on segmentation-related features, we add attentional blocks to extract valuable features from the translation stream. Experiments on three-modality brain tumor segmentation indicate that UAGAN outperforms the existing methods in most cases.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.03548](http://arxiv.org/abs/1907.03548)

##### PDF
[http://arxiv.org/pdf/1907.03548](http://arxiv.org/pdf/1907.03548)

