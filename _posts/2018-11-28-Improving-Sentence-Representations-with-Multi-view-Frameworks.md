---
layout: post
title: "Improving Sentence Representations with Multi-view Frameworks"
date: 2018-11-28 01:12:24
categories: arXiv_CL
tags: arXiv_CL RNN
author: Shuai Tang, Virginia R. de Sa
mathjax: true
---

* content
{:toc}

##### Abstract
Multi-view learning can provide self-supervision when different views are available of the same data. Distributional hypothesis provides another form of useful self-supervision from adjacent sentences which are plentiful in large unlabelled corpora. Motivated by the asymmetry in the two hemispheres of the human brain as well as the observation that different learning architectures tend to emphasise different aspects of sentence meaning, we present two multi-view frameworks for learning sentence representations in an unsupervised fashion. One framework uses a generative objective and the other a discriminative one. In both frameworks, the final representation is an ensemble of two views, in which, one view encodes the input sentence with a Recurrent Neural Network (RNN), and the other view encodes it with a simple linear model. We show that, after learning, the vectors produced by our multi-view frameworks provide improved representations over their single-view learnt counterparts, and the combination of different views gives representational improvement over each view and demonstrates solid transferability on standard downstream tasks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.01064](http://arxiv.org/abs/1810.01064)

##### PDF
[http://arxiv.org/pdf/1810.01064](http://arxiv.org/pdf/1810.01064)

