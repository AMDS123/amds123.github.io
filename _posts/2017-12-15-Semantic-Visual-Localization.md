---
layout: post
title: "Semantic Visual Localization"
date: 2017-12-15 18:02:47
categories: arXiv_CV
tags: arXiv_CV
author: Johannes L. Sch&#xf6;nberger, Marc Pollefeys, Andreas Geiger, Torsten Sattler
mathjax: true
---

* content
{:toc}

##### Abstract
Robust visual localization under a wide range of viewing conditions is a fundamental problem in computer vision. Handling the difficult cases of this problem is not only very challenging but also of high practical relevance, e.g., in the context of life-long localization for augmented reality or autonomous robots. In this paper, we propose a novel approach based on a joint geometric and semantic understanding of the world, enabling it to succeed under conditions where previous approaches failed. Our method leverages a novel generative model for descriptor learning, trained on semantic scene completion as an auxiliary task. The resulting descriptors are robust to missing observations by encoding high-level geometric and semantic information. Experiments on several challenging large-scale localization datasets demonstrate reliable localization under extreme viewpoint, illumination, and geometry changes.

##### Abstract (translated by Google)
在广泛的观看条件下鲁棒的视觉定位是计算机视觉中的一个基本问题。处理这个问题的困难情况不仅非常具有挑战性，而且还具有很高的实际相关性，例如在增强现实或自主机器人的终身定位环境中。在本文中，我们提出了一种基于对世界的联合几何和语义理解的新方法，使其能够在以前的方法失败的条件下成功。我们的方法利用描述符学习的新型生成模型，将语义场景完成训练为辅助任务。由此产生的描述符通过对高级几何和语义信息进行编码而缺失观察值。对几个具有挑战性的大规模定位数据集的实验证明，在极端观点，照明和几何变化下可靠的定位。

##### URL
[http://arxiv.org/abs/1712.05773](http://arxiv.org/abs/1712.05773)

##### PDF
[http://arxiv.org/pdf/1712.05773](http://arxiv.org/pdf/1712.05773)

