---
layout: post
title: "Learning to Rank Scientific Documents from the Crowd"
date: 2016-11-04 14:43:44
categories: arXiv_CL
tags: arXiv_CL Knowledge
author: Jesse M Lingeman, Hong Yu
mathjax: true
---

* content
{:toc}

##### Abstract
Finding related published articles is an important task in any science, but with the explosion of new work in the biomedical domain it has become especially challenging. Most existing methodologies use text similarity metrics to identify whether two articles are related or not. However biomedical knowledge discovery is hypothesis-driven. The most related articles may not be ones with the highest text similarities. In this study, we first develop an innovative crowd-sourcing approach to build an expert-annotated document-ranking corpus. Using this corpus as the gold standard, we then evaluate the approaches of using text similarity to rank the relatedness of articles. Finally, we develop and evaluate a new supervised model to automatically rank related scientific articles. Our results show that authors' ranking differ significantly from rankings by text-similarity-based models. By training a learning-to-rank model on a subset of the annotated corpus, we found the best supervised learning-to-rank model (SVM-Rank) significantly surpassed state-of-the-art baseline systems.

##### Abstract (translated by Google)
查找相关的已发表的文章是任何科学的重要任务，但是随着生物医学领域的新工作的爆发，它变得特别具有挑战性。大多数现有的方法使用文本相似性度量来确定两篇文章是否相关。然而，生物医学知识发现是假设驱动的。最相关的文章可能不是文本相似度最高的文章。在这项研究中，我们首先开发了一种创新的群众采购方法来构建一个专家注释的文档排名语料库。以此语料库为黄金标准，评估文本相似度排序的方法。最后，我们开发和评估一个新的监督模型，自动排序相关的科学文章。我们的研究结果显示作者的排名与基于文本相似度模型的排名有显着的不同。通过在注释语料库的子集上训练学习到排名模型，我们发现最佳监督学习到排名模型（SVM-Rank）显着地超越了最先进的基线系统。

##### URL
[https://arxiv.org/abs/1611.01400](https://arxiv.org/abs/1611.01400)

##### PDF
[https://arxiv.org/pdf/1611.01400](https://arxiv.org/pdf/1611.01400)

