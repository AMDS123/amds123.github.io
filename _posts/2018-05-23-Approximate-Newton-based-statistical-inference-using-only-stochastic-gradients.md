---
layout: post
title: "Approximate Newton-based statistical inference using only stochastic gradients"
date: 2018-05-23 01:07:47
categories: arXiv_CV
tags: arXiv_CV Adversarial Inference
author: Tianyang Li, Anastasios Kyrillidis, Liu Liu, Constantine Caramanis
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel inference framework for convex empirical risk minimization, using approximate stochastic Newton steps. The proposed algorithm is based on the notion of finite differences and allows the approximation of a Hessian-vector product from first-order information. In theory, our method efficiently computes the statistical error covariance in $M$-estimation, both for unregularized convex learning problems and high-dimensional LASSO regression, without using exact second order information, or resampling the entire data set. In practice, we demonstrate the effectiveness of our framework on large-scale machine learning problems, that go even beyond convexity: as a highlight, our work can be used to detect certain adversarial attacks on neural networks.

##### Abstract (translated by Google)
我们提出了一种新的用于凸经验风险最小化的推理框架，使用近似的随机牛顿步骤。所提出的算法基于有限差分的概念并且允许从一阶信息逼近Hessian向量乘积。理论上，我们的方法可以高效地计算$ M $  - 估计中的统计误差协方差，既可以用于非规范化凸学习问题，也可以用于高维LASSO回归，而无需使用精确的二阶信息或重新采样整个数据集。在实践中，我们证明了我们的框架在大规模机器学习问题上的有效性，甚至超越了凸性：作为一个亮点，我们的工作可以用来检测对神经网络的某些敌对攻击。

##### URL
[http://arxiv.org/abs/1805.08920](http://arxiv.org/abs/1805.08920)

##### PDF
[http://arxiv.org/pdf/1805.08920](http://arxiv.org/pdf/1805.08920)

