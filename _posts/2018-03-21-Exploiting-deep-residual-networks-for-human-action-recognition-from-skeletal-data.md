---
layout: post
title: "Exploiting deep residual networks for human action recognition from skeletal data"
date: 2018-03-21 07:43:53
categories: arXiv_CV
tags: arXiv_CV Action_Recognition CNN Deep_Learning Recognition
author: Huy-Hieu Pham, Louahdi Khoudour, Alain Crouzil, Pablo Zegers, Sergio A. Velastin
mathjax: true
---

* content
{:toc}

##### Abstract
The computer vision community is currently focusing on solving action recognition problems in real videos, which contain thousands of samples with many challenges. In this process, Deep Convolutional Neural Networks (D-CNNs) have played a significant role in advancing the state-of-the-art in various vision-based action recognition systems. Recently, the introduction of residual connections in conjunction with a more traditional CNN model in a single architecture called Residual Network (ResNet) has shown impressive performance and great potential for image recognition tasks. In this paper, we investigate and apply deep ResNets for human action recognition using skeletal data provided by depth sensors. Firstly, the 3D coordinates of the human body joints carried in skeleton sequences are transformed into image-based representations and stored as RGB images. These color images are able to capture the spatial-temporal evolutions of 3D motions from skeleton sequences and can be efficiently learned by D-CNNs. We then propose a novel deep learning architecture based on ResNets to learn features from obtained color-based representations and classify them into action classes. The proposed method is evaluated on three challenging benchmark datasets including MSR Action 3D, KARD, and NTU-RGB+D datasets. Experimental results demonstrate that our method achieves state-of-the-art performance for all these benchmarks whilst requiring less computation resource. In particular, the proposed method surpasses previous approaches by a significant margin of 3.4% on MSR Action 3D dataset, 0.67% on KARD dataset, and 2.5% on NTU-RGB+D dataset.

##### Abstract (translated by Google)
计算机视觉社区目前正致力于解决真实视频中的动作识别问题，其中包含成千上万具有诸多挑战的样本。在这个过程中，深度卷积神经网络（D-CNN）在推进各种基于视觉的动作识别系统的最新技术方面发挥了重要作用。最近，在称为残余网络（ResNet）的单一架构中引入残留连接以及更传统的CNN模型，已经显示出令人印象深刻的性能以及图像识别任务的巨大潜力。在本文中，我们使用深度传感器提供的骨架数据研究并应用深度ResNets进行人体动作识别。首先，将骨架序列中携带的人体关节的三维坐标转换为基于图像的表示并存储为RGB图像。这些彩色图像能够从骨架序列中捕捉3D运动的时空演变，并且可以通过D-CNN有效地学习。然后，我们提出了一种基于ResNets的新型深度学习体系结构，以从获得的基于颜色的表示中学习特征并将它们分类为动作类。所提出的方法在三个具有挑战性的基准数据集上评估，包括MSR动作3D，KARD和NTU-RGB + D数据集。实验结果表明，我们的方法实现了所有这些基准的最新性能，同时需要较少的计算资源。特别是，所提出的方法在MSR动作三维数据集上占3.4％的显着优势，在KARD数据集上占0.67％，在NTU-RGB + D数据集上占2.5％。

##### URL
[http://arxiv.org/abs/1803.07781](http://arxiv.org/abs/1803.07781)

##### PDF
[http://arxiv.org/pdf/1803.07781](http://arxiv.org/pdf/1803.07781)

