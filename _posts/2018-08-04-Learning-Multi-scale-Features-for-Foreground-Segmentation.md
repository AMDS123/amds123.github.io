---
layout: post
title: "Learning Multi-scale Features for Foreground Segmentation"
date: 2018-08-04 12:55:25
categories: arXiv_CV
tags: arXiv_CV Segmentation
author: Long Ang Lim, Hacer Yalim Keles
mathjax: true
---

* content
{:toc}

##### Abstract
Foreground segmentation algorithms aim segmenting moving objects from the background in a robust way under various challenging scenarios. Encoder-decoder type deep neural networks that are used in this domain recently perform impressive segmentation results. In this work, we propose a novel robust encoder-decoder structure neural network that can be trained end-to-end using only a few training examples. The proposed method extends the Feature Pooling Module (FPM) of FgSegNet by introducing features fusions inside this module, which is capable of extracting multi-scale features within images; resulting in a robust feature pooling against camera motion, which can alleviate the need of multi-scale inputs to the network. Our method outperforms all existing state-of-the-art methods in CDnet2014 dataset by an average overall F-Measure of 0.9847. We also evaluate the effectiveness of our method on SBI2015 and UCSD Background Subtraction datasets. The source code of the proposed method is made available at this https URL .

##### Abstract (translated by Google)
前景分割算法的目标是在各种具有挑战性的场景下以稳健的方式从背景中分割移动物体。最近在该领域中使用的编码器 - 解码器型深度神经网络执行令人印象深刻的分割结果。在这项工作中，我们提出了一种新颖的鲁棒编码器 - 解码器结构神经网络，只需几个训练样例即可进行端到端训练。该方法通过引入该模块内部的特征融合，扩展了FgSegNet的特征池模块（FPM），能够提取图像内的多尺度特征;从而产生针对相机运动的强大特征池，这可以减轻对网络的多尺度输入的需要。我们的方法优于CDnet2014数据集中所有现有的最先进方法，平均整体F-Measure为0.9847。我们还评估了我们的方法对SBI2015和UCSD背景扣除数据集的有效性。此https URL提供了所提方法的源代码。

##### URL
[https://arxiv.org/abs/1808.01477](https://arxiv.org/abs/1808.01477)

##### PDF
[https://arxiv.org/pdf/1808.01477](https://arxiv.org/pdf/1808.01477)

