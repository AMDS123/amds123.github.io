---
layout: post
title: "Using Pre-Training Can Improve Model Robustness and Uncertainty"
date: 2019-01-28 19:37:07
categories: arXiv_CV
tags: arXiv_CV Adversarial Classification Detection
author: Dan Hendrycks, Kimin Lee, Mantas Mazeika
mathjax: true
---

* content
{:toc}

##### Abstract
Tuning a pre-trained network is commonly thought to improve data efficiency. However, Kaiming He et al. have called into question the utility of pre-training by showing that training from scratch can often yield similar performance, should the model train long enough. We show that although pre-training may not improve performance on traditional classification metrics, it does provide large benefits to model robustness and uncertainty. Through extensive experiments on label corruption, class imbalance, adversarial examples, out-of-distribution detection, and confidence calibration, we demonstrate large gains from pre-training and complementary effects with task-specific methods. We show approximately a 30% relative improvement in label noise robustness and a 10% absolute improvement in adversarial robustness on CIFAR-10 and CIFAR-100. In some cases, using pre-training without task-specific methods surpasses the state-of-the-art, highlighting the importance of using pre-training when evaluating future methods on robustness and uncertainty tasks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1901.09960](http://arxiv.org/abs/1901.09960)

##### PDF
[http://arxiv.org/pdf/1901.09960](http://arxiv.org/pdf/1901.09960)

