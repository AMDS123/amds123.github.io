---
layout: post
title: "Behavior Analysis of NLI Models: Uncovering the Influence of Three Factors on Robustness"
date: 2018-05-11 00:43:59
categories: arXiv_AI
tags: arXiv_AI Attention Inference Relation
author: Vicente Ivan Sanchez Carmona, Jeff Mitchell, Sebastian Riedel
mathjax: true
---

* content
{:toc}

##### Abstract
Natural Language Inference is a challenging task that has received substantial attention, and state-of-the-art models now achieve impressive test set performance in the form of accuracy scores. Here, we go beyond this single evaluation metric to examine robustness to semantically-valid alterations to the input data. We identify three factors - insensitivity, polarity and unseen pairs - and compare their impact on three SNLI models under a variety of conditions. Our results demonstrate a number of strengths and weaknesses in the models' ability to generalise to new in-domain instances. In particular, while strong performance is possible on unseen hypernyms, unseen antonyms are more challenging for all the models. More generally, the models suffer from an insensitivity to certain small but semantically significant alterations, and are also often influenced by simple statistical correlations between words and training labels. Overall, we show that evaluations of NLI models can benefit from studying the influence of factors intrinsic to the models or found in the dataset used.

##### Abstract (translated by Google)
自然语言推理是一项具有挑战性的任务，已经获得了大量的关注，最新的模型现在以准确性分数的形式实现了令人印象深刻的测试集性能。在这里，我们超越了这个单一的评估指标来检查输入数据在语义上有效的改变的鲁棒性。我们确定了三个因素 - 不敏感性，极性和看不见的配对 - 并比较它们在各种条件下对三种SNLI模型的影响。我们的结果证明了模型推广到新的域内实例的能力方面的一些优缺点。特别是，虽然在看不见的上位词上可能有强大的表现，但对于所有模型来说，看不见的反义词更具挑战性。更一般地说，模型对某些小的但语义上显着的变化不敏感，并且还经常受到单词和训练标签之间的简单统计相关性的影响。总的来说，我们表明NLI模型的评估可以从研究模型固有因素的影响或在所使用的数据集中发现而受益。

##### URL
[http://arxiv.org/abs/1805.04212](http://arxiv.org/abs/1805.04212)

##### PDF
[http://arxiv.org/pdf/1805.04212](http://arxiv.org/pdf/1805.04212)

