---
layout: post
title: "Scene-centric Joint Parsing of Cross-view Videos"
date: 2017-11-21 23:01:01
categories: arXiv_CV
tags: arXiv_CV Video_Caption Knowledge Prediction Quantitative Relation
author: Hang Qi, Yuanlu Xu, Tao Yuan, Tianfu Wu, Song-Chun Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
Cross-view video understanding is an important yet under-explored area in computer vision. In this paper, we introduce a joint parsing framework that integrates view-centric proposals into scene-centric parse graphs that represent a coherent scene-centric understanding of cross-view scenes. Our key observations are that overlapping fields of views embed rich appearance and geometry correlations and that knowledge fragments corresponding to individual vision tasks are governed by consistency constraints available in commonsense knowledge. The proposed joint parsing framework represents such correlations and constraints explicitly and generates semantic scene-centric parse graphs. Quantitative experiments show that scene-centric predictions in the parse graph outperform view-centric predictions.

##### Abstract (translated by Google)
跨视点视频理解是计算机视觉领域中一个尚未被充分研究的重要领域。在本文中，我们介绍一个联合解析框架，将以视图为中心的提议集成到以场景为中心的解析图中，这些解析图代表了以交叉视图场景为中心的一致理解。我们的主要观察结果是重叠的视野嵌入了丰富的外观和几何关系，并且与个人视觉任务相对应的知识片段由常识知识中可用的一致性约束来管理。所提出的联合解析框架明确地表示了这种相关性和约束，并生成了以语义为中心的语义分析图。定量实验表明，解析图中以场景为中心的预测优于以视图为中心的预测。

##### URL
[https://arxiv.org/abs/1709.05436](https://arxiv.org/abs/1709.05436)

##### PDF
[https://arxiv.org/pdf/1709.05436](https://arxiv.org/pdf/1709.05436)

