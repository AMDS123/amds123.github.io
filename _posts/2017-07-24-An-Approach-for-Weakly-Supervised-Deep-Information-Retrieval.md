---
layout: post
title: "An Approach for Weakly-Supervised Deep Information Retrieval"
date: 2017-07-24 12:05:43
categories: arXiv_CL
tags: arXiv_CL
author: Sean MacAvaney, Kai Hui, Andrew Yates
mathjax: true
---

* content
{:toc}

##### Abstract
Recent developments in neural information retrieval models have been promising, but a problem remains: human relevance judgments are expensive to produce, while neural models require a considerable amount of training data. In an attempt to fill this gap, we present an approach that---given a weak training set of pseudo-queries, documents, relevance information---filters the data to produce effective positive and negative query-document pairs. This allows large corpora to be used as neural IR model training data, while eliminating training examples that do not transfer well to relevance scoring. The filters include unsupervised ranking heuristics and a novel measure of interaction similarity. We evaluate our approach using a news corpus with article headlines acting as pseudo-queries and article content as documents, with implicit relevance between an article's headline and its content. By using our approach to train state-of-the-art neural IR models and comparing to established baselines, we find that training data generated by our approach can lead to good results on a benchmark test collection.

##### Abstract (translated by Google)
神经信息检索模型的最新发展一直很有希望，但仍然存在一个问题：人的相关性判断花费昂贵，而神经模型需要大量的训练数据。为了填补这一空白，我们提出了一种方法---给定一个伪查询，文档，相关性信息的弱训练集---过滤数据以产生有效的正面和负面的查询 - 文档对。这允许大型语料库被用作神经IR模型训练数据，同时消除不能很好地转移到相关性评分的训练样例。这些过滤器包括无监督的排序启发式和相互作用相似性的新颖度量。我们使用新闻语料库来评估我们的方法，新闻语料将文章标题作为伪查询和文章内容作为文档，文章的标题和内容之间隐含相关性。通过使用我们的方法来训练最先进的神经红外模型并比较已建立的基线，我们发现通过我们的方法生成的训练数据可以在基准测试集合上产生良好的结果。

##### URL
[https://arxiv.org/abs/1707.00189](https://arxiv.org/abs/1707.00189)

##### PDF
[https://arxiv.org/pdf/1707.00189](https://arxiv.org/pdf/1707.00189)

