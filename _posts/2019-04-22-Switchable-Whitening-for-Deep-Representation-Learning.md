---
layout: post
title: "Switchable Whitening for Deep Representation Learning"
date: 2019-04-22 06:22:55
categories: arXiv_CV
tags: arXiv_CV Segmentation Style_Transfer CNN Image_Classification Semantic_Segmentation Represenation_Learning Classification
author: Xingang Pan, Xiaohang Zhan, Jianping Shi, Xiaoou Tang, Ping Luo
mathjax: true
---

* content
{:toc}

##### Abstract
Normalization methods are essential components in convolutional neural networks (CNNs). They either standardize or whiten data using statistics estimated in predefined sets of pixels. Unlike existing works that design normalization techniques for specific tasks, we propose Switchable Whitening (SW), which provides a general form unifying different whitening methods as well as standardization methods. SW learns to switch among these operations in an end-to-end manner. It has several advantages. First, SW adaptively selects appropriate whitening or standardization statistics for different tasks (see Fig.1), making it well suited for a wide range of tasks without manual design. Second, by integrating benefits of different normalizers, SW shows consistent improvements over its counterparts in various challenging benchmarks. Third, SW serves as a useful tool for understanding the characteristics of whitening and standardization techniques. We show that SW outperforms other alternatives on image classification (CIFAR-10/100, ImageNet), semantic segmentation (ADE20K, Cityscapes), domain adaptation (GTA5, Cityscapes), and image style transfer (COCO). For example, without bells and whistles, we achieve state-of-the-art performance with 45.33% mIoU on the ADE20K dataset. Code and models will be released.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.09739](http://arxiv.org/abs/1904.09739)

##### PDF
[http://arxiv.org/pdf/1904.09739](http://arxiv.org/pdf/1904.09739)

