---
layout: post
title: "Learning Deep Representations of Fine-grained Visual Descriptions"
date: 2016-05-17 23:08:46
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Salient Face Embedding Inference Classification Language_Model Recognition
author: Scott Reed, Zeynep Akata, Bernt Schiele, Honglak Lee
mathjax: true
---

* content
{:toc}

##### Abstract
State-of-the-art methods for zero-shot visual recognition formulate learning as a joint embedding problem of images and side information. In these formulations the current best complement to visual features are attributes: manually encoded vectors describing shared characteristics among categories. Despite good performance, attributes have limitations: (1) finer-grained recognition requires commensurately more attributes, and (2) attributes do not provide a natural language interface. We propose to overcome these limitations by training neural language models from scratch; i.e. without pre-training and only consuming words and characters. Our proposed models train end-to-end to align with the fine-grained and category-specific content of images. Natural language provides a flexible and compact way of encoding only the salient visual aspects for distinguishing categories. By training on raw text, our model can do inference on raw text as well, providing humans a familiar mode both for annotation and retrieval. Our model achieves strong performance on zero-shot text-based image retrieval and significantly outperforms the attribute-based state-of-the-art for zero-shot classification on the Caltech UCSD Birds 200-2011 dataset.

##### Abstract (translated by Google)
用于零镜头视觉识别的最新方法将学习视为图像和辅助信息的联合嵌入问题。在这些配方中，视觉特征的当前最佳补充是属性：描述类别之间的共享特征的手动编码向量。尽管性能良好，属性也有其局限性：（1）细粒度识别需要相当多的属性，（2）属性不提供自然语言接口。我们建议通过从头开始训练神经语言模型来克服这些限制;即没有预训练和只消耗文字和字符。我们提出的模型训练端到端与细粒度和类别特定的图像内容相一致。自然语言提供了一种灵活而紧凑的方式来编码区分类别的显着视觉方面。通过对原始文本进行训练，我们的模型也可以对原始文本进行推理，为人类提供一种熟悉的模式，用于注释和检索。我们的模型在基于零点文本的图像检索方面实现了强大的性能，并且在加州理工学院UCSD Birds 200-2011数据集上的零点分类方面明显优于基于属性的最新技术。

##### URL
[https://arxiv.org/abs/1605.05395](https://arxiv.org/abs/1605.05395)

##### PDF
[https://arxiv.org/pdf/1605.05395](https://arxiv.org/pdf/1605.05395)

