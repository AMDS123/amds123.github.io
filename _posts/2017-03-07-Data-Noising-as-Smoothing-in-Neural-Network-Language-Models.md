---
layout: post
title: "Data Noising as Smoothing in Neural Network Language Models"
date: 2017-03-07 19:56:26
categories: arXiv_SD
tags: arXiv_SD Language_Model Relation
author: Ziang Xie, Sida I. Wang, Jiwei Li, Daniel Lévy, Aiming Nie, Dan Jurafsky, Andrew Y. Ng
mathjax: true
---

* content
{:toc}

##### Abstract
Data noising is an effective technique for regularizing neural network models. While noising is widely adopted in application domains such as vision and speech, commonly used noising primitives have not been developed for discrete sequence-level settings such as language modeling. In this paper, we derive a connection between input noising in neural network language models and smoothing in $n$-gram models. Using this connection, we draw upon ideas from smoothing to develop effective noising schemes. We demonstrate performance gains when applying the proposed schemes to language modeling and machine translation. Finally, we provide empirical analysis validating the relationship between noising and smoothing.

##### Abstract (translated by Google)
数据噪声是规范神经网络模型的有效技术。虽然噪声在视觉和语音等应用领域被广泛采用，但是对于离散的序列级设置，如语言建模，还没有开发出常用的噪声基元。在本文中，我们推导了神经网络语言模型中的输入噪声与$ n $ -gram模型的平滑之间的联系。利用这个联系，我们借鉴平滑的想法来制定有效的噪音计划。我们演示性能提升时应用提出的方案语言建模和机器翻译。最后，通过实证分析验证了噪声与平滑的关系。

##### URL
[https://arxiv.org/abs/1703.02573](https://arxiv.org/abs/1703.02573)

##### PDF
[https://arxiv.org/pdf/1703.02573](https://arxiv.org/pdf/1703.02573)

