---
layout: post
title: "Adaptive Mechanism Design: Learning to Promote Cooperation"
date: 2018-06-11 15:48:37
categories: arXiv_AI
tags: arXiv_AI
author: Tobias Baumann, Thore Graepel, John Shawe-Taylor
mathjax: true
---

* content
{:toc}

##### Abstract
In the future, artificial learning agents are likely to become increasingly widespread in our society. They will interact with both other learning agents and humans in a variety of complex settings including social dilemmas. We consider the problem of how an external agent can promote cooperation between artificial learners by distributing additional rewards and punishments based on observing the learners' actions. We propose a rule for automatically learning how to create right incentives by considering the players' anticipated parameter updates. Using this learning rule leads to cooperation with high social welfare in matrix games in which the agents would otherwise learn to defect with high probability. We show that the resulting cooperative outcome is stable in certain games even if the planning agent is turned off after a given number of episodes, while other games require ongoing intervention to maintain mutual cooperation. However, even in the latter case, the amount of necessary additional incentives decreases over time.

##### Abstract (translated by Google)
将来，人工学习代理可能会在我们的社会中变得越来越普遍。他们将与其他学习机构和人类在包括社交困境在内的各种复杂环境中进行互动。我们考虑外部代理人如何通过在观察学习者的行为的基础上分发额外的奖励和惩罚来促进人造学习者之间的合作。我们提出一个规则，通过考虑玩家预期的参数更新来自动学习如何创造正确的激励。使用这个学习规则导致与矩阵游戏中的高社会福利的合作，其中代理将以其他方式学习以高概率瑕疵学习。我们表明，即使规划代理人在给定数量的剧集关闭后，由此产生的合作结果在某些游戏中也是稳定的，而其他游戏则需要持续干预以保持相互合作。但是，即使在后一种情况下，必要的额外激励措施的数量也随着时间的推移而减少

##### URL
[http://arxiv.org/abs/1806.04067](http://arxiv.org/abs/1806.04067)

##### PDF
[http://arxiv.org/pdf/1806.04067](http://arxiv.org/pdf/1806.04067)

