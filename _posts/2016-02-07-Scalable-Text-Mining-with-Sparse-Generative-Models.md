---
layout: post
title: "Scalable Text Mining with Sparse Generative Models"
date: 2016-02-07 02:49:27
categories: arXiv_SD
tags: arXiv_SD Sparse Face Text_Classification Inference Classification
author: Antti Puurula
mathjax: true
---

* content
{:toc}

##### Abstract
The information age has brought a deluge of data. Much of this is in text form, insurmountable in scope for humans and incomprehensible in structure for computers. Text mining is an expanding field of research that seeks to utilize the information contained in vast document collections. General data mining methods based on machine learning face challenges with the scale of text data, posing a need for scalable text mining methods. This thesis proposes a solution to scalable text mining: generative models combined with sparse computation. A unifying formalization for generative text models is defined, bringing together research traditions that have used formally equivalent models, but ignored parallel developments. This framework allows the use of methods developed in different processing tasks such as retrieval and classification, yielding effective solutions across different text mining tasks. Sparse computation using inverted indices is proposed for inference on probabilistic models. This reduces the computational complexity of the common text mining operations according to sparsity, yielding probabilistic models with the scalability of modern search engines. The proposed combination provides sparse generative models: a solution for text mining that is general, effective, and scalable. Extensive experimentation on text classification and ranked retrieval datasets are conducted, showing that the proposed solution matches or outperforms the leading task-specific methods in effectiveness, with a order of magnitude decrease in classification times for Wikipedia article categorization with a million classes. The developed methods were further applied in two 2014 Kaggle data mining prize competitions with over a hundred competing teams, earning first and second places.

##### Abstract (translated by Google)
信息时代带来了大量的数据。其中大部分是文本形式的，对于人类来说是不可逾越的，在计算机的结构中是不可理解的。文本挖掘是一个不断扩大的研究领域，旨在利用大量文档集合中包含的信息。基于机器学习的通用数据挖掘方法面临着文本数据规模的挑战，因此需要可扩展的文本挖掘方法。本文提出了一个可扩展的文本挖掘的解决方案：生成模型结合稀疏计算。定义生成文本模型的统一形式化，汇集了使用正式等效模型的研究传统，但忽略了平行发展。这个框架允许使用在不同的处理任务（如检索和分类）中开发的方法，在不同的文本挖掘任务中产生有效的解决方案。提出了利用倒数索引的稀疏计算方法对概率模型进行推理。这可以根据稀疏度降低常见文本挖掘操作的计算复杂度，从而产生具有现代搜索引擎可伸缩性的概率模型。所提出的组合提供了稀疏的生成模型：用于文本挖掘的通用，有效和可扩展的解决方案。对文本分类和排名检索数据集进行了广泛的实验，表明所提出的解决方案匹配或优于有效的主要任务特定方法，在百万个类别的维基百科文章分类中，分类时间减少了一个数量级。所开发的方法进一步在2014年两届Kaggle数据挖掘大赛中得到应用，上百个参赛队伍获得一，二等奖。

##### URL
[https://arxiv.org/abs/1602.02332](https://arxiv.org/abs/1602.02332)

##### PDF
[https://arxiv.org/pdf/1602.02332](https://arxiv.org/pdf/1602.02332)

