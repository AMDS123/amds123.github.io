---
layout: post
title: "Adversarial Attack Type I: Generating False Positives"
date: 2018-09-03 13:25:06
categories: arXiv_AI
tags: arXiv_AI Adversarial
author: Sanli Tang, Xiaolin Huang, Mingjian Chen, Jie Yang
mathjax: true
---

* content
{:toc}

##### Abstract
False positive and false negative rates are equally important for evaluating the performance of a classifier. Adversarial examples by increasing false negative rate have been studied in recent years. However, harming a classifier by increasing false positive rate is almost blank, since it is much more difficult to generate a new and meaningful positive than the negative. To generate false positives, a supervised generative framework is proposed in this paper. Experiment results show that our method is practical and effective to generate those adversarial examples on large-scale image datasets.

##### Abstract (translated by Google)
假阳性和假阴性率对于评估分类器的性能同样重要。近年来已经研究了通过增加假阴性率的对抗性实例。然而，通过增加误报率来伤害分类器几乎是空白的，因为产生新的和有意义的正面比负面更难。为了产生误报，本文提出了一种监督的生成框架。实验结果表明，我们的方法在大规模图像数据集上生成那些对抗性实例是切实可行的。

##### URL
[http://arxiv.org/abs/1809.00594](http://arxiv.org/abs/1809.00594)

##### PDF
[http://arxiv.org/pdf/1809.00594](http://arxiv.org/pdf/1809.00594)

