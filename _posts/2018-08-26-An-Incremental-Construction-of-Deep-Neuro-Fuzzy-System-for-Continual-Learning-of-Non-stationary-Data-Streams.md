---
layout: post
title: "An Incremental Construction of Deep Neuro Fuzzy System for Continual Learning of Non-stationary Data Streams"
date: 2018-08-26 08:10:13
categories: arXiv_AI
tags: arXiv_AI GAN Classification Detection
author: Mahardhika Pratama, Witold Pedrycz, Geoffrey I. Webb
mathjax: true
---

* content
{:toc}

##### Abstract
Existing fuzzy neural networks (FNNs) are mostly developed under a shallow network configuration having lower generalization power than those of deep structures. This paper proposes a novel self-organizing deep fuzzy neural network, namely deep evolving fuzzy neural networks (DEVFNN). Fuzzy rules can be automatically extracted from data streams or removed if they play little role during their lifespan. The structure of the network can be deepened on demand by stacking additional layers using a drift detection method which not only detects the covariate drift, variations of input space, but also accurately identifies the real drift, dynamic changes of both feature space and target space. DEVFNN is developed under the stacked generalization principle via the feature augmentation concept where a recently developed algorithm, namely Generic Classifier (gClass), drives the hidden layer. It is equipped by an automatic feature selection method which controls activation and deactivation of input attributes to induce varying subsets of input features. A deep network simplification procedure is put forward using the concept of hidden layer merging to prevent uncontrollable growth of input space dimension due to the nature of feature augmentation approach in building a deep network structure. DEVFNN works in the sample-wise fashion and is compatible for data stream applications. The efficacy of DEVFNN has been thoroughly evaluated using six datasets with non-stationary properties under the prequential test-then-train protocol. It has been compared with four state-of the art data stream methods and its shallow counterpart where DEVFNN demonstrates improvement of classification accuracy.

##### Abstract (translated by Google)
现有的模糊神经网络（FNN）主要是在浅网络配置下开发的，其具有比深结构更低的泛化能力。本文提出了一种新的自组织深度模糊神经网络，即深度进化模糊神经网络（DEVFNN）。模糊规则可以从数据流中自动提取，或者如果它们在生命周期中起不到作用，则可以删除。通过使用漂移检测方法堆叠附加层可以根据需要加深网络结构，该漂移检测方法不仅检测协变量漂移，输入空间的变化，而且还准确地识别特征空间和目标空间的实际漂移，动态变化。 DEVFNN是通过特征增强概念在堆叠泛化原理下开发的，其中最近开发的算法，即通用分类器（gClass），驱动隐藏层。它配备了自动特征选择方法，该方法控制输入属性的激活和停用，以引起输入特征的变化子集。利用隐层融合的概念，提出了深度网络简化过程，以防止由于特征增强方法在构建深层网络结构时的性质而导致输入空间维度的不可控增长。 DEVFNN以样本方式工作，并且兼容数据流应用程序。在前序测试 - 然后 - 训练方案下，使用具有非平稳特性的六个数据集彻底评估了DEVFNN的功效。它已经与四种最先进的数据流方法及其浅层对应物进行了比较，其中DEVFNN证明了分类精度的提高。

##### URL
[http://arxiv.org/abs/1808.08517](http://arxiv.org/abs/1808.08517)

##### PDF
[http://arxiv.org/pdf/1808.08517](http://arxiv.org/pdf/1808.08517)

