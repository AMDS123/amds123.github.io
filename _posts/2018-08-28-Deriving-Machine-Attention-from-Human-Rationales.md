---
layout: post
title: "Deriving Machine Attention from Human Rationales"
date: 2018-08-28 15:38:41
categories: arXiv_CL
tags: arXiv_CL Attention
author: Yujia Bao, Shiyu Chang, Mo Yu, Regina Barzilay
mathjax: true
---

* content
{:toc}

##### Abstract
Attention-based models are successful when trained on large amounts of data. In this paper, we demonstrate that even in the low-resource scenario, attention can be learned effectively. To this end, we start with discrete human-annotated rationales and map them into continuous attention. Our central hypothesis is that this mapping is general across domains, and thus can be transferred from resource-rich domains to low-resource ones. Our model jointly learns a domain-invariant representation and induces the desired mapping between rationales and attention. Our empirical results validate this hypothesis and show that our approach delivers significant gains over state-of-the-art baselines, yielding over 15% average error reduction on benchmark datasets.

##### Abstract (translated by Google)
在对大量数据进行培训时，基于注意力的模型是成功的。在本文中，我们证明即使在资源匮乏的情况下，也可以有效地学习注意力。为此，我们从离散的人工注释理论开始，并将它们映射到持续的注意力。我们的中心假设是这种映射在域之间是通用的，因此可以从资源丰富的域转移到低资源域。我们的模型共同学习了一个领域不变的表示，并在理论和注意之间产生了理想的映射。我们的实证结果验证了这一假设，并表明我们的方法比最先进的基线提供了显着的收益，对基准数据集的平均误差降低了15％以上。

##### URL
[http://arxiv.org/abs/1808.09367](http://arxiv.org/abs/1808.09367)

##### PDF
[http://arxiv.org/pdf/1808.09367](http://arxiv.org/pdf/1808.09367)

