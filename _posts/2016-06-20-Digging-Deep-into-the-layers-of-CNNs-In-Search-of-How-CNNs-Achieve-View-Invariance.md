---
layout: post
title: "Digging Deep into the layers of CNNs: In Search of How CNNs Achieve View Invariance"
date: 2016-06-20 10:05:15
categories: arXiv_CV
tags: arXiv_CV CNN
author: Amr Bakry, Mohamed Elhoseiny, Tarek El-Gaaly, Ahmed Elgammal
mathjax: true
---

* content
{:toc}

##### Abstract
This paper is focused on studying the view-manifold structure in the feature spaces implied by the different layers of Convolutional Neural Networks (CNN). There are several questions that this paper aims to answer: Does the learned CNN representation achieve viewpoint invariance? How does it achieve viewpoint invariance? Is it achieved by collapsing the view manifolds, or separating them while preserving them? At which layer is view invariance achieved? How can the structure of the view manifold at each layer of a deep convolutional neural network be quantified experimentally? How does fine-tuning of a pre-trained CNN on a multi-view dataset affect the representation at each layer of the network? In order to answer these questions we propose a methodology to quantify the deformation and degeneracy of view manifolds in CNN layers. We apply this methodology and report interesting results in this paper that answer the aforementioned questions.

##### Abstract (translated by Google)
本文重点研究了卷积神经网络（CNN）不同层所蕴含的特征空间中的视图流形结构。本文旨在回答几个问题：学习的CNN表示是否实现了视点不变性？它如何实现视点不变性？它是通过折叠视图流形，还是将它们分离，同时保留它们来实现的？视图不变性是在哪一层实现的？深层卷积神经网络每层视点流形的结构怎样才能用实验方法进行量化？如何在多视图数据集上对预先训练的CNN进行微调，从而影响网络各层的表示？为了回答这些问题，我们提出了一种方法来量化CNN层中视图流形的变形和简并性。我们应用这种方法论，并在本文中报告有趣的结果，回答上述问题。

##### URL
[https://arxiv.org/abs/1508.01983](https://arxiv.org/abs/1508.01983)

##### PDF
[https://arxiv.org/pdf/1508.01983](https://arxiv.org/pdf/1508.01983)

