---
layout: post
title: "An efficient deep learning hashing neural network for mobile visual search"
date: 2017-10-21 04:37:23
categories: arXiv_CV
tags: arXiv_CV Deep_Learning Recognition
author: Heng Qi, Wu Liu, Liang Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Mobile visual search applications are emerging that enable users to sense their surroundings with smart phones. However, because of the particular challenges of mobile visual search, achieving a high recognition bitrate has becomes a consistent target of previous related works. In this paper, we propose a few-parameter, low-latency, and high-accuracy deep hashing approach for constructing binary hash codes for mobile visual search. First, we exploit the architecture of the MobileNet model, which significantly decreases the latency of deep feature extraction by reducing the number of model parameters while maintaining accuracy. Second, we add a hash-like layer into MobileNet to train the model on labeled mobile visual data. Evaluations show that the proposed system can exceed state-of-the-art accuracy performance in terms of the MAP. More importantly, the memory consumption is much less than that of other deep learning models. The proposed method requires only $13$ MB of memory for the neural network and achieves a MAP of $97.80\%$ on the mobile location recognition dataset used for testing.

##### Abstract (translated by Google)
移动视觉搜索应用正在兴起，使用户能够通过智能手机感知周围环境。然而，由于移动视觉搜索的特殊挑战，实现高识别率已经成为以往相关工作的一致目标。在本文中，我们提出了一种用于构建移动视觉搜索的二叉哈希码的几种参数，低时延和高精度的深度哈希方法。首先，我们利用MobileNet模型的体系结构，通过在保持精确性的同时减少模型参数的数量来显着减少深度特征提取的延迟。其次，我们在MobileNet中添加一个类似散列的图层，以标记移动视觉数据来训练模型。评估结果表明，所提出的系统在MAP方面可以超过最先进的精度性能。更重要的是，内存消耗远远低于其他深度学习模式。所提出的方法对于神经网络仅需要$ 13MB的存储器，并且在用于测试的移动位置识别数据集上实现$ 97.80 \％$的MAP。

##### URL
[https://arxiv.org/abs/1710.07750](https://arxiv.org/abs/1710.07750)

##### PDF
[https://arxiv.org/pdf/1710.07750](https://arxiv.org/pdf/1710.07750)

