---
layout: post
title: "Neural Character-based Composition Models for Abuse Detection"
date: 2018-09-02 19:36:03
categories: arXiv_CL
tags: arXiv_CL Embedding RNN Detection
author: Pushkar Mishra, Helen Yannakoudakis, Ekaterina Shutova
mathjax: true
---

* content
{:toc}

##### Abstract
The advent of social media in recent years has fed into some highly undesirable phenomena such as proliferation of offensive language, hate speech, sexist remarks, etc. on the Internet. In light of this, there have been several efforts to automate the detection and moderation of such abusive content. However, deliberate obfuscation of words by users to evade detection poses a serious challenge to the effectiveness of these efforts. The current state of the art approaches to abusive language detection, based on recurrent neural networks, do not explicitly address this problem and resort to a generic OOV (out of vocabulary) embedding for unseen words. However, in using a single embedding for all unseen words we lose the ability to distinguish between obfuscated and non-obfuscated or rare words. In this paper, we address this problem by designing a model that can compose embeddings for unseen words. We experimentally demonstrate that our approach significantly advances the current state of the art in abuse detection on datasets from two different domains, namely Twitter and Wikipedia talk page.

##### Abstract (translated by Google)
近年来社交媒体的出现加剧了一些非常不受欢迎的现象，例如互联网上的冒犯性语言，仇恨言论，性别歧视言论等。鉴于此，已经进行了若干努力来自动检测和缓和这种滥用内容。然而，用户故意混淆用于逃避检测的词语对这些努力的有效性构成严重挑战。基于递归神经网络的当前现有技术的滥用语言检测方法没有明确地解决该问题并且采用针对看不见的单词的通用OOV（词汇表外）嵌入。然而，在对所有看不见的单词使用单个嵌入时，我们失去了区分混淆和非混淆或罕见单词的能力。在本文中，我们通过设计一个可以为看不见的单词组成嵌入的模型来解决这个问题。我们通过实验证明，我们的方法显着推进了来自两个不同领域（即Twitter和维基百科谈话页面）的数据集滥用检测的当前技术水平。

##### URL
[http://arxiv.org/abs/1809.00378](http://arxiv.org/abs/1809.00378)

##### PDF
[http://arxiv.org/pdf/1809.00378](http://arxiv.org/pdf/1809.00378)

