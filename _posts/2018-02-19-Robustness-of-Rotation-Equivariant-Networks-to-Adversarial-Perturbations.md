---
layout: post
title: "Robustness of Rotation-Equivariant Networks to Adversarial Perturbations"
date: 2018-02-19 13:49:15
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN Prediction
author: Beranger Dumont, Simona Maggio, Pablo Montalvo
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks have been shown to be vulnerable to adversarial examples: very small perturbations of the input having a dramatic impact on the predictions. A wealth of adversarial attacks and distance metrics to quantify the similarity between natural and adversarial images have been proposed, recently enlarging the scope of adversarial examples with geometric transformations beyond pixel-wise attacks. In this context, we investigate the robustness to adversarial attacks of new Convolutional Neural Network architectures providing equivariance to rotations. We found that rotation-equivariant networks are significantly less vulnerable to geometric-based attacks than regular networks on the MNIST, CIFAR-10, and ImageNet datasets.

##### Abstract (translated by Google)
已经证明深度神经网络容易受到对抗性例子的影响：输入的微小扰动对预测产生了巨大影响。已经提出了大量敌对攻击和距离度量来量化自然和敌对图像之间的相似性，最近通过几何变换扩大了对抗性示例的范围，而不是像素级攻击。在这种情况下，我们调查新的卷积神经网络架构的敌对攻击的鲁棒性，为旋转提供等价性。我们发现，与MNIST，CIFAR-10和ImageNet数据集上的常规网络相比，旋转等变网络对基于几何的攻击的脆弱性要小得多。

##### URL
[http://arxiv.org/abs/1802.06627](http://arxiv.org/abs/1802.06627)

##### PDF
[http://arxiv.org/pdf/1802.06627](http://arxiv.org/pdf/1802.06627)

