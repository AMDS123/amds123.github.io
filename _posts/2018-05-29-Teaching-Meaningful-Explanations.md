---
layout: post
title: "Teaching Meaningful Explanations"
date: 2018-05-29 18:35:44
categories: arXiv_AI
tags: arXiv_AI Knowledge Prediction
author: Noel C. F. Codella, Michael Hind, Karthikeyan Natesan Ramamurthy, Murray Campbell, Amit Dhurandhar, Kush R. Varshney, Dennis Wei, Aleksandra Mojsilovic
mathjax: true
---

* content
{:toc}

##### Abstract
The adoption of machine learning in high-stakes applications such as healthcare and law has lagged in part because predictions are not accompanied by explanations comprehensible to the domain user, who often holds ultimate responsibility for decisions and outcomes. In this paper, we propose an approach to generate such explanations in which training data is augmented to include, in addition to features and labels, explanations elicited from domain users. A joint model is then learned to produce both labels and explanations from the input features. This simple idea ensures that explanations are tailored to the complexity expectations and domain knowledge of the consumer. Evaluation spans multiple modeling techniques on a simple game dataset, an image dataset, and a chemical odor dataset, showing that our approach is generalizable across domains and algorithms. Results demonstrate that meaningful explanations can be reliably taught to machine learning algorithms, and in some cases, improve modeling accuracy.

##### Abstract (translated by Google)
在诸如医疗保健和法律等高风险应用中采用机器学习的情况有所滞后，部分原因是因为预测并未伴随域用户可以理解的解释，而域用户往往对决策和结果负最终责任。在本文中，我们提出了一种方法来产生这样的解释，其中增加了训练数据，除了特征和标签之外，还包括从域用户引出的解释。然后学习联合模型，从输入特征生成标签和解释。这个简单的想法确保解释是针对消费者的复杂性期望和领域知识量身定做的。评估跨越了简单的游戏数据集，图像数据集和化学气味数据集上的多种建模技术，显示出我们的方法可以跨领域和算法推广。结果表明有意义的解释可以可靠地教给机器学习算法，并且在某些情况下可以提高建模精度。

##### URL
[https://arxiv.org/abs/1805.11648](https://arxiv.org/abs/1805.11648)

##### PDF
[https://arxiv.org/pdf/1805.11648](https://arxiv.org/pdf/1805.11648)

