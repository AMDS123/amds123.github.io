---
layout: post
title: "Learning Multilingual Topics from Incomparable Corpus"
date: 2018-06-11 23:51:18
categories: arXiv_CL
tags: arXiv_CL Knowledge
author: Shudong Hao, Michael J. Paul
mathjax: true
---

* content
{:toc}

##### Abstract
Multilingual topic models enable crosslingual tasks by extracting consistent topics from multilingual corpora. Most models require parallel or comparable training corpora, which limits their ability to generalize. In this paper, we first demystify the knowledge transfer mechanism behind multilingual topic models by defining an alternative but equivalent formulation. Based on this analysis, we then relax the assumption of training data required by most existing models, creating a model that only requires a dictionary for training. Experiments show that our new method effectively learns coherent multilingual topics from partially and fully incomparable corpora with limited amounts of dictionary resources.

##### Abstract (translated by Google)
多语言主题模型通过从多语言语料库中提取一致的主题来实现跨语言任务。大多数模型需要平行或可比较的训练语料库，这限制了其推广能力。在本文中，我们首先通过定义一个替代但等同的表述来揭示多语言话题模型背后的知识转移机制。基于这一分析，我们放宽了大多数现有模型所需的训练数据的假设，创建了一个只需要用于训练的字典的模型。实验表明，我们的新方法有效地从部分和完全无法比较的语料库中学习连贯的多语言主题，并使用有限的字典资源。

##### URL
[http://arxiv.org/abs/1806.04270](http://arxiv.org/abs/1806.04270)

##### PDF
[http://arxiv.org/pdf/1806.04270](http://arxiv.org/pdf/1806.04270)

