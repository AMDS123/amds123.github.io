---
layout: post
title: "Generating Discriminative Object Proposals via Submodular Ranking"
date: 2016-02-11 00:50:17
categories: arXiv_CV
tags: arXiv_CV Segmentation Detection
author: Yangmuzi Zhang, Zhuolin Jiang, Xi Chen, Larry S. Davis
mathjax: true
---

* content
{:toc}

##### Abstract
A multi-scale greedy-based object proposal generation approach is presented. Based on the multi-scale nature of objects in images, our approach is built on top of a hierarchical segmentation. We first identify the representative and diverse exemplar clusters within each scale by using a diversity ranking algorithm. Object proposals are obtained by selecting a subset from the multi-scale segment pool via maximizing a submodular objective function, which consists of a weighted coverage term, a single-scale diversity term and a multi-scale reward term. The weighted coverage term forces the selected set of object proposals to be representative and compact; the single-scale diversity term encourages choosing segments from different exemplar clusters so that they will cover as many object patterns as possible; the multi-scale reward term encourages the selected proposals to be discriminative and selected from multiple layers generated by the hierarchical image segmentation. The experimental results on the Berkeley Segmentation Dataset and PASCAL VOC2012 segmentation dataset demonstrate the accuracy and efficiency of our object proposal model. Additionally, we validate our object proposals in simultaneous segmentation and detection and outperform the state-of-art performance.

##### Abstract (translated by Google)
提出了一种基于多尺度贪婪的对象提议生成方法。基于图像中物体的多尺度特性，我们的方法建立在分层分割之上。我们首先通过使用多样性排序算法来识别每个范围内的代表性和多样化的样本群集。对象建议是通过最大化子模块目标函数从多尺度分段池中选择一个子集获得的，该子模块包括加权覆盖项，单一尺度多样性项和多尺度奖励项。加权覆盖期限迫使选定的一组对象建议具有代表性和紧凑性;单一尺度的多样性术语鼓励从不同样本集群中选择分段，以便尽可能多地覆盖对象模式;多尺度奖励术语鼓励选择的提议是从分层图像分割产生的多层中进行区分和选择的。伯克利分割数据集和PASCAL VOC2012分割数据集的实验结果证明了我们的对象建议模型的准确性和有效性。此外，我们验证我们的对象建议在同时分割和检测，并超越最先进的性能。

##### URL
[https://arxiv.org/abs/1602.03585](https://arxiv.org/abs/1602.03585)

##### PDF
[https://arxiv.org/pdf/1602.03585](https://arxiv.org/pdf/1602.03585)

