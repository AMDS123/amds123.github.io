---
layout: post
title: "Qiniu Submission to ActivityNet Challenge 2018"
date: 2018-06-12 08:42:55
categories: arXiv_CV
tags: arXiv_CV Recognition
author: Xiaoteng Zhang, Yixin Bao, Feiyun Zhang, Kai Hu, Yicheng Wang, Liang Zhu, Qinzhu He, Yining Lin, Jie Shao, Yao Peng
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we introduce our submissions for the tasks of trimmed activity recognition (Kinetics) and trimmed event recognition (Moments in Time) for Activitynet Challenge 2018. In the two tasks, non-local neural networks and temporal segment networks are implemented as our base models. Multi-modal cues such as RGB image, optical flow and acoustic signal have also been used in our method. We also propose new non-local-based models for further improvement on the recognition accuracy. The final submissions after ensembling the models achieve 83.5% top-1 accuracy and 96.8% top-5 accuracy on the Kinetics validation set, 35.81% top-1 accuracy and 62.59% top-5 accuracy on the MIT validation set.

##### Abstract (translated by Google)
在本文中，我们介绍了我们提交的关于修剪活动识别（动力学）和修剪事件识别（时间矩）的任务2018年的活动网络挑战。在这两个任务中，非局部神经网络和时间段网络实现为我们的基础模型。多模式线索，如RGB图像，光流和声学信号也被用于我们的方法。我们还提出了新的非局部模型来进一步提高识别的准确性。在整合模型后的最终意见书中，动力学验证集的前1精度达到83.5％，前测精度达到96.8％，麻省理工学院验证集的前5个精度达到35.81％，精度达到了前者的62.59％。

##### URL
[http://arxiv.org/abs/1806.04391](http://arxiv.org/abs/1806.04391)

##### PDF
[http://arxiv.org/pdf/1806.04391](http://arxiv.org/pdf/1806.04391)

