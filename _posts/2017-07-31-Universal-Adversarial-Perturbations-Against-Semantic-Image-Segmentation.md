---
layout: post
title: "Universal Adversarial Perturbations Against Semantic Image Segmentation"
date: 2017-07-31 18:55:54
categories: arXiv_CV
tags: arXiv_CV Adversarial Segmentation Image_Classification Classification Deep_Learning
author: Jan Hendrik Metzen, Mummadi Chaithanya Kumar, Thomas Brox, Volker Fischer
mathjax: true
---

* content
{:toc}

##### Abstract
While deep learning is remarkably successful on perceptual tasks, it was also shown to be vulnerable to adversarial perturbations of the input. These perturbations denote noise added to the input that was generated specifically to fool the system while being quasi-imperceptible for humans. More severely, there even exist universal perturbations that are input-agnostic but fool the network on the majority of inputs. While recent work has focused on image classification, this work proposes attacks against semantic image segmentation: we present an approach for generating (universal) adversarial perturbations that make the network yield a desired target segmentation as output. We show empirically that there exist barely perceptible universal noise patterns which result in nearly the same predicted segmentation for arbitrary inputs. Furthermore, we also show the existence of universal noise which removes a target class (e.g., all pedestrians) from the segmentation while leaving the segmentation mostly unchanged otherwise.

##### Abstract (translated by Google)
尽管深度学习在感知任务上是非常成功的，但它也显示出对输入的对抗性干扰。这些扰动表示添加到输入的噪声，它是专门为了欺骗系统而产生的，同时对人类来说是不可察觉的。更严重的是，甚至存在普遍的扰动，这些扰动是输入不可知的，但是欺骗大部分输入的网络。虽然最近的工作集中在图像分类上，但是这项工作提出了针对语义图像分割的攻击：我们提出了一种产生（通用）对抗性扰动的方法，使得网络产生期望的目标分割作为输出。我们经验地显示，存在几乎不可察觉的通用噪声模式，导致对于任意输入几乎相同的预测分割。此外，我们还展示了通用噪声的存在，其从分割中去除目标类别（例如，所有行人），否则大致保持不变。

##### URL
[https://arxiv.org/abs/1704.05712](https://arxiv.org/abs/1704.05712)

##### PDF
[https://arxiv.org/pdf/1704.05712](https://arxiv.org/pdf/1704.05712)

