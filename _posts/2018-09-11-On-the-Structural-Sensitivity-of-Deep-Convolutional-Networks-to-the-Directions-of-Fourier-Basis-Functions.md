---
layout: post
title: "On the Structural Sensitivity of Deep Convolutional Networks to the Directions of Fourier Basis Functions"
date: 2018-09-11 18:23:09
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN Prediction Recognition
author: Yusuke Tsuzuku, Issei Sato
mathjax: true
---

* content
{:toc}

##### Abstract
Data-agnostic quasi-imperceptible perturbations on inputs can severely degrade recognition accuracy of deep convolutional networks. This indicates some structural instability of their predictions and poses a potential security threat. However, characterization of the shared directions of such harmful perturbations remains unknown if they exist, which makes it difficult to address the security threat and performance degradation. Our primal finding is that convolutional networks are sensitive to the directions of Fourier basis functions. We derived the property by specializing a hypothesis of the cause of the sensitivity, known as the linearity of neural networks, to convolutional networks and empirically validated it. As a by-product of the analysis, we propose a fast algorithm to create shift-invariant universal adversarial perturbations available in black-box settings.

##### Abstract (translated by Google)
输入上的数据不可知的准不可察觉的扰动会严重降低深度卷积网络的识别准确度。这表明他们的预测存在一些结构性不稳定性，并构成潜在的安全威胁。然而，如果存在这种有害扰动的共享方向的表征仍然是未知的，这使得难以解决安全威胁和性能降级。我们的初步发现是卷积网络对傅立叶基函数的方向敏感。我们通过将灵敏度原因（称为神经网络的线性）的假设与卷积网络和经验验证它相结合来推导出该属性。作为分析的副产品，我们提出了一种快速算法，可以在黑盒设置中创建移位不变的通用对抗扰动。

##### URL
[http://arxiv.org/abs/1809.04098](http://arxiv.org/abs/1809.04098)

##### PDF
[http://arxiv.org/pdf/1809.04098](http://arxiv.org/pdf/1809.04098)

