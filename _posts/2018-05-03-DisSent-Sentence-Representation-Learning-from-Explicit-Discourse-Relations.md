---
layout: post
title: "DisSent: Sentence Representation Learning from Explicit Discourse Relations"
date: 2018-05-03 03:52:37
categories: arXiv_AI
tags: arXiv_AI Embedding Represenation_Learning Classification Relation
author: Allen Nie, Erin D. Bennett, Noah D. Goodman
mathjax: true
---

* content
{:toc}

##### Abstract
Sentence vectors represent an appealing approach to meaning: learn an embedding that encompasses the meaning of a sentence in a single vector, that can be used for a variety of semantic tasks. Existing models for learning sentence embeddings either require extensive computational resources to train on large corpora, or are trained on costly, manually curated datasets of sentence relations. We observe that humans naturally annotate the relations between their sentences with discourse markers like "but" and "because". These words are deeply linked to the meanings of the sentences they connect. Using this natural signal, we automatically collect a classification dataset from unannotated text. We evaluate our sentence embeddings on a variety of transfer tasks, including discourse-related tasks using Penn Discourse Treebank. We demonstrate that training a model to predict discourse markers yields high quality sentence embeddings.

##### Abstract (translated by Google)
句子向量代表了一种吸引人的意义方法：学习一个包含单个向量中句子含义的嵌入，它可以用于各种语义任务。用于学习句子嵌入的现有模型要么需要大量的计算资源来训练大型语料库，要么训练成本较高的手动策划的句子关系数据集。我们观察到，人类自然地用诸如“but”和“because”这样的话语标记来注释他们的句子之间的关系。这些词与他们连接的句子的含义有着深刻的联系。使用这种自然信号，我们会自动从未注释的文本中收集分类数据集。我们评估我们的句子嵌入在各种转移任务中，包括使用Penn Discourse Treebank的话语相关任务。我们证明，训练模型来预测话语标记可以产生高质量的句子嵌入。

##### URL
[http://arxiv.org/abs/1710.04334](http://arxiv.org/abs/1710.04334)

##### PDF
[http://arxiv.org/pdf/1710.04334](http://arxiv.org/pdf/1710.04334)

