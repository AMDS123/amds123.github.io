---
layout: post
title: "Enhanced Biologically Inspired Model for Image Recognition Based on a Novel Patch Selection Method with Moment"
date: 2017-10-27 15:04:45
categories: arXiv_CV
tags: arXiv_CV Attention Recognition
author: Yan-Feng Lu, Li-Hao Jia, Hong Qaio, Yi Li
mathjax: true
---

* content
{:toc}

##### Abstract
Biologically inspired model (BIM) for image recognition is a robust computational architecture, which has attracted widespread attention. BIM can be described as a four-layer structure based on the mechanisms of the visual cortex. Although the performance of BIM for image recognition is robust, it takes the randomly selected ways for the patch selection, which is sightless, and results in heavy computing burden. To address this issue, we propose a novel patch selection method with oriented Gaussian-Hermite moment (PSGHM), and we enhanced the BIM based on the proposed PSGHM, named as PBIM. In contrast to the conventional BIM which adopts the random method to select patches within the feature representation layers processed by multi-scale Gabor filter banks, the proposed PBIM takes the PSGHM way to extract a small number of representation features while offering promising distinctiveness. To show the effectiveness of the proposed PBIM, experimental studies on object categorization are conducted on the CalTech05, TU Darmstadt (TUD), and GRAZ01 databases. Experimental results demonstrate that the performance of PBIM is a significant improvement on that of the conventional BIM.

##### Abstract (translated by Google)
生物启发模型（BIM）图像识别是一个强大的计算架构，已引起广泛关注。 BIM可以被描述为基于视觉皮层机制的四层结构。虽然BIM对于图像识别的性能很强大，但是随机选择的方式对于斑块选择是不可见的，并导致沉重的计算负担。为解决这个问题，我们提出了一种新的面向高斯 - 埃米特矩（PSGHM）的块选择方法，并在此基础上对所提出的PSGHM进行了改进，命名为PBIM。与传统的采用随机方法选择多尺度Gabor滤波器组的特征表示层中的块的BIM相反，所提出的PBIM采用PSGHM方法来提取少量的表示特征，同时提供了有前途的独特性。为了展示PBIM的有效性，在CalTech05，TU Darmstadt（TUD）和GRAZ01数据库上进行了目标分类的实验研究。实验结果表明PBIM的性能比传统的BIM有明显的提高。

##### URL
[https://arxiv.org/abs/1710.10188](https://arxiv.org/abs/1710.10188)

##### PDF
[https://arxiv.org/pdf/1710.10188](https://arxiv.org/pdf/1710.10188)

