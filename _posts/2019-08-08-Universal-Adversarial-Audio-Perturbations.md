---
layout: post
title: "Universal Adversarial Audio Perturbations"
date: 2019-08-08 17:07:30
categories: arXiv_SD
tags: arXiv_SD Adversarial Knowledge
author: Sajjad Abdoli, Luiz G. Hafemann, Jerome Rony, Ismail Ben Ayed, Patrick Cardinal, Alessandro L. Koerich
mathjax: true
---

* content
{:toc}

##### Abstract
We demonstrate the existence of universal adversarial perturbations, which can fool a family of audio processing architectures, for both targeted and untargeted attacks. To the best of our knowledge, this is the first study on generating universal adversarial perturbations for audio processing systems. We propose two methods for finding such perturbations. The first method is based on an iterative, greedy approach that is well-known in computer vision: it aggregates small perturbations to the input so as to push it to the decision boundary. The second method, which is the main technical contribution of this work, is a novel penalty formulation, which finds targeted and untargeted universal adversarial perturbations. Differently from the greedy approach, the penalty method minimizes an appropriate objective function on a batch of samples. Therefore, it produces more successful attacks when the number of training samples is limited. Moreover, we provide a proof that the proposed penalty method theoretically converges to a solution that corresponds to universal adversarial perturbations. We report comprehensive experiments, showing attack success rates higher than 91.1% and 74.7% for targeted and untargeted attacks, respectively.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.03173](http://arxiv.org/abs/1908.03173)

##### PDF
[http://arxiv.org/pdf/1908.03173](http://arxiv.org/pdf/1908.03173)

