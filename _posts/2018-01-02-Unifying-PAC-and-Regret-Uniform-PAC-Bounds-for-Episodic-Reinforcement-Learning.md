---
layout: post
title: "Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning"
date: 2018-01-02 13:25:46
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Christoph Dann, Tor Lattimore, Emma Brunskill
mathjax: true
---

* content
{:toc}

##### Abstract
Statistical performance bounds for reinforcement learning (RL) algorithms can be critical for high-stakes applications like healthcare. This paper introduces a new framework for theoretically measuring the performance of such algorithms called Uniform-PAC, which is a strengthening of the classical Probably Approximately Correct (PAC) framework. In contrast to the PAC framework, the uniform version may be used to derive high probability regret guarantees and so forms a bridge between the two setups that has been missing in the literature. We demonstrate the benefits of the new framework for finite-state episodic MDPs with a new algorithm that is Uniform-PAC and simultaneously achieves optimal regret and PAC guarantees except for a factor of the horizon.

##### Abstract (translated by Google)
强化学习（RL）算法的统计性能界限对于诸如医疗保健等高风险应用来说可能是至关重要的。本文介绍了一个理论上测量这种算法的性能的新框架，称为Uniform-PAC，它是对经典的可能近似正确（PAC）框架的强化。与PAC框架相比，统一版本可能被用来获得高概率的遗憾保证，因此形成了文献中缺失的两个设置之间的桥梁。我们展示了有限状态场景MDP的新框架的好处，使用Uniform-PAC的新算法，同时实现最佳遗憾和PAC保证，除了地平线的一个因素。

##### URL
[http://arxiv.org/abs/1703.07710](http://arxiv.org/abs/1703.07710)

##### PDF
[http://arxiv.org/pdf/1703.07710](http://arxiv.org/pdf/1703.07710)

