---
layout: post
title: "Image Compression: Sparse Coding vs. Bottleneck Autoencoders"
date: 2017-10-26 21:49:30
categories: arXiv_CV
tags: arXiv_CV Sparse Classification
author: Yijing Watkins, Mohammad Sayeh, Oleksandr Iaroshenko, Garrett Kenyon
mathjax: true
---

* content
{:toc}

##### Abstract
Bottleneck autoencoders have been actively researched as a solution to image compression tasks. In this work, we explore the ability of sparse coding to improve reconstructed image quality for the same degree of compression. We observe that sparse image compression provides qualitatively superior visual quality of reconstructed images but has lower values of PSNR and SSIM compared to bottleneck autoencoders. We hypothesized that there should be another evaluational criterion to support our subjective observations. To test this hypothesis, we fed reconstructed images from both the bottleneck autoencoder and sparse coding into a DCNN classifier and discovered that the images reconstructed from the sparse coding compression obtained on average 1.5\% higher classification accuracy compared to bottleneck autoencoders, implying that sparse coding preserves more content-relevant information.

##### Abstract (translated by Google)
瓶颈自动编码器作为图像压缩任务的解决方案已被积极研究。在这项工作中，我们探索了稀疏编码的能力，以提高相同程度的压缩重建图像质量。我们观察到，稀疏图像压缩提供了重建图像的质量优越的视觉质量，但与瓶颈自动编码器相比，PSNR和SSIM的值较低。我们假设应该有另一个评估标准来支持我们的主观观察。为了验证这一假设，我们将瓶颈自动编码器和稀疏编码两者的重建图像输入到DCNN分类器中，发现从瓶颈自动编码器平均1.5％的分类准确度获得的稀疏编码压缩重建的图像意味着稀疏编码保留了更多与内容相关的信息。

##### URL
[https://arxiv.org/abs/1710.09926](https://arxiv.org/abs/1710.09926)

##### PDF
[https://arxiv.org/pdf/1710.09926](https://arxiv.org/pdf/1710.09926)

