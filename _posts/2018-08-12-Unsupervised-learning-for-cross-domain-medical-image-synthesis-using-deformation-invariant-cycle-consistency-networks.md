---
layout: post
title: "Unsupervised learning for cross-domain medical image synthesis using deformation invariant cycle consistency networks"
date: 2018-08-12 13:49:19
categories: arXiv_AI
tags: arXiv_AI Adversarial GAN CNN
author: Chengjia Wang, Gillian Macnaught, Giorgos Papanastasiou, Tom MacGillivray, David Newby
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, the cycle-consistent generative adversarial networks (CycleGAN) has been widely used for synthesis of multi-domain medical images. The domain-specific nonlinear deformations captured by CycleGAN make the synthesized images difficult to be used for some applications, for example, generating pseudo-CT for PET-MR attenuation correction. This paper presents a deformation-invariant CycleGAN (DicycleGAN) method using deformable convolutional layers and new cycle-consistency losses. Its robustness dealing with data that suffer from domain-specific nonlinear deformations has been evaluated through comparison experiments performed on a multi-sequence brain MR dataset and a multi-modality abdominal dataset. Our method has displayed its ability to generate synthesized data that is aligned with the source while maintaining a proper quality of signal compared to CycleGAN-generated data. The proposed model also obtained comparable performance with CycleGAN when data from the source and target domains are alignable through simple affine transformations.

##### Abstract (translated by Google)
最近，循环一致的生成对抗网络（CycleGAN）已被广泛用于多域医学图像的合成。 CycleGAN捕获的特定于域的非线性变形使得合成图像难以用于某些应用，例如，生成用于PET-MR衰减校正的伪CT。本文介绍了一种变形不变的CycleGAN（DicycleGAN）方法，该方法使用可变形卷积层和新的循环一致性损失。通过在多序列脑MR数据集和多模态腹部数据集上进行的比较实验，评估了其处理受特定领域非线性变形影响的数据的稳健性。与CycleGAN生成的数据相比，我们的方法显示了生成与源对齐的合成数据的能力，同时保持适当的信号质量。当来源和目标域的数据可通过简单的仿射变换对齐时，所提出的模型也获得了与CycleGAN相当的性能。

##### URL
[http://arxiv.org/abs/1808.03944](http://arxiv.org/abs/1808.03944)

##### PDF
[http://arxiv.org/pdf/1808.03944](http://arxiv.org/pdf/1808.03944)

