---
layout: post
title: "Visual Saliency Based on Multiscale Deep Features"
date: 2015-04-10 06:40:46
categories: arXiv_CV
tags: arXiv_CV Salient Segmentation CNN Deep_Learning Recognition
author: Guanbin Li, Yizhou Yu
mathjax: true
---

* content
{:toc}

##### Abstract
Visual saliency is a fundamental problem in both cognitive and computational sciences, including computer vision. In this CVPR 2015 paper, we discover that a high-quality visual saliency model can be trained with multiscale features extracted using a popular deep learning architecture, convolutional neural networks (CNNs), which have had many successes in visual recognition tasks. For learning such saliency models, we introduce a neural network architecture, which has fully connected layers on top of CNNs responsible for extracting features at three different scales. We then propose a refinement method to enhance the spatial coherence of our saliency results. Finally, aggregating multiple saliency maps computed for different levels of image segmentation can further boost the performance, yielding saliency maps better than those generated from a single segmentation. To promote further research and evaluation of visual saliency models, we also construct a new large database of 4447 challenging images and their pixelwise saliency annotation. Experimental results demonstrate that our proposed method is capable of achieving state-of-the-art performance on all public benchmarks, improving the F-Measure by 5.0% and 13.2% respectively on the MSRA-B dataset and our new dataset (HKU-IS), and lowering the mean absolute error by 5.7% and 35.1% respectively on these two datasets.

##### Abstract (translated by Google)
视觉显着性是包括计算机视觉在内的认知科学和计算科学的基本问题。在这个CVPR 2015年的论文中，我们发现高质量的视觉显着性模型可以通过使用在流行的深度学习架构，卷积神经网络（CNN）中提取的多尺度特征进行训练，这在视觉识别任务中已经取得了许多成功。为了学习这种显着性模型，我们引入了一个神经网络体系结构，它在CNN之上完全连接了层，负责在三个不同尺度上提取特征。然后，我们提出一种改进方法来提高我们显着性结果的空间一致性。最后，为不同级别的图像分割而计算的多个显着图的聚合可以进一步提高性能，产生显着性图比那些从单个分割产生的更好。为了促进对视觉显着性模型的进一步研究和评估，我们还构建了一个新的4447个具有挑战性的图像及其像素显着性注释的大型数据库。实验结果表明，我们提出的方法能够在所有公共基准上实现最新的性能，在MSRA-B数据集和我们的新数据集（HKU-IS）上分别提高了5.0％和13.2％ ），并将这两个数据集的平均绝对误差分别降低了5.7％和35.1％。

##### URL
[https://arxiv.org/abs/1503.08663](https://arxiv.org/abs/1503.08663)

##### PDF
[https://arxiv.org/pdf/1503.08663](https://arxiv.org/pdf/1503.08663)

