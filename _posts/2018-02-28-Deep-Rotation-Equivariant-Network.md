---
layout: post
title: "Deep Rotation Equivariant Network"
date: 2018-02-28 07:13:48
categories: arXiv_CV
tags: arXiv_CV Attention CNN
author: Junying Li, Zichen Yang, Haifeng Liu, Deng Cai
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, learning equivariant representations has attracted considerable research attention. Dieleman et al. introduce four operations which can be inserted into convolutional neural network to learn deep representations equivariant to rotation. However, feature maps should be copied and rotated four times in each layer in their approach, which causes much running time and memory overhead. In order to address this problem, we propose Deep Rotation Equivariant Network consisting of cycle layers, isotonic layers and decycle layers. Our proposed layers apply rotation transformation on filters rather than feature maps, achieving a speed up of more than 2 times with even less memory overhead. We evaluate DRENs on Rotated MNIST and CIFAR-10 datasets and demonstrate that it can improve the performance of state-of-the-art architectures.

##### Abstract (translated by Google)
最近，学习equivariant交涉已吸引了相当多的研究关注。 Dieleman等人引入四个可插入卷积神经网络的操作来学习等价于旋转的深度表示。但是，功能图应该在其方法的每个层中被复制和旋转四次，这会导致很多运行时间和内存开销。为了解决这个问题，我们提出由循环层，等渗层和循环层组成的深旋转等变网络。我们提出的图层在滤镜上应用了旋转变换而不是特征贴图，实现了超过2倍的加速，并且内存开销更小。我们评估旋转MNIST和CIFAR-10数据集上的DREN，并证明它可以提高最先进的体系结构的性能。

##### URL
[http://arxiv.org/abs/1705.08623](http://arxiv.org/abs/1705.08623)

##### PDF
[http://arxiv.org/pdf/1705.08623](http://arxiv.org/pdf/1705.08623)

