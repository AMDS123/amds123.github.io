---
layout: post
title: "Improved robustness to adversarial examples using Lipschitz regularization of the loss"
date: 2018-10-23 16:08:46
categories: arXiv_CV
tags: arXiv_CV Regularization Adversarial
author: Chris Finlay, Adam Oberman, Bilal Abbasi
mathjax: true
---

* content
{:toc}

##### Abstract
Adversarial training is an effective method for improving robustness to adversarial attacks. We show that adversarial training using the Fast Signed Gradient Method can be interpreted as a form of regularization. We implemented a more effective form of adversarial training, which in turn can be interpreted as regularization of the loss in the 2-norm, $\|\nabla_x \ell(x)\|_2$. We obtained further improvements to adversarial robustness, as well as provable robustness guarantees, by augmenting adversarial training with Lipschitz regularization.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.00953](http://arxiv.org/abs/1810.00953)

##### PDF
[http://arxiv.org/pdf/1810.00953](http://arxiv.org/pdf/1810.00953)

