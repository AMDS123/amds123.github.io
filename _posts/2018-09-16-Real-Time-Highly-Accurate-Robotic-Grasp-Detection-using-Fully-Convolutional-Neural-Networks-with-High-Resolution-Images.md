---
layout: post
title: "Real-Time, Highly Accurate Robotic Grasp Detection using Fully Convolutional Neural Networks with High-Resolution Images"
date: 2018-09-16 07:36:02
categories: arXiv_CV
tags: arXiv_CV CNN Deep_Learning Detection
author: Dongwon Park, Yonghyeok Seo, Se Young Chun
mathjax: true
---

* content
{:toc}

##### Abstract
Robotic grasp detection for novel objects is a challenging task, but for the last few years, deep learning based approaches have achieved remarkable performance improvements, up to 96.1% accuracy, with RGB-D data. In this paper, we propose fully convolutional neural network (FCNN) based methods for robotic grasp detection. Our methods also achieved state-of-the-art detection accuracy (up to 96.6%) with state-of- the-art real-time computation time for high-resolution images (6-20ms per 360x360 image) on Cornell dataset. Due to FCNN, our proposed method can be applied to images with any size for detecting multigrasps on multiobjects. Proposed methods were evaluated using 4-axis robot arm with small parallel gripper and RGB-D camera for grasping challenging small, novel objects. With accurate vision-robot coordinate calibration through our proposed learning-based, fully automatic approach, our proposed method yielded 90% success rate.

##### Abstract (translated by Google)
对新物体进行机器人抓握检测是一项具有挑战性的任务，但在过去的几年中，基于深度学习的方法通过RGB-D数据实现了显着的性能提升，精度高达96.1％。在本文中，我们提出了完全基于卷积神经网络（FCNN）的机器人抓握检测方法。我们的方法还通过Cornell数据集中高分辨率图像（每360x360图像6-20ms）的最先进实时计算时间，实现了最先进的检测精度（高达96.6％）。由于FCNN，我们提出的方法可以应用于任何大小的图像，用于检测多对象上的多个图。提出的方法使用4轴机器人手臂和小型平行夹具和RGB-D相机进行评估，以抓住具有挑战性的小型新物体。通过我们提出的基于学习的全自动方法进行精确的视觉 - 机器人坐标校准，我们提出的方法产生了90％的成功率。

##### URL
[http://arxiv.org/abs/1809.05828](http://arxiv.org/abs/1809.05828)

##### PDF
[http://arxiv.org/pdf/1809.05828](http://arxiv.org/pdf/1809.05828)

