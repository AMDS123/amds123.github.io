---
layout: post
title: "Domain Stylization: A Strong, Simple Baseline for Synthetic to Real Image Domain Adaptation"
date: 2018-07-24 23:06:49
categories: arXiv_CV
tags: arXiv_CV Object_Detection Segmentation GAN Style_Transfer Semantic_Segmentation Quantitative Detection
author: Aysegul Dundar, Ming-Yu Liu, Ting-Chun Wang, John Zedlewski, Jan Kautz
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks have largely failed to effectively utilize synthetic data when applied to real images due to the covariate shift problem. In this paper, we show that by applying a straightforward modification to an existing photorealistic style transfer algorithm, we achieve state-of-the-art synthetic-to-real domain adaptation results. We conduct extensive experimental validations on four synthetic-to-real tasks for semantic segmentation and object detection, and show that our approach exceeds the performance of any current state-of-the-art GAN-based image translation approach as measured by segmentation and object detection metrics. Furthermore we offer a distance based analysis of our method which shows a dramatic reduction in Frechet Inception distance between the source and target domains, offering a quantitative metric that demonstrates the effectiveness of our algorithm in bridging the synthetic-to-real gap.

##### Abstract (translated by Google)
由于协变量偏移问题，深度神经网络在应用于真实图像时很大程度上未能有效地利用合成数据。在本文中，我们通过对现有的照片级真实样式转换算法应用直接修改，我们实现了最先进的合成到实际域自适应结果。我们对用于语义分割和对象检测的四个合成到实际任务进行了广泛的实验验证，并且表明我们的方法超过了通过分割和对象测量的任何当前基于GAN的图像转换方法的性能。检测指标。此外，我们提供了一种基于距离的方法分析，该方法显示了源域和目标域之间的Frechet Inception距离的显着减少，提供了一个定量度量，证明了我们的算法在弥合合成到实际间隙方面的有效性。

##### URL
[http://arxiv.org/abs/1807.09384](http://arxiv.org/abs/1807.09384)

##### PDF
[http://arxiv.org/pdf/1807.09384](http://arxiv.org/pdf/1807.09384)

