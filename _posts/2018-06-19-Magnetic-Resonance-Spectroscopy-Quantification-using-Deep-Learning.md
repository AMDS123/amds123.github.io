---
layout: post
title: "Magnetic Resonance Spectroscopy Quantification using Deep Learning"
date: 2018-06-19 13:56:56
categories: arXiv_CV
tags: arXiv_CV GAN CNN Deep_Learning Relation
author: Nima Hatami, Micha&#xeb;l Sdika, H&#xe9;l&#xe8;ne Ratiney
mathjax: true
---

* content
{:toc}

##### Abstract
Magnetic resonance spectroscopy (MRS) is an important technique in biomedical research and it has the unique capability to give a non-invasive access to the biochemical content (metabolites) of scanned organs. In the literature, the quantification (the extraction of the potential biomarkers from the MRS signals) involves the resolution of an inverse problem based on a parametric model of the metabolite signal. However, poor signal-to-noise ratio (SNR), presence of the macromolecule signal or high correlation between metabolite spectral patterns can cause high uncertainties for most of the metabolites, which is one of the main reasons that prevents use of MRS in clinical routine. In this paper, quantification of metabolites in MR Spectroscopic imaging using deep learning is proposed. A regression framework based on the Convolutional Neural Networks (CNN) is introduced for an accurate estimation of spectral parameters. The proposed model learns the spectral features from a large-scale simulated data set with different variations of human brain spectra and SNRs. Experimental results demonstrate the accuracy of the proposed method, compared to state of the art standard quantification method (QUEST), on concentration of 20 metabolites and the macromolecule.

##### Abstract (translated by Google)
磁共振波谱分析（MRS）是生物医学研究中的一项重要技术，它具有独特的能力，可非侵入性地获取扫描器官的生化成分（代谢物）。在文献中，量化（从MRS信号中提取潜在生物标志物）涉及基于代谢物信号的参数模型的逆问题的解决。然而，较差的信噪比（SNR），大分子信号的存在或代谢物光谱模式之间的高度相关性可导致大多数代谢物的高不确定性，这是妨碍在临床常规中使用MRS的主要原因之一。在本文中，提出了使用深度学习的MR光谱成像中的代谢物的量化。引入基于卷积神经网络（CNN）的回归框架来准确估计谱参数。所提出的模型从具有人脑光谱和SNR的不同变化的大规模模拟数据集中学习光谱特征。与现有技术标准定量方法（QUEST）相比，实验结果证明所提出的方法对于20种代谢物和大分子的浓度的准确性。

##### URL
[http://arxiv.org/abs/1806.07237](http://arxiv.org/abs/1806.07237)

##### PDF
[http://arxiv.org/pdf/1806.07237](http://arxiv.org/pdf/1806.07237)

