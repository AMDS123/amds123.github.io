---
layout: post
title: "Numeracy for Language Models: Evaluating and Improving their Ability to Predict Numbers"
date: 2018-05-21 16:18:41
categories: arXiv_CL
tags: arXiv_CL Language_Model
author: Georgios P. Spithourakis, Sebastian Riedel
mathjax: true
---

* content
{:toc}

##### Abstract
Numeracy is the ability to understand and work with numbers. It is a necessary skill for composing and understanding documents in clinical, scientific, and other technical domains. In this paper, we explore different strategies for modelling numerals with language models, such as memorisation and digit-by-digit composition, and propose a novel neural architecture that uses a continuous probability density function to model numerals from an open vocabulary. Our evaluation on clinical and scientific datasets shows that using hierarchical models to distinguish numerals from words improves a perplexity metric on the subset of numerals by 2 and 4 orders of magnitude, respectively, over non-hierarchical models. A combination of strategies can further improve perplexity. Our continuous probability density function model reduces mean absolute percentage errors by 18% and 54% in comparison to the second best strategy for each dataset, respectively.

##### Abstract (translated by Google)
数学是理解和使用数字的能力。这是在临床，科学和其他技术领域撰写和理解文件的必备技能。在本文中，我们探讨了用语言模型建模数字的不同策略，例如记忆和逐位数字组合，并提出了一种新颖的神经结构，它使用连续概率密度函数来对开放词汇表中的数字进行建模。我们对临床和科学数据集的评估表明，使用分层模型区分数字和单词，可以将数字子集的困惑度量分别提高2个和4个数量级，而非分层模型。策略的组合可以进一步改善困惑。与每个数据集的次优策略相比，我们的连续概率密度函数模型分别将平均绝对误差百分比降低了18％和54％。

##### URL
[https://arxiv.org/abs/1805.08154](https://arxiv.org/abs/1805.08154)

##### PDF
[https://arxiv.org/pdf/1805.08154](https://arxiv.org/pdf/1805.08154)

