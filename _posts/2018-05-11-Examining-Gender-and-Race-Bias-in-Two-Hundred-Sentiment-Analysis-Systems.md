---
layout: post
title: "Examining Gender and Race Bias in Two Hundred Sentiment Analysis Systems"
date: 2018-05-11 17:57:40
categories: arXiv_CL
tags: arXiv_CL Sentiment Prediction
author: Svetlana Kiritchenko, Saif M. Mohammad
mathjax: true
---

* content
{:toc}

##### Abstract
Automatic machine learning systems can inadvertently accentuate and perpetuate inappropriate human biases. Past work on examining inappropriate biases has largely focused on just individual systems. Further, there is no benchmark dataset for examining inappropriate biases in systems. Here for the first time, we present the Equity Evaluation Corpus (EEC), which consists of 8,640 English sentences carefully chosen to tease out biases towards certain races and genders. We use the dataset to examine 219 automatic sentiment analysis systems that took part in a recent shared task, SemEval-2018 Task 1 'Affect in Tweets'. We find that several of the systems show statistically significant bias; that is, they consistently provide slightly higher sentiment intensity predictions for one race or one gender. We make the EEC freely available.

##### Abstract (translated by Google)
自动机器学习系统可能会不经意地突显和延续不适当的人为偏见。过去检查不当偏见的工作主要集中在单个系统上。此外，没有用于检查系统中不当偏见的基准数据集。在这里，我们首次提出了股票评估语料库（EEC），其中包含8,640个英文句子，这些句子经过仔细挑选，以消除对某些种族和性别的偏见。我们使用数据集来检查219个自动情绪分析系统，这些系统参与了最近的共享任务SemEval-2018任务1“在推文中影响”。我们发现有几个系统显示出统计上显着的偏差;也就是说，他们一贯为一个种族或一个性别提供略高的情绪强度预测。我们可以免费提供EEC。

##### URL
[http://arxiv.org/abs/1805.04508](http://arxiv.org/abs/1805.04508)

##### PDF
[http://arxiv.org/pdf/1805.04508](http://arxiv.org/pdf/1805.04508)

