---
layout: post
title: "Improving Speech Related Facial Action Unit Recognition by Audiovisual Information Fusion"
date: 2017-06-29 14:36:07
categories: arXiv_CV
tags: arXiv_CV Face Relation Recognition
author: Zibo Meng, Shizhong Han, Ping Liu, Yan Tong
mathjax: true
---

* content
{:toc}

##### Abstract
It is challenging to recognize facial action unit (AU) from spontaneous facial displays, especially when they are accompanied by speech. The major reason is that the information is extracted from a single source, i.e., the visual channel, in the current practice. However, facial activity is highly correlated with voice in natural human communications. Instead of solely improving visual observations, this paper presents a novel audiovisual fusion framework, which makes the best use of visual and acoustic cues in recognizing speech-related facial AUs. In particular, a dynamic Bayesian network (DBN) is employed to explicitly model the semantic and dynamic physiological relationships between AUs and phonemes as well as measurement uncertainty. A pilot audiovisual AU-coded database has been collected to evaluate the proposed framework, which consists of a "clean" subset containing frontal faces under well controlled circumstances and a challenging subset with large head movements and occlusions. Experiments on this database have demonstrated that the proposed framework yields significant improvement in recognizing speech-related AUs compared to the state-of-the-art visual-based methods especially for those AUs whose visual observations are impaired during speech, and more importantly also outperforms feature-level fusion methods by explicitly modeling and exploiting physiological relationships between AUs and phonemes.

##### Abstract (translated by Google)
从自发的面部表情中识别面部动作单元（AU）非常具有挑战性，尤其是当它们伴随着语音时。主要原因是在目前的实践中，信息是从一个单一来源，即可视频道中提取的。然而，面部活动与人的自然交流中的声音高度相关。本文不是单纯地改进视觉观察，而是提出了一种新颖的视听融合框架，它能够最大限度地利用视觉和听觉线索来识别语音相关的面部AU。具体而言，采用动态贝叶斯网络（DBN）来明确地模拟AU和音素之间的语义和动态生理关系以及测量不确定性。收集了一个先导视听AU编码数据库来评估提出的框架，该框架包含一个“干净的”子集，包含在良好控制环境下的正面和一个具有大头部运动和遮挡的具有挑战性的子集。在这个数据库上的实验已经证明，与最先进的基于视觉的方法相比，所提出的框架在识别语音相关的AU方面产生显着的改进，特别是对于那些在语音期间视觉观察受到损害的AU，并且更重要的是也优于特征级融合方法，通过明确地建模和利用AU和音素之间的生理关系。

##### URL
[https://arxiv.org/abs/1706.10197](https://arxiv.org/abs/1706.10197)

##### PDF
[https://arxiv.org/pdf/1706.10197](https://arxiv.org/pdf/1706.10197)

