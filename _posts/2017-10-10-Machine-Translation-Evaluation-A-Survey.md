---
layout: post
title: "Machine Translation Evaluation: A Survey"
date: 2017-10-10 14:04:07
categories: arXiv_CL
tags: arXiv_CL Survey Classification Deep_Learning Language_Model Relation
author: Aaron Li-Feng Han, Derek Fai Wong
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce the Machine Translation (MT) evaluation survey that contains both manual and automatic evaluation methods. The traditional human evaluation criteria mainly include the intelligibility, fidelity, fluency, adequacy, comprehension, and informativeness. The advanced human assessments include task-oriented measures, post-editing, segment ranking, and extended criteriea, etc. We classify the automatic evaluation methods into two categories, including lexical similarity scenario and linguistic features application. The lexical similarity methods contain edit distance, precision, recall, F-measure, and word order. The linguistic features can be divided into syntactic features and semantic features respectively. The syntactic features include part of speech tag, phrase types and sentence structures, and the semantic features include named entity, synonyms, textual entailment, paraphrase, semantic roles, and language models. The deep learning models for evaluation are very newly proposed. Subsequently, we also introduce the evaluation methods for MT evaluation including different correlation scores, and the recent quality estimation (QE) tasks for MT. This paper differs from the existing works \cite{GALEprogram2009,EuroMatrixProject2007} from several aspects, by introducing some recent development of MT evaluation measures, the different classifications from manual to automatic evaluation measures, the introduction of recent QE tasks of MT, and the concise construction of the content. We hope this work will be helpful for MT researchers to easily pick up some metrics that are best suitable for their specific MT model development, and help MT evaluation researchers to get a general clue of how MT evaluation research developed. Furthermore, hopefully, this work can also shine some light on other evaluation tasks, except for translation, of NLP fields.

##### Abstract (translated by Google)
我们介绍包含手动和自动评估方法的机器翻译（MT）评估调查。传统的人文评价标准主要包括可理解性，忠实性，流畅性，充分性，理解性和信息性。先进的人体评估包括任务导向测量，后期编辑，细分排序和扩展标准等。将自动评估方法分为词汇相似性情景和语言特征应用两大类。词汇相似度方法包含编辑距离，精度，召回率，F度量和词序。语言特征可分为语法特征和语义特征。句法特征包括词性标注，短语类型和句子结构，语义特征包括命名实体，同义词，文本蕴涵，释义，语义角色和语言模型。评估的深度学习模式是非常新的提议。随后，我们还介绍了MT评估的评估方法，其中包括不同的相关评分，以及最近MT的质量评估（QE）任务。本文与现有的工作不同之处在于从多个方面介绍了MT评估方法的最新进展，从手工评估到自动评估方法的不同分类，MT近期QE任务的介绍以及简明内容的建设。我们希望这项工作能够帮助MT研究人员轻松找到最适合他们特定MT模型开发的一些指标，并帮助MT评估研究人员获得MT评估研究如何发展的一般线索。此外，希望这项工作能够对NLP领域的其他评估任务（翻译除外）有所启发。

##### URL
[https://arxiv.org/abs/1605.04515](https://arxiv.org/abs/1605.04515)

##### PDF
[https://arxiv.org/pdf/1605.04515](https://arxiv.org/pdf/1605.04515)

