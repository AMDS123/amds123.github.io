---
layout: post
title: "Learning Convolutional Text Representations for Visual Question Answering"
date: 2017-05-18 22:51:44
categories: arXiv_CL
tags: arXiv_CL Text_Classification CNN Image_Classification RNN Classification Deep_Learning VQA Recognition
author: Zhengyang Wang, Shuiwang Ji
mathjax: true
---

* content
{:toc}

##### Abstract
Visual question answering is a recently proposed artificial intelligence task that requires a deep understanding of both images and texts. In deep learning, images are typically modeled through convolutional neural networks, and texts are typically modeled through recurrent neural networks. While the requirement for modeling images is similar to traditional computer vision tasks, such as object recognition and image classification, visual question answering raises a different need for textual representation as compared to other natural language processing tasks. In this work, we perform a detailed analysis on natural language questions in visual question answering. Based on the analysis, we propose to rely on convolutional neural networks for learning textual representations. By exploring the various properties of convolutional neural networks specialized for text data, such as width and depth, we present our "CNN Inception + Gate" model. We show that our model improves question representations and thus the overall accuracy of visual question answering models. We also show that the text representation requirement in visual question answering is more complicated and comprehensive than that in conventional natural language processing tasks, making it a better task to evaluate textual representation methods. Shallow models like fastText, which can obtain comparable results with deep learning models in tasks like text classification, are not suitable in visual question answering.

##### Abstract (translated by Google)
视觉问题回答是最近提出的人工智能任务，需要对图像和文本有深入的了解。在深度学习中，图像通常通过卷积神经网络建模，并且文本通常通过递归神经网络建模。虽然对图像建模的要求与传统的计算机视觉任务（如对象识别和图像分类）类似，但与其他自然语言处理任务相比，视觉问题回答提出了对文本表示的不同需求。在这项工作中，我们对视觉问题回答中的自然语言问题进行了详细的分析。基于分析，我们建议依靠卷积神经网络来学习文本表示。通过探索宽度和深度等文本数据专用卷积神经网络的各种性质，我们提出了“CNN入侵+门”模型。我们表明，我们的模型改善了问题的表示，从而提高了视觉问答模型的整体准确性。我们还表明，视觉问答中的文本表示要求比传统的自然语言处理任务更为复杂和全面，使得评估文本表示方法成为一个更好的任务。像文本分类这样的可以获得与深度学习模型相媲美的结果的浅表模型，不适用于视觉问题的回答。

##### URL
[https://arxiv.org/abs/1705.06824](https://arxiv.org/abs/1705.06824)

##### PDF
[https://arxiv.org/pdf/1705.06824](https://arxiv.org/pdf/1705.06824)

