---
layout: post
title: "Fluid Annotation: A Human-Machine Collaboration Interface for Full Image Annotation"
date: 2018-08-20 16:54:46
categories: arXiv_CV
tags: arXiv_CV Face
author: Mykhaylo Andriluka, Jasper R. R. Uijlings, Vittorio Ferrari
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce Fluid Annotation, an intuitive human-machine collaboration interface for annotating the class label and outline of every object and background region in an image. Fluid annotation is based on three principles: (I) Strong Machine-Learning aid. We start from the output of a strong neural network model, which the annotator can edit by correcting the labels of existing regions, adding new regions to cover missing objects, and removing incorrect regions. The edit operations are also assisted by the model. (II) Full image annotation in a single pass. As opposed to performing a series of small annotation tasks in isolation, we propose a unified interface for full image annotation in a single pass. (III) Empower the annotator. We empower the annotator to choose what to annotate and in which order. This enables concentrating on what the machine does not already know, i.e. putting human effort only on the errors it made. This helps using the annotation budget effectively. Through extensive experiments on the COCO+Stuff dataset, we demonstrate that Fluid Annotation leads to accurate annotations very efficiently, taking three times less annotation time than the popular LabelMe interface.

##### Abstract (translated by Google)
我们介绍Fluid Annotation，一个直观的人机协作界面，用于注释图像中每个对象和背景区域的类标签和轮廓。流体注释基于三个原则：（I）强大的机器学习辅助。我们从强神经网络模型的输出开始，注释器可以通过更正现有区域的标签，添加新区域以覆盖缺失的对象以及删除不正确的区域来编辑。模型也协助编辑操作。 （II）单次传递中的完整图像注释。与单独执行一系列小注释任务相反，我们在单个传递中提出了用于完整图像注释的统一接口。 （III）赋予注释者权力。我们授权注释器选择要注释的内容和顺序。这使得能够专注于机器尚未知道的内容，即仅仅将人力投入到它所犯的错误上。这有助于有效地使用注释预算。通过对COCO + Stuff数据集的大量实验，我们证明了Fluid Annotation可以非常有效地导致准确的注释，注释时间比流行的LabelMe界面少三倍。

##### URL
[http://arxiv.org/abs/1806.07527](http://arxiv.org/abs/1806.07527)

##### PDF
[http://arxiv.org/pdf/1806.07527](http://arxiv.org/pdf/1806.07527)

