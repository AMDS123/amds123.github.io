---
layout: post
title: "Parallel Attention: A Unified Framework for Visual Object Discovery through Dialogs and Queries"
date: 2017-11-17 01:46:48
categories: arXiv_CV
tags: arXiv_CV Attention
author: Bohan Zhuang, Qi Wu, Chunhua Shen, Ian Reid, Anton van den Hengel
mathjax: true
---

* content
{:toc}

##### Abstract
Recognising objects according to a pre-defined fixed set of class labels has been well studied in the Computer Vision. There are a great many practical applications where the subjects that may be of interest are not known beforehand, or so easily delineated, however. In many of these cases natural language dialog is a natural way to specify the subject of interest, and the task achieving this capability (a.k.a, Referring Expression Comprehension) has recently attracted attention. To this end we propose a unified framework, the ParalleL AttentioN (PLAN) network, to discover the object in an image that is being referred to in variable length natural expression descriptions, from short phrases query to long multi-round dialogs. The PLAN network has two attention mechanisms that relate parts of the expressions to both the global visual content and also directly to object candidates. Furthermore, the attention mechanisms are recurrent, making the referring process visualizable and explainable. The attended information from these dual sources are combined to reason about the referred object. These two attention mechanisms can be trained in parallel and we find the combined system outperforms the state-of-art on several benchmarked datasets with different length language input, such as RefCOCO, RefCOCO+ and GuessWhat?!.

##### Abstract (translated by Google)
在计算机视觉中已经很好地研究了根据预定义的固定类别标签集合来识别对象。有很多的实际应用，可能感兴趣的主题事先不知道，或者很容易描述。在许多情况下，自然语言对话是指定感兴趣的主题的自然方式，并且实现这种能力的任务（也就是参考表达理解）最近引起了关注。为此，我们提出了一个统一的框架，即并行计算（PLAN）网络，用于发现可变长度自然表达式描述中所涉及的图像中的对象，从简短的短语查询到长的多轮对话框。 PLAN网络有两个注意机制，它们将表达的部分与全局可视内容以及直接对象候选相关联。此外，注意机制是经常性的，使得参考过程可视化和可解释。将这些双重来源的有关信息结合起来，对被引用的对象进行推理。这两种关注机制可以并行进行训练，我们发现组合系统在不同长度语言输入的基准数据集（例如RefCOCO，RefCOCO +和GuessWhat）上的性能优于现有技术。

##### URL
[https://arxiv.org/abs/1711.06370](https://arxiv.org/abs/1711.06370)

##### PDF
[https://arxiv.org/pdf/1711.06370](https://arxiv.org/pdf/1711.06370)

