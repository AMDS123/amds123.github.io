---
layout: post
title: "Challenges of Context and Time in Reinforcement Learning: Introducing Space Fortress as a Benchmark"
date: 2018-09-06 20:17:44
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Akshat Agarwal, Ryan Hope, Katia Sycara
mathjax: true
---

* content
{:toc}

##### Abstract
Research in deep reinforcement learning (RL) has coalesced around improving performance on benchmarks like the Arcade Learning Environment. However, these benchmarks conspicuously miss important characteristics like abrupt context-dependent shifts in strategy and temporal sensitivity that are often present in real-world domains. As a result, RL research has not focused on these challenges, resulting in algorithms which do not understand critical changes in context, and have little notion of real world time. To tackle this issue, this paper introduces the game of Space Fortress as a RL benchmark which incorporates these characteristics. We show that existing state-of-the-art RL algorithms are unable to learn to play the Space Fortress game. We then confirm that this poor performance is due to the RL algorithms' context insensitivity and reward sparsity. We also identify independent axes along which to vary context and temporal sensitivity, allowing Space Fortress to be used as a testbed for understanding both characteristics in combination and also in isolation. We release Space Fortress as an open-source Gym environment.

##### Abstract (translated by Google)
深度强化学习（RL）的研究已经围绕提高Arcade学习环境等基准测试的性能进行了合并。然而，这些基准显着地忽略了重要的特征，例如战略和时间敏感性的突然上下文相关的变化，这些变化经常出现在现实世界的领域中。因此，RL研究并未专注于这些挑战，导致算法无法理解上下文中的关键变化，并且几乎没有关于现实世界时间的概念。为了解决这个问题，本文介绍了太空堡垒游戏作为RL基准，它结合了这些特征。我们展示了现有的最先进的RL算法无法学习玩太空堡垒游戏。然后我们确认这种糟糕的性能是由于RL算法的上下文不敏感和奖励稀疏性造成的。我们还确定了独立的轴，以改变背景和时间灵敏度，允许太空堡垒作为测试平台，用于组合和孤立地理解这两个特征。我们发布Space Fortress作为开源健身房环境。

##### URL
[http://arxiv.org/abs/1809.02206](http://arxiv.org/abs/1809.02206)

##### PDF
[http://arxiv.org/pdf/1809.02206](http://arxiv.org/pdf/1809.02206)

