---
layout: post
title: "Learning Detection with Diverse Proposals"
date: 2017-04-11 20:51:40
categories: arXiv_CV
tags: arXiv_CV Object_Detection Inference Prediction Detection Relation
author: Samaneh Azadi, Jiashi Feng, Trevor Darrell
mathjax: true
---

* content
{:toc}

##### Abstract
To predict a set of diverse and informative proposals with enriched representations, this paper introduces a differentiable Determinantal Point Process (DPP) layer that is able to augment the object detection architectures. Most modern object detection architectures, such as Faster R-CNN, learn to localize objects by minimizing deviations from the ground-truth but ignore correlation between multiple proposals and object categories. Non-Maximum Suppression (NMS) as a widely used proposal pruning scheme ignores label- and instance-level relations between object candidates resulting in multi-labeled detections. In the multi-class case, NMS selects boxes with the largest prediction scores ignoring the semantic relation between categories of potential election. In contrast, our trainable DPP layer, allowing for Learning Detection with Diverse Proposals (LDDP), considers both label-level contextual information and spatial layout relationships between proposals without increasing the number of parameters of the network, and thus improves location and category specifications of final detected bounding boxes substantially during both training and inference schemes. Furthermore, we show that LDDP keeps it superiority over Faster R-CNN even if the number of proposals generated by LDPP is only ~30% as many as those for Faster R-CNN.

##### Abstract (translated by Google)
为了预测一组丰富的表示形式的丰富多彩的信息提议，本文引入了一个可扩展的目标检测体系结构的可微分决定点过程（DPP）层。大多数现代物体检测体系结构，比如更快的R-CNN，学习通过最小化与实际情况的偏差来定位物体，但是忽略多个提议和物体类别之间的相关性。作为广泛使用的提议修剪方案的非最大抑制（NMS）忽略对象候选之间的标签和实例级关系，导致多标签检测。在多类案例中，NMS选择预测分数最大的方框，忽略了潜在选举类别之间的语义关系。相比之下，我们可训练的DPP层允许学习多样建议检测（LDDP），同时考虑标签级上下文信息和提案之间的空间布局关系，而不增加网络参数的数量，从而改善了位置和类别规范基本上在训练和推理方案期间最终检测到的边界框。此外，我们还表明，即使LDPP产生的提案数量仅为R-CNN速度的30％左右，LDDP也能保持其优于R-CNN的优势。

##### URL
[https://arxiv.org/abs/1704.03533](https://arxiv.org/abs/1704.03533)

##### PDF
[https://arxiv.org/pdf/1704.03533](https://arxiv.org/pdf/1704.03533)

