---
layout: post
title: "Deep Transfer in Reinforcement Learning by Language Grounding"
date: 2017-08-01 02:20:00
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning
author: Karthik Narasimhan, Regina Barzilay, Tommi Jaakkola
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we explore the utilization of natural language to drive transfer for reinforcement learning (RL). Despite the wide-spread application of deep RL techniques, learning generalized policy representations that work across domains remains a challenging problem. We demonstrate that textual descriptions of environments provide a compact intermediate channel to facilitate effective policy transfer. We employ a model-based RL approach consisting of a differentiable planning module, a model-free component and a factorized representation to effectively utilize entity descriptions. Our model outperforms prior work on both transfer and multi-task scenarios in a variety of different environments.

##### Abstract (translated by Google)
在本文中，我们探索利用自然语言驱动强化学习（RL）的转移。尽管深度RL技术得到广泛应用，但学习跨领域工作的广义政策表征仍然是一个具有挑战性的问题。我们证明，环境的文字描述提供了一个紧凑的中间通道，以促进有效的政策转移。我们采用基于模型的RL方法，包括一个可区分的规划模块，一个无模型组件和一个分解表示法，以有效地利用实体描述。我们的模型比以前在各种不同的环境中的传输和多任务场景的性能都要好。

##### URL
[https://arxiv.org/abs/1708.00133](https://arxiv.org/abs/1708.00133)

##### PDF
[https://arxiv.org/pdf/1708.00133](https://arxiv.org/pdf/1708.00133)

