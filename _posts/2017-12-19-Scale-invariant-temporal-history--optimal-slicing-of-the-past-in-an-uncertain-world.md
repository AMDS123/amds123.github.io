---
layout: post
title: "Scale-invariant temporal history : optimal slicing of the past in an uncertain world"
date: 2017-12-19 19:33:02
categories: arXiv_AI
tags: arXiv_AI
author: Tyler A. Spears, Brandon G. Jacques, Marc W. Howard, Per B. Sederberg
mathjax: true
---

* content
{:toc}

##### Abstract
In both the human brain and any general artificial intelligence (AI), a representation of the past is necessary to predict the future. However, perfect storage of all experiences is not possible. One possibility, utilized in many applications, is to retain information about the past in a buffer. A limitation of this approach is that although events in the buffer are represented with perfect accuracy, the resources necessary to represent information at a particular time scale go up rapidly. Here we present a neurally-plausible, compressed, scale-free memory representation we call Scale-Invariant Temporal History (SITH). This representation covers an exponentially large period of time in the past at the cost of sacrificing temporal accuracy for events further in the past. The form of this decay is scale-invariant and can be shown to be optimal in that it is able to respond to worlds with a wide range of time scales. We demonstrate the utility of this representation in learning to play a simple video game. In this environment, SITH exhibits better learning performance than a fixed-size buffer history representation. Whereas the buffer performs well as long as the temporal dependencies can be represented within the buffer, SITH performs well over a much larger range of time scales for the same amount of resources. Finally, we discuss how the application of SITH, along with other human-inspired models of cognition, could improve reinforcement and machine learning algorithms in general.

##### Abstract (translated by Google)
在人脑和任何一般的人工智能（AI）中，过去的表示都是预测未来所必需的。但是，所有经验的完美存储是不可能的。在许多应用中使用的一种可能性是将有关过去的信息保存在缓冲器中。这种方法的局限性在于尽管缓冲区中的事件以完美的准确度来表示，但是在特定时间尺度上表示信息所需的资源迅速增加。在这里，我们提出一个神经似乎合理，压缩，无尺度的记忆表示，我们称之为尺度不变时间历史（SITH）。这种表示覆盖了过去指数级的大量时间，代价是牺牲了过去事件的时间精度。这种衰变的形式是尺度不变的，可以被证明是最佳的，因为它能够在广泛的时间尺度上对世界做出反应。我们展示了这种表示在学习玩一个简单的视频游戏的效用。在这种环境下，SITH比固定大小的缓冲历史表示具有更好的学习性能。尽管只要缓冲区内可以表示时间依赖关系，缓冲区就表现良好，但SITH在相同数量的资源上执行的时间范围要大得多。最后，我们讨论SITH的应用以及其他人类启发的认知模型如何能够改善一般的增强和机器学习算法。

##### URL
[http://arxiv.org/abs/1712.07165](http://arxiv.org/abs/1712.07165)

##### PDF
[http://arxiv.org/pdf/1712.07165](http://arxiv.org/pdf/1712.07165)

