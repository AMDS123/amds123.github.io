---
layout: post
title: "Sentence Modeling via Multiple Word Embeddings and Multi-level Comparison for Semantic Textual Similarity"
date: 2018-05-21 03:54:39
categories: arXiv_CL
tags: arXiv_CL Embedding RNN Relation
author: Huy Nguyen Tien, Minh Nguyen Le, Yamasaki Tomohiro, Izuha Tatsuya
mathjax: true
---

* content
{:toc}

##### Abstract
Different word embedding models capture different aspects of linguistic properties. This inspired us to propose a model (M-MaxLSTM-CNN) for employing multiple sets of word embeddings for evaluating sentence similarity/relation. Representing each word by multiple word embeddings, the MaxLSTM-CNN encoder generates a novel sentence embedding. We then learn the similarity/relation between our sentence embeddings via Multi-level comparison. Our method M-MaxLSTM-CNN consistently shows strong performances in several tasks (i.e., measure textual similarity, identify paraphrase, recognize textual entailment). According to the experimental results on STS Benchmark dataset and SICK dataset from SemEval, M-MaxLSTM-CNN outperforms the state-of-the-art methods for textual similarity tasks. Our model does not use hand-crafted features (e.g., alignment features, Ngram overlaps, dependency features) as well as does not require pre-trained word embeddings to have the same dimension.

##### Abstract (translated by Google)
不同的单词嵌入模型捕捉语言属性的不同方面。这启发了我们提出了一个模型（M-MaxLSTM-CNN），用于使用多组词语嵌入来评估句子相似性/关系。 MaxLSTM-CNN编码器通过多个单词嵌入来表示每个单词，从而生成新的句子嵌入。然后我们通过多级比较来了解我们的句子嵌入之间的相似性/关系。我们的方法M-MaxLSTM-CNN在几项任务中始终表现出强大的表现（即测量文本相似性，识别释义，识别文本内容）。根据来自SemEval的STS Benchmark数据集和SICK数据集的实验结果，M-MaxLSTM-CNN比文本相似性任务的最先进方法更胜一筹。我们的模型不使用手工制作的特征（例如对齐特征，Ngram重叠，依赖特征），也不需要预先训练的词嵌入具有相同的维度。

##### URL
[https://arxiv.org/abs/1805.07882](https://arxiv.org/abs/1805.07882)

##### PDF
[https://arxiv.org/pdf/1805.07882](https://arxiv.org/pdf/1805.07882)

