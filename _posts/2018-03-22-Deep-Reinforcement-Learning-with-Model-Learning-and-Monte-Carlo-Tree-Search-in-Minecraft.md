---
layout: post
title: "Deep Reinforcement Learning with Model Learning and Monte Carlo Tree Search in Minecraft"
date: 2018-03-22 16:53:34
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Stephan Alaniz
mathjax: true
---

* content
{:toc}

##### Abstract
Deep reinforcement learning has been successfully applied to several visual-input tasks using model-free methods. In this paper, we propose a model-based approach that combines learning a DNN-based transition model with Monte Carlo tree search to solve a block-placing task in Minecraft. Our learned transition model predicts the next frame and the rewards one step ahead given the last four frames of the agent's first-person-view image and the current action. Then a Monte Carlo tree search algorithm uses this model to plan the best sequence of actions for the agent to perform. On the proposed task in Minecraft, our model-based approach reaches the performance comparable to the Deep Q-Network's, but learns faster and, thus, is more training sample efficient.

##### Abstract (translated by Google)
使用无模型方法已将深度强化学习成功应用于多个视觉输入任务。在本文中，我们提出了一种基于模型的方法，该方法将基于DNN的转换模型与蒙特卡洛树搜索相结合，以解决Minecraft中的块放置任务。我们学到的转换模型预测下一帧和奖励前一步，给出代理的第一人称视角图像的最后四帧和当前动作。然后，蒙特卡洛树搜索算法使用此模型来规划代理执行的最佳操作序列。关于Minecraft中提出的任务，我们基于模型的方法达到了与深度Q网络相当的性能，但学习速度更快，因此更有效地提高了训练样本。

##### URL
[https://arxiv.org/abs/1803.08456](https://arxiv.org/abs/1803.08456)

##### PDF
[https://arxiv.org/pdf/1803.08456](https://arxiv.org/pdf/1803.08456)

