---
layout: post
title: "Unsupervised Textual Grounding: Linking Words to Image Concepts"
date: 2018-03-29 17:58:43
categories: arXiv_CV
tags: arXiv_CV Deep_Learning
author: Raymond A. Yeh, Minh N. Do, Alexander G. Schwing
mathjax: true
---

* content
{:toc}

##### Abstract
Textual grounding, i.e., linking words to objects in images, is a challenging but important task for robotics and human-computer interaction. Existing techniques benefit from recent progress in deep learning and generally formulate the task as a supervised learning problem, selecting a bounding box from a set of possible options. To train these deep net based approaches, access to a large-scale datasets is required, however, constructing such a dataset is time-consuming and expensive. Therefore, we develop a completely unsupervised mechanism for textual grounding using hypothesis testing as a mechanism to link words to detected image concepts. We demonstrate our approach on the ReferIt Game dataset and the Flickr30k data, outperforming baselines by 7.98% and 6.96% respectively.

##### Abstract (translated by Google)
文本基础，即将单词链接到图像中的对象，对于机器人和人机交互而言，是一项具有挑战性的重要任务。现有技术受益于最近深度学习的进展，并且通常将任务作为监督学习问题来制定，从一组可能的选项中选择边界框。为了训练这些基于深度网络的方法，需要访问大规模数据集，然而，构建这样的数据集是耗时且昂贵的。因此，我们使用假设检验作为将单词与检测到的图像概念相关联的机制，开发了完全无监督的文本接地机制。我们在ReferIt游戏数据集和Flickr30k数据上展示了我们的方法，分别比基线高出7.98％和6.96％。

##### URL
[http://arxiv.org/abs/1803.11185](http://arxiv.org/abs/1803.11185)

##### PDF
[http://arxiv.org/pdf/1803.11185](http://arxiv.org/pdf/1803.11185)

