---
layout: post
title: "wubi2en: Character-level Chinese-English Translation through ASCII Encoding"
date: 2018-05-09 00:44:59
categories: arXiv_CL
tags: arXiv_CL CNN NMT
author: Mi Xue Tan, Yuhuang Hu, Nikola I. Nikolov, Richard H.R. Hahnloser
mathjax: true
---

* content
{:toc}

##### Abstract
Character-level Neural Machine Translation (NMT) models have recently achieved impressive results on many language pairs. They particularly do well for Indo-European language pairs, where the languages share the same writing system. However, for translating between Chinese and English, the gap between the two different writing systems poses a major challenge due to a lack of systematic correspondence between the individual linguistic units. In this paper, we enable character-level NMT for Chinese, by breaking down Chinese characters to linguistic units similar to that of Indo-European languages using the Wubi encoding scheme. We show promising results from training Wubi-based models on the subword- and character-level with recurrent as well as convolutional models.

##### Abstract (translated by Google)
字符级神经机器翻译（NMT）模型最近在许多语言对中取得了令人印象深刻的结果。它们特别适用于印欧语系对，语言共享相同的书写系统。然而，为了翻译中英文，由于各个语言单位之间缺乏系统的对应关系，两种不同书写系统之间的差距构成了重大挑战。在本文中，我们使用Wubi编码方案将中文字符分解为与印欧语系相似的语言单元，从而为中文启用字符级NMT。我们展示了使用循环以及卷积模型在子字和字符级上训练基于五笔的模型的有希望的结果。

##### URL
[http://arxiv.org/abs/1805.03330](http://arxiv.org/abs/1805.03330)

##### PDF
[http://arxiv.org/pdf/1805.03330](http://arxiv.org/pdf/1805.03330)

