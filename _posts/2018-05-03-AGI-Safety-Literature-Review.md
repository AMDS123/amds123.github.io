---
layout: post
title: "AGI Safety Literature Review"
date: 2018-05-03 04:26:48
categories: arXiv_AI
tags: arXiv_AI Review Knowledge Survey Prediction
author: Tom Everitt, Gary Lea, Marcus Hutter
mathjax: true
---

* content
{:toc}

##### Abstract
The development of Artificial General Intelligence (AGI) promises to be a major event. Along with its many potential benefits, it also raises serious safety concerns (Bostrom, 2014). The intention of this paper is to provide an easily accessible and up-to-date collection of references for the emerging field of AGI safety. A significant number of safety problems for AGI have been identified. We list these, and survey recent research on solving them. We also cover works on how best to think of AGI from the limited knowledge we have today, predictions for when AGI will first be created, and what will happen after its creation. Finally, we review the current public policy on AGI.

##### Abstract (translated by Google)
人工智能（AGI）的发展有望成为重大事件。伴随着它的许多潜在好处，它也引发了严重的安全问题（Bostrom，2014）。本文的目的是为新兴的AGI安全领域提供易于获取和最新的参考资料。已经确定了AGI的大量安全问题。我们列举这些，并调查最近的解决它们的研究。我们还介绍了如何从我们今天有限的知识中最好地考虑AGI，预测AGI何时首先创建以及创建后会发生什么。最后，我们回顾目前关于AGI的公共政策。

##### URL
[http://arxiv.org/abs/1805.01109](http://arxiv.org/abs/1805.01109)

##### PDF
[http://arxiv.org/pdf/1805.01109](http://arxiv.org/pdf/1805.01109)

