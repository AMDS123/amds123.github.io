---
layout: post
title: "Learning Loss for Knowledge Distillation with Conditional Adversarial Networks"
date: 2017-09-02 01:03:08
categories: arXiv_CV
tags: arXiv_CV Adversarial Knowledge Inference Classification
author: Zheng Xu, Yen-Chang Hsu, Jiawei Huang
mathjax: true
---

* content
{:toc}

##### Abstract
There is an increasing interest on accelerating neural networks for real-time applications. We study the student-teacher strategy, in which a small and fast student network is trained with the auxiliary information provided by a large and accurate teacher network. We use conditional adversarial networks to learn the loss function to transfer knowledge from teacher to student. The proposed method is particularly effective for relatively small student networks. Moreover, experimental results show the effect of network size when the modern networks are used as student. We empirically study trade-off between inference time and classification accuracy, and provide suggestions on choosing a proper student.

##### Abstract (translated by Google)
对加速实时应用的神经网络有越来越多的兴趣。我们研究学生教师策略，在这个策略中，一个小而快的学生网络是由一个庞大而准确的教师网络提供的辅助信息进行训练的。我们使用有条件的敌对网络来学习将知识从老师传授给学生的损失函数。所提出的方法对于相对较小的学生网络特别有效。此外，实验结果显示了现代网络作为学生时的网络规模的影响。我们通过实证研究推理时间和分类准确率之间的权衡关系，并为选择合适的学生提供建议。

##### URL
[https://arxiv.org/abs/1709.00513](https://arxiv.org/abs/1709.00513)

##### PDF
[https://arxiv.org/pdf/1709.00513](https://arxiv.org/pdf/1709.00513)

