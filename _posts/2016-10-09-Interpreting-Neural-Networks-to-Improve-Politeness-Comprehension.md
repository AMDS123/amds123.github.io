---
layout: post
title: "Interpreting Neural Networks to Improve Politeness Comprehension"
date: 2016-10-09 14:42:58
categories: arXiv_CL
tags: arXiv_CL Salient Sentiment Embedding CNN Prediction Quantitative
author: Malika Aubakirova, Mohit Bansal
mathjax: true
---

* content
{:toc}

##### Abstract
We present an interpretable neural network approach to predicting and understanding politeness in natural language requests. Our models are based on simple convolutional neural networks directly on raw text, avoiding any manual identification of complex sentiment or syntactic features, while performing better than such feature-based models from previous work. More importantly, we use the challenging task of politeness prediction as a testbed to next present a much-needed understanding of what these successful networks are actually learning. For this, we present several network visualizations based on activation clusters, first derivative saliency, and embedding space transformations, helping us automatically identify several subtle linguistics markers of politeness theories. Further, this analysis reveals multiple novel, high-scoring politeness strategies which, when added back as new features, reduce the accuracy gap between the original featurized system and the neural model, thus providing a clear quantitative interpretation of the success of these neural networks.

##### Abstract (translated by Google)
我们提出一种可解释的神经网络方法来预测和理解自然语言的礼貌要求。我们的模型基于原始文本上的简单卷积神经网络，避免了对复杂情绪或语法特征的任何手动识别，同时比以往的基于特征的模型表现得更好。更重要的是，我们使用礼貌预测这一具有挑战性的任务作为测试平台，接下来展示对这些成功的网络实际上在学习什么的亟需理解。为此，我们提出了基于激活集群，一阶导数显着性和嵌入空间转换的网络可视化，帮助我们自动识别礼貌理论的几个微妙的语言学标记。此外，这种分析揭示了多种新颖，高分的礼貌策略，当作为新特征加入时，降低了原始特征系统与神经模型之间的准确性差距，从而为这些神经网络的成功提供了清晰的量化解释。

##### URL
[https://arxiv.org/abs/1610.02683](https://arxiv.org/abs/1610.02683)

##### PDF
[https://arxiv.org/pdf/1610.02683](https://arxiv.org/pdf/1610.02683)

