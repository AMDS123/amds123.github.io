---
layout: post
title: "Recurrent Neural Network Grammars"
date: 2016-10-12 04:47:45
categories: arXiv_SD
tags: arXiv_SD Inference RNN Language_Model
author: Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, Noah A. Smith
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce recurrent neural network grammars, probabilistic models of sentences with explicit phrase structure. We explain efficient inference procedures that allow application to both parsing and language modeling. Experiments show that they provide better parsing in English than any single previously published supervised generative model and better language modeling than state-of-the-art sequential RNNs in English and Chinese.

##### Abstract (translated by Google)
我们引入经常性的神经网络语法，带有显式短语结构的句子概率模型。我们解释高效的推理过程，允许应用程序进行解析和语言建模。实验表明，与英文和中文先进的连续RNN相比，它们提供了更好的英文解析能力，比任何以前发表的监督生成模型和更好的语言建模都要好。

##### URL
[https://arxiv.org/abs/1602.07776](https://arxiv.org/abs/1602.07776)

##### PDF
[https://arxiv.org/pdf/1602.07776](https://arxiv.org/pdf/1602.07776)

