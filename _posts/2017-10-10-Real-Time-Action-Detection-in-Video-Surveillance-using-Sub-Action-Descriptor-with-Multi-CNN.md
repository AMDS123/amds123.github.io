---
layout: post
title: "Real-Time Action Detection in Video Surveillance using Sub-Action Descriptor with Multi-CNN"
date: 2017-10-10 02:50:37
categories: arXiv_CV
tags: arXiv_CV Action_Recognition Detection Recognition
author: Cheng-Bin Jin, Shengzhe Li, Hakil Kim
mathjax: true
---

* content
{:toc}

##### Abstract
When we say a person is texting, can you tell the person is walking or sitting? Emphatically, no. In order to solve this incomplete representation problem, this paper presents a sub-action descriptor for detailed action detection. The sub-action descriptor consists of three levels: the posture, the locomotion, and the gesture level. The three levels give three sub-action categories for one action to address the representation problem. The proposed action detection model simultaneously localizes and recognizes the actions of multiple individuals in video surveillance using appearance-based temporal features with multi-CNN. The proposed approach achieved a mean average precision (mAP) of 76.6% at the frame-based and 83.5% at the video-based measurement on the new large-scale ICVL video surveillance dataset that the authors introduce and make available to the community with this paper. Extensive experiments on the benchmark KTH dataset demonstrate that the proposed approach achieved better performance, which in turn boosts the action recognition performance over the state-of-the-art. The action detection model can run at around 25 fps on the ICVL and more than 80 fps on the KTH dataset, which is suitable for real-time surveillance applications.

##### Abstract (translated by Google)
当我们说一个人正在发短信，你能告诉这个人正在走路或坐着吗？强调，不。为了解决这个不完全表示问题，本文提出了一个用于详细动作检测的子动作描述符。子动作描述符由三个级别组成：姿势，运动和手势级别。这三个级别为解决代表性问题提供了三个子行动类别。所提出的动作检测模型同时使用多CNN的基于外观的时间特征来定位和识别多个个体在视频监视中的动作。所提出的方法在新的大规模ICVL视频监测数据集上以基于帧的平均平均精度（mAP）为76.6％，在基于视频的测量方面达到平均平均精确度（mAP）为83.5％，作者通过这个数据集向社区介绍并提供纸。在基准KTH数据集上的大量实验证明，所提出的方法实现了更好的性能，这反过来又提高了动作识别性能，超过了现有技术水平。动作检测模型可以在ICVL上以大约25fps的速度运行，并且在KTH数据集上可以以大于80fps的速度运行，这适用于实时监视应用。

##### URL
[https://arxiv.org/abs/1710.03383](https://arxiv.org/abs/1710.03383)

##### PDF
[https://arxiv.org/pdf/1710.03383](https://arxiv.org/pdf/1710.03383)

