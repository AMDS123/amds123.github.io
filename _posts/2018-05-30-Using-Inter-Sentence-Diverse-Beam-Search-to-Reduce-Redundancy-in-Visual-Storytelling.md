---
layout: post
title: "Using Inter-Sentence Diverse Beam Search to Reduce Redundancy in Visual Storytelling"
date: 2018-05-30 08:59:44
categories: arXiv_CL
tags: arXiv_CL Image_Caption
author: Chao-Chun Hsu, Szu-Min Chen, Ming-Hsun Hsieh, Lun-Wei Ku
mathjax: true
---

* content
{:toc}

##### Abstract
Visual storytelling includes two important parts: coherence between the story and images as well as the story structure. For image to text neural network models, similar images in the sequence would provide close information for story generator to obtain almost identical sentence. However, repeatedly narrating same objects or events will undermine a good story structure. In this paper, we proposed an inter-sentence diverse beam search to generate a more expressive story. Comparing to some recent models of visual storytelling task, which generate story without considering the generated sentence of the previous picture, our proposed method can avoid generating identical sentence even given a sequence of similar pictures.

##### Abstract (translated by Google)
视觉叙事包括两个重要部分：故事与图像之间的连贯性以及故事结构。对于图像到文本的神经网络模型，序列中的相似图像将为故事生成器提供关闭信息以获得几乎相同的句子。然而，反复叙述同一个物体或事件会破坏一个好的故事结构。在本文中，我们提出了一个句子间多样性波束搜索来生成一个更有表现力的故事。与一些最近的视觉叙事任务模型相比，它们在不考虑前一张图片生成的句子的情况下生成故事，我们提出的方法即使给出一系列相似的图片也可以避免生成相同的句子。

##### URL
[http://arxiv.org/abs/1805.11867](http://arxiv.org/abs/1805.11867)

##### PDF
[http://arxiv.org/pdf/1805.11867](http://arxiv.org/pdf/1805.11867)

