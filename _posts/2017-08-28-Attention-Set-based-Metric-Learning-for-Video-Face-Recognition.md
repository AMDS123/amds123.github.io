---
layout: post
title: "Attention-Set based Metric Learning for Video Face Recognition"
date: 2017-08-28 09:25:35
categories: arXiv_CV
tags: arXiv_CV Attention Face Deep_Learning Relation Recognition Face_Recognition
author: Yibo Hu, Xiang Wu, Ran He
mathjax: true
---

* content
{:toc}

##### Abstract
Face recognition has made great progress with the development of deep learning. However, video face recognition (VFR) is still an ongoing task due to various illumination, low-resolution, pose variations and motion blur. Most existing CNN-based VFR methods only obtain a feature vector from a single image and simply aggregate the features in a video, which less consider the correlations of face images in one video. In this paper, we propose a novel Attention-Set based Metric Learning (ASML) method to measure the statistical characteristics of image sets. It is a promising and generalized extension of Maximum Mean Discrepancy with memory attention weighting. First, we define an effective distance metric on image sets, which explicitly minimizes the intra-set distance and maximizes the inter-set distance simultaneously. Second, inspired by Neural Turing Machine, a Memory Attention Weighting is proposed to adapt set-aware global contents. Then ASML is naturally integrated into CNNs, resulting in an end-to-end learning scheme. Our method achieves state-of-the-art performance for the task of video face recognition on the three widely used benchmarks including YouTubeFace, YouTube Celebrities and Celebrity-1000.

##### Abstract (translated by Google)
随着深度学习的发展，人脸识别技术取得了长足的进步。然而，由于各种照明，低分辨率，姿态变化和运动模糊，视频人脸识别（VFR）仍然是一项持续的任务。大多数现有的基于CNN的VFR方法仅从单个图像获得特征矢量，并简单地聚合视频中的特征，而较少考虑一个视频中的脸部图像的相关性。在本文中，我们提出了一种新的基于注意集的度量学习（ASML）方法来衡量图像集的统计特性。记忆关注加权是最大均值差异的一个有前途的广义扩展。首先，我们定义了一个有效的距离度量图像集，这明确地最小化了设置的距离，同时最大化了设置的距离。其次，在神经图灵机的启发下，提出了一种记忆注意加权来适应设置感知的全局内容。然后，ASML被自然地整合到CNN中，从而形成一个端到端的学习计划。我们的方法在YouTubeFace，YouTube Celebrities和Celebrity-1000三个广泛使用的基准测试中实现了视频脸部识别任务的最新性能。

##### URL
[https://arxiv.org/abs/1704.03805](https://arxiv.org/abs/1704.03805)

##### PDF
[https://arxiv.org/e-print/1704.03805](https://arxiv.org/e-print/1704.03805)

