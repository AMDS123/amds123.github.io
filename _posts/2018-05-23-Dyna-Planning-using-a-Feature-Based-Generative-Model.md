---
layout: post
title: "Dyna Planning using a Feature Based Generative Model"
date: 2018-05-23 23:23:34
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Ryan Faulkner, Doina Precup
mathjax: true
---

* content
{:toc}

##### Abstract
Dyna-style reinforcement learning is a powerful approach for problems where not much real data is available. The main idea is to supplement real trajectories, or sequences of sampled states over time, with simulated ones sampled from a learned model of the environment. However, in large state spaces, the problem of learning a good generative model of the environment has been open so far. We propose to use deep belief networks to learn an environment model for use in Dyna. We present our approach and validate it empirically on problems where the state observations consist of images. Our results demonstrate that using deep belief networks, which are full generative models, significantly outperforms the use of linear expectation models, proposed in Sutton et al. (2008)

##### Abstract (translated by Google)
强化风格的强化学习是一种强有力的方法，可用于那些没有太多实际数据的问题。主要思想是补充实际轨迹或随着时间推移的采样状态序列，以及从学习的环境模型中采样的模拟量。然而，在大型的国家空间中，迄今为止，学习环境的良好生成模型的问题已经开放。我们建议使用深层信念网络来学习在Dyna中使用的环境模型。我们提出我们的方法，并根据经验对状态观察由图像组成的问题进行验证。我们的研究结果表明，使用深信念网络，这是完全生成模型，显着优于使用线性期望模型，在Sutton等人提出。 （2008年）

##### URL
[http://arxiv.org/abs/1805.10129](http://arxiv.org/abs/1805.10129)

##### PDF
[http://arxiv.org/pdf/1805.10129](http://arxiv.org/pdf/1805.10129)

