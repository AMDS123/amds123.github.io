---
layout: post
title: "Large-scale Isolated Gesture Recognition Using Convolutional Neural Networks"
date: 2017-01-07 10:31:58
categories: arXiv_CV
tags: arXiv_CV CNN Classification Recognition
author: Pichao Wang, Wanqing Li, Song Liu, Zhimin Gao, Chang Tang, Philip Ogunbona
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes three simple, compact yet effective representations of depth sequences, referred to respectively as Dynamic Depth Images (DDI), Dynamic Depth Normal Images (DDNI) and Dynamic Depth Motion Normal Images (DDMNI). These dynamic images are constructed from a sequence of depth maps using bidirectional rank pooling to effectively capture the spatial-temporal information. Such image-based representations enable us to fine-tune the existing ConvNets models trained on image data for classification of depth sequences, without introducing large parameters to learn. Upon the proposed representations, a convolutional Neural networks (ConvNets) based method is developed for gesture recognition and evaluated on the Large-scale Isolated Gesture Recognition at the ChaLearn Looking at People (LAP) challenge 2016. The method achieved 55.57\% classification accuracy and ranked $2^{nd}$ place in this challenge but was very close to the best performance even though we only used depth data.

##### Abstract (translated by Google)
本文提出了深度序列的三个简单，紧凑而有效的表示，分别称为动态深度图像（DDI），动态深度正常图像（DDNI）和动态深度运动正常图像（DDMNI）。这些动态图像由一系列使用双向排序池的深度图构建，以有效捕捉时空信息。这样的基于图像的表示使我们能够微调现有的在图像数据上训练的ConvNets模型以进行深度序列的分类，而不需要引入大的参数来学习。在提出的表示方法基础上，开发了一种基于卷积神经网络（ConvNets）的手势识别方法，并在2016年人脸识别（LLE）挑战下进行了大规模隔离手势识别评估。该方法分类准确率达到55.57％在这个挑战中排名$ 2 ^ {nd} $，但即使我们只使用了深度数据，也是非常接近最佳性能。

##### URL
[https://arxiv.org/abs/1701.01814](https://arxiv.org/abs/1701.01814)

##### PDF
[https://arxiv.org/pdf/1701.01814](https://arxiv.org/pdf/1701.01814)

