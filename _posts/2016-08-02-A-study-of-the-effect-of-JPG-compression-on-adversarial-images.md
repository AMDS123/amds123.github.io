---
layout: post
title: "A study of the effect of JPG compression on adversarial images"
date: 2016-08-02 14:57:18
categories: arXiv_CV
tags: arXiv_CV Adversarial Image_Classification Classification
author: Gintare Karolina Dziugaite, Zoubin Ghahramani, Daniel M. Roy
mathjax: true
---

* content
{:toc}

##### Abstract
Neural network image classifiers are known to be vulnerable to adversarial images, i.e., natural images which have been modified by an adversarial perturbation specifically designed to be imperceptible to humans yet fool the classifier. Not only can adversarial images be generated easily, but these images will often be adversarial for networks trained on disjoint subsets of data or with different architectures. Adversarial images represent a potential security risk as well as a serious machine learning challenge---it is clear that vulnerable neural networks perceive images very differently from humans. Noting that virtually every image classification data set is composed of JPG images, we evaluate the effect of JPG compression on the classification of adversarial images. For Fast-Gradient-Sign perturbations of small magnitude, we found that JPG compression often reverses the drop in classification accuracy to a large extent, but not always. As the magnitude of the perturbations increases, JPG recompression alone is insufficient to reverse the effect.

##### Abstract (translated by Google)
已知神经网络图像分类器容易受到对抗图像的影响，即已经被专门设计为人类难以察觉的对抗性扰动修改过的自然图像，但却愚弄了分类器。不仅可以容易地生成对抗图像，而且这些图像对于在不相交的数据子集或不同的体系结构上训练的网络通常是敌对的。对抗性图像代表潜在的安全风险以及严重的机器学习挑战 - 显然易受攻击的神经网络与人类的感知图像截然不同。注意到几乎每个图像分类数据集都是由JPG图像组成的，我们评估了JPG压缩对敌对图像分类的影响。对于小幅度的快速梯度符号扰动，我们发现JPG压缩在很大程度上反转了分类精度的下降，但并不总是如此。随着扰动幅度的增加，单单JPG再压缩不足以扭转这种影响。

##### URL
[https://arxiv.org/abs/1608.00853](https://arxiv.org/abs/1608.00853)

##### PDF
[https://arxiv.org/pdf/1608.00853](https://arxiv.org/pdf/1608.00853)

