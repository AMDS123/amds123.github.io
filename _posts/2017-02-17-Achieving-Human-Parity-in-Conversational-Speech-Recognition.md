---
layout: post
title: "Achieving Human Parity in Conversational Speech Recognition"
date: 2017-02-17 07:32:58
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition CNN RNN Language_Model Recognition
author: W. Xiong, J. Droppo, X. Huang, F. Seide, M. Seltzer, A. Stolcke, D. Yu, G. Zweig
mathjax: true
---

* content
{:toc}

##### Abstract
Conversational speech recognition has served as a flagship speech recognition task since the release of the Switchboard corpus in the 1990s. In this paper, we measure the human error rate on the widely used NIST 2000 test set, and find that our latest automated system has reached human parity. The error rate of professional transcribers is 5.9% for the Switchboard portion of the data, in which newly acquainted pairs of people discuss an assigned topic, and 11.3% for the CallHome portion where friends and family members have open-ended conversations. In both cases, our automated system establishes a new state of the art, and edges past the human benchmark, achieving error rates of 5.8% and 11.0%, respectively. The key to our system's performance is the use of various convolutional and LSTM acoustic model architectures, combined with a novel spatial smoothing method and lattice-free MMI acoustic training, multiple recurrent neural network language modeling approaches, and a systematic use of system combination.

##### Abstract (translated by Google)
自20世纪90年代交换机语料库发布以来，会话语音识别一直是旗舰语音识别任务。在本文中，我们测量广泛使用的NIST 2000测试集中的人为错误率，并发现我们最新的自动化系统已经达到了人类平等。专业抄写员的错误率是数据交换板部分的5.9％，其中新近熟悉的人员讨论指定的主题，11.3％的CallHome部分，其中朋友和家人有开放式的对话。在这两种情况下，我们的自动化系统建立了一个新的技术水平，并超越了人类的基准，分别达到了5.8％和11.0％的错误率。系统性能的关键是使用各种卷积和LSTM声学模型结构，结合新颖的空间平滑方法和无格MMI声训练，多循环神经网络语言建模方法，以及系统组合的系统使用。

##### URL
[https://arxiv.org/abs/1610.05256](https://arxiv.org/abs/1610.05256)

##### PDF
[https://arxiv.org/pdf/1610.05256](https://arxiv.org/pdf/1610.05256)

