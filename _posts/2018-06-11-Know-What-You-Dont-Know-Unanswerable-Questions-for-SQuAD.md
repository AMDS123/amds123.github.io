---
layout: post
title: "Know What You Don't Know: Unanswerable Questions for SQuAD"
date: 2018-06-11 06:10:11
categories: arXiv_CL
tags: arXiv_CL Adversarial
author: Pranav Rajpurkar, Robin Jia, Percy Liang
mathjax: true
---

* content
{:toc}

##### Abstract
Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0.

##### Abstract (translated by Google)
抽取式阅读理解系统通常可以在上下文文档中找到问题的正确答案，但他们也倾向于对上下文中没有提到正确答案的问题做出不可靠的猜测。现有的数据集要么专注于可回答的问题，要么使用自动生成的易于识别的无法回答的问题。为了解决这些弱点，我们提供了斯坦福问答数据集（SQuAD）的最新版本SQUAD 2.0。 SQuAD 2.0将现有的SQUAD数据与由群众工作人员撰写的50,000多个无法回答的问题结合起来，看起来类似于可回答的问题。为了在SQuAD 2.0上做得好，系统不仅必须在可能的时候回答问题，而且还要确定段落不支持答案并且不回答问题。 SQuAD 2.0对现有模型来说是一项具有挑战性的自然语言理解任务：在SQuAD 1.1上获得86％F1的强大神经系统在SQuAD 2.0上仅获得66％F1。

##### URL
[http://arxiv.org/abs/1806.03822](http://arxiv.org/abs/1806.03822)

##### PDF
[http://arxiv.org/pdf/1806.03822](http://arxiv.org/pdf/1806.03822)

