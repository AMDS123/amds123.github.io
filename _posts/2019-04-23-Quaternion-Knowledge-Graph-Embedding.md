---
layout: post
title: "Quaternion Knowledge Graph Embedding"
date: 2019-04-23 12:36:59
categories: arXiv_CL
tags: arXiv_CL Knowledge_Graph Knowledge Embedding Represenation_Learning Relation
author: Shuai Zhang, Yi Tay, Lina Yao, Qi Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Complex-valued representations have demonstrated promising results on modeling relational data, i.e., knowledge graphs. This paper proposes a new knowledge graph embedding method. More concretely, we move beyond standard complex representations, adopting expressive hypercomplex representations for learning representations of entities and relations. Hypercomplex embeddings, or Quaternion embeddings (\textbf{QuatE}), are complex valued embeddings with three imaginary components. Different from standard complex (Hermitian) inner product, latent inter-dependencies (between all components) are aptly captured via the Hamilton product in Quaternion space, encouraging a more efficient and expressive representation learning process. Moreover, Quaternions are intuitively desirable for smooth and pure rotation in vector space, preventing noise from sheer/scaling operators. Finally, Quaternion inductive biases enjoy and satisfy the key desiderata of relational representation learning (i.e., modeling symmetry, anti-symmetry, and inversion). Experimental results demonstrate that QuatE achieves state-of-the-art performance on four well-established knowledge graph completion benchmarks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.10281](http://arxiv.org/abs/1904.10281)

##### PDF
[http://arxiv.org/pdf/1904.10281](http://arxiv.org/pdf/1904.10281)

