---
layout: post
title: "X2Face: A network for controlling face generation by using images, audio, and pose codes"
date: 2018-07-27 12:31:16
categories: arXiv_CV
tags: arXiv_CV Face
author: Olivia Wiles, A. Sophia Koepke, Andrew Zisserman
mathjax: true
---

* content
{:toc}

##### Abstract
The objective of this paper is a neural network model that controls the pose and expression of a given face, using another face or modality (e.g. audio). This model can then be used for lightweight, sophisticated video and image editing. 
 We make the following three contributions. First, we introduce a network, X2Face, that can control a source face (specified by one or more frames) using another face in a driving frame to produce a generated frame with the identity of the source frame but the pose and expression of the face in the driving frame. Second, we propose a method for training the network fully self-supervised using a large collection of video data. Third, we show that the generation process can be driven by other modalities, such as audio or pose codes, without any further training of the network. 
 The generation results for driving a face with another face are compared to state-of-the-art self-supervised/supervised methods. We show that our approach is more robust than other methods, as it makes fewer assumptions about the input data. We also show examples of using our framework for video face editing.

##### Abstract (translated by Google)
本文的目的是使用另一个面部或模态（例如音频）控制给定面部的姿势和表情的神经网络模型。然后，该模型可用于轻量级，复杂的视频和图像编辑。
 我们做出以下三点贡献。首先，我们介绍一个网络，X2Face，它可以使用驱动帧中的另一个面来控制源面（由一个或多个帧指定），以生成具有源帧的身份但是面部的姿势和表达的生成帧在驱动框架中。其次，我们提出了一种使用大量视频数据来完全自我监督的网络训练方法。第三，我们表明，生成过程可以由其他模态驱动，例如音频或姿势代码，而无需对网络进行任何进一步的培训。
 将用另一面部驱动面部的生成结果与现有技术的自我监督/监督方法进行比较。我们证明了我们的方法比其他方法更健壮，因为它对输入数据的假设更少。我们还展示了使用我们的视频面部编辑框架的示例。

##### URL
[http://arxiv.org/abs/1807.10550](http://arxiv.org/abs/1807.10550)

##### PDF
[http://arxiv.org/pdf/1807.10550](http://arxiv.org/pdf/1807.10550)

