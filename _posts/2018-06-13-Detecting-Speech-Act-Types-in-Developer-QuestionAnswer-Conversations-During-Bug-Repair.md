---
layout: post
title: "Detecting Speech Act Types in Developer Question/Answer Conversations During Bug Repair"
date: 2018-06-13 16:26:28
categories: arXiv_CL
tags: arXiv_CL Detection
author: Andrew Wood, Paige Rodeghero, Ameer Armaly, Collin McMillan
mathjax: true
---

* content
{:toc}

##### Abstract
This paper targets the problem of speech act detection in conversations about bug repair. We conduct a "Wizard of Oz" experiment with 30 professional programmers, in which the programmers fix bugs for two hours, and use a simulated virtual assistant for help. Then, we use an open coding manual annotation procedure to identify the speech act types in the conversations. Finally, we train and evaluate a supervised learning algorithm to automatically detect the speech act types in the conversations. In 30 two-hour conversations, we made 2459 annotations and uncovered 26 speech act types. Our automated detection achieved 69\% precision and 50\% recall. The key application of this work is to advance the state of the art for virtual assistants in software engineering. Virtual assistant technology is growing rapidly, though applications in software engineering are behind those in other areas, largely due to a lack of relevant data and experiments. This paper targets this problem in the area of developer Q/A conversations about bug repair.

##### Abstract (translated by Google)
本文针对错误修复对话中的言语行为检测问题。我们与30位专业程序员一起进行了“绿野仙踪”实验，其中程序员修复了两个小时的错误，并使用模拟虚拟助手寻求帮助。然后，我们使用开放式编码手动注释程序来识别对话中的言语行为类型。最后，我们训练和评估一个监督学习算法，以自动检测谈话中的言语行为类型。在30个两小时的对话中，我们做了2459个注释并发现了26个言语行为类型。我们的自动检测实现了69％的精确度和50％的召回率。这项工作的关键应用是提高软件工程中虚拟助理的技术水平。虚拟助理技术正在迅速发展，尽管软件工程领域的应用领域落后于其他领域，主要原因是缺乏相关的数据和实验。本文针对开发者Q / A关于错误修复对话领域的这个问题。

##### URL
[https://arxiv.org/abs/1806.05130](https://arxiv.org/abs/1806.05130)

##### PDF
[https://arxiv.org/pdf/1806.05130](https://arxiv.org/pdf/1806.05130)

