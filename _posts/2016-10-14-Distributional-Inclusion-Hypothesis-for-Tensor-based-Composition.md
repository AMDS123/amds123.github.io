---
layout: post
title: "Distributional Inclusion Hypothesis for Tensor-based Composition"
date: 2016-10-14 11:52:19
categories: arXiv_CL
tags: arXiv_CL Relation
author: Dimitri Kartsaklis, Mehrnoosh Sadrzadeh
mathjax: true
---

* content
{:toc}

##### Abstract
According to the distributional inclusion hypothesis, entailment between words can be measured via the feature inclusions of their distributional vectors. In recent work, we showed how this hypothesis can be extended from words to phrases and sentences in the setting of compositional distributional semantics. This paper focuses on inclusion properties of tensors; its main contribution is a theoretical and experimental analysis of how feature inclusion works in different concrete models of verb tensors. We present results for relational, Frobenius, projective, and holistic methods and compare them to the simple vector addition, multiplication, min, and max models. The degrees of entailment thus obtained are evaluated via a variety of existing word-based measures, such as Weed's and Clarke's, KL-divergence, APinc, balAPinc, and two of our previously proposed metrics at the phrase/sentence level. We perform experiments on three entailment datasets, investigating which version of tensor-based composition achieves the highest performance when combined with the sentence-level measures.

##### Abstract (translated by Google)
根据分布式包含假设，词之间的蕴涵可以通过其分布向量的特征包含来度量。在最近的工作中，我们展示了这个假设如何在组合分布语义的设置中从单词延伸到短语和句子。本文着重介绍张量的包含性质;它的主要贡献是对特征包含如何在动词张量的不同具体模型中起作用的理论和实验分析。我们给出关系，Frobenius，投影和整体方法的结果，并将它们与简单的向量加法，乘法，最小和最大模型进行比较。通过各种现有的基于单词的度量，例如Weed's和Clarke's，KL-divergence，APinc，balAPinc以及我们之前在短语/句子级别上提出的两个度量来评估由此获得的包含程度。我们在三个蕴涵数据集上进行实验，研究当与句子级别的措施相结合时，哪个版本的基于张量的构图达到最高性能。

##### URL
[https://arxiv.org/abs/1610.04416](https://arxiv.org/abs/1610.04416)

##### PDF
[https://arxiv.org/pdf/1610.04416](https://arxiv.org/pdf/1610.04416)

