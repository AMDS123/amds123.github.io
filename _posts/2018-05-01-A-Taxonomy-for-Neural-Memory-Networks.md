---
layout: post
title: "A Taxonomy for Neural Memory Networks"
date: 2018-05-01 13:37:37
categories: arXiv_CV
tags: arXiv_CV GAN RNN Memory_Networks
author: Ying Ma, Jose Principe
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, a taxonomy for memory networks is proposed based on their memory organization. The taxonomy includes all the popular memory networks: vanilla recurrent neural network (RNN), long short term memory (LSTM ), neural stack and neural Turing machine and their variants. The taxonomy puts all these networks under a single umbrella and shows their relative expressive power , i.e. vanilla RNN <=LSTM<=neural stack<=neural RAM. The differences and commonality between these networks are analyzed. These differences are also connected to the requirements of different tasks which can give the user instructions of how to choose or design an appropriate memory network for a specific task. As a conceptual simplified class of problems, four tasks of synthetic symbol sequences: counting, counting with interference, reversing and repeat counting are developed and tested to verify our arguments. And we use two natural language processing problems to discuss how this taxonomy helps choosing the appropriate neural memory networks for real world problem.

##### Abstract (translated by Google)
本文基于内存组织提出了内存网络分类。分类包括所有流行的记忆网络：香草递归神经网络（RNN），长期短期记忆（LSTM），神经堆栈和神经图灵机及其变种。分类法将所有这些网络置于一个保护伞下并显示其相对表达能力，即香草RNN <= LSTM <=神经堆栈<=神经RAM。分析了这些网络之间的差异和共性。这些差异还与不同任务的要求相关联，这些要求可以向用户提供如何为特定任务选择或设计适当的存储器网络的指令。作为一个概念上简化的问题类，合成符号序列的四个任务：计数，干扰计数，反转和重复计数被开发和测试，以验证我们的论点。我们使用两个自然语言处理问题来讨论这种分类法如何帮助为现实世界问题选择合适的神经记忆网络。

##### URL
[https://arxiv.org/abs/1805.00327](https://arxiv.org/abs/1805.00327)

##### PDF
[https://arxiv.org/pdf/1805.00327](https://arxiv.org/pdf/1805.00327)

