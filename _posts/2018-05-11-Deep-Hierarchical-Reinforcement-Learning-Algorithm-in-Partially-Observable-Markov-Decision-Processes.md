---
layout: post
title: "Deep Hierarchical Reinforcement Learning Algorithm in Partially Observable Markov Decision Processes"
date: 2018-05-11 14:30:21
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Deep_Learning
author: Le Pham Tuyen, Ngo Anh Vien, Abu Layek, TaeChoong Chung
mathjax: true
---

* content
{:toc}

##### Abstract
In recent years, reinforcement learning has achieved many remarkable successes due to the growing adoption of deep learning techniques and the rapid growth in computing power. Nevertheless, it is well-known that flat reinforcement learning algorithms are often not able to learn well and data-efficient in tasks having hierarchical structures, e.g. consisting of multiple subtasks. Hierarchical reinforcement learning is a principled approach that is able to tackle these challenging tasks. On the other hand, many real-world tasks usually have only partial observability in which state measurements are often imperfect and partially observable. The problems of RL in such settings can be formulated as a partially observable Markov decision process (POMDP). In this paper, we study hierarchical RL in POMDP in which the tasks have only partial observability and possess hierarchical properties. We propose a hierarchical deep reinforcement learning approach for learning in hierarchical POMDP. The deep hierarchical RL algorithm is proposed to apply to both MDP and POMDP learning. We evaluate the proposed algorithm on various challenging hierarchical POMDP.

##### Abstract (translated by Google)
近年来，由于深度学习技术的不断普及和计算能力的快速增长，强化学习取得了许多显着成就。然而，众所周知，扁平强化学习算法在具有分层结构的任务中往往不能很好地学习和数据有效，例如，由多个子任务组成。分层强化学习是一种能够解决这些具有挑战性任务的原则性方法。另一方面，许多现实世界的任务通常只有部分可观测性，其中状态测量通常是不完善的并且部分可观察的。 RL在这种情况下的问题可以被表述为部分可观察的马尔可夫决策过程（POMDP）。在本文中，我们研究了POMDP中的分层RL，其中任务只有部分可观性并且具有分层属性。我们提出了一种分层深度强化学习方法，用于在分层POMDP中进行学习。深层次的RL算法被推荐应用于MDP和POMDP学习。我们评估提出的算法在各种具有挑战性的分层POMDP。

##### URL
[http://arxiv.org/abs/1805.04419](http://arxiv.org/abs/1805.04419)

##### PDF
[http://arxiv.org/pdf/1805.04419](http://arxiv.org/pdf/1805.04419)

