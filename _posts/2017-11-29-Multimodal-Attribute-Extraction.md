---
layout: post
title: "Multimodal Attribute Extraction"
date: 2017-11-29 21:40:59
categories: arXiv_CL
tags: arXiv_CL Weakly_Supervised
author: Robert L. Logan IV, Samuel Humeau, Sameer Singh
mathjax: true
---

* content
{:toc}

##### Abstract
The broad goal of information extraction is to derive structured information from unstructured data. However, most existing methods focus solely on text, ignoring other types of unstructured data such as images, video and audio which comprise an increasing portion of the information on the web. To address this shortcoming, we propose the task of multimodal attribute extraction. Given a collection of unstructured and semi-structured contextual information about an entity (such as a textual description, or visual depictions) the task is to extract the entity's underlying attributes. In this paper, we provide a dataset containing mixed-media data for over 2 million product items along with 7 million attribute-value pairs describing the items which can be used to train attribute extractors in a weakly supervised manner. We provide a variety of baselines which demonstrate the relative effectiveness of the individual modes of information towards solving the task, as well as study human performance.

##### Abstract (translated by Google)
信息提取的广泛目标是从非结构化数据中导出结构化信息。然而，大多数现有的方法只关注文本，忽略了其他类型的非结构化数据，如图像，视频和音频，这些数据构成了网络上越来越多的信息。为了解决这个缺点，我们提出了多模态属性提取的任务。给定关于实体的非结构化和半结构化上下文信息（例如文本描述或视觉描述）的集合，任务是提取实体的基础属性。在本文中，我们提供了一个包含200多万个产品的混合媒体数据的数据集，以及700万个属性值对，描述了可以用来训练属性提取器的项目，以弱监督的方式。我们提供了各种基线，这些基线显示了各种信息模式对于解决任务的相对有效性，以及对人的绩效的研究。

##### URL
[https://arxiv.org/abs/1711.11118](https://arxiv.org/abs/1711.11118)

##### PDF
[https://arxiv.org/pdf/1711.11118](https://arxiv.org/pdf/1711.11118)

