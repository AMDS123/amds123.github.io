---
layout: post
title: "Configurable 3D Scene Synthesis and 2D Image Rendering with Per-Pixel Ground Truth using Stochastic Grammars"
date: 2018-06-20 15:24:55
categories: arXiv_CV
tags: arXiv_CV Segmentation Face Semantic_Segmentation Prediction
author: Chenfanfu Jiang, Siyuan Qi, Yixin Zhu, Siyuan Huang, Jenny Lin, Lap-Fai Yu, Demetri Terzopoulos, Song-Chun Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a systematic learning-based approach to the generation of massive quantities of synthetic 3D scenes and arbitrary numbers of photorealistic 2D images thereof, with associated ground truth information, for the purposes of training, benchmarking, and diagnosing learning-based computer vision and robotics algorithms. In particular, we devise a learning-based pipeline of algorithms capable of automatically generating and rendering a potentially infinite variety of indoor scenes by using a stochastic grammar, represented as an attributed Spatial And-Or Graph, in conjunction with state-of-the-art physics-based rendering. Our pipeline is capable of synthesizing scene layouts with high diversity, and it is configurable inasmuch as it enables the precise customization and control of important attributes of the generated scenes. It renders photorealistic RGB images of the generated scenes while automatically synthesizing detailed, per-pixel ground truth data, including visible surface depth and normal, object identity, and material information (detailed to object parts), as well as environments (e.g., illuminations and camera viewpoints). We demonstrate the value of our synthesized dataset, by improving performance in certain machine-learning-based scene understanding tasks--depth and surface normal prediction, semantic segmentation, reconstruction, etc.--and by providing benchmarks for and diagnostics of trained models by modifying object attributes and scene properties in a controllable manner.

##### Abstract (translated by Google)
我们提出了一种系统的基于学习的方法来生成海量的合成三维场景和任意数量的真实感2D图像以及相关的地面真实信息，用于培训，基准测试和诊断基于学习的计算机视觉和机器人技术算法。特别是，我们设计了一个基于学习的管道流水线算法，能够自动生成和渲染潜在的无限种类的室内场景，通过使用随机语法（表示为属性空间和或图），结合最先进的技术，艺术物理为基础的渲染。我们的流水线能够合成具有高度多样性的场景布局，并且它是可配置的，因为它能够精确定制和控制所生成场景的重要属性。它会自动合成详细的每像素地面实况数据，包括可见表面深度和法线，物体识别，材料信息（详细描述物体部分）以及环境（例如照明和照明相机视点）。我们通过改进某些基于机器学习的场景理解任务（深度和表面正常预测，语义分割，重建等）的性能以及通过提供受训模型的基准和诊断来证明我们的综合数据集的价值。以可控方式修改对象属性和场景属性。

##### URL
[http://arxiv.org/abs/1704.00112](http://arxiv.org/abs/1704.00112)

##### PDF
[http://arxiv.org/pdf/1704.00112](http://arxiv.org/pdf/1704.00112)

