---
layout: post
title: "Discriminative Deep Dyna-Q: Robust Planning for Dialogue Policy Learning"
date: 2018-08-28 17:59:08
categories: arXiv_AI
tags: arXiv_AI RNN
author: Shang-Yu Su, Xiujun Li, Jianfeng Gao, Jingjing Liu, Yun-Nung Chen
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a Discriminative Deep Dyna-Q (D3Q) approach to improving the effectiveness and robustness of Deep Dyna-Q (DDQ), a recently proposed framework that extends the Dyna-Q algorithm to integrate planning for task-completion dialogue policy learning. To obviate DDQ's high dependency on the quality of simulated experiences, we incorporate an RNN-based discriminator in D3Q to differentiate simulated experience from real user experience in order to control the quality of training data. Experiments show that D3Q significantly outperforms DDQ by controlling the quality of simulated experience used for planning. The effectiveness and robustness of D3Q is further demonstrated in a domain extension setting, where the agent's capability of adapting to a changing environment is tested.

##### Abstract (translated by Google)
本文提出了一种判别深度Dyna-Q（D3Q）方法来提高Deep Dyna-Q（DDQ）的有效性和鲁棒性，这是最近提出的框架，它扩展了Dyna-Q算法，以整合任务完成对话政策学习的规划。为了避免DDQ高度依赖模拟体验的质量，我们在D3Q中加入了一个基于RNN的鉴别器，以区分模拟体验和真实用户体验，从而控制训练数据的质量。实验表明，D3Q通过控制用于规划的模拟经验的质量显着优于DDQ。在域扩展设置中进一步证明了D3Q的有效性和稳健性，其中测试了代理适应不断变化的环境的能力。

##### URL
[http://arxiv.org/abs/1808.09442](http://arxiv.org/abs/1808.09442)

##### PDF
[http://arxiv.org/pdf/1808.09442](http://arxiv.org/pdf/1808.09442)

