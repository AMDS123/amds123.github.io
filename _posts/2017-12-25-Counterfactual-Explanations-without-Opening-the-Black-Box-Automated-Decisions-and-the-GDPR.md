---
layout: post
title: "Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR"
date: 2017-12-25 12:26:47
categories: arXiv_AI
tags: arXiv_AI Face
author: Sandra Wachter, Brent Mittelstadt, Chris Russell
mathjax: true
---

* content
{:toc}

##### Abstract
There has been much discussion of the right to explanation in the EU General Data Protection Regulation, and its existence, merits, and disadvantages. Implementing a right to explanation that opens the black box of algorithmic decision-making faces major legal and technical barriers. Explaining the functionality of complex algorithmic decision-making systems and their rationale in specific cases is a technically challenging problem. Some explanations may offer little meaningful information to data subjects, raising questions around their value. Explanations of automated decisions need not hinge on the general public understanding how algorithmic systems function. Even though such interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the black box. Looking at explanations as a means to help a data subject act rather than merely understand, one could gauge the scope and content of explanations according to the specific goal or action they are intended to support. From the perspective of individuals affected by automated decision-making, we propose three aims for explanations: (1) to inform and help the individual understand why a particular decision was reached, (2) to provide grounds to contest the decision if the outcome is undesired, and (3) to understand what would need to change in order to receive a desired result in the future, based on the current decision-making model. We assess how each of these goals finds support in the GDPR. We suggest data controllers should offer a particular type of explanation, unconditional counterfactual explanations, to support these three aims. These counterfactual explanations describe the smallest change to the world that can be made to obtain a desirable outcome, or to arrive at the closest possible world, without needing to explain the internal logic of the system.

##### Abstract (translated by Google)
欧盟“通用数据保护条例”的解释权及其存在，优点和缺点有很多的讨论。实施解释权打开算法决策的黑箱面临着重大的法律和技术障碍。解释复杂算法决策系统的功能及其在特定情况下的基本原理是技术上具有挑战性的问题。一些解释可能会给数据主体提供很少有意义的信息，提出围绕其价值的问题。对自动化决策的解释不必取决于公众对算法系统功能的理解。尽管这种解释性是非常重要的，应该追求，但原则上可以在不打开黑匣子的情况下提供解释。将解释看作是帮助数据主体行事而不仅仅是理解的手段，人们可以根据他们打算支持的具体目标或行动来衡量解释的范围和内容。从受自动化决策影响的个人角度出发，我们提出了三个解释目标：（1）告知并帮助个人理解为什么达成了特定的决定;（2）如果结果是（3）根据目前的决策模型，了解将来需要改变什么才能获得预期的结果。我们评估这些目标如何在GDPR中得到支持。我们建议数据控制者应该提供一种特殊类型的解释，无条件的反事实解释来支持这三个目标。这些反事实的解释描述了为了获得理想的结果或者到达最接近可能的世界而可以做出的对世界的最小改变，而不需要解释系统的内部逻辑。

##### URL
[http://arxiv.org/abs/1711.00399](http://arxiv.org/abs/1711.00399)

##### PDF
[http://arxiv.org/pdf/1711.00399](http://arxiv.org/pdf/1711.00399)

