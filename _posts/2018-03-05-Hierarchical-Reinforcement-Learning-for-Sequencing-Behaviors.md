---
layout: post
title: "Hierarchical Reinforcement Learning for Sequencing Behaviors"
date: 2018-03-05 01:08:08
categories: arXiv_RO
tags: arXiv_RO Reinforcement_Learning
author: Hadi Salman, Jaskaran Grover, Tanmay Shankar
mathjax: true
---

* content
{:toc}

##### Abstract
Recent literature in the robot learning community has focused on learning robot skills that abstract out lower-level details of robot control, such as Dynamic Movement Primitives (DMPs), the options framework in hierarchical RL, and subtask policies. To fully leverage the efficacy of these macro actions, it is necessary to then sequence these primitives to achieve a given task. Our objective is to jointly learn a set of robot skills and a sequence of these learnt skills to accomplish a given task. We consider the task of navigating a robot across various environments using visual input, maximizing the distance traveled through the environment while avoiding static obstacles. Traditional planning methods to solve this problem rely on hand-crafted state representations and heuristics for planning, and often fail to generalize. In contrast, deep neural networks have proved to be powerful function approximators, successfully modeling complex control policies. In addition, the ability of such networks to learn good representations of high-dimensional sensory inputs makes them a valuable tool when dealing with visual inputs. In this project, we explore the capability of deep neural networks to learn and sequence robot skills for navigation, directly using visual input.

##### Abstract (translated by Google)
机器人学习社区最近的文献集中于学习机器人技能，抽象出机器人控制的较低层次的细节，例如动态运动基元（DMP），分层RL中的选项框架和子任务策略。为了充分利用这些宏观行为的有效性，有必要对这些原语进行排序以实现给定的任务。我们的目标是共同学习一套机器人技能和一系列这些学到的技能来完成一项特定的任务。我们考虑使用视觉输入在各种环境中导航机器人的任务，从而最大限度地增加通过环境的距离，同时避免静态障碍物。解决这个问题的传统计划方法依赖于手工制作的状态表示和启发式进行规划，而且往往不能一概而论。相比之下，深度神经网络已被证明是强大的函数逼近器，成功地为复杂的控制策略建模。此外，这些网络学习高维度感官输入的良好表现的能力使得它们在处理视觉输入时是有价值的工具。在这个项目中，我们探索深度神经网络的能力，以直接使用视觉输入来学习和排序机器人导航技能。

##### URL
[http://arxiv.org/abs/1803.01446](http://arxiv.org/abs/1803.01446)

##### PDF
[http://arxiv.org/pdf/1803.01446](http://arxiv.org/pdf/1803.01446)

