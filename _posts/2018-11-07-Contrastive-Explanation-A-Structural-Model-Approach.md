---
layout: post
title: "Contrastive Explanation: A Structural-Model Approach"
date: 2018-11-07 22:05:45
categories: arXiv_AI
tags: arXiv_AI Classification
author: Tim Miller
mathjax: true
---

* content
{:toc}

##### Abstract
The topic of causal explanation in artificial intelligence has gathered interest in recent years as researchers and practitioners aim to increase trust and understanding of intelligent decision-making and action. While different sub-fields have looked into this problem with a sub-field-specific view, there are few models that aim to capture explanation in AI more generally. One general model is based on structural causal models. It defines an explanation as a fact that, if found to be true, would constitute an actual cause of a specific event. However, research in philosophy and social sciences shows that explanations are contrastive: that is, when people ask for an explanation of an event -- the fact --- they (sometimes implicitly) are asking for an explanation relative to some contrast case; that is, "Why P rather than Q?". In this paper, we extend the structural causal model approach to define two complementary notions of contrastive explanation, and demonstrate them on two classical AI problems: classification and planning. We believe that this model can be used to define contrastive explanation of other subfield-specific AI models.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1811.03163](https://arxiv.org/abs/1811.03163)

##### PDF
[https://arxiv.org/pdf/1811.03163](https://arxiv.org/pdf/1811.03163)

