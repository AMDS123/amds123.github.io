---
layout: post
title: "Clinical Text Prediction with Numerically Grounded Conditional Language Models"
date: 2016-10-20 11:48:30
categories: arXiv_CL
tags: arXiv_CL Knowledge Language_Model Prediction
author: Georgios P. Spithourakis, Steffen E. Petersen, Sebastian Riedel
mathjax: true
---

* content
{:toc}

##### Abstract
Assisted text input techniques can save time and effort and improve text quality. In this paper, we investigate how grounded and conditional extensions to standard neural language models can bring improvements in the tasks of word prediction and completion. These extensions incorporate a structured knowledge base and numerical values from the text into the context used to predict the next word. Our automated evaluation on a clinical dataset shows extended models significantly outperform standard models. Our best system uses both conditioning and grounding, because of their orthogonal benefits. For word prediction with a list of 5 suggestions, it improves recall from 25.03% to 71.28% and for word completion it improves keystroke savings from 34.35% to 44.81%, where theoretical bound for this dataset is 58.78%. We also perform a qualitative investigation of how models with lower perplexity occasionally fare better at the tasks. We found that at test time numbers have more influence on the document level than on individual word probabilities.

##### Abstract (translated by Google)
辅助文本输入技术可以节省时间和精力，提高文本质量。在本文中，我们调查标准的神经语言模型的基础和条件扩展如何能够改善字预测和完成的任务。这些扩展将文本中的结构化知识库和数值结合到用于预测下一个单词的上下文中。我们对临床数据集的自动化评估显示，扩展模型明显优于标准模型。我们最好的系统使用调节和接地，因为它们的正交优势。对于5个建议列表的字词预测，它将回忆从25.03％提高到71.28％，对于单词完成，它将按键节省从34.35％提高到44.81％，其中该数据集的理论边界是58.78％。我们还进行定性调查，以确定低迷的模式如何偶尔在任务中表现得更好。我们发现，在测试时间，数字对文档级别的影响大于单个词的概率。

##### URL
[https://arxiv.org/abs/1610.06370](https://arxiv.org/abs/1610.06370)

##### PDF
[https://arxiv.org/pdf/1610.06370](https://arxiv.org/pdf/1610.06370)

