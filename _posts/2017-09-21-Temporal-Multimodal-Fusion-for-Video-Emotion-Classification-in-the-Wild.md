---
layout: post
title: "Temporal Multimodal Fusion for Video Emotion Classification in the Wild"
date: 2017-09-21 08:14:40
categories: arXiv_CV
tags: arXiv_CV Review Face Classification
author: Valentin Vielzeuf, Stéphane Pateux, Frédéric Jurie
mathjax: true
---

* content
{:toc}

##### Abstract
This paper addresses the question of emotion classification. The task consists in predicting emotion labels (taken among a set of possible labels) best describing the emotions contained in short video clips. Building on a standard framework -- lying in describing videos by audio and visual features used by a supervised classifier to infer the labels -- this paper investigates several novel directions. First of all, improved face descriptors based on 2D and 3D Convo-lutional Neural Networks are proposed. Second, the paper explores several fusion methods, temporal and multimodal, including a novel hierarchical method combining features and scores. In addition, we carefully reviewed the different stages of the pipeline and designed a CNN architecture adapted to the task; this is important as the size of the training set is small compared to the difficulty of the problem, making generalization difficult. The so-obtained model ranked 4th at the 2017 Emotion in the Wild challenge with the accuracy of 58.8 %.

##### Abstract (translated by Google)
本文提出了情绪分类的问题。该任务包括预测情感标签（从一组可能的标签中获取），最好地描述短视频片段中包含的情绪。建立在一个标准框架的基础上 - 通过音频和视觉特征来描述视频，用监督分类器来推断标签 - 本文研究了几个新颖的方向。首先，提出了基于二维和三维神经网络的改进的人脸描述子。其次，本文探讨了几种融合方法，时间和多模式，包括一种结合特征和分数的新型分层方法。此外，我们仔细审查了管道的不同阶段，并设计了一个适应任务的CNN架构。这是重要的，因为训练集的大小相对于问题的难度小，使得泛化困难。如此获得的模型在2017年的情感挑战中排名第四，准确率为58.8％。

##### URL
[https://arxiv.org/abs/1709.07200](https://arxiv.org/abs/1709.07200)

##### PDF
[https://arxiv.org/pdf/1709.07200](https://arxiv.org/pdf/1709.07200)

