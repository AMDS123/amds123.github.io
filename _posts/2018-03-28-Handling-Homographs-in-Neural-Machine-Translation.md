---
layout: post
title: "Handling Homographs in Neural Machine Translation"
date: 2018-03-28 05:32:19
categories: arXiv_CL
tags: arXiv_CL Face Embedding NMT
author: Frederick Liu, Han Lu, Graham Neubig
mathjax: true
---

* content
{:toc}

##### Abstract
Homographs, words with different meanings but the same surface form, have long caused difficulty for machine translation systems, as it is difficult to select the correct translation based on the context. However, with the advent of neural machine translation (NMT) systems, which can theoretically take into account global sentential context, one may hypothesize that this problem has been alleviated. In this paper, we first provide empirical evidence that existing NMT systems in fact still have significant problems in properly translating ambiguous words. We then proceed to describe methods, inspired by the word sense disambiguation literature, that model the context of the input word with context-aware word embeddings that help to differentiate the word sense be- fore feeding it into the encoder. Experiments on three language pairs demonstrate that such models improve the performance of NMT systems both in terms of BLEU score and in the accuracy of translating homographs.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1708.06510](https://arxiv.org/abs/1708.06510)

##### PDF
[https://arxiv.org/pdf/1708.06510](https://arxiv.org/pdf/1708.06510)

