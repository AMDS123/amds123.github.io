---
layout: post
title: "Large-Scale Study of Curiosity-Driven Learning"
date: 2018-08-13 17:58:01
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Prediction
author: Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A. Efros
mathjax: true
---

* content
{:toc}

##### Abstract
Reinforcement learning algorithms rely on carefully engineering environment rewards that are extrinsic to the agent. However, annotating each environment with hand-designed, dense rewards is not scalable, motivating the need for developing reward functions that are intrinsic to the agent. Curiosity is a type of intrinsic reward function which uses prediction error as reward signal. In this paper: (a) We perform the first large-scale study of purely curiosity-driven learning, i.e. without any extrinsic rewards, across 54 standard benchmark environments, including the Atari game suite. Our results show surprisingly good performance, and a high degree of alignment between the intrinsic curiosity objective and the hand-designed extrinsic rewards of many game environments. (b) We investigate the effect of using different feature spaces for computing prediction error and show that random features are sufficient for many popular RL game benchmarks, but learned features appear to generalize better (e.g. to novel game levels in Super Mario Bros.). (c) We demonstrate limitations of the prediction-based rewards in stochastic setups. Game-play videos and code are at https://pathak22.github.io/large-scale-curiosity/

##### Abstract (translated by Google)
强化学习算法依赖于仔细设计代理外在的环境奖励。然而，用手工设计的密集奖励来注释每个环境是不可扩展的，这激发了开发代理所固有的奖励功能的需要。好奇心是一种内在奖励函数，它使用预测误差作为奖励信号。在本文中：（a）我们在54个标准基准测试环境（包括Atari游戏套件）中进行了第一次纯粹好奇心驱动学习的大规模研究，即没有任何外在奖励。我们的结果表现出令人惊讶的良好表现，以及内在的好奇心目标与许多游戏环境中手工设计的外在奖励之间的高度一致性。 （b）我们研究了使用不同的特征空间来计算预测误差的效果，并且表明随机特征对于许多流行的RL游戏基准来说已经足够，但是学习的特征看起来更好地概括（例如，超级马里奥兄弟中的新颖游戏等级）。 （c）我们证明了随机设置中基于预测的奖励的局限性。游戏视频和代码在https://pathak22.github.io/large-scale-curiosity/

##### URL
[http://arxiv.org/abs/1808.04355](http://arxiv.org/abs/1808.04355)

##### PDF
[http://arxiv.org/pdf/1808.04355](http://arxiv.org/pdf/1808.04355)

