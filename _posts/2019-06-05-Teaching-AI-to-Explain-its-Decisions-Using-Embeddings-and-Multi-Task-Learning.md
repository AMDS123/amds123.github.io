---
layout: post
title: "Teaching AI to Explain its Decisions Using Embeddings and Multi-Task Learning"
date: 2019-06-05 20:42:14
categories: arXiv_AI
tags: arXiv_AI Knowledge Embedding Prediction
author: Noel C. F. Codella, Michael Hind, Karthikeyan Natesan Ramamurthy, Murray Campbell, Amit Dhurandhar, Kush R. Varshney, Dennis Wei, Aleksandra Mojsilovi&#x107;
mathjax: true
---

* content
{:toc}

##### Abstract
Using machine learning in high-stakes applications often requires predictions to be accompanied by explanations comprehensible to the domain user, who has ultimate responsibility for decisions and outcomes. Recently, a new framework for providing explanations, called TED, has been proposed to provide meaningful explanations for predictions. This framework augments training data to include explanations elicited from domain users, in addition to features and labels. This approach ensures that explanations for predictions are tailored to the complexity expectations and domain knowledge of the consumer. In this paper, we build on this foundational work, by exploring more sophisticated instantiations of the TED framework and empirically evaluate their effectiveness in two diverse domains, chemical odor and skin cancer prediction. Results demonstrate that meaningful explanations can be reliably taught to machine learning algorithms, and in some cases, improving modeling accuracy.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.02299](http://arxiv.org/abs/1906.02299)

##### PDF
[http://arxiv.org/pdf/1906.02299](http://arxiv.org/pdf/1906.02299)

