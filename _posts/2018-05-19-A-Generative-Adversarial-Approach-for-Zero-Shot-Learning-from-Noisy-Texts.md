---
layout: post
title: "A Generative Adversarial Approach for Zero-Shot Learning from Noisy Texts"
date: 2018-05-19 01:18:30
categories: arXiv_CV
tags: arXiv_CV Regularization Adversarial GAN Embedding Classification
author: Yizhe Zhu, Mohamed Elhoseiny, Bingchen Liu, Xi Peng, Ahmed Elgammal
mathjax: true
---

* content
{:toc}

##### Abstract
Most existing zero-shot learning methods consider the problem as a visual semantic embedding one. Given the demonstrated capability of Generative Adversarial Networks(GANs) to generate images, we instead leverage GANs to imagine unseen categories from text descriptions and hence recognize novel classes with no examples being seen. Specifically, we propose a simple yet effective generative model that takes as input noisy text descriptions about an unseen class (e.g.Wikipedia articles) and generates synthesized visual features for this class. With added pseudo data, zero-shot learning is naturally converted to a traditional classification problem. Additionally, to preserve the inter-class discrimination of the generated features, a visual pivot regularization is proposed as an explicit supervision. Unlike previous methods using complex engineered regularizers, our approach can suppress the noise well without additional regularization. Empirically, we show that our method consistently outperforms the state of the art on the largest available benchmarks on Text-based Zero-shot Learning.

##### Abstract (translated by Google)
大多数现有的零点学习方法将问题视为视觉语义嵌入问题。鉴于生成对抗网络（GAN）生成图像的能力，我们改为利用GAN来想象文本描述中看不见的类别，从而识别没有看到任何示例的新类。具体而言，我们提出了一个简单而有效的生成模型，它可以输入有关看不见的类的嘈杂的文本描述（例如，维基百科文章），并为该类生成合成的视觉特征。通过添加伪数据，零点学习自然地转换为传统的分类问题。此外，为了保持产生的特征的类间歧视，提出视觉枢轴正则化作为明确的监督。与以前使用复杂工程正则化器的方法不同，我们的方法可以很好地抑制噪音，无需额外的正则化。从经验上讲，我们证明了我们的方法在基于文本的零点学习的最大可用基准测试中始终优于最先进的技术。

##### URL
[http://arxiv.org/abs/1712.01381](http://arxiv.org/abs/1712.01381)

##### PDF
[http://arxiv.org/pdf/1712.01381](http://arxiv.org/pdf/1712.01381)

