---
layout: post
title: "Expolring Architectures for CNN-Based Word Spotting"
date: 2018-06-28 10:20:41
categories: arXiv_CV
tags: arXiv_CV CNN
author: Eugen Rusakov, Sebastian Sudholt, Fabian Wolf, Gernot A. Fink
mathjax: true
---

* content
{:toc}

##### Abstract
The goal in word spotting is to retrieve parts of document images which are relevant with respect to a certain user-defined query. The recent past has seen attribute-based Convolutional Neural Networks take over this field of research. As is common for other fields of computer vision, the CNNs used for this task are already considerably deep. The question that arises, however, is: How complex does a CNN have to be for word spotting? Are increasingly deeper models giving increasingly bet- ter results or does performance behave asymptotically for these architectures? On the other hand, can similar results be obtained with a much smaller CNN? The goal of this paper is to give an answer to these questions. Therefore, the recently successful TPP- PHOCNet will be compared to a Residual Network, a Densely Connected Convolutional Network and a LeNet architecture empirically. As will be seen in the evaluation, a complex model can be beneficial for word spotting on harder tasks such as the IAM Offline Database but gives no advantage for easier benchmarks such as the George Washington Database.

##### Abstract (translated by Google)
单词识别的目标是检索与某个用户定义的查询相关的部分文档图像。最近过去已经看到基于属性的卷积神经网络接管了这个研究领域。正如其他计算机视觉领域常见的那样，用于此任务的CNN已经相当深入。然而，出现的问题是：美国有线电视新闻网络对于发现字词有多复杂？越来越深的模型会给出越来越好的结果，或者性能对这些架构渐近地表现出来吗？另一方面，使用更小的CNN可以获得类似的结果吗？本文的目标是回答这些问题。因此，最近成功的TPP-PHOCNet将经验性地与剩余网络，密集连接卷积网络和LeNet架构进行比较。从评估中可以看出，一个复杂的模型对于在IAM离线数据库等较困难的任务上进行词语识别可能是有益的，但对于乔治华盛顿数据库等更简单的基准测试并不会带来任何好处。

##### URL
[http://arxiv.org/abs/1806.10866](http://arxiv.org/abs/1806.10866)

##### PDF
[http://arxiv.org/pdf/1806.10866](http://arxiv.org/pdf/1806.10866)

