---
layout: post
title: "Generating Contrastive Explanations with Monotonic Attribute Functions"
date: 2019-05-29 19:48:08
categories: arXiv_AI
tags: arXiv_AI Classification Quantitative
author: Ronny Luss, Pin-Yu Chen, Amit Dhurandhar, Prasanna Sattigeri, Karthikeyan Shanmugam, Chun-Chen Tu
mathjax: true
---

* content
{:toc}

##### Abstract
Explaining decisions of deep neural networks is a hot research topic with applications in medical imaging, video surveillance, and self driving cars. Many methods have been proposed in literature to explain these decisions by identifying relevance of different pixels. In this paper, we propose a method that can generate contrastive explanations for such data where we not only highlight aspects that are in themselves sufficient to justify the classification by the deep model, but also new aspects which if added will change the classification. One of our key contributions is how we define "addition" for such rich data in a formal yet humanly interpretable way that leads to meaningful results. This was one of the open questions laid out in Dhurandhar et.al. (2018) [5], which proposed a general framework for creating (local) contrastive explanations for deep models. We showcase the efficacy of our approach on CelebA and Fashion-MNIST in creating intuitive explanations that are also quantitatively superior compared with other state-of-the-art interpretability methods.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.12698](http://arxiv.org/abs/1905.12698)

##### PDF
[http://arxiv.org/pdf/1905.12698](http://arxiv.org/pdf/1905.12698)

