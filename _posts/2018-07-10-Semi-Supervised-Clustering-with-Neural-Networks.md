---
layout: post
title: "Semi-Supervised Clustering with Neural Networks"
date: 2018-07-10 09:10:35
categories: arXiv_CV
tags: arXiv_CV
author: Ankita Shukla, Gullal Singh Cheema, Saket Anand
mathjax: true
---

* content
{:toc}

##### Abstract
Clustering using neural networks has recently demonstrated promising performance in machine learning and computer vision applications. However, the performance of current approaches is limited either by unsupervised learning or their dependence on large set of labeled data samples. In this paper, we propose ClusterNet that uses pairwise semantic constraints from very few labeled data samples (&lt;5% of total data) and exploits the abundant unlabeled data to drive the clustering approach. We define a new loss function that uses pairwise semantic similarity between objects combined with constrained k-means clustering to efficiently utilize both labeled and unlabeled data in the same framework. The proposed network uses convolution autoencoder to learn a latent representation that groups data into k specified clusters, while also learning the cluster centers simultaneously. We evaluate and compare the performance of ClusterNet on several datasets and state of the art deep clustering approaches.

##### Abstract (translated by Google)
最近，使用神经网络的聚类在机器学习和计算机视觉应用中表现出了很好的性能。然而，当前方法的性能受到无监督学习或其对大量标记数据样本的依赖性的限制。在本文中，我们提出了ClusterNet，它使用来自极少数标记数据样本的成对语义约束（<总数据的5％），并利用丰富的未标记数据来驱动聚类方法。我们定义了一种新的损失函数，该函数使用对象之间的成对语义相似性与约束k均值聚类相结合，以在同一框架中有效地利用标记和未标记的数据。所提出的网络使用卷积自动编码器来学习将数据分组为k个指定簇的潜在表示，同时还学习集群中心。我们评估和比较ClusterNet在几个数据集和最先进的深度聚类方法上的性能。

##### URL
[http://arxiv.org/abs/1806.01547](http://arxiv.org/abs/1806.01547)

##### PDF
[http://arxiv.org/pdf/1806.01547](http://arxiv.org/pdf/1806.01547)

