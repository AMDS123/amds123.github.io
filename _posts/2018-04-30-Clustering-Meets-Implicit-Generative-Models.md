---
layout: post
title: "Clustering Meets Implicit Generative Models"
date: 2018-04-30 11:41:48
categories: arXiv_AI
tags: arXiv_AI
author: Francesco Locatello, Damien Vincent, Ilya Tolstikhin, Gunnar Rätsch, Sylvain Gelly, Bernhard Schölkopf
mathjax: true
---

* content
{:toc}

##### Abstract
Clustering is a cornerstone of unsupervised learning which can be thought as disentangling multiple generative mechanisms underlying the data. In this paper we introduce an algorithmic framework to train mixtures of implicit generative models which we particularize for variational autoencoders. Relying on an additional set of discriminators, we propose a competitive procedure in which the models only need to approximate the portion of the data distribution from which they can produce realistic samples. As a byproduct, each model is simpler to train, and a clustering interpretation arises naturally from the partitioning of the training points among the models. We empirically show that our approach splits the training distribution in a reasonable way and increases the quality of the generated samples.

##### Abstract (translated by Google)
聚类是无监督学习的基石，可以被认为是解开数据背后的多重生成机制。在本文中，我们引入了一种算法框架来训练我们为变分自动编码器所特有的隐式生成模型的混合。依靠一组额外的鉴别器，我们提出了一个竞争程序，其中模型只需要近似数据分布的一部分，从中可以产生真实的样本。作为副产品，每个模型都更容易训练，并且通过模型中训练点的划分自然产生聚类解释。我们凭经验证明，我们的方法以合理的方式分割训练分布并提高生成样本的质量。

##### URL
[https://arxiv.org/abs/1804.11130](https://arxiv.org/abs/1804.11130)

##### PDF
[https://arxiv.org/pdf/1804.11130](https://arxiv.org/pdf/1804.11130)

