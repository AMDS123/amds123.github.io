---
layout: post
title: "Statistics of Deep Generated Images"
date: 2018-03-31 13:44:35
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN CNN Deep_Learning
author: Yu Zeng, Huchuan Lu, Ali Borji
mathjax: true
---

* content
{:toc}

##### Abstract
Here, we explore the low-level statistics of images generated by state-of-the-art deep generative models. First, Variational auto-encoder (VAE~\cite{kingma2013auto}), Wasserstein generative adversarial network (WGAN~\cite{arjovsky2017wasserstein}) and deep convolutional generative adversarial network (DCGAN~\cite{radford2015unsupervised}) are trained on the ImageNet dataset and a large set of cartoon frames from animations. Then, for images generated by these models as well as natural scenes and cartoons, statistics including mean power spectrum, the number of connected components in a given image area, distribution of random filter responses, and contrast distribution are computed. Our analyses on training images support current findings on scale invariance, non-Gaussianity, and Weibull contrast distribution of natural scenes. We find that although similar results hold over cartoon images, there is still a significant difference between statistics of natural scenes and images generated by VAE, DCGAN and WGAN models. In particular, generated images do not have scale invariant mean power spectrum magnitude, which indicates existence of extra structures in these images caused by deconvolution operations. We also find that replacing deconvolution layers in the deep generative models by sub-pixel convolution helps them generate images with a mean power spectrum closer to the mean power spectrum of natural images. Inspecting how well the statistics of deep generated images match the known statistical properties of natural images, such as scale invariance, non-Gaussianity, and Weibull contrast distribution, can a) reveal the degree to which deep learning models capture the essence of the natural scenes, b) provide a new dimension to evaluate models, and c) allow possible improvement of image generative models (e.g., via defining new loss functions).

##### Abstract (translated by Google)
在这里，我们探索由最先进的深度生成模型生成的图像的低级统计。首先，在ImageNet数据集上对Variational auto-encoder（VAE_cite {kingma2013auto}），Wasserstein生成对抗网络（WGAN_ \ cite {arjovsky2017wasserstein}）和深度卷积生成对抗网络（DCGAN_ \ cite {radford2015unsupervised}）进行训练以及动画中的一大组卡通画面。然后，对于由这些模型以及自然场景和漫画生成的图像，计算包括平均功率谱，给定图像区域中的连通分量的数量，随机滤波器响应的分布和对比度分布的统计量。我们对训练图像的分析支持关于自然场景的尺度不变性，非高斯性和威布尔对比度分布的当前发现。我们发现尽管类似的结果在卡通图像上存在，但自然场景和由VAE，DCGAN和WGAN模型生成的图像的统计数据仍然存在显着差异。特别是，生成的图像没有尺度不变的平均功率谱幅度，这表明由去卷积操作引起的这些图像中存在额外的结构。我们还发现，通过亚像素卷积替代深生成模型中的去卷积层有助于它们生成平均功率谱更接近自然图像平均功率谱的图像。检查深度生成图像的统计量与自然图像的已知统计特性（例如尺度不变性，非高斯性和威布尔对比度分布）的匹配程度如何，可以a）揭示深度学习模型捕捉自然场景本质的程度，b）为评估模型提供了新的维度，并且c）允许图像生成模型的可能改进（例如，通过定义新的损失函数）。

##### URL
[http://arxiv.org/abs/1708.02688](http://arxiv.org/abs/1708.02688)

##### PDF
[http://arxiv.org/pdf/1708.02688](http://arxiv.org/pdf/1708.02688)

