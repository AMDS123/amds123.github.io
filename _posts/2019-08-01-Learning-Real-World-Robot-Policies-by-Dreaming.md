---
layout: post
title: "Learning Real-World Robot Policies by Dreaming"
date: 2019-08-01 17:37:41
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning
author: AJ Piergiovanni, Alan Wu, Michael S. Ryoo
mathjax: true
---

* content
{:toc}

##### Abstract
Learning to control robots directly based on images is a primary challenge in robotics. However, many existing reinforcement learning approaches require iteratively obtaining millions of robot samples to learn a policy, which can take significant time. In this paper, we focus on learning a realistic world model capturing the dynamics of scene changes conditioned on robot actions. Our dreaming model can emulate samples equivalent to a sequence of images from the actual environment, technically by learning an action-conditioned future representation/scene regressor. This allows the agent to learn action policies (i.e., visuomotor policies) by interacting with the dreaming model rather than the real-world. We experimentally confirm that our dreaming model enables robot learning of policies that transfer to the real-world.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1805.07813](http://arxiv.org/abs/1805.07813)

##### PDF
[http://arxiv.org/pdf/1805.07813](http://arxiv.org/pdf/1805.07813)

