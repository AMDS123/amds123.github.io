---
layout: post
title: "Adversarial Image Alignment and Interpolation"
date: 2017-06-30 23:59:27
categories: arXiv_CV
tags: arXiv_CV Adversarial Super_Resolution Object_Detection Face CNN Optimization Detection
author: Viren Jain
mathjax: true
---

* content
{:toc}

##### Abstract
Volumetric (3d) images are acquired for many scientific and biomedical purposes using imaging methods such as serial section microscopy, CT scans, and MRI. A frequent step in the analysis and reconstruction of such data is the alignment and registration of images that were acquired in succession along a spatial or temporal dimension. For example, in serial section electron microscopy, individual 2d sections are imaged via electron microscopy and then must be aligned to one another in order to produce a coherent 3d volume. State of the art approaches find image correspondences derived from patch matching and invariant feature detectors, and then solve optimization problems that rigidly or elastically deform series of images into an aligned volume. Here we show how fully convolutional neural networks trained with an adversarial loss function can be used for two tasks: (1) synthesis of missing or damaged image data from adjacent sections, and (2) fine-scale alignment of block-face electron microscopy data. Finally, we show how these two capabilities can be combined in order to produce artificial isotropic volumes from anisotropic image volumes using a super-resolution adversarial alignment and interpolation approach.

##### Abstract (translated by Google)
使用诸如连续切片显微镜，CT扫描和MRI之类的成像方法获取用于许多科学和生物医学目的的体积（3D）图像。分析和重建这些数据的一个频繁的步骤是沿着空间或时间维度连续获取的图像的对齐和配准。例如，在连续切片电子显微镜中，通过电子显微镜成像各个二维切片，然后必须彼此对准以产生连贯的三维体积。现有技术的方法寻找来自贴片匹配和不变特征检测器的图像对应，然后解决将图像系列严格地或弹性地变形为对准的体积的优化问题。在这里，我们展示了如何完全卷积神经网络训练与敌对损失函数可用于两个任务：（1）合成缺失或损坏的图像数据从相邻的部分，和（2）精细尺度对齐的块面电子显微镜数据。最后，我们展示了如何将这两种能力结合起来，从而利用超分辨率对抗和内插方法从各向异性的图像体积中产生人造各向同性的体积。

##### URL
[https://arxiv.org/abs/1707.00067](https://arxiv.org/abs/1707.00067)

##### PDF
[https://arxiv.org/pdf/1707.00067](https://arxiv.org/pdf/1707.00067)

