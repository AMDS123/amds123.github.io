---
layout: post
title: "HyperNetworks with statistical filtering for defending adversarial examples"
date: 2017-11-06 09:11:47
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN Image_Classification Classification Deep_Learning Detection
author: Zhun Sun, Mete Ozay, Takayuki Okatani
mathjax: true
---

* content
{:toc}

##### Abstract
Deep learning algorithms have been known to be vulnerable to adversarial perturbations in various tasks such as image classification. This problem was addressed by employing several defense methods for detection and rejection of particular types of attacks. However, training and manipulating networks according to particular defense schemes increases computational complexity of the learning algorithms. In this work, we propose a simple yet effective method to improve robustness of convolutional neural networks (CNNs) to adversarial attacks by using data dependent adaptive convolution kernels. To this end, we propose a new type of HyperNetwork in order to employ statistical properties of input data and features for computation of statistical adaptive maps. Then, we filter convolution weights of CNNs with the learned statistical maps to compute dynamic kernels. Thereby, weights and kernels are collectively optimized for learning of image classification models robust to adversarial attacks without employment of additional target detection and rejection algorithms. We empirically demonstrate that the proposed method enables CNNs to spontaneously defend against different types of attacks, e.g. attacks generated by Gaussian noise, fast gradient sign methods (Goodfellow et al., 2014) and a black-box attack(Narodytska & Kasiviswanathan, 2016).

##### Abstract (translated by Google)
已知深度学习算法在图像分类等各种任务中容易受到敌对扰动的影响。这个问题是通过采用几种防御方法来检测和拒绝特定类型的攻击来解决的。然而，根据特定防御方案训练和操纵网络增加了学习算法的计算复杂性。在这项工作中，我们提出了一种简单而有效的方法来提高卷积神经网络（CNNs）对对抗性攻击的鲁棒性。为此，我们提出了一种新型的HyperNetwork，以便利用输入数据和特征的统计特性来计算统计自适应地图。然后，我们用学习的统计图过滤CNN的卷积权重来计算动态内核。因此，权重和内核被共同优化用于学习对抗攻击鲁棒的图像分类模型，而不使用额外的目标检测和拒绝算法。我们实验证明，所提出的方法使得CNN能够自发防御不同类型的攻击，例如，高斯噪声产生的攻击，快速梯度符号方法（Goodfellow等，2014）和黑箱攻击（Narodytska＆Kasiviswanathan，2016）。

##### URL
[https://arxiv.org/abs/1711.01791](https://arxiv.org/abs/1711.01791)

##### PDF
[https://arxiv.org/pdf/1711.01791](https://arxiv.org/pdf/1711.01791)

