---
layout: post
title: "Temporal Tessellation: A Unified Approach for Video Analysis"
date: 2017-04-14 19:20:10
categories: arXiv_CV
tags: arXiv_CV Video_Caption Caption Detection
author: Dotan Kaufman, Gil Levi, Tal Hassner, Lior Wolf
mathjax: true
---

* content
{:toc}

##### Abstract
We present a general approach to video understanding, inspired by semantic transfer techniques that have been successfully used for 2D image analysis. Our method considers a video to be a 1D sequence of clips, each one associated with its own semantics. The nature of these semantics -- natural language captions or other labels -- depends on the task at hand. A test video is processed by forming correspondences between its clips and the clips of reference videos with known semantics, following which, reference semantics can be transferred to the test video. We describe two matching methods, both designed to ensure that (a) reference clips appear similar to test clips and (b), taken together, the semantics of the selected reference clips is consistent and maintains temporal coherence. We use our method for video captioning on the LSMDC'16 benchmark, video summarization on the SumMe and TVSum benchmarks, Temporal Action Detection on the Thumos2014 benchmark, and sound prediction on the Greatest Hits benchmark. Our method not only surpasses the state of the art, in four out of five benchmarks, but importantly, it is the only single method we know of that was successfully applied to such a diverse range of tasks.

##### Abstract (translated by Google)
我们提出了一个视频理解的一般方法，受到已成功用于二维图像分析的语义转换技术的启发。我们的方法将视频视为一维片段序列，每个片段与其自己的语义相关联。这些语义的本质 - 自然语言标题或其他标签 - 取决于当前的任务。通过在已知语义的参考视频片段和剪辑之间形成对应关系来处理测试视频，然后可以将参考语义传送到测试视频。我们描述了两种匹配方法，两种方法都是为了确保（a）参考剪辑看起来与测试剪辑相似，（b）合在一起，所选参考剪辑的语义是一致的，并保持时间上的一致性。我们在LSMDC'16基准测试中使用了我们的视频字幕方法，SumMe和TVSum基准测试的视频摘要，Thumos2014基准测试的时间动作测试以及Greatest Hits基准的声音预测。我们的方法不仅在五个基准中的四个中超过了现有技术水平，而且重要的是，我们知道的唯一方法是成功地应用于如此多样化的任务。

##### URL
[https://arxiv.org/abs/1612.06950](https://arxiv.org/abs/1612.06950)

