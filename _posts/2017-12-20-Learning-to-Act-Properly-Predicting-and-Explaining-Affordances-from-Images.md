---
layout: post
title: "Learning to Act Properly: Predicting and Explaining Affordances from Images"
date: 2017-12-20 16:54:09
categories: arXiv_CV
tags: arXiv_CV
author: Ching-Yao Chuang, Jiaman Li, Antonio Torralba, Sanja Fidler
mathjax: true
---

* content
{:toc}

##### Abstract
We address the problem of affordance reasoning in diverse scenes that appear in the real world. Affordances relate the agent's actions to their effects when taken on the surrounding objects. In our work, we take the egocentric view of the scene, and aim to reason about action-object affordances that respect both the physical world as well as the social norms imposed by the society. We also aim to teach artificial agents why some actions should not be taken in certain situations, and what would likely happen if these actions would be taken. We collect a new dataset that builds upon ADE20k, referred to as ADE-Affordance, which contains annotations enabling such rich visual reasoning. We propose a model that exploits Graph Neural Networks to propagate contextual information from the scene in order to perform detailed affordance reasoning about each object. Our model is showcased through various ablation studies, pointing to successes and challenges in this complex task.

##### Abstract (translated by Google)
我们解决在现实世界中出现的各种场景中的可行性推理问题。当物品被拍到周围物品时，物品的行为与其效果相关。在我们的工作中，我们以场景的自我中心为目标，旨在推理既尊重物质世界又尊重社会规范的行为 - 对象可供性。我们还打算教人造代理为什么不应该在某些情况下采取一些行动，如果采取这些行动可能会发生什么。我们收集一个基于ADE20k的新数据集，称为ADE-Affordance，其中包含启用如此丰富的视觉推理的注释。我们提出了一个模型，利用图形神经网络来传播场景中的上下文信息，以便对每个对象进行详细的可供性推理。我们的模型通过各种消融研究来展示，指出在这个复杂任务中的成功和挑战。

##### URL
[https://arxiv.org/abs/1712.07576](https://arxiv.org/abs/1712.07576)

##### PDF
[https://arxiv.org/pdf/1712.07576](https://arxiv.org/pdf/1712.07576)

