---
layout: post
title: "Caveats in Generating Medical Imaging Labels from Radiology Reports"
date: 2019-05-06 22:38:18
categories: arXiv_CV
tags: arXiv_CV
author: Tobi Olatunji, Li Yao, Ben Covington, Alexander Rhodes, Anthony Upton
mathjax: true
---

* content
{:toc}

##### Abstract
Acquiring high-quality annotations in medical imaging is usually a costly process. Automatic label extraction with natural language processing (NLP) has emerged as a promising workaround to bypass the need of expert annotation. Despite the convenience, the limitation of such an approximation has not been carefully examined and is not well understood. With a challenging set of 1,000 chest X-ray studies and their corresponding radiology reports, we show that there exists a surprisingly large discrepancy between what radiologists visually perceive and what they clinically report. Furthermore, with inherently flawed report as ground truth, the state-of-the-art medical NLP fails to produce high-fidelity labels.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1905.02283](https://arxiv.org/abs/1905.02283)

##### PDF
[https://arxiv.org/pdf/1905.02283](https://arxiv.org/pdf/1905.02283)

