---
layout: post
title: "Ensemble p-Laplacian Regularization for Remote Sensing Image Recognition"
date: 2018-06-21 08:37:48
categories: arXiv_CV
tags: arXiv_CV Regularization Attention Optimization Recognition
author: Xueqi Ma, Weifeng Liu, Dapeng Tao, Yicong Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, manifold regularized semi-supervised learning (MRSSL) received considerable attention because it successfully exploits the geometry of the intrinsic data probability distribution including both labeled and unlabeled samples to leverage the performance of a learning model. As a natural nonlinear generalization of graph Laplacian, p-Laplacian has been proved having the rich theoretical foundations to better preserve the local structure. However, it is difficult to determine the fitting graph p-Lapalcian i.e. the parameter which is a critical factor for the performance of graph p-Laplacian. Therefore, we develop an ensemble p-Laplacian regularization (EpLapR) to fully approximate the intrinsic manifold of the data distribution. EpLapR incorporates multiple graphs into a regularization term in order to sufficiently explore the complementation of graph p-Laplacian. Specifically, we construct a fused graph by introducing an optimization approach to assign suitable weights on different p-value graphs. And then, we conduct semi-supervised learning framework on the fused graph. Extensive experiments on UC-Merced data set demonstrate the effectiveness and efficiency of the proposed method.

##### Abstract (translated by Google)
最近，流形正则化半监督学习（MRSSL）引起了相当大的关注，因为它成功地利用了内在数据概率分布的几何形状，包括标记样本和未标记样本以利用学习模型的性能。作为图拉普拉斯算子的一​​种自然非线性推广，已证明p-Laplacian具有丰富的理论基础，可以更好地保存局部结构。然而，难以确定拟合图p-Lapalcian，即作为图p-Laplacian性能的关键因素的参数。因此，我们开发了一个集合p-Laplacian正则化（EpLapR）来完全逼近数据分布的固有流形。 EpLapR将多个图形合并到一个正则化项中，以便充分探索图p-Laplacian的互补性。具体而言，我们通过引入优化方法来构造融合图，以在不同的p值图上分配合适的权重。然后，在融合图上进行半监督学习框架。 UC-Merced数据集的大量实验证明了所提出方法的有效性和有效性。

##### URL
[http://arxiv.org/abs/1806.08109](http://arxiv.org/abs/1806.08109)

##### PDF
[http://arxiv.org/pdf/1806.08109](http://arxiv.org/pdf/1806.08109)

