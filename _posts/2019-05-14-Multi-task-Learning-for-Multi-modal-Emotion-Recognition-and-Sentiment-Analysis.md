---
layout: post
title: "Multi-task Learning for Multi-modal Emotion Recognition and Sentiment Analysis"
date: 2019-05-14 19:42:43
categories: arXiv_CL
tags: arXiv_CL Sentiment Attention Recognition
author: Md Shad Akhtar, Dushyant Singh Chauhan, Deepanway Ghosal, Soujanya Poria, Asif Ekbal, Pushpak Bhattacharyya
mathjax: true
---

* content
{:toc}

##### Abstract
Related tasks often have inter-dependence on each other and perform better when solved in a joint framework. In this paper, we present a deep multi-task learning framework that jointly performs sentiment and emotion analysis both. The multi-modal inputs (i.e., text, acoustic and visual frames) of a video convey diverse and distinctive information, and usually do not have equal contribution in the decision making. We propose a context-level inter-modal attention framework for simultaneously predicting the sentiment and expressed emotions of an utterance. We evaluate our proposed approach on CMU-MOSEI dataset for multi-modal sentiment and emotion analysis. Evaluation results suggest that multi-task learning framework offers improvement over the single-task framework. The proposed approach reports new state-of-the-art performance for both sentiment analysis and emotion analysis.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.05812](http://arxiv.org/abs/1905.05812)

##### PDF
[http://arxiv.org/pdf/1905.05812](http://arxiv.org/pdf/1905.05812)

