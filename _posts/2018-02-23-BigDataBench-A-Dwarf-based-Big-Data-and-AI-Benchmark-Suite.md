---
layout: post
title: "BigDataBench: A Dwarf-based Big Data and AI Benchmark Suite"
date: 2018-02-23 01:28:44
categories: arXiv_AI
tags: arXiv_AI Attention
author: Wanling Gao, Jianfeng Zhan, Lei Wang, Chunjie Luo, Daoyi Zheng, Rui Ren, Chen Zheng, Gang Lu, Jingwei Li, Zheng Cao, Shujie Zhang, Haoning Tang
mathjax: true
---

* content
{:toc}

##### Abstract
As architecture, system, data management, and machine learning communities pay greater attention to innovative big data and data-driven artificial intelligence (in short, AI) algorithms, architecture, and systems, the pressure of benchmarking rises. However, complexity, diversity, frequently changed workloads, and rapid evolution of big data, especially AI systems raise great challenges in benchmarking. First, for the sake of conciseness, benchmarking scalability, portability cost, reproducibility, and better interpretation of performance data, we need understand what are the abstractions of frequently-appearing units of computation, which we call dwarfs, among big data and AI workloads. Second, for the sake of fairness, the benchmarks must include diversity of data and workloads. Third, for co-design of software and hardware, the benchmarks should be consistent across different communities. Other than creating a new benchmark or proxy for every possible workload, we propose using dwarf-based benchmarks--the combination of eight dwarfs--to represent diversity of big data and AI workloads. The current version--BigDataBench 4.0 provides 13 representative real-world data sets and 47 big data and AI benchmarks, including seven workload types: online service, offline analytics, graph analytics, AI, data warehouse, NoSQL, and streaming. BigDataBench 4.0 is publicly available from <a href="http://prof.ict.ac.cn/BigDataBench.">this http URL</a> Also, for the first time, we comprehensively characterize the benchmarks of seven workload types in BigDataBench 4.0 in addition to traditional benchmarks like SPECCPU, PARSEC and HPCC in a hierarchical manner and drill down on five levels, using the Top-Down analysis from an architecture perspective.

##### Abstract (translated by Google)
随着架构，系统，数据管理和机器学习社区更加关注创新的大数据和数据驱动的人工智能（简称人工智能）算法，架构和系统，基准测试的压力也随之上升。然而，复杂性，多样性，经常改变的工作量以及大数据的快速演变，特别是AI系统在基准测试中提出了巨大挑战。首先，为了简洁起见，基准测试的可扩展性，可移植性成本，可重复性以及对性能数据的更好解释，我们需要了解在大数据和AI工作负载中，经常出现的计算单位（我们称之为矮人）是什么抽象概念。其次，为了公平起见，基准测试必须包括数据和工作负载的多样性。第三，对于软件和硬件的协同设计，基准应该在不同的社区中保持一致。除了为每个可能的工作负载创建新的基准或代理外，我们还建议使用基于矮人的基准 - 八个小矮人的组合 - 来表示大数据和AI工作负载的多样性。当前版本--BigDataBench 4.0提供了13个具有代表性的实际数据集以及47个大数据和AI基准测试，包括在线服务，离线分析，图形分析，AI，数据仓库，NoSQL和流媒体等七种工作负载类型。 BigDataBench 4.0可以从<a href="http://prof.ict.ac.cn/BigDataBench.">这个http URL </a>公开获得。此外，我们第一次全面描述了七种工作负载类型的基准在BigDataBench 4.0中，除了像SPECCPU，PARSEC和HPCC这样的传统基准测试以外，还从五个层面进行深入分析，从架构的角度使用Top-Down分析。

##### URL
[http://arxiv.org/abs/1802.08254](http://arxiv.org/abs/1802.08254)

##### PDF
[http://arxiv.org/pdf/1802.08254](http://arxiv.org/pdf/1802.08254)

