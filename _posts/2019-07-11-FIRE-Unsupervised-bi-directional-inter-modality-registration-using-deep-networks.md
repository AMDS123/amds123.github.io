---
layout: post
title: "FIRE: Unsupervised bi-directional inter-modality registration using deep networks"
date: 2019-07-11 09:00:54
categories: arXiv_CV
tags: arXiv_CV Deep_Learning
author: Chengjia Wang, Giorgos Papanastasiou, Agisilaos Chartsias, Grzegorz Jacenkow, Sotirios A. Tsaftaris, Heye Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Inter-modality image registration is an critical preprocessing step for many applications within the routine clinical pathway. This paper presents an unsupervised deep inter-modality registration network that can learn the optimal affine and non-rigid transformations simultaneously. Inverse-consistency is an important property commonly ignored in recent deep learning based inter-modality registration algorithms. We address this issue through the proposed multi-task architecture and the new comprehensive transformation network. Specifically, the proposed model learns a modality-independent latent representation to perform cycle-consistent cross-modality synthesis, and use an inverse-consistent loss to learn a pair of transformations to align the synthesized image with the target. We name this proposed framework as FIRE due to the shape of its structure. Our method shows comparable and better performances with the popular baseline method in experiments on multi-sequence brain MR data and intra-modality 4D cardiac Cine-MR data.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.05062](http://arxiv.org/abs/1907.05062)

##### PDF
[http://arxiv.org/pdf/1907.05062](http://arxiv.org/pdf/1907.05062)

