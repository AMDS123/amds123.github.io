---
layout: post
title: "Comparative evaluation of instrument segmentation and tracking methods in minimally invasive surgery"
date: 2018-05-07 12:39:21
categories: arXiv_CV
tags: arXiv_CV Segmentation Tracking Deep_Learning
author: Sebastian Bodenstedt, Max Allan, Anthony Agustinos, Xiaofei Du, Luis Garcia-Peraza-Herrera, Hannes Kenngott, Thomas Kurmann, Beat M&#xfc;ller-Stich, Sebastien Ourselin, Daniil Pakhomov, Raphael Sznitman, Marvin Teichmann, Martin Thoma, Tom Vercauteren, Sandrine Voros, Martin Wagner, Pamela Wochner, Lena Maier-Hein, Danail Stoyanov, Stefanie Speidel
mathjax: true
---

* content
{:toc}

##### Abstract
Intraoperative segmentation and tracking of minimally invasive instruments is a prerequisite for computer- and robotic-assisted surgery. Since additional hardware like tracking systems or the robot encoders are cumbersome and lack accuracy, surgical vision is evolving as promising techniques to segment and track the instruments using only the endoscopic images. However, what is missing so far are common image data sets for consistent evaluation and benchmarking of algorithms against each other. The paper presents a comparative validation study of different vision-based methods for instrument segmentation and tracking in the context of robotic as well as conventional laparoscopic surgery. The contribution of the paper is twofold: we introduce a comprehensive validation data set that was provided to the study participants and present the results of the comparative validation study. Based on the results of the validation study, we arrive at the conclusion that modern deep learning approaches outperform other methods in instrument segmentation tasks, but the results are still not perfect. Furthermore, we show that merging results from different methods actually significantly increases accuracy in comparison to the best stand-alone method. On the other hand, the results of the instrument tracking task show that this is still an open challenge, especially during challenging scenarios in conventional laparoscopic surgery.

##### Abstract (translated by Google)
微创手术的术中分割和追踪是计算机和机器人辅助手术的先决条件。由于跟踪系统或机器人编码器等附加硬件繁琐且精度不高，手术视野正在演变为有前途的技术，仅使用内窥镜图像分割和跟踪仪器。但是，到目前为止所缺少的是常见的图像数据集，以便对算法进行一致的评估和基准测试。该论文提出了一个比较验证研究，不同的基于视觉的方法用于仪器分割和跟踪机器人以及传统腹腔镜手术。该论文的贡献是双重的：我们引入了一个全面的验证数据集，提供给研究参与者，并呈现比较验证研究的结果。基于验证研究的结果，我们得出的结论是，现代深度学习方法在仪器分割任务中优于其他方法，但结果仍不完美。此外，我们显示，与最佳独立方法相比，来自不同方法的合并结果实际上显着提高了准确性。另一方面，仪器追踪任务的结果表明，这仍然是一个公开挑战，特别是在传统腹腔镜手术中的挑战性情况下。

##### URL
[http://arxiv.org/abs/1805.02475](http://arxiv.org/abs/1805.02475)

##### PDF
[http://arxiv.org/pdf/1805.02475](http://arxiv.org/pdf/1805.02475)

