---
layout: post
title: "Neural Stereoscopic Image Style Transfer"
date: 2018-02-27 16:02:17
categories: arXiv_CV
tags: arXiv_CV Style_Transfer CNN
author: Xinyu Gong, Haozhi Huang, Lin Ma, Fumin Shen, Wei Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Neural style transfer is an emerging technique which is able to endow daily-life images with attractive artistic styles. Previous work has succeeded in applying convolutional neural network (CNN) to style transfer for monocular images or videos. However, style transfer for stereoscopic images is still a missing piece. Different from processing a monocular image, the two views of a stylized stereoscopic pair are required to be consistent to provide the observer a comfortable visual experience. In this paper, we propose a dual path network for view-consistent style transfer on stereoscopic images. While each view of the stereoscopic pair is processed in an individual path, a novel feature aggregation strategy is proposed to effectively share information between the two paths. Besides a traditional perceptual loss used for controlling style transfer quality in each view, a multi-layer view loss is proposed to enforce the network to coordinate the learning of both paths to generate view-consistent stylized results. Extensive experiments show that, compared with previous methods, the proposed model can generate stylized stereoscopic images which achieve the best view consistency.

##### Abstract (translated by Google)
神经风格转移是一种新兴技术，能够赋予日常生活图像以美丽的艺术风格。先前的工作成功地将卷积神经网络（CNN）应用于单目图像或视频的风格转移。然而，立体图像的风格转换仍然是一个缺失的部分。与处理单眼图像不同，程式化立体对的两个视图需要一致以向观察者提供舒适的视觉体验。在本文中，我们提出了一个双路径网络，用于立体图像上视图一致的样式转换。虽然立体对的每个视图都是在单独的路径中处理的，但是提出了一种新的特征聚合策略来有效地共享这两条路径之间的信息。除了用于控制每个视图中样式转换质量的传统感知损失之外，还提出了多层视图丢失来强化网络以协调两条路径的学习以生成视图一致的程式化结果。大量实验表明，与以前的方法相比，所提出的模型可以生成具有最佳视图一致性的程式化立体图像。

##### URL
[https://arxiv.org/abs/1802.09985](https://arxiv.org/abs/1802.09985)

##### PDF
[https://arxiv.org/pdf/1802.09985](https://arxiv.org/pdf/1802.09985)

