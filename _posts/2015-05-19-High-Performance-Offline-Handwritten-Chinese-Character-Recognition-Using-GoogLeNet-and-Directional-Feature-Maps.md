---
layout: post
title: "High Performance Offline Handwritten Chinese Character Recognition Using GoogLeNet and Directional Feature Maps"
date: 2015-05-19 09:32:54
categories: arXiv_CV
tags: arXiv_CV CNN Image_Classification Classification Recognition
author: Zhuoyao Zhong, Lianwen Jin, Zecheng Xie
mathjax: true
---

* content
{:toc}

##### Abstract
Just like its great success in solving many computer vision problems, the convolutional neural networks (CNN) provided new end-to-end approach to handwritten Chinese character recognition (HCCR) with very promising results in recent years. However, previous CNNs so far proposed for HCCR were neither deep enough nor slim enough. We show in this paper that, a deeper architecture can benefit HCCR a lot to achieve higher performance, meanwhile can be designed with less parameters. We also show that the traditional feature extraction methods, such as Gabor or gradient feature maps, are still useful for enhancing the performance of CNN. We design a streamlined version of GoogLeNet [13], which was original proposed for image classification in recent years with very deep architecture, for HCCR (denoted as HCCR-GoogLeNet). The HCCR-GoogLeNet we used is 19 layers deep but involves with only 7.26 million parameters. Experiments were conducted using the ICDAR 2013 offline HCCR competition dataset. It has been shown that with the proper incorporation with traditional directional feature maps, the proposed single and ensemble HCCR-GoogLeNet models achieve new state of the art recognition accuracy of 96.35% and 96.74%, respectively, outperforming previous best result with significant gap.

##### Abstract (translated by Google)
就像它在解决许多计算机视觉问题上的巨大成功一样，卷积神经网络（CNN）为手写汉字识别（HCCR）提供了新的端到端方法，近年来取得了非常有前景的成果。然而，迄今为止提出的HCCR的CNN既不够深入，也不够薄。我们在本文中表明，更深的架构可以使HCCR获益更多，以实现更高的性能，同时可以设计更少的参数。我们还表明，传统的特征提取方法，如Gabor或梯度特征图，仍然有助于提高CNN的性能。我们设计了一个精简版的GoogLeNet [13]，这是最近几年在HCCR（表示为HCCR-GoogLeNet）中提出的用于图像分类的非常深的架构。我们使用的HCCR-GoogLeNet是19层深，但只涉及726万个参数。使用ICDAR 2013离线HCCR竞争数据集进行实验。已经表明，与传统方向特征映射的适当结合，所提出的单个集合HCCR-GoogLeNet模型分别达到96.35％和96.74％的新的现有技术识别准确度，优于先前的最佳结果，具有显着差距。

##### URL
[https://arxiv.org/abs/1505.04925](https://arxiv.org/abs/1505.04925)

##### PDF
[https://arxiv.org/pdf/1505.04925](https://arxiv.org/pdf/1505.04925)

