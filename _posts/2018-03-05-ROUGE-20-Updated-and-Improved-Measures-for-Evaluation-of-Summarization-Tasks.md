---
layout: post
title: "ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization Tasks"
date: 2018-03-05 21:35:04
categories: arXiv_AI
tags: arXiv_AI Face Summarization
author: Kavita Ganesan
mathjax: true
---

* content
{:toc}

##### Abstract
Evaluation of summarization tasks is extremely crucial to determining the quality of machine generated summaries. Over the last decade, ROUGE has become the standard automatic evaluation measure for evaluating summarization tasks. While ROUGE has been shown to be effective in capturing n-gram overlap between system and human composed summaries, there are several limitations with the existing ROUGE measures in terms of capturing synonymous concepts and coverage of topics. Thus, often times ROUGE scores do not reflect the true quality of summaries and prevents multi-faceted evaluation of summaries (i.e. by topics, by overall content coverage and etc). In this paper, we introduce ROUGE 2.0, which has several updated measures of ROUGE: ROUGE-N+Synonyms, ROUGE-Topic, ROUGE-Topic+Synonyms, ROUGE-TopicUniq and ROUGE-TopicUniq+Synonyms; all of which are improvements over the core ROUGE measures.

##### Abstract (translated by Google)
汇总任务的评估对于确定机器生成的摘要的质量非常重要。在过去的十年里，ROUGE已成为评估汇总任务的标准自动评估方法。虽然ROUGE已被证明可以有效捕获系统和人工摘要之间的n-gram重叠，但在捕获同义概念和主题覆盖方面，现有的ROUGE措施存在一些局限性。因此，ROUGE得分通常不能反映摘要的真实质量，并且不能对摘要进行多方面的评估（即通过主题，整体内容覆盖率等）。在本文中，我们引入了ROUGE 2.0，它有几个更新的ROUGE：ROUGE-N +同义词，ROUGE-Topic，ROUGE-Topic +同义词，ROUGE-TopicUniq和ROUGE-TopicUniq +同义词的度量值;所有这些都是对核心ROUGE措施的改进。

##### URL
[http://arxiv.org/abs/1803.01937](http://arxiv.org/abs/1803.01937)

##### PDF
[http://arxiv.org/pdf/1803.01937](http://arxiv.org/pdf/1803.01937)

