---
layout: post
title: "A Deep Reinforcement Learning Approach for Dynamically Stable Inverse Kinematics of Humanoid Robots"
date: 2018-01-31 12:45:28
categories: arXiv_RO
tags: arXiv_RO Reinforcement_Learning
author: S Phaniteja, Parijat Dewangan, Pooja Guhan, Abhishek Sarkar, K Madhava Krishna
mathjax: true
---

* content
{:toc}

##### Abstract
Real time calculation of inverse kinematics (IK) with dynamically stable configuration is of high necessity in humanoid robots as they are highly susceptible to lose balance. This paper proposes a methodology to generate joint-space trajectories of stable configurations for solving inverse kinematics using Deep Reinforcement Learning (RL). Our approach is based on the idea of exploring the entire configuration space of the robot and learning the best possible solutions using Deep Deterministic Policy Gradient (DDPG). The proposed strategy was evaluated on the highly articulated upper body of a humanoid model with 27 degree of freedom (DoF). The trained model was able to solve inverse kinematics for the end effectors with 90% accuracy while maintaining the balance in double support phase.

##### Abstract (translated by Google)
具有动态稳定配置的逆运动学（IK）的实时计算在仿人机器人中是非常必要的，因为它们很容易失去平衡。本文提出了一种生成稳定配置的联合空间轨迹的方法，用于使用深度增强学习（RL）来求解逆运动学。我们的方法是基于探索机器人的整个配置空间，并使用深度确定性策略梯度（DDPG）学习最佳解决方案的思想。所提出的策略是在具有27自由度（DoF）的人形模型的高度连接的上半身上评估的。训练好的模型能够以90％的精度解决末端执行器的反向运动，同时保持双支撑阶段的平衡。

##### URL
[http://arxiv.org/abs/1801.10425](http://arxiv.org/abs/1801.10425)

##### PDF
[http://arxiv.org/pdf/1801.10425](http://arxiv.org/pdf/1801.10425)

