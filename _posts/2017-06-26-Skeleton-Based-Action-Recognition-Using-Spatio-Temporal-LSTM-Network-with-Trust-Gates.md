---
layout: post
title: "Skeleton-Based Action Recognition Using Spatio-Temporal LSTM Network with Trust Gates"
date: 2017-06-26 08:35:45
categories: arXiv_CV
tags: arXiv_CV Attention Action_Recognition RNN Recognition
author: Jun Liu, Amir Shahroudy, Dong Xu, Alex C. Kot, Gang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Skeleton-based human action recognition has attracted a lot of research attention during the past few years. Recent works attempted to utilize recurrent neural networks to model the temporal dependencies between the 3D positional configurations of human body joints for better analysis of human activities in the skeletal data. The proposed work extends this idea to spatial domain as well as temporal domain to better analyze the hidden sources of action-related information within the human skeleton sequences in both of these domains simultaneously. Based on the pictorial structure of Kinect's skeletal data, an effective tree-structure based traversal framework is also proposed. In order to deal with the noise in the skeletal data, a new gating mechanism within LSTM module is introduced, with which the network can learn the reliability of the sequential data and accordingly adjust the effect of the input data on the updating procedure of the long-term context representation stored in the unit's memory cell. Moreover, we introduce a novel multi-modal feature fusion strategy within the LSTM unit in this paper. The comprehensive experimental results on seven challenging benchmark datasets for human action recognition demonstrate the effectiveness of the proposed method.

##### Abstract (translated by Google)
在过去的几年中，基于骨架的人类行为识别已经引起了很多研究的关注。最近的工作试图利用递归神经网络来模拟人体关节的三维位置配置之间的时间依赖关系，以更好地分析骨骼数据中的人类活动。提出的工作将这个想法扩展到空间域和时间域，以便更好地分析这两个域中人类骨骼序列中与动作相关的信息的隐藏源。基于Kinect骨架数据的图形结构，提出了一种有效的基于树型结构的遍历框架。为了处理骨架数据中的噪声，引入了LSTM模块中的一种新的门控机制，使网络能够学习顺序数据的可靠性，从而调整输入数据对长时间更新过程的影响存储在单元的存储单元中的上下文表示。此外，本文还介绍了一种新的多模式特征融合策略。七个具有挑战性的人类行为识别基准数据集的综合实验结果证明了所提出的方法的有效性。

##### URL
[https://arxiv.org/abs/1706.08276](https://arxiv.org/abs/1706.08276)

##### PDF
[https://arxiv.org/pdf/1706.08276](https://arxiv.org/pdf/1706.08276)

