---
layout: post
title: "Towards Robust Neural Machine Translation"
date: 2018-05-16 04:51:29
categories: arXiv_CL
tags: arXiv_CL Adversarial NMT
author: Yong Cheng, Zhaopeng Tu, Fandong Meng, Junjie Zhai, Yang Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Small perturbations in the input can severely distort intermediate representations and thus impact translation quality of neural machine translation (NMT) models. In this paper, we propose to improve the robustness of NMT models with adversarial stability training. The basic idea is to make both the encoder and decoder in NMT models robust against input perturbations by enabling them to behave similarly for the original input and its perturbed counterpart. Experimental results on Chinese-English, English-German and English-French translation tasks show that our approaches can not only achieve significant improvements over strong NMT systems but also improve the robustness of NMT models.

##### Abstract (translated by Google)
输入中的小扰动会严重扭曲中间表示，从而影响神经机器翻译（NMT）模型的翻译质量。在本文中，我们提出通过对抗稳定训练来提高NMT模型的鲁棒性。其基本思想是通过使NMT模型中的编码器和解码器对输入扰动具有鲁棒性，使其对原始输入及其扰动的对应部分表现相似。中英文，英文和英文 - 法文翻译任务的实验结果表明，我们的方法不仅可以在强大的NMT系统上取得显着的改进，而且还可以提高NMT模型的稳健性。

##### URL
[http://arxiv.org/abs/1805.06130](http://arxiv.org/abs/1805.06130)

##### PDF
[http://arxiv.org/pdf/1805.06130](http://arxiv.org/pdf/1805.06130)

