---
layout: post
title: "Revisiting the Master-Slave Architecture in Multi-Agent Deep Reinforcement Learning"
date: 2017-12-20 03:00:46
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Xiangyu Kong, Bo Xin, Fangchen Liu, Yizhou Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Many tasks in artificial intelligence require the collaboration of multiple agents. We exam deep reinforcement learning for multi-agent domains. Recent research efforts often take the form of two seemingly conflicting perspectives, the decentralized perspective, where each agent is supposed to have its own controller; and the centralized perspective, where one assumes there is a larger model controlling all agents. In this regard, we revisit the idea of the master-slave architecture by incorporating both perspectives within one framework. Such a hierarchical structure naturally leverages advantages from one another. The idea of combining both perspectives is intuitive and can be well motivated from many real world systems, however, out of a variety of possible realizations, we highlights three key ingredients, i.e. composed action representation, learnable communication and independent reasoning. With network designs to facilitate these explicitly, our proposal consistently outperforms latest competing methods both in synthetic experiments and when applied to challenging StarCraft micromanagement tasks.

##### Abstract (translated by Google)
人工智能中的许多任务需要多个代理的协作。我们考察了多智能体领域的深度强化学习。最近的研究工作通常采取两种表面上相互矛盾的观点，即分散化的观点，即每个代理人应该有自己的控制者;和集中的角度，假设有一个更大的模型来控制所有的代理人。在这方面，我们通过在一个框架内结合两个观点来重新审视主从架构的概念。这样的等级结构自然地利用了彼此的优点。这两种观点相结合的观点是直观的，可以从很多现实世界的系统中得到很好的激励。然而，在各种可能的实现中，我们强调了三个关键要素，即组合的行动表示，可学习的交流和独立的推理。通过网络设计来明确地促进这些，我们的建议在综合实验和应用于具有挑战性的星际争霸微观管理任务时始终优于最新的竞争方法。

##### URL
[http://arxiv.org/abs/1712.07305](http://arxiv.org/abs/1712.07305)

##### PDF
[http://arxiv.org/pdf/1712.07305](http://arxiv.org/pdf/1712.07305)

