---
layout: post
title: "A Unified Method for First and Third Person Action Recognition"
date: 2017-12-30 21:03:13
categories: arXiv_CV
tags: arXiv_CV Action_Recognition Video_Classification Classification Recognition
author: Ali Javidani, Ahmad Mahmoudi-Aznaveh
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, a new video classification methodology is proposed which can be applied in both first and third person videos. The main idea behind the proposed strategy is to capture complementary information of appearance and motion efficiently by performing two independent streams on the videos. The first stream is aimed to capture long-term motions from shorter ones by keeping track of how elements in optical flow images have changed over time. Optical flow images are described by pre-trained networks that have been trained on large scale image datasets. A set of multi-channel time series are obtained by aligning descriptions beside each other. For extracting motion features from these time series, PoT representation method plus a novel pooling operator is followed due to several advantages. The second stream is accomplished to extract appearance features which are vital in the case of video classification. The proposed method has been evaluated on both first and third-person datasets and results present that the proposed methodology reaches the state of the art successfully.

##### Abstract (translated by Google)
在本文中，提出了一种新的视频分类方法，可以应用于第一人称视频和第三人称视频。提出的策略背后的主要思想是通过在视频上执行两个独立的流来有效地捕获外观和运动的补充信息。第一个流旨在通过跟踪光流图像中的元素随时间变化如何从较短的流中捕捉长期运动。光流图像通过在大规模图像数据集上训练过的预训练网络来描述。一组多通道时间序列是通过将描述彼此对齐而获得的。为了从这些时间序列中提取运动特征，由于几个优点，遵循PoT表示方法加上新的汇集算子。第二个流是为了提取在视频分类情况下至关重要的外观特征。所提出的方法已经在第一人和第三人数据集上进行了评估，结果表明所提出的方法成功地达到了现有技术水平。

##### URL
[http://arxiv.org/abs/1801.00192](http://arxiv.org/abs/1801.00192)

##### PDF
[http://arxiv.org/pdf/1801.00192](http://arxiv.org/pdf/1801.00192)

