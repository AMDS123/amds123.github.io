---
layout: post
title: "Learning Multimodal Word Representation via Dynamic Fusion Methods"
date: 2018-01-02 00:32:29
categories: arXiv_CL
tags: arXiv_CL
author: Shaonan Wang, Jiajun Zhang, Chengqing Zong
mathjax: true
---

* content
{:toc}

##### Abstract
Multimodal models have been proven to outperform text-based models on learning semantic word representations. Almost all previous multimodal models typically treat the representations from different modalities equally. However, it is obvious that information from different modalities contributes differently to the meaning of words. This motivates us to build a multimodal model that can dynamically fuse the semantic representations from different modalities according to different types of words. To that end, we propose three novel dynamic fusion methods to assign importance weights to each modality, in which weights are learned under the weak supervision of word association pairs. The extensive experiments have demonstrated that the proposed methods outperform strong unimodal baselines and state-of-the-art multimodal models.

##### Abstract (translated by Google)
多模式模型已经被证明优于学习语义词表示的基于文本的模型。几乎所有以前的多模式模型通常均等地处理来自不同模态的表示。然而，显然来自不同形式的信息对词语的含义有不同的贡献。这激励我们建立一个多模式模型，可以根据不同类型的词语动态融合不同形式的语义表征。为此，我们提出了三种新的动态融合方法来为每种情态分配重要的权重，其中权重是在弱关联对的弱监督下学习的。广泛的实验表明，所提出的方法胜过强单峰基线和最先进的多模态模型。

##### URL
[http://arxiv.org/abs/1801.00532](http://arxiv.org/abs/1801.00532)

##### PDF
[http://arxiv.org/pdf/1801.00532](http://arxiv.org/pdf/1801.00532)

