---
layout: post
title: "Adversarial Domain Adaptation for Variational Neural Language Generation in Dialogue Systems"
date: 2018-08-08 00:02:18
categories: arXiv_CL
tags: arXiv_CL Adversarial Knowledge
author: Van-Khanh Tran, Le-Minh Nguyen
mathjax: true
---

* content
{:toc}

##### Abstract
Domain Adaptation arises when we aim at learning from source domain a model that can per- form acceptably well on a different target domain. It is especially crucial for Natural Language Generation (NLG) in Spoken Dialogue Systems when there are sufficient annotated data in the source domain, but there is a limited labeled data in the target domain. How to effectively utilize as much of existing abilities from source domains is a crucial issue in domain adaptation. In this paper, we propose an adversarial training procedure to train a Variational encoder-decoder based language generator via multiple adaptation steps. In this procedure, a model is first trained on a source domain data and then fine-tuned on a small set of target domain utterances under the guidance of two proposed critics. Experimental results show that the proposed method can effec- tively leverage the existing knowledge in the source domain to adapt to another related domain by using only a small amount of in-domain data.

##### Abstract (translated by Google)
当我们的目标是从源域学习一个可以在不同目标域上很好地执行的模型时，就会出现域适应。当源域中有足够的带注释数据时，对于口语对话系统中的自然语言生成（NLG）尤为重要，但目标域中的标记数据有限。如何有效地利用来自源域的现有能力是域适应中的关键问题。在本文中，我们提出了一种对抗训练程序，通过多个自适应步骤训练基于变分编码器 - 解码器的语言生成器。在此过程中，首先在源域数据上训练模型，然后在两个提议的批评者的指导下对一小组目标域话语进行微调。实验结果表明，该方法可以有效地利用源域中的现有知识，通过仅使用少量的域内数据来适应另一个相关域。

##### URL
[http://arxiv.org/abs/1808.02586](http://arxiv.org/abs/1808.02586)

##### PDF
[http://arxiv.org/pdf/1808.02586](http://arxiv.org/pdf/1808.02586)

