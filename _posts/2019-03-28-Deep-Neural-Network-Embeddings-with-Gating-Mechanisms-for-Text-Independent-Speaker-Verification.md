---
layout: post
title: "Deep Neural Network Embeddings with Gating Mechanisms for Text-Independent Speaker Verification"
date: 2019-03-28 16:15:11
categories: arXiv_SD
tags: arXiv_SD Attention Embedding CNN
author: Lanhua You, Wu Guo, Lirong Dai, Jun Du
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, gating mechanisms are applied in deep neural network (DNN) training for x-vector-based text-independent speaker verification. First, a gated convolution neural network (GCNN) is employed for modeling the frame-level embedding layers. Compared with the time-delay DNN (TDNN), the GCNN can obtain more expressive frame-level representations through carefully designed memory cell and gating mechanisms. Moreover, we propose a novel gated-attention statistics pooling strategy in which the attention scores are shared with the output gate. The gated-attention statistics pooling combines both gating and attention mechanisms into one framework; therefore, we can capture more useful information in the temporal pooling layer. Experiments are carried out using the NIST SRE16 and SRE18 evaluation datasets. The results demonstrate the effectiveness of the GCNN and show that the proposed gated-attention statistics pooling can further improve the performance.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.12092](http://arxiv.org/abs/1903.12092)

##### PDF
[http://arxiv.org/pdf/1903.12092](http://arxiv.org/pdf/1903.12092)

