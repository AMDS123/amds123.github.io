---
layout: post
title: "On Encoding Temporal Evolution for Real-time Action Prediction"
date: 2018-02-08 00:07:15
categories: arXiv_CV
tags: arXiv_CV CNN RNN Prediction
author: Fahimeh Rezazadegan, Sareh Shirazi, Mahsa Baktashmotlagh, Larry S. Davis
mathjax: true
---

* content
{:toc}

##### Abstract
Anticipating future actions is a key component of intelligence, specifically when it applies to real-time systems, such as robots or autonomous cars. While recent works have addressed prediction of raw RGB pixel values, we focus on anticipating the motion evolution in future video frames. To this end, we construct dynamic images (DIs) by summarising moving pixels through a sequence of future frames. We train a convolutional LSTMs to predict the next DIs based on an unsupervised learning process, and then recognise the activity associated with the predicted DI. We demonstrate the effectiveness of our approach on 3 benchmark action datasets showing that despite running on videos with complex activities, our approach is able to anticipate the next human action with high accuracy and obtain better results than the state-of-the-art methods.

##### Abstract (translated by Google)
预测未来的行动是情报的关键组成部分，特别是当它适用于实时系统，如机器人或自动驾驶汽车。虽然最近的作品已经解决了原始RGB像素值的预测问题，但我们专注于预测未来视频帧中的运动演变。为此，我们通过将一系列未来帧的移动像素进行汇总来构造动态图像（DI）。我们训练一个卷积LSTM，根据无监督的学习过程预测下一个DI，然后识别与预测的DI有关的活动。我们展示了我们的方法在3个基准行动数据集上的有效性，表明尽管在复杂活动的视频上运行，我们的方法能够以高精度预测下一个人类行为，并获得比最先进方法更好的结果。

##### URL
[http://arxiv.org/abs/1709.07894](http://arxiv.org/abs/1709.07894)

##### PDF
[http://arxiv.org/pdf/1709.07894](http://arxiv.org/pdf/1709.07894)

