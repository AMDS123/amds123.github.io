---
layout: post
title: "ACD: Action Concept Discovery from Image-Sentence Corpora"
date: 2016-04-16 18:26:13
categories: arXiv_CV
tags: arXiv_CV Weakly_Supervised Embedding CNN Classification Language_Model
author: Jiyang Gao, Chen Sun, Ram Nevatia
mathjax: true
---

* content
{:toc}

##### Abstract
Action classification in still images is an important task in computer vision. It is challenging as the appearances of ac- tions may vary depending on their context (e.g. associated objects). Manually labeling of context information would be time consuming and difficult to scale up. To address this challenge, we propose a method to automatically discover and cluster action concepts, and learn their classifiers from weakly supervised image-sentence corpora. It obtains candidate action concepts by extracting verb-object pairs from sentences and verifies their visualness with the associated images. Candidate action concepts are then clustered by using a multi-modal representation with image embeddings from deep convolutional networks and text embeddings from word2vec. More than one hundred human action concept classifiers are learned from the Flickr 30k dataset with no additional human effort and promising classification results are obtained. We further apply the AdaBoost algorithm to automatically select and combine relevant action concepts given an action query. Promising results have been shown on the PASCAL VOC 2012 action classification benchmark, which has zero overlap with Flickr30k.

##### Abstract (translated by Google)
静止图像中的动作分类是计算机视觉中的一项重要任务。这是具有挑战性的，因为行为的外观可以根据其背景（例如相关对象）而变化。手动标记上下文信息将是耗时且难以扩展的。针对这一挑战，我们提出了一种自动发现和聚类动作概念的方法，并从弱监督的图像 - 句子语料库中学习他们的分类器。它通过从句子中提取动词 - 宾语对并通过相关图像来验证其视觉效果，从而获得候选动作概念。候选行动概念，然后通过使用多模式表示与来自深卷积网络的图像嵌入和来自word2vec的文本嵌入进行聚类。从Flickr 30k数据集中学习了一百多个人类活动概念分类器，无需额外的人力，就可以获得有前途的分类结果。我们进一步应用AdaBoost算法来自动选择和组合相关的动作概念给定一个动作查询。 PASCAL VOC 2012行动分类基准已经显示了有希望的结果，与Flickr30k没有重叠。

##### URL
[https://arxiv.org/abs/1604.04784](https://arxiv.org/abs/1604.04784)

##### PDF
[https://arxiv.org/pdf/1604.04784](https://arxiv.org/pdf/1604.04784)

