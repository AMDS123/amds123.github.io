---
layout: post
title: "Learning Cross-Modal Deep Representations for Multi-Modal MR Image Segmentation"
date: 2019-08-06 07:42:44
categories: arXiv_CV
tags: arXiv_CV Segmentation Attention CNN Optimization
author: Cheng Li, Hui Sun, Zaiyi Liu, Meiyun Wang, Hairong Zheng, Shanshan Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Multi-modal magnetic resonance imaging (MRI) is essential in clinics for comprehensive diagnosis and surgical planning. Nevertheless, the segmentation of multi-modal MR images tends to be time-consuming and challenging. Convolutional neural network (CNN)-based multi-modal MR image analysis commonly proceeds with multiple down-sampling streams fused at one or several layers. Although inspiring performance has been achieved, the feature fusion is usually conducted through simple summation or concatenation without optimization. In this work, we propose a supervised image fusion method to selectively fuse the useful information from different modalities and suppress the respective noise signals. Specifically, an attention block is introduced as guidance for the information selection. From the different modalities, one modality that contributes most to the results is selected as the master modality, which supervises the information selection of the other assistant modalities. The effectiveness of the proposed method is confirmed through breast mass segmentation in MR images of two modalities and better segmentation results are achieved compared to the state-of-the-art methods.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.01997](http://arxiv.org/abs/1908.01997)

##### PDF
[http://arxiv.org/pdf/1908.01997](http://arxiv.org/pdf/1908.01997)

