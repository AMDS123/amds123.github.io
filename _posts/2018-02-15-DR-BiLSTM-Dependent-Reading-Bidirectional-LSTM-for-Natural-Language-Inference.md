---
layout: post
title: "DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference"
date: 2018-02-15 14:39:47
categories: arXiv_CL
tags: arXiv_CL Inference RNN Deep_Learning Prediction Relation
author: Reza Ghaeini, Sadid A. Hasan, Vivek Datla, Joey Liu, Kathy Lee, Ashequl Qadir, Yuan Ling, Aaditya Prakash, Xiaoli Z. Fern, Oladimeji Farri
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel deep learning architecture to address the natural language inference (NLI) task. Existing approaches mostly rely on simple reading mechanisms for independent encoding of the premise and hypothesis. Instead, we propose a novel dependent reading bidirectional LSTM network (DR-BiLSTM) to efficiently model the relationship between a premise and a hypothesis during encoding and inference. We also introduce a sophisticated ensemble strategy to combine our proposed models, which noticeably improves final predictions. Finally, we demonstrate how the results can be improved further with an additional preprocessing step. Our evaluation shows that DR-BiLSTM obtains the best single model and ensemble model results achieving the new state-of-the-art scores on the Stanford NLI dataset.

##### Abstract (translated by Google)
我们提出了一种新颖的深度学习架构来解决自然语言推理（NLI）任务。现有的方法主要依靠简单的阅读机制来独立编码前提和假设。相反，我们提出了一种新型的依赖阅读双向LSTM网络（DR-BiLSTM），以便在编码和推理过程中有效地模拟前提和假设之间的关系。我们还引入了一个复杂的集合策略来组合我们提出的模型，这显着改善了最终的预测。最后，我们演示如何通过额外的预处理步骤进一步改善结果。我们的评估显示，DR-BiLSTM获得最佳的单一模型和整体模型结果，实现了斯坦福大学NLI数据集上最新的最新成绩。

##### URL
[https://arxiv.org/abs/1802.05577](https://arxiv.org/abs/1802.05577)

##### PDF
[https://arxiv.org/pdf/1802.05577](https://arxiv.org/pdf/1802.05577)

