---
layout: post
title: "Conditional Image-Text Embedding Networks"
date: 2017-11-22 16:58:31
categories: arXiv_CV
tags: arXiv_CV Embedding
author: Bryan A. Plummer, Paige Kordas, M. Hadi Kiapour, Shuai Zheng, Robinson Piramuthu, Svetlana Lazebnik
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents an approach for grounding phrases in images which jointly learns multiple text-conditioned embeddings in a single end-to-end model. In order to differentiate text phrases into semantically distinct subspaces, we propose a concept weight branch that automatically assigns phrases to embeddings, whereas prior works predefine such assignments. Our proposed solution simplifies the representation requirements for individual embeddings and allows the underrepresented concepts to take advantage of the shared representations before feeding them into concept-specific layers. Comprehensive experiments verify the effectiveness of our approach across three phrase grounding datasets, Flickr30K Entities, ReferIt Game, and Visual Genome, where we obtain a (resp.) 3.5%, 2%, and 3.5% improvement in grounding performance over a strong region-phrase embedding baseline.

##### Abstract (translated by Google)
本文提出了一种在单个端到端模型中共同学习多个文本嵌入的图像中的基础短语的方法。为了将文本短语区分为语义上不同的子空间，我们提出了一个概念权重分支，自动将短语分配给嵌入，而之前的作品预先定义了这种分配。我们提出的解决方案简化了单个嵌入的表示要求，并允许代表性不足的概念在将其提供到概念特定的层之前利用共享的表示。综合实验验证了我们的方法在三个接地数据集，Flickr30K实体，ReferIt游戏和Visual Genome中的有效性，我们在一个强大的地区获得了3.5％，2％和3.5％的接地性能的改善，短语嵌入基线。

##### URL
[https://arxiv.org/abs/1711.08389](https://arxiv.org/abs/1711.08389)

##### PDF
[https://arxiv.org/pdf/1711.08389](https://arxiv.org/pdf/1711.08389)

