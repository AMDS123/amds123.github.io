---
layout: post
title: "Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data"
date: 2018-07-23 01:35:21
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption
author: Xihui Liu, Hongsheng Li, Jing Shao, Dapeng Chen, Xiaogang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
The aim of image captioning is to generate captions by machine to describe image contents. Despite many efforts, generating discriminative captions for images remains non-trivial. Most traditional approaches imitate the language structure patterns, thus tend to fall into a stereotype of replicating frequent phrases or sentences and neglect unique aspects of each image. In this work, we propose an image captioning framework with a self-retrieval module as training guidance, which encourages generating discriminative captions. It brings unique advantages: (1) the self-retrieval guidance can act as a metric and an evaluator of caption discriminativeness to assure the quality of generated captions. (2) The correspondence between generated captions and images are naturally incorporated in the generation process without human annotations, and hence our approach could utilize a large amount of unlabeled images to boost captioning performance with no additional laborious annotations. We demonstrate the effectiveness of the proposed retrieval-guided method on COCO and Flickr30k captioning datasets, and show its superior captioning performance with more discriminative captions.

##### Abstract (translated by Google)
图像字幕的目的是通过机器生成字幕来描述图像内容。尽管付出了许多努力，但为图像生成歧视性标题仍然是非平凡的。大多数传统方法模仿语言结构模式，因此往往会陷入复制频繁短语或句子的刻板印象，忽视每个图像的独特方面。在这项工作中，我们提出了一个图像字幕框架，其中有一个自我检索模块作为培训指导，鼓励产生歧视性字幕。它带来了独特的优势：（1）自我检索指导可以作为标题判别的度量和评估者，以确保生成的字幕的质量。 （2）生成的字幕和图像之间的对应关系自然地包含在没有人类注释的生成过程中，因此我们的方法可以利用大量未标记的图像来提高字幕性能而无需额外的费力注释。我们证明了所提出的检索引导方法对COCO和Flickr30k字幕数据集的有效性，并显示其优越的字幕性能和更具辨别性的字幕。

##### URL
[https://arxiv.org/abs/1803.08314](https://arxiv.org/abs/1803.08314)

##### PDF
[https://arxiv.org/pdf/1803.08314](https://arxiv.org/pdf/1803.08314)

