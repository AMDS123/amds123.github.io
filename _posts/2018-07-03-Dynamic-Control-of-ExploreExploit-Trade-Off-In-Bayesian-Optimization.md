---
layout: post
title: "Dynamic Control of Explore/Exploit Trade-Off In Bayesian Optimization"
date: 2018-07-03 16:56:05
categories: arXiv_AI
tags: arXiv_AI Optimization
author: Dipti Jasrasaria, Edward O. Pyzer-Knapp
mathjax: true
---

* content
{:toc}

##### Abstract
Bayesian optimization offers the possibility of optimizing black-box operations not accessible through traditional techniques. The success of Bayesian optimization methods such as Expected Improvement (EI) are significantly affected by the degree of trade-off between exploration and exploitation. Too much exploration can lead to inefficient optimization protocols, whilst too much exploitation leaves the protocol open to strong initial biases, and a high chance of getting stuck in a local minimum. Typically, a constant margin is used to control this trade-off, which results in yet another hyper-parameter to be optimized. We propose contextual improvement as a simple, yet effective heuristic to counter this - achieving a one-shot optimization strategy. Our proposed heuristic can be swiftly calculated and improves both the speed and robustness of discovery of optimal solutions. We demonstrate its effectiveness on both synthetic and real world problems and explore the unaccounted for uncertainty in the pre-determination of search hyperparameters controlling explore-exploit trade-off.

##### Abstract (translated by Google)
贝叶斯优化提供了优化通过传统技术无法访问的黑盒操作的可能性。贝叶斯优化方法（如预期改进（EI））的成功受到勘探和开采之间权衡程度的显着影响。太多的探索可能会导致效率低下的优化协议，同时过多的利用会使协议对强大的初始偏差开放，并且很有可能陷入局部最小化。通常，使用恒定余量来控制这种权衡，这导致另一个超参数被优化。我们建议将上下文改进作为一种简单但有效的启发式方法来对抗这种情况 - 实现一次性优化策略。我们提出的启发式算法可以快速计算，并提高发现最优解的速度和鲁棒性。我们展示了它在合成和现实世界问题上的有效性，并探讨了控制探索 - 利用权衡的搜索超参数预先确定中的不确定性。

##### URL
[http://arxiv.org/abs/1807.01279](http://arxiv.org/abs/1807.01279)

##### PDF
[http://arxiv.org/pdf/1807.01279](http://arxiv.org/pdf/1807.01279)

