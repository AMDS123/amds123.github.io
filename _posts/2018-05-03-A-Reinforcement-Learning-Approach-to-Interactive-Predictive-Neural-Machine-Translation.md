---
layout: post
title: "A Reinforcement Learning Approach to Interactive-Predictive Neural Machine Translation"
date: 2018-05-03 21:50:34
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning Prediction
author: Tsz Kin Lam, Julia Kreutzer, Stefan Riezler
mathjax: true
---

* content
{:toc}

##### Abstract
We present an approach to interactive-predictive neural machine translation that attempts to reduce human effort from three directions: Firstly, instead of requiring humans to select, correct, or delete segments, we employ the idea of learning from human reinforcements in form of judgments on the quality of partial translations. Secondly, human effort is further reduced by using the entropy of word predictions as uncertainty criterion to trigger feedback requests. Lastly, online updates of the model parameters after every interaction allow the model to adapt quickly. We show in simulation experiments that reward signals on partial translations significantly improve character F-score and BLEU compared to feedback on full translations only, while human effort can be reduced to an average number of $5$ feedback requests for every input.

##### Abstract (translated by Google)
我们提出了一种交互式预测神经机器翻译的方法，试图从三个方面减少人类的努力：首先，我们不是要求人类选择，修正或删除片段，而是采用从人体增援中学习的想法，以判断形式部分翻译的质量。其次，通过使用单词预测的熵作为不确定性标准来触发反馈请求，人类的努力进一步减少。最后，在每次交互之后，模型参数的在线更新允许模型快速适应。我们在模拟实验中显示，与仅完整翻译的反馈相比，对部分翻译的奖励信号显着提高了字符F-score和BLEU，而对于每个输入，人力可以降至平均5美元的反馈请求数。

##### URL
[http://arxiv.org/abs/1805.01553](http://arxiv.org/abs/1805.01553)

##### PDF
[http://arxiv.org/pdf/1805.01553](http://arxiv.org/pdf/1805.01553)

