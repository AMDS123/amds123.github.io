---
layout: post
title: "Deep Reinforcement Learning for Visual Object Tracking in Videos"
date: 2017-04-10 20:34:43
categories: arXiv_CV
tags: arXiv_CV Knowledge Attention Tracking Reinforcement_Learning CNN Object_Tracking Relation
author: Da Zhang, Hamid Maei, Xin Wang, Yuan-Fang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we introduce a fully end-to-end approach for visual tracking in videos that learns to predict the bounding box locations of a target object at every frame. An important insight is that the tracking problem can be considered as a sequential decision-making process and historical semantics encode highly relevant information for future decisions. Based on this intuition, we formulate our model as a recurrent convolutional neural network agent that interacts with a video overtime, and our model can be trained with reinforcement learning (RL) algorithms to learn good tracking policies that pay attention to continuous, inter-frame correlation and maximize tracking performance in the long run. The proposed tracking algorithm achieves state-of-the-art performance in an existing tracking benchmark and operates at frame-rates faster than real-time. To the best of our knowledge, our tracker is the first neural-network tracker that combines convolutional and recurrent networks with RL algorithms.

##### Abstract (translated by Google)
在本文中，我们介绍了一个完全端到端的视频跟踪方法，学习如何预测每个帧的目标对象的边界框位置。一个重要的洞察是跟踪问题可以被认为是一个连续的决策过程，而历史语义为未来的决策编码高度相关的信息。基于这种直觉，我们将我们的模型作为一个与视频超时相互作用的递归卷积神经网络代理，并且我们的模型可以用强化学习（RL）算法进行训练，以学习关注连续，帧间的良好跟踪策略相关性和最大限度地追踪性能。所提出的跟踪算法在现有的跟踪基准中实现了最新的性能，并且以比实时快的帧速率运行。据我们所知，我们的跟踪器是第一个将卷积和循环网络与RL算法相结合的神经网络跟踪器。

##### URL
[https://arxiv.org/abs/1701.08936](https://arxiv.org/abs/1701.08936)

##### PDF
[https://arxiv.org/pdf/1701.08936](https://arxiv.org/pdf/1701.08936)

