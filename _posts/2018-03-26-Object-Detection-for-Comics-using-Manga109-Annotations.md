---
layout: post
title: "Object Detection for Comics using Manga109 Annotations"
date: 2018-03-26 05:35:40
categories: arXiv_CV
tags: arXiv_CV Image_Caption Object_Detection CNN Detection
author: Toru Ogawa, Atsushi Otsubo, Rei Narita, Yusuke Matsui, Toshihiko Yamasaki, Kiyoharu Aizawa
mathjax: true
---

* content
{:toc}

##### Abstract
With the growth of digitized comics, image understanding techniques are becoming important. In this paper, we focus on object detection, which is a fundamental task of image understanding. Although convolutional neural networks (CNN)-based methods archived good performance in object detection for naturalistic images, there are two problems in applying these methods to the comic object detection task. First, there is no large-scale annotated comics dataset. The CNN-based methods require large-scale annotations for training. Secondly, the objects in comics are highly overlapped compared to naturalistic images. This overlap causes the assignment problem in the existing CNN-based methods. To solve these problems, we proposed a new annotation dataset and a new CNN model. We annotated an existing image dataset of comics and created the largest annotation dataset, named Manga109-annotations. For the assignment problem, we proposed a new CNN-based detector, SSD300-fork. We compared SSD300-fork with other detection methods using Manga109-annotations and confirmed that our model outperformed them based on the mAP score.

##### Abstract (translated by Google)
随着数字化漫画的发展，图像理解技术变得越来越重要。在本文中，我们着重于对象检测，这是图像理解的基础任务。尽管基于卷积神经网络（CNN）的方法在自然图像的对象检测中存档良好，但在将这些方法应用于漫画对象检测任务时存在两个问题。首先，没有大规模的带注释的漫画数据集。基于CNN的方法需要大规模的培训注释。其次，与自然图像相比，漫画中的物体高度重叠。这种重叠会导致现有的基于CNN的方法中的分配问题。为了解决这些问题，我们提出了一个新的注释数据集和一个新的CNN模型。我们注释了现有的漫画图像数据集，并创建了最大的注释数据集Manga109-annotations。对于分配问题，我们提出了一种新的基于CNN的探测器SSD300-fork。我们使用Manga109注释比较SSD300-fork与其他检测方法，并确认我们的模型基于mAP得分胜过了它们。

##### URL
[https://arxiv.org/abs/1803.08670](https://arxiv.org/abs/1803.08670)

##### PDF
[https://arxiv.org/pdf/1803.08670](https://arxiv.org/pdf/1803.08670)

