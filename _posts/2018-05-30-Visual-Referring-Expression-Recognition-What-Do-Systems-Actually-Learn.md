---
layout: post
title: "Visual Referring Expression Recognition: What Do Systems Actually Learn?"
date: 2018-05-30 06:03:21
categories: arXiv_CL
tags: arXiv_CL Prediction Relation Recognition
author: Volkan Cirik, Louis-Philippe Morency, Taylor Berg-Kirkpatrick
mathjax: true
---

* content
{:toc}

##### Abstract
We present an empirical analysis of the state-of-the-art systems for referring expression recognition -- the task of identifying the object in an image referred to by a natural language expression -- with the goal of gaining insight into how these systems reason about language and vision. Surprisingly, we find strong evidence that even sophisticated and linguistically-motivated models for this task may ignore the linguistic structure, instead relying on shallow correlations introduced by unintended biases in the data selection and annotation process. For example, we show that a system trained and tested on the input image $\textit{without the input referring expression}$ can achieve a precision of 71.2% in top-2 predictions. Furthermore, a system that predicts only the object category given the input can achieve a precision of 84.2% in top-2 predictions. These surprisingly positive results for what should be deficient prediction scenarios suggest that careful analysis of what our models are learning -- and further, how our data is constructed -- is critical as we seek to make substantive progress on grounded language tasks.

##### Abstract (translated by Google)
我们提出了用于引用表达式识别的最先进系统的实证分析 - 识别由自然语言表达引用的图像中的对象的任务 - 以获得对这些系统如何原因的洞察关于语言和视觉。令人惊讶的是，我们发现有力的证据表明，即使是针对这一任务的复杂的，语言驱动的模型也可能会忽略语言结构，而是依赖于数据选择和注释过程中由意外偏差引入的浅层相关性。例如，我们显示在输入图像$ \ textit {没有输入引用表达式} $的条件下训练和测试的系统可以在前2次预测中获得71.2％的精度。此外，仅预测给定输入的对象类别的系统在前2个预测中可以实现84.2％的精度。这些令人惊讶的积极结果表明，对于什么应该是不足的预测情景来说，我们试图在基础语言任务上取得实质性进展，认真分析我们的模型正在学习什么 - 进一步说，我们的数据是如何构建的。

##### URL
[http://arxiv.org/abs/1805.11818](http://arxiv.org/abs/1805.11818)

##### PDF
[http://arxiv.org/pdf/1805.11818](http://arxiv.org/pdf/1805.11818)

