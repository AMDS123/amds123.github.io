---
layout: post
title: "Dynamic Meta-Embeddings for Improved Sentence Representations"
date: 2018-09-05 16:12:13
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Douwe Kiela, Changhan Wang, Kyunghyun Cho
mathjax: true
---

* content
{:toc}

##### Abstract
While one of the first steps in many NLP systems is selecting what pre-trained word embeddings to use, we argue that such a step is better left for neural networks to figure out by themselves. To that end, we introduce dynamic meta-embeddings, a simple yet effective method for the supervised learning of embedding ensembles, which leads to state-of-the-art performance within the same model class on a variety of tasks. We subsequently show how the technique can be used to shed new light on the usage of word embeddings in NLP systems.

##### Abstract (translated by Google)
虽然许多NLP系统的第一步是选择要使用的预训练词嵌入，但我们认为这样的步骤最好留给神经网络自己弄清楚。为此，我们引入了动态元嵌入，这是一种简单而有效的嵌入式集合监督学习方法，可以在同一个模型类中对各种任务进行最先进的性能。我们随后展示了该技术如何用于揭示NLP系统中字嵌入的使用。

##### URL
[http://arxiv.org/abs/1804.07983](http://arxiv.org/abs/1804.07983)

##### PDF
[http://arxiv.org/pdf/1804.07983](http://arxiv.org/pdf/1804.07983)

