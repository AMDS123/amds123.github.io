---
layout: post
title: "Learning Factorized Multimodal Representations"
date: 2018-06-16 03:48:50
categories: arXiv_CV
tags: arXiv_CV Sentiment Represenation_Learning
author: Yao-Hung Hubert Tsai, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency, Ruslan Salakhutdinov
mathjax: true
---

* content
{:toc}

##### Abstract
Learning representations of multimodal data is a fundamentally complex research problem due to the presence of multiple sources of information. To address the complexities of multimodal data, we argue that suitable representation learning models should: 1) factorize representations according to independent factors of variation in the data, capture important features for both 2) discriminative and 3) generative tasks, and 4) couple both modality-specific and multimodal information. To encapsulate all these properties, we propose the Multimodal Factorization Model (MFM) that factorizes multimodal representations into two sets of independent factors: multimodal discriminative factors and modality-specific generative factors. Multimodal discriminative factors are shared across all modalities and contain joint multimodal features required for discriminative tasks such as predicting sentiment. Modality-specific generative factors are unique for each modality and contain the information required for generating data. Our experimental results show that our model is able to learn meaningful multimodal representations and achieve state-of-the-art or competitive performance on five multimodal datasets. Our model also demonstrates flexible generative capabilities by conditioning on the independent factors. We further interpret our factorized representations to understand the interactions that influence multimodal learning.

##### Abstract (translated by Google)
由于存在多种信息来源，学习多模式数据的表示是一个根本复杂的研究问题。为了解决多模态数据的复杂性，我们认为合适的表示学习模型应该：1）根据数据变化的独立因素对表征进行因式分解，捕获2）识别和3）生成任务的重要特征4）特定于模态的和多模式的信息。为了将所有这些特性封装起来，我们提出了多模态因子分解模型（Multimodal Factorization Model，MFM），它将多模态表征分解成两组独立因子：多模态识别因子和特定于模态的生成因子。多模态判别因子在所有模态中共享，并包含预测情绪等区分性任务所需的联合多模态特征。特定于模态的生成因子对于每种模式都是独特的，并且包含生成数据所需的信息。我们的实验结果表明，我们的模型能够学习有意义的多模态表示，并在五个多模态数据集上实现最先进或最具竞争力的表现。我们的模型还通过调节独立因素来展现灵活的生成能力。我们进一步解释我们的分解表示以理解影响多模态学习的相互作用。

##### URL
[http://arxiv.org/abs/1806.06176](http://arxiv.org/abs/1806.06176)

##### PDF
[http://arxiv.org/pdf/1806.06176](http://arxiv.org/pdf/1806.06176)

