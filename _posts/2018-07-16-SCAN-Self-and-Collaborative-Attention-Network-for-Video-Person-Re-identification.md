---
layout: post
title: "SCAN: Self-and-Collaborative Attention Network for Video Person Re-identification"
date: 2018-07-16 06:09:24
categories: arXiv_CV
tags: arXiv_CV Re-identification Segmentation Attention Person_Re-identification
author: Ruimao Zhang, Hongbin Sun, Jingyu Li, Yuying Ge, Liang Lin, Ping Luo, Xiaogang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Video person re-identification attracts much attention in recent years. It aims to match image sequences of pedestrians from different camera views. Previous approaches usually improve this task from three aspects, including a) selecting more discriminative frames, b) generating more informative temporal representations, and c) developing more effective distance metrics. To address the above issues, we present a novel and practical deep architecture for video person re-identification termed Self-and-Collaborative Attention Network (SCAN). It has several appealing properties. First, SCAN adopts non-parametric attention mechanism to refine the intra-sequence and inter-sequence feature representation of videos, and outputs self-and-collaborative feature representation for each video, making the discriminative frames aligned between the probe and gallery sequences.Second, beyond existing models, a generalized pairwise similarity measurement is proposed to calculate the similarity feature representations of video pairs, enabling computing the matching scores by the binary classifier. Third, a dense clip segmentation strategy is also introduced to generate rich probe-gallery pairs to optimize the model. Extensive experiments demonstrate the effectiveness of SCAN, which outperforms top-1 accuracies of the best-performing baselines by 7.8%, 2.1% and 4.9% on iLIDS-VID, PRID2011 and MARS dataset, respectively.

##### Abstract (translated by Google)
视频人物重新识别近年来引起了很多关注。它旨在匹配来自不同摄像机视图的行人的图像序列。以前的方法通常从三个方面改进这项任务，包括a）选择更多的判别框架，b）产生更多信息性的时间表示，以及c）开发更有效的距离度量。为了解决上述问题，我们提出了一种新颖实用的深度体系结构，用于视频人员重新识别，称为自我协作注意网络（SCAN）。它有几个吸引人的特性。首先，SCAN采用非参数注意机制来细化视频的序列内和序列间特征表示，并输出每个视频的自协作特征表示，使得判别帧在探测和图库序列之间对齐。在现有模型之外，提出了广义成对相似性度量来计算视频对的相似性特征表示，使得能够通过二元分类器计算匹配得分。第三，还引入了密集剪辑分割策略以生成丰富的探针 - 图库对以优化模型。大量实验证明了SCAN的有效性，它在iLIDS-VID，PRID2011和MARS数据集上分别优于表现最佳的基线的前1个精度7.8％，2.1％和4.9％。

##### URL
[http://arxiv.org/abs/1807.05688](http://arxiv.org/abs/1807.05688)

##### PDF
[http://arxiv.org/pdf/1807.05688](http://arxiv.org/pdf/1807.05688)

