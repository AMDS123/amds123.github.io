---
layout: post
title: "Recursive Recurrent Nets with Attention Modeling for OCR in the Wild"
date: 2016-03-09 23:49:51
categories: arXiv_CV
tags: arXiv_CV OCR Attention CNN RNN Language_Model Recognition
author: Chen-Yu Lee, Simon Osindero
mathjax: true
---

* content
{:toc}

##### Abstract
We present recursive recurrent neural networks with attention modeling (R$^2$AM) for lexicon-free optical character recognition in natural scene images. The primary advantages of the proposed method are: (1) use of recursive convolutional neural networks (CNNs), which allow for parametrically efficient and effective image feature extraction; (2) an implicitly learned character-level language model, embodied in a recurrent neural network which avoids the need to use N-grams; and (3) the use of a soft-attention mechanism, allowing the model to selectively exploit image features in a coordinated way, and allowing for end-to-end training within a standard backpropagation framework. We validate our method with state-of-the-art performance on challenging benchmark datasets: Street View Text, IIIT5k, ICDAR and Synth90k.

##### Abstract (translated by Google)
我们给自然场景图像提供注意建模（R $ ^ 2 $ AM）的递归递归神经网络用于无词汇光学字符识别。所提出的方法的主要优点是：（1）使用递归卷积神经网络（CNN），其允许参数有效和有效的图像特征提取; （2）隐式学习的字符级语言模型，体现在循环神经网络中，避免了使用N-gram的需要; （3）使用软注意机制，允许模型以协调的方式选择性地利用图像特征，并允许在标准反向传播框架内进行端到端的训练。我们验证了我们的方法在具有挑战性的基准数据集上的最新性能：街景文本，IIIT5k，ICDAR和Synth90k。

##### URL
[https://arxiv.org/abs/1603.03101](https://arxiv.org/abs/1603.03101)

##### PDF
[https://arxiv.org/pdf/1603.03101](https://arxiv.org/pdf/1603.03101)

