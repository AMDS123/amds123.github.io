---
layout: post
title: "Towards More Realistic Human-Robot Conversation: A Seq2Seq-based Body Gesture Interaction System"
date: 2019-05-05 09:53:29
categories: arXiv_CV
tags: arXiv_CV
author: Minjie Hua, Fuyuan Shi, Yibing Nan, Kai Wang, Hao Chen, Shiguo Lian
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a novel method to improve the conversational interaction abilities of intelligent robots to enable more realistic body gestures. The sequence-to-sequence (seq2seq) model is adapted for synthesizing the robots' body gestures represented by the movements of twelve upper-body keypoints in not only the speaking phase, but also the listening phase for which previous methods can hardly achieve. We collected and preprocessed substantial videos of human conversation from Youtube to train our seq2seq-based models and evaluated them by the mean squared error (MSE) and cosine similarity on the test set. The tuned models were implemented to drive a virtual avatar as well as a physical humanoid robot, to demonstrate the improvement on interaction abilities of our method in practice. With body gestures synthesized by our models, the avatar and Pepper exhibited more intelligently while communicating with humans.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.01641](http://arxiv.org/abs/1905.01641)

##### PDF
[http://arxiv.org/pdf/1905.01641](http://arxiv.org/pdf/1905.01641)

