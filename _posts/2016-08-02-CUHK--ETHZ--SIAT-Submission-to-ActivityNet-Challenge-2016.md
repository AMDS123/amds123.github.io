---
layout: post
title: "CUHK & ETHZ & SIAT Submission to ActivityNet Challenge 2016"
date: 2016-08-02 12:58:30
categories: arXiv_CV
tags: arXiv_CV Attention Video_Classification Classification
author: Yuanjun Xiong, Limin Wang, Zhe Wang, Bowen Zhang, Hang Song, Wei Li, Dahua Lin, Yu Qiao, Luc Van Gool, Xiaoou Tang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents the method that underlies our submission to the untrimmed video classification task of ActivityNet Challenge 2016. We follow the basic pipeline of temporal segment networks and further raise the performance via a number of other techniques. Specifically, we use the latest deep model architecture, e.g., ResNet and Inception V3, and introduce new aggregation schemes (top-k and attention-weighted pooling). Additionally, we incorporate the audio as a complementary channel, extracting relevant information via a CNN applied to the spectrograms. With these techniques, we derive an ensemble of deep models, which, together, attains a high classification accuracy (mAP $93.23\%$) on the testing set and secured the first place in the challenge.

##### Abstract (translated by Google)
本文提出了基于我们提交给2016年ActivityNet Challenge的未修剪视频分类任务的方法。我们遵循时间分段网络的基本流程，并通过其他一些技术进一步提高性能。具体而言，我们使用最新的深层模型架构，例如ResNet和Inception V3，并引入新的聚合方案（top-k和注意力加权池）。此外，我们将音频作为补充渠道，通过应用于频谱图的CNN提取相关信息。利用这些技术，我们得到了一个深度模型的集合，它们一起在测试集上获得了很高的分类精确度（93.23％），并在挑战中获得了第一名。

##### URL
[https://arxiv.org/abs/1608.00797](https://arxiv.org/abs/1608.00797)

##### PDF
[https://arxiv.org/pdf/1608.00797](https://arxiv.org/pdf/1608.00797)

