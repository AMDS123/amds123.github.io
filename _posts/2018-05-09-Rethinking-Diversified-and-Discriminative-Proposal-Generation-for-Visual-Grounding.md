---
layout: post
title: "Rethinking Diversified and Discriminative Proposal Generation for Visual Grounding"
date: 2018-05-09 13:25:27
categories: arXiv_CV
tags: arXiv_CV
author: Zhou Yu, Jun Yu, Chenchao Xiang, Zhou Zhao, Qi Tian, Dacheng Tao
mathjax: true
---

* content
{:toc}

##### Abstract
Visual grounding aims to localize an object in an image referred to by a textual query phrase. Various visual grounding approaches have been proposed, and the problem can be modularized into a general framework: proposal generation, multi-modal feature representation, and proposal ranking. Of these three modules, most existing approaches focus on the latter two, with the importance of proposal generation generally neglected. In this paper, we rethink the problem of what properties make a good proposal generator. We introduce the diversity and discrimination simultaneously when generating proposals, and in doing so propose Diversified and Discriminative Proposal Networks model (DDPN). Based on the proposals generated by DDPN, we propose a high performance baseline model for visual grounding and evaluate it on four benchmark datasets. Experimental results demonstrate that our model delivers significant improvements on all the tested data-sets (e.g., 18.8\% improvement on ReferItGame and 8.2\% improvement on Flickr30k Entities over the existing state-of-the-arts respectively)

##### Abstract (translated by Google)
视觉基础旨在将文本中的对象本地化为由文本查询短语引用的图像。已经提出了各种视觉接地方法，并且该问题可以被模块化为一般框架：提案生成，多模式特征表示和提议排名。在这三个模块中，大多数现有的方法都侧重于后两个模块，而提案生成的重要性通常被忽略。在本文中，我们重新思考哪些属性会成为一个好的提案生成器。我们在提出建议时同时引入多样性和歧视，并在此提出多元化和区分性提议网络模型（DDPN）。根据DDPN提出的建议，我们提出了一个高性能的视觉基准基线模型，并在四个基准数据集上进行评估。实验结果表明，我们的模型在所有测试的数据集上都有显着的改进（例如，ReferItGame改进18.8％，Flickr30k实体改善8.2％）分别高于现有技术水平）

##### URL
[http://arxiv.org/abs/1805.03508](http://arxiv.org/abs/1805.03508)

##### PDF
[http://arxiv.org/pdf/1805.03508](http://arxiv.org/pdf/1805.03508)

