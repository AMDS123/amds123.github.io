---
layout: post
title: "Improving interactive reinforcement learning: What makes a good teacher?"
date: 2019-04-15 07:17:20
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Francisco Cruz, Sven Magg, Yukie Nagai, Stefan Wermter
mathjax: true
---

* content
{:toc}

##### Abstract
Interactive reinforcement learning has become an important apprenticeship approach to speed up convergence in classic reinforcement learning problems. In this regard, a variant of interactive reinforcement learning is policy shaping which uses a parent-like trainer to propose the next action to be performed and by doing so reduces the search space by advice. On some occasions, the trainer may be another artificial agent which in turn was trained using reinforcement learning methods to afterward becoming an advisor for other learner-agents. In this work, we analyze internal representations and characteristics of artificial agents to determine which agent may outperform others to become a better trainer-agent. Using a polymath agent, as compared to a specialist agent, an advisor leads to a larger reward and faster convergence of the reward signal and also to a more stable behavior in terms of the state visit frequency of the learner-agents. Moreover, we analyze system interaction parameters in order to determine how influential they are in the apprenticeship process, where the consistency of feedback is much more relevant when dealing with different learner obedience parameters.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.06879](http://arxiv.org/abs/1904.06879)

##### PDF
[http://arxiv.org/pdf/1904.06879](http://arxiv.org/pdf/1904.06879)

