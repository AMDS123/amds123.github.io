---
layout: post
title: "Surgical Activity Recognition in Robot-Assisted Radical Prostatectomy using Deep Learning"
date: 2018-06-01 17:55:38
categories: arXiv_CV
tags: arXiv_CV RNN Deep_Learning Recognition
author: Aneeq Zia, Andrew Hung, Irfan Essa, Anthony Jarc
mathjax: true
---

* content
{:toc}

##### Abstract
Adverse surgical outcomes are costly to patients and hospitals. Approaches to benchmark surgical care are often limited to gross measures across the entire procedure despite the performance of particular tasks being largely responsible for undesirable outcomes. In order to produce metrics from tasks as opposed to the whole procedure, methods to recognize automatically individual surgical tasks are needed. In this paper, we propose several approaches to recognize surgical activities in robot-assisted minimally invasive surgery using deep learning. We collected a clinical dataset of 100 robot-assisted radical prostatectomies (RARP) with 12 tasks each and propose `RP-Net', a modified version of InceptionV3 model, for image based surgical activity recognition. We achieve an average precision of 80.9% and average recall of 76.7% across all tasks using RP-Net which out-performs all other RNN and CNN based models explored in this paper. Our results suggest that automatic surgical activity recognition during RARP is feasible and can be the foundation for advanced analytics.

##### Abstract (translated by Google)
不良的手术结果对患者和医院来说是昂贵的。基准手术护理的方法往往局限于整个手术过程中的总体措施，尽管特定任务的执行主要是造成不良后果的原因。为了从任务产生度量而不是整个程序，需要自动识别个体手术任务的方法。在本文中，我们提出了几种方法来识别使用深度学习的机器人辅助微创手术中的手术活动。我们收集了100个机器人辅助根治性前列腺切除术（RARP）的临床数据集，每个12个任务，并提出基于图像的手术活动识别的“RP-Net”，InceptionV3模型的修改版本。在所有使用RP-Net的任务中，我们的平均精度达到80.9％，平均召回率达到76.7％，超出了本文探讨的所有其他基于RNN和CNN的模型。我们的研究结果表明，在RARP期间识别自动手术活动是可行的，并且可以成为高级分析的基础。

##### URL
[http://arxiv.org/abs/1806.00466](http://arxiv.org/abs/1806.00466)

##### PDF
[http://arxiv.org/pdf/1806.00466](http://arxiv.org/pdf/1806.00466)

