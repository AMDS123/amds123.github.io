---
layout: post
title: "Shortcut-Stacked Sentence Encoders for Multi-Domain Inference"
date: 2017-11-28 18:15:47
categories: arXiv_CL
tags: arXiv_CL Embedding Inference RNN Relation
author: Yixin Nie, Mohit Bansal
mathjax: true
---

* content
{:toc}

##### Abstract
We present a simple sequential sentence encoder for multi-domain natural language inference. Our encoder is based on stacked bidirectional LSTM-RNNs with shortcut connections and fine-tuning of word embeddings. The overall supervised model uses the above encoder to encode two input sentences into two vectors, and then uses a classifier over the vector combination to label the relationship between these two sentences as that of entailment, contradiction, or neural. Our Shortcut-Stacked sentence encoders achieve strong improvements over existing encoders on matched and mismatched multi-domain natural language inference (top non-ensemble single-model result in the EMNLP RepEval 2017 Shared Task (Nangia et al., 2017)). Moreover, they achieve the new state-of-the-art encoding result on the original SNLI dataset (Bowman et al., 2015).

##### Abstract (translated by Google)
我们提出了一个简单的顺序句子编码器的多领域的自然语言推理。我们的编码器基于堆栈双向LSTM-RNN，具有快捷连接和微调字嵌入。整体监督模型使用上述编码器将两个输入句子编码成两个矢量，然后使用矢量组合上的分类器将这两个句子之间的关系标记为包含，矛盾或神经元之间的关系。我们的Shortcut-Stacked语句编码器在匹配和不匹配的多领域自然语言推理（EMNLP RepEval 2017共享任务（Nangia等人，2017）中最高的非整体单模型结果）上实现了对现有编码器的强大改进。此外，他们在原始的SNLI数据集上实现了最新的最新编码结果（Bowman等，2015）。

##### URL
[https://arxiv.org/abs/1708.02312](https://arxiv.org/abs/1708.02312)

##### PDF
[https://arxiv.org/pdf/1708.02312](https://arxiv.org/pdf/1708.02312)

