---
layout: post
title: "Learning Multi-level Features For Sensor-based Human Action Recognition"
date: 2017-09-02 17:57:21
categories: arXiv_CV
tags: arXiv_CV Action_Recognition Recognition
author: Yan Xu, Zhengyang Shen, Xin Zhang, Yifan Gao, Shujian Deng, Yipei Wang, Yubo Fan, Eric I-Chao Chang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a multi-level feature learning framework for human action recognition using a single body-worn inertial sensor. The framework consists of three phases, respectively designed to analyze signal-based (low-level), components (mid-level) and semantic (high-level) information. Low-level features capture the time and frequency domain property while mid-level representations learn the composition of the action. The Max-margin Latent Pattern Learning (MLPL) method is proposed to learn high-level semantic descriptions of latent action patterns as the output of our framework. The proposed method achieves the state-of-the-art performances, 88.7%, 98.8% and 72.6% (weighted F1 score) respectively, on Skoda, WISDM and OPP datasets.

##### Abstract (translated by Google)
本文提出了一个使用单个体戴式惯性传感器的人类行为识别多层次特征学习框架。该框架由三个阶段组成，分别设计用于分析基于信号的（低级），组件（中级）和语义（高级）信息。低级特征捕获时间和频域属性，而中级表征学习动作的组成。提出了最大边缘潜在模式学习（MLPL）方法来学习潜在动作模式的高级语义描述作为框架的输出。所提出的方法在斯柯达，WISDM和OPP数据集上分别达到了88.7％，98.8％和72.6％（加权F1分）的最新成绩。

##### URL
[https://arxiv.org/abs/1611.07143](https://arxiv.org/abs/1611.07143)

##### PDF
[https://arxiv.org/pdf/1611.07143](https://arxiv.org/pdf/1611.07143)

