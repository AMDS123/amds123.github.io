---
layout: post
title: "Multimedia Semantic Integrity Assessment Using Joint Embedding Of Images And Text"
date: 2018-06-29 00:34:27
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption Embedding Represenation_Learning Deep_Learning Quantitative
author: Ayush Jaiswal, Ekraam Sabir, Wael AbdAlmageed, Premkumar Natarajan
mathjax: true
---

* content
{:toc}

##### Abstract
Real world multimedia data is often composed of multiple modalities such as an image or a video with associated text (e.g. captions, user comments, etc.) and metadata. Such multimodal data packages are prone to manipulations, where a subset of these modalities can be altered to misrepresent or repurpose data packages, with possible malicious intent. It is, therefore, important to develop methods to assess or verify the integrity of these multimedia packages. Using computer vision and natural language processing methods to directly compare the image (or video) and the associated caption to verify the integrity of a media package is only possible for a limited set of objects and scenes. In this paper, we present a novel deep learning-based approach for assessing the semantic integrity of multimedia packages containing images and captions, using a reference set of multimedia packages. We construct a joint embedding of images and captions with deep multimodal representation learning on the reference dataset in a framework that also provides image-caption consistency scores (ICCSs). The integrity of query media packages is assessed as the inlierness of the query ICCSs with respect to the reference dataset. We present the MultimodAl Information Manipulation dataset (MAIM), a new dataset of media packages from Flickr, which we make available to the research community. We use both the newly created dataset as well as Flickr30K and MS COCO datasets to quantitatively evaluate our proposed approach. The reference dataset does not contain unmanipulated versions of tampered query packages. Our method is able to achieve F1 scores of 0.75, 0.89 and 0.94 on MAIM, Flickr30K and MS COCO, respectively, for detecting semantically incoherent media packages.

##### Abstract (translated by Google)
真实世界多媒体数据通常由多种模态组成，例如图像或具有相关文本的视频（例如字幕，用户评论等）和元数据。这样的多模式数据包易于操纵，其中可以改变这些模态的子集以歪曲或重新利用数据包，具有可能的恶意意图。因此，开发评估或验证这些多媒体包的完整性的方法是很重要的。使用计算机视觉和自然语言处理方法直接比较图像（或视频）和相关标题以验证媒体包的完整性仅对于有限的一组对象和场景是可能的。在本文中，我们提出了一种新颖的基于深度学习的方法，用于使用多媒体包的参考集来评估包含图像和字幕的多媒体包的语义完整性。我们在一个框架中构建图像和字幕的联合嵌入，在参考数据集上进行深度多模态表示学习，该框架还提供图像标题一致性分数（ICCS）。查询媒体包的完整性被评估为查询ICCS相对于参考数据集的内在性。我们提供了MultimodAl信息操作数据集（MAIM），这是一个来自Flickr的媒体包的新数据集，我们将其提供给研究社区。我们使用新创建的数据集以及Flickr30K和MS COCO数据集来定量评估我们提出的方法。参考数据集不包含未经操作的篡改查询包版本。我们的方法能够分别在MAIM，Flickr30K和MS COCO上获得0.75,0.89和0.94的F1分数，用于检测语义不相干的媒体包。

##### URL
[https://arxiv.org/abs/1707.01606](https://arxiv.org/abs/1707.01606)

##### PDF
[https://arxiv.org/pdf/1707.01606](https://arxiv.org/pdf/1707.01606)

