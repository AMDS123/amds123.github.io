---
layout: post
title: "OpenSpiel: A Framework for Reinforcement Learning in Games"
date: 2019-08-26 03:31:35
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Marc Lanctot, Edward Lockhart, Jean-Baptiste Lespiau, Vinicius Zambaldi, Satyaki Upadhyay, Julien P&#xe9;rolat, Sriram Srinivasan, Finbarr Timbers, Karl Tuyls, Shayegan Omidshafiei, Daniel Hennes, Dustin Morrill, Paul Muller, Timo Ewalds, Ryan Faulkner, J&#xe1;nos Kram&#xe1;r, Bart De Vylder, Brennan Saeta, James Bradbury, David Ding, Sebastian Borgeaud, Matthew Lai, Julian Schrittwieser, Thomas Anthony, Edward Hughes, Ivo Danihelka, Jonah Ryan-Davis
mathjax: true
---

* content
{:toc}

##### Abstract
OpenSpiel is a collection of environments and algorithms for research in general reinforcement learning and search/planning in games. OpenSpiel supports n-player (single- and multi- agent) zero-sum, cooperative and general-sum, one-shot and sequential, strictly turn-taking and simultaneous-move, perfect and imperfect information games, as well as traditional multiagent environments such as (partially- and fully observable) grid worlds and social dilemmas. OpenSpiel also includes tools to analyze learning dynamics and other common evaluation metrics. This document serves both as an overview of the code base and an introduction to the terminology, core concepts, and algorithms across the fields of reinforcement learning, computational game theory, and search.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.09453](http://arxiv.org/abs/1908.09453)

##### PDF
[http://arxiv.org/pdf/1908.09453](http://arxiv.org/pdf/1908.09453)

