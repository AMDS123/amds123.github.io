---
layout: post
title: "Trusted Neural Networks for Safety-Constrained Autonomous Control"
date: 2018-05-18 07:17:15
categories: arXiv_AI
tags: arXiv_AI Knowledge Optimization Gradient_Descent
author: Shalini Ghosh, Amaury Mercier, Dheeraj Pichapati, Susmit Jha, Vinod Yegneswaran, Patrick Lincoln
mathjax: true
---

* content
{:toc}

##### Abstract
We propose Trusted Neural Network (TNN) models, which are deep neural network models that satisfy safety constraints critical to the application domain. We investigate different mechanisms for incorporating rule-based knowledge in the form of first-order logic constraints into a TNN model, where rules that encode safety are accompanied by weights indicating their relative importance. This framework allows the TNN model to learn from knowledge available in form of data as well as logical rules. We propose multiple approaches for solving this problem: (a) a multi-headed model structure that allows trade-off between satisfying logical constraints and fitting training data in a unified training framework, and (b) creating a constrained optimization problem and solving it in dual formulation by posing a new constrained loss function and using a proximal gradient descent algorithm. We demonstrate the efficacy of our TNN framework through experiments using the open-source TORCS~\cite{BernhardCAA15} 3D simulator for self-driving cars. Experiments using our first approach of a multi-headed TNN model, on a dataset generated by a customized version of TORCS, show that (1) adding safety constraints to a neural network model results in increased performance and safety, and (2) the improvement increases with increasing importance of the safety constraints. Experiments were also performed using the second approach of proximal algorithm for constrained optimization --- they demonstrate how the proposed method ensures that (1) the overall TNN model satisfies the constraints even when the training data violates some of the constraints, and (2) the proximal gradient descent algorithm on the constrained objective converges faster than the unconstrained version.

##### Abstract (translated by Google)
我们提出了可信神经网络（TNN）模型，它们是满足对应用领域至关重要的安全约束条件的深度神经网络模型。我们研究了将基于规则的知识以一阶逻辑约束的形式纳入TNN模型的不同机制，其中编码安全性的规则伴随着表示其相对重要性的权重。这个框架允许TNN模型学习数据形式的知识以及逻辑规则。我们提出了多种方法来解决这个问题：（a）一个多头模型结构，允许在满足逻辑约束和适合训练数据的统一训练框架之间进行权衡，以及（b）创建一个约束优化问题并解决它通过构造新的约束损失函数并使用近端梯度下降算法来进行双重制定。我们通过使用开源TORCS〜\ cite {BernhardCAA15} 3D自驾车模拟器的实验，展示了TNN框架的功效。使用我们的第一种多头TNN模型的方法，在由定制版本的TORCS生成的数据集上的实验表明：（1）将安全约束添加到神经网络模型导致性能和安全性的提高，以及（2）改进随着安全限制的重要性增加而增加。实验还使用近端算法的第二种方法进行约束优化 - 它们展示了所提出的方法如何确保：（1）即使训练数据违反了一些约束条件，整体TNN模型也满足约束条件;（2）约束目标上的近端梯度下降算法收敛速度快于无约束版本。

##### URL
[http://arxiv.org/abs/1805.07075](http://arxiv.org/abs/1805.07075)

##### PDF
[http://arxiv.org/pdf/1805.07075](http://arxiv.org/pdf/1805.07075)

