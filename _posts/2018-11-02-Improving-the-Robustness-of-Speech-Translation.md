---
layout: post
title: "Improving the Robustness of Speech Translation"
date: 2018-11-02 03:56:42
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition NMT Recognition
author: Xiang Li, Haiyang Xue, Wei Chen, Yang Liu, Yang Feng, Qun Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Although neural machine translation (NMT) has achieved impressive progress recently, it is usually trained on the clean parallel data set and hence cannot work well when the input sentence is the production of the automatic speech recognition (ASR) system due to the enormous errors in the source. To solve this problem, we propose a simple but effective method to improve the robustness of NMT in the case of speech translation. We simulate the noise existing in the realistic output of the ASR system and inject them into the clean parallel data so that NMT can work under similar word distributions during training and testing. Besides, we also incorporate the Chinese Pinyin feature which is easy to get in speech translation to further improve the translation performance. Experiment results show that our method has a more stable performance and outperforms the baseline by an average of 3.12 BLEU on multiple noisy test sets, even while achieves a generalization improvement on the WMT'17 Chinese-English test set.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.00728](http://arxiv.org/abs/1811.00728)

##### PDF
[http://arxiv.org/pdf/1811.00728](http://arxiv.org/pdf/1811.00728)

