---
layout: post
title: "Computing Approximate Equilibria in Sequential Adversarial Games by Exploitability Descent"
date: 2019-03-13 17:27:04
categories: arXiv_AI
tags: arXiv_AI Adversarial Knowledge Optimization
author: Edward Lockhart, Marc Lanctot, Julien P&#xe9;rolat, Jean-Baptiste Lespiau, Dustin Morrill, Finbarr Timbers, Karl Tuyls
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present exploitability descent, a new algorithm to compute approximate equilibria in two-player zero-sum extensive-form games with imperfect information, by direct policy optimization against worst-case opponents. We prove that when following this optimization, the exploitability of a player's strategy converges asymptotically to zero, and hence when both players employ this optimization, the joint policies converge to a Nash equilibrium. Unlike fictitious play (XFP) and counterfactual regret minimization (CFR), our convergence result pertains to the policies being optimized rather than the average policies. Our experiments demonstrate convergence rates comparable to XFP and CFR in four benchmark games in the tabular case. Using function approximation, we find that our algorithm outperforms the tabular version in two of the games, which, to the best of our knowledge, is the first such result in imperfect information games among this class of algorithms.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.05614](http://arxiv.org/abs/1903.05614)

##### PDF
[http://arxiv.org/pdf/1903.05614](http://arxiv.org/pdf/1903.05614)

