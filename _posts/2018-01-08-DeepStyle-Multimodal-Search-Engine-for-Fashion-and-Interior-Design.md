---
layout: post
title: "DeepStyle: Multimodal Search Engine for Fashion and Interior Design"
date: 2018-01-08 14:08:55
categories: arXiv_CV
tags: arXiv_CV
author: Ivona Tautkute, Tomasz Trzcinski, Aleksander Skorupa, Lukasz Brocki, Krzysztof Marasek
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a multimodal search engine that combines visual and textual cues to retrieve items from a multimedia database aesthetically similar to the query. The goal of our engine is to enable intuitive retrieval of fashion merchandise such as clothes or furniture. Existing search engines treat textual input only as an additional source of information about the query image and do not correspond to the real-life scenario where the user looks for 'the same shirt but of denim'. Our novel method, dubbed DeepStyle, mitigates those shortcomings by using a joint neural network architecture to model contextual dependencies between features of different modalities. We prove the robustness of this approach on two different challenging datasets of fashion items and furniture where our DeepStyle engine outperforms baseline methods by 18-21% on the tested datasets. Our search engine is commercially deployed and available through a Web-based application.

##### Abstract (translated by Google)
在本文中，我们提出了一种多模式搜索引擎，它结合了视觉和文本提示，从美学上类似于查询的多媒体数据库中检索项目。我们的引擎的目标是使服装或家具等时尚商品的直观检索。现有的搜索引擎仅将文本输入视为关于查询图像的附加信息源，并不对应于用户寻找“同一件衬衫而是牛仔布”的真实场景。我们的新方法，被称为DeepStyle，通过使用联合神经网络架构来模拟不同模式的特征之间的上下文相关性，从而减轻了这些缺点。我们证明了这种方法在时尚物品和家具的两个不同具有挑战性的数据集上的稳健性，其中我们的DeepStyle引擎在测试数据集上胜过基准方法的18-21％。我们的搜索引擎是商业部署的，可以通过基于Web的应用程序。

##### URL
[http://arxiv.org/abs/1801.03002](http://arxiv.org/abs/1801.03002)

##### PDF
[http://arxiv.org/pdf/1801.03002](http://arxiv.org/pdf/1801.03002)

