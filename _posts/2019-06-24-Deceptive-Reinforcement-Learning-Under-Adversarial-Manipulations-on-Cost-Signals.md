---
layout: post
title: "Deceptive Reinforcement Learning Under Adversarial Manipulations on Cost Signals"
date: 2019-06-24 15:48:54
categories: arXiv_AI
tags: arXiv_AI Adversarial Reinforcement_Learning Quantitative Relation
author: Yunhan Huang, Quanyan Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper studies reinforcement learning (RL) under malicious falsification on cost signals and introduces a quantitative framework of attack models to understand the vulnerabilities of RL. Focusing on $Q$-learning, we show that $Q$-learning algorithms converge under stealthy attacks and bounded falsifications on cost signals. We characterize the relation between the falsified cost and the $Q$-factors as well as the policy learned by the learning agent which provides fundamental limits for feasible offensive and defensive moves. We propose a robust region in terms of the cost within which the adversary can never achieve the targeted policy. We provide conditions on the falsified cost which can mislead the agent to learn an adversary's favored policy. A numerical case study of water reservoir control is provided to show the potential hazards of RL in learning-based control systems and corroborate the results.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.10571](http://arxiv.org/abs/1906.10571)

##### PDF
[http://arxiv.org/pdf/1906.10571](http://arxiv.org/pdf/1906.10571)

