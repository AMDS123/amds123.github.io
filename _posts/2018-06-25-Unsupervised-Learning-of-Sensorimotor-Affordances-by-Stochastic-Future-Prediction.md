---
layout: post
title: "Unsupervised Learning of Sensorimotor Affordances by Stochastic Future Prediction"
date: 2018-06-25 18:33:34
categories: arXiv_CV
tags: arXiv_CV Embedding Prediction
author: Oleh Rybkin, Karl Pertsch, Andrew Jaegle, Konstantinos G. Derpanis, Kostas Daniilidis
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, much progress has been made building systems that can capture static image properties, but natural environments are intrinsically dynamic. For an intelligent agent, perception is responsible not only for capturing features of scene content, but also capturing its \textit{affordances}: how the state of things can change, especially as the result of the agent's actions. We propose an unsupervised method to learn representations of the sensorimotor affordances of an environment. We do so by learning an embedding for stochastic future prediction that is (i) sensitive to scene dynamics and minimally sensitive to static scene content and (ii) compositional in nature, capturing the fact that changes in the environment can be composed to produce a cumulative change. We show that these two properties are sufficient to induce representations that are reusable across visually distinct scenes that share degrees of freedom. We show the applicability of our method to synthetic settings and its potential for understanding more complex, realistic visual settings.

##### Abstract (translated by Google)
最近，构建可捕获静态图像属性的系统已取得很大进展，但自然环境本质上是动态的。对于一个智能代理人来说，感知不仅负责捕捉场景内容的特征，而且还要捕捉它的\ textit {可供性}：事物状态如何改变，特别是作为代理人行为的结果。我们提出一种无监督的方法来学习环境感觉运动可供性的表示。我们通过学习随机未来预测的嵌入来实现这一点，该预测是（i）对场景动态敏感并对静态场景内容最小敏感，和（ii）本质上是构图，捕捉到环境变化可以被组合以产生累积更改。我们表明，这两个属性足以诱导可重复使用跨视觉不同场景共享自由度的表示。我们展示了我们的方法对综合设置的适用性，以及它对理解更复杂，更真实的视觉设置的潜力。

##### URL
[http://arxiv.org/abs/1806.09655](http://arxiv.org/abs/1806.09655)

##### PDF
[http://arxiv.org/pdf/1806.09655](http://arxiv.org/pdf/1806.09655)

