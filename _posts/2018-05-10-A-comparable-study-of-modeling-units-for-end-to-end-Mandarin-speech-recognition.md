---
layout: post
title: "A comparable study of modeling units for end-to-end Mandarin speech recognition"
date: 2018-05-10 05:54:32
categories: arXiv_CL
tags: arXiv_CL Attention Speech_Recognition Classification Recognition
author: Wei Zou, Dongwei Jiang, Shuaijiang Zhao, Xiangang Li
mathjax: true
---

* content
{:toc}

##### Abstract
End-To-End speech recognition have become increasingly popular in mandarin speech recognition and achieved delightful performance. 
 Mandarin is a tonal language which is different from English and requires special treatment for the acoustic modeling units. There have been several different kinds of modeling units for mandarin such as phoneme, syllable and Chinese character. 
 In this work, we explore two major end-to-end models: connectionist temporal classification (CTC) model and attention based encoder-decoder model for mandarin speech recognition. We compare the performance of three different scaled modeling units: context dependent phoneme(CDP), syllable with tone and Chinese character. 
 We find that all types of modeling units can achieve approximate character error rate (CER) in CTC model and the performance of Chinese character attention model is better than syllable attention model. Furthermore, we find that Chinese character is a reasonable unit for mandarin speech recognition. On DidiCallcenter task, Chinese character attention model achieves a CER of 5.68\% and CTC model gets a CER of 7.29\%, on the other DidiReading task, CER are 4.89\% and 5.79\%, respectively. Moreover, attention model achieves a better performance than CTC model on both datasets.

##### Abstract (translated by Google)
端到端语音识别在普通话语音识别中越来越受欢迎，并取得了令人满意的性能。
 普通话是一种不同于英语的音调语言，需要对声学建模单元进行特殊处理。普通话有几种不同的建模单元，如音素，音节和汉字。
 在这项工作中，我们探讨了两种主要的端到端模型：连接主义时态分类（CTC）模型和基于注意的普通话语音识别编码器 - 解码器模型。我们比较三种不同缩放建模单元的性能：上下文相关音素（CDP），音调和汉字。
 我们发现，所有类型的建模单元都可以达到CTC模型中的近似字符错误率（CER），汉字注意模型的性能优于音节注意模型。此外，我们发现汉字是普通话语音识别的合理单位。在DidiCallcenter任务中，汉字关注模型达到5.68％的CER和CTC模型获得7.29％的CER，另一个DidiReading任务的CER分别为4.89％和5.79％。此外，在两个数据集上，注意模型都比CTC模型获得更好的性能。

##### URL
[http://arxiv.org/abs/1805.03832](http://arxiv.org/abs/1805.03832)

##### PDF
[http://arxiv.org/pdf/1805.03832](http://arxiv.org/pdf/1805.03832)

