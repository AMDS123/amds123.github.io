---
layout: post
title: "Is It Worth the Attention? A Comparative Evaluation of Attention Layers for Argument Unit Segmentation"
date: 2019-06-24 16:40:47
categories: arXiv_CL
tags: arXiv_CL Segmentation Attention Embedding
author: Maximilian Splieth&#xf6;ver, Jonas Klaff, Hendrik Heuer
mathjax: true
---

* content
{:toc}

##### Abstract
Attention mechanisms have seen some success for natural language processing downstream tasks in recent years and generated new State-of-the-Art results. A thorough evaluation of the attention mechanism for the task of Argumentation Mining is missing, though. With this paper, we report a comparative evaluation of attention layers in combination with a bidirectional long short-term memory network, which is the current state-of-the-art approach to the unit segmentation task. We also compare sentence-level contextualized word embeddings to pre-generated ones. Our findings suggest that for this task the additional attention layer does not improve upon a less complex approach. In most cases, the contextualized embeddings do also not show an improvement on the baseline score.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.10068](http://arxiv.org/abs/1906.10068)

##### PDF
[http://arxiv.org/pdf/1906.10068](http://arxiv.org/pdf/1906.10068)

