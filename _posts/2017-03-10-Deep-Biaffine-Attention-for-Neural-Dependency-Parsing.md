---
layout: post
title: "Deep Biaffine Attention for Neural Dependency Parsing"
date: 2017-03-10 04:37:03
categories: arXiv_CL
tags: arXiv_CL Attention RNN
author: Timothy Dozat, Christopher D. Manning
mathjax: true
---

* content
{:toc}

##### Abstract
This paper builds off recent work from Kiperwasser & Goldberg (2016) using neural attention in a simple graph-based dependency parser. We use a larger but more thoroughly regularized parser than other recent BiLSTM-based approaches, with biaffine classifiers to predict arcs and labels. Our parser gets state of the art or near state of the art performance on standard treebanks for six different languages, achieving 95.7% UAS and 94.1% LAS on the most popular English PTB dataset. This makes it the highest-performing graph-based parser on this benchmark---outperforming Kiperwasser Goldberg (2016) by 1.8% and 2.2%---and comparable to the highest performing transition-based parser (Kuncoro et al., 2016), which achieves 95.8% UAS and 94.6% LAS. We also show which hyperparameter choices had a significant effect on parsing accuracy, allowing us to achieve large gains over other graph-based approaches.

##### Abstract (translated by Google)
本文使用基于图形的简单依赖分析器，利用神经关注构建了Kiperwasser＆Goldberg（2016）最近的工作。我们使用比其他最近的基于BiLSTM的方法更大但更彻底的正则化解析器，用偏向量分类器来预测弧和标签。我们的解析器获得六种不同语言的标准树库上的艺术表现或接近艺术表现的水平，在最流行的英语PTB数据集上获得95.7％的UAS和94.1％的LAS。这使得它在这个基准测试中表现最好的基于图表的解析器---比Kiperwasser Goldberg（2016年）高出1.8％和2.2％---并且与表现最好的基于过渡的解析器相比（Kuncoro等，2016年） ，达到95.8％的无人机和94.6％的LAS。我们还显示哪些超参数选择对分析的准确性有重大影响，使我们能够比其他基于图的方法获得更大的收益。

##### URL
[https://arxiv.org/abs/1611.01734](https://arxiv.org/abs/1611.01734)

##### PDF
[https://arxiv.org/pdf/1611.01734](https://arxiv.org/pdf/1611.01734)

