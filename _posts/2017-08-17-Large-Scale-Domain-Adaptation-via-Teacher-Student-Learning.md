---
layout: post
title: "Large-Scale Domain Adaptation via Teacher-Student Learning"
date: 2017-08-17 23:37:18
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition Recognition
author: Jinyu Li, Michael L. Seltzer, Xi Wang, Rui Zhao, Yifan Gong
mathjax: true
---

* content
{:toc}

##### Abstract
High accuracy speech recognition requires a large amount of transcribed data for supervised training. In the absence of such data, domain adaptation of a well-trained acoustic model can be performed, but even here, high accuracy usually requires significant labeled data from the target domain. In this work, we propose an approach to domain adaptation that does not require transcriptions but instead uses a corpus of unlabeled parallel data, consisting of pairs of samples from the source domain of the well-trained model and the desired target domain. To perform adaptation, we employ teacher/student (T/S) learning, in which the posterior probabilities generated by the source-domain model can be used in lieu of labels to train the target-domain model. We evaluate the proposed approach in two scenarios, adapting a clean acoustic model to noisy speech and adapting an adults speech acoustic model to children speech. Significant improvements in accuracy are obtained, with reductions in word error rate of up to 44% over the original source model without the need for transcribed data in the target domain. Moreover, we show that increasing the amount of unlabeled data results in additional model robustness, which is particularly beneficial when using simulated training data in the target-domain.

##### Abstract (translated by Google)
高精度的语音识别需要大量的转录数据进行监督训练。在没有这样的数据的情况下，可以执行训练良好的声学模型的域适应，但是即使在这里，高精度通常也需要来自目标域的重要标记数据。在这项工作中，我们提出了一种不需要转录的领域适应的方法，而是使用由未训练的并行数据组成的语料库，其由来自训练良好的模型的源域和期望的目标域的样本对组成。为了进行适应，我们采用教师/学生（T / S）学习，其中由源域模型生成的后验概率可以代替标签来训练目标域模型。我们在两种情况下评估提出的方法，使干净的声学模型适应有噪语音，并使成人语音声学模型适应儿童言语。准确性得到显着提高，与原始源模型相比，字错误率降低高达44％，而不需要目标域中的转录数据。此外，我们表明，增加未标记数据的数量会产生额外的模型鲁棒性，这在使用目标域中的模拟训练数据时特别有利。

##### URL
[https://arxiv.org/abs/1708.05466](https://arxiv.org/abs/1708.05466)

##### PDF
[https://arxiv.org/pdf/1708.05466](https://arxiv.org/pdf/1708.05466)

