---
layout: post
title: "Insensitive Stochastic Gradient Twin Support Vector Machine for Large Scale Problems"
date: 2017-11-23 06:38:48
categories: arXiv_CV
tags: arXiv_CV Classification Gradient_Descent
author: Zhen Wang, Yuan-Hai Shao, Lan Bai, Li-Ming Liu, Nai-Yang Deng
mathjax: true
---

* content
{:toc}

##### Abstract
Stochastic gradient descent algorithm has been successfully applied on support vector machines (called PEGASOS) for many classification problems. In this paper, stochastic gradient descent algorithm is investigated to twin support vector machines for classification. Compared with PEGASOS, the proposed stochastic gradient twin support vector machines (SGTSVM) is insensitive on stochastic sampling for stochastic gradient descent algorithm. In theory, we prove the convergence of SGTSVM instead of almost sure convergence of PEGASOS. For uniformly sampling, the approximation between SGTSVM and twin support vector machines is also given, while PEGASOS only has an opportunity to obtain an approximation of support vector machines. In addition, the nonlinear SGTSVM is derived directly from its linear case. Experimental results on both artificial datasets and large scale problems show the stable performance of SGTSVM with a fast learning speed.

##### Abstract (translated by Google)
随机梯度下降算法已经成功地应用于支持向量机（称为PEGASOS），用于许多分类问题。本文研究了随机梯度下降算法对双胞胎支持向量机的分类。与PEGASOS相比，随机梯度下降算法对随机抽样不敏感，提出的随机梯度双支持向量机（SGTSVM）算法对随机抽样不敏感。理论上，我们证明了SGTSVM的收敛性，而不是几乎可靠的PEGASOS收敛性。对于均匀采样，还给出了SGTSVM和双支持向量机之间的逼近，而PEGASOS只有机会获得支持向量机的近似值。另外，非线性SGTSVM是直接从线性情况导出的。在人工数据集和大规模问题上的实验结果表明，SGTSVM的学习速度快，性能稳定。

##### URL
[https://arxiv.org/abs/1704.05596](https://arxiv.org/abs/1704.05596)

##### PDF
[https://arxiv.org/pdf/1704.05596](https://arxiv.org/pdf/1704.05596)

