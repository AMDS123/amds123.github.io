---
layout: post
title: "Multi-modal Factorized Bilinear Pooling with Co-Attention Learning for Visual Question Answering"
date: 2017-08-04 12:17:49
categories: arXiv_CV
tags: arXiv_CV QA Attention VQA
author: Zhou Yu, Jun Yu, Jianping Fan, Dacheng Tao
mathjax: true
---

* content
{:toc}

##### Abstract
Visual question answering (VQA) is challenging because it requires a simultaneous understanding of both the visual content of images and the textual content of questions. The approaches used to represent the images and questions in a fine-grained manner and questions and to fuse these multi-modal features play key roles in performance. Bilinear pooling based models have been shown to outperform traditional linear models for VQA, but their high-dimensional representations and high computational complexity may seriously limit their applicability in practice. For multi-modal feature fusion, here we develop a Multi-modal Factorized Bilinear (MFB) pooling approach to efficiently and effectively combine multi-modal features, which results in superior performance for VQA compared with other bilinear pooling approaches. For fine-grained image and question representation, we develop a co-attention mechanism using an end-to-end deep network architecture to jointly learn both the image and question attentions. Combining the proposed MFB approach with co-attention learning in a new network architecture provides a unified model for VQA. Our experimental results demonstrate that the single MFB with co-attention model achieves new state-of-the-art performance on the real-world VQA dataset. Code available at this https URL

##### Abstract (translated by Google)
视觉问答（VQA）具有挑战性，因为它需要同时了解图像的可视内容和问题的文本内容。用于以细粒度方式和问题表示图像和问题以及融合这些多模态特征的方法在性能中起关键作用。基于双线性池的模型已被证明优于VQA的传统线性模型，但是它们的高维表示和高计算复杂性可能严重限制了它们在实践中的适用性。对于多模态特征融合，我们在这里开发了一种多模态分解双线性（MFB）汇集方法，以高效且有效地组合多模态特征，与其他双线性池化方法相比，这导致VQA的优越性能。对于细粒度图像和问题表示，我们使用端到端深度网络架构开发共同关注机制，以共同学习图像和问题注意。在新的网络架构中将提出的MFB方法与共同注意力学习相结合，为VQA提供了统一的模型。我们的实验结果表明，具有共同关注模型的单一MFB在现实世界的VQA数据集上实现了新的最先进的性能。此https网址提供的代码

##### URL
[https://arxiv.org/abs/1708.01471](https://arxiv.org/abs/1708.01471)

##### PDF
[https://arxiv.org/pdf/1708.01471](https://arxiv.org/pdf/1708.01471)

