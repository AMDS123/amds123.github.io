---
layout: post
title: "Hierarchical Neural Story Generation"
date: 2018-05-13 07:07:08
categories: arXiv_CL
tags: arXiv_CL Attention
author: Angela Fan, Mike Lewis, Yann Dauphin
mathjax: true
---

* content
{:toc}

##### Abstract
We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.

##### Abstract (translated by Google)
我们探索故事世代：创造性系统，可以建立连贯流畅的关于话题的文章。我们从一个在线论坛收集一份30万人的书面故事的大型数据集，并配以书面提示。我们的数据集支持层次故事生成，模型首先生成一个前提，然后将其转换为文本段落。我们通过一种新颖的模型融合方式获得进一步的改进，提高了故事与提示的相关性，并增加了一个新的门控多尺度自我注意机制来模拟远程环境。实验显示在自动评估和人为评估中强大的基线有了很大的改进。人类法官更喜欢我们的方法所产生的故事，这些故事来自一个强大的非等级模型，其系数为二比一。

##### URL
[https://arxiv.org/abs/1805.04833](https://arxiv.org/abs/1805.04833)

##### PDF
[https://arxiv.org/pdf/1805.04833](https://arxiv.org/pdf/1805.04833)

