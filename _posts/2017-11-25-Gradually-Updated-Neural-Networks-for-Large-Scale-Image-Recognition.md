---
layout: post
title: "Gradually Updated Neural Networks for Large-Scale Image Recognition"
date: 2017-11-25 20:17:54
categories: arXiv_CV
tags: arXiv_CV CNN Recognition
author: Siyuan Qiao, Zhishuai Zhang, Wei Shen, Bo Wang, Alan Yuille
mathjax: true
---

* content
{:toc}

##### Abstract
We present a simple yet effective neural network architecture for image recognition. Unlike the previous state-of-the-art neural networks which usually have very deep architectures, we build networks that are shallower but can achieve better performances on three competitive benchmark datasets, i.e., CIFAR-10/100 and ImageNet. Our architectures are built using Gradually Updated Neural Network (GUNN) layers, which differ from the standard Convolutional Neural Network (CNN) layers in the way their output channels are computed: the CNN layers compute the output channels simultaneously while GUNN layers compute the channels gradually. By adding the computation ordering to the channels of CNNs, our networks are able to achieve better accuracies while using fewer layers and less memory. The architecture design of GUNN is guided by theoretical results and verified by empirical experiments. We set new records on the CIFAR-10 and CIFAR-100 datasets and achieve better accuracy on ImageNet under similar complexity with the previous state-of-the-art methods.

##### Abstract (translated by Google)
我们提出了一个简单而有效的图像识别神经网络架构。与先前的通常具有非常深的体系结构的现有技术的神经网络不同，我们构建网络较浅，但可以在三个竞争基准数据集（即CIFAR-10/100和ImageNet）上实现更好的性能。我们的架构是使用逐渐更新的神经网络（GUNN）层来建立的，它们与标准的卷积神经网络（CNN）层的输出通道的计算方式不同：CNN层同时计算输出通道，而GUNN层逐渐计算通道。通过将计算顺序添加到CNN的信道，我们的网络能够实现更好的精度，同时使用更少的层和更少的内存。 GUNN的结构设计以理论结果为指导，经验证实验证实。我们在CIFAR-10和CIFAR-100数据集上创建了新的记录，并在与之前的最新方法相似的复杂度下，在ImageNet上实现了更高的准确性。

##### URL
[https://arxiv.org/abs/1711.09280](https://arxiv.org/abs/1711.09280)

##### PDF
[https://arxiv.org/pdf/1711.09280](https://arxiv.org/pdf/1711.09280)

