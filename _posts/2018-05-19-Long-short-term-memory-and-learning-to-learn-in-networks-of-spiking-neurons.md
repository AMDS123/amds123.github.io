---
layout: post
title: "Long short-term memory and learning-to-learn in networks of spiking neurons"
date: 2018-05-19 16:29:36
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning RNN Deep_Learning
author: Guillaume Bellec, Darjan Salaj, Anand Subramoney, Robert Legenstein, Wolfgang Maass
mathjax: true
---

* content
{:toc}

##### Abstract
The brain carries out demanding computations and learning processes with recurrent networks of spiking neurons (RSNNs). But computing and learning capabilities of currently available RSNN models have remained poor, especially in comparison with the performance of recurrent networks of artificial neurons, such as Long Short-Term Memory (LSTM) networks. In this article, we investigate whether deep learning can improve RSNN performance. We applied backpropagation through time (BPTT), augmented by biologically inspired heuristics for synaptic rewiring, to RSNNs whose inherent time constants were enriched through simple models for adapting spiking neurons. We found that the resulting RSNNs approximate, for the first time, the computational power of LSTM networks on two common benchmark tasks. Furthermore, our results show that recent successes with applications of Learning-to-Learn (L2L) to LSTM networks can be ported to RSNNs. This opens the door to the investigation of L2L in data-based models for neural networks of the brain, whose activity can -- unlike that of LSTM networks -- be compared directly with recordings from neurons in the brain. In particular, L2L shows that RSNNs can learn large families of non-linear transformations from very few examples, using previously unknown network learning mechanisms. Furthermore, meta-reinforcement learning (meta-RL) shows that LSNNs can learn and execute complex exploration and exploitation strategies.

##### Abstract (translated by Google)
大脑使用循环神经元网络（RSNNs）执行要求苛刻的计算和学习过程。但目前可用的RSNN模型的计算和学习能力仍然很差，尤其是与长期短期记忆（LSTM）网络等人造神经元网络的性能相比。在本文中，我们调查深度学习是否可以提高RSNN的性能。我们通过时间反向传播（BPTT），增加了生物启发式突触重新连接的启发式算法，RSNN的固有时间常数通过简单的模型来丰富，以适应峰值神经元。我们发现由此产生的RSNN第一次接近LSTM网络在两个通用基准任务上的计算能力。此外，我们的研究结果表明，最近在学习学习（L2L）应用于LSTM网络方面取得的成功可以移植到RSNN。这为L2L在大脑神经网络的基于数据的模型中的研究打开了大门，它的活动可以 - 与LSTM网络不同 - 可以直接与大脑中神经元的记录进行比较。特别是，L2L表明RSNN可以使用以前未知的网络学习机制从极少数示例中学习大型非线性变换系列。此外，元强化学习（元强化学习）表明LSNN可以学习和执行复杂的探索和开发策略。

##### URL
[https://arxiv.org/abs/1803.09574](https://arxiv.org/abs/1803.09574)

##### PDF
[https://arxiv.org/pdf/1803.09574](https://arxiv.org/pdf/1803.09574)

