---
layout: post
title: "HotFlip: White-Box Adversarial Examples for Text Classification"
date: 2018-05-24 16:43:45
categories: arXiv_CL
tags: arXiv_CL Adversarial Text_Classification Classification
author: Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou
mathjax: true
---

* content
{:toc}

##### Abstract
We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier. We find that only a few manipulations are needed to greatly decrease the accuracy. Our method relies on an atomic flip operation, which swaps one token for another, based on the gradients of the one-hot input vectors. Due to efficiency of our method, we can perform adversarial training which makes the model more robust to attacks at test time. With the use of a few semantics-preserving constraints, we demonstrate that HotFlip can be adapted to attack a word-level classifier as well.

##### Abstract (translated by Google)
我们提出了一种有效的方法来生成白盒对抗性例子来欺骗角色级别的神经分类器。我们发现只需少量操作即可大大降低准确性。我们的方法依赖于原子翻转操作，它根据单热输入向量的梯度将一个令牌替换为另一个令牌。由于我们方法的有效性，我们可以进行对抗训练，使得模型在测试时更能抵御攻击。通过使用一些保留语义的约束条件，我们证明HotFlip也可以适用于攻击字级分类器。

##### URL
[http://arxiv.org/abs/1712.06751](http://arxiv.org/abs/1712.06751)

##### PDF
[http://arxiv.org/pdf/1712.06751](http://arxiv.org/pdf/1712.06751)

