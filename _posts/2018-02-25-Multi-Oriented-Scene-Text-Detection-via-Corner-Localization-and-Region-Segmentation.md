---
layout: post
title: "Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation"
date: 2018-02-25 03:34:12
categories: arXiv_CV
tags: arXiv_CV Object_Detection Segmentation Inference Deep_Learning Detection
author: Pengyuan Lyu (1), Cong Yao (2), Wenhao Wu (2), Shuicheng Yan (3), Xiang Bai (1) ((1) Huazhong University of Science and Technology, (2) Megvii Technology Inc., (3) National University of Singapore)
mathjax: true
---

* content
{:toc}

##### Abstract
Previous deep learning based state-of-the-art scene text detection methods can be roughly classified into two categories. The first category treats scene text as a type of general objects and follows general object detection paradigm to localize scene text by regressing the text box locations, but troubled by the arbitrary-orientation and large aspect ratios of scene text. The second one segments text regions directly, but mostly needs complex post processing. In this paper, we present a method that combines the ideas of the two types of methods while avoiding their shortcomings. We propose to detect scene text by localizing corner points of text bounding boxes and segmenting text regions in relative positions. In inference stage, candidate boxes are generated by sampling and grouping corner points, which are further scored by segmentation maps and suppressed by NMS. Compared with previous methods, our method can handle long oriented text naturally and doesn't need complex post processing. The experiments on ICDAR2013, ICDAR2015, MSRA-TD500, MLT and COCO-Text demonstrate that the proposed algorithm achieves better or comparable results in both accuracy and efficiency. Based on VGG16, it achieves an F-measure of 84.3% on ICDAR2015 and 81.5% on MSRA-TD500.

##### Abstract (translated by Google)
先前的基于深度学习的最先进的场景文本检测方法可以大致分为两类。第一类将场景文本视为一种普通对象，遵循一般对象检测范式，通过回归文本框位置来定位场景文本，但受场景文本的任意取向和大纵横比困扰。第二个直接分割文本区域，但大多需要复杂的后期处理。在本文中，我们提出了一种方法，它结合了两种方法的思想，同时避免了它们的缺点。我们建议通过定位文本边界框的角点并在相对位置分割文本区域来检测场景文本。在推理阶段，通过对角点进行采样和分组来产生候选框，这些角点被分割图进一步评分并由NMS进行抑制。与以前的方法相比，我们的方法可以自然地处理长文本，并且不需要复杂的后处理。在ICDAR2013，ICDAR2015，MSRA-TD500，MLT和COCO-Text上的实验表明，所提出的算法在精度和效率方面实现了更好或可比的结果。基于VGG16，ICDAR2015的F-measure为84.3％，MSRA-TD500的F-measure为81.5％。

##### URL
[http://arxiv.org/abs/1802.08948](http://arxiv.org/abs/1802.08948)

##### PDF
[http://arxiv.org/pdf/1802.08948](http://arxiv.org/pdf/1802.08948)

