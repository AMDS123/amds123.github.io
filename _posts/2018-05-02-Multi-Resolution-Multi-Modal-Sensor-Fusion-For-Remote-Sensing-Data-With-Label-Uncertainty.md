---
layout: post
title: "Multi-Resolution Multi-Modal Sensor Fusion For Remote Sensing Data With Label Uncertainty"
date: 2018-05-02 17:51:13
categories: arXiv_CV
tags: arXiv_CV
author: Xiaoxiao Du, Alina Zare
mathjax: true
---

* content
{:toc}

##### Abstract
In remote sensing, each sensor can provide complementary or reinforcing information. It is valuable to fuse outputs from multiple sensors to boost overall performance. Previous supervised fusion methods often require accurate labels for each pixel in the training data. However, in many remote sensing applications, pixel-level labels are difficult or infeasible to obtain. In addition, outputs from multiple sensors may have different levels of resolution or modalities (such as rasterized hyperspectral imagery versus LiDAR 3D point clouds). This paper presents a Multiple Instance Multi-Resolution Fusion (MIMRF) framework that can fuse multi-resolution and multi-modal sensor outputs while learning from ambiguously and imprecisely labeled training data. Experiments were conducted on the MUUFL Gulfport hyperspectral and LiDAR data set and a remotely-sensed soybean and weed data set. Results show improved, consistent performance on scene understanding and agricultural applications when compared to traditional fusion methods.

##### Abstract (translated by Google)
在遥感中，每个传感器都可以提供补充或补充信息。融合多个传感器的输出以提升整体性能是非常有价值的。先前的监督融合方法通常需要训练数据中每个像素的准确标签。但是，在许多遥感应用中，像素级标签很难或不可行。另外，来自多个传感器的输出可能具有不同的分辨率或模态水平（例如栅格化高光谱图像与LiDAR 3D点云）。本文提出了一种多实例多分辨率融合（MIMRF）框架，该框架可以融合多分辨率和多模态传感器输出，同时从不明确和不准确的标记训练数据中学习。在MUUFL Gulfport高光谱和LiDAR数据集以及遥感大豆和杂草数据集上进行了实验。与传统的融合方法相比，结果显示在场景理解和农业应用方面有改进的一致性能。

##### URL
[https://arxiv.org/abs/1805.00930](https://arxiv.org/abs/1805.00930)

##### PDF
[https://arxiv.org/pdf/1805.00930](https://arxiv.org/pdf/1805.00930)

