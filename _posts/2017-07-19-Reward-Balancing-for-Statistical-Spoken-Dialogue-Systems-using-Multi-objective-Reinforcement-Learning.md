---
layout: post
title: "Reward-Balancing for Statistical Spoken Dialogue Systems using Multi-objective Reinforcement Learning"
date: 2017-07-19 21:21:03
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning Optimization
author: Stefan Ultes, Paweł Budzianowski, Iñigo Casanueva, Nikola Mrkšić, Lina Rojas-Barahona, Pei-Hao Su, Tsung-Hsien Wen, Milica Gašić, Steve Young
mathjax: true
---

* content
{:toc}

##### Abstract
Reinforcement learning is widely used for dialogue policy optimization where the reward function often consists of more than one component, e.g., the dialogue success and the dialogue length. In this work, we propose a structured method for finding a good balance between these components by searching for the optimal reward component weighting. To render this search feasible, we use multi-objective reinforcement learning to significantly reduce the number of training dialogues required. We apply our proposed method to find optimized component weights for six domains and compare them to a default baseline.

##### Abstract (translated by Google)
强化学习被广泛用于对话政策优化，其中奖励功能通常由多个部分组成，例如对话成功和对话长度。在这项工作中，我们提出了一个结构化的方法，通过搜索最佳奖励组件权重来找到这些组件之间的良好平衡。为了使这个搜索成为可能，我们使用多目标强化学习来显着减少所需的训练对话的数量。我们应用我们提出的方法来查找六个域的优化组件权重，并将它们与默认基线进行比较。

##### URL
[https://arxiv.org/abs/1707.06299](https://arxiv.org/abs/1707.06299)

##### PDF
[https://arxiv.org/pdf/1707.06299](https://arxiv.org/pdf/1707.06299)

