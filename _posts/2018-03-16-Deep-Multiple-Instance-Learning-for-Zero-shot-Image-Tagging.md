---
layout: post
title: "Deep Multiple Instance Learning for Zero-shot Image Tagging"
date: 2018-03-16 01:25:04
categories: arXiv_CV
tags: arXiv_CV Knowledge Embedding Deep_Learning Recognition
author: Shafin Rahman, Salman Khan
mathjax: true
---

* content
{:toc}

##### Abstract
In-line with the success of deep learning on traditional recognition problem, several end-to-end deep models for zero-shot recognition have been proposed in the literature. These models are successful to predict a single unseen label given an input image, but does not scale to cases where multiple unseen objects are present. In this paper, we model this problem within the framework of Multiple Instance Learning (MIL). To the best of our knowledge, we propose the first end-to-end trainable deep MIL framework for the multi-label zero-shot tagging problem. Due to its novel design, the proposed framework has several interesting features: (1) Unlike previous deep MIL models, it does not use any off-line procedure (e.g., Selective Search or EdgeBoxes) for bag generation. (2) During test time, it can process any number of unseen labels given their semantic embedding vectors. (3) Using only seen labels per image as weak annotation, it can produce a bounding box for each predicted labels. We experiment with the NUS-WIDE dataset and achieve superior performance across conventional, zero-shot and generalized zero-shot tagging tasks.

##### Abstract (translated by Google)
随着深度学习在传统识别问题上的成功，文献中提出了几种用于零点识别的端到端深度模型。这些模型能够成功地预测给定输入图像的单个看不见的标签，但不能伸缩到存在多个看不见的对象的情况。在本文中，我们在多实例学习（MIL）框架下对这个问题进行建模。据我们所知，我们为多标签零点标签问题提出了第一个端到端可训练深度MIL框架。由于其新颖的设计，所提出的框架具有几个有趣的特征：（1）与以前的深层MIL模型不同，它不使用任何离线程序（例如，选择性搜索或EdgeBoxes）来生成包。 （2）在测试期间，它可以根据语义嵌入向量处理任何数量的看不见的标签。 （3）每个图像只使用看到的标签作为弱注释，它可以为每个预测标签生成一个边界框。我们使用NUS-WIDE数据集进行实验，并在传统的零射击和广义零点标记任务中实现卓越的性能。

##### URL
[https://arxiv.org/abs/1803.06051](https://arxiv.org/abs/1803.06051)

##### PDF
[https://arxiv.org/pdf/1803.06051](https://arxiv.org/pdf/1803.06051)

