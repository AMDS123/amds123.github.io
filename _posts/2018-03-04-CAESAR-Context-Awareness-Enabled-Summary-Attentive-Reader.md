---
layout: post
title: "CAESAR: Context Awareness Enabled Summary-Attentive Reader"
date: 2018-03-04 11:07:55
categories: arXiv_CL
tags: arXiv_CL Attention RNN
author: Long-Huei Chen, Kshitiz Tripathi
mathjax: true
---

* content
{:toc}

##### Abstract
Comprehending meaning from natural language is a primary objective of Natural Language Processing (NLP), and text comprehension is the cornerstone for achieving this objective upon which all other problems like chat bots, language translation and others can be achieved. We report a Summary-Attentive Reader we designed to better emulate the human reading process, along with a dictiontary-based solution regarding out-of-vocabulary (OOV) words in the data, to generate answer based on machine comprehension of reading passages and question from the SQuAD benchmark. Our implementation of these features with two popular models (Match LSTM and Dynamic Coattention) was able to reach close to matching the results obtained from humans.

##### Abstract (translated by Google)
从自然语言中理解意义是自然语言处理（NLP）的一个主要目标，而文本理解是实现这一目标的基石，因此可以实现聊天机器人，语言翻译和其他所有问题。我们报告了一个我们为了更好地模拟人类阅读过程而设计的概述性细心的读者，以及基于辞典的数据中词外（OOV）单词的解决方案，根据机器对阅读段落和问题的理解产生答案来自SQuAD基准。我们使用两种流行模型（Match LSTM和Dynamic Coattention）实现了这些功能，能够接近匹配从人类获得的结果。

##### URL
[http://arxiv.org/abs/1803.01335](http://arxiv.org/abs/1803.01335)

##### PDF
[http://arxiv.org/pdf/1803.01335](http://arxiv.org/pdf/1803.01335)

