---
layout: post
title: "Interpretable and Fine-Grained Visual Explanations for Convolutional Neural Networks"
date: 2019-08-07 15:39:55
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN Optimization Prediction Quantitative
author: J&#xf6;rg Wagner, Jan Mathias K&#xf6;hler, Tobias Gindele, Leon Hetzel, Jakob Thadd&#xe4;us Wiedemer, Sven Behnke
mathjax: true
---

* content
{:toc}

##### Abstract
To verify and validate networks, it is essential to gain insight into their decisions, limitations as well as possible shortcomings of training data. In this work, we propose a post-hoc, optimization based visual explanation method, which highlights the evidence in the input image for a specific prediction. Our approach is based on a novel technique to defend against adversarial evidence (i.e. faulty evidence due to artefacts) by filtering gradients during optimization. The defense does not depend on human-tuned parameters. It enables explanations which are both fine-grained and preserve the characteristics of images, such as edges and colors. The explanations are interpretable, suited for visualizing detailed evidence and can be tested as they are valid model inputs. We qualitatively and quantitatively evaluate our approach on a multitude of models and datasets.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.02686](http://arxiv.org/abs/1908.02686)

##### PDF
[http://arxiv.org/pdf/1908.02686](http://arxiv.org/pdf/1908.02686)

