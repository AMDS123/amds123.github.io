---
layout: post
title: "Self-Imitation Learning"
date: 2018-06-14 16:25:55
categories: arXiv_AI
tags: arXiv_AI Optimization
author: Junhyuk Oh, Yijie Guo, Satinder Singh, Honglak Lee
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes Self-Imitation Learning (SIL), a simple off-policy actor-critic algorithm that learns to reproduce the agent's past good decisions. This algorithm is designed to verify our hypothesis that exploiting past good experiences can indirectly drive deep exploration. Our empirical results show that SIL significantly improves advantage actor-critic (A2C) on several hard exploration Atari games and is competitive to the state-of-the-art count-based exploration methods. We also show that SIL improves proximal policy optimization (PPO) on MuJoCo tasks.

##### Abstract (translated by Google)
本文提出了自我模仿学习（SIL），一种简单的关闭策略的演员评论者算法，学习重现代理人过去的良好决策。该算法旨在验证我们的假设，即利用过去的良好体验可以间接推动深度探索。我们的实证结果显示，SIL在几个艰难的探索Atari游戏中显着地提高了优势演员 - 评论家（A2C），并且与最先进的基于计数的探索方法相比具有竞争力。我们还显示SIL改进了MuJoCo任务的近端策略优化（PPO）。

##### URL
[https://arxiv.org/abs/1806.05635](https://arxiv.org/abs/1806.05635)

##### PDF
[https://arxiv.org/pdf/1806.05635](https://arxiv.org/pdf/1806.05635)

