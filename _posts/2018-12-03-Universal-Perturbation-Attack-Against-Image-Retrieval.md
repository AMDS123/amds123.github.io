---
layout: post
title: "Universal Perturbation Attack Against Image Retrieval"
date: 2018-12-03 04:52:06
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Adversarial Attention Image_Classification Classification Deep_Learning Relation
author: Jie Li, Rongrong Ji, Hong Liu, Xiaopeng Hong, Yue Gao, Qi Tian
mathjax: true
---

* content
{:toc}

##### Abstract
Despite the remarkable success, deep learning models have shown to be vulnerable to the universal adversarial perturbation (UAP). The existing endeavors on UAP methods mainly focus on attacking the image classification models. Nevertheless, little attention has been paid to attacking image retrieval systems. In this paper, we make the first attempt for UAP attacking to deep feature based image retrieval. Concretely, attacking image retrieval is to make the retrieval system return more irrelevant images to the query at the top ranking list, whose key design is to corrupt the relationships among features. To this end, we propose a unified method to generate retrieval-based UAP to break the relationships between image features from point-wise, label-wise, and list-wise aspects. We further analyze the impact of the resizing operation in generating UAP, and thus provide a solution to attack high-performance retrieval systems with query resizing. We evaluate the proposed methods on four widely-used image retrieval datasets, i.e., Oxford5k and Paris6k with their revised versions, which lead to a significant performance drop in terms of different metrics, such as mAP, and mP@10. Finally, we test our attacking methods on the real-world visual search engine, i.e., Google Images, which demonstrates the potential of our methods.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.00552](http://arxiv.org/abs/1812.00552)

##### PDF
[http://arxiv.org/pdf/1812.00552](http://arxiv.org/pdf/1812.00552)

