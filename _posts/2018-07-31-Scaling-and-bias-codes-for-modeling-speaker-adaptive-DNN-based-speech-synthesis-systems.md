---
layout: post
title: "Scaling and bias codes for modeling speaker-adaptive DNN-based speech synthesis systems"
date: 2018-07-31 02:29:41
categories: arXiv_SD
tags: arXiv_SD
author: Hieu-Thi Luong, Junichi Yamagishi
mathjax: true
---

* content
{:toc}

##### Abstract
Most neural-network based speaker-adaptive acoustic models for speech synthesis can be categorized into either layer-based or input-code approaches. Although both approaches have their own pros and cons, most existing works on speaker adaptation focus on improving one or the other. In this paper, after we first systematically overview the common principles of neural-network based speaker-adaptive models, we show that these approaches can be represented in a unified framework and can be generalized further. More specifically, we introduce the use of scaling and bias codes as generalized means for speaker-adaptive transformation. By utilizing these codes, we can create a more efficient factorized speaker-adaptive model and capture advantages of both approaches while reducing their disadvantages. The experiments show that the proposed method can improve the performance of speaker adaptation compared with speaker adaptation based on the conventional input code.

##### Abstract (translated by Google)
用于语音合成的大多数基于神经网络的说话者自适应声学模型可以分类为基于层的或输入码方法。虽然这两种方法各有利弊，但大多数关于说话人适应的现有工作都集中在改进其中一种方法。在本文中，在我们首次系统地概述基于神经网络的说话人自适应模型的共同原理之后，我们表明这些方法可以在统一的框架中表示，并且可以进一步推广。更具体地说，我们引入了缩放和偏置码作为说话者自适应变换的通用手段。通过利用这些代码，我们可以创建一个更有效的分解扬声器自适应模型，并捕捉两种方法的优势，同时减少它们的缺点。实验表明，与基于传统输入码的扬声器自适应相比，所提出的方法可以提高扬声器自适应性能。

##### URL
[http://arxiv.org/abs/1807.11632](http://arxiv.org/abs/1807.11632)

##### PDF
[http://arxiv.org/pdf/1807.11632](http://arxiv.org/pdf/1807.11632)

