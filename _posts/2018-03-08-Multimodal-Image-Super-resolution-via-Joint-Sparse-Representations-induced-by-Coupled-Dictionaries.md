---
layout: post
title: "Multimodal Image Super-resolution via Joint Sparse Representations induced by Coupled Dictionaries"
date: 2018-03-08 19:41:41
categories: arXiv_CV
tags: arXiv_CV Super_Resolution Sparse
author: Pingfan Song (Student Member, IEEE), Xin Deng (Student Member, IEEE), Jo&#xe3;o F. C. Mota (Member, IEEE), Nikos Deligiannis (Member, IEEE), Pier Luigi Dragotti (Fellow, IEEE), Miguel R. D. Rodrigues (Senior Member, IEEE)
mathjax: true
---

* content
{:toc}

##### Abstract
Real-world data processing problems often involve various image modalities associated with a certain scene, including RGB images, infrared images or multi-spectral images. The fact that different image modalities often share certain attributes, such as certain edges, textures and other structure primitives, represents an opportunity to enhance various image processing tasks. This paper proposes a new approach to construct a high-resolution (HR) version of a low-resolution (LR) image given another HR image modality as reference, based on joint sparse representations induced by coupled dictionaries. Our approach, which captures the similarities and disparities between different image modalities in a learned sparse feature domain in \emph{lieu} of the original image domain, consists of two phases. The coupled dictionary learning phase is used to learn a set of dictionaries that couple different image modalities in the sparse feature domain given a set of training data. In turn, the coupled super-resolution phase leverages such coupled dictionaries to construct a HR version of the LR target image given another related image modality. One of the merits of our sparsity-driven approach relates to the fact that it overcomes drawbacks such as the texture copying artifacts commonly resulting from inconsistency between the guidance and target images. Experiments on real multimodal images demonstrate that incorporating appropriate guidance information via joint sparse representation induced by coupled dictionary learning brings notable benefits in the super-resolution task with respect to the state-of-the-art. Of particular relevance, the proposed approach also demonstrates better robustness than competing deep-learning-based methods in the presence of noise.

##### Abstract (translated by Google)
真实世界的数据处理问题通常涉及与某个场景相关的各种图像模态，包括RGB图像，红外图像或多光谱图像。事实上，不同的图像模态经常共享某些属性，例如某些边缘，纹理和其他结构基元，这代表了增强各种图像处理任务的机会。本文提出了一种新的方法来构建低分辨率（LR）图像的高分辨率（HR）版本，基于耦合字典引入的联合稀疏表示，给出另一个HR图像模态作为参考。我们的方法捕捉原始图像域的\ emph {lieu}中学习稀疏特征域中不同图像模态之间的相似性和差异，由两个阶段组成。耦合词典学习阶段用于学习一组词典，其在给定一组训练数据的情况下在稀疏特征域中耦合不同的图像模态。接着，耦合的超分辨率阶段利用这种耦合的字典来构建给定另一相关图像模态的LR目标图像的HR版本。我们的稀疏驱动方法的优点之一与它克服了通常由于引导图像和目标图像之间的不一致造成的纹理复制伪像之类的缺陷的事实有关。对实际多模态图像的实验证明，通过联合字典学习引入的联合稀疏表示合并适当的引导信息为超级分辨率任务带来了与现有技术相关的显着优势。尤其相关的是，所提出的方法还表现出比在噪声存在下竞争基于深度学习的方法更好的鲁棒性。

##### URL
[http://arxiv.org/abs/1709.08680](http://arxiv.org/abs/1709.08680)

##### PDF
[http://arxiv.org/pdf/1709.08680](http://arxiv.org/pdf/1709.08680)

