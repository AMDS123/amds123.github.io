---
layout: post
title: "Bi-directional LSTM Recurrent Neural Network for Chinese Word Segmentation"
date: 2016-02-16 00:45:19
categories: arXiv_SD
tags: arXiv_SD Knowledge Segmentation RNN
author: Yushi Yao, Zheng Huang
mathjax: true
---

* content
{:toc}

##### Abstract
Recurrent neural network(RNN) has been broadly applied to natural language processing(NLP) problems. This kind of neural network is designed for modeling sequential data and has been testified to be quite efficient in sequential tagging tasks. In this paper, we propose to use bi-directional RNN with long short-term memory(LSTM) units for Chinese word segmentation, which is a crucial preprocess task for modeling Chinese sentences and articles. Classical methods focus on designing and combining hand-craft features from context, whereas bi-directional LSTM network(BLSTM) does not need any prior knowledge or pre-designing, and it is expert in keeping the contextual information in both directions. Experiment result shows that our approach gets state-of-the-art performance in word segmentation on both traditional Chinese datasets and simplified Chinese datasets.

##### Abstract (translated by Google)
递归神经网络（RNN）已广泛应用于自然语言处理（NLP）问题。这种神经网络是为连续数据建模而设计的，在连续标签任务中被证明是非常有效的。在本文中，我们提出使用长时间短记忆（LSTM）单位的双向RNN进行中文分词，这对于汉语句子和文章的建模是一个至关重要的预处理任务。经典方法的重点在于从上下文设计和组合手工特征，而双向LSTM网络（BLSTM）不需要任何预先知识或预先设计，并且在保持双向的上下文信息方面是专家。实验结果表明，我们的方法在传统中文数据集和简体中文数据集的分词方面获得了最先进的性能。

##### URL
[https://arxiv.org/abs/1602.04874](https://arxiv.org/abs/1602.04874)

##### PDF
[https://arxiv.org/pdf/1602.04874](https://arxiv.org/pdf/1602.04874)

