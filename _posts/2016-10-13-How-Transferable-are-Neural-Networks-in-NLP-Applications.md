---
layout: post
title: "How Transferable are Neural Networks in NLP Applications?"
date: 2016-10-13 07:45:31
categories: arXiv_SD
tags: arXiv_SD Knowledge Transfer_Learning
author: Lili Mou, Zhao Meng, Rui Yan, Ge Li, Yan Xu, Lu Zhang, Zhi Jin
mathjax: true
---

* content
{:toc}

##### Abstract
Transfer learning is aimed to make use of valuable knowledge in a source domain to help model performance in a target domain. It is particularly important to neural networks, which are very likely to be overfitting. In some fields like image processing, many studies have shown the effectiveness of neural network-based transfer learning. For neural NLP, however, existing studies have only casually applied transfer learning, and conclusions are inconsistent. In this paper, we conduct systematic case studies and provide an illuminating picture on the transferability of neural networks in NLP.

##### Abstract (translated by Google)
转移学习旨在利用源域中有价值的知识帮助对目标域中的性能进行建模。神经网络非常重要，这很可能是过度拟合的。在图像处理等领域，许多研究都显示了基于神经网络的转移学习的有效性。然而，对于神经NLP，现有的研究只是漫不经心的应用转移学习，结论是不一致的。在本文中，我们进行了系统的案例研究，并提供了神经网络在NLP中的可转移性的照片。

##### URL
[https://arxiv.org/abs/1603.06111](https://arxiv.org/abs/1603.06111)

##### PDF
[https://arxiv.org/pdf/1603.06111](https://arxiv.org/pdf/1603.06111)

