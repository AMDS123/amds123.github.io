---
layout: post
title: "Title-Guided Encoding for Keyphrase Generation"
date: 2018-08-26 15:28:11
categories: arXiv_CL
tags: arXiv_CL
author: Wang Chen, Yifan Gao, Jiani Zhang, Irwin King, Michael R. Lyu
mathjax: true
---

* content
{:toc}

##### Abstract
Keyphrase generation (KG) aims to generate a set of keyphrases given a document, which is a fundamental task in natural language processing (NLP). Most previous methods solve this problem in an extractive manner, while recently, several attempts are made under the generative setting using deep neural networks. However, the state-of-the-art generative methods simply treat the document title and the document main body equally, ignoring the leading role of the title to the overall document. To solve this problem, we introduce a new model called Title-Guided Network (TG-Net) for automatic keyphrase generation task based on the encoder-decoder architecture with two new features: (i) the title is additionally employed as a query-like input, and (ii) a title-guided encoder gathers the relevant information from the title to each word in the document. Experiments on a range of KG datasets demonstrate that our model outperforms the state-of-the-art models with a large margin, especially for documents with either very low or very high title length ratios.

##### Abstract (translated by Google)
密钥短语生成（KG）旨在生成一组给定文档的关键短语，这是自然语言处理（NLP）中的基本任务。大多数先前的方法以提取方式解决该问题，而最近，在使用深度神经网络的生成设置下进行了多次尝试。然而，最先进的生成方法只是平等地对待文档标题和文档主体，而忽略了标题对整个文档的主导作用。为了解决这个问题，我们引入了一个名为Title-Guided Network（TG-Net）的新模型，用于基于编码器 - 解码器架构的自动密钥短语生成任务，具有两个新特性：（i）标题另外用作查询类似输入，以及（ii）标题引导编码器从标题中收集文档中每个单词的相关信息。在一系列KG数据集上的实验表明，我们的模型优于具有较大余量的最先进模型，特别是对于标题长度比非常低或非常高的文档。

##### URL
[http://arxiv.org/abs/1808.08575](http://arxiv.org/abs/1808.08575)

##### PDF
[http://arxiv.org/pdf/1808.08575](http://arxiv.org/pdf/1808.08575)

