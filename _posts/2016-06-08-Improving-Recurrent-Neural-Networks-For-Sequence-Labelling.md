---
layout: post
title: "Improving Recurrent Neural Networks For Sequence Labelling"
date: 2016-06-08 13:47:18
categories: arXiv_CL
tags: arXiv_CL RNN
author: Marco Dinarelli, Isabelle Tellier
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we study different types of Recurrent Neural Networks (RNN) for sequence labeling tasks. We propose two new variants of RNNs integrating improvements for sequence labeling, and we compare them to the more traditional Elman and Jordan RNNs. We compare all models, either traditional or new, on four distinct tasks of sequence labeling: two on Spoken Language Understanding (ATIS and MEDIA); and two of POS tagging for the French Treebank (FTB) and the Penn Treebank (PTB) corpora. The results show that our new variants of RNNs are always more effective than the others.

##### Abstract (translated by Google)
在本文中，我们研究了用于序列标记任务的不同类型的递归神经网络（RNN）。我们提出两个RNN的新变种，将序列标记的改进整合在一起，并将它们与更传统的Elman和Jordan RNN进行比较。我们比较所有的模型，无论是传统的还是新的，对四种不同的序列标签任务进行比较：两种口语语言理解（ATIS和MEDIA）;和法国树库（FTB）和宾州树库（PTB）语料库的两个POS标签。结果表明，我们新的RNN变体总是比其他变体更有效。

##### URL
[https://arxiv.org/abs/1606.02555](https://arxiv.org/abs/1606.02555)

##### PDF
[https://arxiv.org/pdf/1606.02555](https://arxiv.org/pdf/1606.02555)

