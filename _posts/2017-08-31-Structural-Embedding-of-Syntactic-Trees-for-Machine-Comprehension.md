---
layout: post
title: "Structural Embedding of Syntactic Trees for Machine Comprehension"
date: 2017-08-31 23:20:59
categories: arXiv_SD
tags: arXiv_SD Attention Embedding
author: Rui Liu, Junjie Hu, Wei Wei, Zi Yang, Eric Nyberg
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks for machine comprehension typically utilizes only word or character embeddings without explicitly taking advantage of structured linguistic information such as constituency trees and dependency trees. In this paper, we propose structural embedding of syntactic trees (SEST), an algorithm framework to utilize structured information and encode them into vector representations that can boost the performance of algorithms for the machine comprehension. We evaluate our approach using a state-of-the-art neural attention model on the SQuAD dataset. Experimental results demonstrate that our model can accurately identify the syntactic boundaries of the sentences and extract answers that are syntactically coherent over the baseline methods.

##### Abstract (translated by Google)
用于机器理解的深度神经网络通常仅利用单词或字符嵌入而不明确地利用诸如选区树和依赖树的结构化语言信息。在本文中，我们提出句法树的结构嵌入（SEST），这是一种利用结构化信息并将其编码成向量表示的算法框架，可以提高机器理解算法的性能。我们使用SQUAD数据集上的最新神经注意模型来评估我们的方法。实验结果表明，我们的模型可以准确地识别句子的句法边界，并提取在基线方法上语法上一致的答案。

##### URL
[https://arxiv.org/abs/1703.00572](https://arxiv.org/abs/1703.00572)

##### PDF
[https://arxiv.org/pdf/1703.00572](https://arxiv.org/pdf/1703.00572)

