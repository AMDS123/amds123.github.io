---
layout: post
title: "Fully Convolutional Grasp Detection Network with Oriented Anchor Box"
date: 2018-03-06 14:21:55
categories: arXiv_CV
tags: arXiv_CV CNN Detection
author: Xinwen Zhou, Xuguang Lan, Hanbo Zhang, Zhiqiang Tian, Yang Zhang, Nanning Zheng
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present a real-time approach to predict multiple grasping poses for a parallel-plate robotic gripper using RGB images. A model with oriented anchor box mechanism is proposed and a new matching strategy is used during the training process. An end-to-end fully convolutional neural network is employed in our work. The network consists of two parts: the feature extractor and multi-grasp predictor. The feature extractor is a deep convolutional neural network. The multi-grasp predictor regresses grasp rectangles from predefined oriented rectangles, called oriented anchor boxes, and classifies the rectangles into graspable and ungraspable. On the standard Cornell Grasp Dataset, our model achieves an accuracy of 97.74% and 96.61% on image-wise split and object-wise split respectively, and outperforms the latest state-of-the-art approach by 1.74% on image-wise split and 0.51% on object-wise split.

##### Abstract (translated by Google)
在本文中，我们提出了一种实时方法来预测使用RGB图像的平行板机器人手爪的多个抓取姿势。提出了一种定向锚箱机构模型，并在训练过程中采用了新的匹配策略。我们的工作中采用了端到端的完全卷积神经网络。该网络由两部分组成：特征提取器和多重抓取预测器。特征提取器是深度卷积神经网络。多抓握预测器从预定义的定向矩形中回归抓取矩形，称为定向锚定框，并将这些矩形分类为可抓取和不可分割的。在标准的康奈尔格拉斯数据集上，我们的模型分别在图像分割和对象分割方面的准确率分别达到97.74％和96.61％，并且在图像分割方面优于最新的最新技术方法1.74％和0.51％的对象明智分裂。

##### URL
[http://arxiv.org/abs/1803.02209](http://arxiv.org/abs/1803.02209)

##### PDF
[http://arxiv.org/pdf/1803.02209](http://arxiv.org/pdf/1803.02209)

