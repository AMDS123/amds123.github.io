---
layout: post
title: "Mixing Dirichlet Topic Models and Word Embeddings to Make lda2vec"
date: 2016-05-06 18:13:18
categories: arXiv_CL
tags: arXiv_CL Sparse Embedding Relation
author: Christopher E Moody
mathjax: true
---

* content
{:toc}

##### Abstract
Distributed dense word vectors have been shown to be effective at capturing token-level semantic and syntactic regularities in language, while topic models can form interpretable representations over documents. In this work, we describe lda2vec, a model that learns dense word vectors jointly with Dirichlet-distributed latent document-level mixtures of topic vectors. In contrast to continuous dense document representations, this formulation produces sparse, interpretable document mixtures through a non-negative simplex constraint. Our method is simple to incorporate into existing automatic differentiation frameworks and allows for unsupervised document representations geared for use by scientists while simultaneously learning word vectors and the linear relationships between them.

##### Abstract (translated by Google)
已经证明分布式密集词向量在捕捉语言中的令牌级语义和句法规则方面是有效的，而主题模型可以在文档上形成可解释的表示。在这项工作中，我们描述lda2vec，一个学习与Dirichlet分布的潜在文档级别的主题向量混合密集词向量的模型。与连续密集的文档表示形式相反，这个表达式通过非负单形约束产生稀疏的，可解释的文档混合体。我们的方法很容易整合到现有的自动分化框架中，允许科学家使用无监督的文档表示，同时学习单词向量及它们之间的线性关系。

##### URL
[https://arxiv.org/abs/1605.02019](https://arxiv.org/abs/1605.02019)

##### PDF
[https://arxiv.org/pdf/1605.02019](https://arxiv.org/pdf/1605.02019)

