---
layout: post
title: "Deep Reinforcement Learning for Playing 2.5D Fighting Games"
date: 2018-05-05 15:34:03
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Yu-Jhe Li, Hsin-Yu Chang, Yu-Jing Lin, Po-Wei Wu, Yu-Chiang Frank Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Deep reinforcement learning has shown its success in game playing. However, 2.5D fighting games would be a challenging task to handle due to ambiguity in visual appearances like height or depth of the characters. Moreover, actions in such games typically involve particular sequential action orders, which also makes the network design very difficult. Based on the network of Asynchronous Advantage Actor-Critic (A3C), we create an OpenAI-gym-like gaming environment with the game of Little Fighter 2 (LF2), and present a novel A3C+ network for learning RL agents. The introduced model includes a Recurrent Info network, which utilizes game-related info features with recurrent layers to observe combo skills for fighting. In the experiments, we consider LF2 in different settings, which successfully demonstrates the use of our proposed model for learning 2.5D fighting games.

##### Abstract (translated by Google)
深度强化学习已经显示了它在游戏中的成功。然而，2.5D格斗游戏将是一项具有挑战性的任务，因为人物的高度或深度等视觉外观不明确。此外，这类游戏中的行动通常涉及特定的顺序行动命令，这也使得网络设计非常困难。基于Asynchronous Advantage Actor-Critic（A3C）网络，我们用Little Fighter 2（LF2）的游戏创建了一个OpenAI-gym-like游戏环境，并提供了一个用于学习RL代理商的小型A3C +网络。引入的模型包括一个经常性信息网络，该网络利用游戏相关的信息特征和复发层来观察战斗的组合技能。在实验中，我们考虑了LF2在不同的设置，这成功地演示了我们提出的模型用于学习2.5D格斗游戏的使用。

##### URL
[https://arxiv.org/abs/1805.02070](https://arxiv.org/abs/1805.02070)

##### PDF
[https://arxiv.org/pdf/1805.02070](https://arxiv.org/pdf/1805.02070)

