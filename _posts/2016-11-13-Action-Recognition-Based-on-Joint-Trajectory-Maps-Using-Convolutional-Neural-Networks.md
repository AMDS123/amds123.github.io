---
layout: post
title: "Action Recognition Based on Joint Trajectory Maps Using Convolutional Neural Networks"
date: 2016-11-13 23:24:58
categories: arXiv_CV
tags: arXiv_CV Action_Recognition CNN Recognition
author: Pichao Wang, Zhaoyang Li, Yonghong Hou, Wanqing Li
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, Convolutional Neural Networks (ConvNets) have shown promising performances in many computer vision tasks, especially image-based recognition. How to effectively use ConvNets for video-based recognition is still an open problem. In this paper, we propose a compact, effective yet simple method to encode spatio-temporal information carried in $3D$ skeleton sequences into multiple $2D$ images, referred to as Joint Trajectory Maps (JTM), and ConvNets are adopted to exploit the discriminative features for real-time human action recognition. The proposed method has been evaluated on three public benchmarks, i.e., MSRC-12 Kinect gesture dataset (MSRC-12), G3D dataset and UTD multimodal human action dataset (UTD-MHAD) and achieved the state-of-the-art results.

##### Abstract (translated by Google)
最近，卷积神经网络（ConvNets）在许多计算机视觉任务中显示出有前途的性能，特别是基于图像的识别。如何有效地使用ConvNets进行基于视频的识别仍然是一个悬而未决的问题。在本文中，我们提出了一种紧凑，有效而简单的方法，将$ 3D $骨架序列中携带的时空信息编码成多个$ 2D $图像，称为联合轨迹图（JTM），ConvNets被用来利用用于实时人类行为识别的判别性特征。所提出的方法已经在三个公共基准，即MSRC-12 Kinect手势数据集（MSRC-12），G3D数据集和UTD多模态人类活动数据集（UTD-MHAD）上进行了评估，并且获得了最新的结果。

##### URL
[https://arxiv.org/abs/1611.02447](https://arxiv.org/abs/1611.02447)

##### PDF
[https://arxiv.org/pdf/1611.02447](https://arxiv.org/pdf/1611.02447)

