---
layout: post
title: "Cross-Media Similarity Evaluation for Web Image Retrieval in the Wild"
date: 2017-09-05 09:38:32
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Deep_Learning
author: Jianfeng Dong, Xirong Li, Duanqing Xu
mathjax: true
---

* content
{:toc}

##### Abstract
In order to retrieve unlabeled images by textual queries, cross-media similarity computation is a key ingredient. Although novel methods are continuously introduced, little has been done to evaluate these methods together with large-scale query log analysis. Consequently, how far have these methods brought us in answering real-user queries is unclear. Given baseline methods that compute cross-media similarity using relatively simple text/image matching, how much progress have advanced models made is also unclear. This paper takes a pragmatic approach to answering the two questions. Queries are automatically categorized according to the proposed query visualness measure, and later connected to the evaluation of multiple cross-media similarity models on three test sets. Such a connection reveals that the success of the state-of-the-art is mainly attributed to their good performance on visual-oriented queries, while these queries account for only a small part of real-user queries. To quantify the current progress, we propose a simple text2image method, representing a novel test query by a set of images selected from large-scale query log. Consequently, computing cross-media similarity between the test query and a given image boils down to comparing the visual similarity between the given image and the selected images. Image retrieval experiments on the challenging Clickture dataset show that the proposed text2image compares favorably to recent deep learning based alternatives.

##### Abstract (translated by Google)
为了通过文本查询来检索未标记的图像，跨媒体相似度计算是一个关键因素。虽然新颖的方法不断被引入，但是与大规模的查询日志分析一起评估这些方法的工作很少。因此，这些方法在多大程度上使我们能够回答真实用户查询尚不清楚。鉴于使用相对简单的文本/图像匹配来计算跨媒体相似度的基线方法，具有高级模型的进展还不清楚。本文采取务实的态度回答这两个问题。查询根据提出的查询可视性度量自动分类，并且随后被连接到三个测试集上的多个跨媒体相似度模型的评估。这样的连接表明，最先进的成功主要归因于它们在面向视觉的查询方面的良好性能，而这些查询仅占真实用户查询的一小部分。为了量化当前的进展，我们提出了一种简单的文本图像方法，用从大规模查询日志中选择的一组图像表示一个新的测试查询。因此，计算测试查询与给定图像之间的跨媒体相似性归结为比较给定图像与所选图像之间的视觉相似性。在具有挑战性的Clickture数据集上的图像检索实验表明，所提出的text2image与最近的基于深度学习的替代方案相比是有利的。

##### URL
[https://arxiv.org/abs/1709.01305](https://arxiv.org/abs/1709.01305)

##### PDF
[https://arxiv.org/pdf/1709.01305](https://arxiv.org/pdf/1709.01305)

