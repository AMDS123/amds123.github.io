---
layout: post
title: "ConvNet Architecture Search for Spatiotemporal Feature Learning"
date: 2017-08-16 18:54:39
categories: arXiv_CV
tags: arXiv_CV Image_Caption Object_Detection Segmentation Caption Semantic_Segmentation Inference Detection
author: Du Tran, Jamie Ray, Zheng Shou, Shih-Fu Chang, Manohar Paluri
mathjax: true
---

* content
{:toc}

##### Abstract
Learning image representations with ConvNets by pre-training on ImageNet has proven useful across many visual understanding tasks including object detection, semantic segmentation, and image captioning. Although any image representation can be applied to video frames, a dedicated spatiotemporal representation is still vital in order to incorporate motion patterns that cannot be captured by appearance based models alone. This paper presents an empirical ConvNet architecture search for spatiotemporal feature learning, culminating in a deep 3-dimensional (3D) Residual ConvNet. Our proposed architecture outperforms C3D by a good margin on Sports-1M, UCF101, HMDB51, THUMOS14, and ASLAN while being 2 times faster at inference time, 2 times smaller in model size, and having a more compact representation.

##### Abstract (translated by Google)
通过在ImageNet上进行预训练，使用ConvNets学习图像表示已被证明可用于许多视觉理解任务，包括对象检测，语义分割和图像字幕。虽然任何图像表示都可以应用于视频帧，但是专用的时空表示仍然是至关重要的，以便合并仅基于外观的模型无法捕获的运动模式。本文介绍了一种经验性的ConvNet架构搜索，用于时空特征学习，最终形成深度三维（3D）残差ConvNet。我们提出的架构在Sports-1M，UCF101，HMDB51，THUMOS14和ASLAN上的优势明显优于C3D，同时在推理时间上快2倍，在模型尺寸上缩小2倍，并且具有更紧凑的表示。

##### URL
[https://arxiv.org/abs/1708.05038](https://arxiv.org/abs/1708.05038)

##### PDF
[https://arxiv.org/pdf/1708.05038](https://arxiv.org/pdf/1708.05038)

