---
layout: post
title: "ConvNet Architecture Search for Spatiotemporal Feature Learning"
date: 2017-08-16 18:54:39
categories: arXiv_CV
tags: arXiv_CV Image_Caption Object_Detection Segmentation Caption Semantic_Segmentation Inference Detection
author: Du Tran, Jamie Ray, Zheng Shou, Shih-Fu Chang, Manohar Paluri
mathjax: true
---

* content
{:toc}

##### Abstract
Learning image representations with ConvNets by pre-training on ImageNet has proven useful across many visual understanding tasks including object detection, semantic segmentation, and image captioning. Although any image representation can be applied to video frames, a dedicated spatiotemporal representation is still vital in order to incorporate motion patterns that cannot be captured by appearance based models alone. This paper presents an empirical ConvNet architecture search for spatiotemporal feature learning, culminating in a deep 3-dimensional (3D) Residual ConvNet. Our proposed architecture outperforms C3D by a good margin on Sports-1M, UCF101, HMDB51, THUMOS14, and ASLAN while being 2 times faster at inference time, 2 times smaller in model size, and having a more compact representation.

##### Abstract (translated by Google)
通过在ImageNet上进行预训练来学习ConvNets的图像表示已被证明可用于包括对象检测，语义分割和图像字幕在内的许多视觉理解任务。尽管任何图像表示可以应用于视频帧，但是专用的时空表示仍然是至关重要的，以便包含单独由外观模型无法捕获的运动模式。本文提出了一个经验型的ConvNet架构搜索时空特征学习，最终在一个深层的三维（3D）残差ConvNet。我们提出的体系结构在Sports-1M，UCF101，HMDB51，THUMOS14和ASLAN上的性能优于C3D，在推理时间上快2倍，在模型尺寸上小了2倍，并且代表性更紧凑。

##### URL
[https://arxiv.org/abs/1708.05038](https://arxiv.org/abs/1708.05038)

##### PDF
[https://arxiv.org/pdf/1708.05038](https://arxiv.org/pdf/1708.05038)

