---
layout: post
title: "Constrained Structured Regression with Convolutional Neural Networks"
date: 2015-11-23 22:43:37
categories: arXiv_CV
tags: arXiv_CV CNN Classification
author: Deepak Pathak, Philipp Krähenbühl, Stella X. Yu, Trevor Darrell
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional Neural Networks (CNNs) have recently emerged as the dominant model in computer vision. If provided with enough training data, they predict almost any visual quantity. In a discrete setting, such as classification, CNNs are not only able to predict a label but often predict a confidence in the form of a probability distribution over the output space. In continuous regression tasks, such a probability estimate is often lacking. We present a regression framework which models the output distribution of neural networks. This output distribution allows us to infer the most likely labeling following a set of physical or modeling constraints. These constraints capture the intricate interplay between different input and output variables, and complement the output of a CNN. However, they may not hold everywhere. Our setup further allows to learn a confidence with which a constraint holds, in the form of a distribution of the constrain satisfaction. We evaluate our approach on the problem of intrinsic image decomposition, and show that constrained structured regression significantly increases the state-of-the-art.

##### Abstract (translated by Google)
卷积神经网络（CNN）最近已经成为计算机视觉中的主要模型。如果提供足够的训练数据，他们可以预测几乎任何视觉量。在一个离散的情况下，如分类，CNN不仅能够预测标签，而且往往能够以输出空间的概率分布形式预测置信度。在连续的回归任务中，通常缺乏这样的概率估计。我们提出一个回归框架，模拟神经网络的输出分布。这个输出分布允许我们在一组物理或建模约束条件下推断出最可能的标签。这些约束捕捉了不同输入和输出变量之间错综复杂的相互作用，并补充了CNN的输出。但是，它们可能并不是到处都是。我们的设置进一步允许以限制满意度的分布形式来学习约束所持有的信心。我们评估我们在内在图像分解问题上的方法，并显示约束结构化回归显着增加了最新的技术。

##### URL
[https://arxiv.org/abs/1511.07497](https://arxiv.org/abs/1511.07497)

##### PDF
[https://arxiv.org/pdf/1511.07497](https://arxiv.org/pdf/1511.07497)

