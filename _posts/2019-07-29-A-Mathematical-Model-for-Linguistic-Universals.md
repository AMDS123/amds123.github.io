---
layout: post
title: "A Mathematical Model for Linguistic Universals"
date: 2019-07-29 09:25:49
categories: arXiv_AI
tags: arXiv_AI Knowledge Embedding
author: Weinan E, Yajun Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
Inspired by chemical kinetics and neurobiology, we propose a mathematical theory for pattern recurrence in text documents, applicable to a wide variety of languages. We present a Markov model at the discourse level for Steven Pinker's ``mentalese'', or chains of mental states that transcend the spoken/written forms. Such (potentially) universal temporal structures of textual patterns lead us to a language-independent semantic representation, or a translationally-invariant word embedding, thereby forming the common ground for both comprehensibility within a given language and translatability between different languages. Applying our model to documents of moderate lengths, without relying on external knowledge bases, we reconcile Noam Chomsky's ``poverty of stimulus'' paradox with statistical learning of natural languages.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.12293](http://arxiv.org/abs/1907.12293)

##### PDF
[http://arxiv.org/pdf/1907.12293](http://arxiv.org/pdf/1907.12293)

