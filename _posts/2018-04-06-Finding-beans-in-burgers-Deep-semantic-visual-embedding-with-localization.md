---
layout: post
title: "Finding beans in burgers: Deep semantic-visual embedding with localization"
date: 2018-04-06 14:04:35
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption Embedding Relation
author: Martin Engilberge, Louis Chevallier, Patrick Pérez, Matthieu Cord
mathjax: true
---

* content
{:toc}

##### Abstract
Several works have proposed to learn a two-path neural network that maps images and texts, respectively, to a same shared Euclidean space where geometry captures useful semantic relationships. Such a multi-modal embedding can be trained and used for various tasks, notably image captioning. In the present work, we introduce a new architecture of this type, with a visual path that leverages recent space-aware pooling mechanisms. Combined with a textual path which is jointly trained from scratch, our semantic-visual embedding offers a versatile model. Once trained under the supervision of captioned images, it yields new state-of-the-art performance on cross-modal retrieval. It also allows the localization of new concepts from the embedding space into any input image, delivering state-of-the-art result on the visual grounding of phrases.

##### Abstract (translated by Google)
有几篇作品提出要学习一个双路径神经网络，它将图像和文本分别映射到同一个共享的欧几里德空间，在这个空间中几何图形捕捉到有用的语义关系。这种多模式嵌入可以被训练并用于各种任务，特别是图像字幕。在目前的工作中，我们引入了一种新的这种类型的体系结构，其视觉路径利用了最近的空间感知池机制。结合从头开始共同训练的文本路径，我们的语义视觉嵌入提供了一种多功能模型。一旦在标题图像的监督下进行培训，它就会在跨模式检索中产生新的最新性能。它还允许将来自嵌入空间的新概念本地化到任何输入图像中，从而在短语的视觉基础上提供最新的结果。

##### URL
[https://arxiv.org/abs/1804.01720](https://arxiv.org/abs/1804.01720)

##### PDF
[https://arxiv.org/pdf/1804.01720](https://arxiv.org/pdf/1804.01720)

