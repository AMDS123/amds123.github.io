---
layout: post
title: "Segmentation Free Object Discovery in Video"
date: 2016-09-01 13:08:39
categories: arXiv_CV
tags: arXiv_CV Segmentation Relation
author: Giovanni Cuffaro, Federico Becattini, Claudio Baecchi, Lorenzo Seidenari, Alberto Del Bimbo
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we present a simple yet effective approach to extend without supervision any object proposal from static images to videos. Unlike previous methods, these spatio-temporal proposals, to which we refer as tracks, are generated relying on little or no visual content by only exploiting bounding boxes spatial correlations through time. The tracks that we obtain are likely to represent objects and are a general-purpose tool to represent meaningful video content for a wide variety of tasks. For unannotated videos, tracks can be used to discover content without any supervision. As further contribution we also propose a novel and dataset-independent method to evaluate a generic object proposal based on the entropy of a classifier output response. We experiment on two competitive datasets, namely YouTube Objects and ILSVRC-2015 VID.

##### Abstract (translated by Google)
在本文中，我们提出了一个简单而有效的方法，无需监督任何对象提案从静态图像到视频。与以前的方法不同，这些时空提议（我们称之为轨道）是通过仅仅利用边界框空间相关性而不依赖于很少或者没有视觉内容来生成的。我们获得的曲目可能代表对象，并且是一个通用工具，用于为各种任务呈现有意义的视频内容。对于未注释的视频，可以使用音轨在没有任何监督的情况下发现内容。作为进一步的贡献，我们还提出了一种基于分类器输出响应的熵来评估通用对象提议的新颖且独立于数据集的方法。我们试验了两个竞争数据集，即YouTube对象和ILSVRC-2015 VID。

##### URL
[https://arxiv.org/abs/1609.00221](https://arxiv.org/abs/1609.00221)

##### PDF
[https://arxiv.org/pdf/1609.00221](https://arxiv.org/pdf/1609.00221)

