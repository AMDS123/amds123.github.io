---
layout: post
title: "Beyond Word Embeddings: Learning Entity and Concept Representations from Large Scale Knowledge Bases"
date: 2018-08-30 21:54:56
categories: arXiv_AI
tags: arXiv_AI Knowledge Embedding
author: Walid Shalaby, Wlodek Zadrozny, Hongxia Jin
mathjax: true
---

* content
{:toc}

##### Abstract
Text representations using neural word embeddings have proven effective in many NLP applications. Recent researches adapt the traditional word embedding models to learn vectors of multiword expressions (concepts/entities). However, these methods are limited to textual knowledge bases (e.g., Wikipedia). In this paper, we propose a novel and simple technique for integrating the knowledge about concepts from two large scale knowledge bases of different structure (Wikipedia and Probase) in order to learn concept representations. We adapt the efficient skip-gram model to seamlessly learn from the knowledge in Wikipedia text and Probase concept graph. We evaluate our concept embedding models on two tasks: (1) analogical reasoning, where we achieve a state-of-the-art performance of 91% on semantic analogies, (2) concept categorization, where we achieve a state-of-the-art performance on two benchmark datasets achieving categorization accuracy of 100% on one and 98% on the other. Additionally, we present a case study to evaluate our model on unsupervised argument type identification for neural semantic parsing. We demonstrate the competitive accuracy of our unsupervised method and its ability to better generalize to out of vocabulary entity mentions compared to the tedious and error prone methods which depend on gazetteers and regular expressions.

##### Abstract (translated by Google)
使用神经词嵌入的文本表示已经证明在许多NLP应用中是有效的。最近的研究使传统的单词嵌入模型适应于学习多字表达（概念/实体）的向量。然而，这些方法仅限于文本知识库（例如，维基百科）。在本文中，我们提出了一种新颖而简单的技术，用于整合来自不同结构的两个大规模知识库（维基百科和Probase）的概念知识，以便学习概念表示。我们采用有效的skip-gram模型来无缝地学习维基百科文本和Probase概念图中的知识。我们在两个任务上评估我们的概念嵌入模型：（1）类比推理，我们在语义类比上实现91％的最先进性能，（2）概念分类，我们在其中实现状态-art性能在两个基准数据集上实现100％的分类精度，98％的分类精度。此外，我们提出了一个案例研究来评估我们的模型在无监督的参数类型识别神经语义解析。我们证明了我们的无监督方法的竞争准确性，以及与依赖于地名词典和正则表达式的繁琐且容易出错的方法相比，能够更好地推广到词汇实体提及的能力。

##### URL
[http://arxiv.org/abs/1801.00388](http://arxiv.org/abs/1801.00388)

##### PDF
[http://arxiv.org/pdf/1801.00388](http://arxiv.org/pdf/1801.00388)

