---
layout: post
title: "Learning Heuristics over Large Graphs via Deep Reinforcement Learning"
date: 2019-03-08 09:23:08
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Embedding CNN
author: Akash Mittal, Anuj Dhawan, Sourav Medya, Sayan Ranu, Ambuj Singh
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a deep reinforcement learning framework called GCOMB to learn algorithms that can solve combinatorial problems over large graphs. GCOMB mimics the greedy algorithm in the original problem and incrementally constructs a solution. The proposed framework utilizes Graph Convolutional Network (GCN) to generate node embeddings that predicts the potential nodes in the solution set from the entire node set. These embeddings enable an efficient training process to learn the greedy policy via Q-learning. Through extensive evaluation on several real and synthetic datasets containing up to a million nodes, we establish that GCOMB is up to 41% better than the state of the art, up to seven times faster than the greedy algorithm, robust and scalable to large dynamic networks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.03332](http://arxiv.org/abs/1903.03332)

##### PDF
[http://arxiv.org/pdf/1903.03332](http://arxiv.org/pdf/1903.03332)

