---
layout: post
title: "How clever is the FiLM model, and how clever can it be?"
date: 2018-09-09 21:08:57
categories: arXiv_AI
tags: arXiv_AI Relation
author: Alexander Kuhnle, Huiyuan Xie, Ann Copestake
mathjax: true
---

* content
{:toc}

##### Abstract
The FiLM model achieves close-to-perfect performance on the diagnostic CLEVR dataset and is distinguished from other such models by having a comparatively simple and easily transferable architecture. In this paper, we investigate in more detail the ability of FiLM to learn various linguistic constructions. Our main results show that (a) FiLM is not able to learn relational statements straight away except for very simple instances, (b) training on a broader set of instances as well as pretraining on simpler instance types can help alleviate these learning difficulties, (c) mixing is less robust than pretraining and very sensitive to the compositional structure of the dataset. Overall, our results suggest that the approach of big all-encompassing datasets and the paradigm of "the effectiveness of data" may have fundamental limitations.

##### Abstract (translated by Google)
FiLM模型在诊断CLEVR数据集上实现了接近完美的性能，并且通过具有相对简单且易于转移的架构而区别于其他此类模型。在本文中，我们更详细地研究了FiLM学习各种语言结构的能力。我们的主要结果表明：（a）FiLM不能立即学习关系语句，除非是非常简单的实例，（b）对更广泛的实例进行培训以及对更简单的实例类型进行预训练可以帮助减轻这些学习困难，（ c）混合不如预训练稳健，对数据集的组成结构非常敏感。总的来说，我们的结果表明，大范围的数据集的方法和“数据有效性”的范式可能具有根本的局限性。

##### URL
[http://arxiv.org/abs/1809.03044](http://arxiv.org/abs/1809.03044)

##### PDF
[http://arxiv.org/pdf/1809.03044](http://arxiv.org/pdf/1809.03044)

