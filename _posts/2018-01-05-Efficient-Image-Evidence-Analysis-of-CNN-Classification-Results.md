---
layout: post
title: "Efficient Image Evidence Analysis of CNN Classification Results"
date: 2018-01-05 10:31:21
categories: arXiv_CV
tags: arXiv_CV Salient CNN Classification Deep_Learning Recognition
author: Keyang Zhou, Bernhard Kainz
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional neural networks (CNNs) define the current state-of-the-art for image recognition. With their emerging popularity, especially for critical applications like medical image analysis or self-driving cars, confirmability is becoming an issue. The black-box nature of trained predictors make it difficult to trace failure cases or to understand the internal reasoning processes leading to results. In this paper we introduce a novel efficient method to visualise evidence that lead to decisions in CNNs. In contrast to network fixation or saliency map methods, our method is able to illustrate the evidence for or against a classifier's decision in input pixel space approximately 10 times faster than previous methods. We also show that our approach is less prone to noise and can focus on the most relevant input regions, thus making it more accurate and interpretable. Moreover, by making simplifications we link our method with other visualisation methods, providing a general explanation for gradient-based visualisation techniques. We believe that our work makes network introspection more feasible for debugging and understanding deep convolutional networks. This will increase trust between humans and deep learning models.

##### Abstract (translated by Google)
卷积神经网络（CNN）定义了当前图像识别的最新技术。随着它们越来越受欢迎，特别是对于像医学图像分析或自驾车的关键应用程序，可确认性正成为一个问题。经过训练的预测变量的黑盒特性使得难以追踪失败案例或理解导致结果的内部推理过程。在本文中，我们介绍一种新的有效的方法来可视化的证据导致决策CNNs。与网络固定或显着图方法相反，我们的方法能够说明对于分类器在输入像素空间中的决定的证据或者说反对比先前的方法快大约10倍的证据。我们还表明，我们的方法不太容易产生噪音，可以集中在最相关的输入区域，从而使其更加准确和可解释。此外，通过简化，我们将我们的方法与其他可视化方法联系起来，为基于梯度的可视化技术提供了一个通用的解释。我们相信，我们的工作使网络内省对调试和理解深度卷积网络更加可行。这将增加人与深度学习模式之间的信任。

##### URL
[http://arxiv.org/abs/1801.01693](http://arxiv.org/abs/1801.01693)

##### PDF
[http://arxiv.org/pdf/1801.01693](http://arxiv.org/pdf/1801.01693)

