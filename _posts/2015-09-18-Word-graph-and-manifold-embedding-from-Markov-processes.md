---
layout: post
title: "Word, graph and manifold embedding from Markov processes"
date: 2015-09-18 21:50:38
categories: arXiv_CL
tags: arXiv_CL Embedding Classification
author: Tatsunori B. Hashimoto, David Alvarez-Melis, Tommi S. Jaakkola
mathjax: true
---

* content
{:toc}

##### Abstract
Continuous vector representations of words and objects appear to carry surprisingly rich semantic content. In this paper, we advance both the conceptual and theoretical understanding of word embeddings in three ways. First, we ground embeddings in semantic spaces studied in cognitive-psychometric literature and introduce new evaluation tasks. Second, in contrast to prior work, we take metric recovery as the key object of study, unify existing algorithms as consistent metric recovery methods based on co-occurrence counts from simple Markov random walks, and propose a new recovery algorithm. Third, we generalize metric recovery to graphs and manifolds, relating co-occurence counts on random walks in graphs and random processes on manifolds to the underlying metric to be recovered, thereby reconciling manifold estimation and embedding algorithms. We compare embedding algorithms across a range of tasks, from nonlinear dimensionality reduction to three semantic language tasks, including analogies, sequence completion, and classification.

##### Abstract (translated by Google)
连续的单词和对象的矢量表示似乎带有令人惊讶的丰富的语义内容。在本文中，我们通过三种方式来推进对词嵌入的概念和理论的理解。首先，我们将嵌入到认知心理学文献中研究的语义空间中，并引入新的评估任务。其次，与以前的工作相比，本文以度量恢复为研究重点，将现有算法统一为基于简单马尔可夫随机游走的共现计数的一致度量恢复方法，提出了一种新的恢复算法。第三，我们将度量恢复概括为图和流形，将图中随机游走和流形上的随机过程的共同发生次数与要恢复的基础度量相关联，由此协调流形估计和嵌入算法。我们比较各种任务的嵌入算法，从非线性降维到三种语义语言任务，包括类比，序列完成和分类。

##### URL
[https://arxiv.org/abs/1509.05808](https://arxiv.org/abs/1509.05808)

##### PDF
[https://arxiv.org/pdf/1509.05808](https://arxiv.org/pdf/1509.05808)

