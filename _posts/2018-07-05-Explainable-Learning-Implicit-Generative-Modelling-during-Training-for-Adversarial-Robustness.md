---
layout: post
title: "Explainable Learning: Implicit Generative Modelling during Training for Adversarial Robustness"
date: 2018-07-05 21:52:36
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Priyadarshini Panda, Kaushik Roy
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce Explainable Learning ,ExL, an approach for training neural networks that are intrinsically robust to adversarial attacks. We find that the implicit generative modelling of random noise, during posterior maximization, improves a model's understanding of the data manifold furthering adversarial robustness. We prove our approach's efficacy and provide a simplistic visualization tool for understanding adversarial data, using Principal Component Analysis. Our analysis reveals that adversarial robustness, in general, manifests in models with higher variance along the high-ranked principal components. We show that models learnt with ExL perform remarkably well against a wide-range of black-box attacks.

##### Abstract (translated by Google)
我们介绍了可解释学习，ExL，一种训练神经网络的方法，这种神经网络本身对抗对抗性攻击。我们发现在后验最大化期间随机噪声的隐式生成建模改进了模型对数据流形的理解，从而进一步增强了对抗性鲁棒性。我们使用主成分分析证明了我们的方法的功效，并提供了一个简单的可视化工具，用于理解对抗性数据。我们的分析表明，一般而言，对抗性稳健性表现在沿着高排名主成分的方差较大的模型中。我们表明，使用ExL学习的模型在广泛的黑盒攻击中表现非常出色。

##### URL
[http://arxiv.org/abs/1807.02188](http://arxiv.org/abs/1807.02188)

##### PDF
[http://arxiv.org/pdf/1807.02188](http://arxiv.org/pdf/1807.02188)

