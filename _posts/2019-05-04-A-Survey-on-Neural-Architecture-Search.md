---
layout: post
title: "A Survey on Neural Architecture Search"
date: 2019-05-04 00:08:49
categories: arXiv_CV
tags: arXiv_CV Knowledge NAS Reinforcement_Learning Survey Optimization Deep_Learning
author: Martin Wistuba, Ambrish Rawat, Tejaswini Pedapati
mathjax: true
---

* content
{:toc}

##### Abstract
The growing interest in both the automation of machine learning and deep learning has inevitably led to the development of automated methods for neural architecture optimization. The choice of the network architecture has proven to be critical, and many advances in deep learning spring from its immediate improvements. However, deep learning techniques are computationally intensive and their application requires a high level of domain knowledge. Therefore, even partial automation of this process would help make deep learning more accessible to both researchers and practitioners. With this survey, we provide a formalism which unifies and categorizes the landscape of existing methods along with a detailed analysis that compares and contrasts the different approaches. We achieve this via a discussion of common architecture search spaces and architecture optimization algorithms based on principles of reinforcement learning and evolutionary algorithms along with approaches that incorporate surrogate and one-shot models. Additionally, we address the new research directions which include constrained and multi-objective architecture search as well as automated data augmentation, optimizer and activation function search.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1905.01392](https://arxiv.org/abs/1905.01392)

##### PDF
[https://arxiv.org/pdf/1905.01392](https://arxiv.org/pdf/1905.01392)

