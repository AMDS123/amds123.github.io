---
layout: post
title: "LaVAN: Localized and Visible Adversarial Noise"
date: 2018-01-08 18:44:23
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Danny Karmon, Daniel Zoran, Yoav Goldberg
mathjax: true
---

* content
{:toc}

##### Abstract
Most works on adversarial examples for deep-learning based image classifiers use noise that, while small, covers the entire image. We explore the case where the noise is allowed to be visible but confined to a small, localized patch of the image, without covering any of the main object(s) in the image. We show that it is possible to generate localized adversarial noises that cover only 2% of the pixels in the image, none of them over the main object, and that are transferable across images and locations, and successfully fool a state-of-the-art Inception v3 model with very high success rates.

##### Abstract (translated by Google)
大多数关于基于深度学习的图像分类器的对抗性例子的作品使用的噪声虽然很小，却能覆盖整个图像。我们研究了噪声允许可见的情况，但局限于图像的小的局部区域，而不覆盖图像中的任何主要对象。我们表明，有可能产生局部对抗噪声，其中只包括图像中的2％的像素，没有一个超过主要的对象，并且可以在图像和位置之间转移，并成功地欺骗了最先进的技术，艺术先觉v3模型与非常高的成功率。

##### URL
[http://arxiv.org/abs/1801.02608](http://arxiv.org/abs/1801.02608)

##### PDF
[http://arxiv.org/pdf/1801.02608](http://arxiv.org/pdf/1801.02608)

