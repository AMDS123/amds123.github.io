---
layout: post
title: "Contextualization of Morphological Inflection"
date: 2019-05-04 03:22:55
categories: arXiv_CL
tags: arXiv_CL Face
author: Ekaterina Vylomova, Ryan Cotterell, Timothy Baldwin, Trevor Cohn, Jason Eisner
mathjax: true
---

* content
{:toc}

##### Abstract
Critical to natural language generation is the production of correctly inflected text. In this paper, we isolate the task of predicting a fully inflected sentence from its partially lemmatized version. Unlike traditional morphological inflection or surface realization, our task input does not provide ``gold'' tags that specify what morphological features to realize on each lemmatized word; rather, such features must be inferred from sentential context. We develop a neural hybrid graphical model that explicitly reconstructs morphological features before predicting the inflected forms, and compare this to a system that directly predicts the inflected forms without relying on any morphological annotation. We experiment on several typologically diverse languages from the Universal Dependencies treebanks, showing the utility of incorporating linguistically-motivated latent variables into NLP models.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.01420](http://arxiv.org/abs/1905.01420)

##### PDF
[http://arxiv.org/pdf/1905.01420](http://arxiv.org/pdf/1905.01420)

