---
layout: post
title: "Spatial Transformer Introspective Neural Network"
date: 2018-05-16 17:53:21
categories: arXiv_CV
tags: arXiv_CV Classification
author: Yunhan Zhao, Ye Tian, Wei Shen, Alan Yuille
mathjax: true
---

* content
{:toc}

##### Abstract
Natural images contain many variations such as illumination differences, affine transformations, and shape distortions. Correctly classifying these variations poses a long standing problem. The most commonly adopted solution is to build large-scale datasets that contain objects under different variations. However, this approach is not ideal since it is computationally expensive and it is hard to cover all variations in one single dataset. Towards addressing this difficulty, we propose the spatial transformer introspective neural network (ST-INN) that explicitly generates samples with the unseen affine transformation variations in the training set. Experimental results indicate ST-INN achieves classification accuracy improvements on several benchmark datasets, including MNIST, affNIST, SVHN and CIFAR-10. We further extend our method to cross dataset classification tasks and few-shot learning problems to verify our method under extreme conditions and observe substantial improvements from experiment results.

##### Abstract (translated by Google)
自然图像包含许多变化，例如照明差异，仿射变换和形状失真。正确地对这些变化进行分类是一个长期存在的问题。最常采用的解决方案是构建包含不同变化对象的大型数据集。然而，这种方法并不理想，因为它在计算上花费很大，并且很难涵盖单个数据集中的所有变化。为了解决这个难题，我们提出了空间变换器内省神经网络（ST-INN），其明确地生成具有训练集中不可见的仿射变换变化的样本。实验结果表明，ST-INN在几种基准数据集上实现了分类准确度提升，包括MNIST，affNIST，SVHN和CIFAR-10。我们进一步扩展了我们的方法，以交叉数据集分类任务和少量学习问题来验证我们的方法在极端条件下并观察实验结果的实质性改进。

##### URL
[http://arxiv.org/abs/1805.06447](http://arxiv.org/abs/1805.06447)

##### PDF
[http://arxiv.org/pdf/1805.06447](http://arxiv.org/pdf/1805.06447)

