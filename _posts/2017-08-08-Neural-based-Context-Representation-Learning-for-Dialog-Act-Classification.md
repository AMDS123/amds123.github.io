---
layout: post
title: "Neural-based Context Representation Learning for Dialog Act Classification"
date: 2017-08-08 17:03:25
categories: arXiv_CL
tags: arXiv_CL Attention Represenation_Learning Classification
author: Daniel Ortega, Ngoc Thang Vu
mathjax: true
---

* content
{:toc}

##### Abstract
We explore context representation learning methods in neural-based models for dialog act classification. We propose and compare extensively different methods which combine recurrent neural network architectures and attention mechanisms (AMs) at different context levels. Our experimental results on two benchmark datasets show consistent improvements compared to the models without contextual information and reveal that the most suitable AM in the architecture depends on the nature of the dataset.

##### Abstract (translated by Google)
我们在基于神经模型的对话行为分类中探索上下文表示学习方法。我们提出并比较了在不同情境级别结合递归神经网络架构和注意机制（AM）的广泛不同的方法。我们在两个基准数据集上的实验结果与没有上下文信息的模型相比，显示了一致的改进，并且揭示了体系结构中最适合的AM取决于数据集的性质。

##### URL
[https://arxiv.org/abs/1708.02561](https://arxiv.org/abs/1708.02561)

##### PDF
[https://arxiv.org/pdf/1708.02561](https://arxiv.org/pdf/1708.02561)

