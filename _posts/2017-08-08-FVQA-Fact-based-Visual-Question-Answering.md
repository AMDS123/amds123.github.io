---
layout: post
title: "FVQA: Fact-based Visual Question Answering"
date: 2017-08-08 05:10:20
categories: arXiv_CV
tags: arXiv_CV VQA
author: Peng Wang, Qi Wu, Chunhua Shen, Anton van den Hengel, Anthony Dick
mathjax: true
---

* content
{:toc}

##### Abstract
Visual Question Answering (VQA) has attracted a lot of attention in both Computer Vision and Natural Language Processing communities, not least because it offers insight into the relationships between two important sources of information. Current datasets, and the models built upon them, have focused on questions which are answerable by direct analysis of the question and image alone. The set of such questions that require no external information to answer is interesting, but very limited. It excludes questions which require common sense, or basic factual knowledge to answer, for example. Here we introduce FVQA, a VQA dataset which requires, and supports, much deeper reasoning. FVQA only contains questions which require external information to answer. We thus extend a conventional visual question answering dataset, which contains image-question-answerg triplets, through additional image-question-answer-supporting fact tuples. The supporting fact is represented as a structural triplet, such as <Cat,CapableOf,ClimbingTrees>. We evaluate several baseline models on the FVQA dataset, and describe a novel model which is capable of reasoning about an image on the basis of supporting facts.

##### Abstract (translated by Google)
视觉问答（Visual Question Answering，VQA）在计算机视觉和自然语言处理领域引起了很多关注，不仅仅是因为它提供了对两个重要信息源之间关系的深入了解。目前的数据集，以及建立在这些数据集上的模型，都集中在通过直接分析问题和图像来回答的问题上。这类不需要外部信息回答的问题很有趣，但却非常有限。它排除了需要常识的问题，或者基本的事实知识来回答。这里我们介绍一个VQA数据集FVQA，它需要和支持更深入的推理。 FVQA只包含需要外部信息回答的问题。因此，我们通过附加的图像 - 问题 - 答案 - 支持的事实元组，扩展了一个包含图像问题 - 答案三元组的常规视觉问题答案数据集。支持的事实被表示为一个结构三元组，如<Cat，CapableOf，ClimbingTrees>。我们评估了FVQA数据集上的几个基准模型，并且描述了一个能够基于事实支持来对图像进行推理的新模型。

##### URL
[https://arxiv.org/abs/1606.05433](https://arxiv.org/abs/1606.05433)

