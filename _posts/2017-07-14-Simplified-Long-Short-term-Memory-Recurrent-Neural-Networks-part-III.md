---
layout: post
title: "Simplified Long Short-term Memory Recurrent Neural Networks: part III"
date: 2017-07-14 20:12:37
categories: arXiv_CV
tags: arXiv_CV RNN
author: Atra Akandeh, Fathi M. Salem
mathjax: true
---

* content
{:toc}

##### Abstract
This is part III of three-part work. In parts I and II, we have presented eight variants for simplified Long Short Term Memory (LSTM) recurrent neural networks (RNNs). It is noted that fast computation, specially in constrained computing resources, are an important factor in processing big time-sequence data. In this part III paper, we present and evaluate two new LSTM model variants which dramatically reduce the computational load while retaining comparable performance to the base (standard) LSTM RNNs. In these new variants, we impose (Hadamard) pointwise state multiplications in the cell-memory network in addition to the gating signal networks.

##### Abstract (translated by Google)
这是三部分工作的第三部分。在第一部分和第二部分中，我们已经提出了简化的长期短期记忆（LSTM）递归神经网络（RNN）的八个变体。值得注意的是，快速计算，特别是在受限计算资源中，是处理大时间序列数据的重要因素。在这篇第三部分的论文中，我们介绍和评估了两个新的LSTM模型变体，它们大大减少了计算量，同时保持了与基准（标准）LSTM RNNs相当的性能。在这些新的变体中，除了门控信号网络之外，我们在单元存储器网络中施加（哈达玛）逐点状态乘法。

##### URL
[https://arxiv.org/abs/1707.04626](https://arxiv.org/abs/1707.04626)

##### PDF
[https://arxiv.org/pdf/1707.04626](https://arxiv.org/pdf/1707.04626)

