---
layout: post
title: "Paying More Attention to Saliency: Image Captioning with Saliency and Context Attention"
date: 2018-05-21 09:26:27
categories: arXiv_CV
tags: arXiv_CV Image_Caption Salient Attention Caption CNN RNN Prediction Quantitative
author: Marcella Cornia, Lorenzo Baraldi, Giuseppe Serra, Rita Cucchiara
mathjax: true
---

* content
{:toc}

##### Abstract
Image captioning has been recently gaining a lot of attention thanks to the impressive achievements shown by deep captioning architectures, which combine Convolutional Neural Networks to extract image representations, and Recurrent Neural Networks to generate the corresponding captions. At the same time, a significant research effort has been dedicated to the development of saliency prediction models, which can predict human eye fixations. Even though saliency information could be useful to condition an image captioning architecture, by providing an indication of what is salient and what is not, research is still struggling to incorporate these two techniques. In this work, we propose an image captioning approach in which a generative recurrent neural network can focus on different parts of the input image during the generation of the caption, by exploiting the conditioning given by a saliency prediction model on which parts of the image are salient and which are contextual. We show, through extensive quantitative and qualitative experiments on large scale datasets, that our model achieves superior performances with respect to captioning baselines with and without saliency, and to different state of the art approaches combining saliency and captioning.

##### Abstract (translated by Google)
图像字幕最近引起了很多关注，这得益于深字幕体系结构所展示的令人印象深刻的成就，它们结合了卷积神经网络来提取图像表示，而回归神经网络则生成相应的字幕。同时，一项重要的研究工作致力于开发显着性预测模型，该模型可以预测人眼固定。尽管显着性信息可用于调节图像字幕结构，但通过提供显着和不显着的指示，研究仍在努力将这两种技术结合起来。在这项工作中，我们提出了一种图像字幕方法，其中生成的递归神经网络可以在生成字幕期间关注输入图像的不同部分，方法是利用显着性预测模型给出的条件，图像的哪些部分是突出的，是上下文的。我们通过对大规模数据集的广泛定量和定性实验表明，我们的模型在有和没有显着性的字幕基线方面取得了优异的性能，并且结合了显着性和字幕的不同技术方法。

##### URL
[https://arxiv.org/abs/1706.08474](https://arxiv.org/abs/1706.08474)

##### PDF
[https://arxiv.org/pdf/1706.08474](https://arxiv.org/pdf/1706.08474)

