---
layout: post
title: "That which we call private"
date: 2019-08-08 22:09:52
categories: arXiv_AI
tags: arXiv_AI
author: Ãšlfar Erlingsson, Ilya Mironov, Ananth Raghunathan, Shuang Song
mathjax: true
---

* content
{:toc}

##### Abstract
A casual reader of the study by Jayaraman and Evans in USENIX Security 2019 might conclude that "relaxed definitions of differential privacy" should be avoided, because they "increase the measured privacy leakage." This note clarifies that their study is consistent with a different interpretation. Namely, that the "relaxed definitions" are strict improvements which can improve the epsilon upper-bound guarantees by orders-of-magnitude without changing the actual privacy loss. Practitioners should be careful not to equate real-world privacy with epsilon values, without consideration of their context.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1908.03566](https://arxiv.org/abs/1908.03566)

##### PDF
[https://arxiv.org/pdf/1908.03566](https://arxiv.org/pdf/1908.03566)

