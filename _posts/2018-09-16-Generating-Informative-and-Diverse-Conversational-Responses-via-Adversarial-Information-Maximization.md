---
layout: post
title: "Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization"
date: 2018-09-16 22:45:51
categories: arXiv_AI
tags: arXiv_AI Adversarial
author: Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris Brockett, Bill Dolan
mathjax: true
---

* content
{:toc}

##### Abstract
Responses generated by neural conversational models tend to lack informativeness and diversity. We present Adversarial Information Maximization (AIM), an adversarial learning strategy that addresses these two related but distinct problems. To foster response diversity, we leverage adversarial training that allows distributional matching of synthetic and real responses. To improve informativeness, our framework explicitly optimizes a variational lower bound on pairwise mutual information between query and response. Empirical results from automatic and human evaluations demonstrate that our methods significantly boost informativeness and diversity.

##### Abstract (translated by Google)
神经对话模型产生的反应往往缺乏信息量和多样性。我们提出了对抗性信息最大化（AIM），这是一种针对这两个相关但不同的问题的对抗性学习策略。为了促进响应多样性，我们利用对抗性训练，允许合成和实际响应的分布匹配。为了提高信息量，我们的框架明确地优化了查询和响应之间成对互信息的变化下界。自动和人工评估的实证结果表明，我们的方法显着提高了信息量和多样性。

##### URL
[http://arxiv.org/abs/1809.05972](http://arxiv.org/abs/1809.05972)

##### PDF
[http://arxiv.org/pdf/1809.05972](http://arxiv.org/pdf/1809.05972)

