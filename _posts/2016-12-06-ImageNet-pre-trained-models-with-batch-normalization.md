---
layout: post
title: "ImageNet pre-trained models with batch normalization"
date: 2016-12-06 12:20:00
categories: arXiv_CV
tags: arXiv_CV CNN
author: Marcel Simon, Erik Rodner, Joachim Denzler
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional neural networks (CNN) pre-trained on ImageNet are the backbone of most state-of-the-art approaches. In this paper, we present a new set of pre-trained models with popular state-of-the-art architectures for the Caffe framework. The first release includes Residual Networks (ResNets) with generation script as well as the batch-normalization-variants of AlexNet and VGG19. All models outperform previous models with the same architecture. The models and training code are available at this http URL and this https URL

##### Abstract (translated by Google)
在ImageNet上预先训练的卷积神经网络（CNN）是大多数最先进的方法的基础。在本文中，我们提出了一套新的预先训练的模型，以及用于Caffe框架的流行的最先进的体系结构。第一个版本包括带有生成脚本的Residual Networks（ResNets）以及AlexNet和VGG19的批量规范化变体。所有的模型在相同的架构上胜过以前的模型。模型和培训代码可在此http URL和此https URL中获得

##### URL
[https://arxiv.org/abs/1612.01452](https://arxiv.org/abs/1612.01452)

##### PDF
[https://arxiv.org/pdf/1612.01452](https://arxiv.org/pdf/1612.01452)

