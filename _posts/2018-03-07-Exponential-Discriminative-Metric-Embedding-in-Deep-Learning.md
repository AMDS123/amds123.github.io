---
layout: post
title: "Exponential Discriminative Metric Embedding in Deep Learning"
date: 2018-03-07 02:39:34
categories: arXiv_CV
tags: arXiv_CV Face Embedding CNN Classification Deep_Learning Recognition Face_Recognition
author: Bowen Wu, Zhangling Chen, Jun Wang, Huaming Wu
mathjax: true
---

* content
{:toc}

##### Abstract
With the remarkable success achieved by the Convolutional Neural Networks (CNNs) in object recognition recently, deep learning is being widely used in the computer vision community. Deep Metric Learning (DML), integrating deep learning with conventional metric learning, has set new records in many fields, especially in classification task. In this paper, we propose a replicable DML method, called Include and Exclude (IE) loss, to force the distance between a sample and its designated class center away from the mean distance of this sample to other class centers with a large margin in the exponential feature projection space. With the supervision of IE loss, we can train CNNs to enhance the intra-class compactness and inter-class separability, leading to great improvements on several public datasets ranging from object recognition to face verification. We conduct a comparative study of our algorithm with several typical DML methods on three kinds of networks with different capacity. Extensive experiments on three object recognition datasets and two face recognition datasets demonstrate that IE loss is always superior to other mainstream DML methods and approach the state-of-the-art results.

##### Abstract (translated by Google)
近来，由于卷积神经网络（CNN）在物体识别领域取得的巨大成功，深度学习在计算机视觉领域得到了广泛的应用。深度度量学习（DML）将深度学习与传统度量学习相结合，在许多领域创造了新的记录，特别是在分类任务中。在本文中，我们提出了一个可复制的DML方法，称为包含和排除（IE）损失，以强制样本与其指定类中心之间的距离远离此样本的平均距离，指数特征投影空间。在IE损失的监督下，我们可以通过训练CNN来提高课堂内部的紧凑性和课堂间的可分离性，从而从对象识别到面部验证等多个公共数据集都得到了很大的改进。我们在三种不同容量的网络上对几种典型的DML方法进行了比较研究。在三个目标识别数据集和两个人脸识别数据集上进行的大量实验表明，IE损失总是优于其他主流DML方法，并且接近最新的结果。

##### URL
[http://arxiv.org/abs/1803.02504](http://arxiv.org/abs/1803.02504)

##### PDF
[http://arxiv.org/pdf/1803.02504](http://arxiv.org/pdf/1803.02504)

