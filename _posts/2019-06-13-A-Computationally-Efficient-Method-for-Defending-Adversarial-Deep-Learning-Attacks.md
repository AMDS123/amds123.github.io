---
layout: post
title: "A Computationally Efficient Method for Defending Adversarial Deep Learning Attacks"
date: 2019-06-13 10:56:47
categories: arXiv_CV
tags: arXiv_CV Adversarial Classification Deep_Learning
author: Rajeev Sahay, Rehana Mahfuz, Aly El Gamal
mathjax: true
---

* content
{:toc}

##### Abstract
The reliance on deep learning algorithms has grown significantly in recent years. Yet, these models are highly vulnerable to adversarial attacks, which introduce visually imperceptible perturbations into testing data to induce misclassifications. The literature has proposed several methods to combat such adversarial attacks, but each method either fails at high perturbation values, requires excessive computing power, or both. This letter proposes a computationally efficient method for defending the Fast Gradient Sign (FGS) adversarial attack by simultaneously denoising and compressing data. Specifically, our proposed defense relies on training a fully connected multi-layer Denoising Autoencoder (DAE) and using its encoder as a defense against the adversarial attack. Our results show that using this dimensionality reduction scheme is not only highly effective in mitigating the effect of the FGS attack in multiple threat models, but it also provides a 2.43x speedup in comparison to defense strategies providing similar robustness against the same attack.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1906.05599](https://arxiv.org/abs/1906.05599)

##### PDF
[https://arxiv.org/pdf/1906.05599](https://arxiv.org/pdf/1906.05599)

