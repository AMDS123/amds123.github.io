---
layout: post
title: "Multi-View Task-Driven Recognition in Visual Sensor Networks"
date: 2017-05-31 22:03:10
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Regularization Sparse Represenation_Learning Recognition
author: Ali Taalimi, Alireza Rahimpour, Liu Liu, Hairong Qi
mathjax: true
---

* content
{:toc}

##### Abstract
Nowadays, distributed smart cameras are deployed for a wide set of tasks in several application scenarios, ranging from object recognition, image retrieval, and forensic applications. Due to limited bandwidth in distributed systems, efficient coding of local visual features has in fact been an active topic of research. In this paper, we propose a novel approach to obtain a compact representation of high-dimensional visual data using sensor fusion techniques. We convert the problem of visual analysis in resource-limited scenarios to a multi-view representation learning, and we show that the key to finding properly compressed representation is to exploit the position of cameras with respect to each other as a norm-based regularization in the particular signal representation of sparse coding. Learning the representation of each camera is viewed as an individual task and a multi-task learning with joint sparsity for all nodes is employed. The proposed representation learning scheme is referred to as the multi-view task-driven learning for visual sensor network (MT-VSN). We demonstrate that MT-VSN outperforms state-of-the-art in various surveillance recognition tasks.

##### Abstract (translated by Google)
如今，分布式智能相机被部署用于多种应用场景中的各种任务，从物体识别，图像检索和取证应用。由于分布式系统的带宽有限，本地视觉特征的高效编码实际上是一个活跃的研究课题。在本文中，我们提出了一种新颖的方法来获得使用传感器融合技术的高维视觉数据的紧凑表示。我们将资源有限情景下的视觉分析问题转换为多视图表示学习，并且我们证明寻找正确压缩表示的关键在于利用摄像机相对于对方的位置作为基于规范的正则化稀疏编码的特定信号表示。学习每个摄像机的表示被视为一个单独的任务，并采用联合稀疏的多任务学习的所有节点。所提出的表示学习方案被称为视觉传感器网络（MT-VSN）的多视图任务驱动学习。我们证明MT-VSN在各种监视识别任务中胜过最先进的技术。

##### URL
[https://arxiv.org/abs/1705.10715](https://arxiv.org/abs/1705.10715)

##### PDF
[https://arxiv.org/pdf/1705.10715](https://arxiv.org/pdf/1705.10715)

