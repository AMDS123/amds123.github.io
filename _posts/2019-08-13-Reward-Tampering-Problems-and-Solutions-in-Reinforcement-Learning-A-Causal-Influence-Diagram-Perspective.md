---
layout: post
title: "Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective"
date: 2019-08-13 16:50:00
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Tom Everitt, Marcus Hutter
mathjax: true
---

* content
{:toc}

##### Abstract
Can an arbitrarily intelligent reinforcement learning agent be kept under control by a human user? Or do agents with sufficient intelligence inevitably find ways to shortcut their reward signal? This question impacts how far reinforcement learning can be scaled, and whether alternative paradigms must be developed in order to build safe artificial general intelligence. In this paper, we use an intuitive yet precise graphical model called causal influence diagrams to formalize reward tampering problems. We also describe a number of tweaks to the reinforcement learning objective that prevent incentives for reward tampering. We verify the solutions using recently developed graphical criteria for inferring agent incentives from causal influence diagrams.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.04734](http://arxiv.org/abs/1908.04734)

##### PDF
[http://arxiv.org/pdf/1908.04734](http://arxiv.org/pdf/1908.04734)

