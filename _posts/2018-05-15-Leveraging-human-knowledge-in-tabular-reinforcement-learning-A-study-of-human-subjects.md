---
layout: post
title: "Leveraging human knowledge in tabular reinforcement learning: A study of human subjects"
date: 2018-05-15 13:51:31
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning
author: Ariel Rosenfeld, Moshe Cohen, Matthew E. Taylor, Sarit Kraus
mathjax: true
---

* content
{:toc}

##### Abstract
Reinforcement Learning (RL) can be extremely effective in solving complex, real-world problems. However, injecting human knowledge into an RL agent may require extensive effort and expertise on the human designer's part. To date, human factors are generally not considered in the development and evaluation of possible RL approaches. In this article, we set out to investigate how different methods for injecting human knowledge are applied, in practice, by human designers of varying levels of knowledge and skill. We perform the first empirical evaluation of several methods, including a newly proposed method named SASS which is based on the notion of similarities in the agent's state-action space. Through this human study, consisting of 51 human participants, we shed new light on the human factors that play a key role in RL. We find that the classical reward shaping technique seems to be the most natural method for most designers, both expert and non-expert, to speed up RL. However, we further find that our proposed method SASS can be effectively and efficiently combined with reward shaping, and provides a beneficial alternative to using only a single speedup method with minimal human designer effort overhead.

##### Abstract (translated by Google)
强化学习（RL）可以非常有效地解决复杂的现实世界问题。然而，将人类知识注入RL代理可能需要人类设计师的广泛努力和专业知识。迄今为止，在可能的RL方法的开发和评估中通常不考虑人为因素。在本文中，我们着手调查不同的知识和技能水平的人类设计者在实践中如何应用注入人类知识的不同方法。我们对几种方法进行了第一次实证评估，其中包括一种新提出的方法，名为SASS，它基于代理人状态空间中相似性的概念。通过这项由51名人类参与者组成的人类研究，我们揭示了在RL中发挥关键作用的人为因素。我们发现，经典奖励塑形技术似乎是大多数设计师（包括专家和非专家）加速RL的最自然的方法。然而，我们进一步发现，我们提出的方法SASS可以有效和高效地与奖励整形相结合，并且提供了一个有益的替代方法，只使用单个加速方法，并且人力设计师的工作量最小。

##### URL
[http://arxiv.org/abs/1805.05769](http://arxiv.org/abs/1805.05769)

##### PDF
[http://arxiv.org/pdf/1805.05769](http://arxiv.org/pdf/1805.05769)

