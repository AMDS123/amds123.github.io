---
layout: post
title: "Robotic Navigation using Entropy-Based Exploration"
date: 2019-06-17 11:44:15
categories: arXiv_RO
tags: arXiv_RO Reinforcement_Learning
author: Muhammad Usama, Dong Eui Chang
mathjax: true
---

* content
{:toc}

##### Abstract
Robotic navigation concerns the task in which a robot should be able to find a safe and feasible path and traverse between two points in a complex environment. We approach the problem of robotic navigation using reinforcement learning and use deep $Q$-networks to train agents to solve the task of robotic navigation. We compare the Entropy-Based Exploration (EBE) with the widely used $\epsilon$-greedy exploration strategy by training agents using both of them in simulation. The trained agents are then tested on different versions of the environment to test the generalization ability of the learned policies. We also implement the learned policies on a real robot in complex real environment without any fine tuning and compare the effectiveness of the above-mentioned exploration strategies in the real world setting. Video showing experiments on TurtleBot3 platform is available at \url{https://youtu.be/NHT-EiN_4n8}.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.06969](http://arxiv.org/abs/1906.06969)

##### PDF
[http://arxiv.org/pdf/1906.06969](http://arxiv.org/pdf/1906.06969)

