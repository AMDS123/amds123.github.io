---
layout: post
title: "Multimodal Language Analysis with Recurrent Multistage Fusion"
date: 2018-08-12 10:04:45
categories: arXiv_AI
tags: arXiv_AI Sentiment RNN Recognition
author: Paul Pu Liang, Ziyin Liu, Amir Zadeh, Louis-Philippe Morency
mathjax: true
---

* content
{:toc}

##### Abstract
Computational modeling of human multimodal language is an emerging research area in natural language processing spanning the language, visual and acoustic modalities. Comprehending multimodal language requires modeling not only the interactions within each modality (intra-modal interactions) but more importantly the interactions between modalities (cross-modal interactions). In this paper, we propose the Recurrent Multistage Fusion Network (RMFN) which decomposes the fusion problem into multiple stages, each of them focused on a subset of multimodal signals for specialized, effective fusion. Cross-modal interactions are modeled using this multistage fusion approach which builds upon intermediate representations of previous stages. Temporal and intra-modal interactions are modeled by integrating our proposed fusion approach with a system of recurrent neural networks. The RMFN displays state-of-the-art performance in modeling human multimodal language across three public datasets relating to multimodal sentiment analysis, emotion recognition, and speaker traits recognition. We provide visualizations to show that each stage of fusion focuses on a different subset of multimodal signals, learning increasingly discriminative multimodal representations.

##### Abstract (translated by Google)
人类多模语言的计算建模是自然语言处理中新兴的研究领域，涵盖语言，视觉和声学模式。理解多模式语言不仅需要建模每种模态中的相互作用（模内相互作用），更重要的是模态之间的相互作用（跨模式相互作用）。在本文中，我们提出了循环多级融合网络（RMFN），它将融合问题分解为多个阶段，每个阶段都集中在多模态信号的子集上，以进行专门的有效融合。使用这种多阶段融合方法对跨模态相互作用进行建模，该方法建立在先前阶段的中间表示之上。通过将我们提出的融合方法与递归神经网络系统相结合来模拟时间和模态内相互作用。 RMFN在三种与多模式情感分析，情感识别和说话人特征识别相关的公共数据集中对人类多模式语言进行建模时，展示了最先进的表现。我们提供可视化来表明每个融合阶段都集中在多模态信号的不同子集上，学习越来越具有辨别力的多模态表示。

##### URL
[http://arxiv.org/abs/1808.03920](http://arxiv.org/abs/1808.03920)

##### PDF
[http://arxiv.org/pdf/1808.03920](http://arxiv.org/pdf/1808.03920)

