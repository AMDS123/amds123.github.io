---
layout: post
title: "Toward Mention Detection Robustness with Recurrent Neural Networks"
date: 2016-02-24 23:14:01
categories: arXiv_SD
tags: arXiv_SD Embedding RNN Detection Recognition
author: Thien Huu Nguyen, Avirup Sil, Georgiana Dinu, Radu Florian
mathjax: true
---

* content
{:toc}

##### Abstract
One of the key challenges in natural language processing (NLP) is to yield good performance across application domains and languages. In this work, we investigate the robustness of the mention detection systems, one of the fundamental tasks in information extraction, via recurrent neural networks (RNNs). The advantage of RNNs over the traditional approaches is their capacity to capture long ranges of context and implicitly adapt the word embeddings, trained on a large corpus, into a task-specific word representation, but still preserve the original semantic generalization to be helpful across domains. Our systematic evaluation for RNN architectures demonstrates that RNNs not only outperform the best reported systems (up to 9\% relative error reduction) in the general setting but also achieve the state-of-the-art performance in the cross-domain setting for English. Regarding other languages, RNNs are significantly better than the traditional methods on the similar task of named entity recognition for Dutch (up to 22\% relative error reduction).

##### Abstract (translated by Google)
自然语言处理（NLP）中的一个关键挑战是在应用程序域和语言之间产生良好的性能。在这项工作中，我们通过递归神经网络（RNN）研究提及检测系统的鲁棒性，提取检测系统是信息提取的基本任务之一。 RNN优于传统方法的优势在于它们捕捉大范围的上下文并隐含地将经过大型语料库训练的词嵌入调整为特定于任务的词表示的能力，但是仍然保留了原始的语义泛化以跨域。我们对RNN体系结构的系统评估表明，在一般设置下，RNN不仅胜过最佳报告系统（高达9％的相对误差减少），而且还实现了英文跨域设置的最新性能。对于其他语言而言，RNN在荷兰类命名实体识别任务方面明显优于传统方法（相对误差降低22％）。

##### URL
[https://arxiv.org/abs/1602.07749](https://arxiv.org/abs/1602.07749)

##### PDF
[https://arxiv.org/pdf/1602.07749](https://arxiv.org/pdf/1602.07749)

