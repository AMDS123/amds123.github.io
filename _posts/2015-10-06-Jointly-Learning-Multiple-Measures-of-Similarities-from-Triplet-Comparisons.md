---
layout: post
title: "Jointly Learning Multiple Measures of Similarities from Triplet Comparisons"
date: 2015-10-06 21:42:55
categories: arXiv_CV
tags: arXiv_CV Face Embedding Relation
author: Liwen Zhang, Subhransu Maji, Ryota Tomioka
mathjax: true
---

* content
{:toc}

##### Abstract
Similarity between objects is multi-faceted and it can be easier for human annotators to measure it when the focus is on a specific aspect. We consider the problem of mapping objects into view-specific embeddings where the distance between them is consistent with the similarity comparisons of the form "from the t-th view, object A is more similar to B than to C". Our framework jointly learns view-specific embeddings exploiting correlations between views. Experiments on a number of datasets, including one of multi-view crowdsourced comparison on bird images, show the proposed method achieves lower triplet generalization error when compared to both learning embeddings independently for each view and all views pooled into one view. Our method can also be used to learn multiple measures of similarity over input features taking class labels into account and compares favorably to existing approaches for multi-task metric learning on the ISOLET dataset.

##### Abstract (translated by Google)
对象之间的相似性是多方面的，当注意力集中在特定的方面时，人类注释者可以更容易地进行度量。我们考虑将对象映射到视图特定嵌入的问题，其中它们之间的距离与形式“从第t视图到对象A比B更接近于C”形式的相似性比较一致。我们的框架共同学习利用视图之间相关性的视点特定嵌入。对多个数据集进行实验，包括鸟瞰图上的多视图众包比较，结果表明，与单独为每个视图进行学习嵌入和将所有视图合并到一个视图中相比，所提出的方法实现了较低的三重泛化误差。我们的方法也可以用来学习考虑到类标签的输入特征相似度的多重度量，并与ISOLET数据集上的多任务度量学习的现有方法相比较。

##### URL
[https://arxiv.org/abs/1503.01521](https://arxiv.org/abs/1503.01521)

##### PDF
[https://arxiv.org/pdf/1503.01521](https://arxiv.org/pdf/1503.01521)

