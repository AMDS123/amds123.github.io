---
layout: post
title: "Learning Visual N-Grams from Web Data"
date: 2017-08-06 01:59:22
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Caption CNN Language_Model Prediction Recognition
author: Ang Li, Allan Jabri, Armand Joulin, Laurens van der Maaten
mathjax: true
---

* content
{:toc}

##### Abstract
Real-world image recognition systems need to recognize tens of thousands of classes that constitute a plethora of visual concepts. The traditional approach of annotating thousands of images per class for training is infeasible in such a scenario, prompting the use of webly supervised data. This paper explores the training of image-recognition systems on large numbers of images and associated user comments. In particular, we develop visual n-gram models that can predict arbitrary phrases that are relevant to the content of an image. Our visual n-gram models are feed-forward convolutional networks trained using new loss functions that are inspired by n-gram models commonly used in language modeling. We demonstrate the merits of our models in phrase prediction, phrase-based image retrieval, relating images and captions, and zero-shot transfer.

##### Abstract (translated by Google)
真实世界的图像识别系统需要识别构成过多视觉概念的数万个类。在这种情况下，传统的方法是为每个类别注释数千个图像以进行训练，这促使使用网络监督数据。本文探讨了对大量图像和相关用户评论的图像识别系统的培训。特别是，我们开发了可视化的n-gram模型，可以预测与图像内容相关的任意短语。我们的可视化n-gram模型是使用新的损失函数训练的前馈卷积网络，这些函数受到语言建模中常用的n-gram模型的启发。我们在短语预测，基于短语的图像检索，相关图像和标题以及零射击转移中展示了我们模型的优点。

##### URL
[https://arxiv.org/abs/1612.09161](https://arxiv.org/abs/1612.09161)

##### PDF
[https://arxiv.org/pdf/1612.09161](https://arxiv.org/pdf/1612.09161)

