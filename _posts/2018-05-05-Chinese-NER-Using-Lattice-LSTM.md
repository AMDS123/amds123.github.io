---
layout: post
title: "Chinese NER Using Lattice LSTM"
date: 2018-05-05 08:48:32
categories: arXiv_CL
tags: arXiv_CL Segmentation RNN
author: Yue Zhang, Jie Yang
mathjax: true
---

* content
{:toc}

##### Abstract
We investigate a lattice-structured LSTM model for Chinese NER, which encodes a sequence of input characters as well as all potential words that match a lexicon. Compared with character-based methods, our model explicitly leverages word and word sequence information. Compared with word-based methods, lattice LSTM does not suffer from segmentation errors. Gated recurrent cells allow our model to choose the most relevant characters and words from a sentence for better NER results. Experiments on various datasets show that lattice LSTM outperforms both word-based and character-based LSTM baselines, achieving the best results.

##### Abstract (translated by Google)
我们调查了中国NER格子结构的LSTM模型，该模型编码输入字符序列以及与词典匹配的所有潜在词语。与基于字符的方法相比，我们的模型明确地利用了单词和单词序列信息。与基于字的方法相比，格子LSTM不会遭受分割错误。门控复发细胞允许我们的模型从句子中选择最相关的字符和单词以获得更好的NER结果。对各种数据集的实验表明，格LSTM优于基于字和基于字符的LSTM基线，实现最佳结果。

##### URL
[http://arxiv.org/abs/1805.02023](http://arxiv.org/abs/1805.02023)

##### PDF
[http://arxiv.org/pdf/1805.02023](http://arxiv.org/pdf/1805.02023)

