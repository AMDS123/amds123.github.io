---
layout: post
title: "PIMMS: Permutation Invariant Multi-Modal Segmentation"
date: 2018-07-17 16:32:38
categories: arXiv_CV
tags: arXiv_CV Segmentation CNN Inference
author: Thomas Varsavsky, Zach Eaton-Rosen, Carole H. Sudre, Parashkev Nachev, M. Jorge Cardoso
mathjax: true
---

* content
{:toc}

##### Abstract
In a research context, image acquisition will often involve a pre-defined static protocol and the data will be of high quality. If we are to build applications that work in hospitals without significant operational changes in care delivery, algorithms should be designed to cope with the available data in the best possible way. In a clinical environment, imaging protocols are highly flexible, with MRI sequences commonly missing appropriate sequence labeling (e.g. T1, T2, FLAIR). To this end we introduce PIMMS, a Permutation Invariant Multi-Modal Segmentation technique that is able to perform inference over sets of MRI scans without using modality labels. We present results which show that our convolutional neural network can, in some settings, outperform a baseline model which utilizes modality labels, and achieve comparable performance otherwise.

##### Abstract (translated by Google)
在研究背景下，图像采集通常涉及预定义的静态协议，并且数据将具有高质量。如果我们要构建在医院中工作的应用程序而不会在护理交付中发生重大的操作变化，那么应该设计算法以尽可能最好地处理可用数据。在临床环境中，成像方案是高度灵活的，MRI序列通常缺少适当的序列标记（例如T1，T2，FLAIR）。为此，我们引入了PIMMS，一种置换不变多模态分割技术，能够在不使用模态标签的情况下对MRI扫描集进行推理。我们提出的结果表明，在某些情况下，我们的卷积神经网络可以胜过利用模态标签的基线模型，并且在其他方​​面可以获得相当的性能。

##### URL
[http://arxiv.org/abs/1807.06537](http://arxiv.org/abs/1807.06537)

##### PDF
[http://arxiv.org/pdf/1807.06537](http://arxiv.org/pdf/1807.06537)

