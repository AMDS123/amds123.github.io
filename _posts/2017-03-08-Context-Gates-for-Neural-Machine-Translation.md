---
layout: post
title: "Context Gates for Neural Machine Translation"
date: 2017-03-08 07:14:27
categories: arXiv_CL
tags: arXiv_CL NMT
author: Zhaopeng Tu, Yang Liu, Zhengdong Lu, Xiaohua Liu, Hang Li
mathjax: true
---

* content
{:toc}

##### Abstract
In neural machine translation (NMT), generation of a target word depends on both source and target contexts. We find that source contexts have a direct impact on the adequacy of a translation while target contexts affect the fluency. Intuitively, generation of a content word should rely more on the source context and generation of a functional word should rely more on the target context. Due to the lack of effective control over the influence from source and target contexts, conventional NMT tends to yield fluent but inadequate translations. To address this problem, we propose context gates which dynamically control the ratios at which source and target contexts contribute to the generation of target words. In this way, we can enhance both the adequacy and fluency of NMT with more careful control of the information flow from contexts. Experiments show that our approach significantly improves upon a standard attention-based NMT system by +2.3 BLEU points.

##### Abstract (translated by Google)
在神经机器翻译（NMT）中，目标单词的生成取决于源语境和目标语境。我们发现源语境对翻译的充分性有直接影响，而目标语境影响流利度。直观地说，内容词的生成应该更多地依赖于源语境，并且功能词的生成应该更多地依赖于目标语境。由于缺乏对来源和目标语境影响的有效控制，传统的NMT倾向于产生流畅但不充分的翻译。为了解决这个问题，我们提出了动态控制源和目标上下文有助于产生目标单词的比率的上下文门。通过这种方式，我们可以更加细致地控制来自上下文的信息流，从而提高NMT的充分性和流畅性。实验表明，我们的方法在标准的基于注意力的NMT系统上显着提高了+2.3 BLEU点。

##### URL
[https://arxiv.org/abs/1608.06043](https://arxiv.org/abs/1608.06043)

##### PDF
[https://arxiv.org/pdf/1608.06043](https://arxiv.org/pdf/1608.06043)

