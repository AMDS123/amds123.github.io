---
layout: post
title: "Extractive Adversarial Networks: High-Recall Explanations for Identifying Personal Attacks in Social Media Posts"
date: 2018-09-01 00:15:30
categories: arXiv_CL
tags: arXiv_CL Adversarial Attention
author: Samuel Carton, Qiaozhu Mei, Paul Resnick
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce an adversarial method for producing high-recall explanations of neural text classifier decisions. Building on an existing architecture for extractive explanations via hard attention, we add an adversarial layer which scans the residual of the attention for remaining predictive signal. Motivated by the important domain of detecting personal attacks in social media comments, we additionally demonstrate the importance of manually setting a semantically appropriate `default' behavior for the model by explicitly manipulating its bias term. We develop a validation set of human-annotated personal attacks to evaluate the impact of these changes.

##### Abstract (translated by Google)
我们引入了一种对抗方法，用于产生神经文本分类器决策的高召回率解释。通过强烈关注的现有架构进行解释性解释，我们添加了一个对抗层，扫描剩余的注意力以保留预测信号。在社交媒体评论中检测个人攻击的重要领域的推动下，我们还通过明确地操纵其偏见项来证明为模型手动设置语义上适当的“默认”行为的重要性。我们开发了一套人工注释的人身攻击验证集，以评估这些变化的影响。

##### URL
[http://arxiv.org/abs/1809.01499](http://arxiv.org/abs/1809.01499)

##### PDF
[http://arxiv.org/pdf/1809.01499](http://arxiv.org/pdf/1809.01499)

