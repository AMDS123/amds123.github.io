---
layout: post
title: "Human Semantic Parsing for Person Re-identification"
date: 2018-03-31 21:13:07
categories: arXiv_CV
tags: arXiv_CV Re-identification Person_Re-identification CNN Represenation_Learning Detection
author: Mahdi M. Kalayeh, Emrah Basaran, Muhittin Gokmen, Mustafa E. Kamasak, Mubarak Shah
mathjax: true
---

* content
{:toc}

##### Abstract
Person re-identification is a challenging task mainly due to factors such as background clutter, pose, illumination and camera point of view variations. These elements hinder the process of extracting robust and discriminative representations, hence preventing different identities from being successfully distinguished. To improve the representation learning, usually, local features from human body parts are extracted. However, the common practice for such a process has been based on bounding box part detection. In this paper, we propose to adopt human semantic parsing which, due to its pixel-level accuracy and capability of modeling arbitrary contours, is naturally a better alternative. Our proposed SPReID integrates human semantic parsing in person re-identification and not only considerably outperforms its counter baseline, but achieves state-of-the-art performance. We also show that by employing a \textit{simple} yet effective training strategy, standard popular deep convolutional architectures such as Inception-V3 and ResNet-152, with no modification, while operating solely on full image, can dramatically outperform current state-of-the-art. Our proposed methods improve state-of-the-art person re-identification on: Market-1501 by ~17% in mAP and ~6% in rank-1, CUHK03 by ~4% in rank-1 and DukeMTMC-reID by ~24% in mAP and ~10% in rank-1.

##### Abstract (translated by Google)
人员重新识别是一项具有挑战性的任务，主要是由于诸如背景杂波，姿势，照明和相机角度变化等因素。这些元素阻碍了提取鲁棒性和区分性表示的过程，从而阻止了不同身份被成功区分。为了改善表示学习，通常提取来自人体部位的局部特征。但是，这种过程的通常做法是基于边界框部分检测。在本文中，我们建议采用人为语义分析，由于其像素级精度和建模任意轮廓的能力，自然是更好的选择。我们提出的SPReID将人类语义分析融入人体再识别中，不仅显着优于其反基线，而且达到了最先进的性能。我们还表明，通过采用\ textit {简单}但有效的训练策略，标准流行的深度卷积体系结构，如Inception-V3和ResNet-152，在没有修改的情况下，仅在完整图像上运行时，可以显着地胜过当前状态-艺术。我们提出的方法改善了最先进的人重新识别：Market-1501在mAP中约为17％，在一级中约为6％，CUHK03在一级中约为4％，而DukeMMC-reID由〜 24％在MAP和〜10％在1级。

##### URL
[http://arxiv.org/abs/1804.00216](http://arxiv.org/abs/1804.00216)

##### PDF
[http://arxiv.org/pdf/1804.00216](http://arxiv.org/pdf/1804.00216)

