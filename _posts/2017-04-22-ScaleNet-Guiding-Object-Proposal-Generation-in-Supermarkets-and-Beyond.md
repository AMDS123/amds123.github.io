---
layout: post
title: "ScaleNet: Guiding Object Proposal Generation in Supermarkets and Beyond"
date: 2017-04-22 06:05:31
categories: arXiv_CV
tags: arXiv_CV Prediction Detection
author: Siyuan Qiao, Wei Shen, Weichao Qiu, Chenxi Liu, Alan Yuille
mathjax: true
---

* content
{:toc}

##### Abstract
Motivated by product detection in supermarkets, this paper studies the problem of object proposal generation in supermarket images and other natural images. We argue that estimation of object scales in images is helpful for generating object proposals, especially for supermarket images where object scales are usually within a small range. Therefore, we propose to estimate object scales of images before generating object proposals. The proposed method for predicting object scales is called ScaleNet. To validate the effectiveness of ScaleNet, we build three supermarket datasets, two of which are real-world datasets used for testing and the other one is a synthetic dataset used for training. In short, we extend the previous state-of-the-art object proposal methods by adding a scale prediction phase. The resulted method outperforms the previous state-of-the-art on the supermarket datasets by a large margin. We also show that the approach works for object proposal on other natural images and it outperforms the previous state-of-the-art object proposal methods on the MS COCO dataset. The supermarket datasets, the virtual supermarkets, and the tools for creating more synthetic datasets will be made public.

##### Abstract (translated by Google)
在超市产品检测的驱动下，本文研究超市图像等自然图像中的对象建议生成问题。我们认为，图像中物体尺度的估计有助于生成物体的建议，特别是对于物体尺度通常在一个小范围内的超市图像。因此，我们建议在生成对象建议之前估计图像的对象尺度。所提出的用于预测对象尺度的方法称为ScaleNet。为了验证ScaleNet的有效性，我们构建了三个超市数据集，其中两个是用于测试的真实数据集，另一个是用于训练的合成数据集。简而言之，我们通过添加一个尺度预测阶段来扩展先前的最先进的对象建议方法。所得到的方法大大超过了超市数据集先前的最新水平。我们还显示该方法适用于其他自然图像上的对象提议，并且胜过了先前在MS COCO数据集上的最先进的对象提议方法。超市数据集，虚拟超市以及用于创建更多合成数据集的工具将被公开。

##### URL
[https://arxiv.org/abs/1704.06752](https://arxiv.org/abs/1704.06752)

##### PDF
[https://arxiv.org/pdf/1704.06752](https://arxiv.org/pdf/1704.06752)

