---
layout: post
title: "Defining Locality for Surrogates in Post-hoc Interpretablity"
date: 2018-06-19 23:18:48
categories: arXiv_AI
tags: arXiv_AI Prediction
author: Thibault Laugel, Xavier Renard, Marie-Jeanne Lesot, Christophe Marsala, Marcin Detyniecki
mathjax: true
---

* content
{:toc}

##### Abstract
Local surrogate models, to approximate the local decision boundary of a black-box classifier, constitute one approach to generate explanations for the rationale behind an individual prediction made by the back-box. This paper highlights the importance of defining the right locality, the neighborhood on which a local surrogate is trained, in order to approximate accurately the local black-box decision boundary. Unfortunately, as shown in this paper, this issue is not only a parameter or sampling distribution challenge and has a major impact on the relevance and quality of the approximation of the local black-box decision boundary and thus on the meaning and accuracy of the generated explanation. To overcome the identified problems, quantified with an adapted measure and procedure, we propose to generate surrogate-based explanations for individual predictions based on a sampling centered on particular place of the decision boundary, relevant for the prediction to be explained, rather than on the prediction itself as it is classically done. We evaluate the novel approach compared to state-of-the-art methods and a straightforward improvement thereof on four UCI datasets.

##### Abstract (translated by Google)
局部代理模型，近似黑盒分类器的局部决策边界，构成了一种方法，用于解释由背框进行的单独预测的基本原理。本文强调了定义合适的局部性（局部代理被训练的邻域）的重要性，以便精确近似局部黑盒决策边界。不幸的是，如本文所示，这个问题不仅是一个参数或抽样分布挑战，而且对局部黑盒决策边界近似的相关性和质量以及所生成的含义和准确性有重大影响说明。为了克服已发现的问题，并采用适应性措施和程序对其进行量化，我们提出基于以决策边界的特定地点为中心的抽样，针对个别预测产生以替代为基础的解释，这与解释预测相关，而不是预测本身，因为它是经典的做法。我们评估新方法与最先进的方法进行比较，并在四个UCI数据集上直接进行改进。

##### URL
[http://arxiv.org/abs/1806.07498](http://arxiv.org/abs/1806.07498)

##### PDF
[http://arxiv.org/pdf/1806.07498](http://arxiv.org/pdf/1806.07498)

