---
layout: post
title: "Articulatory information and Multiview Features for Large Vocabulary Continuous Speech Recognition"
date: 2018-02-16 07:45:53
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition CNN Recognition
author: Vikramjit Mitra, Wen Wang, Chris Bartels, Horacio Franco, Dimitra Vergyri
mathjax: true
---

* content
{:toc}

##### Abstract
This paper explores the use of multi-view features and their discriminative transforms in a convolutional deep neural network (CNN) architecture for a continuous large vocabulary speech recognition task. Mel-filterbank energies and perceptually motivated forced damped oscillator coefficient (DOC) features are used after feature-space maximum-likelihood linear regression (fMLLR) transforms, which are combined and fed as a multi-view feature to a single CNN acoustic model. Use of multi-view feature representation demonstrated significant reduction in word error rates (WERs) compared to the use of individual features by themselves. In addition, when articulatory information was used as an additional input to a fused deep neural network (DNN) and CNN acoustic model, it was found to demonstrate further reduction in WER for the Switchboard subset and the CallHome subset (containing partly non-native accented speech) of the NIST 2000 conversational telephone speech test set, reducing the error rate by 12% relative to the baseline in both cases. This work shows that multi-view features in association with articulatory information can improve speech recognition robustness to spontaneous and non-native speech.

##### Abstract (translated by Google)
本文探讨了在卷积深度神经网络（CNN）体系结构中使用多视图特征及其判别变换对连续大词汇量语音识别任务的使用。在特征空间最大似然线性回归（fMLLR）变换之后，Mel滤波器能量和感知动机强制阻尼振荡器系数（DOC）特征被使用，其被合并并作为多视图特征馈送到单个CNN声学模型。与使用单独的特征本身相比，使用多视图特征表示显示出字错误率（WER）的显着降低。此外，当关节信息被用作融合深层神经网络（DNN）和CNN声学模型的附加输入时，发现其显示进一步降低了用于交换板子集和CallHome子集的WER（包含部分非本地重音演讲）的NIST 2000会话电话语音测试集，在两种情况下，相对于基线的错误率降低12％。这项工作表明，与发音信息相关的多视图特征可以提高语音识别对自发和非本地语音的鲁棒性。

##### URL
[http://arxiv.org/abs/1802.05853](http://arxiv.org/abs/1802.05853)

##### PDF
[http://arxiv.org/pdf/1802.05853](http://arxiv.org/pdf/1802.05853)

