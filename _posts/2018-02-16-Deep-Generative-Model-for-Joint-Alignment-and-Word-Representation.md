---
layout: post
title: "Deep Generative Model for Joint Alignment and Word Representation"
date: 2018-02-16 10:11:39
categories: arXiv_AI
tags: arXiv_AI Inference
author: Miguel Rios, Wilker Aziz, Khalil Sima'an
mathjax: true
---

* content
{:toc}

##### Abstract
This work exploits translation data as a source of semantically relevant learning signal for models of word representation. In particular, we exploit equivalence through translation as a form of distributed context and jointly learn how to embed and align with a deep generative model. Our EmbedAlign model embeds words in their complete observed context and learns by marginalisation of latent lexical alignments. Besides, it embeds words as posterior probability densities, rather than point estimates, which allows us to compare words in context using a measure of overlap between distributions (e.g. KL divergence). We investigate our model's performance on a range of lexical semantics tasks achieving competitive results on several standard benchmarks including natural language inference, paraphrasing, and text similarity.

##### Abstract (translated by Google)
这项工作利用翻译数据作为词表示模型的语义相关学习信号的来源。特别是，我们利用翻译的等价性作为分布式语境的一种形式，并共同学习如何嵌入并与深层生成模型相一致。我们的EmbedAlign模型将单词嵌入到他们完整的观察环境中，并通过潜在词汇排列的边缘化来学习。此外，它嵌入单词作为后验概率密度，而不是点估计，这使我们能够使用分布之间的重叠度量（例如KL分歧）来比较上下文中的单词。我们调查了我们的模型在一系列词汇语义学任务上的表现，这些任务在包括自然语言推理，释义和文本相似性在内的多个标准基准测试中取得了有竞争力的结果。

##### URL
[https://arxiv.org/abs/1802.05883](https://arxiv.org/abs/1802.05883)

##### PDF
[https://arxiv.org/pdf/1802.05883](https://arxiv.org/pdf/1802.05883)

