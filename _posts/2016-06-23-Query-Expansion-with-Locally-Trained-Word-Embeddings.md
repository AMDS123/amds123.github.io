---
layout: post
title: "Query Expansion with Locally-Trained Word Embeddings"
date: 2016-06-23 00:46:06
categories: arXiv_CL
tags: arXiv_CL Attention Embedding Language_Model Relation
author: Fernando Diaz, Bhaskar Mitra, Nick Craswell
mathjax: true
---

* content
{:toc}

##### Abstract
Continuous space word embeddings have received a great deal of attention in the natural language processing and machine learning communities for their ability to model term similarity and other relationships. We study the use of term relatedness in the context of query expansion for ad hoc information retrieval. We demonstrate that word embeddings such as word2vec and GloVe, when trained globally, underperform corpus and query specific embeddings for retrieval tasks. These results suggest that other tasks benefiting from global embeddings may also benefit from local embeddings.

##### Abstract (translated by Google)
连续空间词嵌入在自然语言处理和机器学习领域中受到了模拟词语相似性和其他关系模型能力的极大关注。我们在查询扩展的情况下研究术语相关性的用途，用于特别的信息检索。我们证明word2vec和GloVe等词语嵌入在全球训练时表现不及语料库，并为检索任务查询特定的嵌入。这些结果表明，受益于全球嵌入的其他任务也可能受益于当地的嵌入。

##### URL
[https://arxiv.org/abs/1605.07891](https://arxiv.org/abs/1605.07891)

##### PDF
[https://arxiv.org/pdf/1605.07891](https://arxiv.org/pdf/1605.07891)

