---
layout: post
title: "What matters in a transferable neural network model for relation classification in the biomedical domain?"
date: 2017-08-14 04:53:48
categories: arXiv_CL
tags: arXiv_CL Knowledge Transfer_Learning Classification Relation
author: Sunil Kumar Sahu, Ashish Anand
mathjax: true
---

* content
{:toc}

##### Abstract
Lack of sufficient labeled data often limits the applicability of advanced machine learning algorithms to real life problems. However efficient use of Transfer Learning (TL) has been shown to be very useful across domains. TL utilizes valuable knowledge learned in one task (source task), where sufficient data is available, to the task of interest (target task). In biomedical and clinical domain, it is quite common that lack of sufficient training data do not allow to fully exploit machine learning models. In this work, we present two unified recurrent neural models leading to three transfer learning frameworks for relation classification tasks. We systematically investigate effectiveness of the proposed frameworks in transferring the knowledge under multiple aspects related to source and target tasks, such as, similarity or relatedness between source and target tasks, and size of training data for source task. Our empirical results show that the proposed frameworks in general improve the model performance, however these improvements do depend on aspects related to source and target tasks. This dependence then finally determine the choice of a particular TL framework.

##### Abstract (translated by Google)
缺乏足够的标记数据通常限制了高级机器学习算法对现实生活问题的适用性。然而，转移学习（TL）的有效使用已被证明在各个领域非常有用。 TL利用在一个任务（源任务）中获得的有价值的知识，在有足够数据可用的情况下，向感兴趣的任务（目标任务）学习。在生物医学和临床领域，缺乏足够的训练数据是不能充分利用机器学习模型的。在这项工作中，我们提出了两个统一的递归神经模型，导致关系分类任务的三个转移学习框架。我们系统地研究了提出的框架在源和目标任务相关的多个方面传递知识的有效性，例如源和目标任务之间的相似性或相关性，以及源任务的训练数据的大小。我们的实证结果表明，所提出的框架总体上改善了模型的性能，但是这些改进取决于与源和目标任务相关的方面。这种依赖性最终决定了特定TL框架的选择。

##### URL
[https://arxiv.org/abs/1708.03446](https://arxiv.org/abs/1708.03446)

##### PDF
[https://arxiv.org/pdf/1708.03446](https://arxiv.org/pdf/1708.03446)

