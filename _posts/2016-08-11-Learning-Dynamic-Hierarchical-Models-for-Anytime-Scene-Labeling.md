---
layout: post
title: "Learning Dynamic Hierarchical Models for Anytime Scene Labeling"
date: 2016-08-11 14:19:31
categories: arXiv_CV
tags: arXiv_CV Segmentation Semantic_Segmentation Represenation_Learning Inference Prediction
author: Buyu Liu, Xuming He
mathjax: true
---

* content
{:toc}

##### Abstract
With increasing demand for efficient image and video analysis, test-time cost of scene parsing becomes critical for many large-scale or time-sensitive vision applications. We propose a dynamic hierarchical model for anytime scene labeling that allows us to achieve flexible trade-offs between efficiency and accuracy in pixel-level prediction. In particular, our approach incorporates the cost of feature computation and model inference, and optimizes the model performance for any given test-time budget by learning a sequence of image-adaptive hierarchical models. We formulate this anytime representation learning as a Markov Decision Process with a discrete-continuous state-action space. A high-quality policy of feature and model selection is learned based on an approximate policy iteration method with action proposal mechanism. We demonstrate the advantages of our dynamic non-myopic anytime scene parsing on three semantic segmentation datasets, which achieves $90\%$ of the state-of-the-art performances by using $15\%$ of their overall costs.

##### Abstract (translated by Google)
随着对高效图像和视频分析需求的不断增长，场景分析的测试时间成本对于许多大规模或时间敏感的视觉应用而言变得至关重要。我们提出了一个动态分层模型，用于随时进行场景标注，使我们能够在像素级预测中实现效率和准确性之间的灵活取舍。特别是，我们的方法结合了特征计算和模型推理的成本，并通过学习一系列图像自适应分层模型来优化任何给定测试时间预算的模型性能。我们将这种随时表示学习作为具有离散连续状态动作空间的马尔可夫决策过程来制定。基于具有行动建议机制的近似策略迭代方法学习高质量的特征和模型选择策略。我们展示了我们的动态非近视场景解析三个语义分割数据集的优势，通过使用总成本的15％\ $ $来达到$ 90％的最新性能。

##### URL
[https://arxiv.org/abs/1608.03474](https://arxiv.org/abs/1608.03474)

##### PDF
[https://arxiv.org/pdf/1608.03474](https://arxiv.org/pdf/1608.03474)

