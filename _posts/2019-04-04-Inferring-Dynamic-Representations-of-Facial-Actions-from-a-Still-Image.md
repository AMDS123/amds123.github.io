---
layout: post
title: "Inferring Dynamic Representations of Facial Actions from a Still Image"
date: 2019-04-04 07:15:53
categories: arXiv_CV
tags: arXiv_CV
author: Siyang Song, Enrique S&#xe1;nchez-Lozano, Linlin Shen, Alan Johnston, Michel Valstar
mathjax: true
---

* content
{:toc}

##### Abstract
Facial actions are spatio-temporal signals by nature, and therefore their modeling is crucially dependent on the availability of temporal information. In this paper, we focus on inferring such temporal dynamics of facial actions when no explicit temporal information is available, i.e. from still images. We present a novel approach to capture multiple scales of such temporal dynamics, with an application to facial Action Unit (AU) intensity estimation and dimensional affect estimation. In particular, 1) we propose a framework that infers a dynamic representation (DR) from a still image, which captures the bi-directional flow of time within a short time-window centered at the input image; 2) we show that we can train our method without the need of explicitly generating target representations, allowing the network to represent dynamics more broadly; and 3) we propose to apply a multiple temporal scale approach that infers DRs for different window lengths (MDR) from a still image. We empirically validate the value of our approach on the task of frame ranking, and show how our proposed MDR attains state of the art results on BP4D for AU intensity estimation and on SEMAINE for dimensional affect estimation, using only still images at test time.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.02382](http://arxiv.org/abs/1904.02382)

##### PDF
[http://arxiv.org/pdf/1904.02382](http://arxiv.org/pdf/1904.02382)

