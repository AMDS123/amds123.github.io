---
layout: post
title: "Latent Tree Learning with Differentiable Parsers: Shift-Reduce Parsing and Chart Parsing"
date: 2018-06-03 17:34:41
categories: arXiv_CL
tags: arXiv_CL
author: Jean Maillard, Stephen Clark
mathjax: true
---

* content
{:toc}

##### Abstract
Latent tree learning models represent sentences by composing their words according to an induced parse tree, all based on a downstream task. These models often outperform baselines which use (externally provided) syntax trees to drive the composition order. This work contributes (a) a new latent tree learning model based on shift-reduce parsing, with competitive downstream performance and non-trivial induced trees, and (b) an analysis of the trees learned by our shift-reduce model and by a chart-based model.

##### Abstract (translated by Google)
潜在树学习模型通过根据诱导解析树构造它们的词来表示句子，所有这些都基于下游任务。这些模型通常优于使用（外部提供的）语法树驱动构图顺序的基线。这项工作有助于：（a）基于移位 - 归约解析的新的潜在树学习模型，具有竞争性的下游性能和非平凡诱导树，以及（b）通过我们的移位 - 归约模型和图表基于模型。

##### URL
[http://arxiv.org/abs/1806.00840](http://arxiv.org/abs/1806.00840)

##### PDF
[http://arxiv.org/pdf/1806.00840](http://arxiv.org/pdf/1806.00840)

