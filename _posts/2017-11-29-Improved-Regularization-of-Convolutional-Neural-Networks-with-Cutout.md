---
layout: post
title: "Improved Regularization of Convolutional Neural Networks with Cutout"
date: 2017-11-29 14:51:40
categories: arXiv_CV
tags: arXiv_CV Regularization CNN
author: Terrance DeVries, Graham W. Taylor
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional neural networks are capable of learning powerful representational spaces, which are necessary for tackling complex learning tasks. However, due to the model capacity required to capture such representations, they are often susceptible to overfitting and therefore require proper regularization in order to generalize well. In this paper, we show that the simple regularization technique of randomly masking out square regions of input during training, which we call cutout, can be used to improve the robustness and overall performance of convolutional neural networks. Not only is this method extremely easy to implement, but we also demonstrate that it can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance. We evaluate this method by applying it to current state-of-the-art architectures on the CIFAR-10, CIFAR-100, and SVHN datasets, yielding new state-of-the-art results of 2.56%, 15.20%, and 1.30% test error respectively. Code is available at this https URL

##### Abstract (translated by Google)
卷积神经网络能够学习强大的表示空间，这是解决复杂的学习任务所必需的。然而，由于捕获这种表示所需的模型能力，它们往往易于过度拟合，因此需要适当的正则化才能很好地推广。在本文中，我们展示了在训练中随机掩盖输入的正方形区域的简单正则化技术，我们称之为裁剪，可以用来提高卷积神经网络的鲁棒性和整体性能。这种方法不仅非常容易实现，而且还表明它可以与现有的数据增强和其他规则化器一起使用，以进一步提高模型性能。我们通过将其应用于CIFAR-10，CIFAR-100和SVHN数据集上的当前最先进的体系结构来评估这种方法，得到2.56％，15.20％和1.30的新的最新结果％测试错误分别。代码可在此https网址获得

##### URL
[https://arxiv.org/abs/1708.04552](https://arxiv.org/abs/1708.04552)

##### PDF
[https://arxiv.org/pdf/1708.04552](https://arxiv.org/pdf/1708.04552)

