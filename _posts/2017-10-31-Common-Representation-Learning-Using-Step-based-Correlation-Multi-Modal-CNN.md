---
layout: post
title: "Common Representation Learning Using Step-based Correlation Multi-Modal CNN"
date: 2017-10-31 07:43:34
categories: arXiv_CV
tags: arXiv_CV Transfer_Learning Represenation_Learning Deep_Learning Relation
author: Gaurav Bhatt, Piyush Jha, Balasubramanian Raman
mathjax: true
---

* content
{:toc}

##### Abstract
Deep learning techniques have been successfully used in learning a common representation for multi-view data, wherein the different modalities are projected onto a common subspace. In a broader perspective, the techniques used to investigate common representation learning falls under the categories of canonical correlation-based approaches and autoencoder based approaches. In this paper, we investigate the performance of deep autoencoder based methods on multi-view data. We propose a novel step-based correlation multi-modal CNN (CorrMCNN) which reconstructs one view of the data given the other while increasing the interaction between the representations at each hidden layer or every intermediate step. Finally, we evaluate the performance of the proposed model on two benchmark datasets - MNIST and XRMB. Through extensive experiments, we find that the proposed model achieves better performance than the current state-of-the-art techniques on joint common representation learning and transfer learning tasks.

##### Abstract (translated by Google)
深度学习技术已经成功地用于学习多视图数据的共同表示，其中将不同的模态投影到公共子空间上。从更广泛的角度来看，用于调查通用表示学习的技术属于典型相关方法和基于自动编码器的方法。在本文中，我们研究了基于深度自动编码器的多视图数据的性能。我们提出了一种新颖的基于步长的相关多模式CNN（CorrMCNN），该算法重建给定数据的一个视图，同时增加每个隐藏层或每个中间步骤的表示之间的交互。最后，我们评估在两个基准数据集 -  MNIST和XRMB上提出的模型的性能。通过大量的实验，我们发现所提出的模型在联合公共表示学习和转移学习任务方面比现有的最新技术实现了更好的性能。

##### URL
[https://arxiv.org/abs/1711.00003](https://arxiv.org/abs/1711.00003)

##### PDF
[https://arxiv.org/pdf/1711.00003](https://arxiv.org/pdf/1711.00003)

