---
layout: post
title: "Sparse Overcomplete Word Vector Representations"
date: 2015-06-05 18:20:43
categories: arXiv_CL
tags: arXiv_CL Sparse Relation
author: Manaal Faruqui, Yulia Tsvetkov, Dani Yogatama, Chris Dyer, Noah Smith
mathjax: true
---

* content
{:toc}

##### Abstract
Current distributed representations of words show little resemblance to theories of lexical semantics. The former are dense and uninterpretable, the latter largely based on familiar, discrete classes (e.g., supersenses) and relations (e.g., synonymy and hypernymy). We propose methods that transform word vectors into sparse (and optionally binary) vectors. The resulting representations are more similar to the interpretable features typically used in NLP, though they are discovered automatically from raw corpora. Because the vectors are highly sparse, they are computationally easy to work with. Most importantly, we find that they outperform the original vectors on benchmark tasks.

##### Abstract (translated by Google)
目前词汇的分布式表示与词汇语义学理论很少相似。前者是密集和不可解释的，后者主要基于熟悉的，离散的类别（例如，超验）和关系（例如同义词和超类）。我们提出将单词向量转换为稀疏（和可选二进制）向量的方法。结果表示与NLP中通常使用的可解释特征更为相似，不过它们是从原始语料库自动发现的。因为矢量非常稀疏，所以在计算上很容易处理。最重要的是，我们发现它们在基准测试任务上的表现优于原始测试。

##### URL
[https://arxiv.org/abs/1506.02004](https://arxiv.org/abs/1506.02004)

##### PDF
[https://arxiv.org/pdf/1506.02004](https://arxiv.org/pdf/1506.02004)

