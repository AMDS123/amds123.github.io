---
layout: post
title: "T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos"
date: 2017-08-03 07:03:49
categories: arXiv_CV
tags: arXiv_CV Object_Detection CNN Deep_Learning Detection Recognition
author: Kai Kang, Hongsheng Li, Junjie Yan, Xingyu Zeng, Bin Yang, Tong Xiao, Cong Zhang, Zhe Wang, Ruohui Wang, Xiaogang Wang, Wanli Ouyang
mathjax: true
---

* content
{:toc}

##### Abstract
The state-of-the-art performance for object detection has been significantly improved over the past two years. Besides the introduction of powerful deep neural networks such as GoogleNet and VGG, novel object detection frameworks such as R-CNN and its successors, Fast R-CNN and Faster R-CNN, play an essential role in improving the state-of-the-art. Despite their effectiveness on still images, those frameworks are not specifically designed for object detection from videos. Temporal and contextual information of videos are not fully investigated and utilized. In this work, we propose a deep learning framework that incorporates temporal and contextual information from tubelets obtained in videos, which dramatically improves the baseline performance of existing still-image detection frameworks when they are applied to videos. It is called T-CNN, i.e. tubelets with convolutional neueral networks. The proposed framework won the recently introduced object-detection-from-video (VID) task with provided data in the ImageNet Large-Scale Visual Recognition Challenge 2015 (ILSVRC2015).

##### Abstract (translated by Google)
在过去的两年里，最先进的物体检测性能得到了显着的提高。除了引入强大的深度神经网络如GoogleNet和VGG之外，R-CNN及其后续产品Fast R-CNN和R-CNN更快的新型对象检测框架在改善现有技术的基础上，艺术。尽管它们在静止图像上有效，但这些框架并不是专门为从视频中进行对象检测而设计的。视频的时间和上下文信息没有得到充分的调查和利用。在这项工作中，我们提出了一个深入的学习框架，它融合了从视频中得到的小管的时间和上下文信息，大大提高了现有静止图像检测框架应用于视频时的基线性能。它被称为T-CNN，即具有卷积神经网络的小管。提出的框架赢得了最近引入的视频对象检测（VID）任务，并提供了2015年ImageNet大规模视觉识别挑战（ILSVRC2015）中提供的数据。

##### URL
[https://arxiv.org/abs/1604.02532](https://arxiv.org/abs/1604.02532)

