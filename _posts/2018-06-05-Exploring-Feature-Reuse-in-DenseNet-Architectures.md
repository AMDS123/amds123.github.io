---
layout: post
title: "Exploring Feature Reuse in DenseNet Architectures"
date: 2018-06-05 21:11:23
categories: arXiv_CV
tags: arXiv_CV CNN Image_Classification Classification
author: Andy Hess
mathjax: true
---

* content
{:toc}

##### Abstract
Densely Connected Convolutional Networks (DenseNets) have been shown to achieve state-of-the-art results on image classification tasks while using fewer parameters and computation than competing methods. Since each layer in this architecture has full access to the feature maps of all previous layers, the network is freed from the burden of having to relearn previously useful features, thus alleviating issues with vanishing gradients. In this work we explore the question: To what extent is it necessary to connect to all previous layers in order to reap the benefits of feature reuse? To this end, we introduce the notion of local dense connectivity and present evidence that less connectivity, allowing for increased growth rate at a fixed network capacity, can achieve a more efficient reuse of features and lead to higher accuracy in dense architectures.

##### Abstract (translated by Google)
密集连接的卷积网络（DenseNets）已被证明在图像分类任务上达到了最先进的结果，同时使用比竞争方法更少的参数和计算。由于此体系结构中的每个层都可以完全访问所有先前层的功能图，因此网络不必再重新学习以前有用的功能，从而减轻了消失渐变的问题。在这项工作中，我们探讨了这个问题：为了获得功能重用的好处，在多大程度上需要连接到所有先前的图层？为此，我们引入了局部密集连接的概念，并提出证据表明，连通性较低，允许在固定网络容量下增加增长率，可以实现功能的更有效的重用，并导致密集架构中的更高精度。

##### URL
[http://arxiv.org/abs/1806.01935](http://arxiv.org/abs/1806.01935)

##### PDF
[http://arxiv.org/pdf/1806.01935](http://arxiv.org/pdf/1806.01935)

