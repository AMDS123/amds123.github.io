---
layout: post
title: "Revisiting Skip-Gram Negative Sampling Model with Regularization"
date: 2018-04-01 15:41:01
categories: arXiv_CL
tags: arXiv_CL Regularization
author: Cun Mu, Guang Yang, Zheng Yan
mathjax: true
---

* content
{:toc}

##### Abstract
We revisit skip-gram negative sampling (SGNS), a popular neural-network based approach to learning distributed word representation. We first point out the ambiguity issue undermining the SGNS model, in the sense that the word vectors can be entirely distorted without changing the objective value. To resolve this issue, we rectify the SGNS model with quadratic regularization. A theoretical justification, which provides a novel insight into quadratic regularization, is presented. Preliminary experiments are also conducted on Google's analytical reasoning task to support the modified SGNS model.

##### Abstract (translated by Google)
我们重温跳跃式负面抽样（skip-gram negative sampling，SGNS），这是一种流行的基于神经网络的学习分布式词表示的方法。我们首先指出了模糊性问题对SGNS模型的影响，因为在不改变客观价值的情况下，词向量可以被完全扭曲。为了解决这个问题，我们用二次正则化纠正了SGNS模型。提出了一种理论上的理由，它提供了对二次正则化的新颖见解。还对Google的分析推理任务进行了初步实验，以支持修改后的SGNS模型。

##### URL
[http://arxiv.org/abs/1804.00306](http://arxiv.org/abs/1804.00306)

##### PDF
[http://arxiv.org/pdf/1804.00306](http://arxiv.org/pdf/1804.00306)

