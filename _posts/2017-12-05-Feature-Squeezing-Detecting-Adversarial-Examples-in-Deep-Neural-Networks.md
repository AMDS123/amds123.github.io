---
layout: post
title: "Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks"
date: 2017-12-05 23:45:08
categories: arXiv_CV
tags: arXiv_CV Adversarial Detection
author: Weilin Xu, David Evans, Yanjun Qi
mathjax: true
---

* content
{:toc}

##### Abstract
Although deep neural networks (DNNs) have achieved great success in many tasks, they can often be fooled by \emph{adversarial examples} that are generated by adding small but purposeful distortions to natural examples. Previous studies to defend against adversarial examples mostly focused on refining the DNN models, but have either shown limited success or required expensive computation. We propose a new strategy, \emph{feature squeezing}, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on squeezed inputs, feature squeezing detects adversarial examples with high accuracy and few false positives. This paper explores two feature squeezing methods: reducing the color bit depth of each pixel and spatial smoothing. These simple strategies are inexpensive and complementary to other defenses, and can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks.

##### Abstract (translated by Google)
虽然深度神经网络（DNNs）在许多任务中取得了巨大的成功，但它们通常会被对自然事例增加小而有目的的失真而产生的“敌对的例子”所愚弄。以前的研究捍卫敌对的例子主要集中在提炼DNN模型，但要么有限的成功或需要昂贵的计算。我们提出了一种新的策略，通过检测敌对的例子，可以用来强化DNN模型。特征压缩通过将对应于原始空间中的许多不同特征向量的采样合并成单个采样来减少对手可用的搜索空间。通过比较DNN模型对原始输入的预测与对压缩输入的预测，特征压缩检测具有高准确度和少量误报的敌对示例。本文探讨了两种特征压缩方法：减小每个像素的颜色位深度和空间平滑。这些简单的策略是廉价的，并与其他防御措施相辅相成，并且可以结合在一个联合检测框架中，以实现对最先进攻击的高检测率。

##### URL
[http://arxiv.org/abs/1704.01155](http://arxiv.org/abs/1704.01155)

##### PDF
[http://arxiv.org/pdf/1704.01155](http://arxiv.org/pdf/1704.01155)

