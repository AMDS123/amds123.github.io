---
layout: post
title: "Learning sentence embeddings using Recursive Networks"
date: 2018-05-22 02:09:02
categories: arXiv_CL
tags: arXiv_CL Embedding RNN
author: Anson Bastos
mathjax: true
---

* content
{:toc}

##### Abstract
Learning sentence vectors that generalise well is a challenging task. In this paper we compare three methods of learning phrase embeddings: 1) Using LSTMs, 2) using recursive nets, 3) A variant of the method 2 using the POS information of the phrase. We train our models on dictionary definitions of words to obtain a reverse dictionary application similar to Felix et al. [1]. To see if our embeddings can be transferred to a new task we also train and test on the rotten tomatoes dataset [2]. We train keeping the sentence embeddings fixed as well as with fine tuning.

##### Abstract (translated by Google)
学习普遍化的句子向量是一项具有挑战性的任务。在本文中，我们比较了三种学习短语嵌入的方法：1）使用LSTM，2）使用递归网络，3）使用短语的POS信息的方法2的变体。我们训练我们的字典词典定义的模型，以获得与Felix等人相似的逆向字典应用程序。 [1]。为了查看我们的嵌入是否可以转移到新的任务中，我们还要对烂番茄数据集进行训练和测试[2]。我们训练保持句子嵌入固定以及微调。

##### URL
[https://arxiv.org/abs/1805.08353](https://arxiv.org/abs/1805.08353)

##### PDF
[https://arxiv.org/pdf/1805.08353](https://arxiv.org/pdf/1805.08353)

