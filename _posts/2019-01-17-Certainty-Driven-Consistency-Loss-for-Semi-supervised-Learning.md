---
layout: post
title: "Certainty-Driven Consistency Loss for Semi-supervised Learning"
date: 2019-01-17 07:30:44
categories: arXiv_CV
tags: arXiv_CV Deep_Learning Prediction
author: Yingting Li, Lu Liu, Robby T. Tan
mathjax: true
---

* content
{:toc}

##### Abstract
The recently proposed semi-supervised learning methods exploit consistency loss between different predictions under random perturbations. Typically, a student model is trained to predict consistently with the targets generated by a noisy teacher. However, they ignore the fact that not all training data provide meaningful and reliable information in terms of consistency. For misclassified data, blindly minimizing the consistency loss around them can hinder learning. In this paper, we propose a novel certainty-driven consistency loss (CCL) to dynamically select data samples that have relatively low uncertainty. Specifically, we measure the variance or entropy of multiple predictions under random augmentations and dropout as an estimation of uncertainty. Then, we introduce two approaches, i.e. Filtering CCL and Temperature CCL to guide the student learn more meaningful and certain/reliable targets, and hence improve the quality of the gradients backpropagated to the student. Experiments demonstrate the advantages of the proposed method over the state-of-the-art semi-supervised deep learning methods on three benchmark datasets: SVHN, CIFAR10, and CIFAR100. Our method also shows robustness to noisy labels.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1901.05657](https://arxiv.org/abs/1901.05657)

##### PDF
[https://arxiv.org/pdf/1901.05657](https://arxiv.org/pdf/1901.05657)

