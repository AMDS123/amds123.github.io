---
layout: post
title: "Bidirectional Attention Flow for Machine Comprehension"
date: 2018-06-21 10:53:20
categories: arXiv_CL
tags: arXiv_CL Attention Summarization
author: Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi
mathjax: true
---

* content
{:toc}

##### Abstract
Machine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bi-directional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test.

##### Abstract (translated by Google)
机器理解（MC），回答关于给定上下文段落的查询，需要对上下文和查询之间的复杂交互进行建模。最近，关注机制已经成功扩展到MC。典型地，这些方法使用注意力集中在上下文的一小部分上，并用固定大小的矢量对其进行总结，暂时关注双方的注意力，和/或经常形成单向注意力。在本文中，我们介绍双向注意流（BIDAF）网络，这是一个多阶段分层过程，它表示不同粒度级别的上下文，并使用双向注意流动机制来获得无需早期汇总的查询感知上下文表示。我们的实验评估表明，我们的模型在斯坦福问答数据集（SQUAD）和CNN / DailyMail完成测试中达到了最新的结果。

##### URL
[http://arxiv.org/abs/1611.01603](http://arxiv.org/abs/1611.01603)

##### PDF
[http://arxiv.org/pdf/1611.01603](http://arxiv.org/pdf/1611.01603)

