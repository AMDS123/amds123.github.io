---
layout: post
title: "Neural Semantic Parsing over Multiple Knowledge-bases"
date: 2017-04-24 08:34:47
categories: arXiv_SD
tags: arXiv_SD Knowledge
author: Jonathan Herzig, Jonathan Berant
mathjax: true
---

* content
{:toc}

##### Abstract
A fundamental challenge in developing semantic parsers is the paucity of strong supervision in the form of language utterances annotated with logical form. In this paper, we propose to exploit structural regularities in language in different domains, and train semantic parsers over multiple knowledge-bases (KBs), while sharing information across datasets. We find that we can substantially improve parsing accuracy by training a single sequence-to-sequence model over multiple KBs, when providing an encoding of the domain at decoding time. Our model achieves state-of-the-art performance on the Overnight dataset (containing eight domains), improves performance over a single KB baseline from 75.6% to 79.6%, while obtaining a 7x reduction in the number of model parameters.

##### Abstract (translated by Google)
发展语义解析器的一个根本挑战是缺乏以逻辑形式注释的语言形式的强有力的监督。在本文中，我们建议利用不同领域的语言结构规律，并在多个知识库（KB）上训练语义分析器，同时跨数据集共享信息。通过在解码时提供域的编码，我们可以通过在多个KB上训练单个序列到序列模型来显着提高分析准确性。我们的模型在Overnight数据集（包含八个域）上实现了最先进的性能，将单个KB基线的性能从75.6％提高到了79.6％，同时使模型参数数量减少了7倍。

##### URL
[https://arxiv.org/abs/1702.01569](https://arxiv.org/abs/1702.01569)

##### PDF
[https://arxiv.org/pdf/1702.01569](https://arxiv.org/pdf/1702.01569)

