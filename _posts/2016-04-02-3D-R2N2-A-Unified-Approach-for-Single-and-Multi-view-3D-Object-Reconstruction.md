---
layout: post
title: "3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction"
date: 2016-04-02 01:28:27
categories: arXiv_CV
tags: arXiv_CV SLAM
author: Christopher B. Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, Silvio Savarese
mathjax: true
---

* content
{:toc}

##### Abstract
Inspired by the recent success of methods that employ shape priors to achieve robust 3D reconstructions, we propose a novel recurrent neural network architecture that we call the 3D Recurrent Reconstruction Neural Network (3D-R2N2). The network learns a mapping from images of objects to their underlying 3D shapes from a large collection of synthetic data. Our network takes in one or more images of an object instance from arbitrary viewpoints and outputs a reconstruction of the object in the form of a 3D occupancy grid. Unlike most of the previous works, our network does not require any image annotations or object class labels for training or testing. Our extensive experimental analysis shows that our reconstruction framework i) outperforms the state-of-the-art methods for single view reconstruction, and ii) enables the 3D reconstruction of objects in situations when traditional SFM/SLAM methods fail (because of lack of texture and/or wide baseline).

##### Abstract (translated by Google)
受最近成功采用形状先验实现强大三维重建的方法的启发，我们提出了一种新颖的递归神经网络架构，我们称之为三维递归重建神经网络（3D-R2N2）。网络从大量的合成数据中学习从对象图像到其基本3D形状的映射。我们的网络从任意视点获取一个或多个对象实例的图像，并以3D占用网格的形式输出对象的重建。与大多数以前的作品不同，我们的网络不需要任何图像注释或对象类标签进行培训或测试。我们广泛的实验分析表明，我们的重建框架i）优于单视图重建的最先进的方法，并且ii）当传统的SFM / SLAM方法失败时（由于缺乏纹理和/或宽基线）。

##### URL
[https://arxiv.org/abs/1604.00449](https://arxiv.org/abs/1604.00449)

##### PDF
[https://arxiv.org/pdf/1604.00449](https://arxiv.org/pdf/1604.00449)

