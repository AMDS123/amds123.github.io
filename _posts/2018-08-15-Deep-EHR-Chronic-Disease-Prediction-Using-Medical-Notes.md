---
layout: post
title: "Deep EHR: Chronic Disease Prediction Using Medical Notes"
date: 2018-08-15 00:10:55
categories: arXiv_CL
tags: arXiv_CL RNN Deep_Learning Prediction Detection
author: Jingshu Liu, Zachariah Zhang, Narges Razavian
mathjax: true
---

* content
{:toc}

##### Abstract
Early detection of preventable diseases is important for better disease management, improved inter-ventions, and more efficient health-care resource allocation. Various machine learning approacheshave been developed to utilize information in Electronic Health Record (EHR) for this task. Majorityof previous attempts, however, focus on structured fields and lose the vast amount of information inthe unstructured notes. In this work we propose a general multi-task framework for disease onsetprediction that combines both free-text medical notes and structured information. We compareperformance of different deep learning architectures including CNN, LSTM and hierarchical models.In contrast to traditional text-based prediction models, our approach does not require disease specificfeature engineering, and can handle negations and numerical values that exist in the text. Ourresults on a cohort of about 1 million patients show that models using text outperform modelsusing just structured data, and that models capable of using numerical values and negations in thetext, in addition to the raw text, further improve performance. Additionally, we compare differentvisualization methods for medical professionals to interpret model predictions.

##### Abstract (translated by Google)
早期发现可预防疾病对于更好的疾病管理，改善干预措施和更有效的卫生保健资源分配非常重要。已经开发了各种机器学习方法来利用电子健康记录（EHR）中的信息来完成该任务。然而，之前的大多数尝试都集中在结构化领域，并且在非结构化笔记中丢失了大量信息。在这项工作中，我们提出了一个疾病起始预测的一般多任务框架，它结合了自由文本医学笔记和结构化信息。我们比较了不同深度学习架构的性能，包括CNN，LSTM和层次模型。与传统的基于文本的预测模型相比，我们的方法不需要疾病特定的工程，并且可以处理文本中存在的否定和数值。我们对大约100万患者的研究结果显示，使用文本的模型仅使用结构化数据优于模型，并且除了原始文本之外，能够在文本中使用数值和否定的模型进一步提高了性能。此外，我们比较医学专业人员的不同可视化方法来解释模型预测。

##### URL
[http://arxiv.org/abs/1808.04928](http://arxiv.org/abs/1808.04928)

##### PDF
[http://arxiv.org/pdf/1808.04928](http://arxiv.org/pdf/1808.04928)

