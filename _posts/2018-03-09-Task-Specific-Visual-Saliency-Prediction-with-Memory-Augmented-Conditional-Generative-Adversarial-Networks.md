---
layout: post
title: "Task Specific Visual Saliency Prediction with Memory Augmented Conditional Generative Adversarial Networks"
date: 2018-03-09 02:08:09
categories: arXiv_CV
tags: arXiv_CV Salient Adversarial GAN Deep_Learning Prediction Relation
author: Tharindu Fernando, Simon Denman, Sridha Sridharan, Clinton Fookes
mathjax: true
---

* content
{:toc}

##### Abstract
Visual saliency patterns are the result of a variety of factors aside from the image being parsed, however existing approaches have ignored these. To address this limitation, we propose a novel saliency estimation model which leverages the semantic modelling power of conditional generative adversarial networks together with memory architectures which capture the subject's behavioural patterns and task dependent factors. We make contributions aiming to bridge the gap between bottom-up feature learning capabilities in modern deep learning architectures and traditional top-down hand-crafted features based methods for task specific saliency modelling. The conditional nature of the proposed framework enables us to learn contextual semantics and relationships among different tasks together, instead of learning them separately for each task. Our studies not only shed light on a novel application area for generative adversarial networks, but also emphasise the importance of task specific saliency modelling and demonstrate the plausibility of fully capturing this context via an augmented memory architecture.

##### Abstract (translated by Google)
视觉显着性模式是除了解析图像之外的各种因素的结果，然而现有的方法忽略了这些因素。为了解决这个限制，我们提出了一种新的显着性估计模型，其利用条件生成对抗网络的语义建模能力以及捕捉对象的行为模式和任务相关因子的存储器体系结构。我们做出了贡献，旨在缩小现代深度学习架构中自下而上的特性学习功能与传统的自上而下的手工制作的基于特征的特征显着建模方法之间的差距。所提出的框架的条件性质使我们能够在不同任务之间学习语境语义和关系，而不是分别为每个任务学习它们。我们的研究不仅揭示了生成敌对网络的一个新颖应用领域，而且强调了任务特定显着性建模的重要性，并展示了通过增强内存体系结构充分捕捉这种背景的合理性。

##### URL
[http://arxiv.org/abs/1803.03354](http://arxiv.org/abs/1803.03354)

##### PDF
[http://arxiv.org/pdf/1803.03354](http://arxiv.org/pdf/1803.03354)

