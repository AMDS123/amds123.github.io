---
layout: post
title: "Anchoring and Agreement in Syntactic Annotations"
date: 2016-09-21 22:34:47
categories: arXiv_CL
tags: arXiv_CL
author: Yevgeni Berzak, Yan Huang, Andrei Barbu, Anna Korhonen, Boris Katz
mathjax: true
---

* content
{:toc}

##### Abstract
We present a study on two key characteristics of human syntactic annotations: anchoring and agreement. Anchoring is a well known cognitive bias in human decision making, where judgments are drawn towards pre-existing values. We study the influence of anchoring on a standard approach to creation of syntactic resources where syntactic annotations are obtained via human editing of tagger and parser output. Our experiments demonstrate a clear anchoring effect and reveal unwanted consequences, including overestimation of parsing performance and lower quality of annotations in comparison with human-based annotations. Using sentences from the Penn Treebank WSJ, we also report systematically obtained inter-annotator agreement estimates for English dependency parsing. Our agreement results control for parser bias, and are consequential in that they are on par with state of the art parsing performance for English newswire. We discuss the impact of our findings on strategies for future annotation efforts and parser evaluations.

##### Abstract (translated by Google)
我们对人类句法注释的两个关键特征进行了研究：锚定和协议。锚定是人类决策中众所周知的认知偏见，其中对现有的价值进行判断。我们研究了锚定对标准方法创建语法资源的影响，通过人工编辑标记器和分析器输出获得语法标注。我们的实验显示了明确的锚定效果并且揭示了不希望的后果，包括高估了解析性能和与基于人的注释相比较低的注释质量。使用宾夕法尼亚州立大学华尔街日报的句子，我们也报告系统地获得了用于英语依赖分析的内部注释器协议估计。我们的协议结果控制了解析器的偏见，其结果是它们与英语newswire的最先进的解析性能相当。我们讨论我们的研究结果对未来注释工作和解析器评估策略的影响。

##### URL
[https://arxiv.org/abs/1605.04481](https://arxiv.org/abs/1605.04481)

##### PDF
[https://arxiv.org/pdf/1605.04481](https://arxiv.org/pdf/1605.04481)

