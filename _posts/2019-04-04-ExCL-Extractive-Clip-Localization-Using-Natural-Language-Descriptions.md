---
layout: post
title: "ExCL: Extractive Clip Localization Using Natural Language Descriptions"
date: 2019-04-04 19:17:04
categories: arXiv_CL
tags: arXiv_CL GAN
author: Soham Ghosh, Anuva Agarwal, Zarana Parekh, Alexander Hauptmann
mathjax: true
---

* content
{:toc}

##### Abstract
The task of retrieving clips within videos based on a given natural language query requires cross-modal reasoning over multiple frames. Prior approaches such as sliding window classifiers are inefficient, while text-clip similarity driven ranking-based approaches such as segment proposal networks are far more complicated. In order to select the most relevant video clip corresponding to the given text description, we propose a novel extractive approach that predicts the start and end frames by leveraging cross-modal interactions between the text and video - this removes the need to retrieve and re-rank multiple proposal segments. Using recurrent networks we encode the two modalities into a joint representation which is then used in different variants of start-end frame predictor networks. Through extensive experimentation and ablative analysis, we demonstrate that our simple and elegant approach significantly outperforms state of the art on two datasets and has comparable performance on a third.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1904.02755](https://arxiv.org/abs/1904.02755)

##### PDF
[https://arxiv.org/pdf/1904.02755](https://arxiv.org/pdf/1904.02755)

