---
layout: post
title: "OptLayer - Practical Constrained Optimization for Deep Reinforcement Learning in the Real World"
date: 2018-02-23 08:39:26
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization Prediction
author: Tu-Hoa Pham, Giovanni De Magistris, Ryuki Tachibana
mathjax: true
---

* content
{:toc}

##### Abstract
While deep reinforcement learning techniques have recently produced considerable achievements on many decision-making problems, their use in robotics has largely been limited to simulated worlds or restricted motions, since unconstrained trial-and-error interactions in the real world can have undesirable consequences for the robot or its environment. To overcome such limitations, we propose a novel reinforcement learning architecture, OptLayer, that takes as inputs possibly unsafe actions predicted by a neural network and outputs the closest actions that satisfy chosen constraints. While learning control policies often requires carefully crafted rewards and penalties while exploring the range of possible actions, OptLayer ensures that only safe actions are actually executed and unsafe predictions are penalized during training. We demonstrate the effectiveness of our approach on robot reaching tasks, both simulated and in the real world.

##### Abstract (translated by Google)
尽管深度强化学习技术最近在许多决策问题上产生了相当大的成就，但它们在机器人领域的应用在很大程度上局限于模拟世界或受限制的运动，因为现实世界中不受限制的试错相互作用可能会对机器人或其环境。为了克服这些限制，我们提出了一种新型的强化学习架构OptLayer，它将输入可能不安全的动作作为神经网络预测的输出，并输出满足所选约束条件的最接近的动作。尽管学习控制策略通常需要精心制定奖励和惩罚措施，同时探索可能的行动范围，但OptLayer确保只有安全行为才能真正执行，并且不安全预测在培训期间受到惩罚。我们展示了我们的方法在模拟和现实世界中的机器人到达任务的有效性。

##### URL
[http://arxiv.org/abs/1709.07643](http://arxiv.org/abs/1709.07643)

##### PDF
[http://arxiv.org/pdf/1709.07643](http://arxiv.org/pdf/1709.07643)

