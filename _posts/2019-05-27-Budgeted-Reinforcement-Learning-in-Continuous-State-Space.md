---
layout: post
title: "Budgeted Reinforcement Learning in Continuous State Space"
date: 2019-05-27 21:50:33
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Nicolas Carrara, Edouard Leurent, Romain Laroche, Tanguy Urvoy, Odalric-Ambrym Maillard, Olivier Pietquin
mathjax: true
---

* content
{:toc}

##### Abstract
A Budgeted Markov Decision Process (BMDP) is an extension of a Markov Decision Process to critical applications requiring safety constraints. It relies on a notion of risk implemented in the shape of a cost signal constrained to lie below an - adjustable - threshold. So far, BMDPs could only be solved in the case of finite state spaces with known dynamics. This work extends the state-of-the-art to continuous spaces environments and unknown dynamics. We show that the solution to a BMDP is a fixed point of a novel Budgeted Bellman Optimality operator. This observation allows us to introduce natural extensions of Deep Reinforcement Learning algorithms to address large-scale BMDPs. We validate our approach on two simulated applications: spoken dialogue and autonomous driving.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.01004](http://arxiv.org/abs/1903.01004)

##### PDF
[http://arxiv.org/pdf/1903.01004](http://arxiv.org/pdf/1903.01004)

