---
layout: post
title: "Translating Videos to Commands for Robotic Manipulation with Deep Recurrent Neural Networks"
date: 2017-10-01 04:19:52
categories: arXiv_CV
tags: arXiv_CV CNN RNN
author: Anh Nguyen, Dimitrios Kanoulas, Luca Muratore, Darwin G. Caldwell, Nikos G. Tsagarakis
mathjax: true
---

* content
{:toc}

##### Abstract
We present a new method to translate videos to commands for robotic manipulation using Deep Recurrent Neural Networks (RNN). Our framework first extracts deep features from the input video frames with a deep Convolutional Neural Networks (CNN). Two RNN layers with an encoder-decoder architecture are then used to encode the visual features and sequentially generate the output words as the command. We demonstrate that the translation accuracy can be improved by allowing a smooth transaction between two RNN layers and using the state-of-the-art feature extractor. The experimental results on our new challenging dataset show that our approach outperforms recent methods by a fair margin. Furthermore, we combine the proposed translation module with the vision and planning system to let a robot perform various manipulation tasks. Finally, we demonstrate the effectiveness of our framework on a full-size humanoid robot WALK-MAN.

##### Abstract (translated by Google)
我们提出了一种将视频转换为使用深度递归神经网络（RNN）进行机器人操纵的命令的新方法。我们的框架首先使用深度卷积神经网络（CNN）从输入视频帧中提取深层特征。然后使用具有编码器 - 解码器架构的两个RNN层对视觉特征进行编码，并顺序地生成作为命令的输出字。我们证明，通过允许两个RNN层之间的平滑交易和使用最先进的特征提取器，可以提高翻译准确性。我们新的具有挑战性的数据集的实验结果表明，我们的方法胜过了最近的方法。此外，我们将提出的翻译模块与视觉和计划系统相结合，让机器人执行各种操作任务。最后，我们展示了我们的框架在全尺寸人形机器人WALK-MAN上的有效性。

##### URL
[https://arxiv.org/abs/1710.00290](https://arxiv.org/abs/1710.00290)

##### PDF
[https://arxiv.org/pdf/1710.00290](https://arxiv.org/pdf/1710.00290)

