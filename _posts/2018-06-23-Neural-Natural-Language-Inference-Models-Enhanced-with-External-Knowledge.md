---
layout: post
title: "Neural Natural Language Inference Models Enhanced with External Knowledge"
date: 2018-06-23 11:32:06
categories: arXiv_CL
tags: arXiv_CL Knowledge Inference
author: Qian Chen, Xiaodan Zhu, Zhen-Hua Ling, Diana Inkpen, Si Wei
mathjax: true
---

* content
{:toc}

##### Abstract
Modeling natural language inference is a very challenging task. With the availability of large annotated data, it has recently become feasible to train complex models such as neural-network-based inference models, which have shown to achieve the state-of-the-art performance. Although there exist relatively large annotated data, can machines learn all knowledge needed to perform natural language inference (NLI) from these data? If not, how can neural-network-based NLI models benefit from external knowledge and how to build NLI models to leverage it? In this paper, we enrich the state-of-the-art neural natural language inference models with external knowledge. We demonstrate that the proposed models improve neural NLI models to achieve the state-of-the-art performance on the SNLI and MultiNLI datasets.

##### Abstract (translated by Google)
建模自然语言推理是一项非常具有挑战性的任务。随着大量注释数据的可用性，培训复杂模型（如基于神经网络的推理模型）已经成为可行，这些模型已经证明可以实现最先进的性能。尽管存在相对较大的注释数据，机器能够从这些数据中学习执行自然语言推理（NLI）所需的所有知识吗？如果不是，那么基于神经网络的NLI模型如何从外部知识中受益，以及如何构建NLI模型来利用它？在本文中，我们利用外部知识丰富了最先进的神经自然语言推理模型。我们证明了所提出的模型改进了神经NLI模型以实现SNLI和MultiNLI数据集上的最新性能。

##### URL
[http://arxiv.org/abs/1711.04289](http://arxiv.org/abs/1711.04289)

##### PDF
[http://arxiv.org/pdf/1711.04289](http://arxiv.org/pdf/1711.04289)

