---
layout: post
title: "XOGAN: One-to-Many Unsupervised Image-to-Image Translation"
date: 2018-05-18 15:19:22
categories: arXiv_CV
tags: arXiv_CV GAN Relation
author: Yongqi Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Unsupervised image-to-image translation aims at learning the relationship between samples from two image domains without supervised pair information. The relationship between two domain images can be one-to-one, one-to-many or many-to-many. In this paper, we study the one-to-many unsupervised image translation problem in which an input sample from one domain can correspond to multiple samples in the other domain. To learn the complex relationship between the two domains, we introduce an additional variable to control the variations in our one-to-many mapping. A generative model with an XO-structure, called the XOGAN, is proposed to learn the cross domain relationship among the two domains and the ad- ditional variables. Not only can we learn to translate between the two image domains, we can also handle the translated images with additional variations. Experiments are performed on unpaired image generation tasks, including edges-to-objects translation and facial image translation. We show that the proposed XOGAN model can generate plausible images and control variations, such as color and texture, of the generated images. Moreover, while state-of-the-art unpaired image generation algorithms tend to generate images with monotonous colors, XOGAN can generate more diverse results.

##### Abstract (translated by Google)
无监督的图像到图像转换旨在学习来自两个图像域的样本之间的关系，而不需要监督对信息。两个域映像之间的关系可以是一对一，一对多或多对多。在本文中，我们研究一对多无监督图像转换问题，其中一个域的输入样本可以对应另一个域中的多个样本。为了了解两个域之间的复杂关系，我们引入了一个额外的变量来控制我们的一对多映射的变化。提出了一个带有XO结构的生成模型，称为XOGAN，用于学习两个域之间的跨域关系和附加变量。我们不仅可以学习在两个图像域之间进行翻译，还可以处理带有其他变体的翻译图像。实验在未配对的图像生成任务上执行，包括边到物平移和面部图像平移。我们表明，提出的XOGAN模型可以生成合理的图像并控制生成图像的颜色和纹理等变化。此外，尽管最先进的非配对图像生成算法倾向于生成单调颜色的图像，但是XOGAN可以生成更多不同的结果。

##### URL
[http://arxiv.org/abs/1805.07277](http://arxiv.org/abs/1805.07277)

##### PDF
[http://arxiv.org/pdf/1805.07277](http://arxiv.org/pdf/1805.07277)

