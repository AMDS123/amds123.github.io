---
layout: post
title: "Learning a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks"
date: 2017-05-18 02:50:40
categories: arXiv_CL
tags: arXiv_CL Segmentation RNN Deep_Learning
author: Matthias Plappert, Christian Mandery, Tamim Asfour
mathjax: true
---

* content
{:toc}

##### Abstract
Linking human whole-body motion and natural language is of great interest for the generation of semantic representations of observed human behaviors as well as for the generation of robot behaviors based on natural language input. While there has been a large body of research in this area, most approaches that exist today require a symbolic representation of motions (e.g. in the form of motion primitives), which have to be defined a-priori or require complex segmentation algorithms. In contrast, recent advances in the field of neural networks and especially deep learning have demonstrated that sub-symbolic representations that can be learned end-to-end usually outperform more traditional approaches, for applications such as machine translation. In this paper we propose a generative model that learns a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks (RNNs) and sequence-to-sequence learning. Our approach does not require any segmentation or manual feature engineering and learns a distributed representation, which is shared for all motions and descriptions. We evaluate our approach on 2,846 human whole-body motions and 6,187 natural language descriptions thereof from the KIT Motion-Language Dataset. Our results clearly demonstrate the effectiveness of the proposed model: We show that our model generates a wide variety of realistic motions only from descriptions thereof in form of a single sentence. Conversely, our model is also capable of generating correct and detailed natural language descriptions from human motions.

##### Abstract (translated by Google)
将人体全身运动与自然语言联系起来，对观察到的人类行为的语义表征以及基于自然语言输入的机器人行为的产生具有极大的兴趣。虽然在这个领域已经有大量的研究，但是目前存在的大多数方法都需要运动的符号表示（例如以运动基元的形式），其必须先验定义或需要复杂的分割算法。相比之下，神经网络领域，尤其是深度学习方面的最新进展已经证明，对于诸如机器翻译的应用，可以端对端学习的子符号表示通常优于更传统的方法。在本文中，我们提出了一个生成模型，使用深回归神经网络（RNN）和序列到序列学习来学习人体全身运动和自然语言之间的双向映射。我们的方法不需要任何分割或手动特征工程，并学习分布式表示，这是分享所有议案和描述。我们从KIT运动语言数据集中评估了我们对2,846个人体全身运动和6,187个自然语言描述的方法。我们的研究结果清楚地证明了所提出的模型的有效性：我们证明，我们的模型只能从一个句子的形式描述它，从而产生各种逼真的动作。相反，我们的模型也能够从人类运动中产生正确和详细的自然语言描述。

##### URL
[https://arxiv.org/abs/1705.06400](https://arxiv.org/abs/1705.06400)

##### PDF
[https://arxiv.org/pdf/1705.06400](https://arxiv.org/pdf/1705.06400)

