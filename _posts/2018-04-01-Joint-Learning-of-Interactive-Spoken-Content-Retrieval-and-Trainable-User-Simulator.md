---
layout: post
title: "Joint Learning of Interactive Spoken Content Retrieval and Trainable User Simulator"
date: 2018-04-01 16:46:53
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition Recognition
author: Pei-Hung Chung, Kuan Tung, Ching-Lun Tai, Hung-Yi Lee
mathjax: true
---

* content
{:toc}

##### Abstract
User-machine interaction is crucial for information retrieval, especially for spoken content retrieval, because spoken content is difficult to browse, and speech recognition has a high degree of uncertainty. In interactive retrieval, the machine takes different actions to interact with the user to obtain better retrieval results; here it is critical to select the most efficient action. In previous work, deep Q-learning techniques were proposed to train an interactive retrieval system but rely on a hand-crafted user simulator; building a reliable user simulator is difficult. In this paper, we further improve the interactive spoken content retrieval framework by proposing a learnable user simulator which is jointly trained with interactive retrieval system, making the hand-crafted user simulator unnecessary. The experimental results show that the learned simulated users not only achieve larger rewards than the hand-crafted ones but act more like real users.

##### Abstract (translated by Google)
用户与机器的交互对于信息检索是至关重要的，特别是对于口头内容检索，因为口头内容难以浏览，并且语音识别具有高度的不确定性。在交互式检索中，机器采取不同的动作与用户交互以获得更好的检索结果;这里选择最有效的操作至关重要。在之前的工作中，提出了深度Q学习技术来训练交互式检索系统，但依靠手工制作的用户模拟器;建立一个可靠的用户模拟器很困难。在本文中，我们进一步改进了交互式口语内容检索框架，提出了一个可学习的用户模拟器，它与交互式检索系统联合训练，使手工制作的用户模拟器变得不必要。实验结果表明，学习模拟用户不仅获得比手工制作的更多的回报，而且更像真实的用户。

##### URL
[http://arxiv.org/abs/1804.00318](http://arxiv.org/abs/1804.00318)

##### PDF
[http://arxiv.org/pdf/1804.00318](http://arxiv.org/pdf/1804.00318)

