---
layout: post
title: "Improving Coordination in Multi-Agent Deep Reinforcement Learning through Memory-driven Communication"
date: 2019-01-12 18:12:15
categories: arXiv_AI
tags: arXiv_AI Face Reinforcement_Learning
author: Emanuele Pesce, Giovanni Montana
mathjax: true
---

* content
{:toc}

##### Abstract
Deep reinforcement learning algorithms have recently been used to train multiple interacting agents in a centralised manner whilst keeping their execution decentralised. When the agents can only acquire partial observations and are faced with a task requiring coordination and synchronisation skills, inter-agent communication plays an essential role. In this work, we propose a framework for multi-agent training using deep deterministic policy gradients that enables the concurrent, end-to-end learning of an explicit communication protocol through a memory device. During training, the agents learn to perform read and write operations enabling them to infer a shared representation of the world. We empirically demonstrate that concurrent learning of the communication device and individual policies can improve inter-agent coordination and performance, and illustrate how different communication patterns can emerge for different tasks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1901.03887](http://arxiv.org/abs/1901.03887)

##### PDF
[http://arxiv.org/pdf/1901.03887](http://arxiv.org/pdf/1901.03887)

