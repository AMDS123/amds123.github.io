---
layout: post
title: 'SYSTRAN's Pure Neural Machine Translation Systems'
date: 2016-10-18 11:32:42
categories: arXiv_CL
tags: arXiv_CL NMT
author: Josep Crego, Jungi Kim, Guillaume Klein, Anabel Rebollo, Kathy Yang, Jean Senellart, Egor Akhanov, Patrice Brunelle, Aurelien Coquard, Yongchao Deng, Satoshi Enoue, Chiyo Geiss, Joshua Johanson, Ardas Khalsa, Raoum Khiari, Byeongil Ko, Catherine Kobus, Jean Lorieux, Leidiana Martins, Dang-Chuan Nguyen, Alexandra Priori, Thomas Riccardi, Natalia Segal, Christophe Servan, Cyril Tiquet, Bo Wang, Jin Yang, Dakun Zhang, Jing Zhou, Peter Zoldan
---

* content
{:toc}

##### Abstract
Since the first online demonstration of Neural Machine Translation (NMT) by LISA, NMT development has recently moved from laboratory to production systems as demonstrated by several entities announcing roll-out of NMT engines to replace their existing technologies. NMT systems have a large number of training configurations and the training process of such systems is usually very long, often a few weeks, so role of experimentation is critical and important to share. In this work, we present our approach to production-ready systems simultaneously with release of online demonstrators covering a large variety of languages (12 languages, for 32 language pairs). We explore different practical choices: an efficient and evolutive open-source framework; data preparation; network architecture; additional implemented features; tuning for production; etc. We discuss about evaluation methodology, present our first findings and we finally outline further work. Our ultimate goal is to share our expertise to build competitive production systems for "generic" translation. We aim at contributing to set up a collaborative framework to speed-up adoption of the technology, foster further research efforts and enable the delivery and adoption to/by industry of use-case specific engines integrated in real production workflows. Mastering of the technology would allow us to build translation engines suited for particular needs, outperforming current simplest/uniform systems.

##### Abstract (translated by Google)
自从LISA首次在线演示神经机器翻译（NMT）以来，NMT开发最近已经从实验室转向生产系统，一些实体宣布推出NMT引擎以取代现有技术。 NMT系统有大量的培训配置，这些系统的培训过程通常很长，通常是几个星期，所以实验的作用是至关重要的。在这项工作中，我们展示了我们的生产就绪系统的方法，同时发布涵盖各种语言（12种语言，32种语言对）的在线演示。我们探索不同的实际选择：一个高效的，演变的开源框架;数据准备;网络架构;额外实施的功能;调整生产;我们讨论了评估方法，介绍了我们的第一个发现，并最终概述了进一步的工作。我们的最终目标是分享我们的专业知识，为“通用”翻译打造有竞争力的生产体系​​。我们的目标是建立一个合作框架，加快技术的采用，推动进一步的研究工作，并使得行业内的用例专用引擎能够在实际生产流程中得到整合。掌握这项技术将使我们能够构建适合特定需求的翻译引擎，超越当前最简单/统一的系统。

##### URL
[https://arxiv.org/abs/1610.05540](https://arxiv.org/abs/1610.05540)

