---
layout: post
title: "An Attention Mechanism for Answer Selection Using a Combined Global and Local View"
date: 2017-09-20 13:18:58
categories: arXiv_CL
tags: arXiv_CL QA Attention Embedding RNN
author: Yoram Bachrach, Andrej Zukov-Gregoric, Sam Coope, Ed Tovell, Bogdan Maksak, Jose Rodriguez, Conan McMurtie
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a new attention mechanism for neural based question answering, which depends on varying granularities of the input. Previous work focused on augmenting recurrent neural networks with simple attention mechanisms which are a function of the similarity between a question embedding and an answer embeddings across time. We extend this by making the attention mechanism dependent on a global embedding of the answer attained using a separate network. We evaluate our system on InsuranceQA, a large question answering dataset. Our model outperforms current state-of-the-art results on InsuranceQA. Further, we visualize which sections of text our attention mechanism focuses on, and explore its performance across different parameter settings.

##### Abstract (translated by Google)
我们提出了一种基于神经的问题回答的新的注意机制，它依赖于输入的不同粒度。以前的工作主要集中在用简单的注意机制来增强递归神经网络，这是随着时间的推移而嵌入问题和回答嵌入之间的相似性的函数。我们通过使注意机制依赖于使用单独网络获得的答案的全球嵌入来扩展这一点。我们在InsuranceQA上评估我们的系统，这是一个大型的问题回答数据集。我们的模型比InsuranceQA当前的最新成果更胜一筹。此外，我们可以看到我们关注机制关注哪些文本部分，并探索其在不同参数设置下的表现。

##### URL
[https://arxiv.org/abs/1707.01378](https://arxiv.org/abs/1707.01378)

##### PDF
[https://arxiv.org/pdf/1707.01378](https://arxiv.org/pdf/1707.01378)

