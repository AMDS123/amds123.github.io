---
layout: post
title: "Vulnerability of Deep Learning"
date: 2018-03-16 08:52:04
categories: arXiv_AI
tags: arXiv_AI Adversarial Classification Deep_Learning
author: Richard Kenway
mathjax: true
---

* content
{:toc}

##### Abstract
The Renormalisation Group (RG) provides a framework in which it is possible to assess whether a deep-learning network is sensitive to small changes in the input data and hence prone to error, or susceptible to adversarial attack. Distinct classification outputs are associated with different RG fixed points and sensitivity to small changes in the input data is due to the presence of relevant operators at a fixed point. A numerical scheme, based on Monte Carlo RG ideas, is proposed for identifying the existence of relevant operators and the corresponding directions of greatest sensitivity in the input data. Thus, a trained deep-learning network may be tested for its robustness and, if it is vulnerable to attack, dangerous perturbations of the input data identified.

##### Abstract (translated by Google)
重整化组织（RG）提供了一个框架，可以评估深度学习网络是否对输入数据的微小变化敏感，因此容易出错或容易受到敌对攻击。不同的分类输出与不同的RG固定点相关联，并且对输入数据中的小变化的敏感性是由于在固定点处存在相关操作符。提出了一种基于Monte Carlo RG思想的数值方法，用于识别相关算子的存在性和输入数据中相应的最大灵敏度方向。因此，可以对经过训练的深度学习网络的稳健性进行测试，并且如果它容易受到攻击，则识别输入数据的危险扰动。

##### URL
[https://arxiv.org/abs/1803.06111](https://arxiv.org/abs/1803.06111)

##### PDF
[https://arxiv.org/pdf/1803.06111](https://arxiv.org/pdf/1803.06111)

