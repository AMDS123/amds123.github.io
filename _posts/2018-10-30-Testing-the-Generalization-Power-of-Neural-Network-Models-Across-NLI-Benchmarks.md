---
layout: post
title: "Testing the Generalization Power of Neural Network Models Across NLI Benchmarks"
date: 2018-10-30 13:51:14
categories: arXiv_CL
tags: arXiv_CL Inference
author: Aarne Talman, Stergios Chatzikyriakidis
mathjax: true
---

* content
{:toc}

##### Abstract
Neural network models have been very successful for natural language inference, with the best models reaching 90% accuracy in some benchmarks. However, the success of these models turns out to be largely benchmark specific. We show that models trained on natural language inference dataset drawn from one benchmark fail to perform well in others, even if the notion of inference assumed in these benchmark tasks is the same or similar. We train five state-of-the-art neural network models on different datasets and show that each one of these fail to generalize outside of the respective benchmark. In light of these results we conclude that the current neural network models are not able to generalize in capturing the semantics of natural language inference, but seem to be overfitting to the specific dataset.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1810.09774](https://arxiv.org/abs/1810.09774)

##### PDF
[https://arxiv.org/pdf/1810.09774](https://arxiv.org/pdf/1810.09774)

