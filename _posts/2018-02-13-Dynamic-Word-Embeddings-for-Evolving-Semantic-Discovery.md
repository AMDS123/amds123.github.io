---
layout: post
title: "Dynamic Word Embeddings for Evolving Semantic Discovery"
date: 2018-02-13 17:10:42
categories: arXiv_CL
tags: arXiv_CL Embedding Represenation_Learning Quantitative
author: Zijun Yao, Yifan Sun, Weicong Ding, Nikhil Rao, Hui Xiong
mathjax: true
---

* content
{:toc}

##### Abstract
Word evolution refers to the changing meanings and associations of words throughout time, as a byproduct of human language evolution. By studying word evolution, we can infer social trends and language constructs over different periods of human history. However, traditional techniques such as word representation learning do not adequately capture the evolving language structure and vocabulary. In this paper, we develop a dynamic statistical model to learn time-aware word vector representation. We propose a model that simultaneously learns time-aware embeddings and solves the resulting "alignment problem". This model is trained on a crawled NYTimes dataset. Additionally, we develop multiple intuitive evaluation strategies of temporal word embeddings. Our qualitative and quantitative tests indicate that our method not only reliably captures this evolution over time, but also consistently outperforms state-of-the-art temporal embedding approaches on both semantic accuracy and alignment quality.

##### Abstract (translated by Google)
词汇的演变是指不断变化的词汇的意义和联想，是人类语言进化的副产品。通过研究单词的演变，我们可以推断人类历史不同时期的社会趋势和语言结构。然而，传统的词汇表达学习技术并没有充分地捕捉到不断演变的语言结构和词汇。在本文中，我们开发了一个动态统计模型来学习时间感知的词向量表示。我们提出了一个同时学习时间感知嵌入并解决最终“对齐问题”的模型。该模型在爬行的NYTimes数据集上进行训练。此外，我们开发了多种直观的时间词嵌入评估策略。我们的定性和定量测试表明，我们的方法不仅可靠地捕捉了这种随时间推移的演变，而且在语义准确性和对齐质量上始终优于最先进的时间嵌入方法。

##### URL
[http://arxiv.org/abs/1703.00607](http://arxiv.org/abs/1703.00607)

##### PDF
[http://arxiv.org/pdf/1703.00607](http://arxiv.org/pdf/1703.00607)

