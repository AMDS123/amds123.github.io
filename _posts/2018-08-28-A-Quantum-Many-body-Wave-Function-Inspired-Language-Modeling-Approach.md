---
layout: post
title: "A Quantum Many-body Wave Function Inspired Language Modeling Approach"
date: 2018-08-28 13:39:44
categories: arXiv_CL
tags: arXiv_CL QA Embedding CNN Language_Model
author: Peng Zhang, Zhan Su, Lipeng Zhang, Benyou Wang, Dawei Song
mathjax: true
---

* content
{:toc}

##### Abstract
The recently proposed quantum language model (QLM) aimed at a principled approach to modeling term dependency by applying the quantum probability theory. The latest development for a more effective QLM has adopted word embeddings as a kind of global dependency information and integrated the quantum-inspired idea in a neural network architecture. While these quantum-inspired LMs are theoretically more general and also practically effective, they have two major limitations. First, they have not taken into account the interaction among words with multiple meanings, which is common and important in understanding natural language text. Second, the integration of the quantum-inspired LM with the neural network was mainly for effective training of parameters, yet lacking a theoretical foundation accounting for such integration. To address these two issues, in this paper, we propose a Quantum Many-body Wave Function (QMWF) inspired language modeling approach. The QMWF inspired LM can adopt the tensor product to model the aforesaid interaction among words. It also enables us to reveal the inherent necessity of using Convolutional Neural Network (CNN) in QMWF language modeling. Furthermore, our approach delivers a simple algorithm to represent and match text/sentence pairs. Systematic evaluation shows the effectiveness of the proposed QMWF-LM algorithm, in comparison with the state of the art quantum-inspired LMs and a couple of CNN-based methods, on three typical Question Answering (QA) datasets.

##### Abstract (translated by Google)
最近提出的量子语言模型（QLM）旨在通过应用量子概率理论来建模术语依赖性的原理方法。更有效的QLM的最新发展采用了词嵌入作为一种全局依赖信息，并将量子启发的想法集成到神经网络架构中。虽然这些量子启发的LM在理论上更为通用且实用有效，但它们有两个主要限制。首先，他们没有考虑具有多重含义的词之间的相互作用，这在理解自然语言文本时是常见且重要的。其次，量子激励LM与神经网络的整合主要是为了有效地训练参数，但缺乏对这种整合进行解释的理论基础。为了解决这两个问题，在本文中，我们提出了一种量子多体波函数（QMWF）启发的语言建模方法。 QMWF启发的LM可以采用张量积来模拟上述词之间的相互作用。它还使我们能够揭示在QMWF语言建模中使用卷积神经网络（CNN）的固有必要性。此外，我们的方法提供了一种简单的算法来表示和匹配文本/句子对。系统评估显示了所提出的QMWF-LM算法与三种典型的问答（QA）数据集相比，最先进的量子激励LM和几种基于CNN的方法的有效性。

##### URL
[http://arxiv.org/abs/1808.09891](http://arxiv.org/abs/1808.09891)

##### PDF
[http://arxiv.org/pdf/1808.09891](http://arxiv.org/pdf/1808.09891)

