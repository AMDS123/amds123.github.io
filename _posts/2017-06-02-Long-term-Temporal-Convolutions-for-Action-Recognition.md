---
layout: post
title: "Long-term Temporal Convolutions for Action Recognition"
date: 2017-06-02 12:08:57
categories: arXiv_CV
tags: arXiv_CV Action_Recognition CNN Recognition
author: Gül Varol, Ivan Laptev, Cordelia Schmid
mathjax: true
---

* content
{:toc}

##### Abstract
Typical human actions last several seconds and exhibit characteristic spatio-temporal structure. Recent methods attempt to capture this structure and learn action representations with convolutional neural networks. Such representations, however, are typically learned at the level of a few video frames failing to model actions at their full temporal extent. In this work we learn video representations using neural networks with long-term temporal convolutions (LTC). We demonstrate that LTC-CNN models with increased temporal extents improve the accuracy of action recognition. We also study the impact of different low-level representations, such as raw values of video pixels and optical flow vector fields and demonstrate the importance of high-quality optical flow estimation for learning accurate action models. We report state-of-the-art results on two challenging benchmarks for human action recognition UCF101 (92.7%) and HMDB51 (67.2%).

##### Abstract (translated by Google)
典型的人类行为持续几秒钟，展现出特有的时空结构。最近的方法试图捕捉这种结构，并学习与卷积神经网络的行动表示。然而，这样的表示通常是在几个视频帧的层面上学习的，而这些视频帧未能在整个时间范围内对行动建模。在这项工作中，我们学习使用具有长时间卷积（LTC）的神经网络的视频表示。我们证明具有增加的时间范围的LTC-CNN模型提高了动作识别的准确性。我们还研究了视频像素和光流矢量场的原始值等不同低层表示的影响，并展示了高质量光流估计对学习准确动作模型的重要性。我们报告了人类行为识别UCF101（92.7％）和HMDB51（67.2％）两个具有挑战性的基准的最新成果。

##### URL
[https://arxiv.org/abs/1604.04494](https://arxiv.org/abs/1604.04494)

##### PDF
[https://arxiv.org/pdf/1604.04494](https://arxiv.org/pdf/1604.04494)

