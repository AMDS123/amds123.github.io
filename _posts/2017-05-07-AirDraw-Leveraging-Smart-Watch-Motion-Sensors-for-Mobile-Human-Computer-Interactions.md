---
layout: post
title: "AirDraw: Leveraging Smart Watch Motion Sensors for Mobile Human Computer Interactions"
date: 2017-05-07 19:58:54
categories: arXiv_CV
tags: arXiv_CV Recognition
author: Seyed A Sajjadi, Danial Moazen, Ani Nahapetian
mathjax: true
---

* content
{:toc}

##### Abstract
Wearable computing is one of the fastest growing technologies today. Smart watches are poised to take over at least of half the wearable devices market in the near future. Smart watch screen size, however, is a limiting factor for growth, as it restricts practical text input. On the other hand, wearable devices have some features, such as consistent user interaction and hands-free, heads-up operations, which pave the way for gesture recognition methods of text entry. This paper proposes a new text input method for smart watches, which utilizes motion sensor data and machine learning approaches to detect letters written in the air by a user. This method is less computationally intensive and less expensive when compared to computer vision approaches. It is also not affected by lighting factors, which limit computer vision solutions. The AirDraw system prototype developed to test this approach is presented. Additionally, experimental results close to 71% accuracy are presented.

##### Abstract (translated by Google)
可穿戴计算是当今发展最快的技术之一。在不久的将来，智能手表将准备接管至少一半的可穿戴设备市场。然而，智能手表的屏幕尺寸是增长的限制因素，因为它限制了实际的文字输入。另一方面，可穿戴式设备具有一致的用户交互和免提，抬头操作等特点，为文本输入的手势识别方法铺平了道路。本文提出了一种智能手表的新型文本输入方法，利用运动传感器数据和机器学习方法来检测用户在空中写入的字母。与计算机视觉方法相比，这种方法计算量小，费用低廉。它也不受光照因素的影响，这限制了计算机视觉解决方案。介绍了用于测试这种方法的AirDraw系统原型。此外，实验结果接近71％的准确性提出。

##### URL
[https://arxiv.org/abs/1705.02689](https://arxiv.org/abs/1705.02689)

##### PDF
[https://arxiv.org/pdf/1705.02689](https://arxiv.org/pdf/1705.02689)

