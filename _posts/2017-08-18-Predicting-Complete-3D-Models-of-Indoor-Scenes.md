---
layout: post
title: "Predicting Complete 3D Models of Indoor Scenes"
date: 2017-08-18 01:55:57
categories: arXiv_CV
tags: arXiv_CV Segmentation Face
author: Ruiqi Guo, Chuhang Zou, Derek Hoiem
mathjax: true
---

* content
{:toc}

##### Abstract
One major goal of vision is to infer physical models of objects, surfaces, and their layout from sensors. In this paper, we aim to interpret indoor scenes from one RGBD image. Our representation encodes the layout of walls, which must conform to a Manhattan structure but is otherwise flexible, and the layout and extent of objects, modeled with CAD-like 3D shapes. We represent both the visible and occluded portions of the scene, producing a complete 3D parse. Such a scene interpretation is useful for robotics and visual reasoning, but difficult to produce due to the well-known challenge of segmentation, the high degree of occlusion, and the diversity of objects in indoor scene. We take a data-driven approach, generating sets of potential object regions, matching to regions in training images, and transferring and aligning associated 3D models while encouraging fit to observations and overall consistency. We demonstrate encouraging results on the NYU v2 dataset and highlight a variety of interesting directions for future work.

##### Abstract (translated by Google)
视觉的一个主要目标是从传感器推断物体，表面以及它们的布局的物理模型。在本文中，我们旨在从一个RGBD图像解读室内场景。我们的代表性编码墙的布局，必须符合曼哈顿的结构，但要灵活，以及用类似CAD的3D形状建模的对象的布局和范围。我们代表场景的可见部分和遮挡部分，产生完整的3D解析。这种场景解释对于机器人和视觉推理是有用的，但是由于众所周知的分割挑战，高度遮挡以及室内场景中物体的多样性而难以产生。我们采用数据驱动的方法，生成潜在的对象区域集合，与训练图像中的区域相匹配，转移和对齐相关的3D模型，同时鼓励适合观察和整体一致性。我们在纽约大学v2数据集上展示令人鼓舞的成果，并突出了未来工作的各种有趣的方向。

##### URL
[https://arxiv.org/abs/1504.02437](https://arxiv.org/abs/1504.02437)

##### PDF
[https://arxiv.org/pdf/1504.02437](https://arxiv.org/pdf/1504.02437)

