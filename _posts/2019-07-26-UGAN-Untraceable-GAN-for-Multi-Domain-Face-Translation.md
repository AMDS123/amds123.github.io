---
layout: post
title: "UGAN: Untraceable GAN for Multi-Domain Face Translation"
date: 2019-07-26 08:05:13
categories: arXiv_CV
tags: arXiv_CV Adversarial Attention GAN Face
author: Defa Zhu, Si Liu, Wentao Jiang, Chen Gao, Tianyi Wu, Guodong Guo
mathjax: true
---

* content
{:toc}

##### Abstract
The multi-domain image-to-image translation is received increasing attention in the computer vision community. However, the translated images often retain the characteristics of the source domain. In this paper, we propose a novel Untraceable GAN (UGAN) to tackle the phenomenon of source retaining. Specifically, the discriminator of UGAN contains a novel source classifier to tell which domain an image is translated from, with the purpose to determine whether the translated image still retains the characteristics of the source domain. After this adversarial training converges, the translator is able to synthesize the target-only characteristics and also erase the source-only characteristics. In this way, the source domain of the synthesized image becomes untraceable. We perform extensive experiments, and the results have demonstrated that the proposed UGAN can produce superior results over state-of-the-art StarGAN on three face editing tasks, including face aging, makeup, and expression editing. The source code will be made publicly available.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.11418](http://arxiv.org/abs/1907.11418)

##### PDF
[http://arxiv.org/pdf/1907.11418](http://arxiv.org/pdf/1907.11418)

