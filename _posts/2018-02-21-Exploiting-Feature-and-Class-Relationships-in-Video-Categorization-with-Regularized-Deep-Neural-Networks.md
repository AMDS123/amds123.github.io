---
layout: post
title: "Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks"
date: 2018-02-21 20:37:34
categories: arXiv_CV
tags: arXiv_CV Regularization Relation
author: Yu-Gang Jiang, Zuxuan Wu, Jun Wang, Xiangyang Xue, Shih-Fu Chang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we study the challenging problem of categorizing videos according to high-level semantics such as the existence of a particular human action or a complex event. Although extensive efforts have been devoted in recent years, most existing works combined multiple video features using simple fusion strategies and neglected the utilization of inter-class semantic relationships. This paper proposes a novel unified framework that jointly exploits the feature relationships and the class relationships for improved categorization performance. Specifically, these two types of relationships are estimated and utilized by rigorously imposing regularizations in the learning process of a deep neural network (DNN). Such a regularized DNN (rDNN) can be efficiently realized using a GPU-based implementation with an affordable training cost. Through arming the DNN with better capability of harnessing both the feature and the class relationships, the proposed rDNN is more suitable for modeling video semantics. With extensive experimental evaluations, we show that rDNN produces superior performance over several state-of-the-art approaches. On the well-known Hollywood2 and Columbia Consumer Video benchmarks, we obtain very competitive results: 66.9\% and 73.5\% respectively in terms of mean average precision. In addition, to substantially evaluate our rDNN and stimulate future research on large scale video categorization, we collect and release a new benchmark dataset, called FCVID, which contains 91,223 Internet videos and 239 manually annotated categories.

##### Abstract (translated by Google)
在本文中，我们研究了根据诸如特定人类行为或复杂事件的存在等高级语义对视频进行分类的具有挑战性的问题。尽管近年来已经投入了大量的努力，但是大多数现有的作品使用简单的融合策略结合了多个视频特征并且忽略了对类间语义关系的利用。本文提出了一种新的统一框架，联合利用特征关系和类关系来提高分类性能。具体而言，通过在深度神经网络（DNN）的学习过程中严格地施加正则化来估计和利用这两种类型的关系。这种正则化的DNN（rDNN）可以使用基于GPU的实施方式以合理的培训成本高效实现。通过将DNN更好地利用特征和类关系的能力，所提出的rDNN更适合于视频语义建模。通过广泛的实验评估，我们证明了rDNN在几种最先进的方法上产生了卓越的性能。在众所周知的好莱坞2和哥伦比亚消费者视频基准测试中，我们获得了非常有竞争力的结果：平均精度平均分别为66.9％和73.5％。此外，为了充分评估我们的rDNN并刺激未来的大规模视频分类研究，我们收集并发布了一个新的基准数据集，名为FCVID，其中包含91,223个互联网视频和239个手动注释的类别。

##### URL
[http://arxiv.org/abs/1502.07209](http://arxiv.org/abs/1502.07209)

##### PDF
[http://arxiv.org/pdf/1502.07209](http://arxiv.org/pdf/1502.07209)

