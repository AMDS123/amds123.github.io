---
layout: post
title: "Perceptual Values from Observation"
date: 2019-05-20 03:59:44
categories: arXiv_AI
tags: arXiv_AI Sparse Reinforcement_Learning
author: Ashley D. Edwards, Charles L. Isbell
mathjax: true
---

* content
{:toc}

##### Abstract
Imitation by observation is an approach for learning from expert demonstrations that lack action information, such as videos. Recent approaches to this problem can be placed into two broad categories: training dynamics models that aim to predict the actions taken between states, and learning rewards or features for computing them for Reinforcement Learning (RL). In this paper, we introduce a novel approach that learns values, rather than rewards, directly from observations. We show that by using values, we can significantly speed up RL by removing the need to bootstrap action-values, as compared to sparse-reward specifications.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.07861](http://arxiv.org/abs/1905.07861)

##### PDF
[http://arxiv.org/pdf/1905.07861](http://arxiv.org/pdf/1905.07861)

