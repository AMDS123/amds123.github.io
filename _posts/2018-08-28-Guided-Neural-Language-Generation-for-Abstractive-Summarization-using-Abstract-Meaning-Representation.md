---
layout: post
title: "Guided Neural Language Generation for Abstractive Summarization using Abstract Meaning Representation"
date: 2018-08-28 08:04:21
categories: arXiv_CL
tags: arXiv_CL Summarization
author: Hardy, Andreas Vlachos
mathjax: true
---

* content
{:toc}

##### Abstract
Recent work on abstractive summarization has made progress with neural encoder-decoder architectures. However, such models are often challenged due to their lack of explicit semantic modeling of the source document and its summary. In this paper, we extend previous work on abstractive summarization using Abstract Meaning Representation (AMR) with a neural language generation stage which we guide using the source document. We demonstrate that this guidance improves summarization results by 7.4 and 10.5 points in ROUGE-2 using gold standard AMR parses and parses obtained from an off-the-shelf parser respectively. We also find that the summarization performance using the latter is 2 ROUGE-2 points higher than that of a well-established neural encoder-decoder approach trained on a larger dataset. Code is available at \url{https://github.com/sheffieldnlp/AMR2Text-summ}

##### Abstract (translated by Google)
最近关于抽象概括的工作在神经编码器 - 解码器架构方面取得了进展。然而，由于缺乏源文档及其摘要的显式语义建模，这些模型经常受到挑战。在本文中，我们使用抽象意义表示（AMR）和神经语言生成阶段扩展了以前关于抽象概括的工作，我们引导使用源文档。我们证明了本指南使用分别从现成的解析器获得的黄金标准AMR解析和解析，在ROUGE-2中将汇总结果提高了7.4和10.5分。我们还发现使用后者的摘要性能比在较大数据集上训练的成熟的神经编码器 - 解码器方法高2个ROUGE-2点。代码可在\ url {https://github.com/sheffieldnlp/AMR2Text-summ}获取

##### URL
[http://arxiv.org/abs/1808.09160](http://arxiv.org/abs/1808.09160)

##### PDF
[http://arxiv.org/pdf/1808.09160](http://arxiv.org/pdf/1808.09160)

