---
layout: post
title: "SynNet: Structure-Preserving Fully Convolutional Networks for Medical Image Synthesis"
date: 2018-06-29 15:32:57
categories: arXiv_CV
tags: arXiv_CV Super_Resolution Segmentation CNN Deep_Learning
author: Deepa Gunashekar, Sailesh Conjeti, Abhijit Guha Roy, Nassir Navab, Kuangyu Shi
mathjax: true
---

* content
{:toc}

##### Abstract
Cross modal image syntheses is gaining significant interests for its ability to estimate target images of a different modality from a given set of source images,like estimating MR to MR, MR to CT, CT to PET etc, without the need for an actual acquisition.Though they show potential for applications in radiation therapy planning,image super resolution, atlas construction, image segmentation etc.The synthesis results are not as accurate as the actual acquisition.In this paper,we address the problem of multi modal image synthesis by proposing a fully convolutional deep learning architecture called the SynNet.We extend the proposed architecture for various input output configurations. And finally, we propose a structure preserving custom loss function for cross-modal image synthesis.We validate the proposed SynNet and its extended framework on BRATS dataset with comparisons against three state-of-the art methods.And the results of the proposed custom loss function is validated against the traditional loss function used by the state-of-the-art methods for cross modal image synthesis.

##### Abstract (translated by Google)
跨模态图像合成因其能够从一组给定的源图像估计不同模态的目标图像，如估计MR到MR，MR到CT，CT到PET等，而无需实际采集，因此获得了巨大的兴趣。虽然它们在放射治疗计划，图像超分辨率，图谱构建，图像分割等方面显示出应用潜力，但综合结果并不像实际采集那么准确。本文中，我们提出了一种多模式图像合成的问题完全卷积深度学习体系结构称为SynNet。我们扩展了所提出的各种输入输出配置的体系结构。最后，我们提出了一种保留用于跨模态图像合成的定制损失函数的结构。我们通过与三种最先进的方法进行比较，验证了提出的SynNet及其在BRATS数据集上的扩展框架。并且提出了定制损失函数验证了最先进的交叉模态图像合成方法所使用的传统损失函数。

##### URL
[http://arxiv.org/abs/1806.11475](http://arxiv.org/abs/1806.11475)

##### PDF
[http://arxiv.org/pdf/1806.11475](http://arxiv.org/pdf/1806.11475)

