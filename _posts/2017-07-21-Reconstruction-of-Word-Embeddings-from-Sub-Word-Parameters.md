---
layout: post
title: "Reconstruction of Word Embeddings from Sub-Word Parameters"
date: 2017-07-21 16:10:51
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Karl Stratos
mathjax: true
---

* content
{:toc}

##### Abstract
Pre-trained word embeddings improve the performance of a neural model at the cost of increasing the model size. We propose to benefit from this resource without paying the cost by operating strictly at the sub-lexical level. Our approach is quite simple: before task-specific training, we first optimize sub-word parameters to reconstruct pre-trained word embeddings using various distance measures. We report interesting results on a variety of tasks: word similarity, word analogy, and part-of-speech tagging.

##### Abstract (translated by Google)
预先训练的词嵌入以增加模型大小为代价提高了神经模型的性能。我们建议从这个资源中受益，而不需要严格在分词水平上操作来支付成本。我们的方法非常简单：在任务特定的训练之前，我们首先优化子字参数以使用各种距离度量来重构预先训练的字嵌入。我们在各种任务上报告有趣的结果：单词相似性，单词比喻和词性标注。

##### URL
[https://arxiv.org/abs/1707.06957](https://arxiv.org/abs/1707.06957)

##### PDF
[https://arxiv.org/pdf/1707.06957](https://arxiv.org/pdf/1707.06957)

