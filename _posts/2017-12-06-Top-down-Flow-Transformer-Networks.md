---
layout: post
title: "Top-down Flow Transformer Networks"
date: 2017-12-06 20:20:27
categories: arXiv_CV
tags: arXiv_CV CNN
author: Zhiwei Jia, Haoshen Hong, Siyang Wang, Zhuowen Tu
mathjax: true
---

* content
{:toc}

##### Abstract
We study the deformation fields of feature maps across convolutional network layers under explicit top-down spatial transformations. We propose top-down flow transformer (TFT) by focusing on three transformations: translation, rotation, and scaling. We learn flow transformation generators that are able to account for the hidden layer deformations while maintaining the overall consistency across layers. The learned generators are shown to capture the underlying feature transformation processes that are independent of the particular training images. We observe favorable experimental results compared to the existing methods that tie transformations to fixed datasets. A comprehensive study on various datasets including MNIST, shapes, and natural images with both inner and inter datasets (trained on MNIST and validated in a number of datasets) evaluation demonstrates the advantages of our proposed TFT framework, which can be adopted in a variety of computer vision applications.

##### Abstract (translated by Google)
我们研究了显式自顶向下空间变换下卷积网络层的特征映射的变形场。我们提出自上而下的流动变压器（TFT），着重于三个转换：平移，旋转和缩放。我们学习流变换生成器，它能够解决隐藏层变形，同时保持层间的整体一致性。示出所学习的生成器捕捉独立于特定训练图像的潜在特征转换过程。与将转换与固定数据集联系起来的现有方法相比，我们观察到有利的实验结果。对包括MNIST，形状和自然图像在内的多个数据集（MNIST上的训练并在多个数据集中验证）的综合研究包括MNIST，形状和自然图像，评估证明了我们提出的TFT框架的优点，其可以在各种计算机视觉应用。

##### URL
[http://arxiv.org/abs/1712.02400](http://arxiv.org/abs/1712.02400)

##### PDF
[http://arxiv.org/pdf/1712.02400](http://arxiv.org/pdf/1712.02400)

