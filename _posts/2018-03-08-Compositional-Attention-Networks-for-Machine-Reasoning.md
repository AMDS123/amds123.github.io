---
layout: post
title: "Compositional Attention Networks for Machine Reasoning"
date: 2018-03-08 12:37:14
categories: arXiv_AI
tags: arXiv_AI Attention GAN
author: Drew A. Hudson, Christopher D. Manning
mathjax: true
---

* content
{:toc}

##### Abstract
We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. Drawing inspiration from first principles of computer organization, MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.

##### Abstract (translated by Google)
我们介绍了MAC网络，一种新颖的完全可微的神经网络架构，旨在促进显式和表达性推理。从计算机组织的第一原则中汲取灵感，MAC从单片黑盒神经架构转向鼓励透明和多功能的设计。该模型通过将问题分解成一系列基于注意力的推理步骤来解决问题，每个推理步骤都是通过一种新颖的反复记忆，注意和组合（MAC）单元来执行的，该单元在控制和记忆之间保持分离。通过将细胞串联在一起并施加调节它们相互作用的结构约束，MAC有效地学习执行迭代推理过程，这是通过端对端方法从数据中直接推断出来的。我们在具有挑战性的CLEVR数据集中展示模型的强度，鲁棒性和可解释性，以实现视觉推理，实现了最新的98.9％的精确度，减少了以前最佳模型的误差率。更重要的是，我们证明该模型的计算效率和数据有效率，特别是要求比现有模型少5倍的数据以获得更好的结果。

##### URL
[http://arxiv.org/abs/1803.03067](http://arxiv.org/abs/1803.03067)

##### PDF
[http://arxiv.org/pdf/1803.03067](http://arxiv.org/pdf/1803.03067)

