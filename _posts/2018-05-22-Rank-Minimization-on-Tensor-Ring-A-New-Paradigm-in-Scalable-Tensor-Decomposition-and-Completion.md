---
layout: post
title: "Rank Minimization on Tensor Ring: A New Paradigm in Scalable Tensor Decomposition and Completion"
date: 2018-05-22 09:16:34
categories: arXiv_AI
tags: arXiv_AI Regularization
author: Longhao Yuan, Chao Li, Danilo Mandic, Jianting Cao, Qibin Zhao
mathjax: true
---

* content
{:toc}

##### Abstract
In low-rank tensor completion tasks, due to the underlying multiple large-scale singular value decomposition (SVD) operations and rank selection problem of the traditional methods, they suffer from high computational cost and high sensitivity of model complexity. In this paper, taking advantages of high compressibility of the recently proposed tensor ring (TR) decomposition, we propose a new model for tensor completion problem. This is achieved through introducing convex surrogates of tensor low-rank assumption on latent tensor ring factors, which makes it possible for the Schatten norm regularization based models to be solved at much smaller scale. We propose two algorithms which apply different structured Schatten norms on tensor ring factors respectively. By the alternating direction method of multipliers (ADMM) scheme, the tensor ring factors and the predicted tensor can be optimized simultaneously. The experiments on synthetic data and real-world data show the high performance and efficiency of the proposed approach.

##### Abstract (translated by Google)
在低秩张量完成任务中，由于传统方法潜在的多重大规模奇异值分解（SVD）操作和秩选择问题，其计算成本高，模型复杂度高。本文利用最近提出的张量环（TR）分解的高压缩性，提出了一种新的张量完成问题模型。这是通过在潜在张量环因子中引入张量低秩假设的凸代理来实现的，这使得基于Schatten范数正则化的模型能够以更小的尺度解决。我们提出了两种算法，分别对张量环因子应用不同的结构化Schatten规范。利用乘法器交替方向法（ADMM），可以同时优化张量环因子和预测张量。对合成数据和真实世界数据的实验表明了所提出的方法的高性能和高效率。

##### URL
[https://arxiv.org/abs/1805.08468](https://arxiv.org/abs/1805.08468)

##### PDF
[https://arxiv.org/pdf/1805.08468](https://arxiv.org/pdf/1805.08468)

