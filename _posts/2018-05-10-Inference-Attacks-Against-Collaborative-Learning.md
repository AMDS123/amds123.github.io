---
layout: post
title: "Inference Attacks Against Collaborative Learning"
date: 2018-05-10 16:28:44
categories: arXiv_AI
tags: arXiv_AI Adversarial Inference
author: Luca Melis, Congzheng Song, Emiliano De Cristofaro, Vitaly Shmatikov
mathjax: true
---

* content
{:toc}

##### Abstract
Collaborative machine learning and related techniques such as distributed and federated learning allow multiple participants, each with his own training dataset, to build a joint model. Participants train local models and periodically exchange model parameters or gradient updates computed during the training. 
 We demonstrate that the training data used by participants in collaborative learning is vulnerable to inference attacks. First, we show that an adversarial participant can infer the presence of exact data points in others' training data (i.e., membership inference). Then, we demonstrate that the adversary can infer properties that hold only for a subset of the training data and are independent of the properties that the joint model aims to capture. We evaluate the efficacy of our attacks on a variety of tasks, datasets, and learning configurations, and conclude with a discussion of possible defenses.

##### Abstract (translated by Google)
协作式机器学习和相关技术（如分布式和联合式学习）允许多个参与者（每个参与者都有自己的训练数据集）构建联合模型。参与者训练局部模型并定期交换模型参数或训练期间计算的梯度更新。
 我们证明参与者在协作学习中使用的训练数据很容易受到推理攻击。首先，我们显示对抗参与者可以推断出其他人的训练数据中的确切数据点（即，会员推断）的存在。然后，我们证明对手可以推断只包含一部分训练数据的属性，并且独立于联合模型旨在捕获的属性。我们评估攻击对各种任务，数据集和学习配置的有效性，最后讨论可能的防御措施。

##### URL
[http://arxiv.org/abs/1805.04049](http://arxiv.org/abs/1805.04049)

##### PDF
[http://arxiv.org/pdf/1805.04049](http://arxiv.org/pdf/1805.04049)

