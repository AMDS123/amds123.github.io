---
layout: post
title: "Open Source Dataset and Deep Learning Models for Online Digit Gesture Recognition on Touchscreens"
date: 2017-09-20 14:02:55
categories: arXiv_CV
tags: arXiv_CV CNN Deep_Learning Recognition
author: Philip J. Corr, Guenole C. Silvestre, Chris J. Bleakley
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents an evaluation of deep neural networks for recognition of digits entered by users on a smartphone touchscreen. A new large dataset of Arabic numerals was collected for training and evaluation of the network. The dataset consists of spatial and temporal touch data recorded for 80 digits entered by 260 users. Two neural network models were investigated. The first model was a 2D convolutional neural (ConvNet) network applied to bitmaps of the glpyhs created by interpolation of the sensed screen touches and its topology is similar to that of previously published models for offline handwriting recognition from scanned images. The second model used a 1D ConvNet architecture but was applied to the sequence of polar vectors connecting the touch points. The models were found to provide accuracies of 98.50% and 95.86%, respectively. The second model was much simpler, providing a reduction in the number of parameters from 1,663,370 to 287,690. The dataset has been made available to the community as an open source resource.

##### Abstract (translated by Google)
本文介绍了深度神经网络的识别用户在智能手机触摸屏上输入的数字的评估。收集了一个新的阿拉伯数字大数据集，用于网络的训练和评估。数据集由260位用户输入的80位数字记录的空间和时间触摸数据组成。两个神经网络模型进行了调查。第一个模型是二维卷积神经（ConvNet）网络应用于通过感测屏幕触摸的插值创建的glpyhs的位图，其拓扑结构类似于先前公开的用于从扫描图像进行离线手写识别的模型。第二个模型使用了一维ConvNet架构，但应用于连接触点的极坐标矢量序列。发现模型分别提供了98.50％和95.86％的准确性。第二种模式要简单得多，参数数量从1,663,370减少到287,690。数据集已经作为开源资源提供给社区。

##### URL
[https://arxiv.org/abs/1709.06871](https://arxiv.org/abs/1709.06871)

##### PDF
[https://arxiv.org/pdf/1709.06871](https://arxiv.org/pdf/1709.06871)

