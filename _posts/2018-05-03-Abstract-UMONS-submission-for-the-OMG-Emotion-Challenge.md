---
layout: post
title: "Abstract: UMONS submission for the OMG-Emotion Challenge"
date: 2018-05-03 19:42:57
categories: arXiv_SD
tags: arXiv_SD Prediction
author: Delbrouck Jean-Benoit
mathjax: true
---

* content
{:toc}

##### Abstract
This paper describes the UMONS solution for the OMG-Emotion Challenge. We explore a context-dependent architecture where the arousal and valence of an utterance are predicted according to its surrounding context (i.e. the preceding and following utterances of the video). We report an improvement when taking into account context for both unimodal and multimodal predictions.

##### Abstract (translated by Google)
本文描述了OMONS-Emotion挑战的UMONS解决方案。我们探索一种依赖于情境的架构，根据其周围环境（即视频的前后话语）来预测话语的唤醒和效价。当考虑到单峰和多峰预测的背景时，我们报告了一个改进。

##### URL
[http://arxiv.org/abs/1805.02489](http://arxiv.org/abs/1805.02489)

##### PDF
[http://arxiv.org/pdf/1805.02489](http://arxiv.org/pdf/1805.02489)

