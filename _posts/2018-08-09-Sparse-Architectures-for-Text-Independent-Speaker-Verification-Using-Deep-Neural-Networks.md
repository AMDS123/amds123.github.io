---
layout: post
title: "Sparse Architectures for Text-Independent Speaker Verification Using Deep Neural Networks"
date: 2018-08-09 22:42:24
categories: arXiv_SD
tags: arXiv_SD Sparse
author: Sara Sedighi, Shayan Ramhormozi
mathjax: true
---

* content
{:toc}

##### Abstract
Network pruning is of great importance due to the elimination of the unimportant weights or features activated due to the network over-parametrization. Advantages of sparsity enforcement include preventing the overfitting and speedup. Considering a large number of parameters in deep architectures, network compression becomes of critical importance due to the required huge amount of computational power. In this work, we impose structured sparsity for speaker verification which is the validation of the query speaker compared to the speaker gallery. We will show that the mere sparsity enforcement can improve the verification results due to the possible initial overfitting in the network.

##### Abstract (translated by Google)
由于消除了由于网络过度参数化而激活的不重要的权重或特征，网络修剪非常重要。稀疏执行的优点包括防止过度拟合和加速。考虑到深层体系结构中的大量参数，由于需要大量的计算能力，网络压缩变得至关重要。在这项工作中，我们对演讲者验证施加了结构化稀疏性，这是查询说话者与演讲者画廊相比的验证。我们将证明，由于网络中可能的初始过度拟合，仅仅稀疏性执行可以改善验证结果。

##### URL
[http://arxiv.org/abs/1805.07628](http://arxiv.org/abs/1805.07628)

##### PDF
[http://arxiv.org/pdf/1805.07628](http://arxiv.org/pdf/1805.07628)

