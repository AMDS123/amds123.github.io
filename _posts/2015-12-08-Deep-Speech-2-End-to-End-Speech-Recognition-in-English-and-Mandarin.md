---
layout: post
title: "Deep Speech 2: End-to-End Speech Recognition in English and Mandarin"
date: 2015-12-08 19:13:50
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition Deep_Learning Recognition
author: Dario Amodei, Rishita Anubhai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Jingdong Chen, Mike Chrzanowski, Adam Coates, Greg Diamos, Erich Elsen, Jesse Engel, Linxi Fan, Christopher Fougner, Tony Han, Awni Hannun, Billy Jun, Patrick LeGresley, Libby Lin, Sharan Narang, Andrew Ng, Sherjil Ozair, Ryan Prenger, Jonathan Raiman, Sanjeev Satheesh, David Seetapun, Shubho Sengupta, Yi Wang, Zhiqian Wang, Chong Wang, Bo Xiao, Dani Yogatama, Jun Zhan, Zhenyao Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech--two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our application of HPC techniques, resulting in a 7x speedup over our previous system. Because of this efficiency, experiments that previously took weeks now run in days. This enables us to iterate more quickly to identify superior architectures and algorithms. As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally, using a technique called Batch Dispatch with GPUs in the data center, we show that our system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.

##### Abstract (translated by Google)
我们表明，一个端到端的深度学习方法可以用来识别英语或汉语的语音 - 两种截然不同的语言。因为它用神经网络取代了手工设计的组件的整个管道，端到端的学习使我们能够处理各种各样的语音，包括嘈杂的环境，口音和不同的语言。我们的方法的关键是我们的应用高性能计算技术，导致比我们以前的系统加快了7倍。由于这种效率，以前花费数周的实验现在只需几天就可以完成。这使我们能够更快速地进行迭代，以确定出色的体系结构和算法。因此，在一些情况下，我们的系统在标准数据集上进行基准测试时与人类工作者的转录相比具有竞争性。最后，在数据中心使用一种称为批处理调度（GPU）的技术，我们证明我们的系统可以低成本地部署在一个在线设置中，在为用户提供规模时提供低延迟。

##### URL
[https://arxiv.org/abs/1512.02595](https://arxiv.org/abs/1512.02595)

##### PDF
[https://arxiv.org/pdf/1512.02595](https://arxiv.org/pdf/1512.02595)

