---
layout: post
title: "Developing Brain Atlas through Deep Learning"
date: 2018-07-10 01:28:44
categories: arXiv_AI
tags: arXiv_AI GAN CNN Deep_Learning
author: Asim Iqbal, Romesa Khan, Theofanis Karayannis
mathjax: true
---

* content
{:toc}

##### Abstract
To uncover the organizational principles governing the human brain, neuroscientists are in need of developing high-throughput methods that can explore the structure and function of distinct brain regions using animal models. The first step towards this goal is to accurately register the regions of interest in a mouse brain, against a standard reference atlas, with minimum human supervision. The second step is to scale this approach to different animal ages, so as to also allow insights into normal and pathological brain development and aging. We introduce here a fully automated convolutional neural network-based method (SeBRe) for registration through Segmenting Brain Regions of interest in mice at different ages. We demonstrate the validity of our method on different mouse brain post-natal (P) developmental time points, across a range of neuronal markers. Our method outperforms the existing brain registration methods, and provides the minimum mean squared error (MSE) score on a mouse brain dataset. We propose that our deep learning-based registration method can (i) accelerate brain-wide exploration of region-specific changes in brain development and (ii) replace the existing complex brain registration methodology, by simply segmenting brain regions of interest for high-throughput brain-wide analysis.

##### Abstract (translated by Google)
为了揭示管理人类大脑的组织原则，神经科学家需要开发高通量方法，这些方法可以使用动物模型探索不同大脑区域的结构和功能。实现这一目标的第一步是在最小的人工监督下，针对标准参考地图集准确地记录小鼠大脑中的感兴趣区域。第二步是将这种方法扩展到不同的动物年龄，以便也可以深入了解正常和病理性大脑发育和衰老。我们在这里介绍一种全自动卷积神经网络方法（SeBRe），用于通过对不同年龄的小鼠感兴趣的脑区域进行注册。我们证明了我们的方法在不同的小鼠脑产后（P）发育时间点，跨越一系列神经元标记的有效性。我们的方法优于现有的脑注册方法，并提供小鼠大脑数据集的最小均方误差（MSE）分数。我们提出，我们基于深度学习的注册方法可以（i）加速大脑发展中大脑区域特定变化的大脑探索，以及（ii）通过简单地分割感兴趣的大脑区域以获得高通量，取代现有的复杂脑注册方法全脑分析。

##### URL
[http://arxiv.org/abs/1807.03440](http://arxiv.org/abs/1807.03440)

##### PDF
[http://arxiv.org/pdf/1807.03440](http://arxiv.org/pdf/1807.03440)

