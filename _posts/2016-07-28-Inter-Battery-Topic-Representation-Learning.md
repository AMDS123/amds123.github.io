---
layout: post
title: "Inter-Battery Topic Representation Learning"
date: 2016-07-28 10:08:40
categories: arXiv_CV
tags: arXiv_CV Regularization CNN Represenation_Learning Inference Classification
author: Cheng Zhang, Hedvig Kjellstrom, Carl Henrik Ek
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present the Inter-Battery Topic Model (IBTM). Our approach extends traditional topic models by learning a factorized latent variable representation. The structured representation leads to a model that marries benefits traditionally associated with a discriminative approach, such as feature selection, with those of a generative model, such as principled regularization and ability to handle missing data. The factorization is provided by representing data in terms of aligned pairs of observations as different views. This provides means for selecting a representation that separately models topics that exist in both views from the topics that are unique to a single view. This structured consolidation allows for efficient and robust inference and provides a compact and efficient representation. Learning is performed in a Bayesian fashion by maximizing a rigorous bound on the log-likelihood. Firstly, we illustrate the benefits of the model on a synthetic dataset,. The model is then evaluated in both uni- and multi-modality settings on two different classification tasks with off-the-shelf convolutional neural network (CNN) features which generate state-of-the-art results with extremely compact representations.

##### Abstract (translated by Google)
在本文中，我们提出了电池间话题模型（IBTM）。我们的方法通过学习分解潜变量表示来扩展传统的主题模型。结构化表示形成了一个模型，该模型将传统上与歧视性方法（如特征选择）相关联的效益与生成性模型（如原则正则化和处理缺失数据的能力）相结合。分解是通过以对齐的观察对数据表示为不同视图来提供的。这提供了用于选择表示的方法，该表示从单个视图所独有的主题中分别模拟两个视图中存在的主题。这种结构化的整合允许有效和强大的推断，并提供了一个紧凑和高效的表示。学习是通过最大化对数似然的严格界限以贝叶斯方式进行的。首先，我们说明模型在综合数据集上的好处。然后在两种不同分类任务的单模式和多模态设置下对模型进行评估，使用现成的卷积神经网络（CNN）特征，以极其紧凑的表示形式产生最新的结果。

##### URL
[https://arxiv.org/abs/1605.06155](https://arxiv.org/abs/1605.06155)

##### PDF
[https://arxiv.org/pdf/1605.06155](https://arxiv.org/pdf/1605.06155)

