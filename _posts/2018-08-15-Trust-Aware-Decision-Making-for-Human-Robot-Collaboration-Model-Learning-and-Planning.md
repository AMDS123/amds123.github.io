---
layout: post
title: "Trust-Aware Decision Making for Human-Robot Collaboration: Model Learning and Planning"
date: 2018-08-15 03:21:49
categories: arXiv_AI
tags: arXiv_AI
author: Min Chen, Stefanos Nikolaidis, Harold Soh, David Hsu, Siddhartha Srinivasa
mathjax: true
---

* content
{:toc}

##### Abstract
Trust in autonomy is essential for effective human-robot collaboration and user adoption of autonomous systems such as robot assistants. This paper introduces a computational model which integrates trust into robot decision-making. Specifically, we learn from data a partially observable Markov decision process (POMDP) with human trust as a latent variable. The trust-POMDP model provides a principled approach for the robot to (i) infer the trust of a human teammate through interaction, (ii) reason about the effect of its own actions on human trust, and (iii) choose actions that maximize team performance over the long term. We validated the model through human subject experiments on a table-clearing task in simulation (201 participants) and with a real robot (20 participants). In our studies, the robot builds human trust by manipulating low-risk objects first. Interestingly, the robot sometimes fails intentionally in order to modulate human trust and achieve the best team performance. These results show that the trust-POMDP calibrates trust to improve human-robot team performance over the long term. Further, they highlight that maximizing trust alone does not always lead to the best performance.

##### Abstract (translated by Google)
信任自治对于有效的人机协作和用户采用自动系统（如机器人助手）至关重要。本文介绍了一种将信任集成到机器人决策中的计算模型。具体而言，我们从数据中学习了一个部分可观察的马尔可夫决策过程（POMDP），其中人类信任作为潜在变量。信任-POMDP模型为机器人提供了一种原则性方法：（i）通过交互推断人类队友的信任，（ii）推理自己的行为对人类信任的影响，以及（iii）选择最大化团队的行动长期表现。我们通过人体实验在模拟中的表格清除任务（201个参与者）和真实的机器人（20个参与者）中验证了模型。在我们的研究中，机器人首先通过操纵低风险物体来建立人类信任。有趣的是，机器人有时会故意失败，以调节人类的信任并获得最佳的团队表现。这些结果表明，信任-POMDP可以校准信任，从而长期提高人机团队的绩效。此外，他们强调单独最大化信任并不总能带来最佳表现。

##### URL
[http://arxiv.org/abs/1801.04099](http://arxiv.org/abs/1801.04099)

##### PDF
[http://arxiv.org/pdf/1801.04099](http://arxiv.org/pdf/1801.04099)

