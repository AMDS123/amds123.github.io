---
layout: post
title: "Deep Sparse Coding for Invariant Multimodal Halle Berry Neurons"
date: 2017-11-21 19:06:04
categories: arXiv_CV
tags: arXiv_CV Sparse Embedding CNN Classification Deep_Learning Quantitative
author: Edward Kim, Darryl Hannan, Garrett Kenyon
mathjax: true
---

* content
{:toc}

##### Abstract
Deep feed-forward convolutional neural networks (CNNs) have become ubiquitous in virtually all machine learning and computer vision challenges; however, advancements in CNNs have arguably reached an engineering saturation point where incremental novelty results in minor performance gains. Although there is evidence that object classification has reached human levels on narrowly defined tasks, for general applications, the biological visual system is far superior to that of any computer. Research reveals there are numerous missing components in feed-forward deep neural networks that are critical in mammalian vision. The brain does not work solely in a feed-forward fashion, but rather all of the neurons are in competition with each other; neurons are integrating information in a bottom up and top down fashion and incorporating expectation and feedback in the modeling process. Furthermore, our visual cortex is working in tandem with our parietal lobe, integrating sensory information from various modalities. In our work, we sought to improve upon the standard feed-forward deep learning model by augmenting them with biologically inspired concepts of sparsity, top-down feedback, and lateral inhibition. We define our model as a sparse coding problem using hierarchical layers. We solve the sparse coding problem with an additional top-down feedback error driving the dynamics of the neural network. While building and observing the behavior of our model, we were fascinated that multimodal, invariant neurons naturally emerged that mimicked, "Halle Berry neurons" found in the human brain. Furthermore, our sparse representation of multimodal signals demonstrates qualitative and quantitative superiority to the standard feed-forward joint embedding in common vision and machine learning tasks.

##### Abstract (translated by Google)
深度前馈卷积神经网络（CNN）在几乎所有的机器学习和计算机视觉挑战中已经变得无处不在。然而，有线电视新闻网络的进步可以说已经达到了工程饱和点，增加的新颖性导致了微小的性能收益。尽管有证据表明物体分类在狭义的任务上达到了人的水平，但对于一般的应用来说，生物视觉系统远远优于任何计算机。研究揭示了在哺乳动物视觉中至关重要的前馈深层神经网络中存在许多缺失的成分。大脑不是单纯地以前馈的方式工作，而是所有的神经元都在相互竞争;神经元以自底向上和自上而下的方式整合信息，并在建模过程中引入期望和反馈。此外，我们的视觉皮层与我们的顶叶一起工作，整合各种形式的感官信息。在我们的工作中，我们试图改进标准的前馈式深度学习模式，用稀疏性，自上而下的反馈和横向抑制等生物学启发的概念加以改进。我们将我们的模型定义为使用分层的稀疏编码问题。我们通过额外的自上而下的反馈错误来解决稀疏编码问题，驱动神经网络的动态。在建立和观察我们的模型的行为的同时，我们着迷于多模式，不变的神经元自然出现模仿，在人脑中发现“哈利贝瑞神经元”。此外，我们对多模态信号的稀疏表示显示出在普通视觉和机器学习任务中标准前馈联合嵌入的定性和定量优越性。

##### URL
[https://arxiv.org/abs/1711.07998](https://arxiv.org/abs/1711.07998)

##### PDF
[https://arxiv.org/pdf/1711.07998](https://arxiv.org/pdf/1711.07998)

