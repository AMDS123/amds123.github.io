---
layout: post
title: "Learning Mutually Local-global U-nets For High-resolution Retinal Lesion Segmentation in Fundus Images"
date: 2019-01-18 01:05:48
categories: arXiv_CV
tags: arXiv_CV Segmentation
author: Zizheng Yan, Xiaoguang Han, Changmiao Wang, Yuda Qiu, Zixiang Xiong, Shuguang Cui
mathjax: true
---

* content
{:toc}

##### Abstract
Diabetic retinopathy is the most important complication of diabetes. Early diagnosis of retinal lesions helps to avoid visual loss or blindness. Due to high-resolution and small-size lesion regions, applying existing methods, such as U-Nets, to perform segmentation on fundus photography is very challenging. Although downsampling the input images could simplify the problem, it loses detailed information. Conducting patch-level analysis helps reaching fine-scale segmentation yet usually leads to misunderstanding as the lack of context information. In this paper, we propose an efficient network that combines them together, not only being aware of local details but also taking fully use of the context perceptions. This is implemented by integrating the decoder parts of a global-level U-net and a patch-level one. The two streams are jointly optimized, ensuring that they are enhanced mutually. Experimental results demonstrate our new framework significantly outperforms existing patch-based and global-based methods, especially when the lesion regions are scattered and small-scaled.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1901.06047](http://arxiv.org/abs/1901.06047)

##### PDF
[http://arxiv.org/pdf/1901.06047](http://arxiv.org/pdf/1901.06047)

