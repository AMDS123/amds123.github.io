---
layout: post
title: "Fooling OCR Systems with Adversarial Text Images"
date: 2018-02-15 02:08:19
categories: arXiv_CV
tags: arXiv_CV Adversarial OCR Deep_Learning Recognition
author: Congzheng Song, Vitaly Shmatikov
mathjax: true
---

* content
{:toc}

##### Abstract
We demonstrate that state-of-the-art optical character recognition (OCR) based on deep learning is vulnerable to adversarial images. Minor modifications to images of printed text, which do not change the meaning of the text to a human reader, cause the OCR system to "recognize" a different text where certain words chosen by the adversary are replaced by their semantic opposites. This completely changes the meaning of the output produced by the OCR system and by the NLP applications that use OCR for preprocessing their inputs.

##### Abstract (translated by Google)
我们证明，基于深度学习的最先进的光学字符识别（OCR）很容易受到敌对图像的影响。对印刷文本图像的细微修改（不会将文本的含义改变为人类读者）导致OCR系统“识别”不同文本，其中由对手选择的某些单词被其语义对立所取代。这完全改变了OCR系统和使用OCR预处理其输入的NLP应用程序产生的输出的含义。

##### URL
[https://arxiv.org/abs/1802.05385](https://arxiv.org/abs/1802.05385)

##### PDF
[https://arxiv.org/pdf/1802.05385](https://arxiv.org/pdf/1802.05385)

