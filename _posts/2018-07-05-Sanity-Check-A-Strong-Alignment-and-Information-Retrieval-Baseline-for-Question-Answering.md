---
layout: post
title: "Sanity Check: A Strong Alignment and Information Retrieval Baseline for Question Answering"
date: 2018-07-05 03:33:53
categories: arXiv_CL
tags: arXiv_CL QA RNN
author: Vikas Yadav, Rebecca Sharp, Mihai Surdeanu
mathjax: true
---

* content
{:toc}

##### Abstract
While increasingly complex approaches to question answering (QA) have been proposed, the true gain of these systems, particularly with respect to their expensive training requirements, can be inflated when they are not compared to adequate baselines. Here we propose an unsupervised, simple, and fast alignment and information retrieval baseline that incorporates two novel contributions: a \textit{one-to-many alignment} between query and document terms and \textit{negative alignment} as a proxy for discriminative information. Our approach not only outperforms all conventional baselines as well as many supervised recurrent neural networks, but also approaches the state of the art for supervised systems on three QA datasets. With only three hyperparameters, we achieve 47\% P@1 on an 8th grade Science QA dataset, 32.9\% P@1 on a Yahoo! answers QA dataset and 64\% MAP on WikiQA. We also achieve 26.56\% and 58.36\% on ARC challenge and easy dataset respectively. In addition to including the additional ARC results in this version of the paper, for the ARC easy set only we also experimented with one additional parameter -- number of justifications retrieved.

##### Abstract (translated by Google)
虽然已经提出了越来越复杂的问答方法（QA），但这些系统的真正收益，特别是在昂贵的培训要求方面，如果不与足够的基线进行比较，就会被夸大。在这里，我们提出了一个无监督，简单，快速的对齐和信息检索基线，它包含两个新的贡献：查询和文档术语之间的\ textit {一对多对齐}和作为判别信息的代理的\ textit {negative alignment} 。我们的方法不仅优于所有常规基线以及许多有监督的递归神经网络，而且还接近三个QA数据集上受监督系统的现有技术水平。只有三个超参数，我们在8级科学QA数据集上达到47 \％P @ 1，在Yahoo!上达到32.9 \％P @ 1在WikiQA上回答QA数据集和64 \％MAP。我们还分别在ARC挑战和简易数据集上实现了26.56 \％和58.36 \％。除了在此版本的论文中包含额外的ARC结果之外，对于ARC easy set，我们还只尝试了一个额外的参数 - 检索的理由数量。

##### URL
[http://arxiv.org/abs/1807.01836](http://arxiv.org/abs/1807.01836)

##### PDF
[http://arxiv.org/pdf/1807.01836](http://arxiv.org/pdf/1807.01836)

