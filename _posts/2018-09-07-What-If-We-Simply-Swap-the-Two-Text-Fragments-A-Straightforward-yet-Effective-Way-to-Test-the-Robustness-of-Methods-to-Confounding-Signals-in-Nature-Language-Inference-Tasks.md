---
layout: post
title: "What If We Simply Swap the Two Text Fragments? A Straightforward yet Effective Way to Test the Robustness of Methods to Confounding Signals in Nature Language Inference Tasks"
date: 2018-09-07 23:59:22
categories: arXiv_AI
tags: arXiv_AI Embedding Inference Relation
author: Haohan Wang, Da Sun, Eric P. Xing
mathjax: true
---

* content
{:toc}

##### Abstract
Nature language inference (NLI) task is a predictive task of determining the inference relationship of a pair of natural language sentences. With the increasing popularity of NLI, many state-of-the-art predictive models have been proposed with impressive performances. However, several works have noticed the statistical irregularities in the collected NLI data set that may result in an over-estimated performance of these models and proposed remedies. In this paper, we further investigate the statistical irregularities, what we refer as confounding factors, of the NLI data sets. With the belief that some NLI labels should preserve under swapping operations, we propose a simple yet effective way (swapping the two text fragments) of evaluating the NLI predictive models that naturally mitigate the observed problems. Further, we continue to train the predictive models with our swapping manner and propose to use the deviation of the model's evaluation performances under different percentages of training text fragments to be swapped to describe the robustness of a predictive model. Our evaluation metrics leads to some interesting understandings of recent published NLI methods. Finally, we also apply the swapping operation on NLI models to see the effectiveness of this straightforward method in mitigating the confounding factor problems in training generic sentence embeddings for other NLP transfer tasks.

##### Abstract (translated by Google)
自然语言推断（NLI）任务是确定一对自然语言句子的推理关系的预测任务。随着NLI的日益普及，已经提出了许多具有令人印象深刻的性能的最先进的预测模型。然而，一些工作已经注意到收集的NLI数据集中的统计不规则性可能导致这些模型的过高估计性能和建议的补救措施。在本文中，我们进一步研究了NLI数据集的统计不规则性，我们称之为混淆因素。由于认为某些NLI标签应该保留在交换操作下，我们提出了一种简单而有效的方法（交换两个文本片段）来评估自然缓解观察到的问题的NLI预测模型。此外，我们继续以交换方式训练预测模型，并建议在不同百分比的训练文本片段下使用模型评估性能的偏差进行交换，以描述预测模型的稳健性。我们的评估指标可以对最近发布的NLI方法有一些有趣的理解。最后，我们还在NLI模型上应用交换操作，以查看这种直接方法在减少其他NLP传输任务的通用句子嵌入训练中的混杂因素问题方面的有效性。

##### URL
[http://arxiv.org/abs/1809.02719](http://arxiv.org/abs/1809.02719)

##### PDF
[http://arxiv.org/pdf/1809.02719](http://arxiv.org/pdf/1809.02719)

