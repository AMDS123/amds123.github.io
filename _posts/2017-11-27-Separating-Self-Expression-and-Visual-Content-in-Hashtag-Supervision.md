---
layout: post
title: "Separating Self-Expression and Visual Content in Hashtag Supervision"
date: 2017-11-27 16:50:52
categories: arXiv_CV
tags: arXiv_CV
author: Andreas Veit, Maximilian Nickel, Serge Belongie, Laurens van der Maaten
mathjax: true
---

* content
{:toc}

##### Abstract
The variety, abundance, and structured nature of hashtags make them an interesting data source for training vision models. For instance, hashtags have the potential to significantly reduce the problem of manual supervision and annotation when learning vision models for a large number of concepts. However, a key challenge when learning from hashtags is that they are inherently subjective because they are provided by users as a form of self-expression. As a consequence, hashtags may have synonyms (different hashtags referring to the same visual content) and may be ambiguous (the same hashtag referring to different visual content). These challenges limit the effectiveness of approaches that simply treat hashtags as image-label pairs. This paper presents an approach that extends upon modeling simple image-label pairs by modeling the joint distribution of images, hashtags, and users. We demonstrate the efficacy of such approaches in image tagging and retrieval experiments, and show how the joint model can be used to perform user-conditional retrieval and tagging.

##### Abstract (translated by Google)
标签的多样性，丰富性和结构性使其成为训练视觉模型的有趣数据源。例如，在为大量概念学习视觉模型时，主题标签可以显着减少人工监督和注释的问题。然而，从标签学习的一个关键挑战是，它们本质上是主观的，因为它们是由用户提供的一种自我表达形式。因此，主题标签可能具有同义词（不同的主题标签涉及相同的视觉内容）并且可能是不明确的（相同的主题标签涉及不同的视觉内容）。这些挑战限制了简单地将主题标签作为图像标签对的方法的有效性。本文提出了一种通过对图像，主题标签和用户的联合分布进行建模来扩展建模简单图像标签对的方法。我们证明了这些方法在图像标记和检索实验中的功效，并展示了如何使用联合模型来执行用户条件检索和标记。

##### URL
[https://arxiv.org/abs/1711.09825](https://arxiv.org/abs/1711.09825)

##### PDF
[https://arxiv.org/pdf/1711.09825](https://arxiv.org/pdf/1711.09825)

