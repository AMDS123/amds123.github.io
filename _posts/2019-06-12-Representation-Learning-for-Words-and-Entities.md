---
layout: post
title: "Representation Learning for Words and Entities"
date: 2019-06-12 17:29:22
categories: arXiv_AI
tags: arXiv_AI Knowledge_Graph Knowledge Embedding Represenation_Learning Recommendation
author: Pushpendre Rastogi
mathjax: true
---

* content
{:toc}

##### Abstract
This thesis presents new methods for unsupervised learning of distributed representations of words and entities from text and knowledge bases. The first algorithm presented in the thesis is a multi-view algorithm for learning representations of words called Multiview Latent Semantic Analysis (MVLSA). By incorporating up to 46 different types of co-occurrence statistics for the same vocabulary of english words, I show that MVLSA outperforms other state-of-the-art word embedding models. Next, I focus on learning entity representations for search and recommendation and present the second method of this thesis, Neural Variational Set Expansion (NVSE). NVSE is also an unsupervised learning method, but it is based on the Variational Autoencoder framework. Evaluations with human annotators show that NVSE can facilitate better search and recommendation of information gathered from noisy, automatic annotation of unstructured natural language corpora. Finally, I move from unstructured data and focus on structured knowledge graphs. I present novel approaches for learning embeddings of vertices and edges in a knowledge graph that obey logical constraints.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1906.05651](https://arxiv.org/abs/1906.05651)

##### PDF
[https://arxiv.org/pdf/1906.05651](https://arxiv.org/pdf/1906.05651)

