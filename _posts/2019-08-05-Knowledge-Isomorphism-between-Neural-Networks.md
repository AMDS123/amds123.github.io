---
layout: post
title: "Knowledge Isomorphism between Neural Networks"
date: 2019-08-05 12:25:37
categories: arXiv_CV
tags: arXiv_CV Knowledge
author: Ruofan Liang, Tianlin Li, Longfei Li, Quanshi Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper aims to analyze knowledge isomorphism between pre-trained deep neural networks. We propose a generic definition for knowledge isomorphism between neural networks at different fuzziness levels, and design a task-agnostic and model-agnostic method to disentangle and quantify isomorphic features from intermediate layers of a neural network. As a generic tool, our method can be broadly used for different applications. In preliminary experiments, we have used knowledge isomorphism as a tool to diagnose feature representations of neural networks. Knowledge isomorphism provides new insights to explain the success of existing deep-learning techniques, such as knowledge distillation and network compression. More crucially, it has been shown that knowledge isomorphism can also be used to refine pre-trained networks and boost performance.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.01581](http://arxiv.org/abs/1908.01581)

##### PDF
[http://arxiv.org/pdf/1908.01581](http://arxiv.org/pdf/1908.01581)

