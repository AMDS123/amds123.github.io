---
layout: post
title: "Character-Level Question Answering with Attention"
date: 2016-06-05 02:02:10
categories: arXiv_SD
tags: arXiv_SD Knowledge Attention Relation
author: David Golub, Xiaodong He
mathjax: true
---

* content
{:toc}

##### Abstract
We show that a character-level encoder-decoder framework can be successfully applied to question answering with a structured knowledge base. We use our model for single-relation question answering and demonstrate the effectiveness of our approach on the SimpleQuestions dataset (Bordes et al., 2015), where we improve state-of-the-art accuracy from 63.9% to 70.9%, without use of ensembles. Importantly, our character-level model has 16x fewer parameters than an equivalent word-level model, can be learned with significantly less data compared to previous work, which relies on data augmentation, and is robust to new entities in testing.

##### Abstract (translated by Google)
我们表明，一个字符级的编码器 - 解码器框架可以成功地应用于回答结构化知识库的问题。我们使用我们的模型进行单关系问题回答，并且证明了我们的方法在SimpleQuestions数据集上的有效性（Bordes et al。，2015），我们从63.9％提高到70.9％，而没有使用的合奏。重要的是，我们的字符级模型的参数少于等效的单词级模型的16倍，与以前的工作相比，可以获得更少的数据，这依赖于数据增强，并且对于测试中的新实体是强健的。

##### URL
[https://arxiv.org/abs/1604.00727](https://arxiv.org/abs/1604.00727)

##### PDF
[https://arxiv.org/pdf/1604.00727](https://arxiv.org/pdf/1604.00727)

