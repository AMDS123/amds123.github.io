---
layout: post
title: 'Attention-Based Models for Text-Dependent Speaker Verification'
date: 2017-10-31 15:48:14
categories: arXiv_CV
tags: arXiv_CV Image_Caption Speech_Recognition Caption RNN Recognition
author: F A Rezaur Rahman Chowdhury, Quan Wang, Ignacio Lopez Moreno, Li Wan
---

* content
{:toc}

##### Abstract
Attention-based models have recently shown great performance on a range of tasks, such as speech recognition, machine translation, and image captioning due to their ability to summarize relevant information that expands through the entire length of an input sequence. In this paper, we analyze the usage of attention mechanisms to the problem of sequence summarization in our end-to-end text-dependent speaker recognition system. We explore different topologies and their variants of the attention layer, and compare different pooling methods on the attention weights. Ultimately, we show that attention-based models can improves the Equal Error Rate (EER) of our speaker verification system by relatively 14% compared to our non-attention LSTM baseline model.

##### Abstract (translated by Google)
基于注意力的模型最近在诸如语音识别，机器翻译和图像字幕这样的一系列任务中表现出很好的性能，因为它们能够总结在输入序列的整个长度上扩展的相关信息。在本文中，我们分析了注意机制在端到端文本相关说话人识别系统中对序列汇总问题的使用。我们探索不同的关注层的拓扑结构及其变体，并比较不同的关注权重池方法。最后，我们表明基于注意力的模型与我们的非注意LSTM基线模型相比，可以将说话人验证系统的等误差率（EER）提高相对14％。

##### URL
[https://arxiv.org/abs/1710.10470](https://arxiv.org/abs/1710.10470)

