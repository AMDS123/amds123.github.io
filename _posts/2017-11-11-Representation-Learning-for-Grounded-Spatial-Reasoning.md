---
layout: post
title: "Representation Learning for Grounded Spatial Reasoning"
date: 2017-11-11 02:20:54
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning Represenation_Learning Inference
author: Michael Janner, Karthik Narasimhan, Regina Barzilay
mathjax: true
---

* content
{:toc}

##### Abstract
The interpretation of spatial references is highly contextual, requiring joint inference over both language and the environment. We consider the task of spatial reasoning in a simulated environment, where an agent can act and receive rewards. The proposed model learns a representation of the world steered by instruction text. This design allows for precise alignment of local neighborhoods with corresponding verbalizations, while also handling global references in the instructions. We train our model with reinforcement learning using a variant of generalized value iteration. The model outperforms state-of-the-art approaches on several metrics, yielding a 45% reduction in goal localization error.

##### Abstract (translated by Google)
空间参考的解释是高度上下文的，需要对语言和环境的联合推断。我们在模拟环境中考虑空间推理的任务，在这个模拟环境中，代理人可以采取行动并获得奖励。所提出的模型学习了由指导文本操纵的世界的表示。这种设计可以使当地社区与相应的语言表达精确对齐，同时也可以处理说明中的全球参考。我们使用广义值迭代的变体对强化学习进行训练。该模型在几个指标上优于最先进的方法，将目标定位误差降低45％。

##### URL
[https://arxiv.org/abs/1707.03938](https://arxiv.org/abs/1707.03938)

##### PDF
[https://arxiv.org/pdf/1707.03938](https://arxiv.org/pdf/1707.03938)

