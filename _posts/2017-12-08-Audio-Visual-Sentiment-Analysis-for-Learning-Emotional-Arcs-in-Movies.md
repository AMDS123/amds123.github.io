---
layout: post
title: "Audio-Visual Sentiment Analysis for Learning Emotional Arcs in Movies"
date: 2017-12-08 00:27:08
categories: arXiv_CL
tags: arXiv_CL Sentiment CNN Prediction
author: Eric Chu, Deb Roy
mathjax: true
---

* content
{:toc}

##### Abstract
Stories can have tremendous power -- not only useful for entertainment, they can activate our interests and mobilize our actions. The degree to which a story resonates with its audience may be in part reflected in the emotional journey it takes the audience upon. In this paper, we use machine learning methods to construct emotional arcs in movies, calculate families of arcs, and demonstrate the ability for certain arcs to predict audience engagement. The system is applied to Hollywood films and high quality shorts found on the web. We begin by using deep convolutional neural networks for audio and visual sentiment analysis. These models are trained on both new and existing large-scale datasets, after which they can be used to compute separate audio and visual emotional arcs. We then crowdsource annotations for 30-second video clips extracted from highs and lows in the arcs in order to assess the micro-level precision of the system, with precision measured in terms of agreement in polarity between the system's predictions and annotators' ratings. These annotations are also used to combine the audio and visual predictions. Next, we look at macro-level characterizations of movies by investigating whether there exist `universal shapes' of emotional arcs. In particular, we develop a clustering approach to discover distinct classes of emotional arcs. Finally, we show on a sample corpus of short web videos that certain emotional arcs are statistically significant predictors of the number of comments a video receives. These results suggest that the emotional arcs learned by our approach successfully represent macroscopic aspects of a video story that drive audience engagement. Such machine understanding could be used to predict audience reactions to video stories, ultimately improving our ability as storytellers to communicate with each other.

##### Abstract (translated by Google)
故事可以拥有巨大的力量 - 不仅对娱乐有用，还可以激发我们的兴趣，动员我们的行动。一个故事与观众产生共鸣的程度可能部分地反映在观众所感受的情感旅程中。在本文中，我们使用机器学习方法来构建电影中的情感弧线，计算弧线族，并展示某些弧线预测观众参与的能力。该系统适用于好莱坞电影和网上发现的高品质短裤。我们首先使用深度卷积神经网络进行音频​​和视觉情感分析。这些模型在新的和现有的大规模数据集上进行训练，之后可以用来计算独立的音频和视觉情绪弧。然后，我们为了评估系统的微观精确度，根据系统预测和注释者评分之间的极性一致性来测量精确度，从30秒的视频剪辑中提取30秒的视频剪辑。这些注释也用于结合音频和视觉预测。接下来，我们通过调查是否存在情感弧的“通用形状”来考察电影的宏观表征。特别是，我们开发了一种聚类方法来发现不同类型的情感弧。最后，我们在一个简短的网络视频样本集上展示，某些情感弧线是视频收到评论数量的统计显着预测因子。这些结果表明，我们的方法学习到的情感弧线成功地代表了推动观众参与的视频故事的宏观方面。这种机器的理解可以用来预测观众对视频故事的反应，最终提高我们讲故事的人彼此交流的能力。

##### URL
[https://arxiv.org/abs/1712.02896](https://arxiv.org/abs/1712.02896)

##### PDF
[https://arxiv.org/pdf/1712.02896](https://arxiv.org/pdf/1712.02896)

