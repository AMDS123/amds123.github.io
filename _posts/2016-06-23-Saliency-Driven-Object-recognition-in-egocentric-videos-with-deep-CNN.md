---
layout: post
title: "Saliency Driven Object recognition in egocentric videos with deep CNN"
date: 2016-06-23 10:10:31
categories: arXiv_CV
tags: arXiv_CV Salient Segmentation Attention CNN Recognition
author: Philippe Pérez de San Roman, Jenny Benois-Pineau, Jean-Philippe Domenger, Florent Paclet, Daniel Cataert, Aymar de Rugy
mathjax: true
---

* content
{:toc}

##### Abstract
The problem of object recognition in natural scenes has been recently successfully addressed with Deep Convolutional Neuronal Networks giving a significant break-through in recognition scores. The computational efficiency of Deep CNNs as a function of their depth, allows for their use in real-time applications. One of the key issues here is to reduce the number of windows selected from images to be submitted to a Deep CNN. This is usually solved by preliminary segmentation and selection of specific windows, having outstanding "objectiveness" or other value of indicators of possible location of objects. In this paper we propose a Deep CNN approach and the general framework for recognition of objects in a real-time scenario and in an egocentric perspective. Here the window of interest is built on the basis of visual attention map computed over gaze fixations measured by a glass-worn eye-tracker. The application of this set-up is an interactive user-friendly environment for upper-limb amputees. Vision has to help the subject to control his worn neuro-prosthesis in case of a small amount of remaining muscles when the EMG control becomes unefficient. The recognition results on a specifically recorded corpus of 151 videos with simple geometrical objects show the mAP of 64,6\% and the computational time at the generalization lower than a time of a visual fixation on the object-of-interest.

##### Abstract (translated by Google)
深层卷积神经元网络最近成功解决了自然场景中的目标识别问题，在识别分数方面取得了显着的突破。 Deep CNN作为其深度的函数的计算效率允许其在实时应用中的使用。这里的一个关键问题是减少从提交给深层CNN的图像中选择的窗口的数量。这通常通过初步分割和选择特定的窗口来解决，具有出色的“客观性”或其他可能的物体位置指示值。在本文中，我们提出了一个深入的CNN方法和实时情景识别的一般框架和以自我为中心的视角。在这里，感兴趣的窗口基于由玻璃佩戴的眼动仪测量的视线注视图计算的视觉注意力图。这种设置的应用是上肢截肢者的交互式用户友好环境。当EMG控制效率不高时，视觉必须帮助受试者控制其磨损的神经假体。对具有简单几何对象的151个视频的具体记录的语料库的识别结果显示64.6％的mAP和在泛化上的计算时间低于对关注对象的视觉固定时间。

##### URL
[https://arxiv.org/abs/1606.07256](https://arxiv.org/abs/1606.07256)

##### PDF
[https://arxiv.org/pdf/1606.07256](https://arxiv.org/pdf/1606.07256)

