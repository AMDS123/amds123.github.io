---
layout: post
title: "A Fine-to-Coarse Convolutional Neural Network for 3D Human Action Recognition"
date: 2018-08-18 08:20:52
categories: arXiv_CV
tags: arXiv_CV Action_Recognition CNN Relation Recognition
author: Thao Minh Le, Nakamasa Inoue, Koichi Shinoda
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a new framework for human action recognition from a 3D skeleton sequence. Previous studies do not fully utilize the temporal relationships between video segments in a human action. Some studies successfully used very deep Convolutional Neural Network (CNN) models but often suffer from the data insufficiency problem. In this study, we first segment a skeleton sequence into distinct temporal segments in order to exploit the correlations between them. The temporal and spatial features of a skeleton sequence are then extracted simultaneously by utilizing a fine-to-coarse (F2C) CNN architecture optimized for human skeleton sequences. We evaluate our proposed method on NTU RGB+D and SBU Kinect Interaction dataset. It achieves 79.6% and 84.6% of accuracies on NTU RGB+D with cross-object and cross-view protocol, respectively, which are almost identical with the state-of-the-art performance. In addition, our method significantly improves the accuracy of the actions in two-person interactions.

##### Abstract (translated by Google)
本文从三维骨架序列中提出了一种新的人体动作识别框架。以前的研究没有充分利用人类行为中视频片段之间的时间关系。一些研究成功地使用了非常深的卷积神经网络（CNN）模型，但经常遭遇数据不足问题。在本研究中，我们首先将骨架序列分割成不同的时间段，以便利用它们之间的相关性。然后通过利用针对人类骨骼序列优化的细 - 粗（F2C）CNN架构同时提取骨架​​序列的时间和空间特征。我们在NTU RGB + D和SBU Kinect Interaction数据集上评估我们提出的方法。它通过交叉对象和交叉视图协议分别在NTU RGB + D上实现了79.6％和84.6％的精度，这几乎与最先进的性能相同。此外，我们的方法显着提高了双人互动中行动的准确性。

##### URL
[http://arxiv.org/abs/1805.11790](http://arxiv.org/abs/1805.11790)

##### PDF
[http://arxiv.org/pdf/1805.11790](http://arxiv.org/pdf/1805.11790)

