---
layout: post
title: "Speech-Based Visual Question Answering"
date: 2017-09-16 03:43:20
categories: arXiv_CV
tags: arXiv_CV QA Speech_Recognition VQA Recognition
author: Ted Zhang, Dengxin Dai, Tinne Tuytelaars, Marie-Francine Moens, Luc Van Gool
mathjax: true
---

* content
{:toc}

##### Abstract
This paper introduces speech-based visual question answering (VQA), the task of generating an answer given an image and a spoken question. Two methods are studied: an end-to-end, deep neural network that directly uses audio waveforms as input versus a pipelined approach that performs ASR (Automatic Speech Recognition) on the question, followed by text-based visual question answering. Furthermore, we investigate the robustness of both methods by injecting various levels of noise into the spoken question and find both methods to be tolerate noise at similar levels.

##### Abstract (translated by Google)
本文介绍了基于语音的视觉问答（VQA），即给出图像和口语问题产生答案的任务。研究了两种方法：直接使用音频波形作为输入的端到端深度神经网络与在问题上执行ASR（自动语音识别）的流水线方法，然后是基于文本的视觉问题回答。此外，我们通过在语音问题中注入各种级别的噪声来研究两种方法的稳健性，并发现两种方法都能容忍相似级别的噪声。

##### URL
[https://arxiv.org/abs/1705.00464](https://arxiv.org/abs/1705.00464)

##### PDF
[https://arxiv.org/pdf/1705.00464](https://arxiv.org/pdf/1705.00464)

