---
layout: post
title: "Towards Autonomous Reinforcement Learning: Automatic Setting of Hyper-parameters using Bayesian Optimization"
date: 2018-05-12 16:42:55
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization Recognition
author: Juan Cruz Barsce, Jorge A. Palombarini, Ernesto C. Martínez
mathjax: true
---

* content
{:toc}

##### Abstract
With the increase of machine learning usage by industries and scientific communities in a variety of tasks such as text mining, image recognition and self-driving cars, automatic setting of hyper-parameter in learning algorithms is a key factor for achieving satisfactory performance regardless of user expertise in the inner workings of the techniques and methodologies. In particular, for a reinforcement learning algorithm, the efficiency of an agent learning a control policy in an uncertain environment is heavily dependent on the hyper-parameters used to balance exploration with exploitation. In this work, an autonomous learning framework that integrates Bayesian optimization with Gaussian process regression to optimize the hyper-parameters of a reinforcement learning algorithm, is proposed. Also, a bandits-based approach to achieve a balance between computational costs and decreasing uncertainty about the Q-values, is presented. A gridworld example is used to highlight how hyper-parameter configurations of a learning algorithm (SARSA) are iteratively improved based on two performance functions.

##### Abstract (translated by Google)
随着行业和科学团体在文本挖掘，图像识别和自驾车等各种任务中使用机器学习的使用量的增加，学习算法中超参数的自动设置是获得满意性能的关键因素，而不管用户在技​​术和方法的内部运作方面的专业知识。特别是，对于强化学习算法，在不确定环境中学习控制策略的代理的效率很大程度上取决于用于平衡勘探和开发的超参数。在这项工作中，提出了一种将贝叶斯优化与高斯过程回归相结合以优化强化学习算法的超参数的自主学习框架。此外，还介绍了一种基于土匪的方法来实现计算成本与降低Q值不确定性之间的平衡。 gridworld示例用于突出显示如何基于两个性能函数迭代改进学习算法（SARSA）的超参数配置。

##### URL
[https://arxiv.org/abs/1805.04748](https://arxiv.org/abs/1805.04748)

##### PDF
[https://arxiv.org/pdf/1805.04748](https://arxiv.org/pdf/1805.04748)

