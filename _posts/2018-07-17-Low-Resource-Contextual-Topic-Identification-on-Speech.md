---
layout: post
title: "Low-Resource Contextual Topic Identification on Speech"
date: 2018-07-17 04:01:06
categories: arXiv_CL
tags: arXiv_CL Attention Classification
author: Chunxi Liu, Matthew Wiesner, Shinji Watanabe, Craig Harman, Jan Trmal, Najim Dehak, Sanjeev Khudanpur
mathjax: true
---

* content
{:toc}

##### Abstract
In topic identification (topic ID) on real-world unstructured audio, an audio instance of variable topic shifts is first broken into sequential segments, and each segment is independently classified. We first present a general purpose method for topic ID on spoken segments in low-resource languages, using a cascade of universal acoustic modeling, translation lexicons to English, and English-language topic classification. Next, instead of classifying each segment independently, we demonstrate that exploring the contextual dependencies across sequential segments can provide large improvements. In particular, we propose an attention-based contextual model which is able to leverage the contexts in a selective manner. We test both our contextual and non-contextual models on four LORELEI languages, and on all but one our attention-based contextual model significantly outperforms the context-independent models.

##### Abstract (translated by Google)
在关于真实世界非结构化音频的主题识别（主题ID）中，首先将可变主题移位的音频实例分成连续的段，并且每个段被独立地分类。我们首先使用一系列通用声学建模，英语翻译词典和英语主题分类，为低资源语言中的语音片段提供主题ID的通用方法。接下来，我们不是独立地对每个段进行分类，而是展示了跨顺序段探索上下文依赖关系可以提供很大的改进。特别是，我们提出了一种基于注意力的上下文模型，它能够以选择性的方式利用上下文。我们使用四种LORELEI语言测试我们的上下文和非上下文模型，除了一种外，我们基于注意力的上下文模型明显优于上下文无关模型。

##### URL
[http://arxiv.org/abs/1807.06204](http://arxiv.org/abs/1807.06204)

##### PDF
[http://arxiv.org/pdf/1807.06204](http://arxiv.org/pdf/1807.06204)

