---
layout: post
title: "Feed-Forward Networks with Attention Can Solve Some Long-Term Memory Problems"
date: 2016-09-20 05:02:22
categories: arXiv_CV
tags: arXiv_CV Attention
author: Colin Raffel, Daniel P. W. Ellis
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a simplified model of attention which is applicable to feed-forward neural networks and demonstrate that the resulting model can solve the synthetic "addition" and "multiplication" long-term memory problems for sequence lengths which are both longer and more widely varying than the best published results for these tasks.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1512.08756](https://arxiv.org/abs/1512.08756)

##### PDF
[https://arxiv.org/pdf/1512.08756](https://arxiv.org/pdf/1512.08756)

