---
layout: post
title: "Machine Comprehension Using Match-LSTM and Answer Pointer"
date: 2016-11-07 03:39:40
categories: arXiv_CL
tags: arXiv_CL RNN
author: Shuohang Wang, Jing Jiang
mathjax: true
---

* content
{:toc}

##### Abstract
Machine comprehension of text is an important problem in natural language processing. A recently released dataset, the Stanford Question Answering Dataset (SQuAD), offers a large number of real questions and their answers created by humans through crowdsourcing. SQuAD provides a challenging testbed for evaluating machine comprehension algorithms, partly because compared with previous datasets, in SQuAD the answers do not come from a small set of candidate answers and they have variable lengths. We propose an end-to-end neural architecture for the task. The architecture is based on match-LSTM, a model we proposed previously for textual entailment, and Pointer Net, a sequence-to-sequence model proposed by Vinyals et al.(2015) to constrain the output tokens to be from the input sequences. We propose two ways of using Pointer Net for our task. Our experiments show that both of our two models substantially outperform the best results obtained by Rajpurkar et al.(2016) using logistic regression and manually crafted features.

##### Abstract (translated by Google)
机器理解文本是自然语言处理中的一个重要问题。最近发布的数据集，斯坦福问答数据集（SQUAD），提供了大量的真实问题和他们通过众包创造的答案。 SQuAD为评估机器理解算法提供了一个具有挑战性的测试平台，部分原因是与之前的数据集相比，在SQuAD中，答案不是来自一小组候选答案，而是具有不同的长度。我们为这项任务提出了一个端到端的神经架构。该体系结构基于match-LSTM（我们之前提出的用于文本包含的模型）和Pointer Net（由Vinyals等人（2015）提出的序列到序列模型）来限制输出令牌来自输入序列。我们提出两种使用指针网络的方法来完成我们的任务。我们的实验显示，我们的两个模型都大大超过了Rajpurkar等人（2016年）使用logistic回归和手工制作的特征获得的最佳结果。

##### URL
[https://arxiv.org/abs/1608.07905](https://arxiv.org/abs/1608.07905)

##### PDF
[https://arxiv.org/pdf/1608.07905](https://arxiv.org/pdf/1608.07905)

