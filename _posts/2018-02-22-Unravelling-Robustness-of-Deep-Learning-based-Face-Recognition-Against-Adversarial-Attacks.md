---
layout: post
title: "Unravelling Robustness of Deep Learning based Face Recognition Against Adversarial Attacks"
date: 2018-02-22 08:03:26
categories: arXiv_CV
tags: arXiv_CV Adversarial Face Deep_Learning Detection Recognition Face_Recognition
author: Gaurav Goswami, Nalini Ratha, Akshay Agarwal, Richa Singh, Mayank Vatsa
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural network (DNN) architecture based models have high expressive power and learning capacity. However, they are essentially a black box method since it is not easy to mathematically formulate the functions that are learned within its many layers of representation. Realizing this, many researchers have started to design methods to exploit the drawbacks of deep learning based algorithms questioning their robustness and exposing their singularities. In this paper, we attempt to unravel three aspects related to the robustness of DNNs for face recognition: (i) assessing the impact of deep architectures for face recognition in terms of vulnerabilities to attacks inspired by commonly observed distortions in the real world that are well handled by shallow learning methods along with learning based adversaries; (ii) detecting the singularities by characterizing abnormal filter response behavior in the hidden layers of deep networks; and (iii) making corrections to the processing pipeline to alleviate the problem. Our experimental evaluation using multiple open-source DNN-based face recognition networks, including OpenFace and VGG-Face, and two publicly available databases (MEDS and PaSC) demonstrates that the performance of deep learning based face recognition algorithms can suffer greatly in the presence of such distortions. The proposed method is also compared with existing detection algorithms and the results show that it is able to detect the attacks with very high accuracy by suitably designing a classifier using the response of the hidden layers in the network. Finally, we present several effective countermeasures to mitigate the impact of adversarial attacks and improve the overall robustness of DNN-based face recognition.

##### Abstract (translated by Google)
基于深度神经网络（DNN）体系结构的模型具有很高的表达能力和学习能力。但是，它们本质上是一种黑盒子方法，因为在数学表示中很难用数学公式来表达学习的函数。意识到这一点，许多研究人员已经开始设计方法来利用基于深度学习算法的缺陷，质疑它们的鲁棒性并揭示它们的奇点。在本文中，我们试图揭示与面部识别的DNNs的鲁棒性有关的三个方面：（i）评估深度架构对人脸识别的影响，就受到由现实世界中常见扭曲所引起的攻击的脆弱性而言，通过浅层学习方法和学习型对手进行处理; （ii）通过表征深层网络的隐藏层中的异常滤波器响应行为来检测奇点;和（iii）纠正处理流程以缓解问题。我们使用包括OpenFace和VGG-Face在内的多个基于开源DNN的人脸识别网络和两个公开可用的数据库（MEDS和PaSC）进行的实验评估表明，基于深度学习的人脸识别算法的性能可能在这种扭曲。所提出的方法也与现有的检测算法进行了比较，结果表明，通过使用网络中隐藏层的响应适当地设计分类器，它能够以非常高的准确度检测到攻击。最后，我们提出了几种有效的对策来减轻敌对攻击的影响，并提高基于DNN的人脸识别的整体鲁棒性。

##### URL
[http://arxiv.org/abs/1803.00401](http://arxiv.org/abs/1803.00401)

##### PDF
[http://arxiv.org/pdf/1803.00401](http://arxiv.org/pdf/1803.00401)

