---
layout: post
title: "Multimodal Hierarchical Reinforcement Learning Policy for Task-Oriented Visual Dialog"
date: 2018-05-08 19:54:47
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning
author: Jiaping Zhang, Tiancheng Zhao, Zhou Yu
mathjax: true
---

* content
{:toc}

##### Abstract
Creating an intelligent conversational system that understands vision and language is one of the ultimate goals in Artificial Intelligence (AI)~\cite{winograd1972understanding}. Extensive research has focused on vision-to-language generation, however, limited research has touched on combining these two modalities in a goal-driven dialog context. We propose a multimodal hierarchical reinforcement learning framework that dynamically integrates vision and language for task-oriented visual dialog. The framework jointly learns the multimodal dialog state representation and the hierarchical dialog policy to improve both dialog task success and efficiency. We also propose a new technique, state adaptation, to integrate context awareness in the dialog state representation. We evaluate the proposed framework and the state adaptation technique in an image guessing game and achieve promising results.

##### Abstract (translated by Google)
创建一个理解视觉和语言的智能会话系统是人工智能（AI）〜\ cite {winograd1972}理解}的最终目标之一。广泛的研究集中于视觉到语言的产生，然而，有限的研究涉及将这两种模式结合在目标驱动的对话语境中。我们提出了一种多模式分层强化学习框架，它动态集成了面向任务的视觉对话的视觉和语言。该框架共同学习多模式对话状态表示和分层对话策略，以提高对话任务的成功和效率。我们还提出了一种新的技术，即状态适应，将情境意识整合到对话状态表示中。我们在图像猜测游戏中评估所提出的框架和状态适应技术，并取得有希望的结果。

##### URL
[http://arxiv.org/abs/1805.03257](http://arxiv.org/abs/1805.03257)

##### PDF
[http://arxiv.org/pdf/1805.03257](http://arxiv.org/pdf/1805.03257)

