---
layout: post
title: "Discriminability objective for training descriptive captions"
date: 2018-03-12 17:09:26
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption
author: Ruotian Luo, Brian Price, Scott Cohen, Gregory Shakhnarovich
mathjax: true
---

* content
{:toc}

##### Abstract
One property that remains lacking in image captions generated by contemporary methods is discriminability: being able to tell two images apart given the caption for one of them. We propose a way to improve this aspect of caption generation. By incorporating into the captioning training objective a loss component directly related to ability (by a machine) to disambiguate image/caption matches, we obtain systems that produce much more discriminative caption, according to human evaluation. Remarkably, our approach leads to improvement in other aspects of generated captions, reflected by a battery of standard scores such as BLEU, SPICE etc. Our approach is modular and can be applied to a variety of model/loss combinations commonly proposed for image captioning.

##### Abstract (translated by Google)
当代方法生成的图像标题仍然缺乏一个属性，这就是可区分性：如果给出其中一个图像的标题，可以将两幅图像分开。我们提出了一种方法来改善字幕生成的这一方面。根据人类评估，通过在字幕培训目标中纳入与（通过机器）能力消除图像/字幕匹配能力直接相关的损失成分，我们获得了可产生更多歧视性字幕的系统。值得注意的是，我们的方法改善了生成字幕的其他方面，反映了一系列标准分数，如BLEU，SPICE等。我们的方法是模块化的，可以应用于通常为图像字幕提出的各种模型/损耗组合。

##### URL
[https://arxiv.org/abs/1803.04376](https://arxiv.org/abs/1803.04376)

##### PDF
[https://arxiv.org/pdf/1803.04376](https://arxiv.org/pdf/1803.04376)

