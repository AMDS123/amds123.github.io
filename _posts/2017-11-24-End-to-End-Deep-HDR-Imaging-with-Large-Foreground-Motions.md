---
layout: post
title: "End-to-End Deep HDR Imaging with Large Foreground Motions"
date: 2017-11-24 12:12:01
categories: arXiv_CV
tags: arXiv_CV Optimization Quantitative
author: Shangzhe Wu, Jiarui Xu, Yu-Wing Tai, Chi-Keung Tang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes the first end-to-end deep framework for high dynamic range (HDR) imaging of dynamic scenes with large-scale foreground motions. In state-of-the-art deep HDR imaging such as [13], the problem is formulated as an image composition problem, by first aligning input images using optical flows which are still error-prone due to occlusion and large motions. In our end-to-end approach, HDR imaging is formulated as an image translation problem and no optical flows are used. Moreover, our simple translation network can automatically hallucinate plausible HDR details in the presence of total occlusion, saturation and under-exposure, which are otherwise almost impossible to recover by conventional optimization approaches. We perform extensive qualitative and quantitative comparisons to show that our end-to-end HDR approach produces excellent results where color artifacts and geometry distortion are significantly reduced compared with existing state-ofthe-art methods.

##### Abstract (translated by Google)
本文提出了具有大规模前景运动的动态场景的高动态范围（HDR）成像的第一个端到端深度框架。在最先进的深度HDR成像中[13]，该问题被表述为图像合成问题，首先使用由于遮挡和大运动而容易出错的光流来对齐输入图像。在我们的端到端方法中，HDR成像被制定为图像转换问题，并且不使用光流。此外，我们简单的翻译网络可以在存在完全遮挡，饱和度和曝光不足的情况下自动幻化出合理的HDR细节，否则这些细节几乎不可能通过传统优化方法恢复。我们进行了大量的定性和定量比较，表明我们的端到端HDR方法在与现有技术的方法相比显着减少了色彩伪影和几何失真的情况下，可以产生出色的效果。

##### URL
[https://arxiv.org/abs/1711.08937](https://arxiv.org/abs/1711.08937)

##### PDF
[https://arxiv.org/pdf/1711.08937](https://arxiv.org/pdf/1711.08937)

