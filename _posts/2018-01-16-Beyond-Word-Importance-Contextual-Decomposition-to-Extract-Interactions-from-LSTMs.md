---
layout: post
title: "Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs"
date: 2018-01-16 19:21:48
categories: arXiv_CL
tags: arXiv_CL Sentiment RNN Prediction Relation
author: W. James Murdoch, Peter J. Liu, Bin Yu
mathjax: true
---

* content
{:toc}

##### Abstract
The driving force behind the recent success of LSTMs has been their ability to learn complex and non-linear relationships. Consequently, our inability to describe these relationships has led to LSTMs being characterized as black boxes. To this end, we introduce contextual decomposition (CD), an interpretation algorithm for analysing individual predictions made by standard LSTMs, without any changes to the underlying model. By decomposing the output of a LSTM, CD captures the contributions of combinations of words or variables to the final prediction of an LSTM. On the task of sentiment analysis with the Yelp and SST data sets, we show that CD is able to reliably identify words and phrases of contrasting sentiment, and how they are combined to yield the LSTM's final prediction. Using the phrase-level labels in SST, we also demonstrate that CD is able to successfully extract positive and negative negations from an LSTM, something which has not previously been done.

##### Abstract (translated by Google)
LSTMs最近取得成功的驱动力是他们学习复杂和非线性关系的能力。因此，我们无法描述这些关系，导致LSTM被定性为黑盒子。为此，我们引入上下文分解（CD），这是一种解释算法，用于分析由标准LSTM做出的单独预测，而不对基础模型做任何改变。通过分解LSTM的输出，CD捕获单词或变量的组合对LSTM的最终预测的贡献。在Yelp和SST数据集的情感分析任务上，我们发现CD能够可靠地识别对比情绪的词汇和短语，以及它们如何组合以产生LSTM的最终预测。使用SST中的短语级标签，我们也证明CD能够成功地从LSTM中提取正面和负面的否定，这是以前没有做过的。

##### URL
[http://arxiv.org/abs/1801.05453](http://arxiv.org/abs/1801.05453)

##### PDF
[http://arxiv.org/pdf/1801.05453](http://arxiv.org/pdf/1801.05453)

