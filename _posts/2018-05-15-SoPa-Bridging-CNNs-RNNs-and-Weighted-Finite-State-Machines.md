---
layout: post
title: "SoPa: Bridging CNNs, RNNs, and Weighted Finite-State Machines"
date: 2018-05-15 23:03:01
categories: arXiv_AI
tags: arXiv_AI Face Text_Classification CNN Represenation_Learning RNN Classification
author: Roy Schwartz, Sam Thomson, Noah A. Smith
mathjax: true
---

* content
{:toc}

##### Abstract
Recurrent and convolutional neural networks comprise two distinct families of models that have proven to be useful for encoding natural language utterances. In this paper we present SoPa, a new model that aims to bridge these two approaches. SoPa combines neural representation learning with weighted finite-state automata (WFSAs) to learn a soft version of traditional surface patterns. We show that SoPa is an extension of a one-layer CNN, and that such CNNs are equivalent to a restricted version of SoPa, and accordingly, to a restricted form of WFSA. Empirically, on three text classification tasks, SoPa is comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline, and is particularly useful in small data settings.

##### Abstract (translated by Google)
递归和卷积神经网络包括两种不同的模型族，这些模型已被证明可用于编码自然语言话语。在本文中，我们介绍SoPa，一种旨在弥合这两种方法的新模式。 SoPa将神经表达学习与加权有限状态自动机（WFSAs）相结合，以学习传统表面模式的软版本。我们证明SoPa是一个单层CNN的延伸，并且这样的CNN相当于SoPa的受限版本，因此也是WFSA的受限形式。根据经验，在三个文本分类任务中，SoPa与BiLSTM（RNN）基线和CNN基线相比可以相当或更好，并且在小数据设置中特别有用。

##### URL
[http://arxiv.org/abs/1805.06061](http://arxiv.org/abs/1805.06061)

##### PDF
[http://arxiv.org/pdf/1805.06061](http://arxiv.org/pdf/1805.06061)

