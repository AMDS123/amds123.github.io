---
layout: post
title: "Stochastic Inverse Reinforcement Learning"
date: 2019-05-21 09:29:18
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization
author: Ce Ju, Dong Eui Chang
mathjax: true
---

* content
{:toc}

##### Abstract
Inverse reinforcement learning (IRL) is an ill-posed inverse problem since expert demonstrations may infer many solutions of reward functions which is hard to recover by local search methods such as a gradient method. In this paper, we generalize the original IRL problem to recover a probability distribution for reward functions. We call such a generalized problem stochastic inverse reinforcement learning (SIRL) which is first formulated as an expectation optimization problem. We adopt the Monte Carlo expectation-maximization (MCEM) method, a global search method, to estimate the parameter of the probability distribution as the first solution to SIRL. With our approach, it is possible to observe the deep intrinsic property in IRL from a global viewpoint, and the technique achieves a considerable robust recovery performance on the classic learning environment, objectworld.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.08513](http://arxiv.org/abs/1905.08513)

##### PDF
[http://arxiv.org/pdf/1905.08513](http://arxiv.org/pdf/1905.08513)

