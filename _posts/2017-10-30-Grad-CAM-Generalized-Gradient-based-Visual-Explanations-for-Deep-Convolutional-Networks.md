---
layout: post
title: "Grad-CAM++: Generalized Gradient-based Visual Explanations for Deep Convolutional Networks"
date: 2017-10-30 16:55:43
categories: arXiv_CV
tags: arXiv_CV CNN Deep_Learning Prediction
author: Aditya Chattopadhyay, Anirban Sarkar, Prantik Howlader, Vineeth N Balasubramanian
mathjax: true
---

* content
{:toc}

##### Abstract
Over the last decade, Convolutional Neural Network (CNN) models have been highly successful in solving complex vision based problems. However, deep models are perceived as "black box" methods considering the lack of understanding of their internal functioning. There has been a significant recent interest to develop explainable deep learning models, and this paper is an effort in this direction. Building on a recently proposed method called Grad-CAM, we propose Grad-CAM++ to provide better visual explanations of CNN model predictions (when compared to Grad-CAM), in terms of better localization of objects as well as explaining occurrences of multiple objects of a class in a single image. We provide a mathematical explanation for the proposed method, Grad-CAM++, which uses a weighted combination of the positive partial derivatives of the last convolutional layer feature maps with respect to a specific class score as weights to generate a visual explanation for the class label under consideration. Our extensive experiments and evaluations, both subjective and objective, on standard datasets showed that Grad-CAM++ indeed provides better visual explanations for a given CNN architecture when compared to Grad-CAM.

##### Abstract (translated by Google)
在过去的十年中，卷积神经网络（CNN）模型在解决基于复杂视觉的问题方面取得了非常大的成功。然而，考虑到对内部功能缺乏了解，深层模型被视为“黑盒子”方法。开发可解释的深度学习模型已经引起了人们极大的兴趣，本文正是朝这个方向努力的。在最近提出的一种叫做Grad-CAM的方法的基础上，我们提出Grad-CAM ++提供更好的CNN模型预测的视觉解释（与Grad-CAM相比），更好地定位对象以及解释多个一个单一的图像类。我们为所提出的方法Grad-CAM ++提供了一个数学解释，Grad-CAM ++使用最后卷积层特征映射的正偏导数相对于特定类别分数的加权组合作为权重来生成类标签的视觉解释考虑。我们对标准数据集的主观和客观广泛的实验和评估显示，与Grad-CAM相比，Grad-CAM ++确实为给定的CNN架构提供了更好的视觉解释。

##### URL
[https://arxiv.org/abs/1710.11063](https://arxiv.org/abs/1710.11063)

##### PDF
[https://arxiv.org/pdf/1710.11063](https://arxiv.org/pdf/1710.11063)

