---
layout: post
title: "Amobee at IEST 2018: Transfer Learning from Language Models"
date: 2018-08-27 11:04:55
categories: arXiv_CL
tags: arXiv_CL Attention Transfer_Learning RNN Language_Model
author: Alon Rozental, Daniel Fleischer, Zohar Kelrich
mathjax: true
---

* content
{:toc}

##### Abstract
This paper describes the system developed at Amobee for the WASSA 2018 implicit emotions shared task (IEST). The goal of this task was to predict the emotion expressed by missing words in tweets without an explicit mention of those words. We developed an ensemble system consisting of language models together with LSTM-based networks containing a CNN attention mechanism. Our approach represents a novel use of language models (specifically trained on a large Twitter dataset) to predict and classify emotions. Our system reached 1st place with a macro $\text{F}_1$ score of 0.7145.

##### Abstract (translated by Google)
本文描述了Amobee为WASSA 2018隐式情感共享任务（IEST）开发的系统。这项任务的目标是在没有明确提及这些词的情况下预测推文中遗漏词所表达的情绪。我们开发了一个由语言模型和基于LSTM的网络组成的集合系统，该网络包含CNN注意机制。我们的方法代表了语言模型的新用途（特别是在大型Twitter数据集上训练）来预测和分类情绪。我们的系统达到了第一名，宏观$ \ text {F} _1 $得分为0.7145。

##### URL
[http://arxiv.org/abs/1808.08782](http://arxiv.org/abs/1808.08782)

##### PDF
[http://arxiv.org/pdf/1808.08782](http://arxiv.org/pdf/1808.08782)

