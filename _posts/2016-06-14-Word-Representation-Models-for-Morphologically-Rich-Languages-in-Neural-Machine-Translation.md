---
layout: post
title: "Word Representation Models for Morphologically Rich Languages in Neural Machine Translation"
date: 2016-06-14 07:04:37
categories: arXiv_CL
tags: arXiv_CL Attention
author: Ekaterina Vylomova, Trevor Cohn, Xuanli He, Gholamreza Haffari
mathjax: true
---

* content
{:toc}

##### Abstract
Dealing with the complex word forms in morphologically rich languages is an open problem in language processing, and is particularly important in translation. In contrast to most modern neural systems of translation, which discard the identity for rare words, in this paper we propose several architectures for learning word representations from character and morpheme level word decompositions. We incorporate these representations in a novel machine translation model which jointly learns word alignments and translations via a hard attention mechanism. Evaluating on translating from several morphologically rich languages into English, we show consistent improvements over strong baseline methods, of between 1 and 1.5 BLEU points.

##### Abstract (translated by Google)
处理形态丰富的语言中复杂的单词形式是语言处理中的一个公开问题，在翻译中尤为重要。与大多数现代翻译的神经系统相比，丢弃罕见词的身份，本文中我们提出了几个架构，用于学习从字符和词素水平词分解的词表示。我们将这些表示方法合并到一个新的机器翻译模型中，通过一个强硬的关注机制共同学习单词对齐和翻译。评估从几种形态丰富的语言翻译成英文，我们显示在强烈的基线方法，1至1.5 BLEU点之间的持续改进。

##### URL
[https://arxiv.org/abs/1606.04217](https://arxiv.org/abs/1606.04217)

##### PDF
[https://arxiv.org/pdf/1606.04217](https://arxiv.org/pdf/1606.04217)

