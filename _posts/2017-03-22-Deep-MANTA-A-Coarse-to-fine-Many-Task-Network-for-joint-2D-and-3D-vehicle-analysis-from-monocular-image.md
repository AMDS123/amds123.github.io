---
layout: post
title: "Deep MANTA: A Coarse-to-fine Many-Task Network for joint 2D and 3D vehicle analysis from monocular image"
date: 2017-03-22 09:03:25
categories: arXiv_CV
tags: arXiv_CV Pose_Estimation CNN Inference Detection
author: Florian Chabot, Mohamed Chaouch, Jaonary Rabarisoa, Céline Teulière, Thierry Chateau
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present a novel approach, called Deep MANTA (Deep Many-Tasks), for many-task vehicle analysis from a given image. A robust convolutional network is introduced for simultaneous vehicle detection, part localization, visibility characterization and 3D dimension estimation. Its architecture is based on a new coarse-to-fine object proposal that boosts the vehicle detection. Moreover, the Deep MANTA network is able to localize vehicle parts even if these parts are not visible. In the inference, the network's outputs are used by a real time robust pose estimation algorithm for fine orientation estimation and 3D vehicle localization. We show in experiments that our method outperforms monocular state-of-the-art approaches on vehicle detection, orientation and 3D location tasks on the very challenging KITTI benchmark.

##### Abstract (translated by Google)
在本文中，我们提出了一个新的方法，称为深的MANTA（深的多任务），从一个给定的图像多任务车辆分析。一个强大的卷积网络被引入同时车辆检测，零件定位，能见度表征和三维尺寸估计。其架构基于新的从粗到细的对象建议，可以提高车辆检测的效率。而且，即使这些零件不可见，Deep MANTA网络也能够对车辆零件进行定位。在推理中，网络的输出被实时鲁棒的姿态估计算法用于精确的方向估计和3D车辆定位。我们在实验中表明，在非常具有挑战性的KITTI基准测试中，我们的方法优于单眼状态下最先进的车辆检测方法，定位和3D定位任务。

##### URL
[https://arxiv.org/abs/1703.07570](https://arxiv.org/abs/1703.07570)

##### PDF
[https://arxiv.org/pdf/1703.07570](https://arxiv.org/pdf/1703.07570)

