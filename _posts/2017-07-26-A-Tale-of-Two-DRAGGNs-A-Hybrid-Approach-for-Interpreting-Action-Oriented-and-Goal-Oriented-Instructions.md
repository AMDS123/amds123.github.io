---
layout: post
title: "A Tale of Two DRAGGNs: A Hybrid Approach for Interpreting Action-Oriented and Goal-Oriented Instructions"
date: 2017-07-26 23:57:29
categories: arXiv_CL
tags: arXiv_CL
author: Siddharth Karamcheti, Edward C. Williams, Dilip Arumugam, Mina Rhee, Nakul Gopalan, Lawson L. S. Wong, Stefanie Tellex
mathjax: true
---

* content
{:toc}

##### Abstract
Robots operating alongside humans in diverse, stochastic environments must be able to accurately interpret natural language commands. These instructions often fall into one of two categories: those that specify a goal condition or target state, and those that specify explicit actions, or how to perform a given task. Recent approaches have used reward functions as a semantic representation of goal-based commands, which allows for the use of a state-of-the-art planner to find a policy for the given task. However, these reward functions cannot be directly used to represent action-oriented commands. We introduce a new hybrid approach, the Deep Recurrent Action-Goal Grounding Network (DRAGGN), for task grounding and execution that handles natural language from either category as input, and generalizes to unseen environments. Our robot-simulation results demonstrate that a system successfully interpreting both goal-oriented and action-oriented task specifications brings us closer to robust natural language understanding for human-robot interaction.

##### Abstract (translated by Google)
在不同的随机环境中与人类一起操作的机器人必须能够准确地解释自然语言命令。这些指令通常分为两类：指定目标条件或目标状态的指令，以及指定明确操作或者如何执行给定任务的指令。最近的方法已经使用奖励函数作为基于目标的命令的语义表示，其允许使用最先进的计划器来为给定的任务找到策略。但是，这些奖励函数不能直接用来表示面向动作的命令。我们引入了一种新的混合方式，即Deep Recurrent Action-Goal Grounding Network（DRAGGN），用于处理任一类别的自然语言作为输入的任务接地和执行，并概括为看不见的环境。我们的机器人仿真结果表明，一个系统成功地解释了目标导向和行动导向的任务规范，使我们更接近于强大的自然语言理解人机交互。

##### URL
[https://arxiv.org/abs/1707.08668](https://arxiv.org/abs/1707.08668)

##### PDF
[https://arxiv.org/pdf/1707.08668](https://arxiv.org/pdf/1707.08668)

