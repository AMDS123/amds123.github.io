---
layout: post
title: "3DFS: Deformable Dense Depth Fusion and Segmentation for Object Reconstruction from a Handheld Camera"
date: 2016-07-27 20:38:19
categories: arXiv_CV
tags: arXiv_CV Regularization Segmentation Face Quantitative
author: Tanmay Gupta, Daeyun Shin, Naren Sivagnanadasan, Derek Hoiem
mathjax: true
---

* content
{:toc}

##### Abstract
We propose an approach for 3D reconstruction and segmentation of a single object placed on a flat surface from an input video. Our approach is to perform dense depth map estimation for multiple views using a proposed objective function that preserves detail. The resulting depth maps are then fused using a proposed implicit surface function that is robust to estimation error, producing a smooth surface reconstruction of the entire scene. Finally, the object is segmented from the remaining scene using a proposed 2D-3D segmentation that incorporates image and depth cues with priors and regularization over the 3D volume and 2D segmentations. We evaluate 3D reconstructions qualitatively on our Object-Videos dataset, comparing to fusion, multiview stereo, and segmentation baselines. We also quantitatively evaluate the dense depth estimation using the RGBD Scenes V2 dataset [Henry et al. 2013] and the segmentation using keyframe annotations of the Object-Videos dataset.

##### Abstract (translated by Google)
我们提出了一种从输入视频中放置在平坦表面上的单个对象的三维重建和分割的方法。我们的方法是使用提出的保留细节的目标函数对多个视图执行密集的深度图估计。然后使用建议的隐式表面函数对得到的深度图进行融合，该表面函数对于估计误差是鲁棒的，从而产生整个场景的光滑表面重建。最后，使用建议的2D-3D分割将对象从剩余的场景中分割出来，该分割将图像和深度线索与3D体积和2D分割上的先验和正则化相结合。我们在对象视频数据集上定性评估3D重建，与融合，多视点立体和分割基线进行比较。我们还使用RGBD场景V2数据集定量评估密集深度估计[Henry et al。 2013]以及使用Object-Videos数据集的关键帧注释进行分割。

##### URL
[https://arxiv.org/abs/1606.05002](https://arxiv.org/abs/1606.05002)

##### PDF
[https://arxiv.org/pdf/1606.05002](https://arxiv.org/pdf/1606.05002)

