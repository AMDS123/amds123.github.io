---
layout: post
title: "Neural Network Acceptability Judgments"
date: 2018-05-31 13:52:06
categories: arXiv_CL
tags: arXiv_CL RNN Classification
author: Alex Warstadt, Amanpreet Singh, Samuel R. Bowman
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we explore the ability of artificial neural networks to judge the grammatical acceptability of a sentence. Machine learning research of this kind is well placed to answer important open questions about the role of prior linguistic bias in language acquisition by providing a test for the Poverty of the Stimulus Argument. In service of this goal, we introduce the Corpus of Linguistic Acceptability (CoLA), a set of 10,657 English sentences labeled as grammatical or ungrammatical by expert linguists. We train several recurrent neural networks to do binary acceptability classification. These models set a baseline for the task. Error-analysis testing the models on specific grammatical phenomena reveals that they learn some systematic grammatical generalizations like subject-verb-object word order without any grammatical supervision. We find that neural sequence models show promise on the acceptability classification task. However, human-like performance across a wide range of grammatical constructions remains far off.

##### Abstract (translated by Google)
在这项工作中，我们探讨了人工神经网络判断句子语法可接受性的能力。这种类型的机器学习研究很好地回答了关于语言偏见在语言习得中的作用的重要的开放性问题，它通过提供对刺激论争的贫困的测试。为了实现这一目标，我们引入了语言可接受性语料库（CoLA），这是一组由专业语言学家标记为语法或不合语法的10,657个英语句子。我们训练几个循环神经网络来进行二元可接受性分类。这些模型为任务设定了基准。对具体语法现象的模型进行错误分析测试表明，他们学习了一些系统的语法概括，如主语 - 动词 - 宾语词序，而没有任何语法监督。我们发现神经序列模型在可接受性分类任务上显示出前景。然而，在广泛的语法结构中类人的表现仍然遥遥无期。

##### URL
[http://arxiv.org/abs/1805.12471](http://arxiv.org/abs/1805.12471)

##### PDF
[http://arxiv.org/pdf/1805.12471](http://arxiv.org/pdf/1805.12471)

