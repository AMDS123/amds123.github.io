---
layout: post
title: "Unpaired Photo-to-Caricature Translation on Faces in the Wild"
date: 2018-07-25 01:01:15
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Face Represenation_Learning
author: Ziqiang Zheng, Wang Chao, Zhibin Yu, Nan Wang, Haiyong Zheng, Bing Zheng
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, image-to-image translation has been made much progress owing to the success of conditional Generative Adversarial Networks (cGANs). And some unpaired methods based on cycle consistency loss such as DualGAN, CycleGAN and DiscoGAN are really popular. However, it's still very challenging for translation tasks with the requirement of high-level visual information conversion, such as photo-to-caricature translation that requires satire, exaggeration, lifelikeness and artistry. We present an approach for learning to translate faces in the wild from the source photo domain to the target caricature domain with different styles, which can also be used for other high-level image-to-image translation tasks. In order to capture global structure with local statistics while translation, we design a dual pathway model with one coarse discriminator and one fine discriminator. For generator, we provide one extra perceptual loss in association with adversarial loss and cycle consistency loss to achieve representation learning for two different domains. Also the style can be learned by the auxiliary noise input. Experiments on photo-to-caricature translation of faces in the wild show considerable performance gain of our proposed method over state-of-the-art translation methods as well as its potential real applications.

##### Abstract (translated by Google)
最近，由于条件生成对抗网络（cGAN）的成功，图像到图像的翻译已取得很大进展。一些基于周期一致性丢失的不成对方法，如DualGAN，CycleGAN和DiscoGAN，真的很受欢迎。然而，对于需要高级视觉信息转换的翻译任务来说仍然非常具有挑战性，例如需要讽刺，夸张，逼真和艺术性的照片到漫画的翻译。我们提出了一种学习方法，用于学习将源照片域中的面部转换为具有不同样式的目标漫画域，这也可用于其他高级图像到图像转换任务。为了在翻译时利用本地统计数据捕获全局结构，我们设计了一个具有一个粗略鉴别器和一个精细鉴别器的双路径模型。对于发电机，我们提供一个与对抗性损失和周期一致性损失相关的额外感知损失，以实现两个不同域的表示学习。此外，可以通过辅助噪声输入来学习该风格。对野外人脸的照片到漫画的翻译实验表明，我们提出的方法相对于最先进的翻译方法及其潜在的实际应用具有相当大的性能提升。

##### URL
[http://arxiv.org/abs/1711.10735](http://arxiv.org/abs/1711.10735)

##### PDF
[http://arxiv.org/pdf/1711.10735](http://arxiv.org/pdf/1711.10735)

