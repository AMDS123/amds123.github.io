---
layout: post
title: "Fully Convolutional Attention Networks for Fine-Grained Recognition"
date: 2017-03-21 02:08:15
categories: arXiv_CV
tags: arXiv_CV Attention Reinforcement_Learning CNN Recognition
author: Xiao Liu, Tian Xia, Jiang Wang, Yi Yang, Feng Zhou, Yuanqing Lin
mathjax: true
---

* content
{:toc}

##### Abstract
Fine-grained recognition is challenging due to its subtle local inter-class differences versus large intra-class variations such as poses. A key to address this problem is to localize discriminative parts to extract pose-invariant features. However, ground-truth part annotations can be expensive to acquire. Moreover, it is hard to define parts for many fine-grained classes. This work introduces Fully Convolutional Attention Networks (FCANs), a reinforcement learning framework to optimally glimpse local discriminative regions adaptive to different fine-grained domains. Compared to previous methods, our approach enjoys three advantages: 1) the weakly-supervised reinforcement learning procedure requires no expensive part annotations; 2) the fully-convolutional architecture speeds up both training and testing; 3) the greedy reward strategy accelerates the convergence of the learning. We demonstrate the effectiveness of our method with extensive experiments on four challenging fine-grained benchmark datasets, including CUB-200-2011, Stanford Dogs, Stanford Cars and Food-101.

##### Abstract (translated by Google)
细粒度的识别是具有挑战性的，因为其微妙的本地阶层差异与诸如姿势之类的大的阶层间差异。解决这个问题的一个关键是定位判别部分来提取姿态不变的特征。然而，地面实况部分注释可能是昂贵的。此外，很难为很多细粒度的类定义部分。这项工作引入了完全卷积注意网络（FCANs），一个强化学习框架，以最佳地瞥见适应不同细粒度域的局部区分区域。与以前的方法相比，我们的方法有三个优点：1）弱监督强化学习过程不需要昂贵的部分注释; 2）全卷积架构加速了训练和测试; 3）贪婪奖励策略加速了学习的融合。我们在四个具有挑战性的细粒度基准数据集（包括CUB-200-2011，斯坦福大学的狗，斯坦福汽车和食品101）上展示了我们的方法的有效性。

##### URL
[https://arxiv.org/abs/1603.06765](https://arxiv.org/abs/1603.06765)

##### PDF
[https://arxiv.org/pdf/1603.06765](https://arxiv.org/pdf/1603.06765)

