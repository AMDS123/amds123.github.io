---
layout: post
title: "Annotation Artifacts in Natural Language Inference Data"
date: 2018-03-06 18:23:08
categories: arXiv_AI
tags: arXiv_AI Inference
author: Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel R. Bowman, Noah A. Smith
mathjax: true
---

* content
{:toc}

##### Abstract
Large-scale datasets for natural language inference are created by presenting crowd workers with a sentence (premise), and asking them to generate three new sentences (hypotheses) that it entails, contradicts, or is logically neutral with respect to. We show that, in a significant portion of such data, this protocol leaves clues that make it possible to identify the label by looking only at the hypothesis, without observing the premise. Specifically, we show that a simple text categorization model can correctly classify the hypothesis alone in about 67% of SNLI (Bowman et. al, 2015) and 53% of MultiNLI (Williams et. al, 2017). Our analysis reveals that specific linguistic phenomena such as negation and vagueness are highly correlated with certain inference classes. Our findings suggest that the success of natural language inference models to date has been overestimated, and that the task remains a hard open problem.

##### Abstract (translated by Google)
大规模的自然语言推理数据集是通过向群众工作人员提供一个句子（前提），并要求他们生成三个新句子（假设），这些句子包含，矛盾或相对于逻辑中立。我们表明，在这些数据的重要部分中，该协议留下的线索可以通过仅查看假设来识别标签，而无需观察前提。具体而言，我们表明，一个简单的文本分类模型可以在67％的SNLI（Bowman等，2015）和53％的MultiNLI（Williams等，2017）中单独正确地对假设进行分类。我们的分析表明，特定的语言现象，如否定和模糊与某些推理类高度相关。我们的研究结果表明迄今为止自然语言推理模型的成功被高估了，而且这项任务仍然是一个难以解决的问题。

##### URL
[http://arxiv.org/abs/1803.02324](http://arxiv.org/abs/1803.02324)

##### PDF
[http://arxiv.org/pdf/1803.02324](http://arxiv.org/pdf/1803.02324)

