---
layout: post
title: "Incremental Nonparametric Weighted Feature Extraction for OnlineSubspace Pattern Classification"
date: 2016-10-26 01:02:01
categories: arXiv_CV
tags: arXiv_CV Classification
author: Hamid Abrishami Moghaddam, Elaheh Raisi
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, a new online method based on nonparametric weighted feature extraction (NWFE) is proposed. NWFE was introduced to enjoy optimum characteristics of linear discriminant analysis (LDA) and nonparametric discriminant analysis (NDA) while rectifying their drawbacks. It emphasizes the points near decision boundary by putting greater weights on them and deemphasizes other points. Incremental nonparametric weighted feature extraction (INWFE) is the online version of NWFE. INWFE has advantages of NWFE method such as extracting more than L-1 features in contrast to LDA. It is independent of the class distribution and performs well in complex distributed data. The effects of outliers are reduced due to the nature of its nonparametric scatter matrix. Furthermore, it is possible to add new samples asynchronously, i.e. whenever a new sample becomes available at any given time, it can be added to the algorithm. This is useful for many real world applications since all data cannot be available in advance. This method is implemented on Gaussian and non-Gaussian multidimensional data, a number of UCI datasets and Indian Pine dataset. Results are compared with NWFE in terms of classification accuracy and execution time. For nearest neighbour classifier it shows that this technique converges to NWFE at the end of learning process. In addition, the computational complexity is reduced in comparison with NWFE in terms of execution time.

##### Abstract (translated by Google)
本文提出了一种新的基于非参数加权特征提取（NWFE）的在线方法。引入NWFE在纠正线性判别分析（LDA）和非参数判别分析（NDA）的缺点的同时，还具有最佳的特性。它强调靠近决策边界的点，加大权重，淡化其他点。增量非参数加权特征提取（INWFE）是NWFE的在线版本。与LDA相比，INWFE具有NWFE方法的优点，比如提取多于L-1的特征。它独立于类的分布，在复杂的分布式数据中表现良好。由于非参数散布矩阵的性质，异常值的影响被降低。此外，可以异步地添加新的样本，即在任何给定时间新的样本变得可用时，可以将其添加到算法中。这对许多现实世界的应用程序很有用，因为所有的数据都不能预先提供。该方法在高斯和非高斯多维数据，多个UCI数据集和印度派数据集上实现。结果与NWFE在分类准确性和执行时间方面进行比较。对于最近邻分类器来说，这表明这种技术在学习过程结束时收敛到NWFE。另外，在执行时间方面，与NWFE相比计算复杂度降低。

##### URL
[https://arxiv.org/abs/1610.08133](https://arxiv.org/abs/1610.08133)

##### PDF
[https://arxiv.org/pdf/1610.08133](https://arxiv.org/pdf/1610.08133)

