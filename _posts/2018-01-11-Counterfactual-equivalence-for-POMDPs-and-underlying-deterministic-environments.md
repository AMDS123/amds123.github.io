---
layout: post
title: "Counterfactual equivalence for POMDPs, and underlying deterministic environments"
date: 2018-01-11 12:40:59
categories: arXiv_AI
tags: arXiv_AI
author: Stuart Armstrong
mathjax: true
---

* content
{:toc}

##### Abstract
Partially Observable Markov Decision Processes (POMDPs) are rich environments often used in machine learning. But the issue of information and causal structures in POMDPs has been relatively little studied. This paper presents the concepts of equivalent and counterfactually equivalent POMDPs, where agents cannot distinguish which environment they are in though any observations and actions. It shows that any POMDP is counterfactually equivalent, for any finite number of turns, to a deterministic POMDP with all uncertainty concentrated into the initial state. This allows a better understanding of POMDP uncertainty, information, and learning.

##### Abstract (translated by Google)
部分可观测马尔可夫决策过程（POMDP）是机器学习中经常使用的丰富环境。但是，POMDPs中的信息和因果结构问题研究相对较少。本文介绍了等价和反事实上等价的POMDP的概念，其中主体不能通过任何观察和行动来区分它们在哪个环境中。它表明任何POMDP对于任何有限数量的匝数都是反向等价的，对于所有不确定性集中在初始状态的确定性POMDP。这可以更好地理解POMDP的不确定性，信息和学习。

##### URL
[http://arxiv.org/abs/1801.03737](http://arxiv.org/abs/1801.03737)

##### PDF
[http://arxiv.org/pdf/1801.03737](http://arxiv.org/pdf/1801.03737)

