---
layout: post
title: "Learning to Count Objects in Natural Images for Visual Question Answering"
date: 2018-02-15 21:16:59
categories: arXiv_CV
tags: arXiv_CV QA Attention VQA
author: Yan Zhang, Jonathon Hare, Adam Prügel-Bennett
mathjax: true
---

* content
{:toc}

##### Abstract
Visual Question Answering (VQA) models have struggled with counting objects in natural images so far. We identify a fundamental problem due to soft attention in these models as a cause. To circumvent this problem, we propose a neural network component that allows robust counting from object proposals. Experiments on a toy task show the effectiveness of this component and we obtain state-of-the-art accuracy on the number category of the VQA v2 dataset without negatively affecting other categories, even outperforming ensemble models with our single model. On a difficult balanced pair metric, the component gives a substantial improvement in counting over a strong baseline by 6.6%.

##### Abstract (translated by Google)
到目前为止，视觉问答（VQA）模型一直在努力计算自然图像中的对象。由于这些模型中的软关注作为原因，我们确定了一个基本问题。为了避免这个问题，我们提出了一个神经网络组件，它允许从对象提议中进行可靠的计数。玩具任务的实验显示了该组件的有效性，我们在VQA v2数据集的数字类别上获得了最先进的准确性，而不会对其他类别产生负面影响，甚至超越了我们单一模型的集合模型。在一个困难的平衡配对指标上，该组成部分在强基线计数上提供了6.6％的实质性改进。

##### URL
[https://arxiv.org/abs/1802.05766](https://arxiv.org/abs/1802.05766)

##### PDF
[https://arxiv.org/pdf/1802.05766](https://arxiv.org/pdf/1802.05766)

