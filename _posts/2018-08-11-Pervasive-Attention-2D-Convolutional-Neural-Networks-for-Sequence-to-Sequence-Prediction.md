---
layout: post
title: "Pervasive Attention: 2D Convolutional Neural Networks for Sequence-to-Sequence Prediction"
date: 2018-08-11 21:23:24
categories: arXiv_CL
tags: arXiv_CL Attention Face CNN Prediction
author: Maha Elbayad, Laurent Besacier, Jakob Verbeek
mathjax: true
---

* content
{:toc}

##### Abstract
Current state-of-the-art machine translation systems are based on encoder-decoder architectures, that first encode the input sequence, and then generate an output sequence based on the input encoding. Both are interfaced with an attention mechanism that recombines a fixed encoding of the source tokens based on the decoder state. We propose an alternative approach which instead relies on a single 2D convolutional neural network across both sequences. Each layer of our network re-codes source tokens on the basis of the output sequence produced so far. Attention-like properties are therefore pervasive throughout the network. Our model yields excellent results, outperforming state-of-the-art encoder-decoder systems, while being conceptually simpler and having fewer parameters.

##### Abstract (translated by Google)
当前最先进的机器翻译系统基于编码器 - 解码器架构，其首先对输入序列进行编码，然后基于输入编码生成输出序列。两者都与注意机制接口，该注意机制基于解码器状态重新组合源令牌的固定编码。我们提出了一种替代方法，它依赖于跨两个序列的单个2D卷积神经网络。我们网络的每一层都根据目前产生的输出序列重新编码源令牌。因此，类似注意力的属性在整个网络中普遍存在。我们的模型产生了出色的结果，优于最先进的编码器 - 解码器系统，同时在概念上更简单，参数更少。

##### URL
[http://arxiv.org/abs/1808.03867](http://arxiv.org/abs/1808.03867)

##### PDF
[http://arxiv.org/pdf/1808.03867](http://arxiv.org/pdf/1808.03867)

