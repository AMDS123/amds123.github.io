---
layout: post
title: "Visualizing Residual Networks"
date: 2017-01-09 21:42:46
categories: arXiv_CV
tags: arXiv_CV
author: Brian Chu, Daylen Yang, Ravi Tadinada
mathjax: true
---

* content
{:toc}

##### Abstract
Residual networks are the current state of the art on ImageNet. Similar work in the direction of utilizing shortcut connections has been done extremely recently with derivatives of residual networks and with highway networks. This work potentially challenges our understanding that CNNs learn layers of local features that are followed by increasingly global features. Through qualitative visualization and empirical analysis, we explore the purpose that residual skip connections serve. Our assessments show that the residual shortcut connections force layers to refine features, as expected. We also provide alternate visualizations that confirm that residual networks learn what is already intuitively known about CNNs in general.

##### Abstract (translated by Google)
残余网络是ImageNet上的最新技术。最近在残余网络的衍生物和高速公路网络方面进行了类似的利用快捷连接方向的工作。这项工作可能会挑战我们的理解，即有线电视新闻网学习的是随着日益全球化的特点而产生的局部特征。通过定性的可视化和实证分析，我们探索了残差跳跃连接服务的目的。我们的评估显示，剩余的快捷方式连接强制图层按预期改进功能。我们还提供备用可视化，以确认残留网络通常可以直观地了解CNN的情况。

##### URL
[https://arxiv.org/abs/1701.02362](https://arxiv.org/abs/1701.02362)

##### PDF
[https://arxiv.org/pdf/1701.02362](https://arxiv.org/pdf/1701.02362)

