---
layout: post
title: "Unsupervised Video-to-Video Translation"
date: 2018-06-10 18:18:26
categories: arXiv_CV
tags: arXiv_CV Segmentation
author: Dina Bashkirova, Ben Usman, Kate Saenko
mathjax: true
---

* content
{:toc}

##### Abstract
Unsupervised image-to-image translation is a recently proposed task of translating an image to a different style or domain given only unpaired image examples at training time. In this paper, we formulate a new task of unsupervised video-to-video translation, which poses its own unique challenges. Translating video implies learning not only the appearance of objects and scenes but also realistic motion and transitions between consecutive frames.We investigate the performance of per-frame video-to-video translation using existing image-to-image translation networks, and propose a spatio-temporal 3D translator as an alternative solution to this problem. We evaluate our 3D method on multiple synthetic datasets, such as moving colorized digits, as well as the realistic segmentation-to-video GTA dataset and a new CT-to-MRI volumetric images translation dataset. Our results show that frame-wise translation produces realistic results on a single frame level but underperforms significantly on the scale of the whole video compared to our three-dimensional translation approach, which is better able to learn the complex structure of video and motion and continuity of object appearance.

##### Abstract (translated by Google)
无监督的图像到图像转换是最近提出的将图像翻译为不同样式或域的任务，只给出在训练时间不成对的图像示例。在本文中，我们制定了无监督的视频 - 视频翻译的新任务，这带来了自己独特的挑战。翻译视频意味着不仅学习物体和场景的外观，而且学习连续帧之间的逼真运动和过渡。我们研究使用现有的图像到图像翻译网络进行每帧视频到视频翻译的性能，并提出一个空间时间三维翻译作为这个问题的替代解决方案。我们在多种合成数据集上评估我们的3D方法，如移动彩色数字，以及实际的分段到视频GTA数据集和一个新的CT到MRI体积图像平移数据集。我们的研究结果表明，与三维翻译方法相比，逐帧翻译在单帧水平上产生了真实的结果，但是与整个视频的尺度相比，它的表现明显不足，这更好地学习了视频和运动的复杂结构以及连续性物体外观。

##### URL
[http://arxiv.org/abs/1806.03698](http://arxiv.org/abs/1806.03698)

##### PDF
[http://arxiv.org/pdf/1806.03698](http://arxiv.org/pdf/1806.03698)

