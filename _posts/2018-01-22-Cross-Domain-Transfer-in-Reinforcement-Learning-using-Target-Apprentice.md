---
layout: post
title: "Cross-Domain Transfer in Reinforcement Learning using Target Apprentice"
date: 2018-01-22 00:39:19
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Transfer_Learning
author: Girish Joshi, Girish Chowdhary
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present a new approach to Transfer Learning (TL) in Reinforcement Learning (RL) for cross-domain tasks. Many of the available techniques approach the transfer architecture as a method of speeding up the target task learning. We propose to adapt and reuse the mapped source task optimal-policy directly in related domains. We show the optimal policy from a related source task can be near optimal in target domain provided an adaptive policy accounts for the model error between target and source. The main benefit of this policy augmentation is generalizing policies across multiple related domains without having to re-learn the new tasks. Our results show that this architecture leads to better sample efficiency in the transfer, reducing sample complexity of target task learning to target apprentice learning.

##### Abstract (translated by Google)
在本文中，我们提出了一种跨学科任务的强化学习（RL）中的转移学习（TL）的新方法。许多可用的技术将转移架构作为加速目标任务学习的方法。我们建议直接在相关域中调整和重用映射的源任务最优策略。我们展示了一个相关的源任务的最优策略可以在目标域中接近最优，提供一个自适应策略来解决目标和源之间的模型错误。这种政策增强的主要好处是在多个相关领域推广政策，而不必重新学习新的任务。我们的研究结果表明，这种架构导致更好的转移样本效率，减少目标任务学习样本的复杂性，目标学徒学习。

##### URL
[https://arxiv.org/abs/1801.06920](https://arxiv.org/abs/1801.06920)

##### PDF
[https://arxiv.org/pdf/1801.06920](https://arxiv.org/pdf/1801.06920)

