---
layout: post
title: "A Collaborative Computer Aided Diagnosis System with Eye-Tracking, Sparse Attentional Model, and Deep Learning"
date: 2018-02-17 17:20:50
categories: arXiv_CV
tags: arXiv_CV Sparse Attention Face Tracking Deep_Learning Quantitative
author: Naji Khosravan, Haydar Celik, Baris Turkbey, Elizabeth Jones, Bradford Wood, Ulas Bagci
mathjax: true
---

* content
{:toc}

##### Abstract
There are at least two categories of errors in radiology screening that can lead to suboptimal diagnostic decisions and interventions:(i)human fallibility and (ii)complexity of visual search. Computer aided diagnostic (CAD) tools are developed to help radiologists to compensate for some of these errors. However, despite their significant improvements over conventional screening strategies, most CAD systems do not go beyond their use as second opinion tools due to producing a high number of false positives, which human interpreters need to correct. In parallel with efforts in computerized analysis of radiology scans, several researchers have examined behaviors of radiologists while screening medical images to better understand how and why they miss tumors, how they interact with the information in an image, and how they search for unknown pathology in the images. Eye-tracking tools have been instrumental in exploring answers to these fundamental questions. In this paper, we aim to develop a paradigm shift CAD system, called collaborative CAD (C-CAD), that unifies both of the above mentioned research lines: CAD and eye-tracking. We design an eye-tracking interface providing radiologists with a real radiology reading room experience. Then, we propose a novel algorithm that unifies eye-tracking data and a CAD system. Specifically, we present a new graph based clustering and sparsification algorithm to transform eye-tracking data (gaze) into a signal model to interpret gaze patterns quantitatively and qualitatively. The proposed C-CAD collaborates with radiologists via eye-tracking technology and helps them to improve diagnostic decisions. The C-CAD learns radiologists' search efficiency by processing their gaze patterns. To do this, the C-CAD uses a deep learning algorithm in a newly designed multi-task learning platform to segment and diagnose cancers simultaneously.

##### Abstract (translated by Google)
放射线筛查中至少有两类错误可导致次最佳的诊断决策和干预：（i）人为错误和（ii）视觉搜索的复杂性。开发计算机辅助诊断（CAD）工具来帮助放射科医师弥补其中的一些错误。然而，尽管与传统的筛查策略相比，它们有显着的改进，但大多数CAD系统并没有超出其作为第二意见工具的使用范围，因为产生了大量的误报，人类解释者需要纠正。与放射科扫描计算机化分析的努力同时，一些研究人员在放射科医师筛查医学图像的过程中进行了检查，以更好地了解他们错过肿瘤的方式和原因，他们如何与图像中的信息进行交互，以及他们如何寻找未知病理图像。眼动追踪工具有助于探索这些基本问题的答案。在本文中，我们的目标是开发一种称为协同CAD（C-CAD）的范式转换CAD系统，该系统统一了上述研究方向：CAD和眼睛跟踪。我们设计了一个眼睛跟踪界面，为放射科医生提供真正的放射学阅览室体验。然后，我们提出了一种统一眼动数据和CAD系统的新算法。具体而言，我们提出了一种新的基于图形的聚类和稀疏算法，将眼动数据（凝视）转换为信号模型，以定量和定性地解释凝视模式。提议的C-CAD通过眼动追踪技术与放射科医生合作，帮助他们改进诊断决策。 C-CAD通过处理他们的注视模式来学习放射科医师的搜索效率。为此，C-CAD在新设计的多任务学习平台中使用深度学习算法来同时分割和诊断癌症。

##### URL
[http://arxiv.org/abs/1802.06260](http://arxiv.org/abs/1802.06260)

##### PDF
[http://arxiv.org/pdf/1802.06260](http://arxiv.org/pdf/1802.06260)

