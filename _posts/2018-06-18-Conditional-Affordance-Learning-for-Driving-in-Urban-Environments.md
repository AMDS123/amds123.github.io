---
layout: post
title: "Conditional Affordance Learning for Driving in Urban Environments"
date: 2018-06-18 04:31:46
categories: arXiv_RO
tags: arXiv_RO
author: Axel Sauer, Nikolay Savinov, Andreas Geiger
mathjax: true
---

* content
{:toc}

##### Abstract
Most existing approaches to autonomous driving fall into one of two categories: modular pipelines, that build an extensive model of the environment, and imitation learning approaches, that map images directly to control outputs. A recently proposed third paradigm, direct perception, aims to combine the advantages of both by using a neural network to learn appropriate low-dimensional intermediate representations. However, existing direct perception approaches are restricted to simple highway situations, lacking the ability to navigate intersections, stop at traffic lights or respect speed limits. In this work, we propose a direct perception approach which maps video input to intermediate representations suitable for autonomous navigation in complex urban environments given high-level directional inputs. Compared to state-of-the-art reinforcement and conditional imitation learning approaches, we achieve an improvement of up to 68 % in goal-directed navigation on the challenging CARLA simulation benchmark. In addition, our approach is the first to handle traffic lights, speed signs and smooth car-following, resulting in a significant reduction of traffic accidents.

##### Abstract (translated by Google)
大多数现有的自主驾驶方法分为两类：模块化管线，建立广泛的环境模型，以及模仿学习方法，它们将图像直接映射到控制输出。最近提出的第三种范例，直接感知，旨在通过使用神经网络来学习适当的低维中间表示来结合两者的优点。然而，现有的直接感知方法仅限于简单的高速公路情况，缺乏导航交叉路口的能力，停在交通灯或关注速度限制的能力。在这项工作中，我们提出了一种直接感知方法，该方法将视频输入映射到适合在复杂城市环境中进行自主导航的中间表示，从而提供高级定向输入。与最先进的强化和条件模仿学习方法相比，我们在具有挑战性的CARLA模拟基准测试中的目标导航导航上实现了高达68％的改进。另外，我们的方法是首先处理交通信号灯，速度信号和平稳跟车，从而显着减少交通事故。

##### URL
[http://arxiv.org/abs/1806.06498](http://arxiv.org/abs/1806.06498)

##### PDF
[http://arxiv.org/pdf/1806.06498](http://arxiv.org/pdf/1806.06498)

