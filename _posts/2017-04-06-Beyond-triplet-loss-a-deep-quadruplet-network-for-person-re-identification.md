---
layout: post
title: "Beyond triplet loss: a deep quadruplet network for person re-identification"
date: 2017-04-06 06:09:55
categories: arXiv_CV
tags: arXiv_CV Re-identification Attention Person_Re-identification Deep_Learning
author: Weihua Chen, Xiaotang Chen, Jianguo Zhang, Kaiqi Huang
mathjax: true
---

* content
{:toc}

##### Abstract
Person re-identification (ReID) is an important task in wide area video surveillance which focuses on identifying people across different cameras. Recently, deep learning networks with a triplet loss become a common framework for person ReID. However, the triplet loss pays main attentions on obtaining correct orders on the training set. It still suffers from a weaker generalization capability from the training set to the testing set, thus resulting in inferior performance. In this paper, we design a quadruplet loss, which can lead to the model output with a larger inter-class variation and a smaller intra-class variation compared to the triplet loss. As a result, our model has a better generalization ability and can achieve a higher performance on the testing set. In particular, a quadruplet deep network using a margin-based online hard negative mining is proposed based on the quadruplet loss for the person ReID. In extensive experiments, the proposed network outperforms most of the state-of-the-art algorithms on representative datasets which clearly demonstrates the effectiveness of our proposed method.

##### Abstract (translated by Google)
人员重新识别（ReID）是广域视频监控中的一项重要任务，其重点是识别不同摄像机之间的人员。最近，具有三重损失的深度学习网络成为人ReID的通用框架。然而，在训练集上获得正确的命令，三重损失是主要关注的。从训练集到测试集仍然具有较弱的泛化能力，导致性能较差。在本文中，我们设计了一个四重损失，与三重损失相比，可以导致模型输出具有较大的类间变化和较小的类内变化。因此，我们的模型具有更好的泛化能力，可以在测试集上获得更高的性能。具体而言，基于人ReID的四联体损失，提出了使用基于边缘的在线硬阴性挖掘的四联体深度网络。在广泛的实验中，所提出的网络胜过了大多数在代表性数据集上的最先进的算法，这清楚地证明了我们提出的方法的有效性。

##### URL
[https://arxiv.org/abs/1704.01719](https://arxiv.org/abs/1704.01719)

##### PDF
[https://arxiv.org/pdf/1704.01719](https://arxiv.org/pdf/1704.01719)

