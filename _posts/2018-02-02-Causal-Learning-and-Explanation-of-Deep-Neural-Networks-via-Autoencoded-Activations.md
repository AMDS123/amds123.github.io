---
layout: post
title: "Causal Learning and Explanation of Deep Neural Networks via Autoencoded Activations"
date: 2018-02-02 02:24:24
categories: arXiv_AI
tags: arXiv_AI Salient Image_Classification Classification Prediction
author: Michael Harradon, Jeff Druce, Brian Ruttenberg
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks are complex and opaque. As they enter application in a variety of important and safety critical domains, users seek methods to explain their output predictions. We develop an approach to explaining deep neural networks by constructing causal models on salient concepts contained in a CNN. We develop methods to extract salient concepts throughout a target network by using autoencoders trained to extract human-understandable representations of network activations. We then build a bayesian causal model using these extracted concepts as variables in order to explain image classification. Finally, we use this causal model to identify and visualize features with significant causal influence on final classification.

##### Abstract (translated by Google)
深度神经网络复杂而不透明。当他们进入各种重要和安全关键领域的应用，用户寻求解释他们的输出预测的方法。我们通过构建CNN中包含的显着概念的因果模型来开发解释深度神经网络的方法。我们开发了一些方法，通过使用经过训练的自动编码器提取网络激活的人类可理解的表示来提取整个目标网络中的显着概念。然后，我们建立一个贝叶斯因果模型使用这些提取的概念作为变量，以解释图像分类。最后，我们使用这个因果模型来识别和可视化对最终分类具有显着的因果影响的特征。

##### URL
[https://arxiv.org/abs/1802.00541](https://arxiv.org/abs/1802.00541)

##### PDF
[https://arxiv.org/pdf/1802.00541](https://arxiv.org/pdf/1802.00541)

