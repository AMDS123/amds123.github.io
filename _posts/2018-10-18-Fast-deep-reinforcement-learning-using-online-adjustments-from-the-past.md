---
layout: post
title: "Fast deep reinforcement learning using online adjustments from the past"
date: 2018-10-18 17:00:20
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Steven Hansen, Pablo Sprechmann, Alexander Pritzel, Andr√© Barreto, Charles Blundell
mathjax: true
---

* content
{:toc}

##### Abstract
We propose Ephemeral Value Adjusments (EVA): a means of allowing deep reinforcement learning agents to rapidly adapt to experience in their replay buffer. EVA shifts the value predicted by a neural network with an estimate of the value function found by planning over experience tuples from the replay buffer near the current state. EVA combines a number of recent ideas around combining episodic memory-like structures into reinforcement learning agents: slot-based storage, content-based retrieval, and memory-based planning. We show that EVAis performant on a demonstration task and Atari games.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1810.08163](https://arxiv.org/abs/1810.08163)

##### PDF
[https://arxiv.org/pdf/1810.08163](https://arxiv.org/pdf/1810.08163)

