---
layout: post
title: "Visually Indicated Sounds"
date: 2016-04-30 03:03:04
categories: arXiv_CV
tags: arXiv_CV
author: Andrew Owens, Phillip Isola, Josh McDermott, Antonio Torralba, Edward H. Adelson, William T. Freeman
mathjax: true
---

* content
{:toc}

##### Abstract
Objects make distinctive sounds when they are hit or scratched. These sounds reveal aspects of an object's material properties, as well as the actions that produced them. In this paper, we propose the task of predicting what sound an object makes when struck as a way of studying physical interactions within a visual scene. We present an algorithm that synthesizes sound from silent videos of people hitting and scratching objects with a drumstick. This algorithm uses a recurrent neural network to predict sound features from videos and then produces a waveform from these features with an example-based synthesis procedure. We show that the sounds predicted by our model are realistic enough to fool participants in a "real or fake" psychophysical experiment, and that they convey significant information about material properties and physical interactions.

##### Abstract (translated by Google)
物体被撞击或划伤时会发出鲜明的声音。这些声音揭示了一个物体的物质属性的方面，以及产生它们的行为。在本文中，我们提出了预测一个物体在视觉场景中作为一种研究物理相互作用的方式所产生的声音的任务。我们提出了一种算法，它可以合成人们用鼓棒击打和抓物体的无声视频中的声音。该算法使用循环神经网络来预测来自视频的声音特征，然后利用基于示例的合成过程从这些特征产生波形。我们表明，我们的模型预测的声音是足够现实的，以愚弄参与者在“真实或假的”心理物理实验，并传达有关材料属性和物理相互作用的重要信息。

##### URL
[https://arxiv.org/abs/1512.08512](https://arxiv.org/abs/1512.08512)

##### PDF
[https://arxiv.org/pdf/1512.08512](https://arxiv.org/pdf/1512.08512)

