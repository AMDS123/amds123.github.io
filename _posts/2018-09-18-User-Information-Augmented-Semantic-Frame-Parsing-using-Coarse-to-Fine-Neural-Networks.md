---
layout: post
title: "User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks"
date: 2018-09-18 07:08:59
categories: arXiv_CL
tags: arXiv_CL Knowledge Detection
author: Yilin Shen, Xiangyu Zeng, Yu Wang, Hongxia Jin
mathjax: true
---

* content
{:toc}

##### Abstract
Semantic frame parsing is a crucial component in spoken language understanding (SLU) to build spoken dialog systems. It has two main tasks: intent detection and slot filling. Although state-of-the-art approaches showed good results, they require large annotated training data and long training time. In this paper, we aim to alleviate these drawbacks for semantic frame parsing by utilizing the ubiquitous user information. We design a novel coarse-to-fine deep neural network model to incorporate prior knowledge of user information intermediately to better and quickly train a semantic frame parser. Due to the lack of benchmark dataset with real user information, we synthesize the simplest type of user information (location and time) on ATIS benchmark data. The results show that our approach leverages such simple user information to outperform state-of-the-art approaches by 0.25% for intent detection and 0.31% for slot filling using standard training data. When using smaller training data, the performance improvement on intent detection and slot filling reaches up to 1.35% and 1.20% respectively. We also show that our approach can achieve similar performance as state-of-the-art approaches by using less than 80% annotated training data. Moreover, the training time to achieve the similar performance is also reduced by over 60%.

##### Abstract (translated by Google)
语义框架解析是口语理解（SLU）中构建口语对话系统的关键组成部分。它有两个主要任务：意图检测和插槽填充。尽管最先进的方法显示出良好的结果，但它们需要大量注释的训练数据和长的训练时间。在本文中，我们旨在通过利用普遍存在的用户信息来减轻语义帧解析的这些缺点。我们设计了一种新颖的粗到细深度神经网络模型，以中间地结合用户信息的先验知识，以更好地和快速地训练语义帧解析器。由于缺少具有真实用户信息的基准数据集，我们在ATIS基准数据上综合了最简单类型的用户信息（位置和时间）。结果表明，我们的方法利用这些简单的用户信息，使用标准训练数据，在目标检测方面优于最先进的方法0.25％，在插槽填充方面优于0.31％。使用较小的训练数据时，意图检测和插槽填充的性能改进分别达到1.35％和1.20％。我们还表明，通过使用少于80％的带注释的训练数据，我们的方法可以实现与最先进方法类似的性能。此外，实现类似性能的培训时间也减少了60％以上。

##### URL
[http://arxiv.org/abs/1809.06559](http://arxiv.org/abs/1809.06559)

##### PDF
[http://arxiv.org/pdf/1809.06559](http://arxiv.org/pdf/1809.06559)

