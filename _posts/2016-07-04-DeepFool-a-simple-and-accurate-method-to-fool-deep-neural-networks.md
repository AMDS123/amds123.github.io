---
layout: post
title: "DeepFool: a simple and accurate method to fool deep neural networks"
date: 2016-07-04 04:49:44
categories: arXiv_CV
tags: arXiv_CV Adversarial Image_Classification Classification
author: Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard
mathjax: true
---

* content
{:toc}

##### Abstract
State-of-the-art deep neural networks have achieved impressive results on many image classification tasks. However, these same architectures have been shown to be unstable to small, well sought, perturbations of the images. Despite the importance of this phenomenon, no effective methods have been proposed to accurately compute the robustness of state-of-the-art deep classifiers to such perturbations on large-scale datasets. In this paper, we fill this gap and propose the DeepFool algorithm to efficiently compute perturbations that fool deep networks, and thus reliably quantify the robustness of these classifiers. Extensive experimental results show that our approach outperforms recent methods in the task of computing adversarial perturbations and making classifiers more robust.

##### Abstract (translated by Google)
最先进的深度神经网络在许多图像分类任务中取得了令人印象深刻的结果。然而，这些相同的架构已被证明是不稳定的小图像，寻求好的扰动。尽管这种现象十分重要，但是还没有提出有效的方法来准确地计算最先进的深度分类器对大规模数据集上这种干扰的鲁棒性。在本文中，我们填补了这个空白，并提出DeepFool算法来有效计算愚弄深度网络的扰动，从而可靠地量化这些分类器的鲁棒性。广泛的实验结果表明，我们的方法在计算对抗性扰动和使分类器更健壮的任务方面胜过了最近的方法。

##### URL
[https://arxiv.org/abs/1511.04599](https://arxiv.org/abs/1511.04599)

##### PDF
[https://arxiv.org/pdf/1511.04599](https://arxiv.org/pdf/1511.04599)

