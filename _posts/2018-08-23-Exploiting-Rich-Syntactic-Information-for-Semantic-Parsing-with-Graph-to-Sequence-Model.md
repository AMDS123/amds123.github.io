---
layout: post
title: "Exploiting Rich Syntactic Information for Semantic Parsing with Graph-to-Sequence Model"
date: 2018-08-23 03:58:21
categories: arXiv_AI
tags: arXiv_AI Adversarial RNN
author: Kun Xu, Lingfei Wu, Zhiguo Wang, Mo Yu, Liwei Chen, Vadim Sheinin
mathjax: true
---

* content
{:toc}

##### Abstract
Existing neural semantic parsers mainly utilize a sequence encoder, i.e., a sequential LSTM, to extract word order features while neglecting other valuable syntactic information such as dependency graph or constituent trees. In this paper, we first propose to use the \textit{syntactic graph} to represent three types of syntactic information, i.e., word order, dependency and constituency features. We further employ a graph-to-sequence model to encode the syntactic graph and decode a logical form. Experimental results on benchmark datasets show that our model is comparable to the state-of-the-art on Jobs640, ATIS and Geo880. Experimental results on adversarial examples demonstrate the robustness of the model is also improved by encoding more syntactic information.

##### Abstract (translated by Google)
现有的神经语义解析器主要利用序列编码器，即顺序LSTM，来提取单词顺序特征，同时忽略其他有价值的句法信息，例如依赖图或组成树。在本文中，我们首先提出使用\ textit {语法图}来表示三种类型的句法信息，即词序，依赖和选区特征。我们进一步采用图形到序列模型来编码句法图并解码逻辑形式。基准数据集的实验结果表明，我们的模型与Jobs640，ATIS和Geo880的最新技术相当。对抗性实例的实验结果表明，通过编码更多的句法信息，也可以提高模型的鲁棒性。

##### URL
[http://arxiv.org/abs/1808.07624](http://arxiv.org/abs/1808.07624)

##### PDF
[http://arxiv.org/pdf/1808.07624](http://arxiv.org/pdf/1808.07624)

