---
layout: post
title: "Residual Squeeze VGG16"
date: 2017-05-05 23:46:26
categories: arXiv_CV
tags: arXiv_CV Object_Detection Segmentation CNN Image_Classification Classification Deep_Learning Detection
author: Hussam Qassim, David Feinzimer, Abhishek Verma
mathjax: true
---

* content
{:toc}

##### Abstract
Deep learning has given way to a new era of machine learning, apart from computer vision. Convolutional neural networks have been implemented in image classification, segmentation and object detection. Despite recent advancements, we are still in the very early stages and have yet to settle on best practices for network architecture in terms of deep design, small in size and a short training time. In this work, we propose a very deep neural network comprised of 16 Convolutional layers compressed with the Fire Module adapted from the SQUEEZENET model. We also call for the addition of residual connections to help suppress degradation. This model can be implemented on almost every neural network model with fully incorporated residual learning. This proposed model Residual-Squeeze-VGG16 (ResSquVGG16) trained on the large-scale MIT Places365-Standard scene dataset. In our tests, the model performed with accuracy similar to the pre-trained VGG16 model in Top-1 and Top-5 validation accuracy while also enjoying a 23.86% reduction in training time and an 88.4% reduction in size. In our tests, this model was trained from scratch.

##### Abstract (translated by Google)
除了计算机视觉之外，深度学习已经让位于机器学习的新时代。卷积神经网络已经在图像分类，分割和对象检测中得到应用。尽管最近取得了一些进展，但我们仍然处于早期阶段，尚未就网络架构的深入设计，规模小和训练时间等方面进行最佳实践。在这项工作中，我们提出了一个非常深的神经网络，由16个卷积层组成，用SQUEEZENET模型改编的火灾模块进行压缩。我们还呼吁增加残余连接来帮助抑制退化。这个模型可以在几乎每个神经网络模型上实现，并且完全结合了剩余学习。这个建议的模型Residual-Squeeze-VGG16（ResSquVGG16）在大型MIT Places365标准场景数据集上训练。在我们的测试中，该模型的精度类似于预训练的VGG16模型的Top-1和Top-5验证准确度，同时还可以减少23.86％的训练时间和减少88.4％的体积。在我们的测试中，这个模型是从零开始训练的。

##### URL
[https://arxiv.org/abs/1705.03004](https://arxiv.org/abs/1705.03004)

##### PDF
[https://arxiv.org/pdf/1705.03004](https://arxiv.org/pdf/1705.03004)

