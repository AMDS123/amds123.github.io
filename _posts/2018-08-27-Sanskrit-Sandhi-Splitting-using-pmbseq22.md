---
layout: post
title: "Sanskrit Sandhi Splitting using $pmb{seq2^2}$"
date: 2018-08-27 07:19:25
categories: arXiv_CL
tags: arXiv_CL Segmentation RNN Deep_Learning
author: Rahul Aralikatte, Neelamadhav Gantayat, Naveen Panwar, Anush Sankaran, Senthil Mani
mathjax: true
---

* content
{:toc}

##### Abstract
In Sanskrit, small words (morphemes) are combined to form compound words through a process known as Sandhi. Sandhi splitting is the process of splitting a given compound word into its constituent morphemes. Although rules governing word splitting exists in the language, it is highly challenging to identify the location of the splits in a compound word. Though existing Sandhi splitting systems incorporate these pre-defined splitting rules, they have a low accuracy as the same compound word might be broken down in multiple ways to provide syntactically correct splits. 
 In this research, we propose a novel deep learning architecture called Double Decoder RNN (DD-RNN), which (i) predicts the location of the split(s) with 95% accuracy, and (ii) predicts the constituent words (learning the Sandhi splitting rules) with 79.5% accuracy, outperforming the state-of-art by 20%. Additionally, we show the generalization capability of our deep learning model, by showing competitive results in the problem of Chinese word segmentation, as well.

##### Abstract (translated by Google)
在梵文中，小词（词素）通过称为Sandhi的过程组合形成复合词。 Sandhi分裂是将给定的复合词分成其组成语素的过程。尽管在语言中存在管理单词分裂的规则，但是在复合词中识别分裂的位置是非常具有挑战性的。虽然现有的Sandhi分裂系统包含这些预定义的分裂规则，但它们的准确度较低，因为相同的复合词可能会以多种方式分解，以提供语法上正确的分割。
 在这项研究中，我们提出了一种新的深度学习架构，称为双解码器RNN（DD-RNN），它（i）以95％的准确度预测分裂的位置，以及（ii）预测组成单词（学习Sandhi分裂规则）准确率为79.5％，优于现有技术的20％。此外，我们通过展示中文分词问题的竞争结果，展示了我们深度学习模型的泛化能力。

##### URL
[http://arxiv.org/abs/1801.00428](http://arxiv.org/abs/1801.00428)

##### PDF
[http://arxiv.org/pdf/1801.00428](http://arxiv.org/pdf/1801.00428)

