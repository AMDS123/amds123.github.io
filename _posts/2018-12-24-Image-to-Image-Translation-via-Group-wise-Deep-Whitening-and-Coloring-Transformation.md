---
layout: post
title: "Image-to-Image Translation via Group-wise Deep Whitening and Coloring Transformation"
date: 2018-12-24 13:03:24
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Inference Quantitative Relation
author: Wonwoong Cho, Sungha Choi, David Park, Inkyu Shin, Jaegul Choo
mathjax: true
---

* content
{:toc}

##### Abstract
Unsupervised image translation is an active area powered by the advanced generative adversarial networks. Recently introduced models, such as DRIT or MUNIT, utilize a separate encoder in extracting the content and the style of image to successfully incorporate the multimodal nature of image translation. The existing methods, however, overlooks the role that the correlation between feature pairs plays in the overall style. The correlation between feature pairs on top of the mean and the variance of features, are important statistics that define the style of an image. In this regard, we propose an end-to-end framework tailored for image translation that leverages the covariance statistics by whitening the content of an input image followed by coloring to match the covariance statistics with an exemplar. The proposed group-wise deep whitening and coloring (GDWTC) algorithm is motivated by an earlier work of whitening and coloring transformation (WTC), but is augmented to be trained in an end-to-end manner, and with largely reduced computation costs. Our extensive qualitative and quantitative experiments demonstrate that the proposed GDWTC is fast, both in training and inference, and highly effective in reflecting the style of an exemplar.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.09912](http://arxiv.org/abs/1812.09912)

##### PDF
[http://arxiv.org/pdf/1812.09912](http://arxiv.org/pdf/1812.09912)

