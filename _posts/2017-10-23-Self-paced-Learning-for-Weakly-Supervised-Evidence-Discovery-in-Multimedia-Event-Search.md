---
layout: post
title: "Self-paced Learning for Weakly Supervised Evidence Discovery in Multimedia Event Search"
date: 2017-10-23 06:39:45
categories: arXiv_CV
tags: arXiv_CV Attention Weakly_Supervised Quantitative Detection
author: Mengyi Liu, Lu Jiang, Shiguang Shan, Alexander G. Hauptmann
mathjax: true
---

* content
{:toc}

##### Abstract
Multimedia event detection has been receiving increasing attention in recent years. Besides recognizing an event, the discovery of evidences (which is refered to as "recounting") is also crucial for user to better understand the searching result. Due to the difficulty of evidence annotation, only limited supervision of event labels are available for training a recounting model. To deal with the problem, we propose a weakly supervised evidence discovery method based on self-paced learning framework, which follows a learning process from easy "evidences" to gradually more complex ones, and simultaneously exploit more and more positive evidence samples from numerous weakly annotated video segments. Moreover, to evaluate our method quantitatively, we also propose two metrics, \textit{PctOverlap} and \textit{F1-score}, for measuring the performance of evidence localization specifically. The experiments are conducted on a subset of TRECVID MED dataset and demonstrate the promising results obtained by our method.

##### Abstract (translated by Google)
多媒体事件检测近年来受到越来越多的关注。除了识别事件之外，发现证据（被称为“叙述”）对于用户更好地理解搜索结果也是至关重要的。由于证据注释的困难，只有事件标签的有限监督可用于训练重新计数模型。为了解决这个问题，我们提出了一种基于自主学习框架的弱监督证据发现方法，它遵循一个从简单的“证据”到逐渐复杂的学习过程，并同时利用越来越多的弱证据注释的视频片段。此外，为了定量评估我们的方法，我们还提出了两个衡量证据定位性能的指标：\ textit {PctOverlap}和\ textit {F1-score}。实验是在TRECVID MED数据集的一个子集上进行的，并展示了我们的方法获得的有希望的结果。

##### URL
[https://arxiv.org/abs/1608.03748](https://arxiv.org/abs/1608.03748)

##### PDF
[https://arxiv.org/pdf/1608.03748](https://arxiv.org/pdf/1608.03748)

