---
layout: post
title: "Meta-Learning for Multi-objective Reinforcement Learning"
date: 2018-11-08 12:26:42
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Xi Chen, Ali Ghadirzadeh, Mårten Björkman, Patric Jensfelt
mathjax: true
---

* content
{:toc}

##### Abstract
Multi-objective reinforcement learning (MORL) is the generalization of standard reinforcement learning (RL) approaches to solve sequential decision making problems that consist of several, possibly conflicting, objectives. Generally, in such formulations, there is no single optimal policy which optimizes all the objectives simultaneously, and instead, a number of policies has to be found, each optimizing a preference of the objectives. In this paper, we introduce a novel MORL approach by training a meta-policy, a policy simultaneously trained with multiple tasks sampled from a task distribution, for a number of randomly sampled Markov decision processes (MDPs). In other words, the MORL is framed as a meta-learning problem, with the task distribution given by a distribution over the preferences. We demonstrate that such a formulation results in a better approximation of the Pareto optimal solutions, in terms of both the optimality and the computational efficiency. We evaluated our method on obtaining Pareto optimal policies using a number of continuous control problems with high degrees of freedom.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1811.03376](https://arxiv.org/abs/1811.03376)

##### PDF
[https://arxiv.org/pdf/1811.03376](https://arxiv.org/pdf/1811.03376)

