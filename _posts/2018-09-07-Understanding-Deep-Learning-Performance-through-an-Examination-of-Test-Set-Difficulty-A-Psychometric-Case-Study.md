---
layout: post
title: "Understanding Deep Learning Performance through an Examination of Test Set Difficulty: A Psychometric Case Study"
date: 2018-09-07 18:20:46
categories: arXiv_CL
tags: arXiv_CL Sentiment Inference Deep_Learning Relation
author: John P. Lalor, Hao Wu, Tsendsuren Munkhdalai, Hong Yu
mathjax: true
---

* content
{:toc}

##### Abstract
Interpreting the performance of deep learning models beyond test set accuracy is challenging. Characteristics of individual data points are often not considered during evaluation, and each data point is treated equally. We examine the impact of a test set question's difficulty to determine if there is a relationship between difficulty and performance. We model difficulty using well-studied psychometric methods on human response patterns. Experiments on Natural Language Inference (NLI) and Sentiment Analysis (SA) show that the likelihood of answering a question correctly is impacted by the question's difficulty. As DNNs are trained with more data, easy examples are learned more quickly than hard examples.

##### Abstract (translated by Google)
解释超出测试集精度的深度学习模型的性能是具有挑战性的。评估期间通常不考虑各个数据点的特征，并且每个数据点都被平等对待。我们检查测试集问题难以确定是否存在难度和性能之间的关系。我们使用经过充分研究的心理测量方法对人类反应模式进行模拟。自然语言推理（NLI）和情感分析（SA）的实验表明，正确回答问题的可能性受到问题困难的影响。由于DNN受到更多数据的培训，因此比简单的例子更容易学习简单的例子。

##### URL
[http://arxiv.org/abs/1702.04811](http://arxiv.org/abs/1702.04811)

##### PDF
[http://arxiv.org/pdf/1702.04811](http://arxiv.org/pdf/1702.04811)

