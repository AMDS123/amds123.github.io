---
layout: post
title: "The Monkeytyping Solution to the YouTube-8M Video Understanding Challenge"
date: 2017-06-16 05:39:53
categories: arXiv_CV
tags: arXiv_CV Video_Caption Attention Video_Classification Classification
author: He-Da Wang, Teng Zhang, Ji Wu
mathjax: true
---

* content
{:toc}

##### Abstract
This article describes the final solution of team monkeytyping, who finished in second place in the YouTube-8M video understanding challenge. The dataset used in this challenge is a large-scale benchmark for multi-label video classification. We extend the work in [1] and propose several improvements for frame sequence modeling. We propose a network structure called Chaining that can better capture the interactions between labels. Also, we report our approaches in dealing with multi-scale information and attention pooling. In addition, We find that using the output of model ensemble as a side target in training can boost single model performance. We report our experiments in bagging, boosting, cascade, and stacking, and propose a stacking algorithm called attention weighted stacking. Our final submission is an ensemble that consists of 74 sub models, all of which are listed in the appendix.

##### Abstract (translated by Google)
本文介绍了团队monkeytyping的最终解决方案，他们在YouTube-8M视频理解挑战中排名第二。在这个挑战中使用的数据集是多标签视频分类的大规模基准。我们扩展了[1]中的工作，并对帧序列建模提出了一些改进。我们提出一个称为链接的网络结构，可以更好地捕获标签之间的交互。此外，我们报告我们处理多尺度信息和注意力集中的方法。另外，我们发现使用模型集成的输出作为训练中的辅助对象可以提高单个模型的性能。我们报告我们在袋装，提升，级联和堆叠的实验，并提出一种称为注意力加权叠加的叠加算法。我们最后提交的是一个由74个子模型组成的集合，所有这些都在附录中列出。

##### URL
[https://arxiv.org/abs/1706.05150](https://arxiv.org/abs/1706.05150)

##### PDF
[https://arxiv.org/pdf/1706.05150](https://arxiv.org/pdf/1706.05150)

