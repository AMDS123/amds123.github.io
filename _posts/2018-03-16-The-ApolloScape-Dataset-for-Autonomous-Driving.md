---
layout: post
title: "The ApolloScape Dataset for Autonomous Driving"
date: 2018-03-16 12:15:58
categories: arXiv_CV
tags: arXiv_CV Transfer_Learning
author: Xinyu Huang, Xinjing Cheng, Qichuan Geng, Binbin Cao, Dingfu Zhou, Peng Wang, Yuanqing Lin, Ruigang Yang
mathjax: true
---

* content
{:toc}

##### Abstract
Scene parsing aims to assign a class (semantic) label for each pixel in an image. It is a comprehensive analysis of an image. Given the rise of autonomous driving, pixel-accurate environmental perception is expected to be a key enabling technical piece. However, providing a large scale dataset for the design and evaluation of scene parsing algorithms, in particular for outdoor scenes, has been difficult. The per-pixel labelling process is prohibitively expensive, limiting the scale of existing ones. In this paper, we present a large-scale open dataset, ApolloScape, that consists of RGB videos and corresponding dense 3D point clouds. Comparing with existing datasets, our dataset has the following unique properties. The first is its scale, our initial release contains over 140K images - each with its per-pixel semantic mask, up to 1M is scheduled. The second is its complexity. Captured in various traffic conditions, the number of moving objects averages from tens to over one hundred. And the third is the 3D attribute, each image is tagged with high-accuracy pose information at cm accuracy and the static background point cloud has mm relative accuracy. We are able to label these many images by an interactive and efficient labelling pipeline that utilizes the high-quality 3D point cloud. Moreover, our dataset also contains different lane markings based on the lane colors and styles. We expect our new dataset can deeply benefit various autonomous driving related applications that include but not limited to 2D/3D scene understanding, localization, transfer learning, and driving simulation.

##### Abstract (translated by Google)
场景分析旨在为图像中的每个像素分配一个类（语义）标签。这是一个形象的综合分析。鉴于自动驾驶的兴起，像素精确的环境感知预计将成为关键技术。然而，为场景解析算法的设计和评估提供大规模数据集，特别是针对户外场景，是困难的。每像素标签处理过于昂贵，限制了现有标签的规模。在本文中，我们提出了一个大型的开放数据集ApolloScape，它由RGB视频和相应的密集3D点云组成。与现有数据集相比，我们的数据集具有以下独特属性。首先是它的规模，我们最初的版本包含超过140K的图像 - 每个图像具有其每像素语义掩码，预计高达1M。其次是它的复杂性。捕捉到各种交通状况，移动物体的数量从数十到数百。第三个是3D属性，每个图像都以厘米精度标记有高精度姿态信息，而静态背景点云具有mm相对精度。我们可以通过交互式和高效的标签管线来标记这些图像，该管道利用高质量的3D点云。此外，我们的数据集还包含基于车道颜色和样式的不同车道标记。我们预计，我们的新数据集可以深深受益于各种自动驾驶相关应用，包括但不限于2D / 3D场景理解，本地化，传输学习和驾驶模拟。

##### URL
[https://arxiv.org/abs/1803.06184](https://arxiv.org/abs/1803.06184)

##### PDF
[https://arxiv.org/pdf/1803.06184](https://arxiv.org/pdf/1803.06184)

