---
layout: post
title: "Metric Attack and Defense for Person Re-identification"
date: 2019-03-23 04:23:51
categories: arXiv_CV
tags: arXiv_CV Re-identification Adversarial Attention Person_Re-identification Classification Prediction
author: Song Bai, Yingwei Li, Yuyin Zhou, Qizhu Li, Philip H.S. Torr
mathjax: true
---

* content
{:toc}

##### Abstract
Person re-identification (re-ID) has attracted much attention recently due to its great importance in video surveillance. In general, distance metrics used to identify two person images are expected to be robust under various appearance changes. However, our work observes the extreme vulnerability of existing distance metrics to adversarial examples, generated by simply adding human-imperceptible perturbations to person images. Hence, the security danger is dramatically increased when deploying commercial re-ID systems in video surveillance. 
 Although adversarial examples have been extensively applied for classification analysis, it is rarely studied in metric analysis like person re-identification. The most likely reason is the natural gap between the training and testing of re-ID networks, that is, the predictions of a re-ID network cannot be directly used during testing without an effective metric. In this work, we bridge the gap by proposing Adversarial Metric Attack, a parallel methodology to adversarial classification attacks. Comprehensive experiments clearly reveal the adversarial effects in re-ID systems. Meanwhile, we also present an early attempt of training a metric-preserving network, thereby defending the metric against adversarial attacks. At last, by benchmarking various adversarial settings, we expect that our work can facilitate the development of adversarial attack and defense in metric-based applications.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1901.10650](http://arxiv.org/abs/1901.10650)

##### PDF
[http://arxiv.org/pdf/1901.10650](http://arxiv.org/pdf/1901.10650)

