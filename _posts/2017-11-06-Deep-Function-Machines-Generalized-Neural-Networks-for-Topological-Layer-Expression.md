---
layout: post
title: "Deep Function Machines: Generalized Neural Networks for Topological Layer Expression"
date: 2017-11-06 20:51:33
categories: arXiv_CV
tags: arXiv_CV
author: William H. Guss
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we propose a generalization of deep neural networks called deep function machines (DFMs). DFMs act on vector spaces of arbitrary (possibly infinite) dimension and we show that a family of DFMs are invariant to the dimension of input data; that is, the parameterization of the model does not directly hinge on the quality of the input (eg. high resolution images). Using this generalization we provide a new theory of universal approximation of bounded non-linear operators between function spaces. We then suggest that DFMs provide an expressive framework for designing new neural network layer types with topological considerations in mind. Finally, we introduce a novel architecture, RippLeNet, for resolution invariant computer vision, which empirically achieves state of the art invariance.

##### Abstract (translated by Google)
在本文中，我们提出深度神经网络的概括，称为深度函数机（DFM）。 DFMs作用于任意（可能是无限）维度的向量空间，并且我们证明DFM族对于输入数据的维度是不变的;也就是说，模型的参数化不直接取决于输入的质量（例如高分辨率图像）。使用这种泛化，我们提供了一个有界的非线性算子在函数空间之间的通用逼近的新理论。然后，我们建议DFM为考虑到拓扑考虑而设计新的神经网络层类型提供了一个富有表现力的框架。最后，我们介绍了一种新颖的架构，RippLeNet，用于解决方案不变的计算机视觉，它经验地实现了最先进的不变性。

##### URL
[https://arxiv.org/abs/1612.04799](https://arxiv.org/abs/1612.04799)

##### PDF
[https://arxiv.org/pdf/1612.04799](https://arxiv.org/pdf/1612.04799)

