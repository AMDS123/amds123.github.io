---
layout: post
title: "Neural-based Natural Language Generation in Dialogue using RNN Encoder-Decoder with Semantic Aggregation"
date: 2017-07-11 14:47:13
categories: arXiv_CL
tags: arXiv_CL Attention Face RNN
author: Van-Khanh Tran, Le-Minh Nguyen
mathjax: true
---

* content
{:toc}

##### Abstract
Natural language generation (NLG) is an important component in spoken dialogue systems. This paper presents a model called Encoder-Aggregator-Decoder which is an extension of an Recurrent Neural Network based Encoder-Decoder architecture. The proposed Semantic Aggregator consists of two components: an Aligner and a Refiner. The Aligner is a conventional attention calculated over the encoded input information, while the Refiner is another attention or gating mechanism stacked over the attentive Aligner in order to further select and aggregate the semantic elements. The proposed model can be jointly trained both sentence planning and surface realization to produce natural language utterances. The model was extensively assessed on four different NLG domains, in which the experimental results showed that the proposed generator consistently outperforms the previous methods on all the NLG domains.

##### Abstract (translated by Google)
自然语言生成（NLG）是口语对话系统中的重要组成部分。本文提出了一种称为编码器 - 聚合器 - 解码器的模型，它是基于循环神经网络的编码器 - 解码器架构的扩展。提出的语义聚合器由两个组件组成：一个Aligner和一个Refiner。 Aligner是对编码输入信息计算的常规注意力，而Refiner则是堆叠在专注Aligner上的另一个注意或门控机制，以便进一步选择和聚合语义元素。提出的模型可以共同训练句子规划和表面实现来产生自然语言的话语。该模型在四个不同的NLG域上进行了广泛的评估，其中实验结果表明所提出的发生器在所有NLG域上始终优于以前的方法。

##### URL
[https://arxiv.org/abs/1706.06714](https://arxiv.org/abs/1706.06714)

##### PDF
[https://arxiv.org/pdf/1706.06714](https://arxiv.org/pdf/1706.06714)

