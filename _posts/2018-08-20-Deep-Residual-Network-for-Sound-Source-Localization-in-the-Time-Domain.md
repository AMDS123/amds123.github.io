---
layout: post
title: "Deep Residual Network for Sound Source Localization in the Time Domain"
date: 2018-08-20 12:54:51
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition Classification Recognition
author: Dmitry Suvorov, Ge Dong, Roman Zhukov
mathjax: true
---

* content
{:toc}

##### Abstract
This study presents a system for sound source localization in time domain using a deep residual neural network. Data from the linear 8 channel microphone array with 3 cm spacing is used by the network for direction estimation. We propose to use the deep residual network for sound source localization considering the localization task as a classification task. This study describes the gathered dataset and developed architecture of the neural network. We will show the training process and its result in this study. The developed system was tested on validation part of the dataset and on new data capture in real time. The accuracy classification of 30 m sec sound frames is 99.2%. The standard deviation of sound source localization is 4{\deg}. The proposed method of sound source localization was tested inside of speech recognition pipeline. Its usage decreased word error rate by 1.14% in comparison with similar speech recognition pipeline using GCC-PHAT sound source localization.

##### Abstract (translated by Google)
本研究提出了一种利用深度残余神经网络进行时域声源定位的系统。来自具有3cm间隔的线性8通道麦克风阵列的数据被网络用于方向估计。我们建议将深度剩余网络用于声源定位，将本地化任务作为分类任务。该研究描述了收集的数据集和神经网络的开发架构。我们将在本研究中展示培训过程及其结果。开发的系统在数据集的验证部分和实时的新数据捕获上进行了测试。 30米秒声音帧的准确度分类为99.2％。声源定位的标准偏差为4 {\ deg}。在语音识别流水线内测试了所提出的声源定位方法。与使用GCC-PHAT声源定位的类似语音识别流水线相比，它的使用将词误差率降低了1.14％。

##### URL
[http://arxiv.org/abs/1808.06429](http://arxiv.org/abs/1808.06429)

##### PDF
[http://arxiv.org/pdf/1808.06429](http://arxiv.org/pdf/1808.06429)

