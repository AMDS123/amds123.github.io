---
layout: post
title: "One-Step Time-Dependent Future Video Frame Prediction with a Convolutional Encoder-Decoder Neural Network"
date: 2017-07-24 11:11:25
categories: arXiv_CV
tags: arXiv_CV Drone CNN Prediction
author: Vedran Vukotić, Silvia-Laura Pintea, Christian Raymond, Guillaume Gravier, Jan Van Gemert
mathjax: true
---

* content
{:toc}

##### Abstract
There is an inherent need for autonomous cars, drones, and other robots to have a notion of how their environment behaves and to anticipate changes in the near future. In this work, we focus on anticipating future appearance given the current frame of a video. Existing work focuses on either predicting the future appearance as the next frame of a video, or predicting future motion as optical flow or motion trajectories starting from a single video frame. This work stretches the ability of CNNs (Convolutional Neural Networks) to predict an anticipation of appearance at an arbitrarily given future time, not necessarily the next video frame. We condition our predicted future appearance on a continuous time variable that allows us to anticipate future frames at a given temporal distance, directly from the input video frame. We show that CNNs can learn an intrinsic representation of typical appearance changes over time and successfully generate realistic predictions at a deliberate time difference in the near future.

##### Abstract (translated by Google)
自动驾驶汽车，无人驾驶飞机和其他机器人有自己的一个需求，就是要了解自己的环境行为，并预测不久的将来发生的变化。在这项工作中，我们专注于根据视频的当前帧预测未来的外观。现有的工作重点在于将未来的外观预测为视频的下一帧，或者将未来运动预测为从单个视频帧开始的光流或运动轨迹。这项工作延伸了CNN（卷积神经网络）的能力来预测在任意给定的未来时间出现的预期，而不一定是下一个视频帧。我们将预测的未来外观调整为连续的时间变量，使我们能够直接从输入视频帧预测给定时间距离的未来帧。我们显示，CNN可以学习一个典型的外观变化的内在表现，随着时间的推移，并成功地产生现实的预测在故意的时间差异在不久的将来。

##### URL
[https://arxiv.org/abs/1702.04125](https://arxiv.org/abs/1702.04125)

##### PDF
[https://arxiv.org/pdf/1702.04125](https://arxiv.org/pdf/1702.04125)

