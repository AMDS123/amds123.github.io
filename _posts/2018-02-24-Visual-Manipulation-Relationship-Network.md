---
layout: post
title: "Visual Manipulation Relationship Network"
date: 2018-02-24 14:54:13
categories: arXiv_RO
tags: arXiv_RO CNN Relation
author: Hanbo Zhang, Xuguang Lan, Xinwen Zhou, Zhiqiang Tian, Nanning Zheng
mathjax: true
---

* content
{:toc}

##### Abstract
Grasping is one of the most significant manip- ulation in everyday life, which can be influenced a lot by grasping order when there are several objects in the scene. Therefore, the manipulation relationships are needed to help robot better grasp and manipulate objects. This paper presents a new convolutional neural network architecture called Visual Manipulation Relationship Network (VMRN), which is used to help robot detect targets and predict the manipulation relationships in real time. To implement end-to-end training and meet real-time requirements in robot tasks, we propose the Object Pairing Pooling Layer (OP2L), which can help to predict all manipulation relationships in one forward process. To train VMRN, we collect a dataset named Visual Manipulation Rela- tionship Dataset (VMRD) consisting of 5185 images with more than 17000 object instances and the manipulation relationships between all possible pairs of objects in every image, which is labeled by the manipulation relationship tree. The experiment results show that the new network architecture can detect objects and predict manipulation relationships simultaneously and meet the real-time requirements in robot tasks.

##### Abstract (translated by Google)
抓握是日常生活中最重要的操作之一，当场景中有多个物体时，抓握顺序会对其产生很大的影响。因此，需要操纵关系来帮助机器人更好地抓住和操纵物体。本文提出了一种称为视觉操纵关系网络（VMRN）的卷积神经网络体系结构，用于帮助机器人实时检测目标并预测操纵关系。为了实现端到端培训并满足机器人任务的实时要求，我们提出了对象共享池层（OP2L），它可以帮助预测一个转发过程中的所有操作关系。为了训练VMRN，我们收集了一个名为视觉操纵关系数据集（VMRD）的数据集，该数据集由5185个具有17000多个对象实例的图像以及每个图像中所有可能的对象之间的操纵关系组成，这些对象由操纵关系树。实验结果表明，新的网络体系结构可以同时检测对象并预测操作关系，满足机器人任务的实时性要求。

##### URL
[http://arxiv.org/abs/1802.08857](http://arxiv.org/abs/1802.08857)

##### PDF
[http://arxiv.org/pdf/1802.08857](http://arxiv.org/pdf/1802.08857)

