---
layout: post
title: "Towards Active Robotic Vision in Agriculture: A Deep Learning Approach to Visual Servoing in Occluded and Unstructured Protected Cropping Environments"
date: 2019-08-05 22:15:11
categories: arXiv_RO
tags: arXiv_RO CNN Deep_Learning
author: Paul Zapotezny-Anderson, Chris Lehnert
mathjax: true
---

* content
{:toc}

##### Abstract
3D Move To See (3DMTS) is a mutli-perspective visual servoing method for unstructured and occluded environments, like that encountered in robotic crop harvesting. This paper presents a deep learning method, Deep-3DMTS for creating a single-perspective approach for 3DMTS through the use of a Convolutional Neural Network (CNN). The novel method is developed and validated via simulation against the standard 3DMTS approach. The Deep-3DMTS approach is shown to have performance equivalent to the standard 3DMTS baseline in guiding the end effector of a robotic arm to improve the view of occluded fruit (sweet peppers): end effector final position within 11.4 mm of the baseline; and an increase in fruit size in the image by a factor of 17.8 compared to the baseline of 16.8 (avg.).

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1908.01885](https://arxiv.org/abs/1908.01885)

##### PDF
[https://arxiv.org/pdf/1908.01885](https://arxiv.org/pdf/1908.01885)

