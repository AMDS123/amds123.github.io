---
layout: post
title: "The Intelligent ICU Pilot Study: Using Artificial Intelligence Technology for Autonomous Patient Monitoring"
date: 2018-04-25 21:24:46
categories: arXiv_AI
tags: arXiv_AI Face Deep_Learning Detection Face_Detection Recognition Face_Recognition
author: Anis Davoudi, Kumar Rohit Malhotra, Benjamin Shickel, Scott Siegel, Seth Williams, Matthew Ruppert, Emel Bihorac, Tezcan Ozrazgat-Baslanti, Patrick J. Tighe, Azra Bihorac, Parisa Rashidi
mathjax: true
---

* content
{:toc}

##### Abstract
Currently, many critical care indices are repetitively assessed and recorded by overburdened nurses, e.g. physical function or facial pain expressions of nonverbal patients. In addition, many essential information on patients and their environment are not captured at all, or are captured in a non-granular manner, e.g. sleep disturbance factors such as bright light, loud background noise, or excessive visitations. In this pilot study, we examined the feasibility of using pervasive sensing technology and artificial intelligence for autonomous and granular monitoring of critically ill patients and their environment in the Intensive Care Unit (ICU). As an exemplar prevalent condition, we also characterized delirious and non-delirious patients and their environment. We used wearable sensors, light and sound sensors, and a high-resolution camera to collected data on patients and their environment. We analyzed collected data using deep learning and statistical analysis. Our system performed face detection, face recognition, facial action unit detection, head pose detection, facial expression recognition, posture recognition, actigraphy analysis, sound pressure and light level detection, and visitation frequency detection. We were able to detect patient's face (Mean average precision (mAP)=0.94), recognize patient's face (mAP=0.80), and their postures (F1=0.94). We also found that all facial expressions, 11 activity features, visitation frequency during the day, visitation frequency during the night, light levels, and sound pressure levels during the night were significantly different between delirious and non-delirious patients (p-value<0.05). In summary, we showed that granular and autonomous monitoring of critically ill patients and their environment is feasible and can be used for characterizing critical care conditions and related environment factors.

##### Abstract (translated by Google)
目前，许多重要的护理指标被负担过重的护士重复评估和记录，例如，身体功能或非言语患者的面部疼痛表情。此外，关于患者及其环境的许多基本信息完全不被捕获，或者以非粒状方式捕获，例如，睡眠干扰因素，如明亮的光线，大声的背景噪音或过度的探视。在这项初步研究中，我们研究了使用普适传感技术和人工智能对重症监护病房（ICU）中危重病人及其环境进行自主和粒状监测的可行性。作为一种典型的流行病症，我们还描述了deli妄症和非deli妄症患者及其环境。我们使用可穿戴式传感器，光线和声音传感器以及高分辨率相机收集患者及其环境的数据。我们使用深度学习和统计分析来分析收集的数据。我们的系统执行人脸检测，人脸识别，面部动作单元检测，头部姿势检测，面部表情识别，姿势识别，体动记录分析，声压和光水平检测以及访问频率检测。我们能够检测患者的面部（平均精确度（mAP）= 0.94），识别患者的面部（mAP = 0.80）和他们的姿势（F1 = 0.94）。我们还发现，deli妄和非deli妄患者的所有面部表情，11个活动特征，白天的访问频率，夜间的访问频率，光照水平和声压水平显着不同（p值<0.05 ）。总之，我们发现危重病人及其环境的颗粒状和自主监测是可行的，可用于表征重症监护条件和相关环境因素。

##### URL
[https://arxiv.org/abs/1804.10201](https://arxiv.org/abs/1804.10201)

##### PDF
[https://arxiv.org/pdf/1804.10201](https://arxiv.org/pdf/1804.10201)

