---
layout: post
title: "Contrastive Entropy: A new evaluation metric for unnormalized language models"
date: 2016-03-31 13:53:47
categories: arXiv_SD
tags: arXiv_SD RNN Language_Model Relation
author: Kushal Arora, Anand Rangarajan
mathjax: true
---

* content
{:toc}

##### Abstract
Perplexity (per word) is the most widely used metric for evaluating language models. Despite this, there has been no dearth of criticism for this metric. Most of these criticisms center around lack of correlation with extrinsic metrics like word error rate (WER), dependence upon shared vocabulary for model comparison and unsuitability for unnormalized language model evaluation. In this paper, we address the last problem and propose a new discriminative entropy based intrinsic metric that works for both traditional word level models and unnormalized language models like sentence level models. We also propose a discriminatively trained sentence level interpretation of recurrent neural network based language model (RNN) as an example of unnormalized sentence level model. We demonstrate that for word level models, contrastive entropy shows a strong correlation with perplexity. We also observe that when trained at lower distortion levels, sentence level RNN considerably outperforms traditional RNNs on this new metric.

##### Abstract (translated by Google)
困惑（每个单词）是评估语言模型使用最广泛的指标。尽管如此，这一指标并没有受到批评。这些批评大多集中在缺乏与词汇错误率（WER）等外在指标的相关性，对模型比较的共同词汇的依赖以及对非标准化语言模型评估的不适用性。在本文中，我们解决了最后一个问题，并提出了一种新的基于判别熵的内在度量，既适用于传统的单词级别模型，也适用于句子级别模型等非规范化的语言模型。作为非归一化句级模型的一个例子，我们还提出了一种有区别地训练的基于递归神经网络的语言模型（RNN）的句子级解释。我们证明，对于单词级模型，对比熵表现出与困惑的强相关性。我们还观察到，当在较低的失真水平下训练时，句子级别的RNN在这个新的度量上远远优于传统的RNN。

##### URL
[https://arxiv.org/abs/1601.00248](https://arxiv.org/abs/1601.00248)

##### PDF
[https://arxiv.org/pdf/1601.00248](https://arxiv.org/pdf/1601.00248)

