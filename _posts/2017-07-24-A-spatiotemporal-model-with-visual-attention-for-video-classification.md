---
layout: post
title: "A spatiotemporal model with visual attention for video classification"
date: 2017-07-24 01:53:20
categories: arXiv_CV
tags: arXiv_CV Object_Detection Attention Tracking CNN Video_Classification RNN Classification Deep_Learning Detection
author: Mo Shan, Nikolay Atanasov
mathjax: true
---

* content
{:toc}

##### Abstract
High level understanding of sequential visual input is important for safe and stable autonomy, especially in localization and object detection. While traditional object classification and tracking approaches are specifically designed to handle variations in rotation and scale, current state-of-the-art approaches based on deep learning achieve better performance. This paper focuses on developing a spatiotemporal model to handle videos containing moving objects with rotation and scale changes. Built on models that combine Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to classify sequential data, this work investigates the effectiveness of incorporating attention modules in the CNN stage for video classification. The superiority of the proposed spatiotemporal model is demonstrated on the Moving MNIST dataset augmented with rotation and scaling.

##### Abstract (translated by Google)
对顺序视觉输入的高度理解对于安全和稳定的自主性是重要的，特别是在定位和物体检测方面。虽然传统的对象分类和跟踪方法是专门为处理旋转和缩放的变化而设计的，但是基于深度学习的当前最先进的方法实现了更好的性能。本文着重于开发时空模型来处理包含旋转和缩放变化的移动对象的视频。该工作基于将卷积神经网络（CNN）和递归神经网络（RNN）结合起来的模型来对连续数据进行分类，研究了在CNN阶段将注意模块纳入视频分类的有效性。所提出的时空模型的优越性在移动的MNIST数据集上进行了旋转和缩放增强。

##### URL
[https://arxiv.org/abs/1707.02069](https://arxiv.org/abs/1707.02069)

##### PDF
[https://arxiv.org/pdf/1707.02069](https://arxiv.org/pdf/1707.02069)

