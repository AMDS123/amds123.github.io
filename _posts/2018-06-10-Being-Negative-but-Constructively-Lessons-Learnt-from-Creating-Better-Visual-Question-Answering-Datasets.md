---
layout: post
title: "Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets"
date: 2018-06-10 20:34:21
categories: arXiv_AI
tags: arXiv_AI QA Attention VQA
author: Wei-Lun Chao, Hexiang Hu, Fei Sha
mathjax: true
---

* content
{:toc}

##### Abstract
Visual question answering (Visual QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that artificial intelligence should strive to achieve. In this paper, we study a crucial component of this task: how can we design good datasets for the task? We focus on the design of multiple-choice based datasets where the learner has to select the right answer from a set of candidate ones including the target (\ie the correct one) and the decoys (\ie the incorrect ones). Through careful analysis of the results attained by state-of-the-art learning models and human annotators on existing datasets, we show that the design of the decoy answers has a significant impact on how and what the learning models learn from the datasets. In particular, the resulting learner can ignore the visual information, the question, or both while still doing well on the task. Inspired by this, we propose automatic procedures to remedy such design deficiencies. We apply the procedures to re-construct decoy answers for two popular Visual QA datasets as well as to create a new Visual QA dataset from the Visual Genome project, resulting in the largest dataset for this task. Extensive empirical studies show that the design deficiencies have been alleviated in the remedied datasets and the performance on them is likely a more faithful indicator of the difference among learning models. The datasets are released and publicly available via <a href="http://www.teds.usc.edu/website_vqa/.">this http URL</a>

##### Abstract (translated by Google)
视觉问答（Visual QA）最近引起了很多关注，基本上被视为人工智能应该努力实现的（视觉）图灵测试的一种形式。在本文中，我们研究了这项任务的一个关键组成部分：我们如何为任务设计好的数据集？我们专注于基于多选择的数据集的设计，其中学习者必须从一组候选者中选择正确的答案，包括目标（即正确的）和诱饵（即不正确的）。通过仔细分析现有学习模型和人类注释者在现有数据集上获得的结果，我们发现诱骗答案的设计对学习模型如何以及从数据集中学习到什么产生了重大影响。特别是，由此产生的学习者可以忽略视觉信息，问题或两者，同时仍然能够很好地完成任务。受此启发，我们提出自动程序来弥补这种设计缺陷。我们应用这些程序为两个流行的Visual QA数据集重新构造诱饵答案，并从Visual Genome项目中创建一个新的Visual QA数据集，从而产生此任务的最大数据集。广泛的实证研究表明，补救数据集中的设计缺陷已得到缓解，其中的性能可能是学习模型之间差异的更忠实指标。数据集将通过<a href="http://www.teds.usc.edu/website_vqa/.">此http URL </a>发布并公开发布

##### URL
[http://arxiv.org/abs/1704.07121](http://arxiv.org/abs/1704.07121)

##### PDF
[http://arxiv.org/pdf/1704.07121](http://arxiv.org/pdf/1704.07121)

