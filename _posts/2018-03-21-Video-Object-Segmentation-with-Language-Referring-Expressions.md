---
layout: post
title: "Video Object Segmentation with Language Referring Expressions"
date: 2018-03-21 16:44:19
categories: arXiv_CV
tags: arXiv_CV Segmentation Prediction
author: Anna Khoreva, Anna Rohrbach, Bernt Schiele
mathjax: true
---

* content
{:toc}

##### Abstract
Most state-of-the-art semi-supervised video object segmentation methods rely on a pixel-accurate mask of a target object provided for the first frame of a video. However, obtaining a detailed segmentation mask is expensive and time-consuming. In this work we explore an alternative way of identifying a target object, namely by employing language referring expressions. Besides being a more practical and natural way of pointing out a target object, using language specifications can help to avoid drift as well as make the system more robust to complex dynamics and appearance variations. Leveraging recent advances of language grounding models designed for images, we propose an approach to extend them to video data, ensuring temporally coherent predictions. To evaluate our method we augment the popular video object segmentation benchmarks, DAVIS'16 and DAVIS'17 with language descriptions of target objects. We show that our approach performs on par with the methods which have access to a pixel-level mask of the target object on DAVIS'16 and is competitive to methods using scribbles on the challenging DAVIS'17 dataset.

##### Abstract (translated by Google)
大多数最先进的半监督视频对象分割方法依赖于为视频的第一帧提供的目标对象的像素精确掩模。但是，获取详细的分段掩模是昂贵和耗时的。在这项工作中，我们探索了另一种识别目标对象的方式，即通过使用语言表达来表达。除了作为指出目标物体的更实际和自然的方式之外，使用语言规范还可以帮助避免漂移，并使系统对复杂的动力学和外观变化更具鲁棒性。利用为图像设计的语言接地模型的最新进展，我们提出了一种将它们扩展到视频数据的方法，以确保时间上连贯的预测。为了评估我们的方法，我们增加了流行的视频对象分割基准，DAVIS'16和DAVIS'17以及目标对象的语言描述。我们展示了我们的方法与DAVIS'16上可以访问目标对象的像素级掩模的方法相同，并且与在具有挑战性的DAVIS'17数据集上使用涂鸦的方法相竞争。

##### URL
[http://arxiv.org/abs/1803.08006](http://arxiv.org/abs/1803.08006)

##### PDF
[http://arxiv.org/pdf/1803.08006](http://arxiv.org/pdf/1803.08006)

