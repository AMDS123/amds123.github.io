---
layout: post
title: "Recognizing Activities of Daily Living with a Wrist-mounted Camera"
date: 2016-04-28 04:39:03
categories: arXiv_CV
tags: arXiv_CV Object_Detection CNN Detection Recognition
author: Katsunori Ohnishi, Atsushi Kanehira, Asako Kanezaki, Tatsuya Harada
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel dataset and a novel algorithm for recognizing activities of daily living (ADL) from a first-person wearable camera. Handled objects are crucially important for egocentric ADL recognition. For specific examination of objects related to users' actions separately from other objects in an environment, many previous works have addressed the detection of handled objects in images captured from head-mounted and chest-mounted cameras. Nevertheless, detecting handled objects is not always easy because they tend to appear small in images. They can be occluded by a user's body. As described herein, we mount a camera on a user's wrist. A wrist-mounted camera can capture handled objects at a large scale, and thus it enables us to skip object detection process. To compare a wrist-mounted camera and a head-mounted camera, we also develop a novel and publicly available dataset that includes videos and annotations of daily activities captured simultaneously by both cameras. Additionally, we propose a discriminative video representation that retains spatial and temporal information after encoding frame descriptors extracted by Convolutional Neural Networks (CNN).

##### Abstract (translated by Google)
我们提出了一个新的数据集和一个新的算法从第一人称可穿戴相机识别日常生活活动（ADL）。处理对象对于以自我为中心的ADL识别至关重要。对于与环境中的其他物体分开的与用户动作相关的对象的具体检查，许多以前的工作已经解决了从头戴式摄像头和胸式摄像头捕获的图像中的处理对象的检测。不过，检测处理的对象并不总是很容易，因为它们往往在图像中看起来很小。他们可以被用户的身体遮挡。如本文所述，我们将相机安装在用户的手腕上。手持式相机可以大规模地抓取被处理物体，因此可以跳过物体检测过程。为了比较腕上摄像头和头戴式摄像头，我们还开发了一种新颖且公开的数据集，其中包括由两个摄像头同时拍摄的日常活动的视频和注释。另外，我们提出了一个有区别的视频表示，在对由卷积神经网络（CNN）提取的帧描述符进行编码之后保留空间和时间信息。

##### URL
[https://arxiv.org/abs/1511.06783](https://arxiv.org/abs/1511.06783)

##### PDF
[https://arxiv.org/pdf/1511.06783](https://arxiv.org/pdf/1511.06783)

