---
layout: post
title: "A Hierarchical Structured Self-Attentive Model for Extractive Document Summarization"
date: 2018-05-20 17:16:49
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention Summarization Embedding Represenation_Learning Classification Prediction
author: Kamal Al-Sabahi, Zhang Zuping, Mohammed Nadher
mathjax: true
---

* content
{:toc}

##### Abstract
The recent advance in neural network architecture and training algorithms have shown the effectiveness of representation learning. The neural network-based models generate better representation than the traditional ones. They have the ability to automatically learn the distributed representation for sentences and documents. To this end, we proposed a novel model that addresses several issues that are not adequately modeled by the previously proposed models, such as the memory problem and incorporating the knowledge of document structure. Our model uses a hierarchical structured self-attention mechanism to create the sentence and document embeddings. This architecture mirrors the hierarchical structure of the document and in turn enables us to obtain better feature representation. The attention mechanism provides extra source of information to guide the summary extraction. The new model treated the summarization task as a classification problem in which the model computes the respective probabilities of sentence-summary membership. The model predictions are broken up by several features such as information content, salience, novelty and positional representation. The proposed model was evaluated on two well-known datasets, the CNN / Daily Mail, and DUC 2002. The experimental results show that our model outperforms the current extractive state-of-the-art by a considerable margin.

##### Abstract (translated by Google)
神经网络结构和训练算法的最新进展表明了表示学习的有效性。基于神经网络的模型产生比传统模型更好的表示。他们有能力自动学习句子和文档的分布式表示。为此，我们提出了一种新的模型，该模型解决了以前提出的模型没有充分建模的几个问题，如记忆问题和结合文档结构的知识。我们的模型使用分层结构的自我注意机制来创建句子和文档嵌入。这种体系结构反映了文档的层次结构，从而使我们能够获得更好的特征表示。注意机制提供额外的信息来源来指导摘要提取。新模型将汇总任务视为分类问题，其中模型计算句子总结成员的相应概率。模型预测被诸如信息内容，显着性，新颖性和位置表示等几个特征所打破。所提出的模型在两个众所周知的数据集上进行了评估，CNN / Daily Mail和DUC 2002.实验结果表明，我们的模型比现有的提取技术水平优越得多。

##### URL
[https://arxiv.org/abs/1805.07799](https://arxiv.org/abs/1805.07799)

##### PDF
[https://arxiv.org/pdf/1805.07799](https://arxiv.org/pdf/1805.07799)

