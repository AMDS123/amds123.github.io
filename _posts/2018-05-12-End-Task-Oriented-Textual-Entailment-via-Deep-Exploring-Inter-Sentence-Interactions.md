---
layout: post
title: "End-Task Oriented Textual Entailment via Deep Exploring Inter-Sentence Interactions"
date: 2018-05-12 03:29:42
categories: arXiv_CL
tags: arXiv_CL
author: Wenpeng Yin, Dan Roth, Hinrich Sch&#xfc;tze
mathjax: true
---

* content
{:toc}

##### Abstract
This work deals with SciTail, a natural entailment challenge derived from a multi-choice question answering problem. The premises and hypotheses in SciTail are generated with no awareness of each other, and not specifically aimed to the entailment task. This makes it more challenging than other entailment tasks and more directly useful to the end-task -- question answering. We propose DEISTE (deep exploring inter-sentence interactions for textual entailment) for this entailment task. Given word-to-word interactions between the premise-hypothesis pair (P, H), DEISTE consists of: (i) A parameter-dynamic convolution to make important words in P and H play a dominant role in learnt representations; (ii) A position-aware attentive convolution to encode the representation and position information of the aligned word pairs. Experiments show (i) DEISTE gets ~ 5% improvement over prior state of the art, (ii) the pre-trained DEISTE on SciTail generalizes well on RTE-5. Code &amp; model: https://github.com/yinwenpeng/SciTail

##### Abstract (translated by Google)
这项工作涉及SciTail，这是一个由多选题回答问题导出的自然臆想挑战。 SciTail中的前提和假设是在彼此没有意识的情况下产生的，并不是专门针对包含任务的。这使得它比其他引发任务更具挑战性，并且对终端任务 - 问题回答更直接有用。我们提出DEISTE（深度探索文本蕴含的句子间互动）来完成这个包含任务。鉴于前提假设对（P，H）之间的词与词之间的相互作用，DEISTE包括：（i）参数 - 动态卷积，使得P和H中的重要词汇在学习表示中占主导地位; （ii）位置感知专心卷积以对对齐的单词对的表示和位置信息进行编码。实验表明（i）DEISTE比现有技术状态改善了约5％，（ii）SciTail上的预先训练的DEISTE在RTE-5上通用性良好。代码＆amp;型号：https：//github.com/yinwenpeng/SciTail

##### URL
[http://arxiv.org/abs/1804.08813](http://arxiv.org/abs/1804.08813)

##### PDF
[http://arxiv.org/pdf/1804.08813](http://arxiv.org/pdf/1804.08813)

