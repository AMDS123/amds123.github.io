---
layout: post
title: "Knowledge-Grounded Response Generation with Deep Attentional Latent-Variable Model"
date: 2019-03-23 12:19:11
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention
author: Hao-Tong Ye, Kai-Ling Lo, Shang-Yu Su, Yun-Nung Chen
mathjax: true
---

* content
{:toc}

##### Abstract
End-to-end dialogue generation has achieved promising results without using handcrafted features and attributes specific for each task and corpus. However, one of the fatal drawbacks in such approaches is that they are unable to generate informative utterances, so it limits their usage from some real-world conversational applications. This paper attempts at generating diverse and informative responses with a variational generation model, which contains a joint attention mechanism conditioning on the information from both dialogue contexts and extra knowledge.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.09813](http://arxiv.org/abs/1903.09813)

##### PDF
[http://arxiv.org/pdf/1903.09813](http://arxiv.org/pdf/1903.09813)

