---
layout: post
title: "Scale-invariant temporal history : optimal slicing of the past in an uncertain world"
date: 2018-08-11 03:17:31
categories: arXiv_AI
tags: arXiv_AI
author: Tyler A. Spears, Brandon G. Jacques, Marc W. Howard, Per B. Sederberg
mathjax: true
---

* content
{:toc}

##### Abstract
In both the human brain and any general artificial intelligence (AI), a representation of the past is necessary to predict the future. However, perfect storage of all experiences is not feasible. One possibility, utilized in many applications, is to retain information about the past in a buffer. A limitation of this approach is that, although events in the buffer are represented with perfect accuracy, the resources necessary to represent information at multiple time scales go up rapidly. Here we present a neurally-plausible, compressed, scale-free memory representation we call Scale-Invariant Temporal History (SITH). This representation covers an exponentially large period of time at the cost of sacrificing temporal accuracy for events further in the past. The form of this decay is scale-invariant and can be shown to be optimal, in that it is able to respond to worlds with a wide range of relevant time scales. We demonstrate the utility of this representation in learning to play video games at different levels of complexity. In these environments, SITH exhibits better learning performance than both a fixed-size buffer history representation and a representation with exponentially decaying features. Whereas the buffer performs well as long as the temporal dependencies can be represented within the buffer, SITH performs well over a much larger range of time scales with the same amount of resources. Finally, we discuss how the application of SITH, along with other human-inspired models of cognition, could improve reinforcement and machine learning algorithms in general.

##### Abstract (translated by Google)
在人类大脑和任何一般人工智能（AI）中，过去的表现对于预测未来是必要的。但是，所有体验的完美存储是不可行的。在许多应用中使用的一种可能性是在缓冲器中保留关于过去的信息。这种方法的局限性在于，尽管缓冲区中的事件以完美的准确度表示，但是在多个时间尺度上表示信息所需的资源迅速增加。在这里，我们提出了一种神经可信的，压缩的，无标度的记忆表示，我们称之为尺度不变时间历史（SITH）。该表示覆盖了指数上较长的时间段，代价是过去牺牲事件的时间准确性。这种衰变的形式是尺度不变的，并且可以被证明是最优的，因为它能够响应具有广泛相关时间尺度的世界。我们展示了这种表示在学习不同复杂程度的视频游戏中的实用性。在这些环境中，SITH比固定大小的缓冲区历史表示和具有指数衰减特征的表示具有更好的学习性能。只要可以在缓冲区内表示时间依赖性，缓冲区就能很好地执行，而SITH在具有相同数量资源的更大范围的时间尺度上表现良好。最后，我们讨论了SITH的应用以及其他人类启发的认知模型如何能够改进强化和机器学习算法。

##### URL
[http://arxiv.org/abs/1712.07165](http://arxiv.org/abs/1712.07165)

##### PDF
[http://arxiv.org/pdf/1712.07165](http://arxiv.org/pdf/1712.07165)

