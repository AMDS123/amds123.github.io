---
layout: post
title: "DARLA: Improving Zero-Shot Transfer in Reinforcement Learning"
date: 2018-06-06 16:51:02
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Represenation_Learning
author: Irina Higgins, Arka Pal, Andrei A. Rusu, Loic Matthey, Christopher P Burgess, Alexander Pritzel, Matthew Botvinick, Charles Blundell, Alexander Lerchner
mathjax: true
---

* content
{:toc}

##### Abstract
Domain adaptation is an important open problem in deep reinforcement learning (RL). In many scenarios of interest data is hard to obtain, so agents may learn a source policy in a setting where data is readily available, with the hope that it generalises well to the target domain. We propose a new multi-stage RL agent, DARLA (DisentAngled Representation Learning Agent), which learns to see before learning to act. DARLA's vision is based on learning a disentangled representation of the observed environment. Once DARLA can see, it is able to acquire source policies that are robust to many domain shifts - even with no access to the target domain. DARLA significantly outperforms conventional baselines in zero-shot domain adaptation scenarios, an effect that holds across a variety of RL environments (Jaco arm, DeepMind Lab) and base RL algorithms (DQN, A3C and EC).

##### Abstract (translated by Google)
领域适应是深层强化学习（RL）中一个重要的开放问题。在很多情况下，数据很难获得，因此代理商可以在数据易于获取的环境中学习源策略，希望它能够很好地适用于目标域。我们提出了一个新的多阶段RL代理DARLA（DisentAngled Representation Learning Agent），它在学习行为之前学习看到。 DARLA的愿景是基于学习观察环境的解读表达。一旦DARLA能够看到，它就能够获得对许多域名转换稳健的源策略 - 即使没有对目标域的访问。 DARLA在zero-shot领域适应场景中明显优于传统基线，这种效应适用于各种RL环境（Jaco arm，DeepMind Lab）和基础RL算法（DQN，A3C和EC）。

##### URL
[http://arxiv.org/abs/1707.08475](http://arxiv.org/abs/1707.08475)

##### PDF
[http://arxiv.org/pdf/1707.08475](http://arxiv.org/pdf/1707.08475)

