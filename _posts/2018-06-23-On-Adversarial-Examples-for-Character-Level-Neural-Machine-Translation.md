---
layout: post
title: "On Adversarial Examples for Character-Level Neural Machine Translation"
date: 2018-06-23 20:08:56
categories: arXiv_CL
tags: arXiv_CL Adversarial NMT Deep_Learning
author: Javid Ebrahimi, Daniel Lowd, Dejing Dou
mathjax: true
---

* content
{:toc}

##### Abstract
Evaluating on adversarial examples has become a standard procedure to measure robustness of deep learning models. Due to the difficulty of creating white-box adversarial examples for discrete text input, most analyses of the robustness of NLP models have been done through black-box adversarial examples. We investigate adversarial examples for character-level neural machine translation (NMT), and contrast black-box adversaries with a novel white-box adversary, which employs differentiable string-edit operations to rank adversarial changes. We propose two novel types of attacks which aim to remove or change a word in a translation, rather than simply break the NMT. We demonstrate that white-box adversarial examples are significantly stronger than their black-box counterparts in different attack scenarios, which show more serious vulnerabilities than previously known. In addition, after performing adversarial training, which takes only 3 times longer than regular training, we can improve the model's robustness significantly.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1806.09030](https://arxiv.org/abs/1806.09030)

##### PDF
[https://arxiv.org/pdf/1806.09030](https://arxiv.org/pdf/1806.09030)

