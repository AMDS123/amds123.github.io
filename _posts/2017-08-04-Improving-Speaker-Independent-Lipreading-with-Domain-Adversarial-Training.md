---
layout: post
title: "Improving Speaker-Independent Lipreading with Domain-Adversarial Training"
date: 2017-08-04 15:57:38
categories: arXiv_CL
tags: arXiv_CL Adversarial Speech_Recognition Optimization RNN Recognition
author: Michael Wand, Juergen Schmidhuber
mathjax: true
---

* content
{:toc}

##### Abstract
We present a Lipreading system, i.e. a speech recognition system using only visual features, which uses domain-adversarial training for speaker independence. Domain-adversarial training is integrated into the optimization of a lipreader based on a stack of feedforward and LSTM (Long Short-Term Memory) recurrent neural networks, yielding an end-to-end trainable system which only requires a very small number of frames of untranscribed target data to substantially improve the recognition accuracy on the target speaker. On pairs of different source and target speakers, we achieve a relative accuracy improvement of around 40% with only 15 to 20 seconds of untranscribed target speech data. On multi-speaker training setups, the accuracy improvements are smaller but still substantial.

##### Abstract (translated by Google)
我们提出了一个Lipreading系统，即一个只使用视觉特征的语音识别系统，这个系统使用领域对抗训练来使说话者独立。将领域对抗训练集成到基于前馈和LSTM（长期短期记忆）递归神经网络的堆栈器的优化中，产生端对端可训练系统，其仅需要非常少量的帧未转录的目标数据，以大大提高目标说话人的识别准确度。在不同的源语言和目标语音对上，我们实现了大约40％的相对准确度提高，仅有15到20秒的未转录目标语音数据。在多扬声器训练设置中，精度的提高虽然较小，但仍然相当可观。

##### URL
[https://arxiv.org/abs/1708.01565](https://arxiv.org/abs/1708.01565)

##### PDF
[https://arxiv.org/pdf/1708.01565](https://arxiv.org/pdf/1708.01565)

