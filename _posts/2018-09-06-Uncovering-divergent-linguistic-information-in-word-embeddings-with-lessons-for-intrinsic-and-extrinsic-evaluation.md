---
layout: post
title: "Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation"
date: 2018-09-06 17:08:21
categories: arXiv_AI
tags: arXiv_AI Embedding Relation
author: Mikel Artetxe, Gorka Labaka, I&#xf1;igo Lopez-Gazpio, Eneko Agirre
mathjax: true
---

* content
{:toc}

##### Abstract
Following the recent success of word embeddings, it has been argued that there is no such thing as an ideal representation for words, as different models tend to capture divergent and often mutually incompatible aspects like semantics/syntax and similarity/relatedness. In this paper, we show that each embedding model captures more information than directly apparent. A linear transformation that adjusts the similarity order of the model without any external resource can tailor it to achieve better results in those aspects, providing a new perspective on how embeddings encode divergent linguistic information. In addition, we explore the relation between intrinsic and extrinsic evaluation, as the effect of our transformations in downstream tasks is higher for unsupervised systems than for supervised ones.

##### Abstract (translated by Google)
随着最近词嵌入的成功，人们一直认为没有理想的词语表示，因为不同的模型倾向于捕捉不同的，通常是互不相容的方面，如语义/句法和相似性/相关性。在本文中，我们展示了每个嵌入模型捕获的信息多于直接显而易见的信息。在没有任何外部资源的情况下调整模型的相似性顺序的线性变换可以定制它以在这些方面获得更好的结果，从而提供关于嵌入如何编码不同语言信息的新视角。此外，我们探讨了内在和外在评价之间的关系，因为我们对下游任务的转换对无监督系统的影响要高于监督系统。

##### URL
[http://arxiv.org/abs/1809.02094](http://arxiv.org/abs/1809.02094)

##### PDF
[http://arxiv.org/pdf/1809.02094](http://arxiv.org/pdf/1809.02094)

