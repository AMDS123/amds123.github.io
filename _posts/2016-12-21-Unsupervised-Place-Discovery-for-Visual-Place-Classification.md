---
layout: post
title: "Unsupervised Place Discovery for Visual Place Classification"
date: 2016-12-21 00:53:18
categories: arXiv_CV
tags: arXiv_CV GAN CNN Classification
author: Fei Xiaoxiao, Tanaka Kanji, Inamoto Kouya
mathjax: true
---

* content
{:toc}

##### Abstract
In this study, we explore the use of deep convolutional neural networks (DCNNs) in visual place classification for robotic mapping and localization. An open question is how to partition the robot's workspace into places to maximize the performance (e.g., accuracy, precision, recall) of potential DCNN classifiers. This is a chicken and egg problem: If we had a well-trained DCNN classifier, it is rather easy to partition the robot's workspace into places, but the training of a DCNN classifier requires a set of pre-defined place classes. In this study, we address this problem and present several strategies for unsupervised discovery of place classes ("time cue," "location cue," "time-appearance cue," and "location-appearance cue"). We also evaluate the efficacy of the proposed methods using the publicly available University of Michigan North Campus Long-Term (NCLT) Dataset.

##### Abstract (translated by Google)
在这项研究中，我们探讨了深度卷积神经网络（DCNNs）在机器人映射和定位的视觉场所分类中的应用。一个悬而未决的问题是如何将机器人的工作空间划分到不同的位置，以最大限度地提高潜在的DCNN分类器的性能（例如，准确度，精确度，召回率）。这是一个鸡蛋和鸡蛋的问题：如果我们有一个训练有素的DCNN分类器，将机器人的工作空间分割成地方是相当容易的，但是对DCNN分类器的训练需要一组预定义的地点类别。在这项研究中，我们解决了这个问题，并提出了无监督地点类的发现（“时间提示”，“地点提示”，“时间呈现线索”和“位置外观线索”）的几种策略。我们还使用公开的密歇根大学北校区长期（NCLT）数据集评估所提出方法的有效性。

##### URL
[https://arxiv.org/abs/1612.06933](https://arxiv.org/abs/1612.06933)

##### PDF
[https://arxiv.org/pdf/1612.06933](https://arxiv.org/pdf/1612.06933)

