---
layout: post
title: "Deep Generative Dual Memory Network for Continual Learning"
date: 2017-10-28 01:45:43
categories: arXiv_CV
tags: arXiv_CV Deep_Learning
author: Nitin Kamra, Umang Gupta, Yan Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Despite advances in deep learning, artificial neural networks do not learn the same way as humans do. Today, neural networks can learn multiple tasks when trained on them jointly, but cannot maintain performance on learnt tasks when tasks are presented one at a time -- this phenomenon called catastrophic forgetting is a fundamental challenge to overcome before neural networks can learn continually from incoming data. In this work, we derive inspiration from human memory to develop an architecture capable of learning continuously from sequentially incoming tasks, while averting catastrophic forgetting. Specifically, our model consists of a dual memory architecture to emulate the complementary learning systems (hippocampus and the neocortex) in the human brain, and maintains a consolidated long-term memory via generative replay of past experiences. We (i) substantiate our claim that replay should be generative, (ii) show the benefits of generative replay and dual memory via experiments, and (iii) demonstrate improved performance retention even for small models with low capacity. Our architecture displays many important characteristics of the human memory and provides insights on the connection between sleep and learning in humans.

##### Abstract (translated by Google)
尽管深度学习的进展，人造神经网络不像人类那样学习。如今，神经网络可以共同学习多个任务，但是当任务一次一个呈现时，不能保持学习任务的性能 - 这种称为灾难性遗忘的现象是在神经网络可以从传入中不断学习之前克服的基本挑战数据。在这项工作中，我们从人类的记忆中获得灵感，开发一个能够从连续传入的任务不断学习的体系结构，同时避免灾难性的遗忘。具体而言，我们的模型包含一个双重记忆架构，模仿人类大脑中互补的学习系统（海马和新皮质），并通过对过去经验的生成重放来保持巩固的长期记忆。我们（i）证实了我们的主张，即重播应该是有生命力的，（ii）通过实验显示生成性回放和双重记忆的好处，（iii）即使对于低容量的小模型，也表现出改善的性能保留。我们的建筑展示了人类记忆的许多重要特征，并提供了睡眠与人类学习之间的联系。

##### URL
[https://arxiv.org/abs/1710.10368](https://arxiv.org/abs/1710.10368)

##### PDF
[https://arxiv.org/pdf/1710.10368](https://arxiv.org/pdf/1710.10368)

