---
layout: post
title: "Morphological Priors for Probabilistic Neural Word Embeddings"
date: 2016-09-24 01:28:00
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Parminder Bhatia, Robert Guthrie, Jacob Eisenstein
mathjax: true
---

* content
{:toc}

##### Abstract
Word embeddings allow natural language processing systems to share statistical information across related words. These embeddings are typically based on distributional statistics, making it difficult for them to generalize to rare or unseen words. We propose to improve word embeddings by incorporating morphological information, capturing shared sub-word features. Unlike previous work that constructs word embeddings directly from morphemes, we combine morphological and distributional information in a unified probabilistic framework, in which the word embedding is a latent variable. The morphological information provides a prior distribution on the latent word embeddings, which in turn condition a likelihood function over an observed corpus. This approach yields improvements on intrinsic word similarity evaluations, and also in the downstream task of part-of-speech tagging.

##### Abstract (translated by Google)
单词嵌入允许自然语言处理系统在相关单词之间共享统计信息。这些嵌入通常基于分布统计，使得它们难以概括为稀有或看不见的单词。我们建议通过结合形态信息来改善词嵌入，捕获共享的子词特征。不像以前的工作，直接从语素构建词嵌入，我们结合形态和分布信息在一个统一的概率框架，其中嵌入词是一个潜在的变量。形态信息提供潜在词嵌入的先验分布，其依次调节观察语料库上的似然函数。这种方法对内在词相似性评估产生了改进，并且也在词性标注的下游任务中得到改进。

##### URL
[https://arxiv.org/abs/1608.01056](https://arxiv.org/abs/1608.01056)

##### PDF
[https://arxiv.org/pdf/1608.01056](https://arxiv.org/pdf/1608.01056)

