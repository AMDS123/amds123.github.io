---
layout: post
title: "Racial Faces in-the-Wild: Reducing Racial Bias by Deep Unsupervised Domain Adaptation"
date: 2018-12-01 12:10:39
categories: arXiv_CV
tags: arXiv_CV Knowledge Face Deep_Learning Recognition Face_Recognition
author: Mei Wang, Weihong Deng, Jiani Hu, Jianteng Peng, Xunqiang Tao, Yaohai Huang
mathjax: true
---

* content
{:toc}

##### Abstract
Despite of the progress achieved by deep learning in face recognition (FR), more and more people find that racial bias explicitly degrades the performance in realistic FR systems. Facing the fact that existing training and testing databases consist of almost Caucasian subjects, there are still no independent testing databases to evaluate racial bias and even no training databases and methods to reduce it. To facilitate the research towards conquering those unfair issues, this paper contributes a new dataset called Racial Faces in-the-Wild (RFW) database with two important uses, 1) racial bias testing: four testing subsets, namely Caucasian, Asian, Indian and African, are constructed, and each contains about 3000 individuals with 6000 image pairs for face verification, 2) racial bias reducing: one labeled training subset with Caucasians and three unlabeled training subsets with Asians, Indians and Africans are offered to encourage FR algorithms to transfer recognition knowledge from Caucasians to other races. For we all know, RFW is the first database for measuring racial bias in FR algorithms. After proving the existence of domain gap among different races and the existence of racial bias in FR algorithms, we further propose a deep information maximization adaptation network (IMAN) to bridge the domain gap, and comprehensive experiments show that the racial bias could be narrowed-down by our algorithm.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.00194](http://arxiv.org/abs/1812.00194)

##### PDF
[http://arxiv.org/pdf/1812.00194](http://arxiv.org/pdf/1812.00194)

