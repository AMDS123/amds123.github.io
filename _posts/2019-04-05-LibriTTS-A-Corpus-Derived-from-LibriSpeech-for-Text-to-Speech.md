---
layout: post
title: "LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech"
date: 2019-04-05 06:05:00
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition Recognition
author: Heiga Zen, Viet Dang, Rob Clark, Yu Zhang, Ron J. Weiss, Ye Jia, Zhifeng Chen, Yonghui Wu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper introduces a new speech corpus called "LibriTTS" designed for text-to-speech use. It is derived from the original audio and text materials of the LibriSpeech corpus, which has been used for training and evaluating automatic speech recognition systems. The new corpus inherits desired properties of the LibriSpeech corpus while addressing a number of issues which make LibriSpeech less than ideal for text-to-speech work. The released corpus consists of 585 hours of speech data at 24kHz sampling rate from 2,456 speakers and the corresponding texts. Experimental results show that neural end-to-end TTS models trained from the LibriTTS corpus achieved above 4.0 in mean opinion scores in naturalness in five out of six evaluation speakers. The corpus is freely available for download from this http URL.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1904.02882](https://arxiv.org/abs/1904.02882)

##### PDF
[https://arxiv.org/pdf/1904.02882](https://arxiv.org/pdf/1904.02882)

