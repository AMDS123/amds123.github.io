---
layout: post
title: "RenderGAN: Generating Realistic Labeled Data"
date: 2017-01-12 13:37:26
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN CNN
author: Leon Sixt, Benjamin Wild, Tim Landgraf
mathjax: true
---

* content
{:toc}

##### Abstract
Deep Convolutional Neuronal Networks (DCNNs) are showing remarkable performance on many computer vision tasks. Due to their large parameter space, they require many labeled samples when trained in a supervised setting. The costs of annotating data manually can render the use of DCNNs infeasible. We present a novel framework called RenderGAN that can generate large amounts of realistic, labeled images by combining a 3D model and the Generative Adversarial Network framework. In our approach, image augmentations (e.g. lighting, background, and detail) are learned from unlabeled data such that the generated images are strikingly realistic while preserving the labels known from the 3D model. We apply the RenderGAN framework to generate images of barcode-like markers that are attached to honeybees. Training a DCNN on data generated by the RenderGAN yields considerably better performance than training it on various baselines.

##### Abstract (translated by Google)
深度卷积神经网络（DCNN）在许多计算机视觉任务中表现出卓越的性能。由于它们的参数空间很大，在受监督的设置下训练时，它们需要许多标记的样本。手动注释数据的成本可能导致使用DCNNs不可行。我们提出了一个名为RenderGAN的新框架，通过结合3D模型和生成敌对网络框架，可以生成大量现实的标记图像。在我们的方法中，从未标记的数据中学习图像增强（例如，照明，背景和细节），使得所生成的图像在保留从3D模型中已知的标签的同时，显着逼真。我们应用RenderGAN框架生成附加到蜜蜂的条形码标记的图像。对RenderGAN生成的数据进行DCNN训练比在各种基线上进行训练产生更好的性能。

##### URL
[https://arxiv.org/abs/1611.01331](https://arxiv.org/abs/1611.01331)

##### PDF
[https://arxiv.org/pdf/1611.01331](https://arxiv.org/pdf/1611.01331)

