---
layout: post
title: "Connecting Gaze, Scene, and Attention: Generalized Attention Estimation via Joint Modeling of Gaze and Scene Saliency"
date: 2018-07-27 05:25:52
categories: arXiv_CV
tags: arXiv_CV Salient Attention Prediction
author: Eunji Chong, Nataniel Ruiz, Yongxin Wang, Yun Zhang, Agata Rozga, James Rehg
mathjax: true
---

* content
{:toc}

##### Abstract
This paper addresses the challenging problem of estimating the general visual attention of people in images. Our proposed method is designed to work across multiple naturalistic social scenarios and provides a full picture of the subject's attention and gaze. In contrast, earlier works on gaze and attention estimation have focused on constrained problems in more specific contexts. In particular, our model explicitly represents the gaze direction and handles out-of-frame gaze targets. We leverage three different datasets using a multi-task learning approach. We evaluate our method on widely used benchmarks for single-tasks such as gaze angle estimation and attention-within-an-image, as well as on the new challenging task of generalized visual attention prediction. In addition, we have created extended annotations for the MMDB and GazeFollow datasets which are used in our experiments, which we will publicly release.

##### Abstract (translated by Google)
本文讨论了估计图像中人们的一般视觉注意力的挑战性问题。我们提出的方法旨在跨多个自然社会场景，并提供主题的注意和凝视的全貌。相比之下，早期关于凝视和注意力估计的工作集中在更具体的环境中的约束问题上。特别是，我们的模型明确地表示凝视方向并处理框外凝视目标。我们使用多任务学习方法来利用三个不同的数据集。我们对广泛使用的单一任务基准进行评估，例如注视角度估计和图像内部注意，以及广义视觉注意力预测的新挑战性任务。此外，我们还为我们将公开发布的实验中使用的MMDB和GazeFollow数据集创建了扩展注释。

##### URL
[http://arxiv.org/abs/1807.10437](http://arxiv.org/abs/1807.10437)

##### PDF
[http://arxiv.org/pdf/1807.10437](http://arxiv.org/pdf/1807.10437)

