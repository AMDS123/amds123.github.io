---
layout: post
title: "Using Synthetic Data to Train Neural Networks is Model-Based Reasoning"
date: 2017-03-02 17:43:19
categories: arXiv_CV
tags: arXiv_CV Face Inference Recognition
author: Tuan Anh Le, Atilim Gunes Baydin, Robert Zinkov, Frank Wood
mathjax: true
---

* content
{:toc}

##### Abstract
We draw a formal connection between using synthetic training data to optimize neural network parameters and approximate, Bayesian, model-based reasoning. In particular, training a neural network using synthetic data can be viewed as learning a proposal distribution generator for approximate inference in the synthetic-data generative model. We demonstrate this connection in a recognition task where we develop a novel Captcha-breaking architecture and train it using synthetic data, demonstrating both state-of-the-art performance and a way of computing task-specific posterior uncertainty. Using a neural network trained this way, we also demonstrate successful breaking of real-world Captchas currently used by Facebook and Wikipedia. Reasoning from these empirical results and drawing connections with Bayesian modeling, we discuss the robustness of synthetic data results and suggest important considerations for ensuring good neural network generalization when training with synthetic data.

##### Abstract (translated by Google)
我们在使用合成训练数据来优化神经网络参数和近似贝叶斯模型推理之间建立了正式的联系。特别地，使用合成数据训练神经网络可以被看作是在合成数据生成模型中学习用于近似推断的提议分布生成器。我们在一个识别任务中证明了这种联系，在这个任务中，我们开发了一个新颖的Captcha-breaking体系结构，并使用合成数据进行训练，展示了最先进的性能和计算任务特定的后验不确定性的方法。使用这种方式训练的神经网络，我们也展示了Facebook和维基百科目前使用的真实Captchas的成功打破。从这些实证结果和贝叶斯模型的连接推理，我们讨论了合成数据结果的鲁棒性，并提出了在合成数据训练时确保良好神经网络泛化的重要考虑。

##### URL
[https://arxiv.org/abs/1703.00868](https://arxiv.org/abs/1703.00868)

##### PDF
[https://arxiv.org/pdf/1703.00868](https://arxiv.org/pdf/1703.00868)

