---
layout: post
title: "Learning Shape-from-Shading for Deformable Surfaces"
date: 2018-03-23 17:46:20
categories: arXiv_CV
tags: arXiv_CV Face
author: Jan Bednařík, Pascal Fua, Mathieu Salzmann
mathjax: true
---

* content
{:toc}

##### Abstract
Recent years have seen the development of mature solutions for reconstructing deformable surfaces from a single image, provided that they are relatively well-textured. By contrast, recovering the 3D shape of texture-less surfaces remains an open problem, and essentially relates to Shape-from-Shading. In this paper, we introduce a data-driven approach to this problem. We introduce a general framework that can predict diverse 3D representations, such as meshes, normals, and depth maps. Our experiments show that, in contrast with the well-textured scenario, meshes a ill-suited to handle texture-less 3D reconstruction. Furthermore, we demonstrate that our approach generalizes well to unseen objects, and that it yields higher-quality reconstructions than a state-of-the-art SfS technique, particularly in terms of normal estimates. Our reconstructions accurately model the fine details of the surfaces, such as the creases of a T-Shirt worn by a person.

##### Abstract (translated by Google)
最近几年已经看到了从单一图像重建可变形表面的成熟解决方案的发展，只要它们具有相对良好的纹理。相比之下，恢复无纹理表面的3D形状仍然是一个悬而未决的问题，并且本质上涉及从阴影造型。在本文中，我们介绍了一个数据驱动的方法来解决这个问题。我们介绍一个可以预测各种3D表示的通用框架，例如网格，法线和深度图。我们的实验表明，与纹理良好的场景相反，网格不适合处理无纹理的3D重建。此外，我们证明了我们的方法很好地适用于看不见的物体，并且它比最先进的SfS技术产生更高质量的重建，特别是在正常估计方面。我们的重建精确地模拟了表面的细节，例如人穿的T恤的折痕。

##### URL
[https://arxiv.org/abs/1803.08908](https://arxiv.org/abs/1803.08908)

##### PDF
[https://arxiv.org/pdf/1803.08908](https://arxiv.org/pdf/1803.08908)

