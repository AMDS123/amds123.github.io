---
layout: post
title: "WEPSAM: Weakly Pre-Learnt Saliency Model"
date: 2016-05-03 21:47:33
categories: arXiv_CV
tags: arXiv_CV Salient Sparse Prediction Detection
author: Avisek Lahiri, Sourya Roy, Anirban Santara, Pabitra Mitra, Prabir Kumar Biswas
mathjax: true
---

* content
{:toc}

##### Abstract
Visual saliency detection tries to mimic human vision psychology which concentrates on sparse, important areas in natural image. Saliency prediction research has been traditionally based on low level features such as contrast, edge, etc. Recent thrust in saliency prediction research is to learn high level semantics using ground truth eye fixation datasets. In this paper we present, WEPSAM : Weakly Pre-Learnt Saliency Model as a pioneering effort of using domain specific pre-learing on ImageNet for saliency prediction using a light weight CNN architecture. The paper proposes a two step hierarchical learning, in which the first step is to develop a framework for weakly pre-training on a large scale dataset such as ImageNet which is void of human eye fixation maps. The second step refines the pre-trained model on a limited set of ground truth fixations. Analysis of loss on iSUN and SALICON datasets reveal that pre-trained network converges much faster compared to randomly initialized network. WEPSAM also outperforms some recent state-of-the-art saliency prediction models on the challenging MIT300 dataset.

##### Abstract (translated by Google)
视觉显着性检测试图模仿人类视觉心理学，它集中在自然图像中稀疏的重要区域。显着性预测研究传统上基于诸如对比度，边缘等低级特征。最近在显着性预测研究中的重点是使用基础真实性眼固定数据集学习高级语义。在本文中，我们提出了WEPSAM：弱预知显着性模型，作为使用轻量级CNN架构在ImageNet上使用领域特定的预先学习进行显着性预测的开创性工作。本文提出了一个两步的层次学习，其中第一步是开发一个大规模的数据集，如ImageNet的弱预训练框架，这是没有人类的眼睛注视地图。第二步是在有限的一组地面真实情况下对预先训练好的模型进行细化。 iSUN和SALICON数据集的损失分析表明，与随机初始化网络相比，预训练网络收敛速度更快。 WEPSAM也胜过了最近在具有挑战性的MIT300数据集上的最新的显着性预测模型。

##### URL
[https://arxiv.org/abs/1605.01101](https://arxiv.org/abs/1605.01101)

##### PDF
[https://arxiv.org/pdf/1605.01101](https://arxiv.org/pdf/1605.01101)

