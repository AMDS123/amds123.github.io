---
layout: post
title: "Sparse Architectures for Text-Independent Speaker Verification Using Deep Neural Networks"
date: 2018-05-19 17:35:14
categories: arXiv_SD
tags: arXiv_SD Sparse
author: Sara Sedighi
mathjax: true
---

* content
{:toc}

##### Abstract
Network pruning is of great importance due to the elimination of the unimportant weights or features activated due to the network over-parametrization. Advantages of sparsity enforcement include preventing the overfitting and speedup. Considering a large number of parameters in deep architectures, network compression becomes of critical importance due to the required huge amount of computational power. In this work, we impose structured sparsity for speaker verification which is the validation of the query speaker compared to the speaker gallery. We will show that the mere sparsity enforcement can improve the verification results due to the possible initial overfitting in the network.

##### Abstract (translated by Google)
网络修剪非常重要，因为消除了由于网络过度参数化而激活的不重要的权重或功能。稀疏执法的优势包括防止过度配合和加速。考虑到深层架构中的大量参数，由于需要大量的计算能力，网络压缩变得非常重要。在这项工作中，我们对说话人验证施加了结构化的稀疏性，这是说话人说话人相对于说话人说话人的验证。我们将证明，由于网络中可能出现的初始过度配置，单纯的稀疏执行可以提高验证结果。

##### URL
[https://arxiv.org/abs/1805.07628](https://arxiv.org/abs/1805.07628)

##### PDF
[https://arxiv.org/pdf/1805.07628](https://arxiv.org/pdf/1805.07628)

