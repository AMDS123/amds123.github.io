---
layout: post
title: "STD2P: RGBD Semantic Segmentation Using Spatio-Temporal Data-Driven Pooling"
date: 2017-04-26 13:13:02
categories: arXiv_CV
tags: arXiv_CV Segmentation CNN Semantic_Segmentation Prediction
author: Yang He, Wei-Chen Chiu, Margret Keuper, Mario Fritz
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel superpixel-based multi-view convolutional neural network for semantic image segmentation. The proposed network produces a high quality segmentation of a single image by leveraging information from additional views of the same scene. Particularly in indoor videos such as captured by robotic platforms or handheld and bodyworn RGBD cameras, nearby video frames provide diverse viewpoints and additional context of objects and scenes. To leverage such information, we first compute region correspondences by optical flow and image boundary-based superpixels. Given these region correspondences, we propose a novel spatio-temporal pooling layer to aggregate information over space and time. We evaluate our approach on the NYU--Depth--V2 and the SUN3D datasets and compare it to various state-of-the-art single-view and multi-view approaches. Besides a general improvement over the state-of-the-art, we also show the benefits of making use of unlabeled frames during training for multi-view as well as single-view prediction.

##### Abstract (translated by Google)
我们提出了一种新颖的基于超像素的多视角卷积神经网络进行语义图像分割。所提出的网络通过利用来自相同场景的附加视图的信息来产生单个图像的高质量分割。特别是在诸如机器人平台或手持式和人体工学RGBD摄像机捕获的室内视频中，附近的视频帧提供了不同的视点和附加的对象和场景的上下文。为了利用这些信息，我们首先通过光流和基于图像边界的超像素来计算区域对应关系。考虑到这些区域的对应关系，我们提出了一个新的时空汇聚层来聚合空间和时间的信息。我们评估我们的方法在纽约大学 - 深度 -  V2和SUN3D数据集，并将其与各种最先进的单视图和多视图方法进行比较。除了对现有技术的普遍改进之外，我们还展示了在多视图和单视图预测训练期间使用无标签帧的好处。

##### URL
[https://arxiv.org/abs/1604.02388](https://arxiv.org/abs/1604.02388)

##### PDF
[https://arxiv.org/pdf/1604.02388](https://arxiv.org/pdf/1604.02388)

