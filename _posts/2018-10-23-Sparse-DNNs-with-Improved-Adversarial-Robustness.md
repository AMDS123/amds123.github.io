---
layout: post
title: "Sparse DNNs with Improved Adversarial Robustness"
date: 2018-10-23 01:05:41
categories: arXiv_CV
tags: arXiv_CV Adversarial Sparse Classification Relation
author: Yiwen Guo, Chao Zhang, Changshui Zhang, Yurong Chen
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks (DNNs) are computationally/memory-intensive and vulnerable to adversarial attacks, making them prohibitive in some real-world applications. By converting dense models into sparse ones, pruning appears to be a promising solution to reducing the computation/memory cost. This paper studies classification models, especially DNN-based ones, to demonstrate that there exists intrinsic relationships between their sparsity and adversarial robustness. Our analyses reveal, both theoretically and empirically, that nonlinear DNN-based classifiers behave differently under $l_2$ attacks from some linear ones. We further demonstrate that an appropriately higher model sparsity implies better robustness of nonlinear DNNs, whereas over-sparsified models can be more difficult to resist adversarial examples.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.09619](http://arxiv.org/abs/1810.09619)

##### PDF
[http://arxiv.org/pdf/1810.09619](http://arxiv.org/pdf/1810.09619)

