---
layout: post
title: "Responses to a Critique of Artificial Moral Agents"
date: 2019-03-17 03:18:24
categories: arXiv_AI
tags: arXiv_AI
author: Adam Poulsen, Michael Anderson, Susan L. Anderson, Ben Byford, Fabio Fossa, Erica L. Neely, Alejandro Rosas, Alan Winfield
mathjax: true
---

* content
{:toc}

##### Abstract
The field of machine ethics is concerned with the question of how to embed ethical behaviors, or a means to determine ethical behaviors, into artificial intelligence (AI) systems. The goal is to produce artificial moral agents (AMAs) that are either implicitly ethical (designed to avoid unethical consequences) or explicitly ethical (designed to behave ethically). Van Wynsberghe and Robbins' (2018) paper Critiquing the Reasons for Making Artificial Moral Agents critically addresses the reasons offered by machine ethicists for pursuing AMA research; this paper, co-authored by machine ethicists and commentators, aims to contribute to the machine ethics conversation by responding to that critique. The reasons for developing AMAs discussed in van Wynsberghe and Robbins (2018) are: it is inevitable that they will be developed; the prevention of harm; the necessity for public trust; the prevention of immoral use; such machines are better moral reasoners than humans, and building these machines would lead to a better understanding of human morality. In this paper, each co-author addresses those reasons in turn. In so doing, this paper demonstrates that the reasons critiqued are not shared by all co-authors; each machine ethicist has their own reasons for researching AMAs. But while we express a diverse range of views on each of the six reasons in van Wynsberghe and Robbins' critique, we nevertheless share the opinion that the scientific study of AMAs has considerable value.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.07021](http://arxiv.org/abs/1903.07021)

##### PDF
[http://arxiv.org/pdf/1903.07021](http://arxiv.org/pdf/1903.07021)

