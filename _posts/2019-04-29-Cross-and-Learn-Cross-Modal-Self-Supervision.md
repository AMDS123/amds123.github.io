---
layout: post
title: "Cross and Learn: Cross-Modal Self-Supervision"
date: 2019-04-29 17:00:34
categories: arXiv_CV
tags: arXiv_CV Action_Recognition Represenation_Learning Recognition
author: Nawid Sayed, Biagio Brattoli, Bj&#xf6;rn Ommer
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we present a self-supervised method for representation learning utilizing two different modalities. Based on the observation that cross-modal information has a high semantic meaning we propose a method to effectively exploit this signal. For our approach we utilize video data since it is available on a large scale and provides easily accessible modalities given by RGB and optical flow. We demonstrate state-of-the-art performance on highly contested action recognition datasets in the context of self-supervised learning. We show that our feature representation also transfers to other tasks and conduct extensive ablation studies to validate our core contributions. Code and model can be found at https://github.com/nawidsayed/Cross-and-Learn.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.03879](http://arxiv.org/abs/1811.03879)

##### PDF
[http://arxiv.org/pdf/1811.03879](http://arxiv.org/pdf/1811.03879)

