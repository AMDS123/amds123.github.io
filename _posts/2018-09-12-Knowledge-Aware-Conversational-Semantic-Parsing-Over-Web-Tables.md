---
layout: post
title: "Knowledge-Aware Conversational Semantic Parsing Over Web Tables"
date: 2018-09-12 06:37:51
categories: arXiv_CL
tags: arXiv_CL Knowledge QA Language_Model
author: Yibo Sun, Duyu Tang, Nan Duan, Jingjing Xu, Xiaocheng Feng, Bing Qin
mathjax: true
---

* content
{:toc}

##### Abstract
Conversational semantic parsing over tables requires knowledge acquiring and reasoning abilities, which have not been well explored by current state-of-the-art approaches. Motivated by this fact, we propose a knowledge-aware semantic parser to improve parsing performance by integrating various types of knowledge. In this paper, we consider three types of knowledge, including grammar knowledge, expert knowledge, and external resource knowledge. First, grammar knowledge empowers the model to effectively replicate previously generated logical form, which effectively handles the co-reference and ellipsis phenomena in conversation Second, based on expert knowledge, we propose a decomposable model, which is more controllable compared with traditional end-to-end models that put all the burdens of learning on trial-and-error in an end-to-end way. Third, external resource knowledge, i.e., provided by a pre-trained language model or an entity typing model, is used to improve the representation of question and table for a better semantic understanding. We conduct experiments on the SequentialQA dataset. Results show that our knowledge-aware model outperforms the state-of-the-art approaches. Incremental experimental results also prove the usefulness of various knowledge. Further analysis shows that our approach has the ability to derive the meaning representation of a context-dependent utterance by leveraging previously generated outcomes.

##### Abstract (translated by Google)
对表的会话语义解析需要知识获取和推理能力，这些都是当前最先进的方法尚未充分探索的。受此事实的启发，我们提出了一种知识感知语义解析器，通过集成各种类型的知识来提高解析性能。在本文中，我们考虑三种类型的知识，包括语法知识，专家知识和外部资源知识。首先，语法知识使模型能够有效地复制先前生成的逻辑形式，有效地处理会话中的共参考和省略现象。其次，基于专家知识，我们提出了一种可分解​​的模型，与传统的end-to相比，它更具可控性。 - 以端到端的方式将所有学习负担放在反复试验中的模型。第三，外部资源知识，即由预训练的语言模型或实体打字模型提供，用于改进问题和表格的表示，以便更好地理解语义。我们在SequentialQA数据集上进行实验。结果表明，我们的知识感知模型优于最先进的方法。增量实验结果也证明了各种知识的有用性。进一步分析表明，我们的方法能够通过利用先前生成的结果来推导依赖于上下文的话语的意义表示。

##### URL
[http://arxiv.org/abs/1809.04271](http://arxiv.org/abs/1809.04271)

##### PDF
[http://arxiv.org/pdf/1809.04271](http://arxiv.org/pdf/1809.04271)

