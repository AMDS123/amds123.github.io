---
layout: post
title: "A Generic Method for Automatic Ground Truth Generation of Camera-captured Documents"
date: 2016-05-04 09:25:04
categories: arXiv_CV
tags: arXiv_CV OCR Recognition
author: Sheraz Ahmed, Muhammad Imran Malik, Muhammad Zeshan Afzal, Koichi Kise, Masakazu Iwamura, Andreas Dengel, Marcus Liwicki
mathjax: true
---

* content
{:toc}

##### Abstract
The contribution of this paper is fourfold. The first contribution is a novel, generic method for automatic ground truth generation of camera-captured document images (books, magazines, articles, invoices, etc.). It enables us to build large-scale (i.e., millions of images) labeled camera-captured/scanned documents datasets, without any human intervention. The method is generic, language independent and can be used for generation of labeled documents datasets (both scanned and cameracaptured) in any cursive and non-cursive language, e.g., English, Russian, Arabic, Urdu, etc. To assess the effectiveness of the presented method, two different datasets in English and Russian are generated using the presented method. Evaluation of samples from the two datasets shows that 99:98% of the images were correctly labeled. The second contribution is a large dataset (called C3Wi) of camera-captured characters and words images, comprising 1 million word images (10 million character images), captured in a real camera-based acquisition. This dataset can be used for training as well as testing of character recognition systems on camera-captured documents. The third contribution is a novel method for the recognition of cameracaptured document images. The proposed method is based on Long Short-Term Memory and outperforms the state-of-the-art methods for camera based OCRs. As a fourth contribution, various benchmark tests are performed to uncover the behavior of commercial (ABBYY), open source (Tesseract), and the presented camera-based OCR using the presented C3Wi dataset. Evaluation results reveal that the existing OCRs, which already get very high accuracies on scanned documents, have limited performance on camera-captured document images; where ABBYY has an accuracy of 75%, Tesseract an accuracy of 50.22%, while the presented character recognition system has an accuracy of 95.10%.

##### Abstract (translated by Google)
本文的贡献有四个。第一个贡献是一种新颖的通用方法，用于自动生成照相机拍摄的文档图像（书籍，杂志，文章，发票等）。它使我们能够在没有任何人为干预的情况下构建大规模（即数百万张图像）标记的相机捕获/扫描文档数据集。该方法是通用的，独立于语言的，可用于以任何草书和非草书语言（例如英语，俄语，阿拉伯语，乌尔都语等）生成标记的文档数据集（包括扫描的和腮腺炎的）。为了评估提出的方法，使用所提出的方法生成英文和俄文两个不同的数据集。两个数据集的样本评估显示99：98％的图像被正确标记。第二个贡献是一个大型的数据集（称为C3Wi）的相机捕获的字符和单词图像，包括100万字图像（1000万字符的图像），捕捉在一个真正的摄像头采集。该数据集可以用于培训以及在相机捕获的文档上测试字符识别系统。第三个贡献是识别摄影文件图像的新方法。所提出的方法基于长期短期记忆，并且胜过基于相机的OCR的最先进的方法。作为第四个贡献，使用所提供的C3Wi数据集来执行各种基准测试以揭示商业（ABBYY），开源（Tesseract）以及所提出的基于相机的OCR的行为。评估结果显示，已经在扫描文档上获得非常高精度的现有OCR在相机捕获的文档图像上的性能有限;其中ABBYY的准确率为75％，Tesseract准确率为50.22％，而所提供的字符识别系统的准确率为95.10％。

##### URL
[https://arxiv.org/abs/1605.01189](https://arxiv.org/abs/1605.01189)

##### PDF
[https://arxiv.org/pdf/1605.01189](https://arxiv.org/pdf/1605.01189)

