---
layout: post
title: "Unsupervised state representation learning with robotic priors: a robustness benchmark"
date: 2017-09-15 13:15:58
categories: arXiv_CV
tags: arXiv_CV Knowledge GAN Reinforcement_Learning Transfer_Learning Represenation_Learning Quantitative
author: Timothée Lesort, Mathieu Seurin, Xinrui Li, Natalia Díaz Rodríguez, David Filliat
mathjax: true
---

* content
{:toc}

##### Abstract
Our understanding of the world depends highly on our capacity to produce intuitive and simplified representations which can be easily used to solve problems. We reproduce this simplification process using a neural network to build a low dimensional state representation of the world from images acquired by a robot. As in Jonschkowski et al. 2015, we learn in an unsupervised way using prior knowledge about the world as loss functions called robotic priors and extend this approach to high dimension richer images to learn a 3D representation of the hand position of a robot from RGB images. We propose a quantitative evaluation of the learned representation using nearest neighbors in the state space that allows to assess its quality and show both the potential and limitations of robotic priors in realistic environments. We augment image size, add distractors and domain randomization, all crucial components to achieve transfer learning to real robots. Finally, we also contribute a new prior to improve the robustness of the representation. The applications of such low dimensional state representation range from easing reinforcement learning (RL) and knowledge transfer across tasks, to facilitating learning from raw data with more efficient and compact high level representations. The results show that the robotic prior approach is able to extract high level representation as the 3D position of an arm and organize it into a compact and coherent space of states in a challenging dataset.

##### Abstract (translated by Google)
我们对世界的理解很大程度上取决于我们生成直观和简化的表示的能力，这些表示可以很容易地用来解决问题。我们使用神经网络重现这个简化过程，从机器人获取的图像中建立一个低维状态的世界。如在Jonschkowski等人2015年，我们以一种无监督的方式学习，使用关于世界的先验知识作为称为机器人先验的损失函数，并且将这种方法扩展到高维度更丰富的图像，以学习从RGB图像中机器人的手位置的3D表示。我们提出了在状态空间中使用最近邻居的学习表示的量化评估，允许评估其质量，并显示在现实环境中机器人先验的潜力和局限性。我们增加图像大小，添加干扰和域随机化，所有关键组件实现转移学习到真正的机器人。最后，我们也提出了一个新的提高代表性的鲁棒性。这种低维状态表示的应用范围从宽松强化学习（RL）和跨任务的知识转移，到以更高效和紧凑的高级表示方式帮助学习原始数据。结果表明，机器人先验方法能够提取高水平表示作为手臂的三维位置，并将其组织成具有挑战性的数据集中的一个紧凑而连贯的状态空间。

##### URL
[https://arxiv.org/abs/1709.05185](https://arxiv.org/abs/1709.05185)

##### PDF
[https://arxiv.org/pdf/1709.05185](https://arxiv.org/pdf/1709.05185)

