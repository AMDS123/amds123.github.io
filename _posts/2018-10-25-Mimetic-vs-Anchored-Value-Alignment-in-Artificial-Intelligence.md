---
layout: post
title: "Mimetic vs Anchored Value Alignment in Artificial Intelligence"
date: 2018-10-25 21:34:21
categories: arXiv_AI
tags: arXiv_AI
author: Tae Wan Kim, Thomas Donaldson, John Hooker
mathjax: true
---

* content
{:toc}

##### Abstract
"Value alignment" (VA) is considered as one of the top priorities in AI research. Much of the existing research focuses on the "A" part and not the "V" part of "value alignment." This paper corrects that neglect by emphasizing the "value" side of VA and analyzes VA from the vantage point of requirements in value theory, in particular, of avoiding the "naturalistic fallacy"--a major epistemic caveat. The paper begins by isolating two distinct forms of VA: "mimetic" and "anchored." Then it discusses which VA approach better avoids the naturalistic fallacy. The discussion reveals stumbling blocks for VA approaches that neglect implications of the naturalistic fallacy. Such problems are more serious in mimetic VA since the mimetic process imitates human behavior that may or may not rise to the level of correct ethical behavior. Anchored VA, including hybrid VA, in contrast, holds more promise for future VA since it anchors alignment by normative concepts of intrinsic value.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.11116](http://arxiv.org/abs/1810.11116)

##### PDF
[http://arxiv.org/pdf/1810.11116](http://arxiv.org/pdf/1810.11116)

