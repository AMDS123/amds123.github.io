---
layout: post
title: "Moments in Time Dataset: one million videos for event understanding"
date: 2018-01-09 21:46:38
categories: arXiv_AI
tags: arXiv_AI Action_Recognition Recognition
author: Mathew Monfort, Bolei Zhou, Sarah Adel Bargal, Alex Andonian, Tom Yan, Kandan Ramakrishnan, Lisa Brown, Quanfu Fan, Dan Gutfruend, Carl Vondrick, Aude Oliva
mathjax: true
---

* content
{:toc}

##### Abstract
We present the Moments in Time Dataset, a large-scale human-annotated collection of one million short videos corresponding to dynamic events unfolding within three seconds. Modeling the spatial-audio-temporal dynamics even for actions occurring in 3 second videos poses many challenges: meaningful events do not include only people, but also objects, animals, and natural phenomena; visual and auditory events can be symmetrical or not in time ("opening" means "closing" in reverse order), and transient or sustained. We describe the annotation process of our dataset (each video is tagged with one action or activity label among 339 different classes), analyze its scale and diversity in comparison to other large-scale video datasets for action recognition, and report results of several baseline models addressing separately and jointly three modalities: spatial, temporal and auditory. The Moments in Time dataset designed to have a large coverage and diversity of events in both visual and auditory modalities, can serve as a new challenge to develop models that scale to the level of complexity and abstract reasoning that a human processes on a daily basis.

##### Abstract (translated by Google)
我们展示了时间数据集中的瞬间，这是一个大型的人类注释的100万短视频集合，对应于三秒内展开的动态事件。即使对于3秒钟视频中发生的动作，对空间音频 - 时间动态进行建模也带来许多挑战：有意义的事件不仅包括人物，还包括物体，动物和自然现象;视觉和听觉事件可以是对称的或不及时的（“开放”意味着以相反的顺序“关闭”），并且是暂时的或持续的。我们描述了我们的数据集的标注过程（每个视频在339个不同的类别中标记有一个动作或活动标签），分析其大小和多样性与其他大型视频数据集相比，用于动作识别，并报告几个基线模型分别和联合地处理三种模式：空间，时间和听觉。 Moments in Time数据集被设计为在视觉和听觉模式中具有大范围的事件覆盖和多样性，可以作为一个新的挑战来开发模型，扩展到复杂程度和抽象的推理，人类每天的过程。

##### URL
[https://arxiv.org/abs/1801.03150](https://arxiv.org/abs/1801.03150)

##### PDF
[https://arxiv.org/pdf/1801.03150](https://arxiv.org/pdf/1801.03150)

