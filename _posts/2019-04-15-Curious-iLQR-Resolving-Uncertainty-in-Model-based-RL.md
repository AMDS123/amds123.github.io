---
layout: post
title: "Curious iLQR: Resolving Uncertainty in Model-based RL"
date: 2019-04-15 00:02:27
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization
author: Sarah Bechtle, Akshara Rai, Yixin Lin, Ludovic Righetti, Franziska Meier
mathjax: true
---

* content
{:toc}

##### Abstract
Curiosity as a means to explore during reinforcement learning problems has recently become very popular. However, very little progress has been made in utilizing curiosity for learning control. In this work, we propose a model-based reinforcement learning (MBRL) framework that combines Bayesian modeling of the system dynamics with curious iLQR, a risk-seeking iterative LQR approach. During trajectory optimization the curious iLQR attempts to minimize both the task-dependent cost and the uncertainty in the dynamics model. We scale this approach to perform reaching tasks on 7-DoF manipulators, to perform both simulation and real robot reaching experiments. Our experiments consistently show that MBRL with curious iLQR more easily overcomes bad initial dynamics models and reaches desired joint configurations more reliably and with less system rollouts.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.06786](http://arxiv.org/abs/1904.06786)

##### PDF
[http://arxiv.org/pdf/1904.06786](http://arxiv.org/pdf/1904.06786)

