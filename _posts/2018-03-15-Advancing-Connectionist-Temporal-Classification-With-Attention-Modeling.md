---
layout: post
title: "Advancing Connectionist Temporal Classification With Attention Modeling"
date: 2018-03-15 01:19:21
categories: arXiv_CL
tags: arXiv_CL Attention Speech_Recognition Classification Language_Model Recognition
author: Amit Das, Jinyu Li, Rui Zhao, Yifan Gong
mathjax: true
---

* content
{:toc}

##### Abstract
In this study, we propose advancing all-neural speech recognition by directly incorporating attention modeling within the Connectionist Temporal Classification (CTC) framework. In particular, we derive new context vectors using time convolution features to model attention as part of the CTC network. To further improve attention modeling, we utilize content information extracted from a network representing an implicit language model. Finally, we introduce vector based attention weights that are applied on context vectors across both time and their individual components. We evaluate our system on a 3400 hours Microsoft Cortana voice assistant task and demonstrate that our proposed model consistently outperforms the baseline model achieving about 20% relative reduction in word error rates.

##### Abstract (translated by Google)
在这项研究中，我们提出了通过在连接主义时间分类（CTC）框架中直接引入注意力建模来推进全神经语音识别。特别是，我们使用时间卷积特征推导出新的上下文向量，以将注意力建模为CTC网络的一部分。为了进一步改进关注建模，我们利用从网络提取的内容信息来表示隐式语言模型。最后，我们引入基于矢量的注意力权重，这些权重应用于时间及其各个组件上的上下文向量。我们在一个3400小时的Microsoft Cortana语音助手任务上评估我们的系统，并证明我们提出的模型始终优于基准模型，实现了大约20％的字错误率相对降低。

##### URL
[https://arxiv.org/abs/1803.05563](https://arxiv.org/abs/1803.05563)

##### PDF
[https://arxiv.org/pdf/1803.05563](https://arxiv.org/pdf/1803.05563)

