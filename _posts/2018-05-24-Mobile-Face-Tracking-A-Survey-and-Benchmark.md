---
layout: post
title: "Mobile Face Tracking: A Survey and Benchmark"
date: 2018-05-24 15:59:22
categories: arXiv_CV
tags: arXiv_CV Face Tracking Survey Deep_Learning Quantitative Detection Face_Detection Relation
author: Yiming Lin, Jie Shen, Shiyang Cheng, Maja Pantic
mathjax: true
---

* content
{:toc}

##### Abstract
With the rapid development of smartphones, facial analysis has been playing an increasingly important role in a multitude of mobile applications. In most scenarios, face tracking serves as a crucial first step because more often than not, a mobile application would only need to focus on analysing a specific face in a complex setting. Albeit inheriting many commons traits of the generic visual tracking problem, face tracking in mobile scenarios is characterised by a unique set of challenges. In this work, we propose iBUG MobiFace benchmark, the first mobile face tracking benchmark consisting of 50 sequences captured by smartphone users in unconstrained environments. The sequences contain a total of 50,736 frames with 46 distinct identities to be tracked. The tracking target in each sequence is selected with varying difficulties in mobile scenarios. In addition to frame by frame bounding box, the annotations of 9 sequence attributes(e.g. multiple faces) are provided. We further provide a survey of 23 state-of-the-art visual trackers and a comprehensive quantitative evaluation of these methods on the proposed benchmark. In particular, trackers from two most popular frameworks, namely, correlation filter-based tracking and deep learning-based tracking, are studied. Our experiment shows that (a) the performance of all existing generic object trackers drops significantly on the mobile face tracking scenario, suggesting the need of more research effort into mobile face tracking, and (b) the effective combination of deep learning tracking and face-related algorithms(e.g. face detection) provides the most promising basis for future developments in the field. The database, annotations and evaluation protocol/code will be made publicly available on the iBUG website.

##### Abstract (translated by Google)
随着智能手机的迅速发展，面部分析在众多移动应用中扮演着越来越重要的角色。在大多数情况下，面部追踪是至关重要的第一步，因为移动应用程序往往只需要专注于分析复杂环境中的特定面部。尽管继承了通用视觉追踪问题的许多共同特征，但在移动场景中的人脸追踪具有独特的挑战。在这项工作中，我们提出了iBUG MobiFace基准测试，这是第一款由智能手机用户在无约束环境中捕获的序列组成的首个移动人脸跟踪基准。该序列总共包含50,736帧，其中46个不同的身份将被跟踪。在移动场景中，每个序列中的追踪目标在不同的困难中被选择。除了逐帧边界框外，还提供了9个序列属性（例如多个面）的注释。我们进一步提供了23个最先进的视觉跟踪器的调查，并对提出的基准进行了这些方法的全面量化评估。特别是，研究了两种最流行的框架，即基于相关滤波器的跟踪和基于深度学习的跟踪。我们的实验表明：（a）所有现有的通用对象跟踪器的性能在移动人脸跟踪场景中显着下降，这表明需要更多的研究工作来进行移动人脸跟踪;（b）深度学习跟踪和面对面跟踪的有效结合，相关算法（例如人脸检测）为该领域的未来发展提供了最有前景的基础。数据库，注释和评估协议/代码将在iBUG网站上公开发布。

##### URL
[http://arxiv.org/abs/1805.09749](http://arxiv.org/abs/1805.09749)

##### PDF
[http://arxiv.org/pdf/1805.09749](http://arxiv.org/pdf/1805.09749)

