---
layout: post
title: "Do Embedding Models Perform Well for Knowledge Base Completion?"
date: 2018-11-06 13:30:39
categories: arXiv_AI
tags: arXiv_AI Knowledge Embedding
author: Yanjie Wang, Daniel Ruffinelli, Rainer Gemulla, Samuel Broscheit, Christian Meilicke
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we put into question the effectiveness of the evaluation methods currently used to measure the performance of latent factor models for the task of knowledge base completion. We argue that by focusing on a small subset of possible facts in the knowledge base, current evaluation practices are better suited for question answering tasks, rather than knowledge base completion, where it is also important to avoid the addition of incorrect facts into the knowledge base. We illustrate our point by showing how models with limited expressiveness achieve state-of-the-art performance, even while adding many incorrect (even nonsensical) facts to a knowledge base. Finally, we show that when using a simple evaluation procedure designed to also penalize the addition of incorrect facts, the general and relative performance of all models looks very different than previously seen. This indicates the need for more powerful latent factor models for the task of knowledge base completion.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.07180](http://arxiv.org/abs/1810.07180)

##### PDF
[http://arxiv.org/pdf/1810.07180](http://arxiv.org/pdf/1810.07180)

