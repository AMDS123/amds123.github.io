---
layout: post
title: "A bird's-eye view on coherence, and a worm's-eye view on cohesion"
date: 2018-11-01 17:30:50
categories: arXiv_CL
tags: arXiv_CL Attention Text_Generation Language_Model
author: Woon Sang Cho, Pengchuan Zhang, Yizhe Zhang, Xiujun Li, Michel Galley, Mengdi Wang, Jianfeng Gao
mathjax: true
---

* content
{:toc}

##### Abstract
Generating coherent and cohesive long-form texts is a challenging problem in natural language generation. Previous works relied on a large amount of human-generated texts to train language models, however, few attempted to explicitly model the desired linguistic properties of natural language text, such as coherence and cohesion. In this work, we train two expert discriminators for coherence and cohesion, respectively, to provide hierarchical feedback for text generation. We also propose a simple variant of policy gradient, called 'negative-critical sequence training', using margin rewards, in which the 'baseline' is constructed from randomly generated negative samples. We demonstrate the effectiveness of our approach through empirical studies, showing significant improvements over the strong baseline -- attention-based bidirectional MLE-trained neural language model -- in a number of automated metrics. The proposed discriminators can serve as baseline architectures to promote further research to better extract, encode essential linguistic qualities, such as coherence and cohesion.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.00511](http://arxiv.org/abs/1811.00511)

##### PDF
[http://arxiv.org/pdf/1811.00511](http://arxiv.org/pdf/1811.00511)

