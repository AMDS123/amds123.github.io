---
layout: post
title: "Localized Dimension Growth: A Convolutional Random Network Coding Approach to Managing Memory and Decoding Delay"
date: 2013-03-19 04:15:37
categories: arXiv_CV
tags: arXiv_CV Knowledge CNN
author: Guo Wangmei, Shi Xiaomeng (IEEE Student Member), Cai Ning (EEE Senior Member), Muriel Médard (IEEE Fellow)
mathjax: true
---

* content
{:toc}

##### Abstract
We consider an \textit{Adaptive Random Convolutional Network Coding} (ARCNC) algorithm to address the issue of field size in random network coding for multicast, and study its memory and decoding delay performances through both analysis and numerical simulations. ARCNC operates as a convolutional code, with the coefficients of local encoding kernels chosen randomly over a small finite field. The cardinality of local encoding kernels increases with time until the global encoding kernel matrices at related sink nodes have full rank.ARCNC adapts to unknown network topologies without prior knowledge, by locally incrementing the dimensionality of the convolutional code. Because convolutional codes of different constraint lengths can coexist in different portions of the network, reductions in decoding delay and memory overheads can be achieved. We show that this method performs no worse than random linear network codes in terms of decodability, and can provide significant gains in terms of average decoding delay or memory in combination, shuttle and random geometric networks.

##### Abstract (translated by Google)
我们考虑一种自适应随机卷积网络编码（ARCNC）算法来解决多播随机网络编码中的字段大小问题，并通过分析和数值仿真来研究它的存储和解码延迟性能。 ARCNC作为卷积码运行，局部编码核的系数在小的有限域上随机选择。局部编码核的基数随着时间的增加而增加，直到相关汇节点处的全局编码核矩阵具有满秩为止.ARCNC通过局部增加卷积码的维数来适应未知网络拓扑。由于不同约束长度的卷积码可以共存于网络的不同部分，因此可以减少解码延迟和存储开销。我们证明这种方法在可解码性方面不会比随机线性网络编码差，并且可以在平均解码延迟或存储器组合，穿梭和随机几何网络方面提供显着增益。

##### URL
[https://arxiv.org/abs/1303.4484](https://arxiv.org/abs/1303.4484)

##### PDF
[https://arxiv.org/pdf/1303.4484](https://arxiv.org/pdf/1303.4484)

