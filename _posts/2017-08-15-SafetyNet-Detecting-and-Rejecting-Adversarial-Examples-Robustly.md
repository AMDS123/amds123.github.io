---
layout: post
title: "SafetyNet: Detecting and Rejecting Adversarial Examples Robustly"
date: 2017-08-15 05:59:38
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Jiajun Lu, Theerasit Issaranon, David Forsyth
mathjax: true
---

* content
{:toc}

##### Abstract
We describe a method to produce a network where current methods such as DeepFool have great difficulty producing adversarial samples. Our construction suggests some insights into how deep networks work. We provide a reasonable analyses that our construction is difficult to defeat, and show experimentally that our method is hard to defeat with both Type I and Type II attacks using several standard networks and datasets. This SafetyNet architecture is used to an important and novel application SceneProof, which can reliably detect whether an image is a picture of a real scene or not. SceneProof applies to images captured with depth maps (RGBD images) and checks if a pair of image and depth map is consistent. It relies on the relative difficulty of producing naturalistic depth maps for images in post processing. We demonstrate that our SafetyNet is robust to adversarial examples built from currently known attacking approaches.

##### Abstract (translated by Google)
我们描述了一种生成网络的方法，其中现有的方法如DeepFool难以生成对抗样本。我们的建设提供了深入的网络工作的一些见解。我们提供了一个合理的分析，我们的建设是难以打败的，并通过实验表明我们的方法很难用I型和II型攻击使用几个标准网络和数据集来击败。这SafetyNet架构是用于一个重要的和新颖的应用SceneProof，它可以可靠地检测一个图像是否是一个真实的场景的图片。 SceneProof适用于使用深度图（RGBD图像）拍摄的图像，并检查一对图像和深度图是否一致。它依赖于在后期处理中为图像生成自然深度图的相对困难。我们证明我们的安全网对于从目前已知的攻击方法构建的敌对示例是强健的。

##### URL
[https://arxiv.org/abs/1704.00103](https://arxiv.org/abs/1704.00103)

##### PDF
[https://arxiv.org/pdf/1704.00103](https://arxiv.org/pdf/1704.00103)

