---
layout: post
title: "A Feature Learning and Object Recognition Framework for Underwater Fish Images"
date: 2016-03-05 08:33:18
categories: arXiv_CV
tags: arXiv_CV Salient Survey Classification Recognition
author: Meng-Che Chuang, Jenq-Neng Hwang, Kresimir Williams
mathjax: true
---

* content
{:toc}

##### Abstract
Live fish recognition is one of the most crucial elements of fisheries survey applications where vast amount of data are rapidly acquired. Different from general scenarios, challenges to underwater image recognition are posted by poor image quality, uncontrolled objects and environment, as well as difficulty in acquiring representative samples. Also, most existing feature extraction techniques are hindered from automation due to involving human supervision. Toward this end, we propose an underwater fish recognition framework that consists of a fully unsupervised feature learning technique and an error-resilient classifier. Object parts are initialized based on saliency and relaxation labeling to match object parts correctly. A non-rigid part model is then learned based on fitness, separation and discrimination criteria. For the classifier, an unsupervised clustering approach generates a binary class hierarchy, where each node is a classifier. To exploit information from ambiguous images, the notion of partial classification is introduced to assign coarse labels by optimizing the "benefit" of indecision made by the classifier. Experiments show that the proposed framework achieves high accuracy on both public and self-collected underwater fish images with high uncertainty and class imbalance.

##### Abstract (translated by Google)
活鱼识别是渔业调查应用中最重要的元素之一，其中大量的数据被迅速采集。与一般场景不同的是，由于图像质量差，对象和环境不受控制，以及难以获取具有代表性的样本，对水下图像识别提出了挑战。另外，由于涉及人的监督，大多数现有的特征提取技术受到自动化的阻碍。为此，我们提出了一个水下鱼类识别框架，它包含一个完全无监督的特征学习技术和一个错误弹性分类器。对象部分基于显着性和放松标签进行初始化，以正确匹配对象部分。然后根据适应度，分离度和判别标准来学习非刚性零件模型。对于分类器，无监督聚类方法会生成一个二元类层次结构，其中每个节点都是一个分类器。为了利用模糊图像中的信息，引入了部分分类的概念，通过优化分类器产生的优雅的“好处”来分配粗糙的标签。实验结果表明，所提出的框架在公众和自我收集的高度不确定性和类别不平衡的水下鱼类图像上实现了高精度。

##### URL
[https://arxiv.org/abs/1603.01696](https://arxiv.org/abs/1603.01696)

##### PDF
[https://arxiv.org/pdf/1603.01696](https://arxiv.org/pdf/1603.01696)

