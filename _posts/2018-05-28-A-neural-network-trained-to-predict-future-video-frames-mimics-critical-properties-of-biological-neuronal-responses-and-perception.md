---
layout: post
title: "A neural network trained to predict future video frames mimics critical properties of biological neuronal responses and perception"
date: 2018-05-28 02:15:09
categories: arXiv_CV
tags: arXiv_CV CNN Recognition
author: William Lotter, Gabriel Kreiman, David Cox
mathjax: true
---

* content
{:toc}

##### Abstract
While deep neural networks take loose inspiration from neuroscience, it is an open question how seriously to take the analogies between artificial deep networks and biological neuronal systems. Interestingly, recent work has shown that deep convolutional neural networks (CNNs) trained on large-scale image recognition tasks can serve as strikingly good models for predicting the responses of neurons in visual cortex to visual stimuli, suggesting that analogies between artificial and biological neural networks may be more than superficial. However, while CNNs capture key properties of the average responses of cortical neurons, they fail to explain other properties of these neurons. For one, CNNs typically require large quantities of labeled input data for training. Our own brains, in contrast, rarely have access to this kind of supervision, so to the extent that representations are similar between CNNs and brains, this similarity must arise via different training paths. In addition, neurons in visual cortex produce complex time-varying responses even to static inputs, and they dynamically tune themselves to temporal regularities in the visual environment. We argue that these differences are clues to fundamental differences between the computations performed in the brain and in deep networks. To begin to close the gap, here we study the emergent properties of a previously-described recurrent generative network that is trained to predict future video frames in a self-supervised manner. Remarkably, the model is able to capture a wide variety of seemingly disparate phenomena observed in visual cortex, ranging from single unit response dynamics to complex perceptual motion illusions. These results suggest potentially deep connections between recurrent predictive neural network models and the brain, providing new leads that can enrich both fields.

##### Abstract (translated by Google)
尽管深度神经网络从神经科学中获得了灵感，但人们深度网络与生物神经系统之间的类比究竟有多严肃，这是一个悬而未决的问题。有趣的是，最近的研究表明，深度卷积神经网络（CNNs）在大规模图像识别任务上训练可以作为预测视觉皮层神经元对视觉刺激反应的惊人的好模型，表明人造神经网络和生物神经网络可能不仅仅是肤浅的。然而，尽管CNN捕获了皮质神经元平均响应的关键特性，但它们未能解释这些神经元的其他特性。首先，CNN通常需要大量标记的输入数据进行训练。相比之下，我们自己的大脑很少能够获得这种监督，所以就CNN和大脑之间的表征相似而言，这种相似性必须通过不同的培训途径产生。另外，视觉皮层中的神经元即使对静态输入也会产生复杂的时变响应，并且它们会自动将其自身调整为视觉环境中的时间规律。我们认为，这些差异是在大脑和深层网络中进行的计算之间的根本区别的线索。为了缩小差距，我们在这里研究先前描述的经过训练的自发生成网络的自发特性，以自我监督的方式预测未来的视频帧。值得注意的是，该模型能够捕捉视觉皮层中观察到的各种看似不同的现象，从单个单位反应动态到复杂的感知运动幻觉。这些结果表明复发性预测神经网络模型与大脑之间可能存在深层联系，提供可以丰富这两个领域的新的线索。

##### URL
[http://arxiv.org/abs/1805.10734](http://arxiv.org/abs/1805.10734)

##### PDF
[http://arxiv.org/pdf/1805.10734](http://arxiv.org/pdf/1805.10734)

