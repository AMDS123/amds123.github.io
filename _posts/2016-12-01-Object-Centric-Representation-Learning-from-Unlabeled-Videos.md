---
layout: post
title: "Object-Centric Representation Learning from Unlabeled Videos"
date: 2016-12-01 22:36:20
categories: arXiv_CV
tags: arXiv_CV Tracking CNN Image_Classification Represenation_Learning Classification Recognition
author: Ruohan Gao, Dinesh Jayaraman, Kristen Grauman
mathjax: true
---

* content
{:toc}

##### Abstract
Supervised (pre-)training currently yields state-of-the-art performance for representation learning for visual recognition, yet it comes at the cost of (1) intensive manual annotations and (2) an inherent restriction in the scope of data relevant for learning. In this work, we explore unsupervised feature learning from unlabeled video. We introduce a novel object-centric approach to temporal coherence that encourages similar representations to be learned for object-like regions segmented from nearby frames. Our framework relies on a Siamese-triplet network to train a deep convolutional neural network (CNN) representation. Compared to existing temporal coherence methods, our idea has the advantage of lightweight preprocessing of the unlabeled video (no tracking required) while still being able to extract object-level regions from which to learn invariances. Furthermore, as we show in results on several standard datasets, our method typically achieves substantial accuracy gains over competing unsupervised methods for image classification and retrieval tasks.

##### Abstract (translated by Google)
监督（预）训练目前得到了用于视觉识别的表征学习的最新性能，但其代价是（1）密集的手工注释和（2）数据范围内的固有限制学习。在这项工作中，我们从无标签的视频中探索无监督的特征学习。我们引入一种新颖的以时间相干性为中心的方法，鼓励从邻近帧分割出的类似物体区域学习类似的表示。我们的框架依赖于一个连体三重网络来训练深度卷积神经网络（CNN）表示。与现有的时间一致性方法相比，我们的想法具有对未标记视频进行轻量级预处理的优点（不需要跟踪），同时仍然能够提取对象级别的区域以从中学习不变量。此外，正如我们在几个标准数据集的结果中所展示的，我们的方法通常比竞争的无监督方法在图像分类和检索任务中获得更高的准确性。

##### URL
[https://arxiv.org/abs/1612.00500](https://arxiv.org/abs/1612.00500)

##### PDF
[https://arxiv.org/pdf/1612.00500](https://arxiv.org/pdf/1612.00500)

