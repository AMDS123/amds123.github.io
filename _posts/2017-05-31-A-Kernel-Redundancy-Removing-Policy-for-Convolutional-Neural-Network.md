---
layout: post
title: "A Kernel Redundancy Removing Policy for Convolutional Neural Network"
date: 2017-05-31 16:10:54
categories: arXiv_CV
tags: arXiv_CV Super_Resolution Knowledge CNN
author: Chih-Ting Liu, Yi-Heng Wu, Yu-Sheng Lin, Shao-Yi Chien
mathjax: true
---

* content
{:toc}

##### Abstract
Deep Convolutional Neural Networks (CNN) have won a significant place in the computer vision recently, which repeatedly convolving an image to extract the knowledge behind it. However, with the depth of convolutional layers getting deeper and deeper in recent years, the computational complexity also increases significantly, which make it difficult to be deployed on embedded systems with limited hardware resources. In this paper we propose a method to reduce the redundant convolution kernels during the computation of CNN and apply it to a network for super resolution (SR). Using PSNR drop compared to the original network as performance criterion, our method can get the optimal PSNR under a certain computation budget constraint. On the other hand, our method is also capable of minimizing the computation required under a given PSNR drop.

##### Abstract (translated by Google)
深度卷积神经网络（CNN）近来在计算机视觉领域占据了重要的地位，它们通过反复对图像进行卷积来提取背后的知识。然而，随着近年来卷积层深度越来越深，计算复杂度也大大增加，使得硬件资源有限的嵌入式系统难以部署。在本文中，我们提出了一种在CNN计算过程中减少冗余卷积核并将其应用于超分辨率网络（SR）的方法。与原始网络相比，利用PSNR下降作为性能指标，我们的方法可以在一定的计算预算约束下得到最优的PSNR。另一方面，我们的方法也能够最小化在给定的PSNR下降下所需的计算。

##### URL
[https://arxiv.org/abs/1705.10748](https://arxiv.org/abs/1705.10748)

##### PDF
[https://arxiv.org/pdf/1705.10748](https://arxiv.org/pdf/1705.10748)

