---
layout: post
title: "Scene-Specific Pedestrian Detection Based on Parallel Vision"
date: 2017-12-23 09:33:29
categories: arXiv_CV
tags: arXiv_CV Object_Detection Detection
author: Wenwen Zhang, Kunfeng Wang, Hua Qu, Jihong Zhao, Fei-Yue Wang
mathjax: true
---

* content
{:toc}

##### Abstract
As a special type of object detection, pedestrian detection in generic scenes has made a significant progress trained with large amounts of labeled training data manually. While the models trained with generic dataset work bad when they are directly used in specific scenes. With special viewpoints, flow light and backgrounds, datasets from specific scenes are much different from the datasets from generic scenes. In order to make the generic scene pedestrian detectors work well in specific scenes, the labeled data from specific scenes are needed to adapt the models to the specific scenes. While labeling the data manually spends much time and money, especially for specific scenes, each time with a new specific scene, large amounts of images must be labeled. What's more, the labeling information is not so accurate in the pixels manually and different people make different labeling information. In this paper, we propose an ACP-based method, with augmented reality's help, we build the virtual world of specific scenes, and make people walking in the virtual scenes where it is possible for them to appear to solve this problem of lacking labeled data and the results show that data from virtual world is helpful to adapt generic pedestrian detectors to specific scenes.

##### Abstract (translated by Google)
作为一种特殊类型的目标检测，一般场景中的行人检测已经取得了显着的进步，并且手动地对大量标记的训练数据进行训练。虽然使用通用数据集训练的模型在特定场景中直接使用时效果不佳。有了特殊的观点，流光和背景，来自特定场景的数据集与通用场景的数据集有很大的不同。为了使通用场景行人检测器在特定场景下运行良好，需要特定场景的标注数据来使模型适应特定场景。手动标记数据花费很多时间和金钱，特别是对于特定的场景，每次使用新的特定场景时，必须标记大量的图像。而且手工标注的信息在像素上并不准确，不同的人做出不同的标注信息。在本文中，我们提出了一种基于ACP的方法，通过增强现实的帮助，我们构建了特定场景的虚拟世界，并使人们在虚拟场景中行走，这样他们就可以出现，解决这个缺乏标记数据的问题结果表明来自虚拟世界的数据有助于将普通的行人检测器适用于特定的场景。

##### URL
[http://arxiv.org/abs/1712.08745](http://arxiv.org/abs/1712.08745)

##### PDF
[http://arxiv.org/pdf/1712.08745](http://arxiv.org/pdf/1712.08745)

