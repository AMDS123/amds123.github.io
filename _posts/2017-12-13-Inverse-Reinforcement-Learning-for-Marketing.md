---
layout: post
title: "Inverse Reinforcement Learning for Marketing"
date: 2017-12-13 05:46:22
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization
author: Igor Halperin
mathjax: true
---

* content
{:toc}

##### Abstract
Learning customer preferences from an observed behaviour is an important topic in the marketing literature. Structural models typically model forward-looking customers or firms as utility-maximizing agents whose utility is estimated using methods of Stochastic Optimal Control. We suggest an alternative approach to study dynamic consumer demand, based on Inverse Reinforcement Learning (IRL). We develop a version of the Maximum Entropy IRL that leads to a highly tractable model formulation that amounts to low-dimensional convex optimization in the search for optimal model parameters. Using simulations of consumer demand, we show that observational noise for identical customers can be easily confused with an apparent consumer heterogeneity.

##### Abstract (translated by Google)
从观察到的行为中学习客户偏好是营销文献中的一个重要话题。结构模型通常将前瞻性客户或公司模型化为效用最大化的代理，其效用通过随机最优控制的方法进行估计。我们建议基于反向强化学习（IRL）研究动态消费者需求的另一种方法。我们开发了一个版本的最大熵IRL，导致一个非常容易处理的模型公式，在搜索最优模型参数时相当于低维凸优化。使用消费者需求的模拟，我们表明，对于相同客户的观测噪声可以容易地与明显的消费者异质性混淆。

##### URL
[https://arxiv.org/abs/1712.04612](https://arxiv.org/abs/1712.04612)

##### PDF
[https://arxiv.org/pdf/1712.04612](https://arxiv.org/pdf/1712.04612)

