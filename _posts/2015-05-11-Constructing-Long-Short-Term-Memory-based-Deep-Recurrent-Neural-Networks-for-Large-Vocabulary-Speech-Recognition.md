---
layout: post
title: "Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition"
date: 2015-05-11 02:23:06
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition RNN Recognition
author: Xiangang Li, Xihong Wu
mathjax: true
---

* content
{:toc}

##### Abstract
Long short-term memory (LSTM) based acoustic modeling methods have recently been shown to give state-of-the-art performance on some speech recognition tasks. To achieve a further performance improvement, in this research, deep extensions on LSTM are investigated considering that deep hierarchical model has turned out to be more efficient than a shallow one. Motivated by previous research on constructing deep recurrent neural networks (RNNs), alternative deep LSTM architectures are proposed and empirically evaluated on a large vocabulary conversational telephone speech recognition task. Meanwhile, regarding to multi-GPU devices, the training process for LSTM networks is introduced and discussed. Experimental results demonstrate that the deep LSTM networks benefit from the depth and yield the state-of-the-art performance on this task.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1410.4281](https://arxiv.org/abs/1410.4281)

##### PDF
[https://arxiv.org/pdf/1410.4281](https://arxiv.org/pdf/1410.4281)

