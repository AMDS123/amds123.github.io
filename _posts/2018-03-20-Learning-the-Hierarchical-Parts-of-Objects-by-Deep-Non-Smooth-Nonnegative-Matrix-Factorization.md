---
layout: post
title: "Learning the Hierarchical Parts of Objects by Deep Non-Smooth Nonnegative Matrix Factorization"
date: 2018-03-20 02:39:44
categories: arXiv_CV
tags: arXiv_CV Deep_Learning Relation
author: Jinshi Yu, Guoxu Zhou, Andrzej Cichocki, Shengli Xie
mathjax: true
---

* content
{:toc}

##### Abstract
Nonsmooth Nonnegative Matrix Factorization (nsNMF) is capable of producing more localized, less overlapped feature representations than other variants of NMF while keeping satisfactory fit to data. However, nsNMF as well as other existing NMF methods is incompetent to learn hierarchical features of complex data due to its shallow structure. To fill this gap, we propose a deep nsNMF method coined by the fact that it possesses a deeper architecture compared with standard nsNMF. The deep nsNMF not only gives parts-based features due to the nonnegativity constraints, but also creates higher-level, more abstract features by combing lower-level ones. The in-depth description of how deep architecture can help to efficiently discover abstract features in dnsNMF is presented. And we also show that the deep nsNMF has close relationship with the deep autoencoder, suggesting that the proposed model inherits the major advantages from both deep learning and NMF. Extensive experiments demonstrate the standout performance of the proposed method in clustering analysis.

##### Abstract (translated by Google)
非光滑非负矩阵分解（nsNMF）能够产生比NMF的其他变体更多局部化，更少重叠的特征表示，同时保持与数据的满意匹配。然而，nsNMF以及其他现有的NMF方法由于其浅层结构而无法学习复杂数据的分层特征。为了填补这个空白，我们提出了一个深度的nsNMF方法，这个方法是由于它具有比标准nsNMF更深的架构。由于非负性约束，深度nsNMF不仅可以提供基于零件的特征，还可以通过梳理较低级别的特征来创建更高级别，更抽象的特征。介绍深度架构如何有助于高效发现dnsNMF中的抽象特性。而且我们还表明，深度nsNMF与深度自动编码器有着密切的关系，这表明所提出的模型继承了深度学习和NMF的主要优势。大量的实验证明了该方法在聚类分析中的出色表现。

##### URL
[http://arxiv.org/abs/1803.07226](http://arxiv.org/abs/1803.07226)

##### PDF
[http://arxiv.org/pdf/1803.07226](http://arxiv.org/pdf/1803.07226)

