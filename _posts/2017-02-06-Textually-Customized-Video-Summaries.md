---
layout: post
title: "Textually Customized Video Summaries"
date: 2017-02-06 08:31:44
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption Embedding
author: Jinsoo Choi, Tae-Hyun Oh, In So Kweon
mathjax: true
---

* content
{:toc}

##### Abstract
The best summary of a long video differs among different people due to its highly subjective nature. Even for the same person, the best summary may change with time or mood. In this paper, we introduce the task of generating customized video summaries through simple text. First, we train a deep architecture to effectively learn semantic embeddings of video frames by leveraging the abundance of image-caption data via a progressive and residual manner. Given a user-specific text description, our algorithm is able to select semantically relevant video segments and produce a temporally aligned video summary. In order to evaluate our textually customized video summaries, we conduct experimental comparison with baseline methods that utilize ground-truth information. Despite the challenging baselines, our method still manages to show comparable or even exceeding performance. We also show that our method is able to generate semantically diverse video summaries by only utilizing the learned visual embeddings.

##### Abstract (translated by Google)
不同的人对长篇视频的最好的总结是不同的，因为它具有很高的主观性。即使是同一个人，最好的总结也许会随着时间或心情而改变。在本文中，我们介绍通过简单文本生成定制视频摘要的任务。首先，我们训练一个深层次的体系结构，通过逐步和剩余的方式利用丰富的图像标题数据来有效地学习视频帧的语义嵌入。给定用户特定的文本描述，我们的算法能够选择语义相关的视频片段并产生时间上对齐的视频摘要。为了评估我们的文字定制的视频摘要，我们与利用地面真实信息的基线方法进行实验比较。尽管基线具有挑战性，但我们的方法仍然表现出相当甚至超出的表现。我们还表明，我们的方法能够通过仅利用学习的视觉嵌入来生成语义上不同的视频摘要。

##### URL
[https://arxiv.org/abs/1702.01528](https://arxiv.org/abs/1702.01528)

##### PDF
[https://arxiv.org/pdf/1702.01528](https://arxiv.org/pdf/1702.01528)

