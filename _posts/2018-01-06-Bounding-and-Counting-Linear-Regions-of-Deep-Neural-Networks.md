---
layout: post
title: "Bounding and Counting Linear Regions of Deep Neural Networks"
date: 2018-01-06 13:18:46
categories: arXiv_AI
tags: arXiv_AI
author: Thiago Serra, Christian Tjandraatmadja, Srikumar Ramalingam
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we study the representational power of deep neural networks (DNN) that belong to the family of piecewise-linear (PWL) functions, based on PWL activation units such as rectifier or maxout. We investigate the complexity of such networks by studying the number of linear regions of the PWL function. Typically, a PWL function from a DNN can be seen as a large family of linear functions acting on millions of such regions. We directly build upon the work of Montufar et al. (2014), Montufar (2017) and Raghu et al. (2017) by refining the upper and lower bounds on the number of linear regions for rectified and maxout networks. In addition to achieving tighter bounds, we also develop a novel method to perform exact enumeration or counting of the number of linear regions with a mixed-integer linear formulation that maps the input space to output. We use this new capability to visualize how the number of linear regions change while training DNNs.

##### Abstract (translated by Google)
在本文中，我们研究了基于PWL激活单元（如整流器或maxout）的属于分段线性（PWL）函数族的深度神经网络（DNN）的表示能力。我们通过研究PWL函数的线性区域的数量来研究这种网络的复杂性。通常，来自DNN的PWL功能可以看作是在数百万个这样的区域上作用的一大类线性函数。我们直接建立在Montufar等人的工作上。 （2014年），Montufar（2017年）和Raghu等人（2017）通过改善整数网络和最大网络的线性区域数量的上限和下限。除了实现更紧密的边界之外，我们还开发了一种新的方法，用输入空间映射为输出的混合整数线性公式来执行精确枚举或计算线性区域的数量。我们使用这个新功能来可视化在训练DNN时线性区域的数量如何变化。

##### URL
[http://arxiv.org/abs/1711.02114](http://arxiv.org/abs/1711.02114)

##### PDF
[http://arxiv.org/pdf/1711.02114](http://arxiv.org/pdf/1711.02114)

