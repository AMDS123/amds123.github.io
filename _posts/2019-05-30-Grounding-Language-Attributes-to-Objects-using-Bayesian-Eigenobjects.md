---
layout: post
title: "Grounding Language Attributes to Objects using Bayesian Eigenobjects"
date: 2019-05-30 16:15:36
categories: arXiv_CV
tags: arXiv_CV
author: Vanya Cohen, Benjamin Burchfiel, Thao Nguyen, Nakul Gopalan, Stefanie Tellex, George Konidaris
mathjax: true
---

* content
{:toc}

##### Abstract
We develop a system to disambiguate objects based on simple physical descriptions. The system takes as input a natural language phrase and a depth image containing a segmented object and predicts how similar the observed object is to the described object. Our system is designed to learn from only a small amount of human-labeled language data and generalize to viewpoints not represented in the language-annotated depth-image training set. By decoupling 3D shape representation from language representation, our method is able to ground language to novel objects using a small amount of language-annotated depth-data and a larger corpus of unlabeled 3D object meshes, even when these objects are partially observed from unusual viewpoints. Our system is able to disambiguate between novel objects, observed via depth-images, based on natural language descriptions. Our method also enables view-point transfer; trained on human-annotated data on a small set of depth-images captured from frontal viewpoints, our system successfully predicted object attributes from rear views despite having no such depth images in its training set. Finally, we demonstrate our system on a Baxter robot, enabling it to pick specific objects based on human-provided natural language descriptions.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.13153](http://arxiv.org/abs/1905.13153)

##### PDF
[http://arxiv.org/pdf/1905.13153](http://arxiv.org/pdf/1905.13153)

