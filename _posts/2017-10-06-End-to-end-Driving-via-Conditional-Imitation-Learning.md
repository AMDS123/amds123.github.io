---
layout: post
title: "End-to-end Driving via Conditional Imitation Learning"
date: 2017-10-06 14:00:31
categories: arXiv_CV
tags: arXiv_CV
author: Felipe Codevilla, Matthias Müller, Alexey Dosovitskiy, Antonio López, Vladlen Koltun
mathjax: true
---

* content
{:toc}

##### Abstract
Deep networks trained on demonstrations of human driving have learned to follow roads and avoid obstacles. However, driving policies trained via imitation learning cannot be controlled at test time. A vehicle trained end-to-end to imitate an expert cannot be guided to take a specific turn at an upcoming intersection. This limits the utility of such systems. We propose to condition imitation learning on high-level command input. At test time, the learned driving policy functions as a chauffeur that handles sensorimotor coordination but continues to respond to navigational commands. We evaluate different architectures for conditional imitation learning in vision-based driving. We conduct experiments in realistic three-dimensional simulations of urban driving and on a 1/5 scale robotic truck that is trained to drive in a residential area. Both systems drive based on visual input yet remain responsive to high-level navigational commands. Experimental results demonstrate that the presented approach significantly outperforms a number of baselines. The supplementary video can be viewed at this https URL

##### Abstract (translated by Google)
训练有素的人类驾驶示范的深度网络已经学会了遵循道路并避开障碍。但是，通过模仿学习训练的驾驶策略在测试时间是无法控制的。模拟专家端到端训练的车辆不能在即将到来的路口指导具体转弯。这限制了这种系统的效用。我们建议在高层次的指挥输入中进行模仿学习。在测试时间，学习的驾驶策略作为驾驶员处理感觉运动协调，但继续响应导航命令。我们评估不同架构的视觉驾驶条件模仿学习。我们在现实的城市驾驶三维模拟和1/5规模的机器人卡车上进行了实验，这些机器人卡车是在一个居民区驾驶的。两个系统都基于可视化输入进行驱动，但仍然对高级导航命令作出响应。实验结果表明，提出的方法明显胜过一些基线。补充视频可以在这个https URL查看

##### URL
[https://arxiv.org/abs/1710.02410](https://arxiv.org/abs/1710.02410)

##### PDF
[https://arxiv.org/pdf/1710.02410](https://arxiv.org/pdf/1710.02410)

