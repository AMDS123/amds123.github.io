---
layout: post
title: "Incremental Classifier Learning with Generative Adversarial Networks"
date: 2018-02-02 21:35:45
categories: arXiv_CV
tags: arXiv_CV Regularization Adversarial GAN Classification
author: Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, Zhengyou Zhang, Yun Fu
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we address the incremental classifier learning problem, which suffers from catastrophic forgetting. The main reason for catastrophic forgetting is that the past data are not available during learning. Typical approaches keep some exemplars for the past classes and use distillation regularization to retain the classification capability on the past classes and balance the past and new classes. However, there are four main problems with these approaches. First, the loss function is not efficient for classification. Second, there is unbalance problem between the past and new classes. Third, the size of pre-decided exemplars is usually limited and they might not be distinguishable from unseen new classes. Forth, the exemplars may not be allowed to be kept for a long time due to privacy regulations. To address these problems, we propose (a) a new loss function to combine the cross-entropy loss and distillation loss, (b) a simple way to estimate and remove the unbalance between the old and new classes , and (c) using Generative Adversarial Networks (GANs) to generate historical data and select representative exemplars during generation. We believe that the data generated by GANs have much less privacy issues than real images because GANs do not directly copy any real image patches. We evaluate the proposed method on CIFAR-100, Flower-102, and MS-Celeb-1M-Base datasets and extensive experiments demonstrate the effectiveness of our method.

##### Abstract (translated by Google)
在本文中，我们解决增量分类器学习问题，遭受灾难性遗忘。灾难性遗忘的主要原因是过去的数据在学习期间是不可用的。典型的方法保留了过去类别的一些范例，并使用精馏正则化来保留过去类别的分类能力，并平衡过去和新的类别。但是，这些方法有四个主要的问题。首先，损失函数分类效率不高。其次，过去和新阶段之间存在不平衡的问题。第三，预先确定的范例的大小通常是有限的，它们可能无法与看不见的新类别区分开来。第四，由于隐私条例的限制，样本可能不被允许长期保存。为了解决这些问题，我们提出了（a）一个新的损失函数来结合交叉熵损失和蒸馏损失，（b）一个简单的方法来估计和消除新旧类别之间的不平衡，（c）使用生成敌对网络（GAN）生成历史数据并选择代表性范例。我们认为，由GAN生成的数据比真实图像隐私问题少得多，因为GAN不直接复制任何实际的图像补丁。我们在CIFAR-100，Flower-102和MS-Celeb-1M-Base数据集上评估所提出的方法，大量实验证明了我们方法的有效性。

##### URL
[http://arxiv.org/abs/1802.00853](http://arxiv.org/abs/1802.00853)

##### PDF
[http://arxiv.org/pdf/1802.00853](http://arxiv.org/pdf/1802.00853)

