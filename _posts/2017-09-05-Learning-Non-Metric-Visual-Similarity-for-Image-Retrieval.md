---
layout: post
title: "Learning Non-Metric Visual Similarity for Image Retrieval"
date: 2017-09-05 12:39:30
categories: arXiv_CV
tags: arXiv_CV Image_Caption Image_Retrieval Deep_Learning
author: Noa Garcia, George Vogiatzis
mathjax: true
---

* content
{:toc}

##### Abstract
Can a neural network learn the concept of visual similarity? In this work, this question is addressed by training a deep learning model for the specific task of measuring the similarity between a pair of pictures in content-based image retrieval datasets. Traditionally, content-based image retrieval systems rely on two fundamental tasks: 1) computing meaningful image representations from pixels and 2) measuring accurate visual similarity between those representations. Whereas in the last few years several methods have been proposed to find high quality image representations including SIFT, VLAD or RMAC, most techniques still depend on standard metrics such as Euclidean distance or cosine similarity for the visual similarity task. However, standard metrics are independent from data and might be missing the nonlinear inner structure of visual representations. In this paper, we propose to learn a non-metric visual similarity function directly from image representations to measure how alike two images are. Experiments on standard image retrieval datasets show that results are boosted when using the proposed method over standard metrics.

##### Abstract (translated by Google)
神经网络能够学习视觉相似的概念吗？在这项工作中，通过训练一个深度学习模型来解决这个问题，该模型用于测量基于内容的图像检索数据集中的一对图像之间的相似性的具体任务。传统上，基于内容的图像检索系统依赖于两个基本任务：1）从像素计算有意义的图像表示; 2）测量这些表示之间准确的视觉相似性。而在过去的几年中，已经提出了几种方法来寻找包括SIFT，VLAD或RMAC在内的高质量图像表示，大部分技术仍然依赖于视觉相似性任务的标准度量，例如欧氏距离或余弦相似度。但是，标准度量与数据无关，可能会忽略视觉表示的非线性内部结构。在本文中，我们建议直接从图像表示中学习非度量视觉相似度函数，以测量两幅图像的相似程度。对标准图像检索数据集的实验表明，当使用所提出的方法而不是标准度量时，结果得到了提高。

##### URL
[https://arxiv.org/abs/1709.01353](https://arxiv.org/abs/1709.01353)

##### PDF
[https://arxiv.org/pdf/1709.01353](https://arxiv.org/pdf/1709.01353)

