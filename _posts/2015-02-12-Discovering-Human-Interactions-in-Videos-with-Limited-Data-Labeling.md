---
layout: post
title: "Discovering Human Interactions in Videos with Limited Data Labeling"
date: 2015-02-12 22:38:28
categories: arXiv_CV
tags: arXiv_CV
author: Mehran Khodabandeh, Arash Vahdat, Guang-Tong Zhou, Hossein Hajimirsadeghi, Mehrsan Javan Roshtkhari, Greg Mori, Stephen Se
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel approach for discovering human interactions in videos. Activity understanding techniques usually require a large number of labeled examples, which are not available in many practical cases. Here, we focus on recovering semantically meaningful clusters of human-human and human-object interaction in an unsupervised fashion. A new iterative solution is introduced based on Maximum Margin Clustering (MMC), which also accepts user feedback to refine clusters. This is achieved by formulating the whole process as a unified constrained latent max-margin clustering problem. Extensive experiments have been carried out over three challenging datasets, Collective Activity, VIRAT, and UT-interaction. Empirical results demonstrate that the proposed algorithm can efficiently discover perfect semantic clusters of human interactions with only a small amount of labeling effort.

##### Abstract (translated by Google)
我们提出了一种新的方法来发现视频中的人类交互。活动理解技术通常需要大量的标记示例，这在许多实际情况中是不可用的。在这里，我们专注于以无监督的方式恢复语义上有意义的人 - 人和人 - 对象交互集群。基于最大余量聚类（MMC）的新的迭代解决方案被引入，该方法也接受用户反馈来优化聚类。这是通过将整个过程作为一个统一的约束潜在最大边缘聚类问题来实现的。已经对三个具有挑战性的数据集进行了广泛的实验，集体活动，VIRAT和UT-交互。实验结果表明，该算法能够有效地发现人类交互的完美语义簇，只需少量的标记工作。

##### URL
[https://arxiv.org/abs/1502.03851](https://arxiv.org/abs/1502.03851)

##### PDF
[https://arxiv.org/pdf/1502.03851](https://arxiv.org/pdf/1502.03851)

