---
layout: post
title: "Houdini: Fooling Deep Structured Prediction Models"
date: 2017-07-17 19:11:08
categories: arXiv_CV
tags: arXiv_CV Adversarial Segmentation Pose_Estimation Speech_Recognition Semantic_Segmentation Classification Prediction Recognition
author: Moustapha Cisse, Yossi Adi, Natalia Neverova, Joseph Keshet
mathjax: true
---

* content
{:toc}

##### Abstract
Generating adversarial examples is a critical step for evaluating and improving the robustness of learning machines. So far, most existing methods only work for classification and are not designed to alter the true performance measure of the problem at hand. We introduce a novel flexible approach named Houdini for generating adversarial examples specifically tailored for the final performance measure of the task considered, be it combinatorial and non-decomposable. We successfully apply Houdini to a range of applications such as speech recognition, pose estimation and semantic segmentation. In all cases, the attacks based on Houdini achieve higher success rate than those based on the traditional surrogates used to train the models while using a less perceptible adversarial perturbation.

##### Abstract (translated by Google)
生成敌对的例子是评估和提高学习机器健壮性的关键步骤。到目前为止，大多数现有的方法只能用于分类，不能用来改变手头问题的真实性能。我们引入了一种名为Houdini的新颖灵活的方法，用于生成专门针对所考虑的任务的最终性能度量而制定的对抗性示例，无论是组合的还是不可分解的。我们成功地将Houdini应用于一系列应用，如语音识别，姿态估计和语义分割。在所有情况下，基于Houdini的攻击的成功率都高于传统的用于训练模型的替代品，而使用不太可感知的对抗性扰动。

##### URL
[https://arxiv.org/abs/1707.05373](https://arxiv.org/abs/1707.05373)

##### PDF
[https://arxiv.org/pdf/1707.05373](https://arxiv.org/pdf/1707.05373)

