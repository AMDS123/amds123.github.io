---
layout: post
title: "Visual Robot Task Planning"
date: 2018-03-30 21:52:49
categories: arXiv_AI
tags: arXiv_AI
author: Chris Paxton, Yotam Barnoy, Kapil Katyal, Raman Arora, Gregory D. Hager
mathjax: true
---

* content
{:toc}

##### Abstract
Prospection, the act of predicting the consequences of many possible futures, is intrinsic to human planning and action, and may even be at the root of consciousness. Surprisingly, this idea has been explored comparatively little in robotics. In this work, we propose a neural network architecture and associated planning algorithm that (1) learns a representation of the world useful for generating prospective futures after the application of high-level actions, (2) uses this generative model to simulate the result of sequences of high-level actions in a variety of environments, and (3) uses this same representation to evaluate these actions and perform tree search to find a sequence of high-level actions in a new environment. Models are trained via imitation learning on a variety of domains, including navigation, pick-and-place, and a surgical robotics task. Our approach allows us to visualize intermediate motion goals and learn to plan complex activity from visual information.

##### Abstract (translated by Google)
预测，预测许多可能的未来的后果的行为，是人类规划和行动所固有的，甚至可能是意识的根源。令人惊讶的是，这个想法在机器人技术方面已经探索得比较少。在这项工作中，我们提出了一个神经网络体系结构和相关的规划算法，它们（1）在高层次行动的应用之后，学习有用于产生未来期望的世界的表示，（2）使用这个生成模型来模拟（3）使用相同的表示来评估这些动作，并执行树搜索以在新环境中查找一系列高级动作。模型通过模拟学习在各种领域进行训练，包括导航，拾放和外科手术机器人任务。我们的方法允许我们可视化中间动作目标并学习从视觉信息中计划复杂的活动。

##### URL
[http://arxiv.org/abs/1804.00062](http://arxiv.org/abs/1804.00062)

##### PDF
[http://arxiv.org/pdf/1804.00062](http://arxiv.org/pdf/1804.00062)

