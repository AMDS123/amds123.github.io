---
layout: post
title: "Deep Lip Reading: a comparison of models and an online application"
date: 2018-06-15 17:37:01
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition CNN RNN Classification Language_Model Recognition
author: Triantafyllos Afouras, Joon Son Chung, Andrew Zisserman
mathjax: true
---

* content
{:toc}

##### Abstract
The goal of this paper is to develop state-of-the-art models for lip reading -- visual speech recognition. We develop three architectures and compare their accuracy and training times: (i) a recurrent model using LSTMs; (ii) a fully convolutional model; and (iii) the recently proposed transformer model. The recurrent and fully convolutional models are trained with a Connectionist Temporal Classification loss and use an explicit language model for decoding, the transformer is a sequence-to-sequence model. Our best performing model improves the state-of-the-art word error rate on the challenging BBC-Oxford Lip Reading Sentences 2 (LRS2) benchmark dataset by over 20 percent. 
 As a further contribution we investigate the fully convolutional model when used for online (real time) lip reading of continuous speech, and show that it achieves high performance with low latency.

##### Abstract (translated by Google)
本文的目标是开发最先进的唇部阅读模型 - 视觉语音识别。我们开发三种架构，并比较它们的准确性和训练时间：（i）使用LSTM的循环模型; （ii）完全卷积模型;和（iii）最近提出的变压器模型。循环卷积模型和完全卷积模型用Connectionist时间分类损失进行训练，并使用明确的语言模型进行解码，变换器是序列到序列模型。我们的表现最佳的模型将英国BBC-Oxford Lip Reading Sentences 2（LRS2）基准数据集中最先进的单词错误率提高了20％以上。
 作为进一步的贡献，我们研究了完全卷积模型，当用于连续语音的在线（实时）唇读时，并且表明它以低延迟实现高性能。

##### URL
[http://arxiv.org/abs/1806.06053](http://arxiv.org/abs/1806.06053)

##### PDF
[http://arxiv.org/pdf/1806.06053](http://arxiv.org/pdf/1806.06053)

