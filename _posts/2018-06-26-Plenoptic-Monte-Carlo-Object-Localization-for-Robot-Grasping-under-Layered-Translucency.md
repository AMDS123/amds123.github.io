---
layout: post
title: "Plenoptic Monte Carlo Object Localization for Robot Grasping under Layered Translucency"
date: 2018-06-26 02:41:52
categories: arXiv_AI
tags: arXiv_AI GAN
author: Zheming Zhou, Zhiqiang Sui, Odest Chadwicke Jenkins
mathjax: true
---

* content
{:toc}

##### Abstract
In order to fully function in human environments, robot perception will need to account for the uncertainty caused by translucent materials. Translucency poses several open challenges in the form of transparent objects (e.g., drinking glasses), refractive media (e.g., water), and diffuse partial occlusions (e.g., objects behind stained glass panels). This paper presents Plenoptic Monte Carlo Localization (PMCL) as a method for localizing object poses in the presence of translucency using plenoptic (light-field) observations. We propose a new depth descriptor, the Depth Likelihood Volume (DLV), and its use within a Monte Carlo object localization algorithm. We present results of localizing and manipulating objects with translucent materials and objects occluded by layers of translucency. Our PMCL implementation uses observations from a Lytro first generation light field camera to allow a Michigan Progress Fetch robot to perform grasping.

##### Abstract (translated by Google)
为了在人类环境中充分发挥功能，机器人的感知需要考虑到半透明材料带来的不确定性。半透明性以透明物体（例如饮用杯），折射介质（例如水）和漫射部分遮挡物（例如，染色玻璃板后面的物体）的形式提出了几个开放的挑战。本文将全光蒙特卡罗定位（PMCL）作为一种利用全光（光场）观测在半透明存在下定位物体姿态的方法。我们提出了一个新的深度描述符，深度似然量（DLV）及其在蒙特卡罗物体定位算法中的使用。我们介绍用半透明材料和半透明层遮挡物体来定位和操作物体的结果。我们的PMCL实施使用Lytro第一代光场照相机的观察结果，以允许Michigan Progress Fetch机器人执行抓取。

##### URL
[http://arxiv.org/abs/1806.09769](http://arxiv.org/abs/1806.09769)

##### PDF
[http://arxiv.org/pdf/1806.09769](http://arxiv.org/pdf/1806.09769)

