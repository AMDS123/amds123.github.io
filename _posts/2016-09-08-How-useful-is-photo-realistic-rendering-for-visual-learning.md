---
layout: post
title: "How useful is photo-realistic rendering for visual learning?"
date: 2016-09-08 03:43:58
categories: arXiv_CV
tags: arXiv_CV
author: Yair Movshovitz-Attias, Takeo Kanade, Yaser Sheikh
mathjax: true
---

* content
{:toc}

##### Abstract
Data seems cheap to get, and in many ways it is, but the process of creating a high quality labeled dataset from a mass of data is time-consuming and expensive. With the advent of rich 3D repositories, photo-realistic rendering systems offer the opportunity to provide nearly limitless data. Yet, their primary value for visual learning may be the quality of the data they can provide rather than the quantity. Rendering engines offer the promise of perfect labels in addition to the data: what the precise camera pose is; what the precise lighting location, temperature, and distribution is; what the geometry of the object is. In this work we focus on semi-automating dataset creation through use of synthetic data and apply this method to an important task -- object viewpoint estimation. Using state-of-the-art rendering software we generate a large labeled dataset of cars rendered densely in viewpoint space. We investigate the effect of rendering parameters on estimation performance and show realism is important. We show that generalizing from synthetic data is not harder than the domain adaptation required between two real-image datasets and that combining synthetic images with a small amount of real data improves estimation accuracy.

##### Abstract (translated by Google)
数据似乎很便宜，而且在很多方面都是如此，但是从大量数据创建高质量标记数据集的过程是耗时且昂贵的。随着丰富的3D存储库的出现，照片般逼真的渲染系统提供了提供几乎无限的数据的机会。然而，他们的视觉学习的主要价值可能是他们可以提供的数据的质量，而不是数量。除了数据之外，渲染引擎还提供了完美标签的承诺：精确的相机姿态;精确的照明位置，温度和分布是什么;对象的几何形状是什么在这项工作中，我们关注通过合成数据使用半自动化数据集创建，并将这种方法应用于重要任务 - 对象视点估计。使用最先进的渲染软件，我们生成一个在视点空间中密集渲染的大型标记数据集。我们调查渲染参数对估计性能的影响，并显示真实性是重要的。我们表明，从合成数据推广不比两个实际图像数据集之间所需的域适配困难，并且将合成图像与少量实际数据相结合可以提高估计精度。

##### URL
[https://arxiv.org/abs/1603.08152](https://arxiv.org/abs/1603.08152)

##### PDF
[https://arxiv.org/pdf/1603.08152](https://arxiv.org/pdf/1603.08152)

