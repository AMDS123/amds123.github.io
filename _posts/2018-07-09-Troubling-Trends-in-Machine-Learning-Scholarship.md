---
layout: post
title: "Troubling Trends in Machine Learning Scholarship"
date: 2018-07-09 18:59:17
categories: arXiv_AI
tags: arXiv_AI Review Knowledge Attention
author: Zachary C. Lipton, Jacob Steinhardt
mathjax: true
---

* content
{:toc}

##### Abstract
Collectively, machine learning (ML) researchers are engaged in the creation and dissemination of knowledge about data-driven algorithms. In a given paper, researchers might aspire to any subset of the following goals, among others: to theoretically characterize what is learnable, to obtain understanding through empirically rigorous experiments, or to build a working system that has high predictive accuracy. While determining which knowledge warrants inquiry may be subjective, once the topic is fixed, papers are most valuable to the community when they act in service of the reader, creating foundational knowledge and communicating as clearly as possible. 
 Recent progress in machine learning comes despite frequent departures from these ideals. In this paper, we focus on the following four patterns that appear to us to be trending in ML scholarship: (i) failure to distinguish between explanation and speculation; (ii) failure to identify the sources of empirical gains, e.g., emphasizing unnecessary modifications to neural architectures when gains actually stem from hyper-parameter tuning; (iii) mathiness: the use of mathematics that obfuscates or impresses rather than clarifies, e.g., by confusing technical and non-technical concepts; and (iv) misuse of language, e.g., by choosing terms of art with colloquial connotations or by overloading established technical terms. 
 While the causes behind these patterns are uncertain, possibilities include the rapid expansion of the community, the consequent thinness of the reviewer pool, and the often-misaligned incentives between scholarship and short-term measures of success (e.g., bibliometrics, attention, and entrepreneurial opportunity). While each pattern offers a corresponding remedy (don't do it), we also discuss some speculative suggestions for how the community might combat these trends.

##### Abstract (translated by Google)
机器学习（ML）研究人员共同致力于创建和传播有关数据驱动算法的知识。在一篇给定的论文中，研究人员可能渴望实现以下目标的任何子集：其中包括：从理论上描述可学习的内容，通过经验严谨的实验获得理解，或构建具有高预测准确性的工作系统。虽然确定哪些知识需要进行调查可能是主观的，但一旦主题得到修复，当论文为读者服务时，论文对社区最有价值，创造基础知识并尽可能清楚地进行交流。
 尽管经常偏离这些理想，但机器学习的最新进展仍然存在。在本文中，我们关注以下四种模式，这些模式在我们看来是ML学术中的趋势：（i）未能区分解释和推测; （ii）未能确定经验收益的来源，例如，当收益实际上源于超参数调整时，强调对神经架构的不必要修改; （iii）数学：使用混淆或令人印象深刻的数学而不是澄清，例如，混淆技术和非技术概念; （iv）滥用语言，例如选择具有俗语含义的艺术术语或超载既定技术术语。
 虽然这些模式背后的原因尚不确定，但可能性包括社区的迅速扩张，审查人员库存的减少以及奖学金和短期成功衡量标准之间往往错位的激励（例如，文献计量学，注意力和企业家精神）机会）。虽然每种模式都提供了相应的补救措施（不要这样做），但我们还讨论了社区如何对抗这些趋势的一些推测性建议。

##### URL
[http://arxiv.org/abs/1807.03341](http://arxiv.org/abs/1807.03341)

##### PDF
[http://arxiv.org/pdf/1807.03341](http://arxiv.org/pdf/1807.03341)

