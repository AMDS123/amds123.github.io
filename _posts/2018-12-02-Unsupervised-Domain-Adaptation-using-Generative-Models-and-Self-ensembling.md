---
layout: post
title: "Unsupervised Domain Adaptation using Generative Models and Self-ensembling"
date: 2018-12-02 22:29:04
categories: arXiv_CV
tags: arXiv_CV Knowledge GAN Style_Transfer
author: Eman T. Hassan, Xin Chen, David Crandall
mathjax: true
---

* content
{:toc}

##### Abstract
Transferring knowledge across different datasets is an important approach to successfully train deep models with a small-scale target dataset or when few labeled instances are available. In this paper, we aim at developing a model that can generalize across multiple domain shifts, so that this model can adapt from a single source to multiple targets. This can be achieved by randomizing the generation of the data of various styles to mitigate the domain mismatch. First, we present a new adaptation to the CycleGAN model to produce stochastic style transfer between two image batches of different domains. Second, we enhance the classifier performance by using a self-ensembling technique with a teacher and student model to train on both original and generated data. Finally, we present experimental results on three datasets Office-31, Office-Home, and Visual Domain adaptation. The results suggest that selfensembling is better than simple data augmentation with the newly generated data and a single model trained this way can have the best performance across all different transfer tasks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.00479](http://arxiv.org/abs/1812.00479)

##### PDF
[http://arxiv.org/pdf/1812.00479](http://arxiv.org/pdf/1812.00479)

