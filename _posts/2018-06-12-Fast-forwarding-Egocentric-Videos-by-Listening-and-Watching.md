---
layout: post
title: "Fast forwarding Egocentric Videos by Listening and Watching"
date: 2018-06-12 15:58:53
categories: arXiv_CV
tags: arXiv_CV Quantitative
author: Vinicius S. Furlan, Ruzena Bajcsy, Erickson R. Nascimento
mathjax: true
---

* content
{:toc}

##### Abstract
The remarkable technological advance in well-equipped wearable devices is pushing an increasing production of long first-person videos. However, since most of these videos have long and tedious parts, they are forgotten or never seen. Despite a large number of techniques proposed to fast-forward these videos by highlighting relevant moments, most of them are image based only. Most of these techniques disregard other relevant sensors present in the current devices such as high-definition microphones. In this work, we propose a new approach to fast-forward videos using psychoacoustic metrics extracted from the soundtrack. These metrics can be used to estimate the annoyance of a segment allowing our method to emphasize moments of sound pleasantness. The efficiency of our method is demonstrated through qualitative results and quantitative results as far as of speed-up and instability are concerned.

##### Abstract (translated by Google)
装备精良的可穿戴设备的显着技术进步推动了长时间第一人称视频的产量不断增加。但是，由于这些视频中的大部分都具有漫长而乏味的部分，因此它们被遗忘或从未见过。尽管提出了大量技术来突出相关时刻来快速转发这些视频，但其中大多数仅基于图像。大多数这些技术忽略了当前设备中存在的其他相关传感器，例如高清麦克风。在这项工作中，我们提出了一种使用从配乐中提取的心理声学指标来快速转发视频的新方法。这些指标可用于评估细分市场的烦恼程度，从而使我们的方法能够强调愉悦的时刻。我们的方法的效率通过定性结果和定量结果来证明，就加速和不稳定性而言。

##### URL
[http://arxiv.org/abs/1806.04620](http://arxiv.org/abs/1806.04620)

##### PDF
[http://arxiv.org/pdf/1806.04620](http://arxiv.org/pdf/1806.04620)

