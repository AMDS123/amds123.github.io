---
layout: post
title: "Learning Invariances for Policy Generalization"
date: 2018-09-07 17:32:19
categories: arXiv_AI
tags: arXiv_AI Adversarial Knowledge Reinforcement_Learning
author: Remi Tachet des Combes, Philip Bachman, Harm van Seijen
mathjax: true
---

* content
{:toc}

##### Abstract
While recent progress has spawned very powerful machine learning systems, those agents remain extremely specialized and fail to transfer the knowledge they gain to similar yet unseen tasks. In this paper, we study a simple reinforcement learning problem and focus on learning policies that encode the proper invariances for generalization to different settings. We evaluate three potential methods for policy generalization: data augmentation, meta-learning and adversarial training. We find our data augmentation method to be effective, and study the potential of meta-learning and adversarial learning as alternative task-agnostic approaches. 
 Keywords: reinforcement learning, generalization, data augmentation, meta-learning, adversarial learning.

##### Abstract (translated by Google)
虽然最近的进展产生了非常强大的机器学习系统，但这些代理仍然非常专业，无法将他们获得的知识转移到类似但看不见的任务上。在本文中，我们研究了一个简单的强化学习问题，并侧重于学习策略，这些策略编码适用于不同设置的泛化的不变性。我们评估了三种可能的政策概括方法：数据增强，元学习和对抗性训练。我们发现我们的数据增强方法是有效的，并研究元学习和对抗性学习作为替代任务不可知方法的潜力。
 关键词：强化学习，泛化，数据增强，元学习，对抗性学习。

##### URL
[http://arxiv.org/abs/1809.02591](http://arxiv.org/abs/1809.02591)

##### PDF
[http://arxiv.org/pdf/1809.02591](http://arxiv.org/pdf/1809.02591)

