---
layout: post
title: "An Unsupervised Model with Attention Autoencoders for Question Retrieval"
date: 2018-03-09 11:44:39
categories: arXiv_CL
tags: arXiv_CL QA Attention Face
author: Minghua Zhang, Yunfang Wu
mathjax: true
---

* content
{:toc}

##### Abstract
Question retrieval is a crucial subtask for community question answering. Previous research focus on supervised models which depend heavily on training data and manual feature engineering. In this paper, we propose a novel unsupervised framework, namely reduced attentive matching network (RAMN), to compute semantic matching between two questions. Our RAMN integrates together the deep semantic representations, the shallow lexical mismatching information and the initial rank produced by an external search engine. For the first time, we propose attention autoencoders to generate semantic representations of questions. In addition, we employ lexical mismatching to capture surface matching between two questions, which is derived from the importance of each word in a question. We conduct experiments on the open CQA datasets of SemEval-2016 and SemEval-2017. The experimental results show that our unsupervised model obtains comparable performance with the state-of-the-art supervised methods in SemEval-2016 Task 3, and outperforms the best system in SemEval-2017 Task 3 by a wide margin.

##### Abstract (translated by Google)
问题检索是社区问答的重要子任务。以前的研究集中在严重依赖于训练数据和手动特征工程的监督模型上。在本文中，我们提出了一种新的无监督框架，即减少注意匹配网络（RAMN），以计算两个问题之间的语义匹配。我们的RAMN将深层语义表征，浅层词汇不匹配信息和外部搜索引擎产生的初始排名整合在一起。我们第一次提出注意自动编码器来生成问题的语义表示。另外，我们使用词汇不匹配来捕捉两个问题之间的表面匹配，这是从问题中每个单词的重要性得出的。我们在SemEval-2016和SemEval-2017的开放式CQA数据集上进行实验。实验结果表明，我们的无监督模型在SemEval-2016任务3中获得了与先进的监督方法相当的性能，并在很大程度上优于SemEval-2017任务3中的最佳系统。

##### URL
[http://arxiv.org/abs/1803.03476](http://arxiv.org/abs/1803.03476)

##### PDF
[http://arxiv.org/pdf/1803.03476](http://arxiv.org/pdf/1803.03476)

