---
layout: post
title: "There's No Comparison: Reference-less Evaluation Metrics in Grammatical Error Correction"
date: 2016-10-07 02:17:17
categories: arXiv_CL
tags: arXiv_CL Relation
author: Courtney Napoles, Keisuke Sakaguchi, Joel Tetreault
mathjax: true
---

* content
{:toc}

##### Abstract
Current methods for automatically evaluating grammatical error correction (GEC) systems rely on gold-standard references. However, these methods suffer from penalizing grammatical edits that are correct but not in the gold standard. We show that reference-less grammaticality metrics correlate very strongly with human judgments and are competitive with the leading reference-based evaluation metrics. By interpolating both methods, we achieve state-of-the-art correlation with human judgments. Finally, we show that GEC metrics are much more reliable when they are calculated at the sentence level instead of the corpus level. We have set up a CodaLab site for benchmarking GEC output using a common dataset and different evaluation metrics.

##### Abstract (translated by Google)
自动评估语法错误校正（GEC）系统的当前方法依赖于黄金标准参考。然而，这些方法遭受惩罚的语法编辑是正确的，但不符合黄金标准。我们表明，无参考语法性度量与人类判断非常强烈相关，并与领先的基于参考的评估度量标准具有竞争性。通过对两种方法进行插值，我们实现了与人类判断的最先进的相关性。最后，我们表明，GEC度量在语句级而不是语料库级计算时更可靠。我们建立了一个CodaLab网站，用于使用一个通用的数据集和不同的评估指标对GEC输出进行基准测试。

##### URL
[https://arxiv.org/abs/1610.02124](https://arxiv.org/abs/1610.02124)

##### PDF
[https://arxiv.org/pdf/1610.02124](https://arxiv.org/pdf/1610.02124)

