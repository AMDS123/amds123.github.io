---
layout: post
title: "Back-Translation Sampling by Targeting Difficult Words in Neural Machine Translation"
date: 2018-08-27 19:27:01
categories: arXiv_CL
tags: arXiv_CL Prediction
author: Marzieh Fadaee, Christof Monz
mathjax: true
---

* content
{:toc}

##### Abstract
Neural Machine Translation has achieved state-of-the-art performance for several language pairs using a combination of parallel and synthetic data. Synthetic data is often generated by back-translating sentences randomly sampled from monolingual data using a reverse translation model. While back-translation has been shown to be very effective in many cases, it is not entirely clear why. In this work, we explore different aspects of back-translation, and show that words with high prediction loss during training benefit most from the addition of synthetic data. We introduce several variations of sampling strategies targeting difficult-to-predict words using prediction losses and frequencies of words. In addition, we also target the contexts of difficult words and sample sentences that are similar in context. Experimental results for the WMT news translation task show that our method improves translation quality by up to 1.7 and 1.2 Bleu points over back-translation using random sampling for German-English and English-German, respectively.

##### Abstract (translated by Google)
神经机器翻译使用并行和合成数据的组合，为多个语言对实现了最先进的性能。合成数据通常通过使用反向翻译模型从单语数据中随机采样的反向翻译来生成。虽然在许多情况下反向翻译已被证明非常有效，但并不完全清楚原因。在这项工作中，我们探讨了反向翻译的不同方面，并表明在训练期间具有高预测损失的单词从合成数据的添加中获益最多。我们使用预测损失和单词频率介绍了针对难以预测的单词的几种采样策略变体。此外，我们还针对上下文中相似的难词和样本句子的上下文。 WMT新闻翻译任务的实验结果表明，我们的方法分别使用德语 - 英语和英语 - 德语的随机抽样提高了翻译质量，翻译质量高达1.7和1.2 Bleu点。

##### URL
[http://arxiv.org/abs/1808.09006](http://arxiv.org/abs/1808.09006)

##### PDF
[http://arxiv.org/pdf/1808.09006](http://arxiv.org/pdf/1808.09006)

