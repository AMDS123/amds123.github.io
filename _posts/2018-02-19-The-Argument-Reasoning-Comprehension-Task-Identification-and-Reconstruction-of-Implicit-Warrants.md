---
layout: post
title: "The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants"
date: 2018-02-19 12:34:20
categories: arXiv_AI
tags: arXiv_AI Attention Language_Model
author: Ivan Habernal, Henning Wachsmuth, Iryna Gurevych, Benno Stein
mathjax: true
---

* content
{:toc}

##### Abstract
Reasoning is a crucial part of natural language argumentation. To comprehend an argument, one must analyze its warrant, which explains why its claim follows from its premises. As arguments are highly contextualized, warrants are usually presupposed and left implicit. Thus, the comprehension does not only require language understanding and logic skills, but also depends on common sense. In this paper we develop a methodology for reconstructing warrants systematically. We operationalize it in a scalable crowdsourcing process, resulting in a freely licensed dataset with warrants for 2k authentic arguments from news comments. On this basis, we present a new challenging task, the argument reasoning comprehension task. Given an argument with a claim and a premise, the goal is to choose the correct implicit warrant from two options. Both warrants are plausible and lexically close, but lead to contradicting claims. A solution to this task will define a substantial step towards automatic warrant reconstruction. However, experiments with several neural attention and language models reveal that current approaches do not suffice.

##### Abstract (translated by Google)
推理是自然语言论证的重要组成部分。要理解一个论点，必须分析它的授权，这就解释了为什么它的主张是从它的前提出发的。由于参数具有高度的背景化，权证通常是预先设定的，并且是隐含的。因此，理解不仅要求语言理解和逻辑技巧，而且要依靠常识。在本文中，我们制定了系统地重建权证的方法。我们在一个可扩展的众包过程中运作它，产生一个免费许可的数据集，包含来自新闻评论的2k真实论点的权证。在此基础上，我们提出了一个新的具有挑战性的任务，即推理理解任务。鉴于有索赔和前提的争论，目标是从两个选项中选择正确的隐含权证。这两种认股权证都是合理的，词汇紧密，但导致矛盾的说法。这一任务的解决方案将为自动授权重建确定一个实质性步骤。然而，有几种神经关注和语言模型的实验表明，目前的方法是不够的。

##### URL
[http://arxiv.org/abs/1708.01425](http://arxiv.org/abs/1708.01425)

##### PDF
[http://arxiv.org/pdf/1708.01425](http://arxiv.org/pdf/1708.01425)

