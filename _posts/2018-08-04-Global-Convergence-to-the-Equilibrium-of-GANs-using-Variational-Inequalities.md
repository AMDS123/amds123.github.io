---
layout: post
title: "Global Convergence to the Equilibrium of GANs using Variational Inequalities"
date: 2018-08-04 20:47:44
categories: arXiv_CV
tags: arXiv_CV Adversarial Attention GAN Optimization Gradient_Descent
author: Ian Gemp, Sridhar Mahadevan
mathjax: true
---

* content
{:toc}

##### Abstract
In optimization, the negative gradient of a function denotes the direction of steepest descent. Furthermore, traveling in any direction orthogonal to the gradient maintains the value of the function. In this work, we show that these orthogonal directions that are ignored by gradient descent can be critical in equilibrium problems. Equilibrium problems have drawn heightened attention in machine learning due to the emergence of the Generative Adversarial Network (GAN). We use the framework of Variational Inequalities to analyze popular training algorithms for a fundamental GAN variant: the Wasserstein Linear-Quadratic GAN. We show that the steepest descent direction causes divergence from the equilibrium, and guaranteed convergence to the equilibrium is achieved through following a particular orthogonal direction. We call this successful technique Crossing-the-Curl, named for its mathematical derivation as well as its intuition: identify the game's axis of rotation and move "across" space in the direction towards smaller "curling".

##### Abstract (translated by Google)
在优化中，函数的负梯度表示最速下降的方向。此外，在与梯度正交的任何方向上行进都保持函数的值。在这项工作中，我们表明梯度下降忽略的这些正交方向在平衡问题中是至关重要的。由于生成性对抗网络（GAN）的出现，均衡问题引起了机器学习的高度关注。我们使用变分不等式框架来分析基本GAN变体的流行训练算法：Wasserstein线性二次GAN。我们表明，最陡的下降方向导致与平衡的偏离，并且通过遵循特定的正交方向来保证收敛到平衡。我们将这种成功的技术称为Crossing-the-Curl，以其数学推导及其直觉命名：识别游戏的旋转轴，并朝着较小的“卷曲”方向“跨越”空间。

##### URL
[https://arxiv.org/abs/1808.01531](https://arxiv.org/abs/1808.01531)

##### PDF
[https://arxiv.org/pdf/1808.01531](https://arxiv.org/pdf/1808.01531)

