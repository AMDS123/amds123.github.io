---
layout: post
title: "A Framework and Method for Online Inverse Reinforcement Learning"
date: 2018-05-21 02:27:58
categories: arXiv_AI
tags: arXiv_AI Attention Reinforcement_Learning
author: Saurabh Arora, Prashant Doshi, Bikramjit Banerjee
mathjax: true
---

* content
{:toc}

##### Abstract
Inverse reinforcement learning (IRL) is the problem of learning the preferences of an agent from the observations of its behavior on a task. While this problem has been well investigated, the related problem of {\em online} IRL---where the observations are incrementally accrued, yet the demands of the application often prohibit a full rerun of an IRL method---has received relatively less attention. We introduce the first formal framework for online IRL, called incremental IRL (I2RL), and a new method that advances maximum entropy IRL with hidden variables, to this setting. Our formal analysis shows that the new method has a monotonically improving performance with more demonstration data, as well as probabilistically bounded error, both under full and partial observability. Experiments in a simulated robotic application of penetrating a continuous patrol under occlusion shows the relatively improved performance and speed up of the new method and validates the utility of online IRL.

##### Abstract (translated by Google)
逆强化学习（IRL）是从任务的行为观察中学习代理人偏好的问题。虽然这个问题已经得到很好的研究，但是在线观测的IRL相关问题---观测是逐步累积的，但应用的要求往往禁止IRL方法的完全重新运行---收到的相对较少注意。我们引入了第一个在线IRL的正式框架，称为增量IRL（I2RL），以及一个将隐含变量推广到最大熵IRL的新方法。我们的正式分析表明，新方法具有单调地改进的性能，具有更多的演示数据，以及概率有界的误差，无论是在全部或部分可观测性下。在模拟机器人应用中进行穿透闭塞下的连续巡逻的实验表明，新方法的性能相对提高并且加速，并验证了在线IRL的效用。

##### URL
[https://arxiv.org/abs/1805.07871](https://arxiv.org/abs/1805.07871)

##### PDF
[https://arxiv.org/pdf/1805.07871](https://arxiv.org/pdf/1805.07871)

