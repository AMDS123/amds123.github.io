---
layout: post
title: "Tactical Rewind: Self-Correction via Backtracking in Vision-and-Language Navigation"
date: 2019-03-06 18:54:55
categories: arXiv_AI
tags: arXiv_AI Tracking
author: Liyiming Ke, Xiujun Li, Yonatan Bisk, Ari Holtzman, Zhe Gan, Jingjing Liu, Jianfeng Gao, Yejin Choi, Siddhartha Srinivasa
mathjax: true
---

* content
{:toc}

##### Abstract
We present FAST NAVIGATOR, a general framework for action decoding, which yields state-of-the-art results on the recent Room-to-Room (R2R) Vision-and-Language navigation challenge of Anderson et. al. (2018). Given a natural language instruction and photo-realistic image views of a previously unseen environment, the agent must navigate from a source to a target location as quickly as possible. While all of current approaches make local action decisions or score entire trajectories with beam search, our framework seamlessly balances local and global signals when exploring the environment. Importantly, this allows us to act greedily, but use global signals to backtrack when necessary. Our FAST framework, applied to existing models, yielded a 17% relative gain over the previous state-of-the-art, an absolute 6% gain on success rate weighted by path length (SPL).

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.02547](http://arxiv.org/abs/1903.02547)

##### PDF
[http://arxiv.org/pdf/1903.02547](http://arxiv.org/pdf/1903.02547)

