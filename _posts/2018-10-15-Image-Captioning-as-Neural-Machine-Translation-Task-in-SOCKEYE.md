---
layout: post
title: "Image Captioning as Neural Machine Translation Task in SOCKEYE"
date: 2018-10-15 14:27:17
categories: arXiv_CV
tags: arXiv_CV Image_Caption Attention Caption CNN RNN
author: Loris Bazzani, Tobias Domhan, Felix Hieber
mathjax: true
---

* content
{:toc}

##### Abstract
Image captioning is an interdisciplinary research problem that stands between computer vision and natural language processing. The task is to generate a textual description of the content of an image. The typical model used for image captioning is an encoder-decoder deep network, where the encoder captures the essence of an image while the decoder is responsible for generating a sentence describing the image. Attention mechanisms can be used to automatically focus the decoder on parts of the image which are relevant to predict the next word. In this paper, we explore different decoders and attentional models popular in neural machine translation, namely attentional recurrent neural networks, self-attentional transformers, and fully-convolutional networks, which represent the current state of the art of neural machine translation. The image captioning module is available as part of SOCKEYE at this https URL which tutorial can be found at this https URL .

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1810.04101](https://arxiv.org/abs/1810.04101)

##### PDF
[https://arxiv.org/pdf/1810.04101](https://arxiv.org/pdf/1810.04101)

