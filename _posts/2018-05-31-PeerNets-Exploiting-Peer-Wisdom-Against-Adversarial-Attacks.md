---
layout: post
title: "PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks"
date: 2018-05-31 20:33:21
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN Deep_Learning
author: Jan Svoboda, Jonathan Masci, Federico Monti, Michael M. Bronstein, Leonidas Guibas
mathjax: true
---

* content
{:toc}

##### Abstract
Deep learning systems have become ubiquitous in many aspects of our lives. Unfortunately, it has been shown that such systems are vulnerable to adversarial attacks, making them prone to potential unlawful uses. Designing deep neural networks that are robust to adversarial attacks is a fundamental step in making such systems safer and deployable in a broader variety of applications (e.g. autonomous driving), but more importantly is a necessary step to design novel and more advanced architectures built on new computational paradigms rather than marginally building on the existing ones. In this paper we introduce PeerNets, a novel family of convolutional networks alternating classical Euclidean convolutions with graph convolutions to harness information from a graph of peer samples. This results in a form of non-local forward propagation in the model, where latent features are conditioned on the global structure induced by the graph, that is up to 3 times more robust to a variety of white- and black-box adversarial attacks compared to conventional architectures with almost no drop in accuracy.

##### Abstract (translated by Google)
深度学习系统在我们生活的许多方面已经无处不在。不幸的是，已经表明这样的系统容易受到对抗性攻击，使得它们容易出现潜在的非法使用。设计对抗攻击强大的深层神经网络是使这些系统更安全并可用于更广泛的应用（例如自动驾驶）的基本步骤，但更重要的是设计新型和更高级架构的必要步骤计算范式，而不是在现有的基础上构建。在本文中，我们介绍PeerNets，一种新的卷积网络家族，它将经典的欧几里得卷积与图形卷积交替使用，以利用来自同位素样本图形的信息。这导致了模型中的一种非局部前向传播形式，其中潜在特征受到由该图引发的全局结构的限制，其强度比对比各种白色和黑盒对抗攻击的强度高3倍到传统架构，精度几乎没有下降。

##### URL
[http://arxiv.org/abs/1806.00088](http://arxiv.org/abs/1806.00088)

##### PDF
[http://arxiv.org/pdf/1806.00088](http://arxiv.org/pdf/1806.00088)

