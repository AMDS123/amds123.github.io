---
layout: post
title: "Regularized Hierarchical Policies for Compositional Transfer in Robotics"
date: 2019-06-26 17:42:07
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning
author: Markus Wulfmeier, Abbas Abdolmaleki, Roland Hafner, Jost Tobias Springenberg, Michael Neunert, Tim Hertweck, Thomas Lampe, Noah Siegel, Nicolas Heess, Martin Riedmiller
mathjax: true
---

* content
{:toc}

##### Abstract
The successful application of flexible, general learning algorithms -- such as deep reinforcement learning -- to real-world robotics applications is often limited by their poor data-efficiency. Domains with more than a single dominant task of interest encourage algorithms that share partial solutions across tasks to limit the required experiment time. We develop and investigate simple hierarchical inductive biases -- in the form of structured policies -- as a mechanism for knowledge transfer across tasks in reinforcement learning (RL). To leverage the power of these structured policies we design an RL algorithm that enables stable and fast learning. We demonstrate the success of our method both in simulated robot environments (using locomotion and manipulation domains) as well as real robot experiments, demonstrating substantially better data-efficiency than competitive baselines.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.11228](http://arxiv.org/abs/1906.11228)

##### PDF
[http://arxiv.org/pdf/1906.11228](http://arxiv.org/pdf/1906.11228)

