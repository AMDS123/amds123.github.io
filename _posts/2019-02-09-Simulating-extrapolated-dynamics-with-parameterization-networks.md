---
layout: post
title: "Simulating extrapolated dynamics with parameterization networks"
date: 2019-02-09 16:37:34
categories: arXiv_AI
tags: arXiv_AI
author: James P.L. Tan
mathjax: true
---

* content
{:toc}

##### Abstract
An artificial neural network architecture, parameterization networks, is proposed for simulating extrapolated dynamics beyond observed data in dynamical systems. Parameterization networks are used to ensure the long term integrity of extrapolated dynamics, while careful tuning of model hyperparameters against validation errors controls overfitting. A parameterization network is demonstrated on the logistic map, where chaos and other nonlinear phenomena consistent with the underlying model can be extrapolated from non-chaotic training time series with good fidelity. The stated results are a lot less fantastical than they appear to be because the neural network is only extrapolating between quadratic return maps. Nonetheless, the results do suggest that successful extrapolation of qualitatively different behaviors requires learning to occur on a level of abstraction where the corresponding behaviors are more similar in nature.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.03440](http://arxiv.org/abs/1902.03440)

##### PDF
[http://arxiv.org/pdf/1902.03440](http://arxiv.org/pdf/1902.03440)

