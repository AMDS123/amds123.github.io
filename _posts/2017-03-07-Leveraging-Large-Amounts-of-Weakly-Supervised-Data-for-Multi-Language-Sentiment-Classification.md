---
layout: post
title: "Leveraging Large Amounts of Weakly Supervised Data for Multi-Language Sentiment Classification"
date: 2017-03-07 18:15:57
categories: arXiv_SD
tags: arXiv_SD Sentiment Weakly_Supervised Sentiment_Classification CNN Classification Language_Model Prediction
author: Jan Deriu, Aurelien Lucchi, Valeria De Luca, Aliaksei Severyn, Simon Müller, Mark Cieliebak, Thomas Hofmann, Martin Jaggi
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a novel approach for multi-lingual sentiment classification in short texts. This is a challenging task as the amount of training data in languages other than English is very limited. Previously proposed multi-lingual approaches typically require to establish a correspondence to English for which powerful classifiers are already available. In contrast, our method does not require such supervision. We leverage large amounts of weakly-supervised data in various languages to train a multi-layer convolutional network and demonstrate the importance of using pre-training of such networks. We thoroughly evaluate our approach on various multi-lingual datasets, including the recent SemEval-2016 sentiment prediction benchmark (Task 4), where we achieved state-of-the-art performance. We also compare the performance of our model trained individually for each language to a variant trained for all languages at once. We show that the latter model reaches slightly worse - but still acceptable - performance when compared to the single language model, while benefiting from better generalization properties across languages.

##### Abstract (translated by Google)
本文提出了一种在短文本中进行多语言情感分类的新方法。这是一个具有挑战性的任务，因为非英语的培训数据量是非常有限的。以前提出的多语言方法通常需要建立一个强大的分类器已经可用的英文信函。相反，我们的方法不需要这样的监督。我们利用大量各种语言的弱监督数据来训练多层卷积网络，并展示使用这些网络的预训练的重要性。我们对各种多语言数据集的方法进行了全面的评估，其中包括最近的SemEval-2016情绪预测基准（任务4），其中我们获得了最先进的性能。我们还将每种语言单独培训的模型性能与同时针对所有语言培训的变体进行比较。我们表明，后者模型与单一语言模型相比，性能稍差 - 但仍然可以接受 - 表现得更好，同时受益于跨越语言的更好泛化属性。

##### URL
[https://arxiv.org/abs/1703.02504](https://arxiv.org/abs/1703.02504)

##### PDF
[https://arxiv.org/pdf/1703.02504](https://arxiv.org/pdf/1703.02504)

