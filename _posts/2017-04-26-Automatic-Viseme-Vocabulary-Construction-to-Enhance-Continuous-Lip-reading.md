---
layout: post
title: "Automatic Viseme Vocabulary Construction to Enhance Continuous Lip-reading"
date: 2017-04-26 09:34:59
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition Relation Recognition
author: Adriana Fernandez-Lopez, Federico M. Sukno
mathjax: true
---

* content
{:toc}

##### Abstract
Speech is the most common communication method between humans and involves the perception of both auditory and visual channels. Automatic speech recognition focuses on interpreting the audio signals, but it has been demonstrated that video can provide information that is complementary to the audio. Thus, the study of automatic lip-reading is important and is still an open problem. One of the key challenges is the definition of the visual elementary units (the visemes) and their vocabulary. Many researchers have analyzed the importance of the phoneme to viseme mapping and have proposed viseme vocabularies with lengths between 11 and 15 visemes. These viseme vocabularies have usually been manually defined by their linguistic properties and in some cases using decision trees or clustering techniques. In this work, we focus on the automatic construction of an optimal viseme vocabulary based on the association of phonemes with similar appearance. To this end, we construct an automatic system that uses local appearance descriptors to extract the main characteristics of the mouth region and HMMs to model the statistic relations of both viseme and phoneme sequences. To compare the performance of the system different descriptors (PCA, DCT and SIFT) are analyzed. We test our system in a Spanish corpus of continuous speech. Our results indicate that we are able to recognize approximately 58% of the visemes, 47% of the phonemes and 23% of the words in a continuous speech scenario and that the optimal viseme vocabulary for Spanish is composed by 20 visemes.

##### Abstract (translated by Google)
言语是人类最常用的沟通方式，涉及听觉和视觉两个方面的感知。自动语音识别着重于解释音频信号，但已经证明，视频可以提供与音频互补的信息。因此，自动唇读的研究是重要的，仍然是一个公开的问题。其中一个关键的挑战是视觉基本单位（视角）及其词汇的定义。许多研究人员已经分析了音素对视素映射的重要性，并提出了长度在11到15之间的视觉词汇。这些viseme词汇通常是由他们的语言属性手工定义的，在某些情况下使用决策树或聚类技术。在这项工作中，我们专注于自动构建一个基于音素相似外观关联的最佳视位词汇。为此，我们构造一个自动系统，使用局部描述符来提取口区域和HMM的主要特征，以建立视素和音素序列的统计关系。为了比较系统的性能，分析了不同的描述符（PCA，DCT和SIFT）。我们用连续讲话的西班牙语语料库来测试我们的系统。我们的研究结果表明，我们能够在连续的演讲场景中识别大约58％的音位，47％的音素和23％的单词，而西班牙语的最佳视位词汇由20个视位组成。

##### URL
[https://arxiv.org/abs/1704.08035](https://arxiv.org/abs/1704.08035)

##### PDF
[https://arxiv.org/pdf/1704.08035](https://arxiv.org/pdf/1704.08035)

