---
layout: post
title: "On the Complexity of Value Iteration"
date: 2019-04-27 11:03:47
categories: arXiv_AI
tags: arXiv_AI
author: Nikhil Balaji, Stefan Kiefer, Petr Novotn&#xfd;, Guillermo A. P&#xe9;rez, Mahsa Shirmohammadi
mathjax: true
---

* content
{:toc}

##### Abstract
Value iteration is a fundamental algorithm for solving Markov Decision Processes (MDPs). It computes the maximal $n$-step payoff by iterating $n$ times a recurrence equation which is naturally associated to the MDP. At the same time, value iteration provides a policy for the MDP that is optimal on a given finite horizon $n$. In this paper, we settle the computational complexity of value iteration. We show that, given a horizon $n$ in binary and an MDP, computing an optimal policy is EXP-complete, thus resolving an open problem that goes back to the seminal 1987 paper on the complexity of MDPs by Papadimitriou and Tsitsiklis. As a stepping stone, we show that it is EXP-complete to compute the $n$-fold iteration (with $n$ in binary) of a function given by a straight-line program over the integers with $\max$ and $+$ as operators.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1807.04920](http://arxiv.org/abs/1807.04920)

##### PDF
[http://arxiv.org/pdf/1807.04920](http://arxiv.org/pdf/1807.04920)

