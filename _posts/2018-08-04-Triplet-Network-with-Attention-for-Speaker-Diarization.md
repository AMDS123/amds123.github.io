---
layout: post
title: "Triplet Network with Attention for Speaker Diarization"
date: 2018-08-04 21:10:03
categories: arXiv_CL
tags: arXiv_CL Attention Embedding
author: Huan Song, Megan Willi, Jayaraman J. Thiagarajan, Visar Berisha, Andreas Spanias
mathjax: true
---

* content
{:toc}

##### Abstract
In automatic speech processing systems, speaker diarization is a crucial front-end component to separate segments from different speakers. Inspired by the recent success of deep neural networks (DNNs) in semantic inferencing, triplet loss-based architectures have been successfully used for this problem. However, existing work utilizes conventional i-vectors as the input representation and builds simple fully connected networks for metric learning, thus not fully leveraging the modeling power of DNN architectures. This paper investigates the importance of learning effective representations from the sequences directly in metric learning pipelines for speaker diarization. More specifically, we propose to employ attention models to learn embeddings and the metric jointly in an end-to-end fashion. Experiments are conducted on the CALLHOME conversational speech corpus. The diarization results demonstrate that, besides providing a unified model, the proposed approach achieves improved performance when compared against existing approaches.

##### Abstract (translated by Google)
在自动语音处理系统中，扬声器二值化是将不同扬声器的片段分开的关键前端组件。受最近语义推理中深度神经网络（DNN）成功的启发，基于三元组丢失的体系结构已成功用于此问题。然而，现有工作利用传统的i向量作为输入表示，并构建用于度量学习的简单的完全连接网络，因此不能充分利用DNN架构的建模能力。本文研究了直接在公制学习流程中学习有效表示的重要性，以便进行说话人员的疏导。更具体地说，我们建议采用注意力模型以端到端的方式共同学习嵌入和度量。实验在CALLHOME会话语料库上进行。二值化结果表明，除了提供统一模型之外，与现有方法相比，所提出的方法实现了改进的性能。

##### URL
[http://arxiv.org/abs/1808.01535](http://arxiv.org/abs/1808.01535)

##### PDF
[http://arxiv.org/pdf/1808.01535](http://arxiv.org/pdf/1808.01535)

