---
layout: post
title: "Automatic Image Cropping for Visual Aesthetic Enhancement Using Deep Neural Networks and Cascaded Regression"
date: 2017-12-25 09:49:39
categories: arXiv_CV
tags: arXiv_CV Knowledge CNN
author: Guanjun Guo, Hanzi Wang, Chunhua Shen, Yan Yan, Hong-Yuan Mark Liao
mathjax: true
---

* content
{:toc}

##### Abstract
Despite recent progress, computational visual aesthetic is still challenging. Image cropping, which refers to the removal of unwanted scene areas, is an important step to improve the aesthetic quality of an image. However, it is challenging to evaluate whether cropping leads to aesthetically pleasing results because the assessment is typically subjective. In this paper, we propose a novel cascaded cropping regression (CCR) method to perform image cropping by learning the knowledge from professional photographers. The proposed CCR method improves the convergence speed of the cascaded method, which directly uses random-ferns regressors. In addition, a two-step learning strategy is proposed and used in the CCR method to address the problem of lacking labelled cropping data. Specifically, a deep convolutional neural network (CNN) classifier is first trained on large-scale visual aesthetic datasets. The deep CNN model is then designed to extract features from several image cropping datasets, upon which the cropping bounding boxes are predicted by the proposed CCR method. Experimental results on public image cropping datasets demonstrate that the proposed method significantly outperforms several state-of-the-art image cropping methods.

##### Abstract (translated by Google)
尽管最近取得了进展，计算机视觉美学仍然是一个挑战图像裁剪是指去除不需要的场景区域，是提高图像美感质量的重要一步。然而，评估种植是否会带来美观的结果是非常具有挑战性的，因为评估通常是主观的。在本文中，我们提出了一种新的级联裁剪回归（CCR）方法，通过学习专业摄影师的知识进行图像裁剪。所提出的CCR方法提高了直接使用随机蕨类回归机的级联方法的收敛速度。此外，提出了两步学习策略，并在CCR方法中使用，以解决缺少标注的裁剪数据的问题。具体而言，深度卷积神经网络（CNN）分类器首先在大型视觉美学数据集上进行训练。然后设计深CNN模型，从多个图像裁剪数据集中提取特征，通过所提出的CCR方法对裁剪边界框进行预测。公共图像裁剪数据集的实验结果表明，所提出的方法明显优于几种最先进的图像裁剪方法。

##### URL
[http://arxiv.org/abs/1712.09048](http://arxiv.org/abs/1712.09048)

##### PDF
[http://arxiv.org/pdf/1712.09048](http://arxiv.org/pdf/1712.09048)

