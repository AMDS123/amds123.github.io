---
layout: post
title: "Interactive Reinforcement Learning with Dynamic Reuse of Prior Knowledge from Human/Agent's Demonstration"
date: 2018-05-11 17:12:11
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning
author: Zhaodong Wang, Matthew E. Taylor
mathjax: true
---

* content
{:toc}

##### Abstract
Reinforcement learning has enjoyed multiple successes in recent years. However, these successes typically require very large amounts of data before an agent achieves acceptable performance. This paper introduces a novel way of combating such requirements by leveraging existing (human or agent) knowledge. In particular, this paper uses demonstrations from agents and humans, allowing an untrained agent to quickly achieve high performance. We empirically compare with, and highlight the weakness of, HAT and CHAT, methods of transferring knowledge from a source agent/human to a target agent. This paper introduces an effective transfer approach, DRoP, combining the offline knowledge (demonstrations recorded before learning) with online confidence-based performance analysis. DRoP dynamically involves the demonstrator's knowledge, integrating it into the reinforcement learning agent's online learning loop to achieve efficient and robust learning.

##### Abstract (translated by Google)
强化学习近年来取得了多项成功。但是，这些成功通常需要非常大量的数据才能实现可接受的性能。本文介绍了一种通过利用现有（人类或代理）知识来打击这些需求的新方法。特别是，本文使用代理和人类的演示，允许未经培训的代理快速实现高性能。我们通过实证比较，并强调了HAT和CHAT将知识从源代理/人员转移到目标代理的方法的弱点。本文介绍了一种有效的传输方法DRoP，将离线知识（在学习之前记录的演示）与基于在线置信度的性能分析相结合。 DRoP动态地涉及演示者的知识，将其整合到强化学习代理的在线学习循环中以实现高效和强大的学习。

##### URL
[http://arxiv.org/abs/1805.04493](http://arxiv.org/abs/1805.04493)

##### PDF
[http://arxiv.org/pdf/1805.04493](http://arxiv.org/pdf/1805.04493)

