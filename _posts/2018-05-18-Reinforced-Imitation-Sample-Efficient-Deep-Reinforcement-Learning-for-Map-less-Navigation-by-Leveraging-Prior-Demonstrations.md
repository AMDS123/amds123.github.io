---
layout: post
title: "Reinforced Imitation: Sample Efficient Deep Reinforcement Learning for Map-less Navigation by Leveraging Prior Demonstrations"
date: 2018-05-18 08:40:56
categories: arXiv_RO
tags: arXiv_RO Reinforcement_Learning
author: Mark Pfeiffer, Samarth Shukla, Matteo Turchetta, Cesar Cadena, Andreas Krause, Roland Siegwart, Juan Nieto
mathjax: true
---

* content
{:toc}

##### Abstract
This work presents a learning-based approach for target driven map-less navigation. The underlying navigation model is an end-to-end neural network which is trained using a combination of expert demonstrations, imitation learning (IL) and reinforcement learning (RL). While RL and IL suffer from a large sample complexity and the distribution mismatch problem, respectively, we show that pre-training the navigation model using expert demonstrations can reduce the training time to reach at least the same level of performance compared to plain RL by a factor of 5. We present a thorough evaluation of different combinations of expert demonstrations and RL, both in simulation and on a real robotic platform. Our results show that the final model outperforms both standalone approaches in the amount of successful navigation tasks. The learned navigation policy is also able to generalize to unseen and real-world environments.

##### Abstract (translated by Google)
这项工作为目标驱动的无地图导航提供了一种基于学习的方法。基础导航模型是一个端到端的神经网络，它使用专家演示，模仿学习（IL）和强化学习（RL）相结合的方式进行训练。虽然RL和IL分别遭受大样本复杂性和分布不匹配问题，但我们表明，使用专家演示预训练导航模型可以减少训练时间，以达到与普通RL相比的至少相同水平的性能，因子5.我们对仿真和真实机器人平台上的专家演示和RL的不同组合进行全面评估。我们的结果表明，最终模型在成功导航任务的数量上优于单独的方法。学习的导航策略还能够概括为看不见的和真实世界的环境。

##### URL
[http://arxiv.org/abs/1805.07095](http://arxiv.org/abs/1805.07095)

##### PDF
[http://arxiv.org/pdf/1805.07095](http://arxiv.org/pdf/1805.07095)

