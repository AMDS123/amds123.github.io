---
layout: post
title: "Trick Me If You Can: Adversarial Writing of Trivia Challenge Questions"
date: 2018-09-07 22:39:33
categories: arXiv_CL
tags: arXiv_CL Adversarial
author: Eric Wallace, Pedro Rodriguez, Shi Feng, Jordan Boyd-Graber
mathjax: true
---

* content
{:toc}

##### Abstract
Modern natural language processing systems have been touted as approaching human performance. However, existing datasets are imperfect tests. Examples are written with humans in mind, not computers, and often do not properly expose model limitations. We address this by developing a new process for crowdsourced annotation, adversarial writing, where humans interact with trained models and try to break them. Applying this annotation process to Trivia question answering yields a challenge set, which despite being easy for human players to answer, systematically stumps automated question answering systems. Diagnosing model errors on the evaluation data provides actionable insights to explore in developing more robust and generalizable question answering systems.

##### Abstract (translated by Google)
现代自然语言处理系统被吹捧为接近人类表现。但是，现有数据集是不完美的测试。示例是针对人类而非计算机编写的，并且通常不能正确地暴露模型限制。我们通过开发一个用于众包注释，对抗性写作的新流程来解决这个问题，人类与受过训练的模型进行交互并试图打破它们。将此注释过程应用于Trivia问题回答会产生一个挑战集，尽管人类玩家很容易回答，但系统地将自动问答系统排除在外。诊断评估数据上的模型错误提供了可操作的见解，以便在开发更强大和可推广的问答系统时进行探索。

##### URL
[http://arxiv.org/abs/1809.02701](http://arxiv.org/abs/1809.02701)

##### PDF
[http://arxiv.org/pdf/1809.02701](http://arxiv.org/pdf/1809.02701)

