---
layout: post
title: "A Survey of Safety and Trustworthiness of Deep Neural Networks"
date: 2019-07-26 18:25:01
categories: arXiv_AI
tags: arXiv_AI Review Adversarial Survey
author: Xiaowei Huang, Daniel Kroening, Wenjie Ruan, James Sharp, Youcheng Sun, Emese Thamo, Min Wu, Xinping Yi
mathjax: true
---

* content
{:toc}

##### Abstract
In the past few years, significant progress has been made on deep neural networks (DNNs) in achieving human-level performance on several long-standing tasks. With the broader deployment of DNNs on various applications, the concerns on its safety and trustworthiness have been raised in public, especially after the widely reported fatal incidents of self-driving cars. Research to address these concerns is very active, with many papers released in the past few years. This survey paper conducts a review of the current research effort on making DNNs safe and trustworthy, by focusing on four aspects: verification, testing, adversarial attack and defence, and interpretability. In total, we surveyed 178 papers, most of which published after 2017.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.08342](http://arxiv.org/abs/1812.08342)

##### PDF
[http://arxiv.org/pdf/1812.08342](http://arxiv.org/pdf/1812.08342)

