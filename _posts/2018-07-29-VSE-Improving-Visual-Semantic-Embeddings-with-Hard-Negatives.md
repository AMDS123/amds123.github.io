---
layout: post
title: "VSE++: Improving Visual-Semantic Embeddings with Hard Negatives"
date: 2018-07-29 19:11:57
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Caption Embedding Prediction
author: Fartash Faghri, David J. Fleet, Jamie Ryan Kiros, Sanja Fidler
mathjax: true
---

* content
{:toc}

##### Abstract
We present a new technique for learning visual-semantic embeddings for cross-modal retrieval. Inspired by hard negative mining, the use of hard negatives in structured prediction, and ranking loss functions, we introduce a simple change to common loss functions used for multi-modal embeddings. That, combined with fine-tuning and use of augmented data, yields significant gains in retrieval performance. We showcase our approach, VSE++, on MS-COCO and Flickr30K datasets, using ablation studies and comparisons with existing methods. On MS-COCO our approach outperforms state-of-the-art methods by 8.8% in caption retrieval and 11.3% in image retrieval (at R@1).

##### Abstract (translated by Google)
我们提出了一种学习视觉语义嵌入的新技术，用于跨模态检索。受硬负面挖掘，在结构化预测中使用硬阴性以及排名损失函数的启发，我们引入了对用于多模态嵌入的常见损失函数的简单更改。结合微调和增强数据的使用，可以显着提高检索性能。我们使用消融研究和现有方法的比较，在MS-COCO和Flickr30K数据集上展示我们的方法VSE ++。在MS-COCO上，我们的方法在字幕检索方面优于8.8％，在图像检索方面优于11.3％（在R @ 1处）。

##### URL
[https://arxiv.org/abs/1707.05612](https://arxiv.org/abs/1707.05612)

##### PDF
[https://arxiv.org/pdf/1707.05612](https://arxiv.org/pdf/1707.05612)

