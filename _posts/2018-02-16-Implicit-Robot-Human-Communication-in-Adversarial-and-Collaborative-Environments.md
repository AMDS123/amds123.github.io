---
layout: post
title: "Implicit Robot-Human Communication in Adversarial and Collaborative Environments"
date: 2018-02-16 21:53:59
categories: arXiv_AI
tags: arXiv_AI Adversarial
author: Anagha Kulkarni, Siddharth Srivastava, Subbarao Kambhampati
mathjax: true
---

* content
{:toc}

##### Abstract
Users of AI systems may rely upon them to produce plans for achieving desired objectives. Such AI systems should be able to compute obfuscated plans whose execution in adversarial situations protects privacy as well as legible plans which are easy for team-members to understand in collaborative situations. We develop a unified framework that addresses these dual problems by computing plans with a desired level of comprehensibility from the point of view of a partially informed observer. Our approach produces obfuscated plans with observations that are consistent with at least 'k' goals from a given set of decoy goals. In addition, when the goal is known to the observer, our approach generates obfuscated plans with observations that are diverse with at least 'l' candidate plans. Our approach for plan legibility produces plans that achieve a goal while being consistent with at most 'j' goals in a given set of confounding goals. We provide an empirical evaluation to show the feasibility and usefulness of our approaches.

##### Abstract (translated by Google)
AI系统的用户可能依靠他们制定实现预期目标的计划。这种AI系统应该能够计算混淆计划，这些计划在敌对状态下执行，以保护隐私以及易于团队成员在协作情况下理解的易读计划。我们开发了一个统一的框架，通过从部分知情的观察者的角度计算具有理想水平的可理解性的计划来解决这些双重问题。我们的方法产生混淆的计划，观察结果与给定的一组诱饵目标中的至少'k'个目标一致。另外，当观察者知道目标时，我们的方法会生成混淆的计划，观察结果至少有'l'个候选计划。我们的计划易读性方法产生了实现目标的计划，同时在一组给定的混杂目标中与大多数“j”目标保持一致。我们提供了一个实证评估来展示我们方法的可行性和实用性。

##### URL
[http://arxiv.org/abs/1802.06137](http://arxiv.org/abs/1802.06137)

##### PDF
[http://arxiv.org/pdf/1802.06137](http://arxiv.org/pdf/1802.06137)

