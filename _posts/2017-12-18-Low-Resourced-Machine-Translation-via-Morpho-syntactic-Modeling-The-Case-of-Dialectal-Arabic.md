---
layout: post
title: "Low Resourced Machine Translation via Morpho-syntactic Modeling: The Case of Dialectal Arabic"
date: 2017-12-18 07:04:10
categories: arXiv_CL
tags: arXiv_CL Sparse Attention
author: Alexander Erdmann, Nizar Habash, Dima Taji, Houda Bouamor
mathjax: true
---

* content
{:toc}

##### Abstract
We present the second ever evaluated Arabic dialect-to-dialect machine translation effort, and the first to leverage external resources beyond a small parallel corpus. The subject has not previously received serious attention due to lack of naturally occurring parallel data; yet its importance is evidenced by dialectal Arabic's wide usage and breadth of inter-dialect variation, comparable to that of Romance languages. Our results suggest that modeling morphology and syntax significantly improves dialect-to-dialect translation, though optimizing such data-sparse models requires consideration of the linguistic differences between dialects and the nature of available data and resources. On a single-reference blind test set where untranslated input scores 6.5 BLEU and a model trained only on parallel data reaches 14.6, pivot techniques and morphosyntactic modeling significantly improve performance to 17.5.

##### Abstract (translated by Google)
我们介绍了第二次评估的阿拉伯方言到方言机器翻译的工作，第一个利用外部资源，超越了一个小的平行语料库。由于缺乏自然发生的并行数据，该主题以前没有受到过重视;但其重要性却体现在方言阿拉伯语的广泛使用和广泛的方言间变异上，与罗曼语的语言相媲美。我们的研究结果表明，建模形态和语法显着提高了方言到方言的翻译，尽管优化这种数据稀疏模型需要考虑方言之间的语言差异以及可用数据和资源的性质。在单参考盲测试集中，未翻译输入评分6.5 BLEU和仅训练平行数据的模型达到14.6，枢轴技术和形态句法建模显着提高性能至17.5。

##### URL
[http://arxiv.org/abs/1712.06273](http://arxiv.org/abs/1712.06273)

##### PDF
[http://arxiv.org/pdf/1712.06273](http://arxiv.org/pdf/1712.06273)

