---
layout: post
title: "Interpretable to Whom? A Role-based Model for Analyzing Interpretable Machine Learning Systems"
date: 2018-06-20 04:52:33
categories: arXiv_AI
tags: arXiv_AI Relation
author: Richard Tomsett, Dave Braines, Dan Harborne, Alun Preece, Supriyo Chakraborty
mathjax: true
---

* content
{:toc}

##### Abstract
Several researchers have argued that a machine learning system's interpretability should be defined in relation to a specific agent or task: we should not ask if the system is interpretable, but to whom is it interpretable. We describe a model intended to help answer this question, by identifying different roles that agents can fulfill in relation to the machine learning system. We illustrate the use of our model in a variety of scenarios, exploring how an agent's role influences its goals, and the implications for defining interpretability. Finally, we make suggestions for how our model could be useful to interpretability researchers, system developers, and regulatory bodies auditing machine learning systems.

##### Abstract (translated by Google)
一些研究人员认为机器学习系统的可解释性应该根据具体的代理人或任务来定义：我们不应该问系统是否可以解释，而是可以解释谁。我们通过识别代理可以在机器学习系统中实现的不同角色来描述旨在帮助回答这个问题的模型。我们举例说明了我们的模型在各种情景中的使用，探讨了代理人角色如何影响其目标，以及定义可解释性的含义。最后，我们就如何使我们的模型对解释性研究人员，系统开发人员以及审计机器学习系统的监管机构有用提出建议。

##### URL
[http://arxiv.org/abs/1806.07552](http://arxiv.org/abs/1806.07552)

##### PDF
[http://arxiv.org/pdf/1806.07552](http://arxiv.org/pdf/1806.07552)

