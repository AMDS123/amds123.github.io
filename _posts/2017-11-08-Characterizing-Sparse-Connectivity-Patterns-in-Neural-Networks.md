---
layout: post
title: "Characterizing Sparse Connectivity Patterns in Neural Networks"
date: 2017-11-08 02:45:55
categories: arXiv_CV
tags: arXiv_CV Sparse CNN Classification
author: Sourya Dey, Kuan-Wen Huang, Peter A. Beerel, Keith M. Chugg
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel way of reducing the number of parameters in the storage-hungry fully connected classification layers of a neural network by using pre-defined sparsity, where the majority of connections are absent prior to starting training. Our results indicate that convolutional neural networks can operate without any loss of accuracy at less than 0.5% classification layer connection density, or less than 5% overall network connection density. We also investigate the effects of pre-defining the sparsity of networks with only fully connected layers. Based on our sparsifying technique, we introduce the `scatter' metric to characterize the quality of a particular connection pattern. As proof of concept, we show results on CIFAR, MNIST and a new dataset on classifying Morse code symbols, which highlights some interesting trends and limits of sparse connection patterns.

##### Abstract (translated by Google)
我们提出了一种新的方法，通过使用预先定义的稀疏性，在开始训练之前大多数连接不存在的情况下，减少神经网络的需要存储空间的完全连接的分类层中的参数数量。我们的研究结果表明，卷积神经网络可以在小于0.5％的分类层连接密度或小于5％的整体网络连接密度的情况下，在没有任何精度损失的情况下运行。我们还研究了只有完全连接层预先定义网络的稀疏性的影响。基于我们的稀疏技术，我们引入“散布”度量来表征特定连接模式的质量。作为概念的证明，我们在CIFAR，MNIST上展示结果，并在摩尔斯电码符号分类上展示了一个新的数据集，这突出了稀疏连接模式的一些有趣的趋势和局限性。

##### URL
[https://arxiv.org/abs/1711.02131](https://arxiv.org/abs/1711.02131)

##### PDF
[https://arxiv.org/pdf/1711.02131](https://arxiv.org/pdf/1711.02131)

