---
layout: post
title: "Deep Learning Architectures for Face Recognition in Video Surveillance"
date: 2018-02-27 16:10:15
categories: arXiv_CV
tags: arXiv_CV Review Face CNN Deep_Learning Relation Recognition Face_Recognition
author: Saman Bashbaghi, Eric Granger, Robert Sabourin, Mostafa Parchami
mathjax: true
---

* content
{:toc}

##### Abstract
Face recognition (FR) systems for video surveillance (VS) applications attempt to accurately detect the presence of target individuals over a distributed network of cameras. In video-based FR systems, facial models of target individuals are designed a priori during enrollment using a limited number of reference still images or video data. These facial models are not typically representative of faces being observed during operations due to large variations in illumination, pose, scale, occlusion, blur, and to camera inter-operability. Specifically, in still-to-video FR application, a single high-quality reference still image captured with still camera under controlled conditions is employed to generate a facial model to be matched later against lower-quality faces captured with video cameras under uncontrolled conditions. Current video-based FR systems can perform well on controlled scenarios, while their performance is not satisfactory in uncontrolled scenarios mainly because of the differences between the source (enrollment) and the target (operational) domains. Most of the efforts in this area have been toward the design of robust video-based FR systems in unconstrained surveillance environments. This chapter presents an overview of recent advances in still-to-video FR scenario through deep convolutional neural networks (CNNs). In particular, deep learning architectures proposed in the literature based on triplet-loss function (e.g., cross-correlation matching CNN, trunk-branch ensemble CNN and HaarNet) and supervised autoencoders (e.g., canonical face representation CNN) are reviewed and compared in terms of accuracy and computational complexity.

##### Abstract (translated by Google)
用于视频监控（VS）应用的人脸识别（FR）系统试图通过分布式相机网络准确检测目标个体的存在。在基于视频的FR系统中，使用有限数量的参考静止图像或视频数据在登记期间先验地设计目标个体的面部模型。由于照明，姿势，比例，遮挡，模糊以及相机互操作性的巨大变化，这些面部模型通常不能代表在操作期间观察到的面部。具体而言，在静止视频FR应用中，采用在受控条件下利用静止照相机拍摄的单个高质量参考静止图像来产生面部模型，以在未受控条件下针对使用摄像机捕捉的较低质量面部进行匹配。当前基于视频的FR系统可以在受控场景下表现良好，但在不受控制的情况下，其表现不令人满意，主要是由于源（注册）和目标（运营）域之间的差异。该领域的大部分努力一直致力于在无约束的监视环境中设计强大的基于视频的FR系统。本章通过深度卷积神经网络（CNN）概述了静止视频FR情景的最新进展。尤其是，在文献中提出的基于三重损失函数（例如，互相关匹配CNN，干线分支集合CNN和HaarNet）和受监督自动编码器（例如，典型人脸表征CNN）的深度学习体系结构被审查和比较的准确性和计算复杂性。

##### URL
[https://arxiv.org/abs/1802.09990](https://arxiv.org/abs/1802.09990)

##### PDF
[https://arxiv.org/pdf/1802.09990](https://arxiv.org/pdf/1802.09990)

