---
layout: post
title: "WebVision Database: Visual Learning and Understanding from Web Data"
date: 2017-08-09 14:59:30
categories: arXiv_CV
tags: arXiv_CV Recognition
author: Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, Luc Van Gool
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present a study on learning visual recognition models from large scale noisy web data. We build a new database called WebVision, which contains more than $2.4$ million web images crawled from the Internet by using queries generated from the 1,000 semantic concepts of the benchmark ILSVRC 2012 dataset. Meta information along with those web images (e.g., title, description, tags, etc.) are also crawled. A validation set and test set containing human annotated images are also provided to facilitate algorithmic development. Based on our new database, we obtain a few interesting observations: 1) the noisy web images are sufficient for training a good deep CNN model for visual recognition; 2) the model learnt from our WebVision database exhibits comparable or even better generalization ability than the one trained from the ILSVRC 2012 dataset when being transferred to new datasets and tasks; 3) a domain adaptation issue (a.k.a., dataset bias) is observed, which means the dataset can be used as the largest benchmark dataset for visual domain adaptation. Our new WebVision database and relevant studies in this work would benefit the advance of learning state-of-the-art visual models with minimum supervision based on web data.

##### Abstract (translated by Google)
在本文中，我们提出了一个从大规模噪声网络数据学习视觉识别模型的研究。我们构建了一个名为WebVision的新数据库，其中包含使用基准ILSVRC 2012数据集的1,000个语义概念生成的查询从Internet爬取的超过2.4百万美元的Web图像。元信息连同那些网页图像（例如标题，描述，标签等）也被抓取。还提供了包含人类注释图像的验证集和测试集以促进算法开发。基于我们的新数据库，我们得到了一些有趣的观察：1）有噪声的网络图像足以训练一个良好的深度视觉识别CNN模型; 2）从WebVision数据库获得的模型与传统的数据集和任务相比，从ILSVRC 2012数据集训练的模型具有可比较甚至更好的泛化能力; 3）观察到领域适应问题（也就是数据集偏差），这意味着该数据集可以被用作视域适应的最大基准数据集。我们新的WebVision数据库和这项工作的相关研究将有利于在基于Web数据的最小监督下学习最先进的视觉模型。

##### URL
[https://arxiv.org/abs/1708.02862](https://arxiv.org/abs/1708.02862)

##### PDF
[https://arxiv.org/pdf/1708.02862](https://arxiv.org/pdf/1708.02862)

