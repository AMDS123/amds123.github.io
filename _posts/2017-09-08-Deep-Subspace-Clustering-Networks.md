---
layout: post
title: "Deep Subspace Clustering Networks"
date: 2017-09-08 02:22:22
categories: arXiv_CV
tags: arXiv_CV
author: Pan Ji, Tong Zhang, Hongdong Li, Mathieu Salzmann, Ian Reid
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel deep neural network architecture for unsupervised subspace clustering. This architecture is built upon deep auto-encoders, which non-linearly map the input data into a latent space. Our key idea is to introduce a novel self-expressive layer between the encoder and the decoder to mimic the "self-expressiveness" property that has proven effective in traditional subspace clustering. Being differentiable, our new self-expressive layer provides a simple but effective way to learn pairwise affinities between all data points through a standard back-propagation procedure. Being nonlinear, our neural-network based method is able to cluster data points having complex (often nonlinear) structures. We further propose pre-training and fine-tuning strategies that let us effectively learn the parameters of our subspace clustering networks. Our experiments show that the proposed method significantly outperforms the state-of-the-art unsupervised subspace clustering methods.

##### Abstract (translated by Google)
我们提出了一个新的深度神经网络架构无监督子空间聚类。这种架构建立在深度自动编码器之上，它将输入数据非线性映射到潜在空间。我们的主要思想是在编码器和解码器之间引入一个新颖的自我表现层，以模仿在传统子空间聚类中证明有效的“自我表现”属性。作为可区分的，我们的新的自我表现层提供了一个简单但有效的方法，通过标准的反向传播过程学习所有数据点之间的成对亲和性。作为非线性的，我们的基于神经网络的方法能够对具有复杂（通常是非线性）结构的数据点进行聚类。我们进一步提出了预训练和微调策略，让我们有效地学习子空间聚类网络的参数。我们的实验表明，提出的方法显着优于最先进的无监督子空间聚类方法。

##### URL
[https://arxiv.org/abs/1709.02508](https://arxiv.org/abs/1709.02508)

##### PDF
[https://arxiv.org/pdf/1709.02508](https://arxiv.org/pdf/1709.02508)

