---
layout: post
title: "Multi-modal Conditional Attention Fusion for Dimensional Emotion Prediction"
date: 2017-09-04 12:05:47
categories: arXiv_CV
tags: arXiv_CV Attention RNN Prediction
author: Shizhe Chen, Qin Jin
mathjax: true
---

* content
{:toc}

##### Abstract
Continuous dimensional emotion prediction is a challenging task where the fusion of various modalities usually achieves state-of-the-art performance such as early fusion or late fusion. In this paper, we propose a novel multi-modal fusion strategy named conditional attention fusion, which can dynamically pay attention to different modalities at each time step. Long-short term memory recurrent neural networks (LSTM-RNN) is applied as the basic uni-modality model to capture long time dependencies. The weights assigned to different modalities are automatically decided by the current input features and recent history information rather than being fixed at any kinds of situation. Our experimental results on a benchmark dataset AVEC2015 show the effectiveness of our method which outperforms several common fusion strategies for valence prediction.

##### Abstract (translated by Google)
连续的维度情感预测是一个具有挑战性的任务，其中各种形式的融合通常达到最先进的性能，如早期融合或后期融合。在本文中，我们提出了一种新的多模态融合策略，称为条件注意融合，可以动态地关注每个时间段的不同模态。应用长短期记忆递归神经网络（LSTM-RNN）作为基本的单模态模型来捕获长时间依赖性。分配给不同模态的权重由当前输入特征和近期历史信息自动决定，而不是固定在任何情况下。我们在基准数据集AVEC2015上的实验结果显示了我们的方法的效率优于几种常用于价预测的融合策略。

##### URL
[https://arxiv.org/abs/1709.02251](https://arxiv.org/abs/1709.02251)

##### PDF
[https://arxiv.org/pdf/1709.02251](https://arxiv.org/pdf/1709.02251)

