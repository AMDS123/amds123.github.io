---
layout: post
title: "Spatial Transformer Networks"
date: 2016-02-04 18:08:46
categories: arXiv_CV
tags: arXiv_CV CNN
author: Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.

##### Abstract (translated by Google)
卷积神经网络定义了一个异常强大的模型类，但是仍然受限于缺乏以计算和参数有效的方式对输入数据进行空间不变的能力。在这项工作中，我们介绍一个新的可学习模块，即空间变换器，它明确允许网络中的数据的空间操作。这个可区分的模块可以被插入到现有的卷积体系结构中，使得神经网络能够主动地在特征映射本身的条件下空间变换特征映射，而不需要对优化过程进行任何额外的训练监督或修改。我们表明，空间变换器的使用导致模型学习不变性的翻译，规模，旋转和更一般的翘曲，导致在几个基准上的最先进的性能，以及一些类的转换。

##### URL
[https://arxiv.org/abs/1506.02025](https://arxiv.org/abs/1506.02025)

##### PDF
[https://arxiv.org/pdf/1506.02025](https://arxiv.org/pdf/1506.02025)

