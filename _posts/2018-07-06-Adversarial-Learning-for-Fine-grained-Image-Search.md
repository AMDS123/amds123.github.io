---
layout: post
title: "Adversarial Learning for Fine-grained Image Search"
date: 2018-07-06 04:03:11
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Kevin Lin, Fan Yang, Qiaosong Wang, Robinson Piramuthu
mathjax: true
---

* content
{:toc}

##### Abstract
Fine-grained image search is still a challenging problem due to the difficulty in capturing subtle differences regardless of pose variations of objects from fine-grained categories. In practice, a dynamic inventory with new fine-grained categories adds another dimension to this challenge. In this work, we propose an end-to-end network, called FGGAN, that learns discriminative representations by implicitly learning a geometric transformation from multi-view images for fine-grained image search. We integrate a generative adversarial network (GAN) that can automatically handle complex view and pose variations by converting them to a canonical view without any predefined transformations. Moreover, in an open-set scenario, our network is able to better match images from unseen and unknown fine-grained categories. Extensive experiments on two public datasets and a newly collected dataset have demonstrated the outstanding robust performance of the proposed FGGAN in both closed-set and open-set scenarios, providing as much as 10% relative improvement compared to baselines.

##### Abstract (translated by Google)
细粒度图像搜索仍然是一个具有挑战性的问题，因为无论细粒度类别中的对象的姿势变化如何，都难以捕获细微的差异。实际上，具有新细粒度类别的动态库存为此挑战增加了另一个维度。在这项工作中，我们提出了一个名为FGGAN的端到端网络，它通过隐式地从多视图图像中学习几何变换来进行细粒度图像搜索，从而学习判别式表示。我们集成了一个生成对抗网络（GAN），它可以自动处理复杂视图和姿势变化，方法是将它们转换为规范视图，而无需任何预定义的转换。此外，在开放式场景中，我们的网络能够更好地匹配来自未见和未知细粒度类别的图像。对两个公共数据集和新收集的数据集进行的大量实验证明了所提出的FGGAN在封闭集和开放集方案中的出色稳健性能，与基线相比可提供高达10％的相对改进。

##### URL
[http://arxiv.org/abs/1807.02247](http://arxiv.org/abs/1807.02247)

##### PDF
[http://arxiv.org/pdf/1807.02247](http://arxiv.org/pdf/1807.02247)

