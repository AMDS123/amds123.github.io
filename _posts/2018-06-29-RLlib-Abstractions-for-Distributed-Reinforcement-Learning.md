---
layout: post
title: "RLlib: Abstractions for Distributed Reinforcement Learning"
date: 2018-06-29 00:19:24
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Eric Liang, Richard Liaw, Philipp Moritz, Robert Nishihara, Roy Fox, Ken Goldberg, Joseph E. Gonzalez, Michael I. Jordan, Ion Stoica
mathjax: true
---

* content
{:toc}

##### Abstract
Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available at https://rllib.io/.

##### Abstract (translated by Google)
强化学习（RL）算法涉及高度不规则计算模式的深度嵌套，每个计算模式通常展示分布式计算的机会。我们主张通过适应自顶向下的层次控制算法来以可组合的方式分发RL组件，从而将并行性和资源需求封装在短期运行的计算任务中。我们通过RLlib展示了这个原理的好处：为RL提供可扩展的软件原语的库。这些原语使得广泛的算法能够实现高性能，可扩展性和大量的代码重用。 RLlib位于https://rllib.io/。

##### URL
[http://arxiv.org/abs/1712.09381](http://arxiv.org/abs/1712.09381)

##### PDF
[http://arxiv.org/pdf/1712.09381](http://arxiv.org/pdf/1712.09381)

