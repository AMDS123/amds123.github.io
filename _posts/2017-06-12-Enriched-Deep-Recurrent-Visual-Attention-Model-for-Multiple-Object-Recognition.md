---
layout: post
title: "Enriched Deep Recurrent Visual Attention Model for Multiple Object Recognition"
date: 2017-06-12 11:55:35
categories: arXiv_CV
tags: arXiv_CV Attention Gradient_Descent Recognition
author: Artsiom Ablavatski, Shijian Lu, Jianfei Cai
mathjax: true
---

* content
{:toc}

##### Abstract
We design an Enriched Deep Recurrent Visual Attention Model (EDRAM) - an improved attention-based architecture for multiple object recognition. The proposed model is a fully differentiable unit that can be optimized end-to-end by using Stochastic Gradient Descent (SGD). The Spatial Transformer (ST) was employed as visual attention mechanism which allows to learn the geometric transformation of objects within images. With the combination of the Spatial Transformer and the powerful recurrent architecture, the proposed EDRAM can localize and recognize objects simultaneously. EDRAM has been evaluated on two publicly available datasets including MNIST Cluttered (with 70K cluttered digits) and SVHN (with up to 250k real world images of house numbers). Experiments show that it obtains superior performance as compared with the state-of-the-art models.

##### Abstract (translated by Google)
我们设计了一个丰富的深度复发视觉注意模型（EDRAM） - 一个改进的基于注意的多目标识别体系结构。所提出的模型是一个完全可微的单元，可以使用随机梯度下降（SGD）进行端到端的优化。空间变换器（ST）被用作视觉注意机制，允许学习图像内物体的几何变换。通过结合空间变换器和强大的循环体系结构，所提出的EDRAM可以同时定位和识别物体。 EDRAM已经在两个公开可用的数据集（包括MNIST Cluttered（具有70K的杂乱数字）和SVHN（具有多达250k的真实世界的门牌号的图像））上评估。实验表明，与最先进的模型相比，它获得了卓越的性能。

##### URL
[https://arxiv.org/abs/1706.03581](https://arxiv.org/abs/1706.03581)

##### PDF
[https://arxiv.org/pdf/1706.03581](https://arxiv.org/pdf/1706.03581)

