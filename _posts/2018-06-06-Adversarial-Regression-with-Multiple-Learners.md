---
layout: post
title: "Adversarial Regression with Multiple Learners"
date: 2018-06-06 15:44:53
categories: arXiv_AI
tags: arXiv_AI Adversarial Prediction
author: Liang Tong, Sixie Yu, Scott Alfeld, Yevgeniy Vorobeychik
mathjax: true
---

* content
{:toc}

##### Abstract
Despite the considerable success enjoyed by machine learning techniques in practice, numerous studies demonstrated that many approaches are vulnerable to attacks. An important class of such attacks involves adversaries changing features at test time to cause incorrect predictions. Previous investigations of this problem pit a single learner against an adversary. However, in many situations an adversary's decision is aimed at a collection of learners, rather than specifically targeted at each independently. We study the problem of adversarial linear regression with multiple learners. We approximate the resulting game by exhibiting an upper bound on learner loss functions, and show that the resulting game has a unique symmetric equilibrium. We present an algorithm for computing this equilibrium, and show through extensive experiments that equilibrium models are significantly more robust than conventional regularized linear regression.

##### Abstract (translated by Google)
尽管机器学习技术在实践中取得了相当大的成功，但许多研究表明，许多方法容易受到攻击。这类攻击的一个重要类别是攻击者在测试时间改变功能，导致不正确的预测。以前对这个问题的调查让一个学习者反对一个对手。然而，在许多情况下，对手的决定是针对学习者的集合，而不是针对每个人单独进行。我们研究了多个学习者的敌对线性回归问题。我们通过展示学习者损失函数的上限来近似得到的游戏，并且表明由此产生的游戏具有唯一的对称均衡。我们提出了一种计算这种均衡的算法，并通过大量实验证明，均衡模型比传统的正则化线性回归显着更强健。

##### URL
[http://arxiv.org/abs/1806.02256](http://arxiv.org/abs/1806.02256)

##### PDF
[http://arxiv.org/pdf/1806.02256](http://arxiv.org/pdf/1806.02256)

