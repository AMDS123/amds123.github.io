---
layout: post
title: "Dynamic Temporal Alignment of Speech to Lips"
date: 2018-08-19 19:58:05
categories: arXiv_CV
tags: arXiv_CV Quantitative
author: Tavi Halperin, Ariel Ephrat, Shmuel Peleg
mathjax: true
---

* content
{:toc}

##### Abstract
Many speech segments in movies are re-recorded in a studio during postproduction, to compensate for poor sound quality as recorded on location. Manual alignment of the newly-recorded speech with the original lip movements is a tedious task. We present an audio-to-video alignment method for automating speech to lips alignment, stretching and compressing the audio signal to match the lip movements. This alignment is based on deep audio-visual features, mapping the lips video and the speech signal to a shared representation. Using this shared representation we compute the lip-sync error between every short speech period and every video frame, followed by the determination of the optimal corresponding frame for each short sound period over the entire video clip. We demonstrate successful alignment both quantitatively, using a human perception-inspired metric, as well as qualitatively. The strongest advantage of our audio-to-video approach is in cases where the original voice in unclear, and where a constant shift of the sound can not give a perfect alignment. In these cases state-of-the-art methods will fail.

##### Abstract (translated by Google)
电影中的许多语音片段在后期制作期间被重新录制在录音室中，以补偿在位置上录制的差的声音质量。将新录制的语音与原始唇部动作手动对齐是一项繁琐的工作。我们提出了一种音频到视频对齐方法，用于自动化语音到嘴唇对齐，拉伸和压缩音频信号以匹配唇部运动。这种对齐基于深度视听特征，将嘴唇视频和语音信号映射到共享表示。使用这种共享表示，我们计算每个短语音周期和每个视频帧之间的唇形同步误差，然后确定整个视频片段上每个短声音周期的最佳对应帧。我们使用人类感知启发度量以及定性证明了数量上的成功对齐。我们的音频到视频方法的最大优势在于原始声音不清晰，声音不断变换无法完美对齐的情况。在这些情况下，最先进的方法将失败。

##### URL
[http://arxiv.org/abs/1808.06250](http://arxiv.org/abs/1808.06250)

##### PDF
[http://arxiv.org/pdf/1808.06250](http://arxiv.org/pdf/1808.06250)

