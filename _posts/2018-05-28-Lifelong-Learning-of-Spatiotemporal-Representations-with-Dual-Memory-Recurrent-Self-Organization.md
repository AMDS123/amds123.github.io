---
layout: post
title: "Lifelong Learning of Spatiotemporal Representations with Dual-Memory Recurrent Self-Organization"
date: 2018-05-28 15:08:19
categories: arXiv_AI
tags: arXiv_AI Sparse Knowledge GAN Recognition
author: German I. Parisi, Jun Tani, Cornelius Weber, Stefan Wermter
mathjax: true
---

* content
{:toc}

##### Abstract
Humans excel at continually acquiring and fine-tuning knowledge over sustained time spans. This ability, typically referred to as lifelong learning, is crucial for artificial agents interacting in real-world, dynamic environments where i) the number of tasks to be learned is not pre-defined, ii) training samples become progressively available over time, and iii) annotated samples may be very sparse. In this paper, we propose a dual-memory self-organizing system that learns spatiotemporal representations from videos. The architecture draws inspiration from the interplay of the hippocampal and neocortical systems in the mammalian brain argued to mediate the complementary tasks of quickly integrating specific experiences, i.e., episodic memory (EM), and slowly learning generalities from episodic events, i.e., semantic memory (SM). The complementary memories are modeled as recurrent self-organizing neural networks: The EM quickly adapts to incoming novel sensory observations via competitive Hebbian Learning, whereas the SM progressively learns compact representations by using task-relevant signals to regulate intrinsic levels of neurogenesis and neuroplasticity. For the consolidation of knowledge, trajectories of neural reactivations are periodically replayed to both networks. We analyze and evaluate the performance of our approach with the CORe50 benchmark dataset for continuous object recognition from videos. We show that the proposed approach significantly outperforms current (supervised) methods of lifelong learning in three different incremental learning scenarios, and that due to the unsupervised nature of neural network self-organization, our approach can be used in scenarios where sample annotations are sparse.

##### Abstract (translated by Google)
人类在持续时间跨度上擅长不断获取和微调知识。这种能力，通常称为终身学习，对于在真实世界中动态环境中进行交互的人工智能体至关重要，其中i）要学习的任务数量未预先定义，ii）随着时间的推移，训练样本逐渐可用，以及iii）带注释的样本可能非常稀疏。在本文中，我们提出了一个双存储器自组织系统，学习视频的时空表示。该体系结构从哺乳动物大脑中海马与新皮层系统的相互作用中获得灵感，该理论认为调解快速整合特定体验（即情节记忆（EM））和从情景事件（即情景记忆（语义记忆） SM）。互补记忆被建模为循环自组织神经网络：EM通过竞争性Hebbian学习快速适应传入的新颖感官观察，而SM通过使用任务相关信号来调节内在神经发生水平和神经可塑性，从而逐步学习紧凑表示。为了巩固知识，神经重新激活的轨迹定期重播到两个网络。我们使用CORe50基准数据集来分析和评估我们方法的性能，以便从视频中持续识别对象。我们表明，提出的方法显着优于三种不同增量学习场景下的终身学习的当前（监督）方法，并且由于神经网络自组织的无监督性质，我们的方法可用于样本注释稀少的场景。

##### URL
[http://arxiv.org/abs/1805.10966](http://arxiv.org/abs/1805.10966)

##### PDF
[http://arxiv.org/pdf/1805.10966](http://arxiv.org/pdf/1805.10966)

