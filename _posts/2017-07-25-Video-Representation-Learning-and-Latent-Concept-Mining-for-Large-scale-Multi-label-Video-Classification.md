---
layout: post
title: "Video Representation Learning and Latent Concept Mining for Large-scale Multi-label Video Classification"
date: 2017-07-25 07:50:26
categories: arXiv_CV
tags: arXiv_CV Video_Caption Represenation_Learning Video_Classification RNN Classification
author: Po-Yao Huang, Ye Yuan, Zhenzhong Lan, Lu Jiang, Alexander G. Hauptmann
mathjax: true
---

* content
{:toc}

##### Abstract
We report on CMU Informedia Lab's system used in Google's YouTube 8 Million Video Understanding Challenge. In this multi-label video classification task, our pipeline achieved 84.675% and 84.662% GAP on our evaluation split and the official test set. We attribute the good performance to three components: 1) Refined video representation learning with residual links and hypercolumns 2) Latent concept mining which captures interactions among concepts. 3) Learning with temporal segments and weighted multi-model ensemble. We conduct experiments to validate and analyze the contribution of our models. We also share some unsuccessful trials leveraging conventional approaches such as recurrent neural networks for video representation learning for this large-scale video dataset. All the codes to reproduce our results are publicly available at this https URL

##### Abstract (translated by Google)
我们报告了CMU Informedia实验室在Google的YouTube 8百万视频理解挑战中使用的系统。在这个多标签的视频分类任务中，我们的流水线在我们的评估分割和官方测试集中获得了84.675％和84.662％的GAP。我们把这个好的表现归结为三个组成部分：1）用残差链接和超列进行精确的视频表示学习2）捕获概念间相互作用的潜在概念挖掘。 3）学习时间段和加权多模式集合。我们进行实验来验证和分析模型的贡献。我们还分享了一些不成功的试验，利用传统的方法，例如用于视频表示学习的递归神经网络用于这个大规模的视频数据集。所有的代码重现我们的结果是公开在这个https网址

##### URL
[https://arxiv.org/abs/1707.01408](https://arxiv.org/abs/1707.01408)

##### PDF
[https://arxiv.org/pdf/1707.01408](https://arxiv.org/pdf/1707.01408)

