---
layout: post
title: "OpenSalicon: An Open Source Implementation of the Salicon Saliency Model"
date: 2016-06-01 04:28:10
categories: arXiv_CV
tags: arXiv_CV Salient Attention Prediction
author: Christopher Thomas
mathjax: true
---

* content
{:toc}

##### Abstract
In this technical report, we present our publicly downloadable implementation of the SALICON saliency model. At the time of this writing, SALICON is one of the top performing saliency models on the MIT 300 fixation prediction dataset which evaluates how well an algorithm is able to predict where humans would look in a given image. Recently, numerous models have achieved state-of-the-art performance on this benchmark, but none of the top 5 performing models (including SALICON) are available for download. To address this issue, we have created a publicly downloadable implementation of the SALICON model. It is our hope that our model will engender further research in visual attention modeling by providing a baseline for comparison of other algorithms and a platform for extending this implementation. The model we provide supports both training and testing, enabling researchers to quickly fine-tune the model on their own dataset. We also provide a pre-trained model and code for those users who only need to generate saliency maps for images without training their own model.

##### Abstract (translated by Google)
在这份技术报告中，我们展示了我们公开下载的SALICON显着性模型的实现。在写这篇文章的时候，SALICON是MIT 300固定预测数据集中表现最出色的显着模型之一，它评估算法能够预测人类在给定图像中的外观。最近，众多型号在这个基准测试中取得了最先进的性能，但前五名的性能模型（包括SALICON）都没有下载。为了解决这个问题，我们创建了一个可公开下载的SALICON模型的实现。我们希望，我们的模型将通过提供一个比较其他算法的基线和一个扩展这个实现的平台，在视觉注意力模型上产生进一步的研究。我们提供的模型支持训练和测试，使研究人员能够在自己的数据集上快速微调模型。我们还为那些只需要为图像生成显着性地图的用户提供预先训练的模型和代码，而不需要培训他们自己的模型。

##### URL
[https://arxiv.org/abs/1606.00110](https://arxiv.org/abs/1606.00110)

##### PDF
[https://arxiv.org/pdf/1606.00110](https://arxiv.org/pdf/1606.00110)

