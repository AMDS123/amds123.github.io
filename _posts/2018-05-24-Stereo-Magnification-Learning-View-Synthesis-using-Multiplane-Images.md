---
layout: post
title: "Stereo Magnification: Learning View Synthesis using Multiplane Images"
date: 2018-05-24 17:58:02
categories: arXiv_CV
tags: arXiv_CV Attention
author: Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe, Noah Snavely
mathjax: true
---

* content
{:toc}

##### Abstract
The view synthesis problem--generating novel views of a scene from known imagery--has garnered recent attention due in part to compelling applications in virtual and augmented reality. In this paper, we explore an intriguing scenario for view synthesis: extrapolating views from imagery captured by narrow-baseline stereo cameras, including VR cameras and now-widespread dual-lens camera phones. We call this problem stereo magnification, and propose a learning framework that leverages a new layered representation that we call multiplane images (MPIs). Our method also uses a massive new data source for learning view extrapolation: online videos on YouTube. Using data mined from such videos, we train a deep network that predicts an MPI from an input stereo image pair. This inferred MPI can then be used to synthesize a range of novel views of the scene, including views that extrapolate significantly beyond the input baseline. We show that our method compares favorably with several recent view synthesis methods, and demonstrate applications in magnifying narrow-baseline stereo images.

##### Abstract (translated by Google)
视图合成问题 - 从已知图像中生成一个场景的新视图 - 最近引起了关注，部分原因是由于虚拟和增强现实中的引人注目的应用程序。在本白皮书中，我们探索了一个有趣的视点合成场景：从窄基线立体相机（包括VR相机和现在广泛使用的双镜头相机手机）拍摄的图像中推断视图的视图。我们将这个问题称为立体放大，并提出了一个学习框架，它利用了我们称之为多平面图像（MPI）的新分层表示。我们的方法还使用大量新数据源来学习视图推测：YouTube上的在线视频。使用从这些视频中挖掘出的数据，我们训练了一个深度网络，从输入的立体图像对预测MPI。这个推断的MPI可以用来合成一系列新的场景视图，包括显着超出输入基线的视图。我们展示了我们的方法与最近的几种视图合成方法相比毫不逊色，并展示了放大窄基线立体图像的应用。

##### URL
[http://arxiv.org/abs/1805.09817](http://arxiv.org/abs/1805.09817)

##### PDF
[http://arxiv.org/pdf/1805.09817](http://arxiv.org/pdf/1805.09817)

