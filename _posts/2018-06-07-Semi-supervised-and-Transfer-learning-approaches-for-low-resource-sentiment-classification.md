---
layout: post
title: "Semi-supervised and Transfer learning approaches for low resource sentiment classification"
date: 2018-06-07 18:59:26
categories: arXiv_CL
tags: arXiv_CL Regularization Sentiment Sentiment_Classification Transfer_Learning Classification
author: Rahul Gupta, Saurabh Sahu, Carol Espy-Wilson, Shrikanth Narayanan
mathjax: true
---

* content
{:toc}

##### Abstract
Sentiment classification involves quantifying the affective reaction of a human to a document, media item or an event. Although researchers have investigated several methods to reliably infer sentiment from lexical, speech and body language cues, training a model with a small set of labeled datasets is still a challenge. For instance, in expanding sentiment analysis to new languages and cultures, it may not always be possible to obtain comprehensive labeled datasets. In this paper, we investigate the application of semi-supervised and transfer learning methods to improve performances on low resource sentiment classification tasks. We experiment with extracting dense feature representations, pre-training and manifold regularization in enhancing the performance of sentiment classification systems. Our goal is a coherent implementation of these methods and we evaluate the gains achieved by these methods in matched setting involving training and testing on a single corpus setting as well as two cross corpora settings. In both the cases, our experiments demonstrate that the proposed methods can significantly enhance the model performance against a purely supervised approach, particularly in cases involving a handful of training data.

##### Abstract (translated by Google)
情感分类涉及量化人对文档，媒体项目或事件的情感反应。虽然研究人员已经研究了几种方法来可靠地从词汇，语音和肢体语言线索中推断情感，但使用一小组标记数据集来训练模型仍然是一个挑战。例如，在将情感分析扩展到新的语言和文化中时，获得全面标记的数据集可能并不总是可能的。在本文中，我们研究了半监督和转移学习方法在提高低资源情感分类任务性能方面的应用。我们尝试提取密集的特征表示，预训练和流形正则化来提高情感分类系统的性能。我们的目标是对这些方法进行连贯实施，并且我们评估这些方法在单个语料库环境和两个跨语料环境中进行培训和测试的匹配环境中所取得的成果。在这两种情况下，我们的实验都表明，所提出的方法可以显着提高模型性能，而不是纯监督方法，特别是在涉及少量训练数据的情况下。

##### URL
[http://arxiv.org/abs/1806.02863](http://arxiv.org/abs/1806.02863)

##### PDF
[http://arxiv.org/pdf/1806.02863](http://arxiv.org/pdf/1806.02863)

