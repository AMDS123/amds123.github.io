---
layout: post
title: "Inverse Reinforcement Learning via Nonparametric Spatio-Temporal Subgoal Modeling"
date: 2018-03-01 15:31:28
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Prediction
author: Adrian &#x160;o&#x161;i&#x107;, Elmar Rueckert, Jan Peters, Abdelhak M. Zoubir, Heinz Koeppl
mathjax: true
---

* content
{:toc}

##### Abstract
Recent advances in the field of inverse reinforcement learning (IRL) have yielded sophisticated frameworks which relax the original modeling assumption that the behavior of an observed agent reflects only a single intention. Instead, the demonstration data is typically divided into parts, to account for the fact that different trajectories may correspond to different intentions, e.g., because they were generated by different domain experts. In this work, we go one step further: using the intuitive concept of subgoals, we build upon the premise that even a single trajectory can be explained more efficiently locally within a certain context than globally, enabling a more compact representation of the observed behavior. Based on this assumption, we build an implicit intentional model of the agent's goals to forecast its behavior in unobserved situations. The result is an integrated Bayesian prediction framework which provides smooth policy estimates that are consistent with the expert's plan and significantly outperform existing IRL solutions. Most notably, our framework naturally handles situations where the intentions of the agent change with time and classical IRL algorithms fail. In addition, due to its probabilistic nature, the model can be straightforwardly applied in an active learning setting to guide the demonstration process of the expert.

##### Abstract (translated by Google)
反强化学习（IRL）领域的最新进展产生了复杂的框架，放松了原始建模假设，即观察到的代理行为仅反映单一意图。相反，演示数据通常被分成若干部分，以说明不同的轨迹可能对应于不同的意图的事实，例如，因为它们是由不同的领域专家产生的。在这项工作中，我们更进一步：使用直观的子目标概念，我们构建的前提是，即使在某个特定环境下，甚至可以更有效地解释单个弹道，而不是全局，从而可以更加紧凑地表示观察到的行为。基于这个假设，我们建立了一个代理人目标的隐含的有意模型，以预测它在未观察到的情况下的行为。其结果是一个综合贝叶斯预测框架，提供与专家计划一致的平滑政策估计，并且明显优于现有的IRL解决方案。最值得注意的是，我们的框架自然处理代理人的意图随着时间而改变并且经典的IRL算法失败的情况。此外，由于其概率性质，该模型可以直接应用于主动学习环境中，以指导专家的演示过程。

##### URL
[http://arxiv.org/abs/1803.00444](http://arxiv.org/abs/1803.00444)

##### PDF
[http://arxiv.org/pdf/1803.00444](http://arxiv.org/pdf/1803.00444)

