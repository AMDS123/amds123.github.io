---
layout: post
title: "Holarchic Structures for Decentralized Deep Learning - A Performance Analysis"
date: 2018-09-17 21:51:57
categories: arXiv_AI
tags: arXiv_AI Regularization GAN Optimization Deep_Learning
author: Evangelos Pournaras, Srivatsan Yadhunathan, Ada Diaconescu
mathjax: true
---

* content
{:toc}

##### Abstract
Structure plays a key role in learning performance. In centralized computational systems, hyperparameter optimization and regularization techniques such as dropout are computational means to enhance learning performance by adjusting the deep hierarchical structure. However, in decentralized deep learning by the Internet of Things, the structure is an actual network of autonomous interconnected devices such as smart phones that interact via complex network protocols. Self-adaptation of the learning structure is a challenge. Uncertainties such as network latency, node and link failures or even bottlenecks by limited processing capacity and energy availability can signif- icantly downgrade learning performance. Network self-organization and self-management is complex, while it requires additional computational and network resources that hinder the feasibility of decentralized deep learning. In contrast, this paper introduces a self-adaptive learning approach based on holarchic learning structures for exploring, mitigating and boosting learning performance in distributed environments with uncertainties. A large-scale performance analysis with 864000 experiments fed with synthetic and real-world data from smart grid and smart city pilot projects confirm the cost-effectiveness of holarchic structures for decentralized deep learning.

##### Abstract (translated by Google)
结构在学习表现中起着关键作用。在集中式计算系统中，超参数优化和诸如丢失的正则化技术是通过调整深层次结构来增强学习性能的计算手段。然而，在物联网的分散式深度学习中，该结构是诸如智能电话之类的自主互连设备的实际网络，其通过复杂的网络协议进行交互。学习结构的自我适应是一项挑战。诸如网络延迟，节点和链路故障或甚至由于有限的处理能力和能源可用性造成的瓶颈等不确定因素可能会显着降低学习成绩。网络自组织和自我管理是复杂的，而它需要额外的计算和网络资源，这阻碍了分散式深度学习的可行性。相比之下，本文介绍了一种基于holarchic学习结构的自适应学习方法，用于在具有不确定性的分布式环境中探索，减轻和提高学习性能。利用来自智能电网和智能城市试点项目的综合和实际数据进行的864000次实验的大规模性能分析证实了用于分散式深度学习的结构的成本效益。

##### URL
[http://arxiv.org/abs/1805.02686](http://arxiv.org/abs/1805.02686)

##### PDF
[http://arxiv.org/pdf/1805.02686](http://arxiv.org/pdf/1805.02686)

