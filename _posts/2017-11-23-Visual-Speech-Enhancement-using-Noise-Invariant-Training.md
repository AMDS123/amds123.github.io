---
layout: post
title: "Visual Speech Enhancement using Noise-Invariant Training"
date: 2017-11-23 17:51:46
categories: arXiv_CV
tags: arXiv_CV
author: Aviv Gabbay, Asaph Shamir, Shmuel Peleg
mathjax: true
---

* content
{:toc}

##### Abstract
Visual speech enhancement is used on videos shot in noisy environments to enhance the voice of a visible speaker and to reduce background noise. While most existing methods use audio-only inputs, we propose an audio-visual neural network model for this purpose. The visible mouth movements are used to separate the speaker's voice from the background sounds. Instead of training our speech enhancement model on a wide range of possible noise types, we train the model on videos where other speech samples of the target speaker are used as background noise. A model trained using this paradigm generalizes well to various noise types, while also substantially reducing training time. The proposed model outperforms prior audio visual methods on two public lipreading datasets. It is also the first to be demonstrated on a general dataset not designed for lipreading. Our dataset was composed of weekly addresses of Barack Obama.

##### Abstract (translated by Google)
在嘈杂环境中拍摄的视频中使用可视语音增强功能来增强可见扬声器的声音并减少背景噪音。虽然大多数现有的方法使用纯音频输入，但我们为此提出了一个视听神经网络模型。可见的嘴部动作被用来将讲话者的声音与背景声音分开。我们不是在广泛的可能噪声类型上训练语音增强模型，而是使用目标说话人的其他语音样本作为背景噪声的视频训练模型。使用这种范例训练的模型很好地适用于各种噪音类型，同时也大大减少了训练时间。所提出的模型在两个公开的唇读数据集上优于先前的视听方法。它也是第一个在没有设计用于唇读的通用数据集上进行演示的。我们的数据集由奥巴马每周的地址组成。

##### URL
[https://arxiv.org/abs/1711.08789](https://arxiv.org/abs/1711.08789)

##### PDF
[https://arxiv.org/pdf/1711.08789](https://arxiv.org/pdf/1711.08789)

