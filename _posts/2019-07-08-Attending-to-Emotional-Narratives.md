---
layout: post
title: "Attending to Emotional Narratives"
date: 2019-07-08 03:50:43
categories: arXiv_CL
tags: arXiv_CL Attention Prediction Recognition
author: Zhengxuan Wu, Xiyu Zhang, Tan Zhi-Xuan, Jamil Zaki, Desmond C. Ong
mathjax: true
---

* content
{:toc}

##### Abstract
Attention mechanisms in deep neural networks have achieved excellent performance on sequence-prediction tasks. Here, we show that these recently-proposed attention-based mechanisms---in particular, the Transformer with its parallelizable self-attention layers, and the Memory Fusion Network with attention across modalities and time---also generalize well to multimodal time-series emotion recognition. Using a recently-introduced dataset of emotional autobiographical narratives, we adapt and apply these two attention mechanisms to predict emotional valence over time. Our models perform extremely well, in some cases reaching a performance comparable with human raters. We end with a discussion of the implications of attention mechanisms to affective computing.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.04197](http://arxiv.org/abs/1907.04197)

##### PDF
[http://arxiv.org/pdf/1907.04197](http://arxiv.org/pdf/1907.04197)

