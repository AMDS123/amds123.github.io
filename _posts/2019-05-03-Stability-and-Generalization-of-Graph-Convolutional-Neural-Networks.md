---
layout: post
title: "Stability and Generalization of Graph Convolutional Neural Networks"
date: 2019-05-03 02:04:51
categories: arXiv_AI
tags: arXiv_AI Knowledge CNN
author: Saurabh Verma, Zhi-Li Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Inspired by convolutional neural networks on 1D and 2D data, graph convolutional neural networks (GCNNs) have been developed for various learning tasks on graph data, and have shown superior performance on real-world datasets. Despite their success, there is a dearth of theoretical explorations of GCNN models such as their generalization properties. In this paper, we take a first step towards developing a deeper theoretical understanding of GCNN models by analyzing the stability of single-layer GCNN models and deriving their generalization guarantees in a semi-supervised graph learning setting. In particular, we show that the algorithmic stability of a GCNN model depends upon the largest absolute eigenvalue of its graph convolution filter. Moreover, to ensure the uniform stability needed to provide strong generalization guarantees, the largest absolute eigenvalue must be independent of the graph size. Our results shed new insights on the design of new &amp; improved graph convolution filters with guaranteed algorithmic stability. We evaluate the generalization gap and stability on various real-world graph datasets and show that the empirical results indeed support our theoretical findings. To the best of our knowledge, we are the first to study stability bounds on graph learning in a semi-supervised setting and derive generalization bounds for GCNN models.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.01004](http://arxiv.org/abs/1905.01004)

##### PDF
[http://arxiv.org/pdf/1905.01004](http://arxiv.org/pdf/1905.01004)

