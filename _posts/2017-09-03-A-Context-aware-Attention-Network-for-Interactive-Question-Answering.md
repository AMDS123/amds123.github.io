---
layout: post
title: "A Context-aware Attention Network for Interactive Question Answering"
date: 2017-09-03 21:41:07
categories: arXiv_CL
tags: arXiv_CL QA Attention Quantitative
author: Huayu Li, Martin Renqiang Min, Yong Ge, Asim Kadav
mathjax: true
---

* content
{:toc}

##### Abstract
Neural network based sequence-to-sequence models in an encoder-decoder framework have been successfully applied to solve Question Answering (QA) problems, predicting answers from statements and questions. However, almost all previous models have failed to consider detailed context information and unknown states under which systems do not have enough information to answer given questions. These scenarios with incomplete or ambiguous information are very common in the setting of Interactive Question Answering (IQA). To address this challenge, we develop a novel model, employing context-dependent word-level attention for more accurate statement representations and question-guided sentence-level attention for better context modeling. We also generate unique IQA datasets to test our model, which will be made publicly available. Employing these attention mechanisms, our model accurately understands when it can output an answer or when it requires generating a supplementary question for additional input depending on different contexts. When available, user's feedback is encoded and directly applied to update sentence-level attention to infer an answer. Extensive experiments on QA and IQA datasets quantitatively demonstrate the effectiveness of our model with significant improvement over state-of-the-art conventional QA models.

##### Abstract (translated by Google)
编码器 - 解码器框架中的基于神经网络的序列 - 序列模型已经成功地应用于解决问题答案（QA）问题，预测来自陈述和问题的答案。然而，几乎所有以前的模型都没有考虑详细的上下文信息和未知的状态，在这些状态下系统没有足够的信息来回答给定的问题。在交互式问答（IQA）的设置中，这些信息不完整或模糊的情景是非常普遍的。为了应对这一挑战，我们开发了一种新颖的模型，采用上下文相关的单词级关注，以获得更准确的语句表示和问题引导的句子级关注，从而实现更好的上下文建模。我们还生成独特的IQA数据集来测试我们的模型，并将公开发布。使用这些注意机制，我们的模型能够准确地理解何时可以输出答案，或者何时需要根据不同的上下文为附加输入生成补充问题。当可用时，用户的反馈被编码并直接用于更新句子级别的注意力以推断答案。 QA和IQA数据集的大量实验在数量上证明了我们模型的有效性，与先进的传统QA模型相比有显着的改进。

##### URL
[https://arxiv.org/abs/1612.07411](https://arxiv.org/abs/1612.07411)

##### PDF
[https://arxiv.org/pdf/1612.07411](https://arxiv.org/pdf/1612.07411)

