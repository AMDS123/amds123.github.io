---
layout: post
title: "Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input"
date: 2018-04-04 15:03:08
categories: arXiv_CV
tags: arXiv_CV Object_Detection Segmentation Caption Detection
author: David Harwath, Adrià Recasens, Dídac Surís, Galen Chuang, Antonio Torralba, James Glass
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we explore neural network models that learn to associate segments of spoken audio captions with the semantically relevant portions of natural images that they refer to. We demonstrate that these audio-visual associative localizations emerge from network-internal representations learned as a by-product of training to perform an image-audio retrieval task. Our models operate directly on the image pixels and speech waveform, and do not rely on any conventional supervision in the form of labels, segmentations, or alignments between the modalities during training. We perform analysis using the Places 205 and ADE20k datasets demonstrating that our models implicitly learn semantically-coupled object and word detectors.

##### Abstract (translated by Google)
在本文中，我们探索神经网络模型，学习将语音音频字幕的片段与它们所引用的自然图像的语义相关部分相关联。我们证明了这些视听关联本地化来自网络内部表示，这些表示是作为执行图像 - 音频检索任务的训练的副产品而学习的。我们的模型直接在图像像素和语音波形上运行，并且在训练期间不依赖于标签，分段或模式之间的任何常规监督。我们使用Places 205和ADE20k数据集进行分析，证明我们的模型隐含地学习了语义耦合的对象和单词检测器。

##### URL
[https://arxiv.org/abs/1804.01452](https://arxiv.org/abs/1804.01452)

##### PDF
[https://arxiv.org/pdf/1804.01452](https://arxiv.org/pdf/1804.01452)

