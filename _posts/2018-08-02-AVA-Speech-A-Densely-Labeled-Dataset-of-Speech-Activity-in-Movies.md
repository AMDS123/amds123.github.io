---
layout: post
title: "AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies"
date: 2018-08-02 00:13:11
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition Detection Recognition
author: Sourish Chaudhuri, Joseph Roth, Daniel P. W. Ellis, Andrew Gallagher, Liat Kaver, Radhika Marvin, Caroline Pantofaru, Nathan Reale, Loretta Guarino Reid, Kevin Wilson, Zhonghua Xi
mathjax: true
---

* content
{:toc}

##### Abstract
Speech activity detection (or endpointing) is an important processing step for applications such as speech recognition, language identification and speaker diarization. Both audio- and vision-based approaches have been used for this task in various settings, often tailored toward end applications. However, much of the prior work reports results in synthetic settings, on task-specific datasets, or on datasets that are not openly available. This makes it difficult to compare approaches and understand their strengths and weaknesses. In this paper, we describe a new dataset which we will release publicly containing densely labeled speech activity in YouTube videos, with the goal of creating a shared, available dataset for this task. The labels in the dataset annotate three different speech activity conditions: clean speech, speech co-occurring with music, and speech co-occurring with noise, which enable analysis of model performance in more challenging conditions based on the presence of overlapping noise. We report benchmark performance numbers on AVA-Speech using off-the-shelf, state-of-the-art audio and vision models that serve as a baseline to facilitate future research.

##### Abstract (translated by Google)
语音活动检测（或终点）是语音识别，语言识别和说话者日记等应用的重要处理步骤。基于音频和视觉的方法已经在各种环境中用于此任务，通常针对最终应用进行定制。但是，大多数先前的工作报告会导致合成设置，特定于任务的数据集或不公开可用的数据集。这使得比较方法和理解它们的优点和缺点变得困难。在本文中，我们将描述一个新的数据集，我们将在YouTube视频中公开发布包含密集标记的语音活动，目标是为此任务创建共享的可用数据集。数据集中的标签标注三种不同的语音活动条件：干净的语音，与音乐共存的语音，以及与噪声共存的语音，这使得能够基于重叠噪声的存在在更具挑战性的条件下分析模型性能。我们使用现成的，最先进的音频和视觉模型报告AVA-Speech的基准性能数据，这些模型可作为促进未来研究的基准。

##### URL
[http://arxiv.org/abs/1808.00606](http://arxiv.org/abs/1808.00606)

##### PDF
[http://arxiv.org/pdf/1808.00606](http://arxiv.org/pdf/1808.00606)

