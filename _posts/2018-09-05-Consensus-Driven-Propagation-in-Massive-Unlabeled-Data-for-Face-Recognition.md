---
layout: post
title: "Consensus-Driven Propagation in Massive Unlabeled Data for Face Recognition"
date: 2018-09-05 09:41:16
categories: arXiv_CV
tags: arXiv_CV Face Relation Recognition Face_Recognition
author: Xiaohang Zhan, Ziwei Liu, Junjie Yan, Dahua Lin, Chen Change Loy
mathjax: true
---

* content
{:toc}

##### Abstract
Face recognition has witnessed great progress in recent years, mainly attributed to the high-capacity model designed and the abundant labeled data collected. However, it becomes more and more prohibitive to scale up the current million-level identity annotations. In this work, we show that unlabeled face data can be as effective as the labeled ones. Here, we consider a setting closely mimicking the real-world scenario, where the unlabeled data are collected from unconstrained environments and their identities are exclusive from the labeled ones. Our main insight is that although the class information is not available, we can still faithfully approximate these semantic relationships by constructing a relational graph in a bottom-up manner. We propose Consensus-Driven Propagation (CDP) to tackle this challenging problem with two modules, the "committee" and the "mediator", which select positive face pairs robustly by carefully aggregating multi-view information. Extensive experiments validate the effectiveness of both modules to discard outliers and mine hard positives. With CDP, we achieve a compelling accuracy of 78.18% on MegaFace identification challenge by using only 9% of the labels, comparing to 61.78% when no unlabeled data are used and 78.52% when all labels are employed.

##### Abstract (translated by Google)
面部识别近年来取得了很大进展，主要归功于设计的高容量模型和丰富的标签数据。然而，扩大当前的百万级身份注释变得越来越禁止。在这项工作中，我们表明未标记的面部数据可以与标记的面部数据一样有效。在这里，我们考虑一个与现实场景密切相关的设置，其中未标记的数据是从不受约束的环境中收集的，并且它们的身份与标记的数据不同。我们的主要观点是，尽管类信息不可用，但我们仍然可以通过以自下而上的方式构建关系图来忠实地近似这些语义关系。我们提出共识驱动传播（CDP）来解决这个具有挑战性的问题，包括两个模块，“委员会”和“调解员”，它们通过仔细聚合多视图信息来强有力地选择正面对。大量实验验证了两个模块的有效性，以丢弃异常值和挖掘硬性积极因素。使用CDP，我们通过仅使用9％的标签来实现MegaFace识别挑战的78.18％的令人信服的准确度，相比之下使用未标记数据时为61.78％，使用所有标签时为78.52％。

##### URL
[http://arxiv.org/abs/1809.01407](http://arxiv.org/abs/1809.01407)

##### PDF
[http://arxiv.org/pdf/1809.01407](http://arxiv.org/pdf/1809.01407)

