---
layout: post
title: "TricorNet: A Hybrid Temporal Convolutional and Recurrent Network for Video Action Segmentation"
date: 2017-05-22 15:55:08
categories: arXiv_CV
tags: arXiv_CV Segmentation Attention CNN RNN
author: Li Ding, Chenliang Xu
mathjax: true
---

* content
{:toc}

##### Abstract
Action segmentation as a milestone towards building automatic systems to understand untrimmed videos has received considerable attention in the recent years. It is typically being modeled as a sequence labeling problem but contains intrinsic and sufficient differences than text parsing or speech processing. In this paper, we introduce a novel hybrid temporal convolutional and recurrent network (TricorNet), which has an encoder-decoder architecture: the encoder consists of a hierarchy of temporal convolutional kernels that capture the local motion changes of different actions; the decoder is a hierarchy of recurrent neural networks that are able to learn and memorize long-term action dependencies after the encoding stage. Our model is simple but extremely effective in terms of video sequence labeling. The experimental results on three public action segmentation datasets have shown that the proposed model achieves superior performance over the state of the art.

##### Abstract (translated by Google)
行动细分作为构建自动系统以理解未修剪视频的里程碑，近年来受到了相当的关注。通常将其建模为序列标签问题，但与文本解析或语音处理相比包含内在和足够的差异。在本文中，我们引入了一种新颖的混合时间卷积和递归网络（TricorNet），它具有编码器 - 解码器架构：编码器包括时间卷积核的层次结构，捕获不同动作的局部运动变化;解码器是循环神经网络的层次结构，能够在编码阶段之后学习和记忆长期的动作依赖性。我们的模型很简单，但在视频序列标签方面非常有效。在三个公共行为分割数据集上的实验结果表明，所提出的模型在现有技术水平上实现了优越的性能。

##### URL
[https://arxiv.org/abs/1705.07818](https://arxiv.org/abs/1705.07818)

##### PDF
[https://arxiv.org/pdf/1705.07818](https://arxiv.org/pdf/1705.07818)

