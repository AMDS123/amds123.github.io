---
layout: post
title: "DNN-HMM based Speaker Adaptive Emotion Recognition using Proposed Epoch and MFCC Features"
date: 2018-06-04 06:58:45
categories: arXiv_AI
tags: arXiv_AI Recognition
author: Md. Shah Fahad, Jainath Yadav, Gyadhar Pradhan, Akshay Deepak
mathjax: true
---

* content
{:toc}

##### Abstract
Speech is produced when time varying vocal tract system is excited with time varying excitation source. Therefore, the information present in a speech such as message, emotion, language, speaker is due to the combined effect of both excitation source and vocal tract system. However, there is very less utilization of excitation source features to recognize emotion. In our earlier work, we have proposed a novel method to extract glottal closure instants (GCIs) known as epochs. In this paper, we have explored epoch features namely instantaneous pitch, phase and strength of epochs for discriminating emotions. We have combined the excitation source features and the well known Male-frequency cepstral coefficient (MFCC) features to develop an emotion recognition system with improved performance. DNN-HMM speaker adaptive models have been developed using MFCC, epoch and combined features. IEMOCAP emotional database has been used to evaluate the models. The average accuracy for emotion recognition system when using MFCC and epoch features separately is 59.25% and 54.52% respectively. The recognition performance improves to 64.2% when MFCC and epoch features are combined.

##### Abstract (translated by Google)
当随时间变化的激励源激励时变声道系统时，会产生语音。因此，信息，消息，情感，语言，说话人等言语中的信息是由于激励源和声道系统的综合作用。然而，利用激励源特征来识别情绪的能力非常低。在我们之前的工作中，我们提出了一种新的方法来提取被称为时代的声门闭合时刻（GCI）。在本文中，我们探索了划时代特征，即瞬时音高，阶段和时代的力量区分情绪。我们结合了激励源特征和众所周知的男性频率倒谱系数（MFCC）特征来开发具有改进性能的情绪识别系统。已经使用MFCC，时代和组合特征开发了DNN-HMM扬声器自适应模型。 IEMOCAP情绪数据库已用于评估模型。当分别使用MFCC和时代特征时情感识别系统的平均准确率分别为59.25％和54.52％。当MFCC和时代特征相结合时，识别性能提高到64.2％。

##### URL
[http://arxiv.org/abs/1806.00984](http://arxiv.org/abs/1806.00984)

##### PDF
[http://arxiv.org/pdf/1806.00984](http://arxiv.org/pdf/1806.00984)

