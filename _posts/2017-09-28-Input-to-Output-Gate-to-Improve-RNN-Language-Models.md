---
layout: post
title: "Input-to-Output Gate to Improve RNN Language Models"
date: 2017-09-28 06:40:39
categories: arXiv_CL
tags: arXiv_CL RNN Language_Model
author: Sho Takase, Jun Suzuki, Masaaki Nagata
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a reinforcing method that refines the output layers of existing Recurrent Neural Network (RNN) language models. We refer to our proposed method as Input-to-Output Gate (IOG). IOG has an extremely simple structure, and thus, can be easily combined with any RNN language models. Our experiments on the Penn Treebank and WikiText-2 datasets demonstrate that IOG consistently boosts the performance of several different types of current topline RNN language models.

##### Abstract (translated by Google)
本文提出了一种改进现有递​​归神经网络（RNN）语言模型输出层的增强方法。我们将我们提出的方法称为输入到输出门（IOG）。 IOG具有非常简单的结构，因此可以很容易地与任何RNN语言模型相结合。我们在Penn Treebank和WikiText-2数据集上进行的实验表明，IOG持续提升了几种不同类型的当前顶级RNN语言模型的性能。

##### URL
[https://arxiv.org/abs/1709.08907](https://arxiv.org/abs/1709.08907)

##### PDF
[https://arxiv.org/pdf/1709.08907](https://arxiv.org/pdf/1709.08907)

