---
layout: post
title: "3-D Hand Pose Estimation from Kinect's Point Cloud Using Appearance Matching"
date: 2016-04-07 15:16:17
categories: arXiv_CV
tags: arXiv_CV Pose_Estimation
author: Pasquale Coscia, Francesco A.N. Palmieri, Francesco Castaldo, Alberto Cavallo
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel appearance-based approach for pose estimation of a human hand using the point clouds provided by the low-cost Microsoft Kinect sensor. Both the free-hand case, in which the hand is isolated from the surrounding environment, and the hand-object case, in which the different types of interactions are classified, have been considered. The hand-object case is clearly the most challenging task having to deal with multiple tracks. The approach proposed here belongs to the class of partial pose estimation where the estimated pose in a frame is used for the initialization of the next one. The pose estimation is obtained by applying a modified version of the Iterative Closest Point (ICP) algorithm to synthetic models to obtain the rigid transformation that aligns each model with respect to the input data. The proposed framework uses a "pure" point cloud as provided by the Kinect sensor without any other information such as RGB values or normal vector components. For this reason, the proposed method can also be applied to data obtained from other types of depth sensor, or RGB-D camera.

##### Abstract (translated by Google)
我们提出了一种新颖的基于外观的方法，使用低成本的微软Kinect传感器提供的点云来进行人手姿态估计。已经考虑了将手与周围环境隔离的手自由的情况以及对不同类型的交互进行分类的手对象情况。手对象的情况显然是处理多轨的最具挑战性的任务。这里提出的方法属于部分姿态估计的类别，其中帧中的估计姿态被用于下一个的初始化。通过将迭代最接近点（ICP）算法的修改版本应用于合成模型来获得姿态估计，以获得使每个模型相对于输入数据对准的刚性变换。所提出的框架使用由Kinect传感器提供的“纯”点云，而没有任何其他信息，例如RGB值或法向矢量分量。为此，所提出的方法也可以应用于从其他类型的深度传感器或RGB-D相机获得的数据。

##### URL
[https://arxiv.org/abs/1604.02032](https://arxiv.org/abs/1604.02032)

##### PDF
[https://arxiv.org/pdf/1604.02032](https://arxiv.org/pdf/1604.02032)

