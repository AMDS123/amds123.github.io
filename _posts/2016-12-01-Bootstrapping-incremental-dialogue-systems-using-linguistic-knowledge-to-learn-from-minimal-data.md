---
layout: post
title: "Bootstrapping incremental dialogue systems: using linguistic knowledge to learn from minimal data"
date: 2016-12-01 16:49:04
categories: arXiv_CL
tags: arXiv_CL Knowledge Reinforcement_Learning
author: Dimitrios Kalatzis, Arash Eshghi, Oliver Lemon
mathjax: true
---

* content
{:toc}

##### Abstract
We present a method for inducing new dialogue systems from very small amounts of unannotated dialogue data, showing how word-level exploration using Reinforcement Learning (RL), combined with an incremental and semantic grammar - Dynamic Syntax (DS) - allows systems to discover, generate, and understand many new dialogue variants. The method avoids the use of expensive and time-consuming dialogue act annotations, and supports more natural (incremental) dialogues than turn-based systems. Here, language generation and dialogue management are treated as a joint decision/optimisation problem, and the MDP model for RL is constructed automatically. With an implemented system, we show that this method enables a wide range of dialogue variations to be automatically captured, even when the system is trained from only a single dialogue. The variants include question-answer pairs, over- and under-answering, self- and other-corrections, clarification interaction, split-utterances, and ellipsis. This generalisation property results from the structural knowledge and constraints present within the DS grammar, and highlights some limitations of recent systems built using machine learning techniques only.

##### Abstract (translated by Google)
我们提出了一种从非常少量的非注释对话数据中引入新的对话系统的方法，展示了如何使用强化学习（RL）结合增量和语义语法 - 动态语法（DS） - 进行单词级别的探索，生成和理解许多新的对话变体。该方法避免使用昂贵且耗时的对话行为注释，并且支持比基于回合的系统更自然（增量）的对话。在这里，语言生成和对话管理被视为一个联合决策/优化问题，而RL的MDP模型是自动构建的。通过一个实现的系统，我们展示了这种方法能够自动捕获大范围的对话变化，即使系统仅通过一次对话进行训练。这些变体包括问答对，过度和不足答案，自我和其他纠正，澄清互动，分裂话语和省略号。这种泛化特性是DS语法中存在的结构知识和约束的结果，并强调了仅使用机器学习技术构建的近期系统的一些局限性。

##### URL
[https://arxiv.org/abs/1612.00347](https://arxiv.org/abs/1612.00347)

##### PDF
[https://arxiv.org/pdf/1612.00347](https://arxiv.org/pdf/1612.00347)

