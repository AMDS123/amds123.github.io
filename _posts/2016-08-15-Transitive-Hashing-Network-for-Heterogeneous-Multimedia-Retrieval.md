---
layout: post
title: "Transitive Hashing Network for Heterogeneous Multimedia Retrieval"
date: 2016-08-15 15:36:41
categories: arXiv_CV
tags: arXiv_CV QA Relation
author: Zhangjie Cao, Mingsheng Long, Qiang Yang
mathjax: true
---

* content
{:toc}

##### Abstract
Hashing has been widely applied to large-scale multimedia retrieval due to the storage and retrieval efficiency. Cross-modal hashing enables efficient retrieval from database of one modality in response to a query of another modality. Existing work on cross-modal hashing assumes heterogeneous relationship across modalities for hash function learning. In this paper, we relax the strong assumption by only requiring such heterogeneous relationship in an auxiliary dataset different from the query/database domain. We craft a hybrid deep architecture to simultaneously learn the cross-modal correlation from the auxiliary dataset, and align the dataset distributions between the auxiliary dataset and the query/database domain, which generates transitive hash codes for heterogeneous multimedia retrieval. Extensive experiments exhibit that the proposed approach yields state of the art multimedia retrieval performance on public datasets, i.e. NUS-WIDE, ImageNet-YahooQA.

##### Abstract (translated by Google)
由于存储和检索效率的原因，散列技术被广泛应用于大规模的多媒体检索。通过跨模态散列，可以从一种模式的数据库中有效地检索其他模式的查询。现有的跨模态散列工作假设散列函数学习模式之间存在异构关系。在本文中，我们放松强烈的假设，只需要在不同于查询/数据库域的辅助数据集中使用这种异构关系。我们制作了一个混合的深层架构，可以同时从辅助数据集中学习跨模态关联，并将辅助数据集和查询/数据库领域之间的数据集分布对齐，从而生成用于异构多​​媒体检索的可传递哈希代码。广泛的实验表明，所提出的方法在公共数据集（即NUS-WIDE，ImageNet-YahooQA）上获得了最先进的多媒体检索性能。

##### URL
[https://arxiv.org/abs/1608.04307](https://arxiv.org/abs/1608.04307)

##### PDF
[https://arxiv.org/pdf/1608.04307](https://arxiv.org/pdf/1608.04307)

