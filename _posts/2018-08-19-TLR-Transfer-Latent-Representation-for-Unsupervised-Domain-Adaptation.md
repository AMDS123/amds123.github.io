---
layout: post
title: "TLR: Transfer Latent Representation for Unsupervised Domain Adaptation"
date: 2018-08-19 13:14:01
categories: arXiv_AI
tags: arXiv_AI Prediction
author: Pan Xiao, Bo Du, Jia Wu, Lefei Zhang, Ruimin Hu, Xuelong Li
mathjax: true
---

* content
{:toc}

##### Abstract
Domain adaptation refers to the process of learning prediction models in a target domain by making use of data from a source domain. Many classic methods solve the domain adaptation problem by establishing a common latent space, which may cause the loss of many important properties across both domains. In this manuscript, we develop a novel method, transfer latent representation (TLR), to learn a better latent space. Specifically, we design an objective function based on a simple linear autoencoder to derive the latent representations of both domains. The encoder in the autoencoder aims to project the data of both domains into a robust latent space. Besides, the decoder imposes an additional constraint to reconstruct the original data, which can preserve the common properties of both domains and reduce the noise that causes domain shift. Experiments on cross-domain tasks demonstrate the advantages of TLR over competing methods.

##### Abstract (translated by Google)
域适应是指通过利用来自源域的数据来学习目标域中的预测模型的过程。许多经典方法通过建立共同的潜在空间来解决域适应问题，这可能导致两个域中许多重要属性的丢失。在这篇手稿中，我们开发了一种新方法，转移潜在表示（TLR），以学习更好的潜在空间。具体而言，我们基于简单的线性自动编码器设计目标函数，以导出两个域的潜在表示。自动编码器中的编码器旨在将两个域的数据投影到强大的潜在空间中。此外，解码器施加额外的约束来重建原始数据，这可以保留两个域的共同属性并减少引起域移位的噪声。跨域任务的实验证明了TLR优于竞争方法的优势。

##### URL
[http://arxiv.org/abs/1808.06206](http://arxiv.org/abs/1808.06206)

##### PDF
[http://arxiv.org/pdf/1808.06206](http://arxiv.org/pdf/1808.06206)

