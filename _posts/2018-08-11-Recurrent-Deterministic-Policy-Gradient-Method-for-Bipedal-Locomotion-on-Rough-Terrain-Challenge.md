---
layout: post
title: "Recurrent Deterministic Policy Gradient Method for Bipedal Locomotion on Rough Terrain Challenge"
date: 2018-08-11 09:55:39
categories: arXiv_AI
tags: arXiv_AI Deep_Learning
author: Doo Re Song, Chuanyu Yang, Christopher McGreavy, Zhibin Li
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a deep learning framework that is capable of solving partially observable locomotion tasks based on our novel interpretation of Recurrent Deterministic Policy Gradient (RDPG). We study on bias of sampled error measure and its variance induced by the partial observability of environment and subtrajectory sampling, respectively. Three major improvements are introduced in our RDPG based learning framework: tail-step bootstrap of interpolated temporal difference, initialisation of hidden state using past trajectory scanning, and injection of external experiences learned by other agents. The proposed learning framework was implemented to solve the Bipedal-Walker challenge in OpenAI's gym simulation environment where only partial state information is available. Our simulation study shows that the autonomous behaviors generated by the RDPG agent are highly adaptive to a variety of obstacles and enables the agent to effectively traverse rugged terrains for long distance with higher success rate than leading contenders.

##### Abstract (translated by Google)
本文提出了一个深度学习框架，能够根据我们对Recurrent Deterministic Policy Gradient（RDPG）的新颖解释来解决部分可观察的运动任务。我们分别研究了采样误差测量的偏差及其由环境和子轨道采样的部分可观测性引起的方差。在我们的基于RDPG的学习框架中引入了三个主要的改进：插值时间差的尾步骤引导，使用过去轨迹扫描的隐藏状态的初始化，以及注入其他代理学习的外部经验。提出的学习框架是为了解决OpenAI健身房模拟环境中的Bipedal-Walker挑战，其中只有部分状态信息可用。我们的模拟研究表明，RDPG代理产生的自主行为高度适应各种障碍，使得代理能够有效地穿越崎岖的地形进行长距离比成功率更高的成功率。

##### URL
[http://arxiv.org/abs/1710.02896](http://arxiv.org/abs/1710.02896)

##### PDF
[http://arxiv.org/pdf/1710.02896](http://arxiv.org/pdf/1710.02896)

