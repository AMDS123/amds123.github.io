---
layout: post
title: "Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning"
date: 2018-03-14 13:33:06
categories: arXiv_CV
tags: arXiv_CV VQA
author: David Mascharka, Philip Tran, Ryan Soklaski, Arjun Majumdar
mathjax: true
---

* content
{:toc}

##### Abstract
Visual question answering requires high-order reasoning about an image, which is a fundamental capability needed by machine systems to follow complex directives. Recently, modular networks have been shown to be an effective framework for performing visual reasoning tasks. While modular networks were initially designed with a degree of model transparency, their performance on complex visual reasoning benchmarks was lacking. Current state-of-the-art approaches do not provide an effective mechanism for understanding the reasoning process. In this paper, we close the performance gap between interpretable models and state-of-the-art visual reasoning methods. We propose a set of visual-reasoning primitives which, when composed, manifest as a model capable of performing complex reasoning tasks in an explicitly-interpretable manner. The fidelity and interpretability of the primitives' outputs enable an unparalleled ability to diagnose the strengths and weaknesses of the resulting model. Critically, we show that these primitives are highly performant, achieving state-of-the-art accuracy of 99.1% on the CLEVR dataset. We also show that our model is able to effectively learn generalized representations when provided a small amount of data containing novel object attributes. Using the CoGenT generalization task, we show more than a 20 percentage point improvement over the current state of the art.

##### Abstract (translated by Google)
视觉问题回答需要图像的高阶推理，这是机器系统遵循复杂指令所需的基本能力。最近，模块化网络已被证明是执行视觉推理任务的有效框架。虽然模块化网络最初设计时具有一定程度的模型透明度，但它们在复杂的视觉推理基准上的表现还很欠缺。当前最先进的方法不能提供理解推理过程的有效机制。在本文中，我们关闭了可解释模型和最先进的视觉推理方法之间的性能差距。我们提出了一组视觉推理原语，它们在组成时表现为能够以明确可解释的方式执行复杂推理任务的模型。基元输出的保真度和可解释性使得无与伦比的能力可以诊断所得模型的优点和缺点。重要的是，我们显示这些原始数据是高性能的，在CLEVR数据集上达到了99.1％的最高精确度。我们还表明，当提供包含新颖对象属性的少量数据时，我们的模型能够有效地学习广义表示。使用CoGenT概括任务，我们显示出比现有技术水平提高了20个百分点。

##### URL
[https://arxiv.org/abs/1803.05268](https://arxiv.org/abs/1803.05268)

##### PDF
[https://arxiv.org/pdf/1803.05268](https://arxiv.org/pdf/1803.05268)

