---
layout: post
title: "Lifted Marginal MAP Inference"
date: 2018-07-02 10:45:21
categories: arXiv_AI
tags: arXiv_AI Inference Relation
author: Vishal Sharma, Noman Ahmed Sheikh, Happy Mittal, Vibhav Gogate, Parag Singla
mathjax: true
---

* content
{:toc}

##### Abstract
Lifted inference reduces the complexity of inference in relational probabilistic models by identifying groups of constants (or atoms) which behave symmetric to each other. A number of techniques have been proposed in the literature for lifting marginal as well MAP inference. We present the first application of lifting rules for marginal-MAP (MMAP), an important inference problem in models having latent (random) variables. Our main contribution is two fold: (1) we define a new equivalence class of (logical) variables, called Single Occurrence for MAX (SOM), and show that solution lies at extreme with respect to the SOM variables, i.e., predicate groundings differing only in the instantiation of the SOM variables take the same truth value (2) we define a sub-class {\em SOM-R} (SOM Reduce) and exploit properties of extreme assignments to show that MMAP inference can be performed by reducing the domain of SOM-R variables to a single constant.We refer to our lifting technique as the {\em SOM-R} rule for lifted MMAP. Combined with existing rules such as decomposer and binomial, this results in a powerful framework for lifted MMAP. Experiments on three benchmark domains show significant gains in both time and memory compared to ground inference as well as lifted approaches not using SOM-R.

##### Abstract (translated by Google)
通过识别行为彼此对称的常数（或原子）组，提升推断降低了关系概率模型中推理的复杂性。文献中已经提出了许多用于提升边缘和MAP推理的技术。我们提出了边际MAP（MMAP）提升规则的第一个应用，这是一个具有潜在（随机）变量的模型中的重要推理问题。我们的主要贡献有两个：（1）我们定义了一个新的（逻辑）变量等价类，称为MAX的单一事件（SOM），并表明解决方案相对于SOM变量处于极端，即谓词基础不同只有在SOM变量的实例化中才采用相同的真值（2）我们定义一个子类{\ em SOM-R}（SOM Reduce）并利用极端赋值的属性来表明MMAP推理可以通过减少SOM-R变量的域到单个常量。我们将提升技术称为提升MMAP的{\ em SOM-R}规则。与分解器和二项式等现有规则相结合，可以为解除MMAP提供强大的框架。与地面推理相比，三个基准域上的实验显示时间和内存都有显着增益，以及不使用SOM-R的提升方法。

##### URL
[http://arxiv.org/abs/1807.00589](http://arxiv.org/abs/1807.00589)

##### PDF
[http://arxiv.org/pdf/1807.00589](http://arxiv.org/pdf/1807.00589)

