---
layout: post
title: "Patch Correspondences for Interpreting Pixel-level CNNs"
date: 2018-09-04 01:35:17
categories: arXiv_CV
tags: arXiv_CV Segmentation Embedding CNN Semantic_Segmentation Quantitative
author: Victor Fragoso, Chunhui Liu, Aayush Bansal, Deva Ramanan
mathjax: true
---

* content
{:toc}

##### Abstract
We present compositional nearest neighbors (CompNN), a simple approach to visually interpreting distributed representations learned by a convolutional neural network (CNN) for pixel-level tasks (e.g., image synthesis and segmentation). It does so by reconstructing both a CNN's input and output image by copy-pasting corresponding patches from the training set with similar feature embeddings. To do so efficiently, it makes of a patch-match-based algorithm that exploits the fact that the patch representations learned by a CNN for pixel level tasks vary smoothly. Finally, we show that CompNN can be used to establish semantic correspondences between two images and control properties of the output image by modifying the images contained in the training set. We present qualitative and quantitative experiments for semantic segmentation and image-to-image translation that demonstrate that CompNN is a good tool for interpreting the embeddings learned by pixel-level CNNs.

##### Abstract (translated by Google)
我们提出了组成最近邻居（CompNN），这是一种用于在视觉上解释由卷积神经网络（CNN）学习的用于像素级任务（例如，图像合成和分割）的分布式表示的简单方法。它通过从具有类似特征嵌入的训练集中复制粘贴相应的补丁来重建CNN的输入和输出图像。为了有效地做到这一点，它构成了基于补丁匹配的算法，该算法利用了CNN针对像素级任务所学习的补丁表示平滑变化的事实。最后，我们展示了CompNN可用于建立两个图像之间的语义对应关系，并通过修改训练集中包含的图像来控制输出图像的属性。我们提供了语义分割和图像到图像转换的定性和定量实验，证明CompNN是解释像素级CNN学习的嵌入的好工具。

##### URL
[http://arxiv.org/abs/1711.10683](http://arxiv.org/abs/1711.10683)

##### PDF
[http://arxiv.org/pdf/1711.10683](http://arxiv.org/pdf/1711.10683)

