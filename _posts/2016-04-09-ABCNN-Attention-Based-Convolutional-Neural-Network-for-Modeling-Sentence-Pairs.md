---
layout: post
title: "ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs"
date: 2016-04-09 11:59:39
categories: arXiv_CL
tags: arXiv_CL Attention CNN
author: Wenpeng Yin, Hinrich Schütze, Bing Xiang, Bowen Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
How to model a pair of sentences is a critical issue in many NLP tasks such as answer selection (AS), paraphrase identification (PI) and textual entailment (TE). Most prior work (i) deals with one individual task by fine-tuning a specific system; (ii) models each sentence's representation separately, rarely considering the impact of the other sentence; or (iii) relies fully on manually designed, task-specific linguistic features. This work presents a general Attention Based Convolutional Neural Network (ABCNN) for modeling a pair of sentences. We make three contributions. (i) ABCNN can be applied to a wide variety of tasks that require modeling of sentence pairs. (ii) We propose three attention schemes that integrate mutual influence between sentences into CNN; thus, the representation of each sentence takes into consideration its counterpart. These interdependent sentence pair representations are more powerful than isolated sentence representations. (iii) ABCNN achieves state-of-the-art performance on AS, PI and TE tasks.

##### Abstract (translated by Google)
如何建模一对句子是许多NLP任务（如答案选择（AS），释义识别（PI）和文本引用（TE））中的关键问题。大多数以前的工作（i）通过微调一个特定的系统来处理一个单独的任务; （ii）分别模拟每个句子的表述，很少考虑另一个句子的影响;或者（iii）完全依靠手动设计的，特定于任务的语言特征。这项工作提出了一个基于注意的卷积神经网络（ABCNN）建模一对句子。我们做三个贡献。 （i）ABCNN可以应用于需要模拟句对的各种任务。 （ii）我们提出三个注意方案，将句子之间的相互影响整合到CNN中;因此，每个句子的表示考虑到了其对应。这些相互依存的句对表示比单独的句子表示更有效。 （iii）ABCNN在AS，PI和TE任务上实现了最先进的性能。

##### URL
[https://arxiv.org/abs/1512.05193](https://arxiv.org/abs/1512.05193)

##### PDF
[https://arxiv.org/pdf/1512.05193](https://arxiv.org/pdf/1512.05193)

