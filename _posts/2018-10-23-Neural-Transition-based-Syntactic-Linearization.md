---
layout: post
title: "Neural Transition-based Syntactic Linearization"
date: 2018-10-23 00:47:24
categories: arXiv_CL
tags: arXiv_CL RNN Language_Model
author: Linfeng Song, Yue Zhang, Daniel Gildea
mathjax: true
---

* content
{:toc}

##### Abstract
The task of linearization is to find a grammatical order given a set of words. Traditional models use statistical methods. Syntactic linearization systems, which generate a sentence along with its syntactic tree, have shown state-of-the-art performance. Recent work shows that a multi-layer LSTM language model outperforms competitive statistical syntactic linearization systems without using syntax. In this paper, we study neural syntactic linearization, building a transition-based syntactic linearizer leveraging a feed-forward neural network, observing significantly better results compared to LSTM language models on this task.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.09609](http://arxiv.org/abs/1810.09609)

##### PDF
[http://arxiv.org/pdf/1810.09609](http://arxiv.org/pdf/1810.09609)

