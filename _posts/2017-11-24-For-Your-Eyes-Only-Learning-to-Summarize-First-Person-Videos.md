---
layout: post
title: "For Your Eyes Only: Learning to Summarize First-Person Videos"
date: 2017-11-24 10:42:42
categories: arXiv_CV
tags: arXiv_CV Summarization Embedding RNN Deep_Learning Quantitative
author: Hsuan-I Ho, Wei-Chen Chiu, Yu-Chiang Frank Wang
mathjax: true
---

* content
{:toc}

##### Abstract
With the increasing amount of video data, it is desirable to highlight or summarize the videos of interest for viewing, search, or storage purposes. However, existing summarization approaches are typically trained from third-person videos, which cannot generalize to highlight the first-person ones. By advancing deep learning techniques, we propose a unique network architecture for transferring spatiotemporal information across video domains, which jointly solves metric-learning based feature embedding and keyframe selection via Bidirectional Long Short-Term Memory (BiLSTM). A practical semi-supervised learning setting is considered, i.e., only fully annotated third-person videos, unlabeled first-person videos, and a small amount of annotated first-person ones are required to train our proposed model. Qualitative and quantitative evaluations are performed in our experiments, which confirm that our model performs favorably against baseline and state-of-the-art approaches on first-person video summarization.

##### Abstract (translated by Google)
随着视频数据量的增加，为了观看，搜索或存储的目的，需要突出或总结感兴趣的视频。然而，现有的摘要方法通常是由第三方视频进行培训的，不能一概而论地强调第一人称视频。通过推进深度学习技术，我们提出了一种独特的网络体系结构，用于跨视频域传递时空信息，通过双向长时间短期记忆（BiLSTM）共同解决基于度量学习的特征嵌入和关键帧选择问题。考虑实际的半监督学习设置，即仅需要完全注释的第三人视频，未标记的第一人称视频以及少量注释的第一人视频来训练我们提出的模型。定性和定量评估是在我们的实验中进行的，这证实了我们的模型在第一人称视频摘要的基线和最先进的方法方面表现出色。

##### URL
[https://arxiv.org/abs/1711.08922](https://arxiv.org/abs/1711.08922)

##### PDF
[https://arxiv.org/pdf/1711.08922](https://arxiv.org/pdf/1711.08922)

