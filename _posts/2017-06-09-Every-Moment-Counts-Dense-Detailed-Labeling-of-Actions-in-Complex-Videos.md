---
layout: post
title: "Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos"
date: 2017-06-09 10:42:09
categories: arXiv_CV
tags: arXiv_CV Action_Recognition RNN Prediction Relation Recognition
author: Serena Yeung, Olga Russakovsky, Ning Jin, Mykhaylo Andriluka, Greg Mori, Li Fei-Fei
mathjax: true
---

* content
{:toc}

##### Abstract
Every moment counts in action recognition. A comprehensive understanding of human activity in video requires labeling every frame according to the actions occurring, placing multiple labels densely over a video sequence. To study this problem we extend the existing THUMOS dataset and introduce MultiTHUMOS, a new dataset of dense labels over unconstrained internet videos. Modeling multiple, dense labels benefits from temporal relations within and across classes. We define a novel variant of long short-term memory (LSTM) deep networks for modeling these temporal relations via multiple input and output connections. We show that this model improves action labeling accuracy and further enables deeper understanding tasks ranging from structured retrieval to action prediction.

##### Abstract (translated by Google)
每一刻都在行动认同中算计。要全面了解视频中的人类活动，需要根据所发生的行为标记每一帧，将多个标签密集地放置在视频序列上。为了研究这个问题，我们扩展了现有的THUMOS数据集，并引入了MultiTHUMOS，这是一个在无约束的互联网视频上的密集标签的新数据集。建模多个密集标签可以从类内部和之间的时间关系中受益。我们定义了一个长期短期记忆（LSTM）深层网络的新型变体，用于通过多个输入和输出连接对这些时间关系进行建模。我们表明，这个模型提高了行为标签的准确性，并进一步加深了从结构化检索到行动预测的理解任务。

##### URL
[https://arxiv.org/abs/1507.05738](https://arxiv.org/abs/1507.05738)

##### PDF
[https://arxiv.org/pdf/1507.05738](https://arxiv.org/pdf/1507.05738)

