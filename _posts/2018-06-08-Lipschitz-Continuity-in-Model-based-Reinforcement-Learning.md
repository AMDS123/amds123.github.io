---
layout: post
title: "Lipschitz Continuity in Model-based Reinforcement Learning"
date: 2018-06-08 04:02:26
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Prediction
author: Kavosh Asadi, Dipendra Misra, Michael L. Littman
mathjax: true
---

* content
{:toc}

##### Abstract
We examine the impact of learning Lipschitz continuous models in the context of model-based reinforcement learning. We provide a novel bound on multi-step prediction error of Lipschitz models where we quantify the error using the Wasserstein metric. We go on to prove an error bound for the value-function estimate arising from Lipschitz models and show that the estimated value function is itself Lipschitz. We conclude with empirical results that show the benefits of controlling the Lipschitz constant of neural-network models.

##### Abstract (translated by Google)
我们研究在基于模型的强化学习环境中学习Lipschitz连续模型的影响。我们提供了一个关于Lipschitz模型的多步预测误差的新界，我们使用Wasserstein度量来量化误差。我们继续证明由Lipschitz模型引起的值函数估计的误差界限，并证明估计值函数本身是Lipschitz。我们用实验结果得出结论，显示控制神经网络模型的Lipschitz常数的好处。

##### URL
[http://arxiv.org/abs/1804.07193](http://arxiv.org/abs/1804.07193)

##### PDF
[http://arxiv.org/pdf/1804.07193](http://arxiv.org/pdf/1804.07193)

