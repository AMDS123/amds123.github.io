---
layout: post
title: "Mammalian Value Systems"
date: 2017-12-31 18:47:10
categories: arXiv_AI
tags: arXiv_AI GAN
author: Gopal P. Sarma, Nick J. Hay
mathjax: true
---

* content
{:toc}

##### Abstract
Characterizing human values is a topic deeply interwoven with the sciences, humanities, art, and many other human endeavors. In recent years, a number of thinkers have argued that accelerating trends in computer science, cognitive science, and related disciplines foreshadow the creation of intelligent machines which meet and ultimately surpass the cognitive abilities of human beings, thereby entangling an understanding of human values with future technological development. Contemporary research accomplishments suggest sophisticated AI systems becoming widespread and responsible for managing many aspects of the modern world, from preemptively planning users' travel schedules and logistics, to fully autonomous vehicles, to domestic robots assisting in daily living. The extrapolation of these trends has been most forcefully described in the context of a hypothetical "intelligence explosion," in which the capabilities of an intelligent software agent would rapidly increase due to the presence of feedback loops unavailable to biological organisms. The possibility of superintelligent agents, or simply the widespread deployment of sophisticated, autonomous AI systems, highlights an important theoretical problem: the need to separate the cognitive and rational capacities of an agent from the fundamental goal structure, or value system, which constrains and guides the agent's actions. The "value alignment problem" is to specify a goal structure for autonomous agents compatible with human values. In this brief article, we suggest that recent ideas from affective neuroscience and related disciplines aimed at characterizing neurological and behavioral universals in the mammalian kingdom provide important conceptual foundations relevant to describing human values. We argue that the notion of "mammalian value systems" points to a potential avenue for fundamental research in AI safety and AI ethics.

##### Abstract (translated by Google)
描绘人的价值是与科学，人文，艺术和许多其他人类事业深层交织的话题。近年来，一些思想家认为计算机科学，认知科学和相关学科的发展趋势预示着智能机器的诞生，这种智能机器能够满足并最终超越人类的认知能力，从而让人们对未来的人类价值观产生纠缠技术发展。当代的研究成果表明，复杂的人工智能系统变得普遍，并负责管理现代世界的许多方面，从预先规划用户的旅行时间表和物流，到完全自主的车辆，到协助日常生活的家庭机器人。在假设的“智能爆炸”的背景下，对这些趋势的推断进行了最有力的描述，其中智能软件代理的能力将由于存在对生物有机体不可用的反馈回路而迅速增加。超级智能代理的可能性，或简单地广泛部署复杂的，自主的AI系统，突出了一个重要的理论问题：需要将代理人的认知和理性能力从基本目标结构或价值体系中分离出来，这约束和指导代理人的行为。 “价值对准问题”是为与人类价值相容的自治智能体指定一个目标结构。在这篇简短的文章中，我们建议来自情感神经科学和相关学科的最近观点旨在描述哺乳动物王国中的神经和行为普遍性，为描述人类价值观提供了重要的概念基础。我们认为，“哺乳动物价值体系”的概念指出了人工智能安全和人工智能伦理的基础研究的潜在途径。

##### URL
[http://arxiv.org/abs/1607.08289](http://arxiv.org/abs/1607.08289)

##### PDF
[http://arxiv.org/pdf/1607.08289](http://arxiv.org/pdf/1607.08289)

