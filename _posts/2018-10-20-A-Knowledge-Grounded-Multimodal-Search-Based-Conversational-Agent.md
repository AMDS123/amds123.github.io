---
layout: post
title: "A Knowledge-Grounded Multimodal Search-Based Conversational Agent"
date: 2018-10-20 16:58:54
categories: arXiv_AI
tags: arXiv_AI Knowledge
author: Shubham Agarwal, Ondrej Dusek, Ioannis Konstas, Verena Rieser
mathjax: true
---

* content
{:toc}

##### Abstract
Multimodal search-based dialogue is a challenging new task: It extends visually grounded question answering systems into multi-turn conversations with access to an external database. We address this new challenge by learning a neural response generation system from the recently released Multimodal Dialogue (MMD) dataset (Saha et al., 2017). We introduce a knowledge-grounded multimodal conversational model where an encoded knowledge base (KB) representation is appended to the decoder input. Our model substantially outperforms strong baselines in terms of text-based similarity measures (over 9 BLEU points, 3 of which are solely due to the use of additional information from the KB.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.11954](http://arxiv.org/abs/1810.11954)

##### PDF
[http://arxiv.org/pdf/1810.11954](http://arxiv.org/pdf/1810.11954)

