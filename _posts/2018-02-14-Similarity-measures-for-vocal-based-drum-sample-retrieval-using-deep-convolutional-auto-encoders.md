---
layout: post
title: "Similarity measures for vocal-based drum sample retrieval using deep convolutional auto-encoders"
date: 2018-02-14 16:08:09
categories: arXiv_SD
tags: arXiv_SD CNN Deep_Learning
author: Adib Mehrabi, Keunwoo Choi, Simon Dixon, Mark Sandler
mathjax: true
---

* content
{:toc}

##### Abstract
The expressive nature of the voice provides a powerful medium for communicating sonic ideas, motivating recent research on methods for query by vocalisation. Meanwhile, deep learning methods have demonstrated state-of-the-art results for matching vocal imitations to imitated sounds, yet little is known about how well learned features represent the perceptual similarity between vocalisations and queried sounds. In this paper, we address this question using similarity ratings between vocal imitations and imitated drum sounds. We use a linear mixed effect regression model to show how features learned by convolutional auto-encoders (CAEs) perform as predictors for perceptual similarity between sounds. Our experiments show that CAEs outperform three baseline feature sets (spectrogram-based representations, MFCCs, and temporal features) at predicting the subjective similarity ratings. We also investigate how the size and shape of the encoded layer effects the predictive power of the learned features. The results show that preservation of temporal information is more important than spectral resolution for this application.

##### Abstract (translated by Google)
声音的表达性为传播声音思想提供了强大的媒介，激发了最近对声音查询方法的研究。同时，深度学习方法已经证明了将声音模仿与模仿声音相匹配的最新结果，但关于如何很好地学习特征代表声音与查询声音之间的感知相似性知之甚少。在本文中，我们使用声乐模仿和模仿鼓声之间的相似性评级来解决这个问题。我们使用线性混合效应回归模型来显示卷积自动编码器（CAE）学习的特征如何作为声音之间感知相似性的预测因子。我们的实验表明，在预测主观相似性评级时，CAE优于三个基线特征集（频谱图表示，MFCC和时间特征）。我们还调查编码层的大小和形状如何影响学习功能的预测能力。结果表明，对于这种应用，时间信息的保存比光谱分辨率更重要。

##### URL
[http://arxiv.org/abs/1802.05178](http://arxiv.org/abs/1802.05178)

##### PDF
[http://arxiv.org/pdf/1802.05178](http://arxiv.org/pdf/1802.05178)

