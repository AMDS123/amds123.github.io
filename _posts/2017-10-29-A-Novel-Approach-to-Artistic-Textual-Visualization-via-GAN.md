---
layout: post
title: "A Novel Approach to Artistic Textual Visualization via GAN"
date: 2017-10-29 02:39:16
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Yichi Ma, Muhan Ma
mathjax: true
---

* content
{:toc}

##### Abstract
While the visualization of statistical data tends to a mature technology, the visualization of textual data is still in its infancy, especially for the artistic text. Due to the fact that visualization of artistic text is valuable and attractive in both art and information science, we attempt to realize this tentative idea in this article. We propose the Generative Adversarial Network based Artistic Textual Visualization (GAN-ATV) which can create paintings after analyzing the semantic content of existing poems. Our GAN-ATV consists of two main sections: natural language analysis section and visual information synthesis section. In natural language analysis section, we use Bag-of-Word (BoW) feature descriptors and a two-layer network to mine and analyze the high-level semantic information from poems. In visual information synthesis section, we design a cross-modal semantic understanding module and integrate it with Generative Adversarial Network (GAN) to create paintings, whose content are corresponding to the original poems. Moreover, in order to train our GAN-ATV and verify its performance, we establish a cross-modal artistic dataset named "Cross-Art". In the Cross-Art dataset, there are six topics and each topic has their corresponding paintings and poems. The experimental results on Cross-Art dataset are shown in this article.

##### Abstract (translated by Google)
虽然统计数据的可视化趋向于成熟的技术，但文本数据的可视化仍处于起步阶段，特别是对于艺术文本。由于艺术文本的可视化在艺术和信息科学中都是有价值和有吸引力的，所以我们试图在这篇文章中实现这个设想。我们提出基于生成对抗网络的艺术文本可视化（GAN-ATV），通过分析现有诗歌的语义内容，可以创作绘画。我们的GAN-ATV由两个主要部分组成：自然语言分析部分和视觉信息合成部分。在自然语言分析部分，我们使用Bag-of-Word（BoW）特征描述符和一个双层网络来挖掘和分析来自诗歌的高级语义信息。在视觉信息综合部分，我们设计了一个跨语义的语义理解模块，并将其与生成对手网络（GAN）相结合来创建绘画，其内容与原始诗歌相对应。此外，为了培训我们的GAN-ATV并验证其性能，我们建立了一个名为“Cross-Art”的跨模态艺术数据集。在交叉艺术数据集中，共有六个主题，每个主题都有相应的绘画和诗歌。本文展示了跨艺术数据集的实验结果。

##### URL
[https://arxiv.org/abs/1710.10553](https://arxiv.org/abs/1710.10553)

##### PDF
[https://arxiv.org/pdf/1710.10553](https://arxiv.org/pdf/1710.10553)

