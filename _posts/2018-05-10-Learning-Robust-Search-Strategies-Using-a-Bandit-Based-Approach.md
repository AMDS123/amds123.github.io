---
layout: post
title: "Learning Robust Search Strategies Using a Bandit-Based Approach"
date: 2018-05-10 08:30:37
categories: arXiv_AI
tags: arXiv_AI
author: Wei Xia, Roland H. C. Yap
mathjax: true
---

* content
{:toc}

##### Abstract
Effective solving of constraint problems often requires choosing good or specific search heuristics. However, choosing or designing a good search heuristic is non-trivial and is often a manual process. In this paper, rather than manually choosing/designing search heuristics, we propose the use of bandit-based learning techniques to automatically select search heuristics. Our approach is online where the solver learns and selects from a set of heuristics during search. The goal is to obtain automatic search heuristics which give robust performance. Preliminary experiments show that our adaptive technique is more robust than the original search heuristics. It can also outperform the original heuristics.

##### Abstract (translated by Google)
有效解决约束问题通常需要选择好的或特定的搜索启发式算法。但是，选择或设计一个好的搜索启发式算法并不重要，通常是一个手动过程。在本文中，我们建议使用基于土匪的学习技术来自动选择搜索启发式，而不是手动选择/设计搜索启发式。我们的方法是在线，求解者在搜索过程中学习并从一组启发式中进行选择。目标是获得自动搜索启发式，从而提供强大的性能。初步实验表明，我们的自适应技术比原始搜索启发式更强大。它也可以超越最初的启发式。

##### URL
[http://arxiv.org/abs/1805.03876](http://arxiv.org/abs/1805.03876)

##### PDF
[http://arxiv.org/pdf/1805.03876](http://arxiv.org/pdf/1805.03876)

