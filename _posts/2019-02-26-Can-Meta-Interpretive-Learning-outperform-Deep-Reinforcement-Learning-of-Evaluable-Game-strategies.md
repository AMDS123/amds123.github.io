---
layout: post
title: "Can Meta-Interpretive Learning outperform Deep Reinforcement Learning of Evaluable Game strategies?"
date: 2019-02-26 10:04:19
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Transfer_Learning
author: C&#xe9;line Hocquette, Stephen H. Muggleton
mathjax: true
---

* content
{:toc}

##### Abstract
World-class human players have been outperformed in a number of complex two person games (Go, Chess, Checkers) by Deep Reinforcement Learning systems. However, owing to tractability considerations minimax regret of a learning system cannot be evaluated in such games. In this paper we consider simple games (Noughts-and-Crosses and Hexapawn) in which minimax regret can be efficiently evaluated. We use these games to compare Cumulative Minimax Regret for variants of both standard and deep reinforcement learning against two variants of a new Meta-Interpretive Learning system called MIGO. In our experiments all tested variants of both normal and deep reinforcement learning have worse performance (higher cumulative minimax regret) than both variants of MIGO on Noughts-and-Crosses and Hexapawn. Additionally, MIGO's learned rules are relatively easy to comprehend, and are demonstrated to achieve significant transfer learning in both directions between Noughts-and-Crosses and Hexapawn.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.09835](http://arxiv.org/abs/1902.09835)

##### PDF
[http://arxiv.org/pdf/1902.09835](http://arxiv.org/pdf/1902.09835)

