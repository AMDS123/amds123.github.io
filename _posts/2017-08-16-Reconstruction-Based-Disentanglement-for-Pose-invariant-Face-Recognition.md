---
layout: post
title: "Reconstruction-Based Disentanglement for Pose-invariant Face Recognition"
date: 2017-08-16 15:52:01
categories: arXiv_CV
tags: arXiv_CV Face Embedding Recognition Face_Recognition
author: Xi Peng, Xiang Yu, Kihyuk Sohn, Dimitris Metaxas, Manmohan Chandraker
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks (DNNs) trained on large-scale datasets have recently achieved impressive improvements in face recognition. But a persistent challenge remains to develop methods capable of handling large pose variations that are relatively underrepresented in training data. This paper presents a method for learning a feature representation that is invariant to pose, without requiring extensive pose coverage in training data. We first propose to generate non-frontal views from a single frontal face, in order to increase the diversity of training data while preserving accurate facial details that are critical for identity discrimination. Our next contribution is to seek a rich embedding that encodes identity features, as well as non-identity ones such as pose and landmark locations. Finally, we propose a new feature reconstruction metric learning to explicitly disentangle identity and pose, by demanding alignment between the feature reconstructions through various combinations of identity and pose features, which is obtained from two images of the same subject. Experiments on both controlled and in-the-wild face datasets, such as MultiPIE, 300WLP and the profile view database CFP, show that our method consistently outperforms the state-of-the-art, especially on images with large head pose variations. Detail results and resource are referred to this https URL

##### Abstract (translated by Google)
在大规模数据集上训练的深度神经网络（DNN）最近在人脸识别方面取得了显着的进步。但是，持续的挑战仍然是开发能够处理训练数据中代表性相对较低的大姿态变化的方法。本文提出了一种方法来学习一个不变的特征表示，而不需要在训练数据中广泛的姿态覆盖。我们首先提出从单个正面人脸中生成非正面视图，以增加训练数据的多样性，同时保留对身份歧视至关重要的精确面部细节。我们的下一个贡献是寻求一个丰富的嵌入，对身份特征进行编码，以及诸如姿势和地标位置之类的非身份特征。最后，我们提出了一个新的特征重建度量学习，明确地解开身份和姿态，要求通过身份和姿势特征的各种组合的特征重建之间的对齐，这是从同一主题的两个图像获得的。在MultiPIE，300WLP和配置文件视图数据库CFP等受控和野外人脸数据集上的实验表明，我们的方法始终优于现有技术，特别是在头部姿势变化较大的图像上。详细的结果和资源被引用到这个https URL

##### URL
[https://arxiv.org/abs/1702.03041](https://arxiv.org/abs/1702.03041)

##### PDF
[https://arxiv.org/pdf/1702.03041](https://arxiv.org/pdf/1702.03041)

