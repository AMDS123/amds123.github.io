---
layout: post
title: "Deep Learning Driven Visual Path Prediction from a Single Image"
date: 2016-01-27 05:04:31
categories: arXiv_CV
tags: arXiv_CV Tracking Inference Deep_Learning Prediction Quantitative
author: Siyu Huang, Xi Li, Zhongfei Zhang, Zhouzhou He, Fei Wu, Wei Liu, Jinhui Tang, Yueting Zhuang
mathjax: true
---

* content
{:toc}

##### Abstract
Capabilities of inference and prediction are significant components of visual systems. In this paper, we address an important and challenging task of them: visual path prediction. Its goal is to infer the future path for a visual object in a static scene. This task is complicated as it needs high-level semantic understandings of both the scenes and motion patterns underlying video sequences. In practice, cluttered situations have also raised higher demands on the effectiveness and robustness of the considered models. Motivated by these observations, we propose a deep learning framework which simultaneously performs deep feature learning for visual representation in conjunction with spatio-temporal context modeling. After that, we propose a unified path planning scheme to make accurate future path prediction based on the analytic results of the context models. The highly effective visual representation and deep context models ensure that our framework makes a deep semantic understanding of the scene and motion pattern, consequently improving the performance of the visual path prediction task. In order to comprehensively evaluate the model's performance on the visual path prediction task, we construct two large benchmark datasets from the adaptation of video tracking datasets. The qualitative and quantitative experimental results show that our approach outperforms the existing approaches and owns a better generalization capability.

##### Abstract (translated by Google)
推理和预测的能力是视觉系统的重要组成部分。在本文中，我们解决了一个重要和具有挑战性的任务：视觉路径预测。它的目标是在静态场景中推断可视对象的未来路径。这个任务是复杂的，因为它需要视频序列底层的场景和运动模式的高级语义理解。在实践中，混乱的情况也对所考虑的模型的有效性和鲁棒性提出了更高的要求。受到这些观察的启发，我们提出了一个深度学习框架，它与时空上下文建模一起为视觉表示同时进行深度特征学习。之后，我们提出了一个统一的路径规划方案，根据上下文模型的分析结果做出准确的未来路径预测。高效的视觉表示和深层的上下文模型确保了我们的框架对场景和运动模式有了深刻的语义理解，从而提高了视觉路径预测任务的性能。为了全面评估模型在视觉路径预测任务中的性能，本文从视频跟踪数据集的改编中构建了两个大型基准数据集。定性和定量实验结果表明，我们的方法优于现有方法，具有更好的泛化能力。

##### URL
[https://arxiv.org/abs/1601.07265](https://arxiv.org/abs/1601.07265)

##### PDF
[https://arxiv.org/pdf/1601.07265](https://arxiv.org/pdf/1601.07265)

