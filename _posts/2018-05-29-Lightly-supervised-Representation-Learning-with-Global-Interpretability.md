---
layout: post
title: "Lightly-supervised Representation Learning with Global Interpretability"
date: 2018-05-29 15:49:11
categories: arXiv_CL
tags: arXiv_CL Embedding Represenation_Learning Classification
author: Marco A. Valenzuela-Esc&#xe1;rcega, Ajay Nagesh, Mihai Surdeanu
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a lightly-supervised approach for information extraction, in particular named entity classification, which combines the benefits of traditional bootstrapping, i.e., use of limited annotations and interpretability of extraction patterns, with the robust learning approaches proposed in representation learning. Our algorithm iteratively learns custom embeddings for both the multi-word entities to be extracted and the patterns that match them from a few example entities per category. We demonstrate that this representation-based approach outperforms three other state-of-the-art bootstrapping approaches on two datasets: CoNLL-2003 and OntoNotes. Additionally, using these embeddings, our approach outputs a globally-interpretable model consisting of a decision list, by ranking patterns based on their proximity to the average entity embedding in a given class. We show that this interpretable model performs close to our complete bootstrapping model, proving that representation learning can be used to produce interpretable models with small loss in performance.

##### Abstract (translated by Google)
我们提出了一种用于信息提取的轻度监督方法，特别是命名实体分类，它结合了传统引导的好处，即使用有限的注释和提取模式的可解释性，以及表示学习中提出的鲁棒学习方法。我们的算法迭代地学习要提取的多个单词实体的定制嵌入以及从每个类别的几个示例实体匹配它们的模式。我们证明这种基于表示的方法胜过两种数据集上的三种其他最先进的引导方法：CoNLL-2003和OntoNotes。此外，使用这些嵌入，我们的方法输出一个由决策列表组成的全局可解释模型，通过基于它们与给定类别中平均实体嵌入的接近度对模式进行排名。我们表明，这个可解释模型执行接近我们的完整引导模型，证明表示学习可以用于生产性能损失小的可解释模型。

##### URL
[http://arxiv.org/abs/1805.11545](http://arxiv.org/abs/1805.11545)

##### PDF
[http://arxiv.org/pdf/1805.11545](http://arxiv.org/pdf/1805.11545)

