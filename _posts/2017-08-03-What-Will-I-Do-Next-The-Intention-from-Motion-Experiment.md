---
layout: post
title: "What Will I Do Next? The Intention from Motion Experiment"
date: 2017-08-03 07:37:58
categories: arXiv_CV
tags: arXiv_CV Classification Prediction Quantitative
author: Andrea Zunino, Jacopo Cavazza, Atesh Koul, Andrea Cavallo, Cristina Becchio, Vittorio Murino
mathjax: true
---

* content
{:toc}

##### Abstract
In computer vision, video-based approaches have been widely explored for the early classification and the prediction of actions or activities. However, it remains unclear whether this modality (as compared to 3D kinematics) can still be reliable for the prediction of human intentions, defined as the overarching goal embedded in an action sequence. Since the same action can be performed with different intentions, this problem is more challenging but yet affordable as proved by quantitative cognitive studies which exploit the 3D kinematics acquired through motion capture systems. In this paper, we bridge cognitive and computer vision studies, by demonstrating the effectiveness of video-based approaches for the prediction of human intentions. Precisely, we propose Intention from Motion, a new paradigm where, without using any contextual information, we consider instantaneous grasping motor acts involving a bottle in order to forecast why the bottle itself has been reached (to pass it or to place in a box, or to pour or to drink the liquid inside). We process only the grasping onsets casting intention prediction as a classification framework. Leveraging on our multimodal acquisition (3D motion capture data and 2D optical videos), we compare the most commonly used 3D descriptors from cognitive studies with state-of-the-art video-based techniques. Since the two analyses achieve an equivalent performance, we demonstrate that computer vision tools are effective in capturing the kinematics and facing the cognitive problem of human intention prediction.

##### Abstract (translated by Google)
在计算机视觉中，基于视频的方法已经被广泛地探索，用于早期分类和预测行动或活动。然而，这种模式（与三维运动学相比）是否仍然可以用于预测人类意图，这个模式被定义为嵌入动作序列中的总体目标还不清楚。由于可以用不同的意图来执行相同的动作，所以这个问题更具挑战性，但是如定量认知研究证明的那样，该定量认知研究利用通过动作捕捉系统获得的3D运动学。在本文中，我们通过展示基于视频的方法预测人类意图的有效性来弥合认知和计算机视觉研究。准确地说，我们提出了一种新的范式，即在不使用任何背景信息的情况下，我们提出了一种新的范例，即通过即时掌握涉及瓶子的运动行为来预测为什么瓶子已经达到（通过或放在盒子里，或倒入或饮用里面的液体）。我们只把握住铸造意图预测作为一个分类框架。利用我们的多模式采集（3D运动捕捉数据和2D光学视频），我们将最常用的认知研究3D描述符与最先进的基于视频的技术进行比较。由于这两个分析达到相同的性能，我们证明，计算机视觉工具是有效的捕捉运动学和面对人类意图预测的认知问题。

##### URL
[https://arxiv.org/abs/1708.01034](https://arxiv.org/abs/1708.01034)

##### PDF
[https://arxiv.org/pdf/1708.01034](https://arxiv.org/pdf/1708.01034)

