---
layout: post
title: "CrossNets : A New Approach to Complex Learning"
date: 2017-05-21 06:50:49
categories: arXiv_CV
tags: arXiv_CV
author: Chirag Agarwal, Mehdi Sharifzhadeh, Joe Klobusicky, Dan Schonfeld
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel neural network structure called CrossNets, which considers architectures on directed acyclic graphs. This structure builds on previous generalizations of feed forward models, such as ResNets, by allowing for all forward cross connections between layers (both adjacent and non-adjacent). The addition of cross connections among the network increases information flow across the whole network, leading to better training and testing performances. The superior performance of the network is tested against four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN. We conclude with a proof of convergence for Crossnets to a local minimum for error, where weights for connections are chosen through backpropagation with momentum.

##### Abstract (translated by Google)
我们提出了一种新的神经网络结构，称为CrossNets，它考虑了有向无环图的结构。这个结构建立在前馈模型的一般化基础上，比如ResNets，允许层（相邻和不相邻）之间的所有前向交叉连接。网络之间的交叉连接增加了整个网络的信息流，从而导致更好的培训和测试性能。该网络的优越性能是针对四个基准数据集：MNIST，CIFAR-10，CIFAR-100和SVHN进行测试的。我们用一个交叉网络的收敛性证明来得出一个局部最小误差的结论，其中连接的权重通过反向传播和动量来选择。

##### URL
[https://arxiv.org/abs/1705.07404](https://arxiv.org/abs/1705.07404)

##### PDF
[https://arxiv.org/pdf/1705.07404](https://arxiv.org/pdf/1705.07404)

