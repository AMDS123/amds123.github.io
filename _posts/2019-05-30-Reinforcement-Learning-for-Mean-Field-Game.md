---
layout: post
title: "Reinforcement Learning for Mean Field Game"
date: 2019-05-30 23:58:22
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Nilay Tiwari, Arnob Ghosh, Vaneet Aggarwal
mathjax: true
---

* content
{:toc}

##### Abstract
Stochastic games provide a framework for interactions among multi-agents and enable a myriad of applications. In these games, agents decide on actions simultaneously, the state of an agent moves to the next state, and each agent receives a reward. However, finding an equilibrium (if exists) in this game is often difficult when the number of agents become large. This paper focuses on finding a mean-field equilibrium (MFE) in an action coupled stochastic game setting in an episodic framework. It is assumed that the impact of the other agents' can be assumed by the empirical distribution of the mean of the actions. All agents know the action distribution and employ lower-myopic best response dynamics to choose the optimal oblivious strategy. This paper proposes a posterior sampling based approach for reinforcement learning in the mean-field game, where each agent samples a transition probability from the previous transitions. We show that the policy and action distributions converge to the optimal oblivious strategy and the limiting distribution, respectively, which constitute a MFE.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.13357](http://arxiv.org/abs/1905.13357)

##### PDF
[http://arxiv.org/pdf/1905.13357](http://arxiv.org/pdf/1905.13357)

