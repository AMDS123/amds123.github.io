---
layout: post
title: "Towards Neural Phrase-based Machine Translation"
date: 2017-10-28 02:56:01
categories: arXiv_CL
tags: arXiv_CL Segmentation Attention NMT
author: Po-Sen Huang, Chong Wang, Sitao Huang, Dengyong Zhou, Li Deng
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present Neural Phrase-based Machine Translation (NPMT). Our method explicitly models the phrase structures in output sequences using Sleep-WAke Networks (SWAN), a recently proposed segmentation-based sequence modeling method. To mitigate the monotonic alignment requirement of SWAN, we introduce a new layer to perform (soft) local reordering of input sequences. Different from existing neural machine translation (NMT) approaches, NPMT does not use attention-based decoding mechanisms. Instead, it directly outputs phrases in a sequential order. Our experiments show that NPMT achieves superior performances on IWSLT 2014 German-English/English-German and IWSLT 2015 English-Vietnamese machine translation tasks compared with strong NMT baselines. We also observe that our method produces meaningful phrases in output languages.

##### Abstract (translated by Google)
在本文中，我们提出基于神经短语的机器翻译（NPMT）。我们的方法使用最近提出的基于分段的序列建模方法睡眠WAKE网络（SWAN）在输出序列中明确地模拟短语结构。为了减轻SWAN的单调对齐要求，我们引入了一个新层来执行输入序列的（软）局部重新排序。与现有的神经机器翻译（NMT）方法不同，NPMT不使用基于注意力的解码机制。相反，它会按顺序直接输出短语。我们的实验表明，NPMT在IWSLT 2014德语 - 英语/英语 - 德语和IWSLT 2015英语 - 越南语机器翻译任务上，与强大的NMT基线相比，表现出色。我们也观察到我们的方法在输出语言中产生了有意义的短语

##### URL
[https://arxiv.org/abs/1706.05565](https://arxiv.org/abs/1706.05565)

##### PDF
[https://arxiv.org/pdf/1706.05565](https://arxiv.org/pdf/1706.05565)

