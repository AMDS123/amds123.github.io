---
layout: post
title: "Investigating Human + Machine Complementarity for Recidivism Predictions"
date: 2018-08-28 05:28:35
categories: arXiv_AI
tags: arXiv_AI Prediction
author: Sarah Tan, Julius Adebayo, Kori Inkpen, Ece Kamar
mathjax: true
---

* content
{:toc}

##### Abstract
When might human input help (or not) when assessing risk in fairness-related domains? Dressel and Farid asked Mechanical Turk workers to evaluate a subset of individuals in the ProPublica COMPAS data set for risk of recidivism, and concluded that COMPAS predictions were no more accurate or fair than predictions made by humans. We delve deeper into this claim in this paper. We construct a Human Risk Score based on the predictions made by multiple Mechanical Turk workers on the same individual, study the agreement and disagreement between COMPAS and Human Scores on subgroups of individuals, and construct hybrid Human+AI models to predict recidivism. Our key finding is that on this data set, human and COMPAS decision making differed, but not in ways that could be leveraged to significantly improve ground truth prediction. We present the results of our analyses and suggestions for how machine and human input may have complementary strengths to address challenges in the fairness domain.

##### Abstract (translated by Google)
在评估公平相关领域的风险时，人类输入何时可以帮助（或不支持）？ Dressel和Farid要求Mechanical Turk工作人员评估ProPublica COMPAS数据集中的一部分个体的再犯风险，并得出结论，COMPAS预测并不比人类预测更准确或更公平。我们在本文中深入研究了这一主张。我们根据多个机械土耳其人工人对同一个体的预测构建人类风险评分，研究COMPAS与人类亚组之间的协议和分歧，并构建混合人类+ AI模型以预测累犯。我们的主要发现是，在这个数据集上，人类和COMPAS的决策制定不同，但不是可以用来显着改善地面实况预测的方式。我们提出了我们的分析结果，以及机器和人力投入如何具有互补优势以应对公平领域挑战的建议。

##### URL
[http://arxiv.org/abs/1808.09123](http://arxiv.org/abs/1808.09123)

##### PDF
[http://arxiv.org/pdf/1808.09123](http://arxiv.org/pdf/1808.09123)

