---
layout: post
title: "Joint Learning of Sentence Embeddings for Relevance and Entailment"
date: 2016-06-22 22:41:26
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Petr Baudis, Silvestr Stanko, Jan Sedivy
mathjax: true
---

* content
{:toc}

##### Abstract
We consider the problem of Recognizing Textual Entailment within an Information Retrieval context, where we must simultaneously determine the relevancy as well as degree of entailment for individual pieces of evidence to determine a yes/no answer to a binary natural language question. We compare several variants of neural networks for sentence embeddings in a setting of decision-making based on evidence of varying relevance. We propose a basic model to integrate evidence for entailment, show that joint training of the sentence embeddings to model relevance and entailment is feasible even with no explicit per-evidence supervision, and show the importance of evaluating strong baselines. We also demonstrate the benefit of carrying over text comprehension model trained on an unrelated task for our small datasets. Our research is motivated primarily by a new open dataset we introduce, consisting of binary questions and news-based evidence snippets. We also apply the proposed relevance-entailment model on a similar task of ranking multiple-choice test answers, evaluating it on a preliminary dataset of school test questions as well as the standard MCTest dataset, where we improve the neural model state-of-art.

##### Abstract (translated by Google)
我们考虑在信息检索的背景下识别文本的完成的问题，在这里我们必须同时确定相关性和个别证据的包含程度，以确定对二元自然语言问题的是/否的答案。我们比较几个变种的神经网络句子嵌入在决策设置的基础上，不同相关性的证据。我们提出了一个整合证据的基本模型，证明即使没有明确的证据监督，句子嵌入的联合训练也是可行的，并且显示了评估强基线的重要性。我们还展示了在我们的小数据集上进行针对不相关任务训练的文本理解模型的益处。我们的研究主要是由我们介绍的一个新的开放数据集，包括二进制问题和基于新闻的证据片断。我们还将所提议的相关性 - 包含模型应用于对多项选择题测试答案进行排序的类似任务中，对学校测试题的初步数据集以及标准MCTest数据集进行评估，在那里我们改进了神经模型状态。

##### URL
[https://arxiv.org/abs/1605.04655](https://arxiv.org/abs/1605.04655)

##### PDF
[https://arxiv.org/pdf/1605.04655](https://arxiv.org/pdf/1605.04655)

