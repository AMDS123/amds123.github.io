---
layout: post
title: "Attention-based Extraction of Structured Information from Street View Imagery"
date: 2017-08-20 11:34:31
categories: arXiv_CV
tags: arXiv_CV Attention RNN
author: Zbigniew Wojna, Alex Gorban, Dar-Shyang Lee, Kevin Murphy, Qian Yu, Yeqing Li, Julian Ibarz
mathjax: true
---

* content
{:toc}

##### Abstract
We present a neural network model - based on CNNs, RNNs and a novel attention mechanism - which achieves 84.2% accuracy on the challenging French Street Name Signs (FSNS) dataset, significantly outperforming the previous state of the art (Smith'16), which achieved 72.46%. Furthermore, our new method is much simpler and more general than the previous approach. To demonstrate the generality of our model, we show that it also performs well on an even more challenging dataset derived from Google Street View, in which the goal is to extract business names from store fronts. Finally, we study the speed/accuracy tradeoff that results from using CNN feature extractors of different depths. Surprisingly, we find that deeper is not always better (in terms of accuracy, as well as speed). Our resulting model is simple, accurate and fast, allowing it to be used at scale on a variety of challenging real-world text extraction problems.

##### Abstract (translated by Google)
我们提出了一个神经网络模型 - 基于CNNs，RNNs和一种新型的注意机制 - 在富有挑战性的法国街道名称标志（FSNS）数据集上达到了84.2％的准确率，明显优于以前的艺术状态（Smith'16）达到72.46％。而且，我们的新方法比以前的方法简单得多。为了证明我们的模型的一般性，我们证明它在从Google Street View派生的更具挑战性的数据集上表现良好，其中目标是从商店前端提取商业名称。最后，我们研究使用不同深度的CNN特征提取器产生的速度/准确性折衷。令人惊讶的是，我们发现更深层次并不总是更好（在准确性和速度方面）。我们的结果模型简单，准确，快速，可以在各种具有挑战性的真实世界文本提取问题上大规模使用。

##### URL
[https://arxiv.org/abs/1704.03549](https://arxiv.org/abs/1704.03549)

##### PDF
[https://arxiv.org/pdf/1704.03549](https://arxiv.org/pdf/1704.03549)

