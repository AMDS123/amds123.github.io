---
layout: post
title: "Dual Recurrent Attention Units for Visual Question Answering"
date: 2018-02-01 09:35:33
categories: arXiv_AI
tags: arXiv_AI QA Attention Embedding Relation VQA
author: Ahmed Osman, Wojciech Samek
mathjax: true
---

* content
{:toc}

##### Abstract
We propose an architecture for VQA which utilizes recurrent layers to generate visual and textual attention. The memory characteristic of the proposed recurrent attention units offers a rich joint embedding of visual and textual features and enables the model to reason relations between several parts of the image and question. Our single model outperforms the first place winner on the VQA 1.0 dataset, performs within margin to the current state-of-the-art ensemble model. We also experiment with replacing attention mechanisms in other state-of-the-art models with our implementation and show increased accuracy. In both cases, our recurrent attention mechanism improves performance in tasks requiring sequential or relational reasoning on the VQA dataset.

##### Abstract (translated by Google)
我们提出了一个VQA架构，利用复发层产生视觉和文本的关注。所提出的经常性关注单元的记忆特征提供了视觉和文本特征的丰富的联合嵌入，并使该模型能够推理图像的几个部分和问题之间的关系。我们的单一模型胜过VQA 1.0数据集的第一名获胜者，在当前最先进的集成模型的范围内执行。我们还尝试用我们的实施替换其他最先进模型中的关注机制，并显示更高的准确性。在这两种情况下，我们经常关注的机制都会提高VQA数据集上需要顺序或关系推理的任务的性能。

##### URL
[http://arxiv.org/abs/1802.00209](http://arxiv.org/abs/1802.00209)

##### PDF
[http://arxiv.org/pdf/1802.00209](http://arxiv.org/pdf/1802.00209)

