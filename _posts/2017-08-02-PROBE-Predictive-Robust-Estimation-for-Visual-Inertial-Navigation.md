---
layout: post
title: "PROBE: Predictive Robust Estimation for Visual-Inertial Navigation"
date: 2017-08-02 21:31:11
categories: arXiv_CV
tags: arXiv_CV Prediction
author: Valentin Peretroukhin, Lee Clement, Matthew Giamou, Jonathan Kelly
mathjax: true
---

* content
{:toc}

##### Abstract
Navigation in unknown, chaotic environments continues to present a significant challenge for the robotics community. Lighting changes, self-similar textures, motion blur, and moving objects are all considerable stumbling blocks for state-of-the-art vision-based navigation algorithms. In this paper we present a novel technique for improving localization accuracy within a visual-inertial navigation system (VINS). We make use of training data to learn a model for the quality of visual features with respect to localization error in a given environment. This model maps each visual observation from a predefined prediction space of visual-inertial predictors onto a scalar weight, which is then used to scale the observation covariance matrix. In this way, our model can adjust the influence of each observation according to its quality. We discuss our choice of predictors and report substantial reductions in localization error on 4 km of data from the KITTI dataset, as well as on experimental datasets consisting of 700 m of indoor and outdoor driving on a small ground rover equipped with a Skybotix VI-Sensor.

##### Abstract (translated by Google)
在未知的混乱环境中导航仍然是机器人界面临的重大挑战。照明变化，自相似纹理，运动模糊和移动物体都是最先进的基于视觉的导航算法的巨大绊脚石。在本文中，我们提出了一种新的技术，以提高视觉惯性导航系统（VINS）内的定位精度。我们利用训练数据来学习在特定环境中关于定位误差的视觉特征质量的模型。该模型将来自视觉 - 惯性预测器的预定义预测空间的每个视觉观测映射到标量权重上，然后将其用于缩放观测协方差矩阵。这样，我们的模型可以根据其质量调整每个观察的影响。我们讨论了我们对预报因子的选择，并报告了KITTI数据集的4公里数据以及包含700米室内和室外驾驶的实验数据在配备有Skybotix VI-Sensor 。

##### URL
[https://arxiv.org/abs/1708.00174](https://arxiv.org/abs/1708.00174)

##### PDF
[https://arxiv.org/pdf/1708.00174](https://arxiv.org/pdf/1708.00174)

