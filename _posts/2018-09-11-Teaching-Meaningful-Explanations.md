---
layout: post
title: "Teaching Meaningful Explanations"
date: 2018-09-11 01:44:51
categories: arXiv_AI
tags: arXiv_AI Knowledge Prediction
author: Noel C. F. Codella, Michael Hind, Karthikeyan Natesan Ramamurthy, Murray Campbell, Amit Dhurandhar, Kush R. Varshney, Dennis Wei, Aleksandra Mojsilovic
mathjax: true
---

* content
{:toc}

##### Abstract
The adoption of machine learning in high-stakes applications such as healthcare and law has lagged in part because predictions are not accompanied by explanations comprehensible to the domain user, who often holds the ultimate responsibility for decisions and outcomes. In this paper, we propose an approach to generate such explanations in which training data is augmented to include, in addition to features and labels, explanations elicited from domain users. A joint model is then learned to produce both labels and explanations from the input features. This simple idea ensures that explanations are tailored to the complexity expectations and domain knowledge of the consumer. Evaluation spans multiple modeling techniques on a game dataset, a (visual) aesthetics dataset, a chemical odor dataset and a Melanoma dataset showing that our approach is generalizable across domains and algorithms. Results demonstrate that meaningful explanations can be reliably taught to machine learning algorithms, and in some cases, also improve modeling accuracy.

##### Abstract (translated by Google)
在医疗保健和法律等高风险应用中采用机器学习的情况有所滞后，部分原因是预测并未附带域用户可理解的解释，域用户通常对决策和结果负有最终责任。在本文中，我们提出了一种方法来生成这样的解释，其中增强了训练数据，除了特征和标签之外，还包括从域用户引出的解释。然后学习联合模型以从输入特征产生标签和解释。这个简单的想法确保解释是根据消费者的复杂性期望和领域知识量身定制的。评估跨越游戏数据集，（视觉）美学数据集，化学气味数据集和黑色素瘤数据集的多种建模技术，显示我们的方法可跨域和算法推广。结果表明，可以可靠地向机器学习算法传授有意义的解释，并且在某些情况下，还可以提高建模精度。

##### URL
[http://arxiv.org/abs/1805.11648](http://arxiv.org/abs/1805.11648)

##### PDF
[http://arxiv.org/pdf/1805.11648](http://arxiv.org/pdf/1805.11648)

