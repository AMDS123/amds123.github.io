---
layout: post
title: "Learning Generalized Reactive Policies using Deep Neural Networks"
date: 2018-07-25 01:54:26
categories: arXiv_AI
tags: arXiv_AI Knowledge
author: Edward Groshev, Maxwell Goldstein, Aviv Tamar, Siddharth Srivastava, Pieter Abbeel
mathjax: true
---

* content
{:toc}

##### Abstract
We present a new approach to learning for planning, where knowledge acquired while solving a given set of planning problems is used to plan faster in related, but new problem instances. We show that a deep neural network can be used to learn and represent a \emph{generalized reactive policy} (GRP) that maps a problem instance and a state to an action, and that the learned GRPs efficiently solve large classes of challenging problem instances. In contrast to prior efforts in this direction, our approach significantly reduces the dependence of learning on handcrafted domain knowledge or feature selection. Instead, the GRP is trained from scratch using a set of successful execution traces. We show that our approach can also be used to automatically learn a heuristic function that can be used in directed search algorithms. We evaluate our approach using an extensive suite of experiments on two challenging planning problem domains and show that our approach facilitates learning complex decision making policies and powerful heuristic functions with minimal human input. Videos of our results are available at goo.gl/Hpy4e3.

##### Abstract (translated by Google)
我们提出了一种新的规划学习方法，在解决一系列规划问题时获得的知识用于在相关但新的问题实例中更快地计划。我们证明了深度神经网络可以用来学习和表示将问题实例和状态映射到动作的\ emph {广义反应策略}（GRP），并且学习的GRP有效地解决了大类具有挑战性的问题实例。与之前在这方面的努力相比，我们的方法显着降低了学习对手工领域知识或特征选择的依赖性。相反，GRP使用一组成功的执行跟踪从头开始训练。我们展示了我们的方法也可以用于自动学习可用于定向搜索算法的启发式函数。我们在两个具有挑战性的规划问题领域中使用一系列广泛的实验来评估我们的方法，并表明我们的方法有助于学习复杂的决策策略和强大的启发式功能，而人力输入最少我们的结果视频可在goo.gl/Hpy4e3上获得。

##### URL
[http://arxiv.org/abs/1708.07280](http://arxiv.org/abs/1708.07280)

##### PDF
[http://arxiv.org/pdf/1708.07280](http://arxiv.org/pdf/1708.07280)

