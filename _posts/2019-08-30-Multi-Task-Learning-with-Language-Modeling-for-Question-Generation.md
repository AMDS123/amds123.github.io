---
layout: post
title: "Multi-Task Learning with Language Modeling for Question Generation"
date: 2019-08-30 16:10:20
categories: arXiv_CL
tags: arXiv_CL Attention Language_Model
author: Wenjie Zhou, Minghua Zhang, Yunfang Wu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper explores the task of answer-aware questions generation. Based on the attention-based pointer generator model, we propose to incorporate an auxiliary task of language modeling to help question generation in a hierarchical multi-task learning structure. Our joint-learning model enables the encoder to learn a better representation of the input sequence, which will guide the decoder to generate more coherent and fluent questions. On both SQuAD and MARCO datasets, our multi-task learning model boosts the performance, achieving state-of-the-art results. Moreover, human evaluation further proves the high quality of our generated questions.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.11813](http://arxiv.org/abs/1908.11813)

##### PDF
[http://arxiv.org/pdf/1908.11813](http://arxiv.org/pdf/1908.11813)

