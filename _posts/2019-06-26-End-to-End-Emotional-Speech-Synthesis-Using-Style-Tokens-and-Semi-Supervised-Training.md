---
layout: post
title: "End-to-End Emotional Speech Synthesis Using Style Tokens and Semi-Supervised Training"
date: 2019-06-26 06:12:59
categories: arXiv_SD
tags: arXiv_SD Recognition
author: Peng-fei Wu, Zhen-hua Ling, Li-juan Liu, Yuan Jiang, Hong-chuan Wu, Li-rong Dai
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes an end-to-end emotional speech synthesis (ESS) method which adopts global style tokens (GSTs) for semi-supervised training. This model is built based on the GST-Tacotron framework. The style tokens are defined to present emotion categories. A cross entropy loss function between token weights and emotion labels is designed to obtain the interpretability of style tokens utilizing the small portion of training data with emotion labels. Emotion recognition experiments confirm that this method can achieve one-to-one correspondence between style tokens and emotion categories effectively. Objective and subjective evaluation results show that our model outperforms the conventional Tacotron model for ESS when only 5\% of training data has emotion labels. Its subjective performance is close to the Tacotron model trained using all emotion labels.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.10859](http://arxiv.org/abs/1906.10859)

##### PDF
[http://arxiv.org/pdf/1906.10859](http://arxiv.org/pdf/1906.10859)

