---
layout: post
title: "Modular Deep Q Networks for Sim-to-real Transfer of Visuo-motor Policies"
date: 2017-12-19 04:59:03
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Deep_Learning
author: Fangyi Zhang, J&#xfc;rgen Leitner, Michael Milford, Peter Corke
mathjax: true
---

* content
{:toc}

##### Abstract
While deep learning has had significant successes in computer vision thanks to the abundance of visual data, collecting sufficiently large real-world datasets for robot learning can be costly. To increase the practicality of these techniques on real robots, we propose a modular deep reinforcement learning method capable of transferring models trained in simulation to a real-world robotic task. We introduce a bottleneck between perception and control, enabling the networks to be trained independently, but then merged and fine-tuned in an end-to-end manner to further improve hand-eye coordination. On a canonical, planar visually-guided robot reaching task a fine-tuned accuracy of 1.6 pixels is achieved, a significant improvement over naive transfer (17.5 pixels), showing the potential for more complicated and broader applications. Our method provides a technique for more efficient learning and transfer of visuo-motor policies for real robotic systems without relying entirely on large real-world robot datasets.

##### Abstract (translated by Google)
虽然深度学习在计算机视觉方面取得了显着的成功，但由于大量的视觉数据，收集足够大的真实世界的机器人学习数据集可能是昂贵的。为了提高这些技术在真实机器人上的实用性，我们提出了一种模块化的深度强化学习方法，能够将模拟训练的模型转化为真实的机器人任务。我们引入感知与控制之间的瓶颈，使网络得到独立的训练，然后以端到端的方式进行合并与微调，进一步提高手眼协调能力。在规范的，平面的视觉引导机器人达到任务的情况下，获得了1.6像素的精确调整精度，相对于朴素转移（17.5像素）显着改善，显示出更复杂和更广泛应用的潜力。我们的方法提供了一种技术，可以在不依赖大型现实世界中的机器人数据集的情况下，更高效地学习和传输实际机器人系统的视觉运动策略。

##### URL
[http://arxiv.org/abs/1610.06781](http://arxiv.org/abs/1610.06781)

##### PDF
[http://arxiv.org/pdf/1610.06781](http://arxiv.org/pdf/1610.06781)

