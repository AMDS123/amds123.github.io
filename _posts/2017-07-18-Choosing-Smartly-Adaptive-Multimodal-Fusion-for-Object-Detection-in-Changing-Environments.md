---
layout: post
title: "Choosing Smartly: Adaptive Multimodal Fusion for Object Detection in Changing Environments"
date: 2017-07-18 16:36:56
categories: arXiv_CV
tags: arXiv_CV Object_Detection CNN Prediction Detection
author: Oier Mees, Andreas Eitel, Wolfram Burgard
mathjax: true
---

* content
{:toc}

##### Abstract
Object detection is an essential task for autonomous robots operating in dynamic and changing environments. A robot should be able to detect objects in the presence of sensor noise that can be induced by changing lighting conditions for cameras and false depth readings for range sensors, especially RGB-D cameras. To tackle these challenges, we propose a novel adaptive fusion approach for object detection that learns weighting the predictions of different sensor modalities in an online manner. Our approach is based on a mixture of convolutional neural network (CNN) experts and incorporates multiple modalities including appearance, depth and motion. We test our method in extensive robot experiments, in which we detect people in a combined indoor and outdoor scenario from RGB-D data, and we demonstrate that our method can adapt to harsh lighting changes and severe camera motion blur. Furthermore, we present a new RGB-D dataset for people detection in mixed in- and outdoor environments, recorded with a mobile robot.

##### Abstract (translated by Google)
对象检测对于在动态和变化的环境中操作的自主机器人是必不可少的任务。机器人应该能够在传感器噪声的存在下检测物体，这些噪声可以通过改变摄像机的照明条件以及距离传感器（尤其是RGB-D摄像机）的假深度读数来引起。为了解决这些挑战，我们提出了一种新的自适应融合方法，用于对象检测，学习以在线方式加权不同传感器模态的预测。我们的方法是基于卷积神经网络（CNN）专家的混合，并结合多种形式，包括外观，深度和运动。我们在广泛的机器人实验中测试了我们的方法，其中我们通过RGB-D数据检测室内和室外场景中的人，我们证明了我们的方法可以适应严酷的照明变化和严重的相机运动模糊。此外，我们还提供了一个新的RGB-D数据集，用于在室内和室外混合环境中进行人员检测，并使用移动机器人进行记录。

##### URL
[https://arxiv.org/abs/1707.05733](https://arxiv.org/abs/1707.05733)

##### PDF
[https://arxiv.org/pdf/1707.05733](https://arxiv.org/pdf/1707.05733)

