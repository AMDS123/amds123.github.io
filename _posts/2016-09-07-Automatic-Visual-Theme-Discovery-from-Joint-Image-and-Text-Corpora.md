---
layout: post
title: "Automatic Visual Theme Discovery from Joint Image and Text Corpora"
date: 2016-09-07 07:22:09
categories: arXiv_CV
tags: arXiv_CV Image_Caption Embedding
author: Ke Sun, Xianxu Hou, Qian Zhang, Guoping Qiu
mathjax: true
---

* content
{:toc}

##### Abstract
A popular approach to semantic image understanding is to manually tag images with keywords and then learn a mapping from vi- sual features to keywords. Manually tagging images is a subjective pro- cess and the same or very similar visual contents are often tagged with different keywords. Furthermore, not all tags have the same descriptive power for visual contents and large vocabulary available from natural language could result in a very diverse set of keywords. In this paper, we propose an unsupervised visual theme discovery framework as a better (more compact, efficient and effective) alternative to semantic represen- tation of visual contents. We first show that tag based annotation lacks consistency and compactness for describing visually similar contents. We then learn the visual similarity between tags based on the visual features of the images containing the tags. At the same time, we use a natural language processing technique (word embedding) to measure the seman- tic similarity between tags. Finally, we cluster tags into visual themes based on their visual similarity and semantic similarity measures using a spectral clustering algorithm. We conduct user studies to evaluate the effectiveness and rationality of the visual themes discovered by our unsu- pervised algorithm and obtains promising result. We then design three common computer vision tasks, example based image search, keyword based image search and image labelling to explore potential applica- tion of our visual themes discovery framework. In experiments, visual themes significantly outperforms tags on semantic image understand- ing and achieve state-of-art performance in all three tasks. This again demonstrate the effectiveness and versatility of proposed framework.

##### Abstract (translated by Google)
一种流行的语义图像理解方法是用关键字手动标记图像，然后学习从视觉特征到关键词的映射。手动标记图像是一个主观过程，相同或非常相似的视觉内容通常使用不同的关键字进行标记。而且，并不是所有的标签对于视觉内容都具有相同的描述能力，并且从自然语言中可获得的大量词汇可能导致非常多样化的关键词集合。在本文中，我们提出了一个无监督的视觉主题发现框架作为视觉内容语义表示的一种更好的（更紧凑，更高效和更有效）的替代方案。我们首先表明基于标签的注释缺乏一致性和紧凑性来描述视觉上相似的内容。然后，我们基于包含标签的图像的视觉特征来学习标签之间的视觉相似性。同时，我们使用自然语言处理技术（词嵌入）来衡量标签之间的语义相似性。最后，利用谱聚类算法将标签聚类为视觉主题，基于视觉相似度和语义相似性度量。我们进行用户研究，以评估我们的非监督算法发现的视觉主题的有效性和合理性，并获得有希望的结果。然后，我们设计了三个常见的计算机视觉任务，基于实例的图像搜索，基于关键字的图像搜索和图像标注，以探索我们的视觉主题发现框架的潜在应用。在实验中，视觉主题在语义图像理解上显着优于标签，并在所有三项任务中实现了最先进的性能。这再次证明了所提议的框架的有效性和多功能性。

##### URL
[https://arxiv.org/abs/1609.01859](https://arxiv.org/abs/1609.01859)

##### PDF
[https://arxiv.org/pdf/1609.01859](https://arxiv.org/pdf/1609.01859)

