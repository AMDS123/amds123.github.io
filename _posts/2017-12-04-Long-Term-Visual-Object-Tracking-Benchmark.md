---
layout: post
title: "Long-Term Visual Object Tracking Benchmark"
date: 2017-12-04 21:02:24
categories: arXiv_CV
tags: arXiv_CV Deep_Learning
author: Abhinav Moudgil, Vineet Gandhi
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for visual object tracking. The dataset consists of 50 videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term tracking performance and possibly train better deep learning architectures (avoiding/reducing augmentation, which may not reflect realistic real world behavior). We benchmark the dataset on 17 state of the art trackers and rank them according to tracking accuracy and run time speeds. We further categorize the test sequences with different attributes and present a thorough quantitative and qualitative evaluation. Our most interesting observations are (a) existing short sequence benchmarks fail to bring out the inherent differences in tracking algorithms which widen up while tracking on long sequences and (b) the accuracy of most trackers abruptly drops on challenging long sequences, suggesting the potential need of research efforts in the direction of long term tracking.

##### Abstract (translated by Google)
在本文中，我们提出了一个新的长视频数据集（称为轨道长和Prosper  -  TLP）和视觉对象跟踪的基准。该数据集包含来自真实世界场景的50个视频，包括持续时间超过400分钟（676K帧），使得每个序列的平均持续时间大于20倍，并且总持续时间大于8倍到现有的通用数据集进行视觉跟踪。所提出的数据集为适当评估长期跟踪性能铺平了道路，并可能训练出更好的深度学习架构（避免/减少增强，这可能不能反映真实的现实行为）。我们基于17个最先进的跟踪器状态数据集进行基准测试，并根据跟踪精度和运行时间速度进行排序。我们进一步对不同属性的测试序列进行分类，并进行全面的定量和定性评估。我们最感兴趣的观察结果是：（a）现有的短序列基准没有显示跟踪算法的固有差异，这种差异在跟踪长序列时加宽;（b）大多数跟踪器的准确性在具有挑战性的长序列上突然下降，表明潜在需要在长期跟踪方面的研究工作。

##### URL
[http://arxiv.org/abs/1712.01358](http://arxiv.org/abs/1712.01358)

