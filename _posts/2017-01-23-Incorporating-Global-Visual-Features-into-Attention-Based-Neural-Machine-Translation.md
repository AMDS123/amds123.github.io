---
layout: post
title: "Incorporating Global Visual Features into Attention-Based Neural Machine Translation"
date: 2017-01-23 17:43:23
categories: arXiv_CL
tags: arXiv_CL CNN NMT
author: Iacer Calixto, Qun Liu, Nick Campbell
---

* content
{:toc}

##### Abstract
We introduce multi-modal, attention-based neural machine translation (NMT) models which incorporate visual features into different parts of both the encoder and the decoder. We utilise global image features extracted using a pre-trained convolutional neural network and incorporate them (i) as words in the source sentence, (ii) to initialise the encoder hidden state, and (iii) as additional data to initialise the decoder hidden state. In our experiments, we evaluate how these different strategies to incorporate global image features compare and which ones perform best. We also study the impact that adding synthetic multi-modal, multilingual data brings and find that the additional data have a positive impact on multi-modal models. We report new state-of-the-art results and our best models also significantly improve on a comparable phrase-based Statistical MT (PBSMT) model trained on the Multi30k data set according to all metrics evaluated. To the best of our knowledge, it is the first time a purely neural model significantly improves over a PBSMT model on all metrics evaluated on this data set.

##### Abstract (translated by Google)
我们引入了多模式，基于注意的神经机器翻译（NMT）模型，其将视觉特征合并到编码器和解码器的不同部分中。我们利用用预先训练的卷积神经网络提取的全局图像特征，并将它们（i）作为源语句中的词，（ii）初始化编码器隐藏状态，和（iii）作为附加数据来初始化解码器隐藏状态。在我们的实验中，我们评估了如何将这些不同的策略整合到全局图像特征中，以及哪些策略表现最佳我们还研究了添加合成多模式，多语言数据带来的影响，并发现附加数据对多模式模型有积极的影响。我们报告了最新的最新研究成果，我们的最佳模型也根据所评估的所有指标，对基于Multi30k数据集训练的可比语句统计MT（PBSMT）模型进行了显着改进。据我们所知，这是一个纯粹的神经模型，首次在PBSMT模型上对这个数据集上评估的所有度量进行了显着的改进。

##### URL
[https://arxiv.org/abs/1701.06521](https://arxiv.org/abs/1701.06521)

