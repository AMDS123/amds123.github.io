---
layout: post
title: "SR-GAN: Semantic Rectifying Generative Adversarial Network for Zero-shot Learning"
date: 2019-04-15 12:30:09
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Zihan Ye, Fan lyu, Linyan Li, Qiming Fu, Jinchang Ren, Fuyuan Hu
mathjax: true
---

* content
{:toc}

##### Abstract
The existing Zero-Shot learning (ZSL) methods may suffer from the vague class attributes that are highly overlapped for different classes. Unlike these methods that ignore the discrimination among classes, in this paper, we propose to classify unseen image by rectifying the semantic space guided by the visual space. First, we pre-train a Semantic Rectifying Network (SRN) to rectify semantic space with a semantic loss and a rectifying loss. Then, a Semantic Rectifying Generative Adversarial Network (SR-GAN) is built to generate plausible visual feature of unseen class from both semantic feature and rectified semantic feature. To guarantee the effectiveness of rectified semantic features and synthetic visual features, a pre-reconstruction and a post reconstruction networks are proposed, which keep the consistency between visual feature and semantic feature. Experimental results demonstrate that our approach significantly outperforms the state-of-the-arts on four benchmark datasets.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.06996](http://arxiv.org/abs/1904.06996)

##### PDF
[http://arxiv.org/pdf/1904.06996](http://arxiv.org/pdf/1904.06996)

