---
layout: post
title: "Diversity-Driven Selection of Exploration Strategies in Multi-Armed Bandits"
date: 2018-08-23 13:24:17
categories: arXiv_AI
tags: arXiv_AI
author: Fabien C. Y. Benureau, Pierre-Yves Oudeyer
mathjax: true
---

* content
{:toc}

##### Abstract
We consider a scenario where an agent has multiple available strategies to explore an unknown environment. For each new interaction with the environment, the agent must select which exploration strategy to use. We provide a new strategy-agnostic method that treat the situation as a Multi-Armed Bandits problem where the reward signal is the diversity of effects that each strategy produces. We test the method empirically on a simulated planar robotic arm, and establish that the method is both able discriminate between strategies of dissimilar quality, even when the differences are tenuous, and that the resulting performance is competitive with the best fixed mixture of strategies.

##### Abstract (translated by Google)
我们考虑一种情况，即代理有多种可用策略来探索未知环境。对于与环境的每次新交互，代理必须选择要使用的探索策略。我们提供了一种新的战略无关方法，将情况视为多武装强盗问题，其中奖励信号是每种策略产生的效果的多样性。我们在模拟平面机器人手臂上凭经验测试该方法，并确定该方法能够区分不同质量的策略，即使差异很脆弱，并且所得到的性能与最佳固定混合策略竞争。

##### URL
[http://arxiv.org/abs/1808.07739](http://arxiv.org/abs/1808.07739)

##### PDF
[http://arxiv.org/pdf/1808.07739](http://arxiv.org/pdf/1808.07739)

