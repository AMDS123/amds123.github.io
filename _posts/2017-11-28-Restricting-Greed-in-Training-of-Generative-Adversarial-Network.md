---
layout: post
title: "Restricting Greed in Training of Generative Adversarial Network"
date: 2017-11-28 06:55:59
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Deep_Learning
author: Haoxuan You, Zhicheng Jiao, Haojun Xu, Jie Li, Ying Wang, Xinbo Gao
mathjax: true
---

* content
{:toc}

##### Abstract
Generative adversarial network (GAN) has gotten wide re-search interest in the field of deep learning. Variations of GAN have achieved competitive results on specific tasks. However, the stability of training and diversity of generated instances are still worth studying further. Training of GAN can be thought of as a greedy procedure, in which the generative net tries to make the locally optimal choice (minimizing loss function of discriminator) in each iteration. Unfortunately, this often makes generated data resemble only a few modes of real data and rotate between modes. To alleviate these problems, we propose a novel training strategy to restrict greed in training of GAN. With help of our method, the generated samples can cover more instance modes with more stable training process. Evaluating our method on several representative datasets, we demonstrate superiority of improved training strategy on typical GAN models with different distance metrics.

##### Abstract (translated by Google)
生成对抗网络（GAN）在深度学习领域已经获得了广泛的研究兴趣。 GAN的变化已经在具体任务上取得了具有竞争力的结果。但是，培训的稳定性和生成实例的多样性仍然值得进一步研究。 GAN的训练可以被认为是一个贪婪的过程，在这个过程中，生成网在每次迭代中试图做出局部最优选择（最小化鉴别器的损失函数）。不幸的是，这经常使生成的数据仅仅与真实数据的几种模式类似，并在模式之间旋转。为了缓解这些问题，我们提出了一种新的训练策略来限制GAN训练中的贪婪。在我们的方法的帮助下，生成的样本可以覆盖更多的实例模式，更稳定的训练过程。评估我们的方法在几个有代表性的数据集上，我们证明了改进的训练策略对具有不同距离度量的典型GAN模型的优越性。

##### URL
[https://arxiv.org/abs/1711.10152](https://arxiv.org/abs/1711.10152)

##### PDF
[https://arxiv.org/pdf/1711.10152](https://arxiv.org/pdf/1711.10152)

