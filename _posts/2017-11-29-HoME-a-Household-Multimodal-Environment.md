---
layout: post
title: "HoME: a Household Multimodal Environment"
date: 2017-11-29 18:45:59
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning
author: Simon Brodeur, Ethan Perez, Ankesh Anand, Florian Golemo, Luca Celotti, Florian Strub, Jean Rouat, Hugo Larochelle, Aaron Courville
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce HoME: a Household Multimodal Environment for artificial agents to learn from vision, audio, semantics, physics, and interaction with objects and other agents, all within a realistic context. HoME integrates over 45,000 diverse 3D house layouts based on the SUNCG dataset, a scale which may facilitate learning, generalization, and transfer. HoME is an open-source, OpenAI Gym-compatible platform extensible to tasks in reinforcement learning, language grounding, sound-based navigation, robotics, multi-agent learning, and more. We hope HoME better enables artificial agents to learn as humans do: in an interactive, multimodal, and richly contextualized setting.

##### Abstract (translated by Google)
我们介绍HoME：一个家庭多模态环境，用于在逼真的环境下从视觉，音频，语义，物理以及与对象和其他代理的交互中学习。 HoME基于SUNCG数据集合了超过45,000种不同的3D房屋布局，这个尺度可以促进学习，概括和转移。 HoME是一个开放源代码的OpenAI体育场兼容平台，可扩展到强化学习，语言接地，基于声音的导航，机器人，多代理学习等等。我们希望HoME能够更好地使人造代理人能够像人类一样学习：在交互式，多模态和丰富情境化的环境中。

##### URL
[https://arxiv.org/abs/1711.11017](https://arxiv.org/abs/1711.11017)

