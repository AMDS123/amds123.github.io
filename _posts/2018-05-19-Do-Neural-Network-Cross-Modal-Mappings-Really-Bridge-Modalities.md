---
layout: post
title: "Do Neural Network Cross-Modal Mappings Really Bridge Modalities?"
date: 2018-05-19 15:51:43
categories: arXiv_CV
tags: arXiv_CV
author: Guillem Collell, Marie-Francine Moens
mathjax: true
---

* content
{:toc}

##### Abstract
Feed-forward networks are widely used in cross-modal applications to bridge modalities by mapping distributed vectors of one modality to the other, or to a shared space. The predicted vectors are then used to perform e.g., retrieval or labeling. Thus, the success of the whole system relies on the ability of the mapping to make the neighborhood structure (i.e., the pairwise similarities) of the predicted vectors akin to that of the target vectors. However, whether this is achieved has not been investigated yet. Here, we propose a new similarity measure and two ad hoc experiments to shed light on this issue. In three cross-modal benchmarks we learn a large number of language-to-vision and vision-to-language neural network mappings (up to five layers) using a rich diversity of image and text features and loss functions. Our results reveal that, surprisingly, the neighborhood structure of the predicted vectors consistently resembles more that of the input vectors than that of the target vectors. In a second experiment, we further show that untrained nets do not significantly disrupt the neighborhood (i.e., semantic) structure of the input vectors.

##### Abstract (translated by Google)
前馈网络广泛用于跨模态应用，通过将一种模式的分布式向量映射到另一种模式或共享空间来连接模式。预测矢量然后用于执行例如检索或标记。因此，整个系统的成功依赖于映射使预测矢量的邻域结构（即成对相似性）类似于目标矢量的能力。但是，这是否实现尚未调查。在这里，我们提出了一个新的相似性度量和两个临时实验来揭示这个问题。在三个跨模式基准测试中，我们使用丰富多样的图像和文本特征以及丢失函数学习大量的语言到视觉和视觉到语言的神经网络映射（最多五层）。我们的结果表明，令人惊讶的是，预测向量的邻域结构一致地类似于输入向量的多于目标向量的邻域结构。在第二个实验中，我们进一步表明未经训练的网络不会显着破坏输入向量的邻域（即语义）结构。

##### URL
[https://arxiv.org/abs/1805.07616](https://arxiv.org/abs/1805.07616)

##### PDF
[https://arxiv.org/pdf/1805.07616](https://arxiv.org/pdf/1805.07616)

