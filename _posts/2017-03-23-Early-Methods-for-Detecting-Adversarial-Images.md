---
layout: post
title: "Early Methods for Detecting Adversarial Images"
date: 2017-03-23 18:03:47
categories: arXiv_CV
tags: arXiv_CV Salient Adversarial Object_Detection Prediction Detection
author: Dan Hendrycks, Kevin Gimpel
mathjax: true
---

* content
{:toc}

##### Abstract
Many machine learning classifiers are vulnerable to adversarial perturbations. An adversarial perturbation modifies an input to change a classifier's prediction without causing the input to seem substantially different to human perception. We deploy three methods to detect adversarial images. Adversaries trying to bypass our detectors must make the adversarial image less pathological or they will fail trying. Our best detection method reveals that adversarial images place abnormal emphasis on the lower-ranked principal components from PCA. Other detectors and a colorful saliency map are in an appendix.

##### Abstract (translated by Google)
许多机器学习分类器容易受到对抗干扰。对抗性扰动修改输入以改变分类器的预测，而不会导致输入看起来与人类感知显着不同。我们部署三种方法来检测敌对图像。试图绕过我们的探测器的敌人必须使敌对的图像更少的病态，否则将失败尝试。我们最好的检测方法揭示了对抗性图像不重视PCA的低级主成分。其他探测器和彩色显着图在附录中。

##### URL
[https://arxiv.org/abs/1608.00530](https://arxiv.org/abs/1608.00530)

##### PDF
[https://arxiv.org/pdf/1608.00530](https://arxiv.org/pdf/1608.00530)

