---
layout: post
title: "An Improved Residual LSTM Architecture for Acoustic Modeling"
date: 2017-08-17 01:37:21
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition RNN Recognition
author: Lu Huang, Jiasong Sun, Ji Xu, Yi Yang
mathjax: true
---

* content
{:toc}

##### Abstract
Long Short-Term Memory (LSTM) is the primary recurrent neural networks architecture for acoustic modeling in automatic speech recognition systems. Residual learning is an efficient method to help neural networks converge easier and faster. In this paper, we propose several types of residual LSTM methods for our acoustic modeling. Our experiments indicate that, compared with classic LSTM, our architecture shows more than 8% relative reduction in Phone Error Rate (PER) on TIMIT tasks. At the same time, our residual fast LSTM approach shows 4% relative reduction in PER on the same task. Besides, we find that all this architecture could have good results on THCHS-30, Librispeech and Switchboard corpora.

##### Abstract (translated by Google)
长期短期记忆（LSTM）是用于自动语音识别系统中的声学建模的主要递归神经网络架构。残留学习是帮助神经网络更容易和更快速收敛的有效方法。在本文中，我们提出了几种类型的残余LSTM方法用于我们的声学建模。我们的实验表明，与经典的LSTM相比，我们的架构在TIMIT任务上显示出手机错误率（PER）相对降低了8％以上。与此同时，我们的剩余快速LSTM方法在相同的任务中PER的相对降低了4％。另外，我们发现所有这些架构在THCHS-30，Librispeech和Switchboard语料库上都可以有很好的效果。

##### URL
[https://arxiv.org/abs/1708.05682](https://arxiv.org/abs/1708.05682)

##### PDF
[https://arxiv.org/pdf/1708.05682](https://arxiv.org/pdf/1708.05682)

