---
layout: post
title: "Interpretable Convolutional Neural Networks"
date: 2017-11-13 23:28:23
categories: arXiv_CV
tags: arXiv_CV Knowledge CNN
author: Quanshi Zhang, Ying Nian Wu, Song-Chun Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a method to modify traditional convolutional neural networks (CNNs) into interpretable CNNs, in order to clarify knowledge representations in high conv-layers of CNNs. In an interpretable CNN, each filter in a high conv-layer represents a certain object part. We do not need any annotations of object parts or textures to supervise the learning process. Instead, the interpretable CNN automatically assigns each filter in a high conv-layer with an object part during the learning process. Our method can be applied to different types of CNNs with different structures. The clear knowledge representation in an interpretable CNN can help people understand the logics inside a CNN, i.e., based on which patterns the CNN makes the decision. Experiments showed that filters in an interpretable CNN were more semantically meaningful than those in traditional CNNs.

##### Abstract (translated by Google)
本文提出了一种将传统的卷积神经网络（CNNs）修改为可解释的CNN的方法，以阐明CNN高层次的知识表示。在一个可解释的CNN中，高频层中的每个过滤器代表一个特定的对象部分。我们不需要任何注释的对象部分或纹理来监督学习过程。相反，在学习过程中，可解释的CNN会自动将一个对象部分中的每个过滤器分配到一个高度合适的层。我们的方法可以应用于不同结构的不同类型的CNN。在可解释的CNN中清晰的知识表示可以帮助人们理解CNN内部的逻辑，也就是根据CNN做出决定的模式。实验表明，可解释CNN中的过滤器在语义上比传统CNN中的过滤器更有意义。

##### URL
[https://arxiv.org/abs/1710.00935](https://arxiv.org/abs/1710.00935)

##### PDF
[https://arxiv.org/pdf/1710.00935](https://arxiv.org/pdf/1710.00935)

