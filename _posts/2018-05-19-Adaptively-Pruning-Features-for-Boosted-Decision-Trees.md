---
layout: post
title: "Adaptively Pruning Features for Boosted Decision Trees"
date: 2018-05-19 13:44:57
categories: arXiv_AI
tags: arXiv_AI
author: Maryam Aziz, Jesse Anderton, Javed Aslam
mathjax: true
---

* content
{:toc}

##### Abstract
Boosted decision trees enjoy popularity in a variety of applications; however, for large-scale datasets, the cost of training a decision tree in each round can be prohibitively expensive. Inspired by ideas from the multi-arm bandit literature, we develop a highly efficient algorithm for computing exact greedy-optimal decision trees, outperforming the state-of-the-art Quick Boost method. We further develop a framework for deriving lower bounds on the problem that applies to a wide family of conceivable algorithms for the task (including our algorithm and Quick Boost), and we demonstrate empirically on a wide variety of data sets that our algorithm is near-optimal within this family of algorithms. We also derive a lower bound applicable to any algorithm solving the task, and we demonstrate that our algorithm empirically achieves performance close to this best-achievable lower bound.

##### Abstract (translated by Google)
增强型决策树在各种应用中享有盛誉。然而，对于大规模数据集来说，在每一轮训练决策树的成本可能非常昂贵。灵感来自多臂土匪文献的想法，我们开发了一种计算精确贪婪最优决策树的高效算法，超越了最先进的Quick Boost方法。我们进一步开发了一个框架，用于推导适用于任务可用算法（包括我们的算法和Quick Boost）的广泛系列的问题的下界，并且我们凭借经验证明了我们的算法近似于多种数据集，在这个算法家族中是最佳的。我们还推导出适用于解决任务的任何算法的下限，并且我们证明了我们的算法凭经验实现了接近此最佳可实现下限的性能。

##### URL
[https://arxiv.org/abs/1805.07592](https://arxiv.org/abs/1805.07592)

##### PDF
[https://arxiv.org/pdf/1805.07592](https://arxiv.org/pdf/1805.07592)

