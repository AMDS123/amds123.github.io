---
layout: post
title: "Semantic-Unit-Based Dilated Convolution for Multi-Label Text Classification"
date: 2018-08-26 14:36:22
categories: arXiv_CL
tags: arXiv_CL Attention Text_Classification Classification
author: Junyang Lin, Qi Su, Pengcheng Yang, Shuming Ma, Xu Sun
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel model for multi-label text classification, which is based on sequence-to-sequence learning. The model generates higher-level semantic unit representations with multi-level dilated convolution as well as a corresponding hybrid attention mechanism that extracts both the information at the word-level and the level of the semantic unit. Our designed dilated convolution effectively reduces dimension and supports an exponential expansion of receptive fields without loss of local information, and the attention-over-attention mechanism is able to capture more summary relevant information from the source context. Results of our experiments show that the proposed model has significant advantages over the baseline models on the dataset RCV1-V2 and Ren-CECps, and our analysis demonstrates that our model is competitive to the deterministic hierarchical models and it is more robust to classifying low-frequency labels.

##### Abstract (translated by Google)
我们提出了一种基于序列到序列学习的多标签文本分类的新模型。该模型利用多级扩张卷积生成更高级别的语义单元表示，以及相应的混合注意机制，其提取单词级别的信息和语义单元的级别。我们设计的扩张卷积有效地减少了维度并支持接收域的指数扩展而不会丢失本地信息，并且注意力过度关注机制能够从源上下文中捕获更多摘要相关信息。我们的实验结果表明，所提出的模型相对于数据集RCV1-V2和Ren-CECps的基线模型具有显着的优势，并且我们的分析表明我们的模型与确定性分层模型相比具有竞争力，并且对于分类低 - 频率标签。

##### URL
[http://arxiv.org/abs/1808.08561](http://arxiv.org/abs/1808.08561)

##### PDF
[http://arxiv.org/pdf/1808.08561](http://arxiv.org/pdf/1808.08561)

