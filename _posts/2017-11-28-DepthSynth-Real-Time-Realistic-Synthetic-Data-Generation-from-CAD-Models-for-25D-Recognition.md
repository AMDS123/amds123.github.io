---
layout: post
title: "DepthSynth: Real-Time Realistic Synthetic Data Generation from CAD Models for 2.5D Recognition"
date: 2017-11-28 17:34:22
categories: arXiv_CV
tags: arXiv_CV Face Recognition
author: Benjamin Planche, Ziyan Wu, Kai Ma, Shanhui Sun, Stefan Kluckner, Terrence Chen, Andreas Hutter, Sergey Zakharov, Harald Kosch, Jan Ernst
mathjax: true
---

* content
{:toc}

##### Abstract
Recent progress in computer vision has been dominated by deep neural networks trained over large amounts of labeled data. Collecting such datasets is however a tedious, often impossible task; hence a surge in approaches relying solely on synthetic data for their training. For depth images however, discrepancies with real scans still noticeably affect the end performance. We thus propose an end-to-end framework which simulates the whole mechanism of these devices, generating realistic depth data from 3D models by comprehensively modeling vital factors e.g. sensor noise, material reflectance, surface geometry. Not only does our solution cover a wider range of sensors and achieve more realistic results than previous methods, assessed through extended evaluation, but we go further by measuring the impact on the training of neural networks for various recognition tasks; demonstrating how our pipeline seamlessly integrates such architectures and consistently enhances their performance.

##### Abstract (translated by Google)
最近在计算机视觉方面的进展一直是由大量标记数据训练的深度神经网络支配的。然而，收集这样的数据集是一个单调乏味，往往不可能完成的任务;因此仅仅依靠合成数据进行培训的方法激增。但是，对于深度图像，真实扫描的差异仍然会明显影响最终性能。因此，我们提出了一个模拟这些设备的整个机制的端到端框架，通过综合地模拟重要因素，从而从3D模型产生真实的深度数据。传感器噪声，材料反射率，表面几何形状。我们的解决方案不仅覆盖范围更广的传感器，并通过扩展评估来评估比以前的方法更为真实的结果，而且还通过测量各种识别任务对神经网络训练的影响来进一步研究;展示了我们的流水线如何将这些架构无缝地集成在一起，并不断提升其性能。

##### URL
[https://arxiv.org/abs/1702.08558](https://arxiv.org/abs/1702.08558)

##### PDF
[https://arxiv.org/pdf/1702.08558](https://arxiv.org/pdf/1702.08558)

