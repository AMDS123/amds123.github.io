---
layout: post
title: "Human-Centered Emotion Recognition in Animated GIFs"
date: 2019-04-27 20:16:04
categories: arXiv_CV
tags: arXiv_CV Attention Face RNN Prediction Relation Recognition
author: Zhengyuan Yang, Yixuan Zhang, Jiebo Luo
mathjax: true
---

* content
{:toc}

##### Abstract
As an intuitive way of expression emotion, the animated Graphical Interchange Format (GIF) images have been widely used on social media. Most previous studies on automated GIF emotion recognition fail to effectively utilize GIF's unique properties, and this potentially limits the recognition performance. In this study, we demonstrate the importance of human related information in GIFs and conduct human-centered GIF emotion recognition with a proposed Keypoint Attended Visual Attention Network (KAVAN). The framework consists of a facial attention module and a hierarchical segment temporal module. The facial attention module exploits the strong relationship between GIF contents and human characters, and extracts frame-level visual feature with a focus on human faces. The Hierarchical Segment LSTM (HS-LSTM) module is then proposed to better learn global GIF representations. Our proposed framework outperforms the state-of-the-art on the MIT GIFGIF dataset. Furthermore, the facial attention module provides reliable facial region mask predictions, which improves the model's interpretability.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.12201](http://arxiv.org/abs/1904.12201)

##### PDF
[http://arxiv.org/pdf/1904.12201](http://arxiv.org/pdf/1904.12201)

