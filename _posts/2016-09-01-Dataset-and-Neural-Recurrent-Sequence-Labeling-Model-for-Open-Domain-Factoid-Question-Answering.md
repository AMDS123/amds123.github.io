---
layout: post
title: "Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering"
date: 2016-09-01 10:56:45
categories: arXiv_CL
tags: arXiv_CL QA Face Classification
author: Peng Li, Wei Li, Zhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, Wei Xu
mathjax: true
---

* content
{:toc}

##### Abstract
While question answering (QA) with neural network, i.e. neural QA, has achieved promising results in recent years, lacking of large scale real-word QA dataset is still a challenge for developing and evaluating neural QA system. To alleviate this problem, we propose a large scale human annotated real-world QA dataset WebQA with more than 42k questions and 556k evidences. As existing neural QA methods resolve QA either as sequence generation or classification/ranking problem, they face challenges of expensive softmax computation, unseen answers handling or separate candidate answer generation component. In this work, we cast neural QA as a sequence labeling problem and propose an end-to-end sequence labeling model, which overcomes all the above challenges. Experimental results on WebQA show that our model outperforms the baselines significantly with an F1 score of 74.69% with word-based input, and the performance drops only 3.72 F1 points with more challenging character-based input.

##### Abstract (translated by Google)
虽然近年来神经网络（即神经网络QA）的问答（QA）取得了很好的效果，但缺乏大规模的实词QA数据集对开发和评估神经网络QA系统仍然是一个挑战。为了缓解这个问题，我们提出了一个大规模的人类注释的现实世界QA数据集WebQA，其中有超过42k个问题和556k个证据。由于现有的神经QA方法解决QA问题，无论是序列生成还是分类/排序问题，他们面临着昂贵的softmax计算，看不见的答案处理或单独的候选答案生成组件的挑战。在这项工作中，我们把神经质量分析作为序列标记问题，提出了一个端到端的序列标记模型，克服了上述所有的挑战。 WebQA的实验结果显示，我们的模型比基线显着优于基线，基于单词输入的F1分数为74.69％，性能下降仅3.72个F1分，更具有挑战性的基于字符的输入。

##### URL
[https://arxiv.org/abs/1607.06275](https://arxiv.org/abs/1607.06275)

##### PDF
[https://arxiv.org/pdf/1607.06275](https://arxiv.org/pdf/1607.06275)

