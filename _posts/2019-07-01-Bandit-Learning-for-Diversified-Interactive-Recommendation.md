---
layout: post
title: "Bandit Learning for Diversified Interactive Recommendation"
date: 2019-07-01 03:52:55
categories: arXiv_AI
tags: arXiv_AI Attention Inference Recommendation
author: Yong Liu, Yingtai Xiao, Qiong Wu, Chunyan Miao, Juyong Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Interactive recommender systems that enable the interactions between users and the recommender system have attracted increasing research attentions. Previous methods mainly focus on optimizing recommendation accuracy. However, they usually ignore the diversity of the recommendation results, thus usually results in unsatisfying user experiences. In this paper, we propose a novel diversified recommendation model, named Diversified Contextual Combinatorial Bandit (DC$^2$B), for interactive recommendation with users' implicit feedback. Specifically, DC$^2$B employs determinantal point process in the recommendation procedure to promote diversity of the recommendation results. To learn the model parameters, a Thompson sampling-type algorithm based on variational Bayesian inference is proposed. In addition, theoretical regret analysis is also provided to guarantee the performance of DC$^2$B. Extensive experiments on real datasets are performed to demonstrate the effectiveness of the proposed method.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.01647](http://arxiv.org/abs/1907.01647)

##### PDF
[http://arxiv.org/pdf/1907.01647](http://arxiv.org/pdf/1907.01647)

