---
layout: post
title: "Neural Latent Relational Analysis to Capture Lexical Semantic Relations in a Vector Space"
date: 2018-09-10 15:37:30
categories: arXiv_CL
tags: arXiv_CL Sparse Embedding Relation
author: Koki Washio, Tsuneaki Kato
mathjax: true
---

* content
{:toc}

##### Abstract
Capturing the semantic relations of words in a vector space contributes to many natural language processing tasks. One promising approach exploits lexico-syntactic patterns as features of word pairs. In this paper, we propose a novel model of this pattern-based approach, neural latent relational analysis (NLRA). NLRA can generalize co-occurrences of word pairs and lexico-syntactic patterns, and obtain embeddings of the word pairs that do not co-occur. This overcomes the critical data sparseness problem encountered in previous pattern-based models. Our experimental results on measuring relational similarity demonstrate that NLRA outperforms the previous pattern-based models. In addition, when combined with a vector offset model, NLRA achieves a performance comparable to that of the state-of-the-art model that exploits additional semantic relational data.

##### Abstract (translated by Google)
捕获向量空间中的单词的语义关系有助于许多自然语言处理任务。一种有希望的方法利用词汇句法模式作为单词对的特征。在本文中，我们提出了一种新的模式，这种基于模式的方法，神经潜在关系分析（NLRA）。 NLRA可以推广单词对和词汇句法模式的共现，并获得不共同出现的单词对的嵌入。这克服了先前基于模式的模型中遇到的关键数据稀疏性问题。我们测量关系相似性的实验结果表明，NLRA优于以前的基于模式的模型。此外，当与矢量偏移模型结合使用时，NLRA实现了与利用其他语义关系数据的最新模型相当的性能。

##### URL
[http://arxiv.org/abs/1809.03401](http://arxiv.org/abs/1809.03401)

##### PDF
[http://arxiv.org/pdf/1809.03401](http://arxiv.org/pdf/1809.03401)

