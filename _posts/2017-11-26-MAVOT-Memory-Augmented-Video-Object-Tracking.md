---
layout: post
title: "MAVOT: Memory-Augmented Video Object Tracking"
date: 2017-11-26 16:20:45
categories: arXiv_CV
tags: arXiv_CV Tracking Object_Tracking Detection
author: Boyu Liu, Yanzhao Wang, Yu-Wing Tai, Chi-Keung Tang
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a one-shot learning approach for video object tracking. The proposed algorithm requires seeing the object to be tracked only once, and employs an external memory to store and remember the evolving features of the foreground object as well as backgrounds over time during tracking. With the relevant memory retrieved and updated in each tracking, our tracking model is capable of maintaining long-term memory of the object, and thus can naturally deal with hard tracking scenarios including partial and total occlusion, motion changes and large scale and shape variations. In our experiments we use the ImageNet ILSVRC2015 video detection dataset to train and use the VOT-2016 benchmark to test and compare our Memory-Augmented Video Object Tracking (MAVOT) model. From the results, we conclude that given its oneshot property and simplicity in design, MAVOT is an attractive approach in visual tracking because it shows good performance on VOT-2016 benchmark and is among the top 5 performers in accuracy and robustness in occlusion, motion changes and empty target.

##### Abstract (translated by Google)
我们介绍一种针对视频对象跟踪的一次学习方法。所提出的算法要求仅观察一次被跟踪物体，并且使用外部存储器来存储和记忆前景物体的演变特征以及跟踪期间的背景。通过在每次跟踪中检索和更新相关存储器，我们的跟踪模型能够保持对象的长期记忆，因此能够自然处理包括局部和全部遮挡，运动变化以及大规模和形状变化的硬跟踪场景。在我们的实验中，我们使用ImageNet ILSVRC2015视频检测数据集来训练和使用VOT-2016基准测试和比较我们的记忆增强视频对象跟踪（MAVOT）模型。从结果来看，我们得出结论，鉴于其独特的性质和简单的设计，MAVOT在视觉追踪方面是一个有吸引力的方法，因为它在VOT-2016基准测试中表现出良好的表现，并且在遮挡，运动变化和空目标。

##### URL
[https://arxiv.org/abs/1711.09414](https://arxiv.org/abs/1711.09414)

##### PDF
[https://arxiv.org/pdf/1711.09414](https://arxiv.org/pdf/1711.09414)

