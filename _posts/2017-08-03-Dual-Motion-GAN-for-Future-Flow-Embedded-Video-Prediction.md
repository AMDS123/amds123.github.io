---
layout: post
title: "Dual Motion GAN for Future-Flow Embedded Video Prediction"
date: 2017-08-03 04:23:30
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Represenation_Learning Prediction
author: Xiaodan Liang, Lisa Lee, Wei Dai, Eric P. Xing
mathjax: true
---

* content
{:toc}

##### Abstract
Future frame prediction in videos is a promising avenue for unsupervised video representation learning. Video frames are naturally generated by the inherent pixel flows from preceding frames based on the appearance and motion dynamics in the video. However, existing methods focus on directly hallucinating pixel values, resulting in blurry predictions. In this paper, we develop a dual motion Generative Adversarial Net (GAN) architecture, which learns to explicitly enforce future-frame predictions to be consistent with the pixel-wise flows in the video through a dual-learning mechanism. The primal future-frame prediction and dual future-flow prediction form a closed loop, generating informative feedback signals to each other for better video prediction. To make both synthesized future frames and flows indistinguishable from reality, a dual adversarial training method is proposed to ensure that the future-flow prediction is able to help infer realistic future-frames, while the future-frame prediction in turn leads to realistic optical flows. Our dual motion GAN also handles natural motion uncertainty in different pixel locations with a new probabilistic motion encoder, which is based on variational autoencoders. Extensive experiments demonstrate that the proposed dual motion GAN significantly outperforms state-of-the-art approaches on synthesizing new video frames and predicting future flows. Our model generalizes well across diverse visual scenes and shows superiority in unsupervised video representation learning.

##### Abstract (translated by Google)
视频中的未来帧预测是无监督视频表示学习的有前途的途径。基于视频中的外观和运动动态，视频帧自然由来自先前帧的固有像素流生成。然而，现有的方法直接关注幻像像素值，导致模糊的预测。在本文中，我们开发了一种双运动生成对抗网络（GAN）架构，通过双重学习机制，学习明确强制未来帧预测与视频中的像素流相一致。原始未来帧预测和双向未来流预测形成闭环，为了更好的视频预测而彼此生成信息反馈信号。为了使合成的未来帧和流与现实无法区分，提出了双向对抗训练方法，以确保未来流预测能够帮助推断现实的未来帧，而未来帧预测反过来导致实际的光流。我们的双运动GAN还可以利用基于变分自动编码器的新型概率运动编码器来处理不同像素位置的自然运动不确定性。大量实验表明，所提出的双运动GAN在合成新的视频帧和预测未来流量方面明显优于最新的方法。我们的模型在不同的视觉场景中进行了概括，并且在无监督的视频表示学习中表现出优越性。

##### URL
[https://arxiv.org/abs/1708.00284](https://arxiv.org/abs/1708.00284)

##### PDF
[https://arxiv.org/pdf/1708.00284](https://arxiv.org/pdf/1708.00284)

