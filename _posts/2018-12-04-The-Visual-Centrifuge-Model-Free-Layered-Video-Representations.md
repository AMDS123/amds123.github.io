---
layout: post
title: "The Visual Centrifuge: Model-Free Layered Video Representations"
date: 2018-12-04 14:47:23
categories: arXiv_CV
tags: arXiv_CV Video_Caption CNN Quantitative
author: Jean-Baptiste Alayrac, Jo&#xe3;o Carreira, Andrew Zisserman
mathjax: true
---

* content
{:toc}

##### Abstract
True video understanding requires making sense of non-lambertian scenes where the color of light arriving at the camera sensor encodes information about not just the last object it collided with, but about multiple mediums -- colored windows, dirty mirrors, smoke or rain. Layered video representations have the potential of accurately modelling realistic scenes but have so far required stringent assumptions on motion, lighting and shape. Here we propose a learning-based approach for multi-layered video representation: we introduce novel uncertainty-capturing 3D convolutional architectures and train them to separate blended videos. We show that these models then generalize to single videos, where they exhibit interesting abilities: color constancy, factoring out shadows and separating reflections. We present quantitative and qualitative results on real world videos.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.01461](http://arxiv.org/abs/1812.01461)

##### PDF
[http://arxiv.org/pdf/1812.01461](http://arxiv.org/pdf/1812.01461)

