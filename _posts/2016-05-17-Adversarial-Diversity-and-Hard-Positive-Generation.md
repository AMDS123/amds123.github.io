---
layout: post
title: "Adversarial Diversity and Hard Positive Generation"
date: 2016-05-17 02:46:39
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Andras Rozsa, Ethan M. Rudd, Terrance E. Boult
mathjax: true
---

* content
{:toc}

##### Abstract
State-of-the-art deep neural networks suffer from a fundamental problem - they misclassify adversarial examples formed by applying small perturbations to inputs. In this paper, we present a new psychometric perceptual adversarial similarity score (PASS) measure for quantifying adversarial images, introduce the notion of hard positive generation, and use a diverse set of adversarial perturbations - not just the closest ones - for data augmentation. We introduce a novel hot/cold approach for adversarial example generation, which provides multiple possible adversarial perturbations for every single image. The perturbations generated by our novel approach often correspond to semantically meaningful image structures, and allow greater flexibility to scale perturbation-amplitudes, which yields an increased diversity of adversarial images. We present adversarial images on several network topologies and datasets, including LeNet on the MNIST dataset, and GoogLeNet and ResidualNet on the ImageNet dataset. Finally, we demonstrate on LeNet and GoogLeNet that fine-tuning with a diverse set of hard positives improves the robustness of these networks compared to training with prior methods of generating adversarial images.

##### Abstract (translated by Google)
最先进的深度神经网络遭受一个根本性的问题 - 他们错误分类对输入应用小的扰动而形成的敌对的例子。在本文中，我们提出了一种新的用于量化对抗性图像的心理测量知觉对抗相似性得分（PASS）测量，介绍了硬性阳性生成的概念，并使用一组不同的对抗性扰动（不仅仅是最接近的）来进行数据增强。我们引入了一种新颖的热/冷方法来生成对抗的例子，它为每一幅图像提供了多种可能的对抗干扰。由我们的新方法产生的扰动通常对应于语义上有意义的图像结构，并且允许更大的灵活性来缩放扰动振幅，这产生对抗图像的增加的多样性。我们在几个网络拓扑和数据集上展示敌对图像，包括MNIST数据集上的LeNet和ImageNet数据集上的GoogLeNet和ResidualNet。最后，我们在LeNet和GoogLeNet上展示，与使用先前产生敌对图像的方法进行训练相比，使用多种硬性积极方式进行微调可以提高这些网络的鲁棒性。

##### URL
[https://arxiv.org/abs/1605.01775](https://arxiv.org/abs/1605.01775)

##### PDF
[https://arxiv.org/pdf/1605.01775](https://arxiv.org/pdf/1605.01775)

