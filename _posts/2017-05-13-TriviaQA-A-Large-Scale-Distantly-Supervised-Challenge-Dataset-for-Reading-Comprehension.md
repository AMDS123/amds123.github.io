---
layout: post
title: "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension"
date: 2017-05-13 21:12:37
categories: arXiv_CL
tags: arXiv_CL QA
author: Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer
mathjax: true
---

* content
{:toc}

##### Abstract
We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at -- this http URL

##### Abstract (translated by Google)
我们提出TriviaQA，一个挑战性的阅读理解数据库，包含超过650K的问题 - 答案 - 证据三元组。问答QA包括琐事爱好者撰写的95K个问答组合，以及独立收集的证据文件，平均每个问题6个，为回答问题提供高质量的远程监督。我们发现，与其他最近引入的大规模数据集相比，TriviaQA（1）具有相对复杂的组合问题，（2）在问题和相应的答案 - 证据句子之间具有相当大的句法和词汇变异性，（3）需要更多交叉句推理找到答案。我们还提出了两个基线算法：一个基于特征的分类器和一个现代化的神经网络，在SQUAD阅读理解上表现良好。这两种方法都没有接近人类的表现（23％和40％比80％），这表明TriviaQA是一个具有挑战性的测试平台，值得重大的未来研究。数据和代码可在此http URL

##### URL
[https://arxiv.org/abs/1705.03551](https://arxiv.org/abs/1705.03551)

##### PDF
[https://arxiv.org/pdf/1705.03551](https://arxiv.org/pdf/1705.03551)

