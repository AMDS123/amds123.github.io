---
layout: post
title: "On Differentiating Parameterized Argmin and Argmax Problems with Application to Bi-level Optimization"
date: 2016-07-21 03:43:35
categories: arXiv_CV
tags: arXiv_CV Optimization Gradient_Descent
author: Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, Edison Guo
mathjax: true
---

* content
{:toc}

##### Abstract
Some recent works in machine learning and computer vision involve the solution of a bi-level optimization problem. Here the solution of a parameterized lower-level problem binds variables that appear in the objective of an upper-level problem. The lower-level problem typically appears as an argmin or argmax optimization problem. Many techniques have been proposed to solve bi-level optimization problems, including gradient descent, which is popular with current end-to-end learning approaches. In this technical report we collect some results on differentiating argmin and argmax optimization problems with and without constraints and provide some insightful motivating examples.

##### Abstract (translated by Google)
最近在机器学习和计算机视觉方面的一些工作涉及双层优化问题的解决方案。这里，参数化的低层次问题的解决方案绑定了出现在高层次问题目标中的变量。较低级别的问题通常表现为argmin或argmax优化问题。已经提出了许多技术来解决双层优化问题，包括渐变下降，这是当前端到端学习方法所普遍的。在这份技术报告中，我们收集了一些关于区分argmin和argmax优化问题的结果，并提供了一些有启发性的例子。

##### URL
[https://arxiv.org/abs/1607.05447](https://arxiv.org/abs/1607.05447)

##### PDF
[https://arxiv.org/pdf/1607.05447](https://arxiv.org/pdf/1607.05447)

