---
layout: post
title: "Establishing Appropriate Trust via Critical States"
date: 2018-10-18 17:29:47
categories: arXiv_RO
tags: arXiv_RO
author: Sandy H. Huang, Kush Bhatia, Pieter Abbeel, Anca D. Dragan
mathjax: true
---

* content
{:toc}

##### Abstract
In order to effectively interact with or supervise a robot, humans need to have an accurate mental model of its capabilities and how it acts. Learned neural network policies make that particularly challenging. We propose an approach for helping end-users build a mental model of such policies. Our key observation is that for most tasks, the essence of the policy is captured in a few critical states: states in which it is very important to take a certain action. Our user studies show that if the robot shows a human what its understanding of the task's critical states is, then the human can make a more informed decision about whether to deploy the policy, and if she does deploy it, when she needs to take control from it at execution time.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.08174](http://arxiv.org/abs/1810.08174)

##### PDF
[http://arxiv.org/pdf/1810.08174](http://arxiv.org/pdf/1810.08174)

