---
layout: post
title: "Ultradense Word Embeddings by Orthogonal Transformation"
date: 2016-05-08 08:50:11
categories: arXiv_SD
tags: arXiv_SD Sentiment Embedding
author: Sascha Rothe, Sebastian Ebert, Hinrich Schütze
mathjax: true
---

* content
{:toc}

##### Abstract
Embeddings are generic representations that are useful for many NLP tasks. In this paper, we introduce DENSIFIER, a method that learns an orthogonal transformation of the embedding space that focuses the information relevant for a task in an ultradense subspace of a dimensionality that is smaller by a factor of 100 than the original space. We show that ultradense embeddings generated by DENSIFIER reach state of the art on a lexicon creation task in which words are annotated with three types of lexical information - sentiment, concreteness and frequency. On the SemEval2015 10B sentiment analysis task we show that no information is lost when the ultradense subspace is used, but training is an order of magnitude more efficient due to the compactness of the ultradense space.

##### Abstract (translated by Google)
嵌入是对许多NLP任务有用的通用表示。在本文中，我们引入了DENSIFIER，这是一种学习嵌入空间的正交变换的方法，它将一个任务的相关信息集中在维度比原始空间小100倍的超密度子空间中。我们表明，由DENSIFIER产生的超密度嵌入达到了词汇创作任务中的艺术水平，其中词语用三种类型的词汇信息注解 - 情感，具体性和频率。在SemEval2015 10B情绪分析任务中，我们表明，使用超密度子空间时不会丢失任何信息，但由于超密空间的紧凑性，训练的效率提高了一个数量级。

##### URL
[https://arxiv.org/abs/1602.07572](https://arxiv.org/abs/1602.07572)

##### PDF
[https://arxiv.org/pdf/1602.07572](https://arxiv.org/pdf/1602.07572)

