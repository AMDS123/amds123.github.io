---
layout: post
title: "CBinfer: Exploiting Frame-to-Frame Locality for Faster Convolutional Network Inference on Video Streams"
date: 2018-08-15 15:27:29
categories: arXiv_CV
tags: arXiv_CV Segmentation CNN Semantic_Segmentation Inference Detection
author: Lukas Cavigelli, Luca Benini
mathjax: true
---

* content
{:toc}

##### Abstract
The last few years have brought advances in computer vision at an amazing pace, grounded on new findings in deep neural network construction and training as well as the availability of large labeled datasets. Applying these networks to images demands a high computational effort and pushes the use of state-of-the-art networks on real-time video data out of reach of embedded platforms. Many recent works focus on reducing network complexity for real-time inference on embedded computing platforms. We adopt an orthogonal viewpoint and propose a novel algorithm exploiting the spatio-temporal sparsity of pixel changes. This optimized inference procedure resulted in an average speed-up of 9.1x over cuDNN on the Tegra X2 platform at a negligible accuracy loss of &lt;0.1% and no retraining of the network for a semantic segmentation application. Similarly, an average speed-up of 7.0x has been achieved for a pose detection DNN on static camera video surveillance data. These throughput gains combined with a lower power consumption result in an energy efficiency of 511 GOp/s/W compared to 70 GOp/s/W for the baseline.

##### Abstract (translated by Google)
最近几年以惊人的速度带来了计算机视觉的进步，基于深度神经网络构建和培训的新发现以及大型标记数据集的可用性。将这些网络应用于图像需要高计算量，并且在嵌入式平台无法到达的实时视频数据上推动使用最先进的网络。最近的许多工作都致力于降低网络复杂性，以便在嵌入式计算平台上进行实时推理。我们采用正交观点，提出了一种利用像素变化的时空稀疏性的新算法。这种优化的推理过程导致Tegra X2平台上的cuDNN平均加速率为9.1倍，精度损失可忽略不计<0.1％，并且对于语义分段应用程序没有网络重新训练。同样，静态摄像机视频监控数据上的姿态检测DNN的平均加速率已达到7.0倍。与基线的70 GOp / s / W相比，这些吞吐量增益与更低的功耗相结合，能效为511 GOp / s / W.

##### URL
[http://arxiv.org/abs/1808.05488](http://arxiv.org/abs/1808.05488)

##### PDF
[http://arxiv.org/pdf/1808.05488](http://arxiv.org/pdf/1808.05488)

