---
layout: post
title: "ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes"
date: 2017-04-11 08:09:33
categories: arXiv_CV
tags: arXiv_CV Segmentation Face Semantic_Segmentation Classification Deep_Learning
author: Angela Dai, Angel X. Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, Matthias Nießner
mathjax: true
---

* content
{:toc}

##### Abstract
A key requirement for leveraging supervised deep learning methods is the availability of large, labeled datasets. Unfortunately, in the context of RGB-D scene understanding, very little data is available -- current datasets cover a small range of scene views and have limited semantic annotations. To address this issue, we introduce ScanNet, an RGB-D video dataset containing 2.5M views in 1513 scenes annotated with 3D camera poses, surface reconstructions, and semantic segmentations. To collect this data, we designed an easy-to-use and scalable RGB-D capture system that includes automated surface reconstruction and crowdsourced semantic annotation. We show that using this data helps achieve state-of-the-art performance on several 3D scene understanding tasks, including 3D object classification, semantic voxel labeling, and CAD model retrieval. The dataset is freely available at this http URL

##### Abstract (translated by Google)
利用有监督的深度学习方法的一个关键要求是可以使用大型的带标签的数据集。不幸的是，在RGB-D场景理解的情况下，只有很少的数据是可用的 - 当前数据集涵盖了一小部分场景视图，并且具有有限的语义注释。为了解决这个问题，我们引入了ScanNet，这是一个RGB-D视频数据集，其中包含用3D相机姿态，表面重构和语义分割标注的1513个场景中的2.5M视图。为了收集这些数据，我们设计了一个易于使用和可扩展的RGB-D采集系统，其中包括自动表面重建和众包语义标注。我们表明，使用这些数据有助于在几个三维场景理解任务（包括3D对象分类，语义体素标记和CAD模型检索）上实现最先进的性能。这个数据集可以在这个http URL上免费获得

##### URL
[https://arxiv.org/abs/1702.04405](https://arxiv.org/abs/1702.04405)

##### PDF
[https://arxiv.org/pdf/1702.04405](https://arxiv.org/pdf/1702.04405)

