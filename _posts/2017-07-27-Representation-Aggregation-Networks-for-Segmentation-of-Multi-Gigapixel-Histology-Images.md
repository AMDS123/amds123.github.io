---
layout: post
title: "Representation-Aggregation Networks for Segmentation of Multi-Gigapixel Histology Images"
date: 2017-07-27 10:56:58
categories: arXiv_CV
tags: arXiv_CV Segmentation CNN Represenation_Learning RNN
author: Abhinav Agarwalla, Muhammad Shaban, Nasir M. Rajpoot
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional Neural Network (CNN) models have become the state-of-the-art for most computer vision tasks with natural images. However, these are not best suited for multi-gigapixel resolution Whole Slide Images (WSIs) of histology slides due to large size of these images. Current approaches construct smaller patches from WSIs which results in the loss of contextual information. We propose to capture the spatial context using novel Representation-Aggregation Network (RAN) for segmentation purposes, wherein the first network learns patch-level representation and the second network aggregates context from a grid of neighbouring patches. We can use any CNN for representation learning, and can utilize CNN or 2D-Long Short Term Memory (2D-LSTM) for context-aggregation. Our method significantly outperformed conventional patch-based CNN approaches on segmentation of tumour in WSIs of breast cancer tissue sections.

##### Abstract (translated by Google)
卷积神经网络（CNN）模型已经成为大多数具有自然图像的计算机视觉任务的最新技术。然而，由于这些图像的大尺寸，这些并不是最适合用于多千兆像素分辨率整体幻灯片图像（WSI）的组织学幻灯片。目前的方法从WSI构造较小的补丁，导致上下文信息的丢失。我们建议采用新颖的表示 - 聚集网络（RAN）捕获空间上下文用于分段目的，其中第一个网络学习补丁级表示，第二个网络从相邻补丁网格聚合上下文。我们可以使用任何CNN进行表示学习，并且可以利用CNN或2D-Long Short Term Memory（2D-LSTM）进行上下文聚合。我们的方法显着优于传统的基于贴片的CNN方法在乳腺癌组织切片的WSI中分割肿瘤。

##### URL
[https://arxiv.org/abs/1707.08814](https://arxiv.org/abs/1707.08814)

##### PDF
[https://arxiv.org/pdf/1707.08814](https://arxiv.org/pdf/1707.08814)

