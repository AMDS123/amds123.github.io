---
layout: post
title: "Reliable Decision Support using Counterfactual Models"
date: 2018-02-01 13:40:16
categories: arXiv_AI
tags: arXiv_AI Face Prediction Relation
author: Peter Schulam, Suchi Saria
mathjax: true
---

* content
{:toc}

##### Abstract
Decision-makers are faced with the challenge of estimating what is likely to happen when they take an action. For instance, if I choose not to treat this patient, are they likely to die? Practitioners commonly use supervised learning algorithms to fit predictive models that help decision-makers reason about likely future outcomes, but we show that this approach is unreliable, and sometimes even dangerous. The key issue is that supervised learning algorithms are highly sensitive to the policy used to choose actions in the training data, which causes the model to capture relationships that do not generalize. We propose using a different learning objective that predicts counterfactuals instead of predicting outcomes under an existing action policy as in supervised learning. To support decision-making in temporal settings, we introduce the Counterfactual Gaussian Process (CGP) to predict the counterfactual future progression of continuous-time trajectories under sequences of future actions. We demonstrate the benefits of the CGP on two important decision-support tasks: risk prediction and "what if?" reasoning for individualized treatment planning.

##### Abstract (translated by Google)
决策者面临着估计他们采取行动时可能发生的事情的挑战。例如，如果我选择不治疗这个病人，他们是否可能死亡？从业者通常使用监督学习算法来拟合预测模型，以帮助决策者推断未来的可能结果，但是我们表明这种方法是不可靠的，有时甚至是危险的。关键问题是监督式学习算法对用于选择训练数据中的动作的策略高度敏感，这使得模型捕捉到不能概括的关系。我们建议使用不同的学习目标来预测反事实，而不是像监督式学习那样在现有的行动政策下预测结果。为了支持时间设置中的决策，我们引入反事实高斯过程（CGP）来预测未来行为序列下连续时间轨迹的反事实未来进展。我们在两个重要的决策支持任务中证明了CGP的好处：风险预测和“如果？推理个性化的治疗计划。

##### URL
[http://arxiv.org/abs/1703.10651](http://arxiv.org/abs/1703.10651)

##### PDF
[http://arxiv.org/pdf/1703.10651](http://arxiv.org/pdf/1703.10651)

