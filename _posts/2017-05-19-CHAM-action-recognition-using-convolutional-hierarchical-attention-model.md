---
layout: post
title: "CHAM: action recognition using convolutional hierarchical attention model"
date: 2017-05-19 06:11:26
categories: arXiv_CV
tags: arXiv_CV Image_Caption Attention Caption Action_Recognition CNN RNN Recognition
author: Shiyang Yan, Jeremy S. Smith, Wenjin Lu, Bailing Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, the soft attention mechanism, which was originally proposed in language processing, has been applied in computer vision tasks like image captioning. This paper presents improvements to the soft attention model by combining a convolutional LSTM with a hierarchical system architecture to recognize action categories in videos. We call this model the Convolutional Hierarchical Attention Model (CHAM). The model applies a convolutional operation inside the LSTM cell and an attention map generation process to recognize actions. The hierarchical architecture of this model is able to explicitly reason on multi-granularities of action categories. The proposed architecture achieved improved results on three publicly available datasets: the UCF sports dataset, the Olympic sports dataset and the HMDB51 dataset.

##### Abstract (translated by Google)
最近，最初在语言处理中提出的软关注机制已经应用于计算机视觉任务，如图像字幕。本文通过将卷积LSTM与分层系统架构相结合来识别视频中的动作类别，从而对软注意模型进行了改进。我们将此模型称为卷积分层注意模型（CHAM）。该模型在LSTM单元内应用卷积运算，并在注意图生成过程中识别动作。该模型的分层体系结构能够明确推理多粒度的动作类别。所提出的架构在三个公开可用的数据集上实现了改进的结果：UCF体育数据集，奥林匹克体育数据集和HMDB51数据集。

##### URL
[https://arxiv.org/abs/1705.03146](https://arxiv.org/abs/1705.03146)

##### PDF
[https://arxiv.org/pdf/1705.03146](https://arxiv.org/pdf/1705.03146)

