---
layout: post
title: "Neural Generation of Diverse Questions using Answer Focus, Contextual and Linguistic Features"
date: 2018-09-07 18:47:20
categories: arXiv_AI
tags: arXiv_AI Attention Embedding Recognition
author: Vrindavan Harrison, Marilyn Walker
mathjax: true
---

* content
{:toc}

##### Abstract
Question Generation is the task of automatically creating questions from textual input. In this work we present a new Attentional Encoder--Decoder Recurrent Neural Network model for automatic question generation. Our model incorporates linguistic features and an additional sentence embedding to capture meaning at both sentence and word levels. The linguistic features are designed to capture information related to named entity recognition, word case, and entity coreference resolution. In addition our model uses a copying mechanism and a special answer signal that enables generation of numerous diverse questions on a given sentence. Our model achieves state of the art results of 19.98 Bleu_4 on a benchmark Question Generation dataset, outperforming all previously published results by a significant margin. A human evaluation also shows that these added features improve the quality of the generated questions.

##### Abstract (translated by Google)
问题生成是从文本输入自动创建问题的任务。在这项工作中，我们提出了一个新的注意编码器 - 解码器回归神经网络模型，用于自动生成问题。我们的模型结合了语言特征和一个额外的句子嵌入来捕捉句子和单词级别的意义。语言特征旨在捕获与命名实体识别，单词大小写和实体共指解析相关的信息。此外，我们的模型使用复制机制和特殊答案信号，可以在给定句子上生成许多不同的问题。我们的模型在基准问题生成数据集上实现了19.98 Bleu_4的最新结果，优于所有先前公布的结果。人工评估还表明，这些增加的功能可以提高生成的问题的质量。

##### URL
[http://arxiv.org/abs/1809.02637](http://arxiv.org/abs/1809.02637)

##### PDF
[http://arxiv.org/pdf/1809.02637](http://arxiv.org/pdf/1809.02637)

