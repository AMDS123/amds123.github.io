---
layout: post
title: "TIP: Typifying the Interpretability of Procedures"
date: 2017-12-26 16:12:02
categories: arXiv_AI
tags: arXiv_AI
author: Amit Dhurandhar, Vijay Iyengar, Ronny Luss, Karthikeyan Shanmugam
mathjax: true
---

* content
{:toc}

##### Abstract
We provide a novel notion of what it means to be interpretable, looking past the usual association with human understanding. Our key insight is that interpretability is not an absolute concept and so we define it relative to a target model, which may or may not be a human. We define a framework that allows for comparing interpretable procedures by linking it to important practical aspects such as accuracy and robustness. We characterize many of the current state-of-the-art interpretable methods in our framework portraying its general applicability. Finally, principled interpretable strategies are proposed and empirically evaluated on synthetic data, as well as on the largest public olfaction dataset that was made recently available \cite{olfs}. We also experiment on MNIST with a simple target model and different oracle models of varying complexity. This leads to the insight that the improvement in the target model is not only a function of the oracle models performance, but also its relative complexity with respect to the target model.

##### Abstract (translated by Google)
我们提供了一个新的概念来表达可以解释的意思，从过去与人类理解之间的平常关系看。我们关键的洞察力是可解释性不是一个绝对的概念，所以我们将它定义为一个可能或可能不是人类的目标模型。我们定义了一个框架，通过将可解释的过程与准确性和健壮性等重要的实际方面联系起来，来比较可解释的过程。我们在描述其一般适用性的框架中描述了许多当前最先进的可解释方法。最后，提出了原则性的可解释策略，并对合成数据以及最近公布的最大的公共嗅觉数据集进行了实证评估\ cite {olfs}。我们还对MNIST进行了一个简单的目标模型和不同复杂度的不同预言模型的实验。这导致了目标模型的改进不仅是预言模型性能的一个功能，而且它相对于目标模型的相对复杂性。

##### URL
[http://arxiv.org/abs/1706.02952](http://arxiv.org/abs/1706.02952)

##### PDF
[http://arxiv.org/pdf/1706.02952](http://arxiv.org/pdf/1706.02952)

