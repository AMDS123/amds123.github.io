---
layout: post
title: "EG-GAN: Cross-Language Emotion Gain Synthesis based on Cycle-Consistent Adversarial Networks"
date: 2019-05-27 12:41:36
categories: arXiv_CL
tags: arXiv_CL Adversarial GAN
author: Xiaoqi Jia, Jianwei Tai, Qingjia Huang, Yakai Li, Weijuan Zhang, Haichao Du
mathjax: true
---

* content
{:toc}

##### Abstract
Despite remarkable contributions from existing emotional speech synthesizers, we find that these methods are based on Text-to-Speech system or limited by aligned speech pairs, which suffered from pure emotion gain synthesis. Meanwhile, few studies have discussed the cross-language generalization ability of above methods to cope with the task of emotional speech synthesis in various languages. We propose a cross-language emotion gain synthesis method named EG-GAN which can learn a language-independent mapping from source emotion domain to target emotion domain in the absence of paired speech samples. EG-GAN is based on cycle-consistent generation adversarial network with a gradient penalty and an auxiliary speaker discriminator. The domain adaptation is introduced to implement the rapid migrating and sharing of emotional gains among different languages. The experiment results show that our method can efficiently synthesize high quality emotional speech from any source speech for given emotion categories, without the limitation of language differences and aligned speech pairs.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.11173](http://arxiv.org/abs/1905.11173)

##### PDF
[http://arxiv.org/pdf/1905.11173](http://arxiv.org/pdf/1905.11173)

