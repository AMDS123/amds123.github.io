---
layout: post
title: "Learning for New Visual Environments with Limited Labels"
date: 2019-01-25 20:49:35
categories: arXiv_CV
tags: arXiv_CV
author: Pengkai Zhu, Hanxiao Wang, Venkatesh Saligrama
mathjax: true
---

* content
{:toc}

##### Abstract
In computer vision applications, such as domain adaptation (DA), few shot learning (FSL) and zero-shot learning (ZSL), we encounter new objects and environments, for which insufficient examples exist to allow for training "models from scratch," and methods that adapt existing models, trained on the presented training environment, to the new scenario are required. We propose a novel visual attribute encoding method that encodes each image as a low-dimensional probability vector composed of prototypical part-type probabilities. The prototypes are learnt to be representative of all training data. At test-time we utilize this encoding as an input to a classifier. At test-time we freeze the encoder and only learn/adapt the classifier component to limited annotated labels in FSL; new semantic attributes in ZSL. We conduct extensive experiments on benchmark datasets. Our method outperforms state-of-art methods trained for the specific contexts (ZSL, FSL, DA).

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1901.09079](http://arxiv.org/abs/1901.09079)

##### PDF
[http://arxiv.org/pdf/1901.09079](http://arxiv.org/pdf/1901.09079)

