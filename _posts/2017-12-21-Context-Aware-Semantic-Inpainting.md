---
layout: post
title: "Context-Aware Semantic Inpainting"
date: 2017-12-21 03:19:00
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN CNN
author: Haofeng Li, Guanbin Li, Liang Lin, Yizhou Yu
mathjax: true
---

* content
{:toc}

##### Abstract
Recently image inpainting has witnessed rapid progress due to generative adversarial networks (GAN) that are able to synthesize realistic contents. However, most existing GAN-based methods for semantic inpainting apply an auto-encoder architecture with a fully connected layer, which cannot accurately maintain spatial information. In addition, the discriminator in existing GANs struggle to understand high-level semantics within the image context and yield semantically consistent content. Existing evaluation criteria are biased towards blurry results and cannot well characterize edge preservation and visual authenticity in the inpainting results. In this paper, we propose an improved generative adversarial network to overcome the aforementioned limitations. Our proposed GAN-based framework consists of a fully convolutional design for the generator which helps to better preserve spatial structures and a joint loss function with a revised perceptual loss to capture high-level semantics in the context. Furthermore, we also introduce two novel measures to better assess the quality of image inpainting results. Experimental results demonstrate that our method outperforms the state of the art under a wide range of criteria.

##### Abstract (translated by Google)
近年来，由于能够综合现实内容的生成对抗网络（GAN），图像修复已经取得了迅速的进展。然而，大多数现有的基于GAN的语义修补方法采用的是全连接层的自动编码体系结构，无法准确地维护空间信息。另外，现有GAN中的鉴别器在图像上下文中难于理解高级语义，并产生语义上一致的内容。现有的评价标准偏向模糊的结果，不能很好地刻画边缘保存和视觉真实性。在本文中，我们提出了一个改进的生成对抗网络来克服上述限制。我们提出的基于GAN的框架由发生器的完全卷积设计组成，这有助于更好地保留空间结构和联合损失函数，修正感知损失以捕获上下文中的高级语义。此外，我们还介绍了两个新的措施，以更好地评估图像修复效果的质量。实验结果表明，我们的方法在广泛的标准下优于现有技术。

##### URL
[http://arxiv.org/abs/1712.07778](http://arxiv.org/abs/1712.07778)

##### PDF
[http://arxiv.org/pdf/1712.07778](http://arxiv.org/pdf/1712.07778)

