---
layout: post
title: "Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning"
date: 2017-12-20 02:50:20
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Tianmin Shu, Caiming Xiong, Richard Socher
mathjax: true
---

* content
{:toc}

##### Abstract
Learning policies for complex tasks that require multiple different skills is a major challenge in reinforcement learning (RL). It is also a requirement for its deployment in real-world scenarios. This paper proposes a novel framework for efficient multi-task reinforcement learning. Our framework trains agents to employ hierarchical policies that decide when to use a previously learned policy and when to learn a new skill. This enables agents to continually acquire new skills during different stages of training. Each learned task corresponds to a human language description. Because agents can only access previously learned skills through these descriptions, the agent can always provide a human-interpretable description of its choices. In order to help the agent learn the complex temporal dependencies necessary for the hierarchical policy, we provide it with a stochastic temporal grammar that modulates when to rely on previously learned skills and when to execute new skills. We validate our approach on Minecraft games designed to explicitly test the ability to reuse previously learned skills while simultaneously learning new skills.

##### Abstract (translated by Google)
针对复杂任务需要多种不同技能的学习策略是强化学习（RL）中的主要挑战。这也是在真实情况下部署的要求。本文提出了一个高效的多任务强化学习的新框架。我们的框架训练代理人采用分级政策，决定何时使用以前学过的政策，以及何时学习新技能。这使得代理商可以在不同的培训阶段不断获得新的技能。每个学习的任务对应于人类语言描述。因为代理人只能通过这些描述访问以前学过的技能，所以代理人总是可以提供一个人类可以解释的选择的描述。为了帮助代理人学习分层策略所需的复杂的时间依赖关系，我们提供了一个随机的时间语法来调整何时依靠先前学过的技能以及何时执行新的技能。我们验证了我们的Minecraft游戏方法，旨在明确测试重复使用以前学过的技能的能力，同时学习新的技能。

##### URL
[http://arxiv.org/abs/1712.07294](http://arxiv.org/abs/1712.07294)

##### PDF
[http://arxiv.org/pdf/1712.07294](http://arxiv.org/pdf/1712.07294)

