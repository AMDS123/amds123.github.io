---
layout: post
title: "Driver Gaze Region Estimation Without Using Eye Movement"
date: 2016-03-01 17:21:25
categories: arXiv_CV
tags: arXiv_CV Attention Tracking
author: Lex Fridman, Philipp Langhans, Joonbum Lee, Bryan Reimer
mathjax: true
---

* content
{:toc}

##### Abstract
Automated estimation of the allocation of a driver's visual attention may be a critical component of future Advanced Driver Assistance Systems. In theory, vision-based tracking of the eye can provide a good estimate of gaze location. In practice, eye tracking from video is challenging because of sunglasses, eyeglass reflections, lighting conditions, occlusions, motion blur, and other factors. Estimation of head pose, on the other hand, is robust to many of these effects, but cannot provide as fine-grained of a resolution in localizing the gaze. However, for the purpose of keeping the driver safe, it is sufficient to partition gaze into regions. In this effort, we propose a system that extracts facial features and classifies their spatial configuration into six regions in real-time. Our proposed method achieves an average accuracy of 91.4% at an average decision rate of 11 Hz on a dataset of 50 drivers from an on-road study.

##### Abstract (translated by Google)
自动估算驾驶员视觉注意力的分配可能是未来高级驾驶员辅助系统的重要组成部分。理论上，基于视觉的眼睛跟踪可以提供对注视位置的良好估计。在实践中，由于太阳镜，镜片反射，照明条件，遮挡，运动模糊和其他因素，视频的眼睛跟踪是具有挑战性的。另一方面，头部姿势的估计对于许多这些效果是稳健的，但是不能提供精确定位凝视的分辨率。但是，为了保证驾驶员的安全，将注意力分成区域就足够了。在这项工作中，我们提出一个系统，提取面部特征，并将其空间配置分类为六个区域的实时。我们提出的方法在一个50人的道路研究数据集上以11Hz的平均决策率达到91.4％的平均准确度。

##### URL
[https://arxiv.org/abs/1507.04760](https://arxiv.org/abs/1507.04760)

##### PDF
[https://arxiv.org/pdf/1507.04760](https://arxiv.org/pdf/1507.04760)

