---
layout: post
title: "An Analysis of Visual Question Answering Algorithms"
date: 2017-09-13 18:56:45
categories: arXiv_CV
tags: arXiv_CV QA Attention GAN VQA
author: Kushal Kafle, Christopher Kanan
mathjax: true
---

* content
{:toc}

##### Abstract
In visual question answering (VQA), an algorithm must answer text-based questions about images. While multiple datasets for VQA have been created since late 2014, they all have flaws in both their content and the way algorithms are evaluated on them. As a result, evaluation scores are inflated and predominantly determined by answering easier questions, making it difficult to compare different methods. In this paper, we analyze existing VQA algorithms using a new dataset. It contains over 1.6 million questions organized into 12 different categories. We also introduce questions that are meaningless for a given image to force a VQA system to reason about image content. We propose new evaluation schemes that compensate for over-represented question-types and make it easier to study the strengths and weaknesses of algorithms. We analyze the performance of both baseline and state-of-the-art VQA models, including multi-modal compact bilinear pooling (MCB), neural module networks, and recurrent answering units. Our experiments establish how attention helps certain categories more than others, determine which models work better than others, and explain how simple models (e.g. MLP) can surpass more complex models (MCB) by simply learning to answer large, easy question categories.

##### Abstract (translated by Google)
在视觉问答（VQA）中，算法必须回答有关图像的基于文本的问题。虽然自2014年底以来已经创建了多个VQA数据集，但它们的内容和算法评估方式都存在缺陷。结果，评估分数被夸大并且主要通过回答更容易的问题来确定，使得难以比较不同的方法。在本文中，我们使用新数据集分析现有的VQA算法。它包含超过160万个问题，分为12个不同的类别。我们还引入了对给定图像毫无意义的问题，以迫使VQA系统推断图像内容。我们提出新的评估方案，以补偿过度代表的问题类型，并使研究算法的优势和劣势更容易。我们分析了基线和最先进的VQA模型的性能，包括多模式紧凑双线性池（MCB），神经模块网络和循环应答单元。我们的实验确定了注意力如何比其他类别更有助于某些类别，确定哪些模型比其他类型更好，并解释简单模型（例如MLP）如何通过简单地学习回答大而简单的问题类别来超越更复杂的模型（MCB）。

##### URL
[https://arxiv.org/abs/1703.09684](https://arxiv.org/abs/1703.09684)

##### PDF
[https://arxiv.org/pdf/1703.09684](https://arxiv.org/pdf/1703.09684)

