---
layout: post
title: "Exploiting Images for Video Recognition with Hierarchical Generative Adversarial Networks"
date: 2018-05-11 13:20:04
categories: arXiv_CV
tags: arXiv_CV Adversarial Knowledge GAN Deep_Learning Recognition
author: Feiwu Yu, Xinxiao Wu, Yuchao Sun, Lixin Duan
mathjax: true
---

* content
{:toc}

##### Abstract
Existing deep learning methods of video recognition usually require a large number of labeled videos for training. But for a new task, videos are often unlabeled and it is also time-consuming and labor-intensive to annotate them. Instead of human annotation, we try to make use of existing fully labeled images to help recognize those videos. However, due to the problem of domain shifts and heterogeneous feature representations, the performance of classifiers trained on images may be dramatically degraded for video recognition tasks. In this paper, we propose a novel method, called Hierarchical Generative Adversarial Networks (HiGAN), to enhance recognition in videos (i.e., target domain) by transferring knowledge from images (i.e., source domain). The HiGAN model consists of a \emph{low-level} conditional GAN and a \emph{high-level} conditional GAN. By taking advantage of these two-level adversarial learning, our method is capable of learning a domain-invariant feature representation of source images and target videos. Comprehensive experiments on two challenging video recognition datasets (i.e. UCF101 and HMDB51) demonstrate the effectiveness of the proposed method when compared with the existing state-of-the-art domain adaptation methods.

##### Abstract (translated by Google)
视频识别的现有深度学习方法通​​常需要大量标记视频进行训练。但对于一项新任务，视频往往没有标签，而且注释它们也耗费时间和劳动力。我们试图利用现有的完全标记的图像来帮助识别这些视频，而不是人类注释。然而，由于域转移和异构特征表示的问题，对图像进行训练的分类器的性能可能会显着降低以用于视频识别任务。在本文中，我们提出了一种称为分层生成对抗网络（HiGAN）的新方法，通过从图像（即源域）传输知识来增强视频（即，目标域）中的识别。 HiGAN模型由一个\ emph {低级}条件GAN和一个\ emph {高级}条件GAN组成。通过利用这些两级对抗学习，我们的方法能够学习源图像和目标视频的域不变特征表示。对两个具有挑战性的视频识别数据集（即UCF101和HMDB51）进行的全面实验证明了与现有的最先进的领域自适应方法相比所提出方法的有效性。

##### URL
[http://arxiv.org/abs/1805.04384](http://arxiv.org/abs/1805.04384)

##### PDF
[http://arxiv.org/pdf/1805.04384](http://arxiv.org/pdf/1805.04384)

