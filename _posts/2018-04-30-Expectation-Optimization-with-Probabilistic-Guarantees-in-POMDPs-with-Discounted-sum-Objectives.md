---
layout: post
title: "Expectation Optimization with Probabilistic Guarantees in POMDPs with Discounted-sum Objectives"
date: 2018-04-30 11:52:15
categories: arXiv_AI
tags: arXiv_AI Optimization
author: Krishnendu Chatterjee, Adrián Elgyütt, Petr Novotný, Owen Rouillé
mathjax: true
---

* content
{:toc}

##### Abstract
Partially-observable Markov decision processes (POMDPs) with discounted-sum payoff are a standard framework to model a wide range of problems related to decision making under uncertainty. Traditionally, the goal has been to obtain policies that optimize the expectation of the discounted-sum payoff. A key drawback of the expectation measure is that even low probability events with extreme payoff can significantly affect the expectation, and thus the obtained policies are not necessarily risk-averse. An alternate approach is to optimize the probability that the payoff is above a certain threshold, which allows obtaining risk-averse policies, but ignores optimization of the expectation. We consider the expectation optimization with probabilistic guarantee (EOPG) problem, where the goal is to optimize the expectation ensuring that the payoff is above a given threshold with at least a specified probability. We present several results on the EOPG problem, including the first algorithm to solve it.

##### Abstract (translated by Google)
具有贴现收益的部分可观察马尔可夫决策过程（POMDPs）是一个标准框架，用于模拟与不确定条件下的决策有关的各种问题。传统上，目标是获得优化折现收益预期的政策。期望值的一个主要缺点是，即使是极低收益的低概率事件也会显着影响期望值，因此获得的策略不一定是风险厌恶的。另一种方法是优化回报超过某个阈值的概率，这允许获取风险规避策略，但忽略期望的优化。我们考虑带有概率保证（EOPG）问题的期望优化，其目标是优化期望，确保支付至少以特定概率高于给定阈值。我们在EOPG问题上提出了几个结果，包括解决它的第一个算法。

##### URL
[https://arxiv.org/abs/1804.10601](https://arxiv.org/abs/1804.10601)

##### PDF
[https://arxiv.org/pdf/1804.10601](https://arxiv.org/pdf/1804.10601)

