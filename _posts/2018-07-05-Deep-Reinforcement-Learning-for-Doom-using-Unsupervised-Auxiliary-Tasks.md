---
layout: post
title: "Deep Reinforcement Learning for Doom using Unsupervised Auxiliary Tasks"
date: 2018-07-05 12:30:15
categories: arXiv_AI
tags: arXiv_AI Sparse Reinforcement_Learning
author: Georgios Papoudakis, Kyriakos C. Chatzidimitriou, Pericles A. Mitkas
mathjax: true
---

* content
{:toc}

##### Abstract
Recent developments in deep reinforcement learning have enabled the creation of agents for solving a large variety of games given a visual input. These methods have been proven successful for 2D games, like the Atari games, or for simple tasks, like navigating in mazes. It is still an open question, how to address more complex environments, in which the reward is sparse and the state space is huge. In this paper we propose a divide and conquer deep reinforcement learning solution and we test our agent in the first person shooter (FPS) game of Doom. Our work is based on previous works in deep reinforcement learning and in Doom agents. We also present how our agent is able to perform better in unknown environments compared to a state of the art reinforcement learning algorithm.

##### Abstract (translated by Google)
深度强化学习的最新发展使得能够创建代理以在给定视觉输入的情况下解决各种各样的游戏。这些方法已被证明对于2D游戏（如Atari游戏）或简单任务（如在迷宫中导航）都是成功的。这仍然是一个悬而未决的问题，如何解决更复杂的环境，其中奖励稀少，国家空间巨大。在本文中，我们提出了一个划分和征服深度强化学习解决方案，我们在Doom的第一人称射击游戏（FPS）中测试我们的经纪人。我们的工作基于以前深度强化学习和Doom代理的工作。我们还介绍了与最先进的强化学习算法相比，我们的代理如何在未知环境中表现更好。

##### URL
[http://arxiv.org/abs/1807.01960](http://arxiv.org/abs/1807.01960)

##### PDF
[http://arxiv.org/pdf/1807.01960](http://arxiv.org/pdf/1807.01960)

