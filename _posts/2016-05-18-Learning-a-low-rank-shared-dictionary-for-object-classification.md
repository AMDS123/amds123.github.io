---
layout: post
title: "Learning a low-rank shared dictionary for object classification"
date: 2016-05-18 00:36:39
categories: arXiv_CV
tags: arXiv_CV Sparse Classification
author: Tiep H. Vu, Vishal Monga
mathjax: true
---

* content
{:toc}

##### Abstract
Despite the fact that different objects possess distinct class-specific features, they also usually share common patterns. Inspired by this observation, we propose a novel method to explicitly and simultaneously learn a set of common patterns as well as class-specific features for classification. Our dictionary learning framework is hence characterized by both a shared dictionary and particular (class-specific) dictionaries. For the shared dictionary, we enforce a low-rank constraint, i.e. claim that its spanning subspace should have low dimension and the coefficients corresponding to this dictionary should be similar. For the particular dictionaries, we impose on them the well-known constraints stated in the Fisher discrimination dictionary learning (FDDL). Further, we propose a new fast and accurate algorithm to solve the sparse coding problems in the learning step, accelerating its convergence. The said algorithm could also be applied to FDDL and its extensions. Experimental results on widely used image databases establish the advantages of our method over state-of-the-art dictionary learning methods.

##### Abstract (translated by Google)
尽管不同的物体具有不同的类别特征，但它们通常也具有共同的模式。受这一观察的启发，我们提出了一种新颖的方法来明确地同时学习一组通用模式以及用于分类的类别特征。我们的字典学习框架的特点是共享字典和特定的（特定于类的）字典。对于共享字典，我们强制执行一个低秩约束，即声明它的生成子空间应该具有低维度，并且对应于这个字典的系数应该是相似的。对于特定的字典，我们强加给他们在Fisher判别字典学习（FDDL）中陈述的众所周知的限制。此外，我们提出了一种快速而准确的算法来解决学习步骤中的稀疏编码问题，加速其收敛性。所述算法也可以应用于FDDL及其扩展。广泛使用的图像数据库的实验结果证明了我们的方法优于最先进的字典学习方法的优点。

##### URL
[https://arxiv.org/abs/1602.00310](https://arxiv.org/abs/1602.00310)

##### PDF
[https://arxiv.org/pdf/1602.00310](https://arxiv.org/pdf/1602.00310)

