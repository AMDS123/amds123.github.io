---
layout: post
title: "Consequentialist conditional cooperation in social dilemmas with imperfect information"
date: 2018-03-02 14:54:33
categories: arXiv_AI
tags: arXiv_AI Face Reinforcement_Learning
author: Alexander Peysakhovich, Adam Lerer
mathjax: true
---

* content
{:toc}

##### Abstract
Social dilemmas, where mutual cooperation can lead to high payoffs but participants face incentives to cheat, are ubiquitous in multi-agent interaction. We wish to construct agents that cooperate with pure cooperators, avoid exploitation by pure defectors, and incentivize cooperation from the rest. However, often the actions taken by a partner are (partially) unobserved or the consequences of individual actions are hard to predict. We show that in a large class of games good strategies can be constructed by conditioning one's behavior solely on outcomes (ie. one's past rewards). We call this consequentialist conditional cooperation. We show how to construct such strategies using deep reinforcement learning techniques and demonstrate, both analytically and experimentally, that they are effective in social dilemmas beyond simple matrix games. We also show the limitations of relying purely on consequences and discuss the need for understanding both the consequences of and the intentions behind an action.

##### Abstract (translated by Google)
社交困境，相互合作可能导致高回报，但参与者面临欺骗的诱因，在多主体互动中无处不在。我们希望建立与纯合作者合作的代理商，避免纯粹背叛者的剥削，并激励其他合作者。但是，通常情况下，合作伙伴采取的行动（部分）不被观察到，或者个人行为的后果难以预测。我们证明，在一大类游戏中，可以通过仅仅根据结果（即过去的回报）来调节自己的行为来构建好的策略。我们称之为后果性有条件合作。我们展示了如何使用深度强化学习技术来构建这样的策略，并且通过分析和实验证明，它们在简单矩阵游戏之外的社会困境中是有效的。我们还展示了单纯依靠后果的局限性，并讨论了理解行动背后的原因和意图的必要性。

##### URL
[http://arxiv.org/abs/1710.06975](http://arxiv.org/abs/1710.06975)

##### PDF
[http://arxiv.org/pdf/1710.06975](http://arxiv.org/pdf/1710.06975)

