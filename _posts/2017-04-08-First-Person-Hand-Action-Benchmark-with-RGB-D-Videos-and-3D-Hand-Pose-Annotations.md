---
layout: post
title: "First-Person Hand Action Benchmark with RGB-D Videos and 3D Hand Pose Annotations"
date: 2017-04-08 09:45:12
categories: arXiv_CV
tags: arXiv_CV Knowledge Pose_Estimation Action_Recognition Recognition
author: Guillermo Garcia-Hernando, Shanxin Yuan, Seungryul Baek, Tae-Kyun Kim
mathjax: true
---

* content
{:toc}

##### Abstract
In this work we study the use of 3D hand poses to recognize first-person hand actions interacting with 3D objects. Towards this goal, we collected RGB-D video sequences of more than 100K frames of 45 daily hand action categories, involving 25 different objects in several hand grasp configurations. To obtain high quality hand pose annotations from real sequences, we used our own mo-cap system that automatically infers the location of each of the 21 joints of the hand via 6 magnetic sensors on the finger tips and the inverse-kinematics of a hand model. To the best of our knowledge, this is the first benchmark for RGB-D hand action sequences with 3D hand poses. Additionally, we recorded the 6D (i.e. 3D rotations and locations) object poses and provide 3D object models for a subset of hand-object interaction sequences. We present extensive experimental evaluations of RGB-D and pose-based action recognition by 18 baselines/state-of-the-art. The impact of using appearance features, poses and their combinations are measured, and the different training/testing protocols including cross-persons are evaluated. Finally, we assess how ready the current hand pose estimation is when hands are severely occluded by objects in egocentric views and its influence on action recognition. From the results, we see clear benefits of using hand pose as a cue for action recognition compared to other data modalities. Our dataset and experiments can be of interest to communities of 6D object pose, robotics, and 3D hand pose estimation as well as action recognition.

##### Abstract (translated by Google)
在这项工作中，我们研究了使用3D手势来识别与3D对象交互的第一人称手势动作。为了实现这一目标，我们收集了45个日常手部类别的超过100K帧的RGB-D视频序列，涉及25个不同的物体，以几种手形配置。为了从实际序列中获得高质量的手部姿态注释，我们使用了我们自己的手掌模型系统，通过指尖上的6个磁性传感器和手部模型的反向运动自动推断手部每个21个关节的位置。据我们所知，这是3D手形的RGB-D手部动作序列的第一个基准。另外，我们记录了6D（即，3D旋转和位置）对象姿势并且为手对象交互序列的子集提供了3D对象模型。我们提出了广泛的RGB-D实验评估和基于姿态的行动识别18个基线/最先进的。测量使用外貌特征，姿势及其组合的影响，并评估包括跨人的不同训练/测试协议。最后，我们评估当前手姿态估计的准备情况是什么时候双手被以自我中心观点的对象严重遮挡以及它对动作识别的影响。从结果中，我们看到与其他数据模式相比，使用手部姿势作为行为识别提示的明显好处。我们的数据集和实验可能是6D对象姿态，机器人和3D手姿态估计以及动作识别的社区所感兴趣的。

##### URL
[https://arxiv.org/abs/1704.02463](https://arxiv.org/abs/1704.02463)

##### PDF
[https://arxiv.org/pdf/1704.02463](https://arxiv.org/pdf/1704.02463)

