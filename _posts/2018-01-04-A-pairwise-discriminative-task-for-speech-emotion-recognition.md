---
layout: post
title: "A pairwise discriminative task for speech emotion recognition"
date: 2018-01-04 03:30:47
categories: arXiv_SD
tags: arXiv_SD Face Recognition
author: Zheng Lian, Ya Li, Jianhua Tao, Jian Huang
mathjax: true
---

* content
{:toc}

##### Abstract
Speech emotion recognition is an important task in human-machine interaction. However, it faces many challenges such as the ambiguity of emotion expression and the lack of training samples. To solve these problems, we propose a novel 'Pairwise discriminative task', which attempts to learn the similarity and distinction between two audios rather than specific labels. In the task, pairwise audios are fed into audio encode networks to extract audio vectors, followed with discrimination networks behind to judge whether audios belong to the same emotion category or not. The system is optimized in an end-to-end manner to minimize the loss function, which cooperates cosine similarity loss and cross entropy loss together. To verify the performance of audio representation vectors extracted from the system, we test them on IEMOCAP database-a common evaluation corpus. We gain 56.33% unweighted accuracy on the test database, which surpasses above 5% compared with traditional end-to-end speech emotion recognition networks.

##### Abstract (translated by Google)
语音情感识别是人机交互中的一项重要任务。然而，它面临许多挑战，如情绪表达的模糊性和缺乏训练样本。为了解决这些问题，我们提出了一种新颖的“两两鉴别任务”，试图学习两个音频之间的相似性和区别性，而不是特定的标签。在这个任务中，将成对的音频输入到音频编码网络中以提取音频矢量，然后用判断网络来判断音频是否属于同一个情感类别。该系统以端到端的方式进行了优化，使损失函数最小化，将余弦相似性损失和交叉熵损失合在一起。为了验证从系统中提取的音频表示向量的性能，我们在IEMOCAP数据库（一个通用的评估语料库）上测试它们。与传统的端到端语音情感识别网络相比，我们在测试数据库上获得了56.33％的不加权精度，超过了5％以上。

##### URL
[http://arxiv.org/abs/1801.01237](http://arxiv.org/abs/1801.01237)

##### PDF
[http://arxiv.org/pdf/1801.01237](http://arxiv.org/pdf/1801.01237)

