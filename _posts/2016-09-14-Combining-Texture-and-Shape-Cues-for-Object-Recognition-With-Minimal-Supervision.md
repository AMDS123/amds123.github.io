---
layout: post
title: "Combining Texture and Shape Cues for Object Recognition With Minimal Supervision"
date: 2016-09-14 17:41:48
categories: arXiv_CV
tags: arXiv_CV Weakly_Supervised Classification Deep_Learning Prediction Detection Recognition
author: Xingchao Peng, Kate Saenko
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel approach to object classification and detection which requires minimal supervision and which combines visual texture cues and shape information learned from freely available unlabeled web search results. The explosion of visual data on the web can potentially make visual examples of almost any object easily accessible via web search. Previous unsupervised methods have utilized either large scale sources of texture cues from the web, or shape information from data such as crowdsourced CAD models. We propose a two-stream deep learning framework that combines these cues, with one stream learning visual texture cues from image search data, and the other stream learning rich shape information from 3D CAD models. To perform classification or detection for a novel image, the predictions of the two streams are combined using a late fusion scheme. We present experiments and visualizations for both tasks on the standard benchmark PASCAL VOC 2007 to demonstrate that texture and shape provide complementary information in our model. Our method outperforms previous web image based models, 3D CAD model based approaches, and weakly supervised models.

##### Abstract (translated by Google)
我们提出了一种新颖的方法来对象分类和检测，需要最小的监督，并结合视觉纹理线索和形状信息从免费提供的无标签的网页搜索结果学习。网络上可视化数据的爆炸式增长几乎可以通过网络搜索轻松访问任何对象。先前的无监督方法已经利用来自网络的大规模纹理提示源，或来自诸如众包CAD模型的数据的形状信息。我们提出了一个双流深度学习框架，结合这些线索，一个流从图像搜索数据学习视觉纹理提示，另一个流从3D CAD模型学习丰富的形状信息。为了对新颖图像进行分类或检测，使用后期融合方案来组合两个流的预测。我们在标准基准PASCAL VOC 2007上展示了这两个任务的实验和可视化，以证明纹理和形状在我们的模型中提供了补充信息。我们的方法胜过以前的基于Web图像的模型，基于3D CAD模型的方法和弱监督模型。

##### URL
[https://arxiv.org/abs/1609.04356](https://arxiv.org/abs/1609.04356)

##### PDF
[https://arxiv.org/pdf/1609.04356](https://arxiv.org/pdf/1609.04356)

