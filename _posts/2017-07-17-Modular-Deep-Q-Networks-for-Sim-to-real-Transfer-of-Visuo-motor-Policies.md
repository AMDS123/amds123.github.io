---
layout: post
title: "Modular Deep Q Networks for Sim-to-real Transfer of Visuo-motor Policies"
date: 2017-07-17 09:59:35
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning Deep_Learning
author: Fangyi Zhang, Jürgen Leitner, Michael Milford, Peter Corke
mathjax: true
---

* content
{:toc}

##### Abstract
While deep learning has had significant successes in computer vision thanks to the abundance of visual data, collecting sufficiently large real-world datasets for robot learning can be costly. To increase the practicality of these techniques on real robots, we propose a modular deep reinforcement learning method capable of transferring models trained in simulation to a real-world robotic task. We introduce a bottleneck between perception and control, enabling the networks to be trained independently, but then merged and fine-tuned in an end-to-end manner. On a canonical, planar visually-guided robot reaching task a fine-tuned accuracy of 1.6 pixels is achieved, a significant improvement over naive transfer (17.5 px), showing the potential for more complicated and broader applications. Our method provides a technique for more efficiently improving hand-eye coordination on a real robotic system without relying entirely on large real-world robot datasets.

##### Abstract (translated by Google)
虽然深度学习在计算机视觉方面取得了显着的成功，但由于大量的视觉数据，收集足够大的真实世界的机器人学习数据集可能是昂贵的。为了提高这些技术在真实机器人上的实用性，我们提出了一种模块化的深度强化学习方法，能够将模拟训练的模型转化为真实的机器人任务。我们在感知和控制之间引入了一个瓶颈，使得网络能够被独立地训练，然后以端到端的方式进行合并和微调。在规范的平面视觉引导机器人上，达到了1.6像素的微调精度，相对于朴素转换（17.5像素）有了显着的改善，显示了更复杂和更广泛应用的潜力。我们的方法提供了一种技术，可以更有效地提高真实机器人系统上的手眼协调能力，而不必完全依赖大型现实世界的机器人数据集。

##### URL
[https://arxiv.org/abs/1610.06781](https://arxiv.org/abs/1610.06781)

##### PDF
[https://arxiv.org/pdf/1610.06781](https://arxiv.org/pdf/1610.06781)

