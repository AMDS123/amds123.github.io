---
layout: post
title: "DAP3D-Net: Where, What and How Actions Occur in Videos?"
date: 2016-02-10 12:25:52
categories: arXiv_CV
tags: arXiv_CV CNN Classification
author: Li Liu, Yi Zhou, Ling Shao
mathjax: true
---

* content
{:toc}

##### Abstract
Action parsing in videos with complex scenes is an interesting but challenging task in computer vision. In this paper, we propose a generic 3D convolutional neural network in a multi-task learning manner for effective Deep Action Parsing (DAP3D-Net) in videos. Particularly, in the training phase, action localization, classification and attributes learning can be jointly optimized on our appearancemotion data via DAP3D-Net. For an upcoming test video, we can describe each individual action in the video simultaneously as: Where the action occurs, What the action is and How the action is performed. To well demonstrate the effectiveness of the proposed DAP3D-Net, we also contribute a new Numerous-category Aligned Synthetic Action dataset, i.e., NASA, which consists of 200; 000 action clips of more than 300 categories and with 33 pre-defined action attributes in two hierarchical levels (i.e., low-level attributes of basic body part movements and high-level attributes related to action motion). We learn DAP3D-Net using the NASA dataset and then evaluate it on our collected Human Action Understanding (HAU) dataset. Experimental results show that our approach can accurately localize, categorize and describe multiple actions in realistic videos.

##### Abstract (translated by Google)
在具有复杂场景的视频中进行动作解析是计算机视觉中一个有趣而又具有挑战性的任务在本文中，我们提出了一个通用的三维卷积神经网络的多任务学习方式，在视频中进行有效的深度解析（DAP3D-Net）。特别是在训练阶段，通过DAP3D-Net可以将动作定位，分类和属性学习等功能共同优化。对于即将到来的测试视频，我们可以将视频中的每个动作同时描述为：动作发生的地方，动作是什么以及动作是如何执行的。为了充分证明所提出的DAP3D-Net的有效性，我们还提供了一个新的众多类别的对齐合成行动数据集，即NASA，它由200个; （即基本身体部分运动的低级属性和与动作运动相关的高级属性）的300个类别的000个动作片段以及33个预定义的动作属性。我们使用NASA数据集学习DAP3D-Net，然后在收集的人类行动理解（HAU）数据集上对其进行评估。实验结果表明，我们的方法可以准确地定位，分类和描述现实视频中的多个动作。

##### URL
[https://arxiv.org/abs/1602.03346](https://arxiv.org/abs/1602.03346)

##### PDF
[https://arxiv.org/pdf/1602.03346](https://arxiv.org/pdf/1602.03346)

