---
layout: post
title: "Toward an Expressive Bipedal Robot: Variable Gait Synthesis and Validation in a Planar Model"
date: 2018-08-16 17:25:44
categories: arXiv_RO
tags: arXiv_RO Face Optimization
author: Umer Huzaifa, Catherine Maguire, Amy LaViers
mathjax: true
---

* content
{:toc}

##### Abstract
Humans are efficient, yet expressive in their motion. Human walking behaviors can be used to walk across a great variety of surfaces without falling and to communicate internal state to other humans through variable gait styles. This provides inspiration for creating similarly expressive bipedal robots. To this end, a framework is presented for stylistic gait generation in a compass-like under-actuated planar biped model. The gait design is done using model-based trajectory optimization with variable constraints. For a finite range of optimization parameters, a large set of 360 gaits can be generated for this model. In particular, step length and cost function are varied to produce distinct cyclic walking gaits. From these resulting gaits, 6 gaits are identified and labeled, using embodied movement analysis, with stylistic verbs that correlate with human activity, e.g., "lope" and "saunter". These labels have been validated by conducting user studies in Amazon Mechanical Turk and thus demonstrate that visually distinguishable, meaningful gaits are generated using this framework. This lays groundwork for creating a bipedal humanoid with variable socially competent movement profiles.

##### Abstract (translated by Google)
人类的行动效率高，但表现力强。人类行走行为可用于穿越各种各样的表面而不会摔倒，并通过可变步态样式将内部状态传达给其他人。这为创建具有类似表现力的双足机器人提供了灵感。为此，提出了一种框架，用于在类似罗盘的欠驱动平面Biped模型中生成风格步态。步态设计使用具有可变约束的基于模型的轨迹优化来完成。对于有限范围的优化参数，可以为该模型生成大量的360个步态。特别地，改变步长和成本函数以产生不同的循环步态步态。根据这些得到的步态，使用具体的运动分析识别和标记6个步态，其中使用与人类活动相关的风格动词，例如“lope”和“saunter”。这些标签已通过在Amazon Mechanical Turk进行用户研究得到验证，从而证明使用此框架可生成视觉上可区分的，有意义的步态。这为创建具有可变社会能力的运动轮廓的双足人形机器人奠定了基础。

##### URL
[http://arxiv.org/abs/1808.05594](http://arxiv.org/abs/1808.05594)

##### PDF
[http://arxiv.org/pdf/1808.05594](http://arxiv.org/pdf/1808.05594)

