---
layout: post
title: "Unsupervised Learning of Latent Physical Properties Using Perception-Prediction Networks"
date: 2018-07-24 17:28:27
categories: arXiv_AI
tags: arXiv_AI Inference Prediction
author: David Zheng, Vinson Luo, Jiajun Wu, Joshua B. Tenenbaum
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a framework for the completely unsupervised learning of latent object properties from their interactions: the perception-prediction network (PPN). Consisting of a perception module that extracts representations of latent object properties and a prediction module that uses those extracted properties to simulate system dynamics, the PPN can be trained in an end-to-end fashion purely from samples of object dynamics. The representations of latent object properties learned by PPNs not only are sufficient to accurately simulate the dynamics of systems comprised of previously unseen objects, but also can be translated directly into human-interpretable properties (e.g., mass, coefficient of restitution) in an entirely unsupervised manner. Crucially, PPNs also generalize to novel scenarios: their gradient-based training can be applied to many dynamical systems and their graph-based structure functions over systems comprised of different numbers of objects. Our results demonstrate the efficacy of graph-based neural architectures in object-centric inference and prediction tasks, and our model has the potential to discover relevant object properties in systems that are not yet well understood.

##### Abstract (translated by Google)
我们提出了一个框架，用于从他们的交互中完全无监督地学习潜在对象属性：感知预测网络（PPN）。由提取潜在对象属性的表示的感知模块和使用这些提取的属性来模拟系统动态​​的预测模块组成，PPN可以纯粹从对象动态的样本以端到端的方式进行训练。 PPN学习的潜在对象属性的表示不仅足以准确地模拟由先前看不见的对象组成的系统的动态，而且还可以完全无监督地直接转换为人类可解释的属性（例如，质量，恢复系数）。方式。至关重要的是，PPN还可以推广到新的场景：它们基于梯度的训练可以应用于许多动态系统，并且它们基于图形的结构功能可以应用于由不同数量的对象组成的系统。我们的结果证明了基于图形的神经架构在以对象为中心的推理和预测任务中的功效，我们的模型有可能在尚未被充分理解的系统中发现相关的对象属性。

##### URL
[https://arxiv.org/abs/1807.09244](https://arxiv.org/abs/1807.09244)

##### PDF
[https://arxiv.org/pdf/1807.09244](https://arxiv.org/pdf/1807.09244)

