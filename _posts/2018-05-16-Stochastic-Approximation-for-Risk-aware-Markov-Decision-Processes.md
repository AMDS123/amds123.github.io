---
layout: post
title: "Stochastic Approximation for Risk-aware Markov Decision Processes"
date: 2018-05-16 05:01:17
categories: arXiv_AI
tags: arXiv_AI
author: Wenjie Huang, William B. Haskell
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we develop a stochastic approximation type algorithm to solve finite state and action, infinite-horizon, risk-aware Markov decision processes. Our algorithm is based on solving stochastic saddle-point problems for risk estimation and doing $Q$-learning for finding the optimal risk-aware policy. We show that several widely investigated risk measures (e.g. conditional value-at-risk, optimized certainty equivalent, and absolute semi-deviation) can be expressed as such stochastic saddle-point problems. We establish the almost sure convergence and convergence rate results for our overall algorithm. For error tolerance $\epsilon$ and learning rate $k$, the convergence rate of our algorithm is $\Omega((\ln(1/\delta\epsilon)/\epsilon^{2})^{1/k}+(\ln(1/\epsilon))^{1/(1-k)})$ with probability $1-\delta$.

##### Abstract (translated by Google)
在本文中，我们开发了一种随机逼近型算法来解决有限状态和行为，无限时域，风险意识马尔可夫决策过程。我们的算法是基于求解随机鞍点问题进行风险估计，并通过$ Q $学习来找到最优的风险感知策略。我们表明，一些广泛研究的风险度量（例如条件风险价值，优化的确定性等价和绝对的半偏差）可以表示为随机鞍点问题。我们为整体算法建立了几乎可靠的收敛性和收敛速度结果。对于误差容限$ \ epsilon $和学习速率$ k $，我们的算法的收敛速度为$ \ Omega（\ ln（1 / \ delta \ epsilon ^ {2}）^ {1 / k} +（\ ln（1 /ε））^ {1 /（1-k）}）$，概率为$ 1- \ delta $。

##### URL
[http://arxiv.org/abs/1805.04238](http://arxiv.org/abs/1805.04238)

##### PDF
[http://arxiv.org/pdf/1805.04238](http://arxiv.org/pdf/1805.04238)

