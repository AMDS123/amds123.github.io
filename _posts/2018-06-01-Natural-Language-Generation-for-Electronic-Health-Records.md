---
layout: post
title: "Natural Language Generation for Electronic Health Records"
date: 2018-06-01 12:01:48
categories: arXiv_CL
tags: arXiv_CL Adversarial GAN Optimization Deep_Learning
author: Scott Lee
mathjax: true
---

* content
{:toc}

##### Abstract
A variety of methods existing for generating synthetic electronic health records (EHRs), but they are not capable of generating unstructured text, like emergency department (ED) chief complaints, history of present illness or progress notes. Here, we use the encoder-decoder model, a deep learning algorithm that features in many contemporary machine translation systems, to generate synthetic chief complaints from discrete variables in EHRs, like age group, gender, and discharge diagnosis. After being trained end-to-end on authentic records, the model can generate realistic chief complaint text that preserves much of the epidemiological information in the original data. As a side effect of the model's optimization goal, these synthetic chief complaints are also free of relatively uncommon abbreviation and misspellings, and they include none of the personally-identifiable information (PII) that was in the training data, suggesting it may be used to support the de-identification of text in EHRs. When combined with algorithms like generative adversarial networks (GANs), our model could be used to generate fully-synthetic EHRs, facilitating data sharing between healthcare providers and researchers and improving our ability to develop machine learning methods tailored to the information in healthcare data.

##### Abstract (translated by Google)
现有的用于生成合成电子健康记录（EHR）的各种方法，但是它们不能生成非结构化文本，如急诊科主要投诉，当前疾病史或进度说明。在这里，我们使用编码器 - 解码器模型，这是一种在许多当代机器翻译系统中具有特色的深度学习算法，用于生成EHR中离散变量的合成主要投诉，如年龄组，性别和出院诊断。在对真实记录进行端到端的培训后，该模型可以生成实际的主诉文本，保留原始数据中的大部分流行病学信息。作为模型优化目标的副作用，这些合成主要投诉也没有相对罕见的缩写和拼写错误，并且它们不包含培训数据中的个人身份信息（PII），这表明它可能被用于支持电子健康档案中文字的去识别。当与生成对抗网络（GAN）等算法结合使用时，我们的模型可用于生成完全合成的电子病历，促进医疗保健提供者和研究人员之间的数据共享，并提高我们开发适合医疗保健数据信息的机器学习方法的能力。

##### URL
[http://arxiv.org/abs/1806.01353](http://arxiv.org/abs/1806.01353)

##### PDF
[http://arxiv.org/pdf/1806.01353](http://arxiv.org/pdf/1806.01353)

