---
layout: post
title: "Consistent Discretization and Minimization of the L1 Norm on Manifolds"
date: 2016-09-18 06:56:57
categories: arXiv_CV
tags: arXiv_CV Optimization
author: Alex Bronstein, Yoni Choukroun, Ron Kimmel, Matan Sela
mathjax: true
---

* content
{:toc}

##### Abstract
The L1 norm has been tremendously popular in signal and image processing in the past two decades due to its sparsity-promoting properties. More recently, its generalization to non-Euclidean domains has been found useful in shape analysis applications. For example, in conjunction with the minimization of the Dirichlet energy, it was shown to produce a compactly supported quasi-harmonic orthonormal basis, dubbed as compressed manifold modes. The continuous L1 norm on the manifold is often replaced by the vector l1 norm applied to sampled functions. We show that such an approach is incorrect in the sense that it does not consistently discretize the continuous norm and warn against its sensitivity to the specific sampling. We propose two alternative discretizations resulting in an iteratively-reweighed l2 norm. We demonstrate the proposed strategy on the compressed modes problem, which reduces to a sequence of simple eigendecomposition problems not requiring non-convex optimization on Stiefel manifolds and producing more stable and accurate results.

##### Abstract (translated by Google)
在过去的二十年里，L1规范在信号和图像处理方面因其稀疏性的提升而倍受欢迎。最近，它被推广到非欧几里得领域被发现在形状分析应用中是有用的。例如，结合Dirichlet能量的最小化，它被证明可以产生一个紧凑的准谐调正交基，称为压缩流形模式。流形上的连续L1范数常常被应用于采样函数的向量l1范数所取代。我们表明，这种方法是不正确的，因为它不一致地离散连续的规范，并警告它对具体抽样的敏感性。我们提出了两种可选择的离散化，导致了一个迭代重新的l2范数。我们证明了在压缩模式问题上提出的策略，它减少到一个简单的本征分解问题序列，不需要Stiefel流形上的非凸优化，并产生更稳定和准确的结果。

##### URL
[https://arxiv.org/abs/1609.05434](https://arxiv.org/abs/1609.05434)

##### PDF
[https://arxiv.org/pdf/1609.05434](https://arxiv.org/pdf/1609.05434)

