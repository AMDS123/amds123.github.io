---
layout: post
title: "Quantity beats quality for semantic segmentation of corrosion in images"
date: 2018-06-30 04:53:57
categories: arXiv_CV
tags: arXiv_CV Segmentation CNN Semantic_Segmentation Deep_Learning Detection
author: Will Nash, Tom Drummond, Nick Birbilis
mathjax: true
---

* content
{:toc}

##### Abstract
Dataset creation is typically one of the first steps when applying Artificial Intelligence methods to a new task; and the real world performance of models hinges on the quality and quantity of data available. Producing an image dataset for semantic segmentation is resource intensive, particularly for specialist subjects where class segmentation is not able to be effectively farmed out. The benefit of producing a large, but poorly labelled, dataset versus a small, expertly segmented dataset for semantic segmentation is an open question. Here we show that a large, noisy dataset outperforms a small, expertly segmented dataset for training a Fully Convolutional Network model for semantic segmentation of corrosion in images. A large dataset of 250 images with segmentations labelled by undergraduates and a second dataset of just 10 images, with segmentations labelled by subject matter experts were produced. The mean Intersection over Union and micro F-score metrics were compared after training for 50,000 epochs. This work is illustrative for researchers setting out to develop deep learning models for detection and location of specialist features.

##### Abstract (translated by Google)
数据集创建通常是将人工智能方法应用于新任务时的第一步;模型的真实世界性能取决于可用数据的质量和数量。为语义分割生成图像数据集是资源密集型的，特别是对于无法有效地进行类别分割的专业主体。生成大型但标记较差的数据集与用于语义分割的小型专业分段数据集的好处是一个悬而未决的问题。在这里，我们展示了一个大的，有噪声的数据集优于一个小的，专业分段的数据集，用于训练完全卷积网络模型，用于图像中腐蚀的语义分割。制作了250个图像的大型数据集，其中包括由本科生标记的分段和仅包含10个图像的第二数据集，其中由主题专家标记分段。在训练50,000个时期之后，比较了平均交叉联盟和微观F-得分指标。这项工作说明研究人员着手开发用于检测和定位专家特征的深度学习模型。

##### URL
[http://arxiv.org/abs/1807.03138](http://arxiv.org/abs/1807.03138)

##### PDF
[http://arxiv.org/pdf/1807.03138](http://arxiv.org/pdf/1807.03138)

