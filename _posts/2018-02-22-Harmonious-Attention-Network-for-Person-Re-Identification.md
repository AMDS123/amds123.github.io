---
layout: post
title: "Harmonious Attention Network for Person Re-Identification"
date: 2018-02-22 16:04:55
categories: arXiv_CV
tags: arXiv_CV Re-identification Attention Person_Re-identification CNN Detection
author: Wei Li, Xiatian Zhu, Shaogang Gong
mathjax: true
---

* content
{:toc}

##### Abstract
Existing person re-identification (re-id) methods either assume the availability of well-aligned person bounding box images as model input or rely on constrained attention selection mechanisms to calibrate misaligned images. They are therefore sub-optimal for re-id matching in arbitrarily aligned person images potentially with large human pose variations and unconstrained auto-detection errors. In this work, we show the advantages of jointly learning attention selection and feature representation in a Convolutional Neural Network (CNN) by maximising the complementary information of different levels of visual attention subject to re-id discriminative learning constraints. Specifically, we formulate a novel Harmonious Attention CNN (HA-CNN) model for joint learning of soft pixel attention and hard regional attention along with simultaneous optimisation of feature representations, dedicated to optimise person re-id in uncontrolled (misaligned) images. Extensive comparative evaluations validate the superiority of this new HA-CNN model for person re-id over a wide variety of state-of-the-art methods on three large-scale benchmarks including CUHK03, Market-1501, and DukeMTMC-ReID.

##### Abstract (translated by Google)
现有的人重新识别（re-id）方法或者假定可以将准确对齐的人的边界框图像用作模型输入，或者依靠受限的注意选择机制来校准未对准的图像。因此，它们对于任意对齐的人物图像中的重新匹配而言是次优的，潜在地具有大的人体姿势变化和无约束的自动检测错误。在这项工作中，我们展示联合学习卷积神经网络（CNN）中的关注选择和特征表示的优点，通过最大化不同级别的视觉注意力的补充信息受到重新识别学习约束。具体而言，我们制定了一种新的和谐注意CNN（HA-CNN）模型，用于联合学习软像素注意力和硬区域注意力，并同时优化特征表示，致力于优化未控制（未对齐）图像中的人员重新识别。广泛的比较评估验证了这种新型HA-CNN模型在包括CUHK03，Market-1501和DukeMMC-ReID在内的三种大规模基准测试中的各种最先进方法的优势。

##### URL
[http://arxiv.org/abs/1802.08122](http://arxiv.org/abs/1802.08122)

##### PDF
[http://arxiv.org/pdf/1802.08122](http://arxiv.org/pdf/1802.08122)

