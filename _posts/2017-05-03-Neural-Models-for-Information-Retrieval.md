---
layout: post
title: "Neural Models for Information Retrieval"
date: 2017-05-03 17:08:05
categories: arXiv_CV
tags: arXiv_CV Review Embedding
author: Bhaskar Mitra, Nick Craswell
mathjax: true
---

* content
{:toc}

##### Abstract
Neural ranking models for information retrieval (IR) use shallow or deep neural networks to rank search results in response to a query. Traditional learning to rank models employ machine learning techniques over hand-crafted IR features. By contrast, neural models learn representations of language from raw text that can bridge the gap between query and document vocabulary. Unlike classical IR models, these new machine learning based approaches are data-hungry, requiring large scale training data before they can be deployed. This tutorial introduces basic concepts and intuitions behind neural IR models, and places them in the context of traditional retrieval models. We begin by introducing fundamental concepts of IR and different neural and non-neural approaches to learning vector representations of text. We then review shallow neural IR methods that employ pre-trained neural term embeddings without learning the IR task end-to-end. We introduce deep neural networks next, discussing popular deep architectures. Finally, we review the current DNN models for information retrieval. We conclude with a discussion on potential future directions for neural IR.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1705.01509](https://arxiv.org/abs/1705.01509)

##### PDF
[https://arxiv.org/pdf/1705.01509](https://arxiv.org/pdf/1705.01509)

