---
layout: post
title: "The Kinetics Human Action Video Dataset"
date: 2017-05-19 12:07:01
categories: arXiv_CV
tags: arXiv_CV Classification
author: Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, Mustafa Suleyman, Andrew Zisserman
mathjax: true
---

* content
{:toc}

##### Abstract
We describe the DeepMind Kinetics human action video dataset. The dataset contains 400 human action classes, with at least 400 video clips for each action. Each clip lasts around 10s and is taken from a different YouTube video. The actions are human focussed and cover a broad range of classes including human-object interactions such as playing instruments, as well as human-human interactions such as shaking hands. We describe the statistics of the dataset, how it was collected, and give some baseline performance figures for neural network architectures trained and tested for human action classification on this dataset. We also carry out a preliminary analysis of whether imbalance in the dataset leads to bias in the classifiers.

##### Abstract (translated by Google)
我们描述DeepMind动力学人类行动视频数据集。该数据集包含400个人类动作类，每个动作至少有400个视频剪辑。每个剪辑持续10秒左右，取自不同的YouTube视频。这些行动是以人为本，涵盖范围广泛的课程，包括人与物的互动，例如演奏乐器，以及握手等人与人之间的互动。我们描述了数据集的统计数据，它是如何收集的，并给出了神经网络体系结构的一些基线性能数据，这些数据集在这个数据集上进行了人类行为分类的训练和测试。我们还对数据集中的不平衡是否导致分类器的偏差进行了初步分析。

##### URL
[https://arxiv.org/abs/1705.06950](https://arxiv.org/abs/1705.06950)

##### PDF
[https://arxiv.org/pdf/1705.06950](https://arxiv.org/pdf/1705.06950)

