---
layout: post
title: "Answering Visual What-If Questions: From Actions to Predicted Scene Descriptions"
date: 2018-09-11 07:22:28
categories: arXiv_CV
tags: arXiv_CV
author: M. Wagner, H. Basevi, R. Shetty, W. Li, M. Malinowski, M. Fritz, A. Leonardis
mathjax: true
---

* content
{:toc}

##### Abstract
In-depth scene descriptions and question answering tasks have greatly increased the scope of today's definition of scene understanding. While such tasks are in principle open ended, current formulations primarily focus on describing only the current state of the scenes under consideration. In contrast, in this paper, we focus on the future states of the scenes which are also conditioned on actions. We posit this as a question answering task, where an answer has to be given about a future scene state, given observations of the current scene, and a question that includes a hypothetical action. Our solution is a hybrid model which integrates a physics engine into a question answering architecture in order to anticipate future scene states resulting from object-object interactions caused by an action. We demonstrate first results on this challenging new problem and compare to baselines, where we outperform fully data-driven end-to-end learning approaches.

##### Abstract (translated by Google)
深入的场景描述和问题回答任务大大增加了今天场景理解定义的范围。虽然这些任务原则上是开放式的，但是当前的配方主要集中于仅描述所考虑的场景的当前状态。相比之下，在本文中，我们关注的是场景的未来状态，这些状态也取决于行动。我们认为这是一个问题回答任务，其中必须给出关于未来场景状态的答案，给出对当前场景的观察，以及包括假设动作的问题。我们的解决方案是一种混合模型，它将物理引擎集成到问题解答架构中，以预测由操作引起的对象 - 对象交互所导致的未来场景状态。我们展示了这个具有挑战性的新问题的第一批结果，并与基线进行比较，我们的表现优于完全数据驱动的端到端学习方法。

##### URL
[http://arxiv.org/abs/1809.03707](http://arxiv.org/abs/1809.03707)

##### PDF
[http://arxiv.org/pdf/1809.03707](http://arxiv.org/pdf/1809.03707)

