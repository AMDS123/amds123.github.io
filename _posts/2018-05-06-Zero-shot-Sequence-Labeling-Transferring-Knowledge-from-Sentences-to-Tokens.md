---
layout: post
title: "Zero-shot Sequence Labeling: Transferring Knowledge from Sentences to Tokens"
date: 2018-05-06 13:53:50
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention Quantitative
author: Marek Rei, Anders S&#xf8;gaard
mathjax: true
---

* content
{:toc}

##### Abstract
Can attention- or gradient-based visualization techniques be used to infer token-level labels for binary sequence tagging problems, using networks trained only on sentence-level labels? We construct a neural network architecture based on soft attention, train it as a binary sentence classifier and evaluate against token-level annotation on four different datasets. Inferring token labels from a network provides a method for quantitatively evaluating what the model is learning, along with generating useful feedback in assistance systems. Our results indicate that attention-based methods are able to predict token-level labels more accurately, compared to gradient-based methods, sometimes even rivaling the supervised oracle network.

##### Abstract (translated by Google)
使用基于注意力或基于梯度的可视化技术来使用仅在句级标签上训练的网络来推断二进制序列标记问题的标记级标签？我们构建了一个基于软注意力的神经网络体系结构，将它作为一个二元句子分类器进行训练，并对四个不同数据集上的标记级别注释进行评估。从网络推测令牌标签提供了一种定量评估模型学习内容的方法，并在辅助系统中生成有用的反馈。我们的结果表明，与基于梯度的方法相比，基于注意力的方法能够更准确地预测令牌级别的标签，有时甚至可以与监督的oracle网络相媲美。

##### URL
[http://arxiv.org/abs/1805.02214](http://arxiv.org/abs/1805.02214)

##### PDF
[http://arxiv.org/pdf/1805.02214](http://arxiv.org/pdf/1805.02214)

