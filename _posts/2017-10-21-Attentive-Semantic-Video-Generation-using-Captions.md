---
layout: post
title: "Attentive Semantic Video Generation using Captions"
date: 2017-10-21 21:12:41
categories: arXiv_CV
tags: arXiv_CV Style_Transfer Caption Action_Recognition Recognition
author: Tanya Marwah, Gaurav Mittal, Vineeth N. Balasubramanian
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a network architecture to perform variable length semantic video generation using captions. We adopt a new perspective towards video generation where we allow the captions to be combined with the long-term and short-term dependencies between video frames and thus generate a video in an incremental manner. Our experiments demonstrate our network architecture's ability to distinguish between objects, actions and interactions in a video and combine them to generate videos for unseen captions. The network also exhibits the capability to perform spatio-temporal style transfer when asked to generate videos for a sequence of captions. We also show that the network's ability to learn a latent representation allows it generate videos in an unsupervised manner and perform other tasks such as action recognition. (Accepted in International Conference in Computer Vision (ICCV) 2017)

##### Abstract (translated by Google)
本文提出了一种使用字幕进行可变长度语义视频生成的网络架构。我们采用了一种新的视角生成视角，我们允许将字幕与视频帧之间的长期和短期依赖相结合，从而以增量方式生成视频。我们的实验证明了我们的网络架构能够区分视频中的对象，动作和交互，并将它们组合起来为不可见的字幕生成视频。当被要求为一系列字幕生成视频时，网络还具有执行时空样式传输的能力。我们还表明，网络学习潜在表示的能力允许它以无人监督的方式生成视频，并执行其他任务，如动作识别。 （2017年计算机视觉国际会议（ICCV）接受）

##### URL
[https://arxiv.org/abs/1708.05980](https://arxiv.org/abs/1708.05980)

##### PDF
[https://arxiv.org/pdf/1708.05980](https://arxiv.org/pdf/1708.05980)

