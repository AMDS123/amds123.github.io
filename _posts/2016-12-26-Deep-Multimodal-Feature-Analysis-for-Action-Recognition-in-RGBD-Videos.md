---
layout: post
title: "Deep Multimodal Feature Analysis for Action Recognition in RGB+D Videos"
date: 2016-12-26 05:31:52
categories: arXiv_CV
tags: arXiv_CV Regularization Action_Recognition Classification Recognition
author: Amir Shahroudy, Tian-Tsong Ng, Yihong Gong, Gang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Single modality action recognition on RGB or depth sequences has been extensively explored recently. It is generally accepted that each of these two modalities has different strengths and limitations for the task of action recognition. Therefore, analysis of the RGB+D videos can help us to better study the complementary properties of these two types of modalities and achieve higher levels of performance. In this paper, we propose a new deep autoencoder based shared-specific feature factorization network to separate input multimodal signals into a hierarchy of components. Further, based on the structure of the features, a structured sparsity learning machine is proposed which utilizes mixed norms to apply regularization within components and group selection between them for better classification performance. Our experimental results show the effectiveness of our cross-modality feature analysis framework by achieving state-of-the-art accuracy for action classification on five challenging benchmark datasets.

##### Abstract (translated by Google)
RGB或深度序列的单模式动作识别最近已被广泛地探索。人们普遍认为，这两种模式中的每一种在行动承认的任务上都有不同的优势和局限性。因此，对RGB + D视频的分析可以帮助我们更好地研究这两种模式的互补性质，并获得更高的性能水平。在本文中，我们提出了一个新的基于深度自动编码器的特定于共享的特征分解网络，将输入的多模态信号分解为组件层次结构。进一步在特征结构的基础上，提出了一种结构化稀疏学习机，利用混合规范在构件之间应用正则化，并在它们之间进行分组选择，以达到更好的分类效果。我们的实验结果显示了我们的跨模态特征分析框架的有效性，通过在五个具有挑战性的基准数据集上实现行动分类的最新准确性。

##### URL
[https://arxiv.org/abs/1603.07120](https://arxiv.org/abs/1603.07120)

##### PDF
[https://arxiv.org/pdf/1603.07120](https://arxiv.org/pdf/1603.07120)

