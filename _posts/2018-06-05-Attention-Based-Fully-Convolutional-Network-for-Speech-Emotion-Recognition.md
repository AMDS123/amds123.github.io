---
layout: post
title: "Attention Based Fully Convolutional Network for Speech Emotion Recognition"
date: 2018-06-05 06:00:46
categories: arXiv_SD
tags: arXiv_SD Segmentation Attention CNN Transfer_Learning Recognition
author: Yuanyuan Zhang, Jun Du, Zirui Wang, Jianshu Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Speech emotion recognition is a challenging task for three main reasons: 1) human emotion is abstract, which means it is hard to distinguish; 2) in general, human emotion can only be detected in some specific moments during a long utterance; 3) speech data with emotional labeling is usually limited. In this paper, we present a novel attention based fully convolutional network for speech emotion recognition. We employ fully convolutional network as it is able to handle variable-length speech, free of the demand of segmentation to keep critical information not lost. The proposed attention mechanism can make our model be aware of which time-frequency region of speech spectrogram is more emotion-relevant. Considering limited data, the transfer learning is also adapted to improve the accuracy. Especially, it's interesting to observe obvious improvement obtained with natural scene image based pre-trained model. Validated on the publicly available IEMOCAP corpus, the proposed model outperformed the state-of-the-art methods with a weighted accuracy of 70.4% and an unweighted accuracy of 63.9% respectively.

##### Abstract (translated by Google)
语音情感识别是一个具有挑战性的任务，主要有三个原因：1）人的情感是抽象的，这意味着很难区分; 2）一般来说，只有在长时间的话语中的某些特定时刻才能检测到人的情绪; 3）带有情感标签的语音数据通常是有限的。在本文中，我们提出了一种基于注意的全语音情感识别完全卷积网络。我们采用完全卷积网络，因为它能够处理可变长度的语音，不需要分割来保持关键信息不丢失。所提出的注意机制可以使我们的模型意识到语音频谱图的哪个时频区域更加情绪相关。考虑到有限的数据，转移学习也适用于提高准确性。特别是，观察基于自然场景图像的预训练模型所获得的明显改善是有趣的。在公开可用的IEMOCAP语料库上验证，该模型的表现优于最先进的方法，加权准确率为70.4％，未加权准确率分别为63.9％。

##### URL
[http://arxiv.org/abs/1806.01506](http://arxiv.org/abs/1806.01506)

##### PDF
[http://arxiv.org/pdf/1806.01506](http://arxiv.org/pdf/1806.01506)

