---
layout: post
title: "DeepID-Net: multi-stage and deformable deep convolutional neural networks for object detection"
date: 2014-09-11 17:13:26
categories: arXiv_CV
tags: arXiv_CV Object_Detection CNN Deep_Learning Detection
author: Wanli Ouyang, Ping Luo, Xingyu Zeng, Shi Qiu, Yonglong Tian, Hongsheng Li, Shuo Yang, Zhe Wang, Yuanjun Xiong, Chen Qian, Zhenyao Zhu, Ruohui Wang, Chen-Change Loy, Xiaogang Wang, Xiaoou Tang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose multi-stage and deformable deep convolutional neural networks for object detection. This new deep learning object detection diagram has innovations in multiple aspects. In the proposed new deep architecture, a new deformation constrained pooling (def-pooling) layer models the deformation of object parts with geometric constraint and penalty. With the proposed multi-stage training strategy, multiple classifiers are jointly optimized to process samples at different difficulty levels. A new pre-training strategy is proposed to learn feature representations more suitable for the object detection task and with good generalization capability. By changing the net structures, training strategies, adding and removing some key components in the detection pipeline, a set of models with large diversity are obtained, which significantly improves the effectiveness of modeling averaging. The proposed approach ranked \#2 in ILSVRC 2014. It improves the mean averaged precision obtained by RCNN, which is the state-of-the-art of object detection, from $31\%$ to $45\%$. Detailed component-wise analysis is also provided through extensive experimental evaluation.

##### Abstract (translated by Google)
在本文中，我们提出了用于物体检测的多级可变形深度卷积神经网络。这个新的深度学习对象检测图具有多方面的创新。在所提出的新的深层结构中，一个新的变形约束池（def-pooling）层用几何约束和惩罚来模拟目标部件的变形。通过提出的多阶段训练策略，多个分类器被联合优化以处理不同难度级别的样本。提出了一种新的预训练策略来学习更适合于目标检测任务的特征表示，具有较好的泛化能力。通过改变网络结构，训练策略，增加和删除检测流水线中的一些关键组件，得到了一组具有较大差异性的模型，大大提高了建模平均的有效性。所提出的方法在ILSVRC 2014中排名第二。它将由目标检测技术水平最高的RCNN（从$ 31 \％$到$ 45 \％$）获得的平均精度提高了许多。通过广泛的实验评估也提供了详细的成分分析。

##### URL
[https://arxiv.org/abs/1409.3505](https://arxiv.org/abs/1409.3505)

