---
layout: post
title: "Learning Deep Visual Object Models From Noisy Web Data: How to Make it Work"
date: 2017-02-28 10:02:36
categories: arXiv_CV
tags: arXiv_CV Classification
author: Nizar Massouh, Francesca Babiloni, Tatiana Tommasi, Jay Young, Nick Hawes, Barbara Caputo
mathjax: true
---

* content
{:toc}

##### Abstract
Deep networks thrive when trained on large scale data collections. This has given ImageNet a central role in the development of deep architectures for visual object classification. However, ImageNet was created during a specific period in time, and as such it is prone to aging, as well as dataset bias issues. Moving beyond fixed training datasets will lead to more robust visual systems, especially when deployed on robots in new environments which must train on the objects they encounter there. To make this possible, it is important to break free from the need for manual annotators. Recent work has begun to investigate how to use the massive amount of images available on the Web in place of manual image annotations. We contribute to this research thread with two findings: (1) a study correlating a given level of noisily labels to the expected drop in accuracy, for two deep architectures, on two different types of noise, that clearly identifies GoogLeNet as a suitable architecture for learning from Web data; (2) a recipe for the creation of Web datasets with minimal noise and maximum visual variability, based on a visual and natural language processing concept expansion strategy. By combining these two results, we obtain a method for learning powerful deep object models automatically from the Web. We confirm the effectiveness of our approach through object categorization experiments using our Web-derived version of ImageNet on a popular robot vision benchmark database, and on a lifelong object discovery task on a mobile robot.

##### Abstract (translated by Google)
深度网络在大规模数据收集培训时蓬勃发展。这使得ImageNet在深度视觉对象分类体系结构的开发中发挥了核心作用。然而，ImageNet是在特定的时间段内创建的，因此易于老化以及数据集偏差问题。超越固定的训练数据集将导致更强大的视觉系统，尤其是在新环境中部署在机器人上，这些新环境必须训练他们在那里遇到的物体。要做到这一点，摆脱手动注释者的需要是非常重要的。最近的工作已经开始研究如何使用Web上可用的大量图像来代替手动图像注释。我们为这项研究提供了两个研究成果：（1）研究了两种不同类型的噪声中，一个给定的噪音标签水平与预期的精度下降之间的关系，这两个深度结构清楚地表明了GoogLeNet是一个合适的体系结构从Web数据中学习; （2）基于视觉和自然语言处理概念扩展策略，创建具有最小噪声和最大视觉可变性的Web数据集的配方。通过结合这两个结果，我们获得了从Web自动学习强大的深层对象模型的方法。我们通过在一个流行的机器人视觉基准数据库上使用我们的Web衍生版本的ImageNet进行对象分类实验，以及在移动机器人上进行终身物体发现任务，来确认我们方法的有效性。

##### URL
[https://arxiv.org/abs/1702.08513](https://arxiv.org/abs/1702.08513)

##### PDF
[https://arxiv.org/pdf/1702.08513](https://arxiv.org/pdf/1702.08513)

