---
layout: post
title: "Tabular Benchmarks for Joint Architecture and Hyperparameter Optimization"
date: 2019-05-13 11:17:23
categories: arXiv_CV
tags: arXiv_CV Optimization
author: Aaron Klein, Frank Hutter
mathjax: true
---

* content
{:toc}

##### Abstract
Due to the high computational demands executing a rigorous comparison between hyperparameter optimization (HPO) methods is often cumbersome. The goal of this paper is to facilitate a better empirical evaluation of HPO methods by providing benchmarks that are cheap to evaluate, but still represent realistic use cases. We believe these benchmarks provide an easy and efficient way to conduct reproducible experiments for neural hyperparameter search. Our benchmarks consist of a large grid of configurations of a feed forward neural network on four different regression datasets including architectural hyperparameters and hyperparameters concerning the training pipeline. Based on this data, we performed an in-depth analysis to gain a better understanding of the properties of the optimization problem, as well as of the importance of different types of hyperparameters. Second, we exhaustively compared various different state-of-the-art methods from the hyperparameter optimization literature on these benchmarks in terms of performance and robustness.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1905.04970](https://arxiv.org/abs/1905.04970)

##### PDF
[https://arxiv.org/pdf/1905.04970](https://arxiv.org/pdf/1905.04970)

