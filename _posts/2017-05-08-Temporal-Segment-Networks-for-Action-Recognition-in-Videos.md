---
layout: post
title: "Temporal Segment Networks for Action Recognition in Videos"
date: 2017-05-08 16:21:26
categories: arXiv_CV
tags: arXiv_CV Action_Recognition CNN Video_Classification Classification Recognition
author: Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, Luc Van Gool
mathjax: true
---

* content
{:toc}

##### Abstract
Deep convolutional networks have achieved great success for image recognition. However, for action recognition in videos, their advantage over traditional methods is not so evident. We present a general and flexible video-level framework for learning action models in videos. This method, called temporal segment network (TSN), aims to model long-range temporal structures with a new segment-based sampling and aggregation module. This unique design enables our TSN to efficiently learn action models by using the whole action videos. The learned models could be easily adapted for action recognition in both trimmed and untrimmed videos with simple average pooling and multi-scale temporal window integration, respectively. We also study a series of good practices for the instantiation of TSN framework given limited training samples. Our approach obtains the state-the-of-art performance on four challenging action recognition benchmarks: HMDB51 (71.0%), UCF101 (94.9%), THUMOS14 (80.1%), and ActivityNet v1.2 (89.6%). Using the proposed RGB difference for motion models, our method can still achieve competitive accuracy on UCF101 (91.0%) while running at 340 FPS. Furthermore, based on the temporal segment networks, we won the video classification track at the ActivityNet challenge 2016 among 24 teams, which demonstrates the effectiveness of TSN and the proposed good practices.

##### Abstract (translated by Google)
深卷积网络在图像识别方面取得了巨大的成功。但是，对于视频中的动作识别来说，它们相对于传统方法的优势并不明显。我们提出了一个通用的，灵活的视频级框架，用于学习视频中的动作模型。这种称为时间分段网络（TSN）的方法旨在利用新的基于分段的采样和聚合模块对远程时间结构进行建模。这种独特的设计使我们的TSN能够通过使用整个动作视频有效地学习动作模型。学习模型可以很容易地适应行动识别在修剪和未修剪的视频分别与简单的平均池和多尺度时间窗口集成。我们还研究了一些有限的训练样本的TSN框架实例化的良好实践。我们的方法在四个具有挑战性的动作识别基准上获得了最先进的性能：HMDB51（71.0％），UCF101（94.9％），THUMOS14（80.1％）和ActivityNet v1.2（89.6％）。使用建议的RGB差异运动模型，我们的方法仍然可以达到竞争精度UCF101（91.0％），而运行在340 FPS。此外，基于时间细分网络，我们赢得了24个团队中2016年ActivityNet挑战赛的视频分类赛道，体现了TSN的有效性和所提出的良好做法。

##### URL
[https://arxiv.org/abs/1705.02953](https://arxiv.org/abs/1705.02953)

##### PDF
[https://arxiv.org/pdf/1705.02953](https://arxiv.org/pdf/1705.02953)

