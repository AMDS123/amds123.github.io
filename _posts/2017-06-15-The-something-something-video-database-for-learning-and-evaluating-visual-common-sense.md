---
layout: post
title: "The 'something something' video database for learning and evaluating visual common sense"
date: 2017-06-15 21:15:13
categories: arXiv_CV
tags: arXiv_CV Knowledge Caption Classification Prediction
author: Raghav Goyal, Samira Ebrahimi Kahou, Vincent Michalski, Joanna Materzyńska, Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos, Moritz Mueller-Freitag, Florian Hoppe, Christian Thurau, Ingo Bax, Roland Memisevic
mathjax: true
---

* content
{:toc}

##### Abstract
Neural networks trained on datasets such as ImageNet have led to major advances in visual object classification. One obstacle that prevents networks from reasoning more deeply about complex scenes and situations, and from integrating visual knowledge with natural language, like humans do, is their lack of common sense knowledge about the physical world. Videos, unlike still images, contain a wealth of detailed information about the physical world. However, most labelled video datasets represent high-level concepts rather than detailed physical aspects about actions and scenes. In this work, we describe our ongoing collection of the "something-something" database of video prediction tasks whose solutions require a common sense understanding of the depicted situation. The database currently contains more than 100,000 videos across 174 classes, which are defined as caption-templates. We also describe the challenges in crowd-sourcing this data at scale.

##### Abstract (translated by Google)
在ImageNet等数据集上训练的神经网络已经在视觉对象分类方面取得了重大进展。阻止网络更深入地推理复杂场景和情境，以及将视觉知识与自然语言相结合的一个障碍，就像人类一样，是他们缺乏关于物理世界的常识知识。与静止图像不同，视频包含有关物理世界的大量详细信息。但是，大多数标记的视频数据集代表高级概念，而不是有关动作和场景的详细物理方面。在这项工作中，我们描述了我们正在进行的视频预测任务的“某事物”数据库的收集，其解决方案需要对所描述的情况有一个常识性的理解。该数据库目前包含174个类中的100,000多个视频，这些视频被定义为标题模板。我们还描述了大规模众包这些数据的挑战。

##### URL
[https://arxiv.org/abs/1706.04261](https://arxiv.org/abs/1706.04261)

##### PDF
[https://arxiv.org/pdf/1706.04261](https://arxiv.org/pdf/1706.04261)

