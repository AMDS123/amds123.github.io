---
layout: post
title: "AdapterNet - learning input transformation for domain adaptation"
date: 2018-05-29 17:38:38
categories: arXiv_CV
tags: arXiv_CV
author: Alon Hazan, Yoel Shoshan, Daniel Khapun, Roy Aladjem, Vadim Ratner
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks have demonstrated impressive performance in various machine learning tasks. However, they are notoriously sensitive to changes in data distribution. Often, even a slight change in the distribution can lead to drastic performance reduction. Artificially augmenting the data may help to some extent, but in most cases, fails to achieve model invariance to the data distribution. Some examples where this sub-class of domain adaptation can be valuable are various imaging modalities such as thermal imaging, X-ray, ultrasound, and MRI, where changes in acquisition parameters or acquisition device manufacturer will result in different representation of the same input. Our work shows that standard finetuning fails to adapt the model in certain important cases. We propose a novel method of adapting to a new data source, and demonstrate near perfect adaptation on a customized ImageNet benchmark.

##### Abstract (translated by Google)
深度神经网络在各种机器学习任务中表现出令人印象深刻的性能但是，他们对数据分布的变化非常敏感。通常情况下，即使分布发生轻微变化，也会导致性能大幅降低。人为地增加数据可能在一定程度上有所帮助，但在大多数情况下，无法实现数据分布的模型不变性。这种域适应的子类可能有价值的一些示例是各种成像模式，例如热成像，X射线，超声波和MRI，其中采集参数或采集设备制造商的变化将导致相同输入的不同表示。我们的工作表明标准微调在某些重要情况下不能适应模型。我们提出了一种适应新数据源的新方法，并在定制的ImageNet基准测试中展现了近乎完美的适应性。

##### URL
[http://arxiv.org/abs/1805.11601](http://arxiv.org/abs/1805.11601)

##### PDF
[http://arxiv.org/pdf/1805.11601](http://arxiv.org/pdf/1805.11601)

