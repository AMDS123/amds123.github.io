---
layout: post
title: "Adapting Sequence Models for Sentence Correction"
date: 2017-07-27 22:50:55
categories: arXiv_CL
tags: arXiv_CL
author: Allen Schmaltz, Yoon Kim, Alexander M. Rush, Stuart M. Shieber
mathjax: true
---

* content
{:toc}

##### Abstract
In a controlled experiment of sequence-to-sequence approaches for the task of sentence correction, we find that character-based models are generally more effective than word-based models and models that encode subword information via convolutions, and that modeling the output data as a series of diffs improves effectiveness over standard approaches. Our strongest sequence-to-sequence model improves over our strongest phrase-based statistical machine translation model, with access to the same data, by 6 M2 (0.5 GLEU) points. Additionally, in the data environment of the standard CoNLL-2014 setup, we demonstrate that modeling (and tuning against) diffs yields similar or better M2 scores with simpler models and/or significantly less data than previous sequence-to-sequence approaches.

##### Abstract (translated by Google)
在针对句子纠正任务的序列到序列方法的受控实验中，我们发现基于字符的模型通常比通过卷积编码子字信息的基于字的模型和模型更有效，并且将输出数据建模为一系列的差异提高了标准方法的有效性。我们最强大的序列到序列模型改进了我们最强大的基于短语的统计机器翻译模型，访问相同的数据，达到6M2（0.5GLEU）点。此外，在标准CoNLL-2014设置的数据环境中，我们证明，与以前的序列到序列方法相比，建模（和调优）差异会产生类似或更好的M2分数，简单的模型和/或明显更少的数据。

##### URL
[https://arxiv.org/abs/1707.09067](https://arxiv.org/abs/1707.09067)

##### PDF
[https://arxiv.org/pdf/1707.09067](https://arxiv.org/pdf/1707.09067)

