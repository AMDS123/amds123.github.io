---
layout: post
title: "Low-Resource Text Classification using Domain-Adversarial Learning"
date: 2018-07-13 17:30:32
categories: arXiv_CL
tags: arXiv_CL Adversarial Text_Classification Classification Deep_Learning
author: Daniel Grie&#xdf;haber, Ngoc Thang Vu, Johannes Maucher
mathjax: true
---

* content
{:toc}

##### Abstract
Deep learning techniques have recently shown to be successful in many natural language processing tasks forming state-of-the-art systems. They require, however, a large amount of annotated data which is often missing. This paper explores the use of domain-adversarial learning as a regularizer to avoid overfitting when training domain invariant features for deep, complex neural network in low-resource and zero-resource settings in new target domains or languages. In the case of new languages, we show that monolingual word-vectors can be directly used for training without pre-alignment. Their projection into a common space can be learnt ad-hoc at training time reaching the final performance of pretrained multilingual word-vectors.

##### Abstract (translated by Google)
最近，深度学习技术已经证明在许多自然语言处理任务中是成功的，这些任务形成了最先进的系统。但是，它们需要大量经过注释的数据，而这些数据往往是缺失的。本文探讨了在新的目标域或语言中，在低资源和零资源设置中训练深度，复杂神经网络的域不变特征时，域对抗性学习作为正则化器的使用，以避免过度拟合。在新语言的情况下，我们表明单语词向量可以直接用于训练而无需预先对齐。它们在公共空间中的投射可以在训练时临时学习，达到预训练多语言单词矢量的最终性能。

##### URL
[http://arxiv.org/abs/1807.05195](http://arxiv.org/abs/1807.05195)

##### PDF
[http://arxiv.org/pdf/1807.05195](http://arxiv.org/pdf/1807.05195)

