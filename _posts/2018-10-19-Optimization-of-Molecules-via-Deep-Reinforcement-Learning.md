---
layout: post
title: "Optimization of Molecules via Deep Reinforcement Learning"
date: 2018-10-19 20:23:44
categories: arXiv_AI
tags: arXiv_AI Knowledge Face Reinforcement_Learning Optimization
author: Zhenpeng Zhou, Steven Kearnes, Li Li, Richard N. Zare, Patrick Riley
mathjax: true
---

* content
{:toc}

##### Abstract
We present a framework, which we call Molecule Deep $Q$-Networks (MolDQN), for molecule optimization by combining domain knowledge of chemistry and state-of-the-art reinforcement learning techniques (prioritized experience replay, double $Q$-learning, and randomized value functions). We directly define modifications on molecules, thereby ensuring 100% chemical validity. Further, we operate without pre-training on any dataset to avoid possible bias from the choice of that set. As a result, our model outperforms several other state-of-the-art algorithms by having a higher success rate of acquiring molecules with better properties. Inspired by problems faced during medicinal chemistry lead optimization, we extend our model with multi-objective reinforcement learning, which maximizes drug-likeness while maintaining similarity to the original molecule. We further show the path through chemical space to achieve optimization for a molecule to understand how the model works.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.08678](http://arxiv.org/abs/1810.08678)

##### PDF
[http://arxiv.org/pdf/1810.08678](http://arxiv.org/pdf/1810.08678)

