---
layout: post
title: "Semi-supervised Word Sense Disambiguation with Neural Models"
date: 2016-11-05 01:15:21
categories: arXiv_SD
tags: arXiv_SD RNN Language_Model
author: Dayu Yuan, Julian Richardson, Ryan Doherty, Colin Evans, Eric Altendorf
mathjax: true
---

* content
{:toc}

##### Abstract
Determining the intended sense of words in text - word sense disambiguation (WSD) - is a long standing problem in natural language processing. Recently, researchers have shown promising results using word vectors extracted from a neural network language model as features in WSD algorithms. However, a simple average or concatenation of word vectors for each word in a text loses the sequential and syntactic information of the text. In this paper, we study WSD with a sequence learning neural net, LSTM, to better capture the sequential and syntactic patterns of the text. To alleviate the lack of training data in all-words WSD, we employ the same LSTM in a semi-supervised label propagation classifier. We demonstrate state-of-the-art results, especially on verbs.

##### Abstract (translated by Google)
确定文本中的词语意义 - 词义消歧（WSD） - 是自然语言处理中长期存在的问题。最近，研究人员已经使用从神经网络语言模型中提取的单词向量作为WSD算法中的特征显示了有前景的结果。然而，文本中每个单词的单词向量的简单平均或级联失去了文本的顺序和句法信息。在本文中，我们用序列学习神经网络LSTM来研究WSD，以更好地捕捉文本的顺序和句法模式。为了缓解全词WSD中训练数据的不足，我们在半监督标签传播分类器中使用相同的LSTM。我们展示了最先进的结果，特别是在动词上。

##### URL
[https://arxiv.org/abs/1603.07012](https://arxiv.org/abs/1603.07012)

##### PDF
[https://arxiv.org/pdf/1603.07012](https://arxiv.org/pdf/1603.07012)

