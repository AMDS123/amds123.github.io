---
layout: post
title: "Danger-aware Weighted Advantage Composition of Deep Reinforcement Learning for Robot Navigation"
date: 2018-09-11 13:16:56
categories: arXiv_RO
tags: arXiv_RO Reinforcement_Learning
author: Wei Zhang, Yunfeng Zhang, Ning Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Self-navigation, referring to automatically reaching the goal while avoiding collision with obstacles, is a fundamental skill of mobile robots. Currently, Deep Reinforcement Learning (DRL) can enable the robot to navigate in a more complex environment with less computation power compared to conventional methods. However, it is time-consuming and hard to train the robot to learn goal-reaching and obstacle-avoidance skills simultaneously using DRL-based algorithms. In this paper, two Dueling Deep Q Networks (DQN) named Goal Network and Avoidance Network are used to learn the goal-reaching and obstacle-avoidance skills individually. A novel method named danger-aware advantage composition is proposed to fuse the two networks together without any redesigning and retraining. The composed Navigation Network can enable the robot to reach the goal right behind the wall and to navigate in unknown complexed environment safely and quickly.

##### Abstract (translated by Google)
自动导航，指的是在避免与障碍物碰撞的同时自动到达目标，是移动机器人的基本技能。目前，与传统方法相比，深度强化学习（DRL）可以使机器人在更复杂的环境中导航，并且计算能力更低。然而，使用基于DRL的算法训练机器人同时学习目标到达和避障技能是耗时且困难的。在本文中，两个名为目标网络和规避网络的决斗深度Q网络（DQN）被用于分别学习目标达成和避障技能。提出了一种名为危险感知优势组合的新方法，将两个网络融合在一起，无需重新设计和再训练。组合的导航网络可以使机器人直接到达墙后的目标，并安全，快速地在未知的复杂环境中导航。

##### URL
[http://arxiv.org/abs/1809.03847](http://arxiv.org/abs/1809.03847)

##### PDF
[http://arxiv.org/pdf/1809.03847](http://arxiv.org/pdf/1809.03847)

