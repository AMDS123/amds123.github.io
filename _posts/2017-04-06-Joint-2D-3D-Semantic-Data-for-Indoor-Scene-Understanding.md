---
layout: post
title: "Joint 2D-3D-Semantic Data for Indoor Scene Understanding"
date: 2017-04-06 01:46:13
categories: arXiv_CV
tags: arXiv_CV Face
author: Iro Armeni, Sasha Sax, Amir R. Zamir, Silvio Savarese
mathjax: true
---

* content
{:toc}

##### Abstract
We present a dataset of large-scale indoor spaces that provides a variety of mutually registered modalities from 2D, 2.5D and 3D domains, with instance-level semantic and geometric annotations. The dataset covers over 6,000m2 and contains over 70,000 RGB images, along with the corresponding depths, surface normals, semantic annotations, global XYZ images (all in forms of both regular and 360{\deg} equirectangular images) as well as camera information. It also includes registered raw and semantically annotated 3D meshes and point clouds. The dataset enables development of joint and cross-modal learning models and potentially unsupervised approaches utilizing the regularities present in large-scale indoor spaces. The dataset is available here: this http URL

##### Abstract (translated by Google)
我们提出了一个大规模的室内空间数据集，提供了从2D，2.5D和3D领域，与实例级语义和几何注释的各种相互注册模态。该数据集覆盖6000多平方米，包含超过70000个RGB图像，以及相应的深度，曲面法线，语义注释，全局XYZ图像（全都以正方形和360度方形图像的形式）以及相机信息。它还包括注册的原始和语义注释的3D网格和点云。该数据集使得能够利用大规模室内空间中的规律来开发联合和跨模态学习模型以及可能无监督的方法。数据集可以在这里找到：这个http URL

##### URL
[https://arxiv.org/abs/1702.01105](https://arxiv.org/abs/1702.01105)

##### PDF
[https://arxiv.org/pdf/1702.01105](https://arxiv.org/pdf/1702.01105)

