---
layout: post
title: "Unified Embedding and Metric Learning for Zero-Exemplar Event Detection"
date: 2017-05-05 09:45:58
categories: arXiv_CV
tags: arXiv_CV Object_Detection Embedding Detection
author: Noureldien Hussein, Efstratios Gavves, Arnold W.M. Smeulders
mathjax: true
---

* content
{:toc}

##### Abstract
Event detection in unconstrained videos is conceived as a content-based video retrieval with two modalities: textual and visual. Given a text describing a novel event, the goal is to rank related videos accordingly. This task is zero-exemplar, no video examples are given to the novel event. Related works train a bank of concept detectors on external data sources. These detectors predict confidence scores for test videos, which are ranked and retrieved accordingly. In contrast, we learn a joint space in which the visual and textual representations are embedded. The space casts a novel event as a probability of pre-defined events. Also, it learns to measure the distance between an event and its related videos. Our model is trained end-to-end on publicly available EventNet. When applied to TRECVID Multimedia Event Detection dataset, it outperforms the state-of-the-art by a considerable margin.

##### Abstract (translated by Google)
在不受约束的视频中的事件检测被设想为具有两种模式的基于内容的视频检索：文本和视觉。给定描述一个新事件的文本，目标是相应地对相关的视频进行排名。这个任务是零范例，没有视频的例子给小说事件。相关工作在外部数据源上培训概念探测器。这些检测器预测测试视频的置信度分数，其被相应地排序和检索。相反，我们学习了一个嵌入视觉和文本表示的联合空间。空间将事件作为预定义事件的概率投射出一个新事件。此外，它学习测量事件与其相关视频之间的距离。我们的模型在公共可用的EventNet上进行端对端培训。当应用于TRECVID多媒体事件检测数据集时，其性能优于现有技术。

##### URL
[https://arxiv.org/abs/1705.02148](https://arxiv.org/abs/1705.02148)

##### PDF
[https://arxiv.org/pdf/1705.02148](https://arxiv.org/pdf/1705.02148)

