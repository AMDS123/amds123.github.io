---
layout: post
title: "Unsupervised Odometry and Depth Learning for Endoscopic Capsule Robots"
date: 2018-03-02 21:30:39
categories: arXiv_RO
tags: arXiv_RO Pose_Estimation Quantitative Detection
author: Mehmet Turan, Evin Pinar Ornek, Nail Ibrahimli, Can Giracoglu, Yasin Almalioglu, Mehmet Fatih Yanik, Metin Sitti
mathjax: true
---

* content
{:toc}

##### Abstract
In the last decade, many medical companies and research groups have tried to convert passive capsule endoscopes as an emerging and minimally invasive diagnostic technology into actively steerable endoscopic capsule robots which will provide more intuitive disease detection, targeted drug delivery and biopsy-like operations in the gastrointestinal(GI) tract. In this study, we introduce a fully unsupervised, real-time odometry and depth learner for monocular endoscopic capsule robots. We establish the supervision by warping view sequences and assigning the re-projection minimization to the loss function, which we adopt in multi-view pose estimation and single-view depth estimation network. Detailed quantitative and qualitative analyses of the proposed framework performed on non-rigidly deformable ex-vivo porcine stomach datasets proves the effectiveness of the method in terms of motion estimation and depth recovery.

##### Abstract (translated by Google)
在过去的十年中，许多医疗公司和研究小组试图将被动式胶囊内窥镜作为一种新兴的微创诊断技术转化为主动式内窥镜式胶囊机器人，这将提供更直观的疾病检测，靶向药物输送和类似活检的手术胃肠（GI）道。在这项研究中，我们为单眼内窥镜胶囊机器人引入了完全无监督的实时测距和深度学习器。我们通过翘曲视图序列来建立监督，并将重投影最小化分配给损失函数，我们在多视角姿态估计和单视角深度估计网络中采用了这种方法。对非刚性可变形的体外猪胃数据集进行的拟议框架的详细定量和定性分析证明了该方法在运动估计和深度恢复方面的有效性。

##### URL
[http://arxiv.org/abs/1803.01047](http://arxiv.org/abs/1803.01047)

##### PDF
[http://arxiv.org/pdf/1803.01047](http://arxiv.org/pdf/1803.01047)

