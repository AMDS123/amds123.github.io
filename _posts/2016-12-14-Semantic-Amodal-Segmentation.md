---
layout: post
title: "Semantic Amodal Segmentation"
date: 2016-12-14 19:49:24
categories: arXiv_CV
tags: arXiv_CV Salient Object_Detection Segmentation Semantic_Segmentation Classification Detection Recognition
author: Yan Zhu, Yuandong Tian, Dimitris Mexatas, Piotr Dollár
mathjax: true
---

* content
{:toc}

##### Abstract
Common visual recognition tasks such as classification, object detection, and semantic segmentation are rapidly reaching maturity, and given the recent rate of progress, it is not unreasonable to conjecture that techniques for many of these problems will approach human levels of performance in the next few years. In this paper we look to the future: what is the next frontier in visual recognition? We offer one possible answer to this question. We propose a detailed image annotation that captures information beyond the visible pixels and requires complex reasoning about full scene structure. Specifically, we create an amodal segmentation of each image: the full extent of each region is marked, not just the visible pixels. Annotators outline and name all salient regions in the image and specify a partial depth order. The result is a rich scene structure, including visible and occluded portions of each region, figure-ground edge information, semantic labels, and object overlap. We create two datasets for semantic amodal segmentation. First, we label 500 images in the BSDS dataset with multiple annotators per image, allowing us to study the statistics of human annotations. We show that the proposed full scene annotation is surprisingly consistent between annotators, including for regions and edges. Second, we annotate 5000 images from COCO. This larger dataset allows us to explore a number of algorithmic ideas for amodal segmentation and depth ordering. We introduce novel metrics for these tasks, and along with our strong baselines, define concrete new challenges for the community.

##### Abstract (translated by Google)
诸如分类，目标检测和语义分割等常见的视觉识别任务正在迅速成熟，并且鉴于最近的进展速度，推测这些问题中的许多技术在接下来的几年中将会接近人类的性能水平并不是没有道理的年份。在本文中，我们展望未来：视觉识别的下一个前沿是什么？我们为这个问题提供了一个可能的答案。我们提出了一个详细的图像注释，捕捉超出可见像素的信息，并需要关于全景场景结构的复杂推理。具体而言，我们创建每个图像的一个amodal分割：每个区域的全部范围被标记，而不仅仅是可见像素。注释者勾画和命名图像中的所有显着区域，并指定部分深度顺序。其结果是丰富的场景结构，包括每个区域的可见和遮挡部分，图形边缘信息，语义标签和对象重叠。我们创建两个数据集用于语义amodal分割。首先，我们用BSDS数据集中的500个图像标注每个图像的多个注释器，使我们能够研究人类注释的统计。我们表明，提出的全景场景注释在注释器之间出奇地一致，包括区域和边缘。其次，我们从COCO注释5000张图片。这个较大的数据集使我们能够探索一些关于amodal分割和深度排序的算法思想。我们为这些任务引入新颖的指标，并配合强大的基线为社区定义具体的新挑战。

##### URL
[https://arxiv.org/abs/1509.01329](https://arxiv.org/abs/1509.01329)

##### PDF
[https://arxiv.org/pdf/1509.01329](https://arxiv.org/pdf/1509.01329)

