---
layout: post
title: "Learning weakly supervised multimodal phoneme embeddings"
date: 2017-10-18 12:21:22
categories: arXiv_CL
tags: arXiv_CL Weakly_Supervised Embedding Recognition
author: Rahma Chaabouni, Ewan Dunbar, Neil Zeghidour, Emmanuel Dupoux
mathjax: true
---

* content
{:toc}

##### Abstract
Recent works have explored deep architectures for learning multimodal speech representation (e.g. audio and images, articulation and audio) in a supervised way. Here we investigate the role of combining different speech modalities, i.e. audio and visual information representing the lips movements, in a weakly supervised way using Siamese networks and lexical same-different side information. In particular, we ask whether one modality can benefit from the other to provide a richer representation for phone recognition in a weakly supervised setting. We introduce mono-task and multi-task methods for merging speech and visual modalities for phone recognition. The mono-task learning consists in applying a Siamese network on the concatenation of the two modalities, while the multi-task learning receives several different combinations of modalities at train time. We show that multi-task learning enhances discriminability for visual and multimodal inputs while minimally impacting auditory inputs. Furthermore, we present a qualitative analysis of the obtained phone embeddings, and show that cross-modal visual input can improve the discriminability of phonological features which are visually discernable (rounding, open/close, labial place of articulation), resulting in representations that are closer to abstract linguistic features than those based on audio only.

##### Abstract (translated by Google)
最近的作品探索了以监督的方式学习多模态语音表示（例如音频和图像，发音和音频）的深层架构。在这里我们研究了使用连体网络和词汇相同的不同侧面信息以弱监督方式组合不同语音模态（即代表嘴唇运动的音频和视觉信息）的作用。具体来说，我们问一个模式是否可以从另一个模式中受益，在弱监督的环境下为电话识别提供更丰富的表示。我们引入单任务和多任务方法来合并语音和视觉模式以进行电话识别。单任务学习包括在两种模式的连接上应用连体网络，而多任务学习在训练时间接收几种不同的模态组合。我们表明，多任务学习增强视觉和多式联运投入的歧视性，同时最小影响听觉输入。此外，我们对所获得的手机嵌入进行了定性分析，并且显示交叉模态视觉输入可以改善视觉上可辨别的语音特征（圆滑，开/闭，发音的阴唇位置）的可辨性，导致表示比仅基于音频的那些更接近抽象语言特征。

##### URL
[https://arxiv.org/abs/1704.06913](https://arxiv.org/abs/1704.06913)

##### PDF
[https://arxiv.org/pdf/1704.06913](https://arxiv.org/pdf/1704.06913)

