---
layout: post
title: "Video Depth-From-Defocus"
date: 2016-10-12 16:43:10
categories: arXiv_CV
tags: arXiv_CV
author: Hyeongwoo Kim, Christian Richardt, Christian Theobalt
mathjax: true
---

* content
{:toc}

##### Abstract
Many compelling video post-processing effects, in particular aesthetic focus editing and refocusing effects, are feasible if per-frame depth information is available. Existing computational methods to capture RGB and depth either purposefully modify the optics (coded aperture, light-field imaging), or employ active RGB-D cameras. Since these methods are less practical for users with normal cameras, we present an algorithm to capture all-in-focus RGB-D video of dynamic scenes with an unmodified commodity video camera. Our algorithm turns the often unwanted defocus blur into a valuable signal. The input to our method is a video in which the focus plane is continuously moving back and forth during capture, and thus defocus blur is provoked and strongly visible. This can be achieved by manually turning the focus ring of the lens during recording. The core algorithmic ingredient is a new video-based depth-from-defocus algorithm that computes space-time-coherent depth maps, deblurred all-in-focus video, and the focus distance for each frame. We extensively evaluate our approach, and show that it enables compelling video post-processing effects, such as different types of refocusing.

##### Abstract (translated by Google)
如果每帧深度信息可用，许多引人注目的视频后处理效果，特别是审美焦点编辑和重新聚焦效果是可行的。捕捉RGB和深度的现有计算方法有意修改光学（编码孔径，光场成像），或采用有源RGB-D相机。由于这些方法对于具有普通摄像机的用户不太实用，我们提出了一种用未修改的商品摄像机捕捉动态场景的全焦点RGB-D视频的算法。我们的算法将常常不需要的散焦模糊转化为有价值的信号。我们方法的输入是一个视频，其中的焦平面在拍摄过程中不断前后移动，因此散焦模糊被激发并强烈可见。这可以通过在录制过程中手动旋转镜头的对焦环来实现。核心算法成分是一种新的基于视频的离焦深度算法，可计算空间时间相关的深度图，去模糊全焦点视频以及每帧的焦距。我们对我们的方法进行了广泛的评估，并表明它可以提供引人注目的视频后期处理效果，例如不同类型的重新对焦。

##### URL
[https://arxiv.org/abs/1610.03782](https://arxiv.org/abs/1610.03782)

##### PDF
[https://arxiv.org/pdf/1610.03782](https://arxiv.org/pdf/1610.03782)

