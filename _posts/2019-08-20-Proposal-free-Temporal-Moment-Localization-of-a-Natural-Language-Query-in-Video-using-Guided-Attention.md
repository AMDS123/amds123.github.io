---
layout: post
title: "Proposal-free Temporal Moment Localization of a Natural-Language Query in Video using Guided Attention"
date: 2019-08-20 09:22:54
categories: arXiv_CV
tags: arXiv_CV Attention Caption
author: Cristian Rodriguez Opazo, Edison Marrese-Taylor, Fatemeh Sadat Saleh, Hongdong Li, Stephen Gould
mathjax: true
---

* content
{:toc}

##### Abstract
This paper studies the problem of temporal moment localization in a long untrimmed video using natural language as the query. Given an untrimmed video and a sentence as the query, the goal is to determine the starting, and the ending, of the relevant visual moment in the video, that corresponds to the query sentence. While previous works have tackled this task by a propose-and-rank approach, we introduce a more efficient, end-to-end trainable, and {\em proposal-free approach} that relies on three key components: a dynamic filter to transfer language information to the visual domain, a new loss function to guide our model to attend the most relevant parts of the video, and soft labels to model annotation uncertainty. We evaluate our method on two benchmark datasets, Charades-STA and ActivityNet-Captions. Experimental results show that our approach outperforms state-of-the-art methods on both datasets.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.07236](http://arxiv.org/abs/1908.07236)

##### PDF
[http://arxiv.org/pdf/1908.07236](http://arxiv.org/pdf/1908.07236)

