---
layout: post
title: "Disentangled Relational Representations for Explaining and Learning from Demonstration"
date: 2019-07-31 17:52:25
categories: arXiv_RO
tags: arXiv_RO Relation
author: Yordan Hristov, Daniel Angelov, Michael Burke, Alex Lascarides, Subramanian Ramamoorthy
mathjax: true
---

* content
{:toc}

##### Abstract
Learning from demonstration is an effective method for human users to instruct desired robot behaviour. However, for most non-trivial tasks of practical interest, efficient learning from demonstration depends crucially on inductive bias in the chosen structure for rewards/costs and policies. We address the case where this inductive bias comes from an exchange with a human user. We propose a method in which a learning agent utilizes the information bottleneck layer of a high-parameter variational neural model, with auxiliary loss terms, in order to ground abstract concepts such as spatial relations. The concepts are referred to in natural language instructions and are manifested in the high-dimensional sensory input stream the agent receives from the world. We evaluate the properties of the latent space of the learned model in a photorealistic synthetic environment and particularly focus on examining its usability for downstream tasks. Additionally, through a series of controlled table-top manipulation experiments, we demonstrate that the learned manifold can be used to ground demonstrations as symbolic plans, which can then be executed on a PR2 robot.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.13627](http://arxiv.org/abs/1907.13627)

##### PDF
[http://arxiv.org/pdf/1907.13627](http://arxiv.org/pdf/1907.13627)

