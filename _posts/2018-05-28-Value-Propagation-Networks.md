---
layout: post
title: "Value Propagation Networks"
date: 2018-05-28 23:21:32
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Nantas Nardelli, Gabriel Synnaeve, Zeming Lin, Pushmeet Kohli, Philip H. S. Torr, Nicolas Usunier
mathjax: true
---

* content
{:toc}

##### Abstract
We present Value Propagation (VProp), a parameter-efficient differentiable planning module built on Value Iteration which can successfully be trained using reinforcement learning to solve unseen tasks, has the capability to generalize to larger map sizes, and can learn to navigate in dynamic environments. Furthermore, we show that the module enables learning to plan when the environment also includes stochastic elements, providing a cost-efficient learning system to build low-level size-invariant planners for a variety of interactive navigation problems. We evaluate on static and dynamic configurations of MazeBase grid-worlds, with randomly generated environments of several different sizes, and on a StarCraft navigation scenario, with more complex dynamics, and pixels as input.

##### Abstract (translated by Google)
我们提出价值传播（VProp），一种基于Value Iteration的参数高效差异化规划模块，它可以使用强化学习来解决看不见的任务，并可以成功地进行训练，能够推广到更大的地图尺寸，并且可以学习在动态环境中进行导航。此外，我们还表明，该模块使学习能够在环境中还包含随机元素时进行规划，为各种交互式导航问题提供经济高效的学习系统以构建低级别规模不变的规划器。我们评估MazeBase网格世界的静态和动态配置，以及几种不同尺寸的随机生成环境，以及在StarCraft导航场景中，具有更复杂的动态特性以及像素作为输入。

##### URL
[http://arxiv.org/abs/1805.11199](http://arxiv.org/abs/1805.11199)

##### PDF
[http://arxiv.org/pdf/1805.11199](http://arxiv.org/pdf/1805.11199)

