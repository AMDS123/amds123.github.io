---
layout: post
title: "Exploiting Processing in Non-Volatile Memory for Binary Neural Network Accelerators"
date: 2018-12-10 06:53:36
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition Recognition
author: Salonik Resch, S. Karen Khatamifard, Zamshed Iqbal Chowdhury, Masoud Zabihi, Zhengyang Zhao, Jian-Ping Wang, Sachin S. Sapatnekar, Ulya R. Karpuzcu
mathjax: true
---

* content
{:toc}

##### Abstract
Neural networks are used in a wide range of applications, such as speech recognition and image processing. There is a strong motivation to improve the performance of these applications due to their industrial and commercial significance. Recently, binary neural networks have shown impressive efficiency and accuracy on image recognition data sets. The nature of the operations performed in these algorithms lend themselves well to specialized hardware and processing-in-memory (PIM) approaches. In this paper, we introduce a spintronic, reconfigurable in-memory accelerator for binary neural networks, NV-Net. NV-Net is capable of being used as a standard STT-MRAM array and a computational substrate simultaneously and allows for massively parallel and energy efficient computation. We evaluate NV-Net using multiple image classifiers and a genomics kernel for similarity matching. Our simulation results show that NV-Net is more energy efficient than alternative CPU, GPU, and FPGA based implementations and is also capable of a higher throughput.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1812.03989](https://arxiv.org/abs/1812.03989)

##### PDF
[https://arxiv.org/pdf/1812.03989](https://arxiv.org/pdf/1812.03989)

