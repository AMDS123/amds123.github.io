---
layout: post
title: 'Generalized Grounding Graphs: A Probabilistic Framework for Understanding Grounded Commands'
date: 2017-12-05 21:12:15
categories: arXiv_CL
tags: arXiv_CL
author: Thomas Kollar, Stefanie Tellex, Matthew Walter, Albert Huang, Abraham Bachrach, Sachi Hemachandra, Emma Brunskill, Ashis Banerjee, Deb Roy, Seth Teller, Nicholas Roy
---

* content
{:toc}

##### Abstract
Many task domains require robots to interpret and act upon natural language commands which are given by people and which refer to the robot's physical surroundings. Such interpretation is known variously as the symbol grounding problem, grounded semantics and grounded language acquisition. This problem is challenging because people employ diverse vocabulary and grammar, and because robots have substantial uncertainty about the nature and contents of their surroundings, making it difficult to associate the constitutive language elements (principally noun phrases and spatial relations) of the command text to elements of those surroundings. Symbolic models capture linguistic structure but have not scaled successfully to handle the diverse language produced by untrained users. Existing statistical approaches can better handle diversity, but have not to date modeled complex linguistic structure, limiting achievable accuracy. Recent hybrid approaches have addressed limitations in scaling and complexity, but have not effectively associated linguistic and perceptual features. Our framework, called Generalized Grounding Graphs (G^3), addresses these issues by defining a probabilistic graphical model dynamically according to the linguistic parse structure of a natural language command. This approach scales effectively, handles linguistic diversity, and enables the system to associate parts of a command with the specific objects, places, and events in the external world to which they refer. We show that robots can learn word meanings and use those learned meanings to robustly follow natural language commands produced by untrained users. We demonstrate our approach for both mobility commands and mobile manipulation commands involving a variety of semi-autonomous robotic platforms, including a wheelchair, a micro-air vehicle, a forklift, and the Willow Garage PR2.

##### Abstract (translated by Google)
许多任务领域需要机器人来解释和处理由人们提供的指向机器人物理环境的自然语言命令。这种解释不同地被称为符号接地问题，基础语义和基础语言习得。这个问题是具有挑战性的，因为人们使用不同的词汇和语法，而且由于机器人对周围环境的性质和内容有很大的不确定性，所以很难将命令文本的构成语言元素（主要是名词短语和空间关系）那些环境。符号模型捕捉语言结构，但尚未成功地处理由未经培训的用户产生的多样化语言。现有的统计方法可以更好地处理多样性，但是迄今为止还没有建立复杂的语言结构，限制了可实现的准确性。最近的混合方法已经解决了缩放和复杂性方面的限制，但没有有效地将语言和感知特征相关联。我们的框架被称为广义基础图（G ^ 3），通过根据自然语言命令的语言分析结构动态地定义概率图模型来解决这些问题。这种方法能够有效扩展，处理语言的多样性，并使系统能够将命令的部分与外部世界中特定的对象，地点和事件相关联。我们表明，机器人可以学习单词的含义，并使用这些学习的意义，以强有力地遵循由未经培训的用户产生的自然语言命令。我们展示了我们的移动命令和涉及各种半自主机器人平台（包括轮椅，微型飞行器，叉车和柳树车库PR2）的移动操纵命令的方法。

##### URL
[http://arxiv.org/abs/1712.01097](http://arxiv.org/abs/1712.01097)

