---
layout: post
title: "Data-Efficient Learning of Feedback Policies from Image Pixels using Deep Dynamical Models"
date: 2015-10-09 15:21:01
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning Embedding Prediction
author: John-Alexander M. Assael, Niklas Wahlström, Thomas B. Schön, Marc Peter Deisenroth
mathjax: true
---

* content
{:toc}

##### Abstract
Data-efficient reinforcement learning (RL) in continuous state-action spaces using very high-dimensional observations remains a key challenge in developing fully autonomous systems. We consider a particularly important instance of this challenge, the pixels-to-torques problem, where an RL agent learns a closed-loop control policy ("torques") from pixel information only. We introduce a data-efficient, model-based reinforcement learning algorithm that learns such a closed-loop policy directly from pixel information. The key ingredient is a deep dynamical model for learning a low-dimensional feature embedding of images jointly with a predictive model in this low-dimensional feature space. Joint learning is crucial for long-term predictions, which lie at the core of the adaptive nonlinear model predictive control strategy that we use for closed-loop control. Compared to state-of-the-art RL methods for continuous states and actions, our approach learns quickly, scales to high-dimensional state spaces, is lightweight and an important step toward fully autonomous end-to-end learning from pixels to torques.

##### Abstract (translated by Google)
使用非常高维观测的连续状态行为空间中的数据有效强化学习（RL）仍然是开发完全自主系统的关键挑战。我们考虑这个挑战的一个特别重要的例子，像素到扭矩问题，RL代理从像素信息中学习一个闭环控制策略（“扭矩”）。我们引入一个数据有效的，基于模型的强化学习算法，直接从像素信息中学习这种闭环策略。关键要素是在这个低维特征空间中用于学习图像的低维特征嵌入和预测模型的深度动态模型。联合学习对于长期预测是至关重要的，这些预测是我们用于闭环控制的自适应非线性模型预测控制策略的核心。与最先进的用于连续状态和动作的RL方法相比，我们的方法快速学习，扩展到高维状态空间，是轻量级的，是从像素到力矩完全自主端到端学习的重要步骤。

##### URL
[https://arxiv.org/abs/1510.02173](https://arxiv.org/abs/1510.02173)

##### PDF
[https://arxiv.org/pdf/1510.02173](https://arxiv.org/pdf/1510.02173)

