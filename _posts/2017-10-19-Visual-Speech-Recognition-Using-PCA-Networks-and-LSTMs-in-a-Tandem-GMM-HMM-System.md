---
layout: post
title: "Visual Speech Recognition Using PCA Networks and LSTMs in a Tandem GMM-HMM System"
date: 2017-10-19 14:41:25
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition CNN RNN Recognition
author: Marina Zimmermann, Mostafa Mehdipour Ghazi, Hazım Kemal Ekenel, Jean-Philippe Thiran
mathjax: true
---

* content
{:toc}

##### Abstract
Automatic visual speech recognition is an interesting problem in pattern recognition especially when audio data is noisy or not readily available. It is also a very challenging task mainly because of the lower amount of information in the visual articulations compared to the audible utterance. In this work, principle component analysis is applied to the image patches - extracted from the video data - to learn the weights of a two-stage convolutional network. Block histograms are then extracted as the unsupervised learning features. These features are employed to learn a recurrent neural network with a set of long short-term memory cells to obtain spatiotemporal features. Finally, the obtained features are used in a tandem GMM-HMM system for speech recognition. Our results show that the proposed method has outperformed the baseline techniques applied to the OuluVS2 audiovisual database for phrase recognition with the frontal view cross-validation and testing sentence correctness reaching 79% and 73%, respectively, as compared to the baseline of 74% on cross-validation.

##### Abstract (translated by Google)
自动可视语音识别在模式识别中是一个有趣的问题，特别是当音频数据有噪声或不易获得时。这也是一个非常具有挑战性的任务，主要是因为与可听发音相比，视觉发音中的信息量较少。在这项工作中，将主成分分析应用于从视频数据中提取的图像块，以了解两级卷积网络的权重。然后提取块直方图作为无监督学习特征。这些特征被用于学习具有一组长的短期记忆细胞的循环神经网络以获得时空特征。最后，所获得的特征被用于串联的GMM-HMM系统中用于语音识别。我们的研究结果表明，提出的方法已经超过了用于短语识别的OuluVS2视听数据库的基线技术，正面视图交叉验证和测试句子正确率分别达到了74％和73％，而基线为74％交叉验证。

##### URL
[https://arxiv.org/abs/1710.07161](https://arxiv.org/abs/1710.07161)

##### PDF
[https://arxiv.org/pdf/1710.07161](https://arxiv.org/pdf/1710.07161)

