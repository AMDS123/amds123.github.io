---
layout: post
title: "Supervised Neural Models Revitalize the Open Relation Extraction"
date: 2019-08-16 08:47:24
categories: arXiv_CL
tags: arXiv_CL Review Relation_Extraction Embedding RNN Relation
author: Shengbin Jia, Shijia E, Yang Xiang
mathjax: true
---

* content
{:toc}

##### Abstract
Open relation extraction (ORE) remains a challenge to obtain a semantic representation by discovering arbitrary relation tuples from the un-structured text. However, perhaps due to limited data, previous extractors use unsupervised or semi-supervised methods based on pattern matching, which heavily depend on manual work or syntactic parsers and are inefficient or error-cascading. Their development has encountered bottlenecks. Although a few people try to use neural network based models to improve the ORE task performance recently, it is always intractable for ORE to produce supervised systems based on various neural architectures. We analyze and review the neural ORE methods. Further, we construct a large-scale automatically tagging training set and design a tagging scheme to frame ORE as a supervised sequence tagging task. A hybrid neural sequence tagging model (NST) is proposed which combines BiLSTM, CNN and CRF to capture the contextual temporal information, local spatial information, and sentence level tag information of the sequence by using the word and part-of-speech embeddings. Experiments on multiple datasets show that our method is better than most of the existing pattern-based methods and other neural networks based models.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.01761](http://arxiv.org/abs/1908.01761)

##### PDF
[http://arxiv.org/pdf/1908.01761](http://arxiv.org/pdf/1908.01761)

