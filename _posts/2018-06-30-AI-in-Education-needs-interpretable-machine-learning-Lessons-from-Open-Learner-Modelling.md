---
layout: post
title: "AI in Education needs interpretable machine learning: Lessons from Open Learner Modelling"
date: 2018-06-30 11:28:17
categories: arXiv_AI
tags: arXiv_AI Knowledge
author: Cristina Conati, Kaska Porayska-Pomsta, Manolis Mavrikis
mathjax: true
---

* content
{:toc}

##### Abstract
Interpretability of the underlying AI representations is a key raison d'\^{e}tre for Open Learner Modelling (OLM) -- a branch of Intelligent Tutoring Systems (ITS) research. OLMs provide tools for 'opening' up the AI models of learners' cognition and emotions for the purpose of supporting human learning and teaching. Over thirty years of research in ITS (also known as AI in Education) produced important work, which informs about how AI can be used in Education to best effects and, through the OLM research, what are the necessary considerations to make it interpretable and explainable for the benefit of learning. We argue that this work can provide a valuable starting point for a framework of interpretable AI, and as such is of relevance to the application of both knowledge-based and machine learning systems in other high-stakes contexts, beyond education.

##### Abstract (translated by Google)
基础AI表示的可解释性是开放式学习者建模（OLM）的一个关键存在因素 -  OLM是智能辅导系统（ITS）研究的一个分支。 OLM提供工具，用于“打开”学习者认知和情感的AI模型，以支持人类的学习和教学。 ITS的三十多年研究（也称为教育中的人工智能）产生了重要的工作，通过OLM研究了解人工智能如何在教育中用于最佳效果，以及使其可解释和解释的必要考虑因素。为了学习的好处。我们认为，这项工作可以为可解释的人工智能框架提供一个有价值的起点，因此与基于知识的机器学习系统和机器学习系统在教育之外的其他高风险背景下的应用相关。

##### URL
[http://arxiv.org/abs/1807.00154](http://arxiv.org/abs/1807.00154)

##### PDF
[http://arxiv.org/pdf/1807.00154](http://arxiv.org/pdf/1807.00154)

