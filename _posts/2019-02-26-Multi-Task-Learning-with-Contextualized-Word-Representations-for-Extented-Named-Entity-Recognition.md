---
layout: post
title: "Multi-Task Learning with Contextualized Word Representations for Extented Named Entity Recognition"
date: 2019-02-26 18:53:22
categories: arXiv_CL
tags: arXiv_CL Recognition
author: Thai-Hoang Pham, Khai Mai, Nguyen Minh Trung, Nguyen Tuan Duc, Danushka Bolegala, Ryohei Sasano, Satoshi Sekine
mathjax: true
---

* content
{:toc}

##### Abstract
Fine-Grained Named Entity Recognition (FG-NER) is critical for many NLP applications. While classical named entity recognition (NER) has attracted a substantial amount of research, FG-NER is still an open research domain. The current state-of-the-art (SOTA) model for FG-NER relies heavily on manual efforts for building a dictionary and designing hand-crafted features. The end-to-end framework which achieved the SOTA result for NER did not get the competitive result compared to SOTA model for FG-NER. In this paper, we investigate how effective multi-task learning approaches are in an end-to-end framework for FG-NER in different aspects. Our experiments show that using multi-task learning approaches with contextualized word representation can help an end-to-end neural network model achieve SOTA results without using any additional manual effort for creating data and designing features.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.10118](http://arxiv.org/abs/1902.10118)

##### PDF
[http://arxiv.org/pdf/1902.10118](http://arxiv.org/pdf/1902.10118)

