---
layout: post
title: "Controllable Neural Story Plot Generation via Reinforcement Learning"
date: 2019-02-27 19:54:32
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning Language_Model
author: Pradyumna Tambwekar, Murtaza Dhuliawala, Animesh Mehta, Lara J. Martin, Brent Harrison, Mark O. Riedl
mathjax: true
---

* content
{:toc}

##### Abstract
Language-modeling--based approaches to story plot generation attempt to construct a plot by sampling from a language model (LM) to predict the next character, word, or sentence to add to the story. LM techniques lack the ability to receive guidance from the user to achieve a specific goal, resulting in stories that don't have a clear sense of progression and lack coherence. We present a reward-shaping technique that analyzes a story corpus and produces intermediate rewards that are backpropagated into a pre-trained LM in order to guide the model towards a given goal. Automated evaluations show our technique can create a model that generates story plots which consistently achieve a specified goal. Human-subject studies show that the generated stories have more plausible event ordering than baseline plot generation techniques.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1809.10736](http://arxiv.org/abs/1809.10736)

##### PDF
[http://arxiv.org/pdf/1809.10736](http://arxiv.org/pdf/1809.10736)

