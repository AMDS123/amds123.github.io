---
layout: post
title: "Attention Tree: Learning Hierarchies of Visual Features for Large-Scale Image Recognition"
date: 2016-08-01 20:51:29
categories: arXiv_CV
tags: arXiv_CV Attention GAN Image_Classification Optimization Classification Recognition
author: Priyadarshini Panda, Kaushik Roy
mathjax: true
---

* content
{:toc}

##### Abstract
One of the key challenges in machine learning is to design a computationally efficient multi-class classifier while maintaining the output accuracy and performance. In this paper, we present a tree-based classifier: Attention Tree (ATree) for large-scale image classification that uses recursive Adaboost training to construct a visual attention hierarchy. The proposed attention model is inspired from the biological 'selective tuning mechanism for cortical visual processing'. We exploit the inherent feature similarity across images in datasets to identify the input variability and use recursive optimization procedure, to determine data partitioning at each node, thereby, learning the attention hierarchy. A set of binary classifiers is organized on top of the learnt hierarchy to minimize the overall test-time complexity. The attention model maximizes the margins for the binary classifiers for optimal decision boundary modelling, leading to better performance at minimal complexity. The proposed framework has been evaluated on both Caltech-256 and SUN datasets and achieves accuracy improvement over state-of-the-art tree-based methods at significantly lower computational cost.

##### Abstract (translated by Google)
机器学习的关键挑战之一是设计一个计算高效的多级分类器，同时保持输出精度和性能。在本文中，我们提出了一种基于树的分类器：用于大规模图像分类的注意树（Atree），它使用递归Adaboost训练构造一个视觉注意层次结构。提出的注意模型受到生物学皮质视觉处理的选择性调节机制的启发。我们利用数据集中图像之间的固有特征相似性来识别输入变化，并使用递归优化过程来确定每个节点处的数据划分，从而学习注意层次。一组二进制分类器被组织在所学习的层次之上，以最小化总的测试时间复杂度。注意模型最大化了二元分类器的边际，以实现最佳决策边界建模，从而以最小的复杂性实现更好的性能。已经在Caltech-256和SUN数据集上对所提出的框架进行了评估，并且以相当低的计算成本实现了对基于最新树的方法的准确度改进。

##### URL
[https://arxiv.org/abs/1608.00611](https://arxiv.org/abs/1608.00611)

##### PDF
[https://arxiv.org/pdf/1608.00611](https://arxiv.org/pdf/1608.00611)

