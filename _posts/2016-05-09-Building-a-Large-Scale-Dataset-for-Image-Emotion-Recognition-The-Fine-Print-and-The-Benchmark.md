---
layout: post
title: "Building a Large Scale Dataset for Image Emotion Recognition: The Fine Print and The Benchmark"
date: 2016-05-09 18:14:52
categories: arXiv_CV
tags: arXiv_CV CNN Recognition
author: Quanzeng You, Jiebo Luo, Hailin Jin, Jianchao Yang
mathjax: true
---

* content
{:toc}

##### Abstract
Psychological research results have confirmed that people can have different emotional reactions to different visual stimuli. Several papers have been published on the problem of visual emotion analysis. In particular, attempts have been made to analyze and predict people's emotional reaction towards images. To this end, different kinds of hand-tuned features are proposed. The results reported on several carefully selected and labeled small image data sets have confirmed the promise of such features. While the recent successes of many computer vision related tasks are due to the adoption of Convolutional Neural Networks (CNNs), visual emotion analysis has not achieved the same level of success. This may be primarily due to the unavailability of confidently labeled and relatively large image data sets for visual emotion analysis. In this work, we introduce a new data set, which started from 3+ million weakly labeled images of different emotions and ended up 30 times as large as the current largest publicly available visual emotion data set. We hope that this data set encourages further research on visual emotion analysis. We also perform extensive benchmarking analyses on this large data set using the state of the art methods including CNNs.

##### Abstract (translated by Google)
心理学研究结果证实，人们可以对不同的视觉刺激产生不同的情绪反应。关于视觉情绪分析问题已经发表了几篇论文。特别是试图分析和预测人们对图像的情绪反应。为此，提出了不同类型的手调特征。在几个仔细挑选和标记的小图像数据集上报告的结果证实了这种特征的前景。虽然最近许多计算机视觉相关任务的成功是由于采用卷积神经网络（CNN），视觉情感分析并没有取得同样的成功。这可能主要是由于用于视觉情绪分析的自信地标记和相对较大的图像数据集的不可用性。在这项工作中，我们引入了一个新的数据集，这个数据集从300万个不同情绪的弱标记图像开始，最终以当前最大的公开可用的视觉情绪数据集的30倍。我们希望这个数据集鼓励进一步研究视觉情绪分析。我们还使用包括CNN在内的最先进的方法对这个大型数据集进行了广泛的基准分析。

##### URL
[https://arxiv.org/abs/1605.02677](https://arxiv.org/abs/1605.02677)

##### PDF
[https://arxiv.org/pdf/1605.02677](https://arxiv.org/pdf/1605.02677)

