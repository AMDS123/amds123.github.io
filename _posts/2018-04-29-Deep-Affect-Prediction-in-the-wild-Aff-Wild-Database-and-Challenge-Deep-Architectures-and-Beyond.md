---
layout: post
title: "Deep Affect Prediction in-the-wild: Aff-Wild Database and Challenge, Deep Architectures, and Beyond"
date: 2018-04-29 14:18:07
categories: arXiv_AI
tags: arXiv_AI GAN CNN RNN Deep_Learning Prediction Recognition
author: Dimitrios Kollias, Panagiotis Tzirakis, Mihalis A. Nicolaou, Athanasios Papaioannou, Guoying Zhao, Björn Schuller, Irene Kotsia, Stefanos Zafeiriou
mathjax: true
---

* content
{:toc}

##### Abstract
Automatic understanding of human affect using visual signals is of great importance in everyday human-machine interactions. Appraising human emotional states, behaviors and reactions displayed in real-world settings, can be accomplished using latent continuous dimensions (e.g., the circumplex model of affect). Valence (i.e., how positive or negative is an emotion) and arousal (i.e., power of the activation of the emotion) constitute the most popular and effective affect representations. Nevertheless, the majority of collected datasets this far, although containing naturalistic emotional states, have been captured in highly controlled recording conditions. In this paper, we introduce the Aff-Wild benchmark for training and evaluating affect recognition algorithms. We also report on the results of the First Affect-in-the-wild Challenge (Aff-Wild Challenge) that was recently organized on the Aff-Wild database, and was the first ever challenge on the estimation of valence and arousal in-the-wild. Furthermore, we design and extensively train an end-to-end deep neural architecture which performs prediction of continuous emotion dimensions based on visual cues. The proposed deep learning architecture, AffWildNet, includes convolutional and recurrent neural network (CNN-RNN) layers, exploiting the invariant properties of convolutional features, while also modeling temporal dynamics that arise in human behavior via the recurrent layers. The AffWildNet produced state-of-the-art results on the Aff-Wild Challenge. We then exploit the AffWild database for learning features, which can be used as priors for achieving best performances both for dimensional, as well as categorical emotion recognition, using the RECOLA, AFEW-VA and EmotiW 2017 datasets, compared to all other methods designed for the same goal.

##### Abstract (translated by Google)
使用视觉信号自动理解人类的影响在日常的人机交互中非常重要。评估在现实环境中显示的人类情绪状态，行为和反应可以使用潜在的连续维度（例如影响的环形模型）来完成。价值（即，情绪有多积极或消极）和觉醒（即情绪激活的力量）构成了最流行和有效的情感表征。尽管如此，尽管包含自然主义情绪状态，但迄今为止收集的大部分数据集都是在高度控制的记录条件下捕获的。在本文中，我们介绍了用于训练和评估情感识别算法的Aff-Wild基准。我们还报道了最近在Aff-Wild数据库中组织的第一次野外挑战赛（Aff-Wild挑战赛）的结果，并且是有史以来第一次在估计价格和唤醒方面的挑战-野生。此外，我们设计并广泛地训练一个端到端的深度神经架构，它基于视觉线索执行连续情绪维度的预测。所提出的深度学习架构AffWildNet包括卷积和递归神经网络（CNN-RNN）层，利用卷积特征的不变特性，同时还通过递归层对人类行为中出现的时间动态进行建模。 AffWildNet在Aff-Wild挑战赛上制作了最先进的成绩。然后，我们利用AffWild数据库进行学习功能，与所有其他设计的方法相比，该功能可以用作前期功能，以便使用RECOLA，AFEW-VA和EmotiW 2017数据集实现尺寸以及分类情感识别的最佳性能相同的目标。

##### URL
[https://arxiv.org/abs/1804.10938](https://arxiv.org/abs/1804.10938)

##### PDF
[https://arxiv.org/pdf/1804.10938](https://arxiv.org/pdf/1804.10938)

