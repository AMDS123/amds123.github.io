---
layout: post
title: "Foolbox: A Python toolbox to benchmark the robustness of machine learning models"
date: 2018-03-20 10:10:10
categories: arXiv_CV
tags: arXiv_CV Adversarial Face Classification Deep_Learning
author: Jonas Rauber, Wieland Brendel, Matthias Bethge
mathjax: true
---

* content
{:toc}

##### Abstract
Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at https://github.com/bethgelab/foolbox . The most up-to-date documentation can be found at <a href="http://foolbox.readthedocs.io">this http URL</a> .

##### Abstract (translated by Google)
即使是今天最先进的机器学习模型也很容易受到其输入几乎不可察觉的扰动的影响。 Foolbox是一种新的Python软件包，用于产生这种对抗性扰动，并量化和比较机器学习模型的稳健性。围绕这样的想法构建，即最可比较的鲁棒性度量是制作对抗性示例所需的最小扰动。为此，Foolbox提供了大多数公开的对抗攻击方法的参考实现以及一些新的攻击方法，所有这些都执行内部超参数调整以找到最小对抗性扰动。此外，Foolbox与PyTorch，Keras，TensorFlow，Theano和MXNet等最受欢迎的深度学习框架接口，并允许不同的对抗标准，如目标错误分类和top-k错误分类以及不同的距离度量。该代码根据MIT许可获得许可，并可在https://github.com/bethgelab/foolbox上公开获取。最新的文档可以在<a href="http://foolbox.readthedocs.io">这个http URL </a>上找到。

##### URL
[http://arxiv.org/abs/1707.04131](http://arxiv.org/abs/1707.04131)

##### PDF
[http://arxiv.org/pdf/1707.04131](http://arxiv.org/pdf/1707.04131)

