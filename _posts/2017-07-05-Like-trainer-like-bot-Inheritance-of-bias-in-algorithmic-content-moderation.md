---
layout: post
title: "Like trainer, like bot? Inheritance of bias in algorithmic content moderation"
date: 2017-07-05 17:19:45
categories: arXiv_CL
tags: arXiv_CL
author: Reuben Binns, Michael Veale, Max Van Kleek, Nigel Shadbolt
mathjax: true
---

* content
{:toc}

##### Abstract
The internet has become a central medium through which `networked publics' express their opinions and engage in debate. Offensive comments and personal attacks can inhibit participation in these spaces. Automated content moderation aims to overcome this problem using machine learning classifiers trained on large corpora of texts manually annotated for offence. While such systems could help encourage more civil debate, they must navigate inherently normatively contestable boundaries, and are subject to the idiosyncratic norms of the human raters who provide the training data. An important objective for platforms implementing such measures might be to ensure that they are not unduly biased towards or against particular norms of offence. This paper provides some exploratory methods by which the normative biases of algorithmic content moderation systems can be measured, by way of a case study using an existing dataset of comments labelled for offence. We train classifiers on comments labelled by different demographic subsets (men and women) to understand how differences in conceptions of offence between these groups might affect the performance of the resulting models on various test sets. We conclude by discussing some of the ethical choices facing the implementers of algorithmic moderation systems, given various desired levels of diversity of viewpoints amongst discussion participants.

##### Abstract (translated by Google)
互联网已成为“网络公众”发表意见，辩论的中心媒介。无礼的评论和人身攻击可以阻止参与这些空间。自动化内容审核旨在利用机器学习分类器来克服这个问题，该机器学习分类器通过手动注释的大型文本文本进行训练。虽然这样的系统可能有助于鼓励更多的公民辩论，但它们必须本质上具有规范性的可竞争的边界，并受制于提供培训数据的人类评估者的特质规范。执行这些措施的平台的一个重要目标可能是确保它们不会过度偏向或违反特定的犯罪准则。本文提供了一些探索性的方法，通过一个案例研究使用现有的评论数据集标记为犯罪的算法内容调节系统的规范偏见可以测量。我们根据不同的人口统计学子集（男性和女性）标注的评论对分类器进行培训，以了解这些组之间在犯罪概念方面的差异是否会影响各种测试集合的模型的性能。我们通过讨论算法调节系统的实现者面临的一些道德选择结束，给出讨论参与者中各种期望的多样性观点。

##### URL
[https://arxiv.org/abs/1707.01477](https://arxiv.org/abs/1707.01477)

##### PDF
[https://arxiv.org/pdf/1707.01477](https://arxiv.org/pdf/1707.01477)

