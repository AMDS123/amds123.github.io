---
layout: post
title: "Predictive Coding for Dynamic Visual Processing: Development of Functional Hierarchy in a Multiple Spatio-Temporal Scales RNN Model"
date: 2017-09-06 04:04:04
categories: arXiv_CV
tags: arXiv_CV RNN Prediction
author: Minkyu Choi, Jun Tani
mathjax: true
---

* content
{:toc}

##### Abstract
The current paper proposes a novel predictive coding type neural network model, the predictive multiple spatio-temporal scales recurrent neural network (P-MSTRNN). The P-MSTRNN learns to predict visually perceived human whole-body cyclic movement patterns by exploiting multiscale spatio-temporal constraints imposed on network dynamics by using differently sized receptive fields as well as different time constant values for each layer. After learning, the network becomes able to proactively imitate target movement patterns by inferring or recognizing corresponding intentions by means of the regression of prediction error. Results show that the network can develop a functional hierarchy by developing a different type of dynamic structure at each layer. The paper examines how model performance during pattern generation as well as predictive imitation varies depending on the stage of learning. The number of limit cycle attractors corresponding to target movement patterns increases as learning proceeds. And, transient dynamics developing early in the learning process successfully perform pattern generation and predictive imitation tasks. The paper concludes that exploitation of transient dynamics facilitates successful task performance during early learning periods.

##### Abstract (translated by Google)
本文提出了一种新的预测编码型神经网络模型，即预测多时空尺度递归神经网络（P-MSTRNN）。 P-MSTRNN通过利用不同大小的感受野以及每个层的不同时间常数值，利用施加在网络动力学上的多尺度时空约束来学习预测视觉感知的人类全身周期性运动模式。学习后，网络通过预测误差的回归，通过推断或识别相应的意图，变得能够主动地模仿目标运动模式。结果表明，网络可以通过在每一层开发不同类型的动态结构来开发功能层次结构。本文考察模式生成过程中的模型表现以及预测性模仿如何随着学习阶段而变化。随着学习的进行，与目标运动模式相对应的极限环吸引器的数量增加。并且，在学习过程早期发展的瞬态动态成功地执行模式生成和预测性模仿任务。本文的结论是，利用瞬态动力学有助于在早期学习阶段成功完成任务。

##### URL
[https://arxiv.org/abs/1708.00812](https://arxiv.org/abs/1708.00812)

##### PDF
[https://arxiv.org/pdf/1708.00812](https://arxiv.org/pdf/1708.00812)

