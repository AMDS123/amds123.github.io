---
layout: post
title: "Synthetic Data for Text Localisation in Natural Images"
date: 2016-04-22 13:23:08
categories: arXiv_CV
tags: arXiv_CV Object_Detection CNN Deep_Learning Detection Relation
author: Ankush Gupta, Andrea Vedaldi, Andrew Zisserman
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we introduce a new method for text detection in natural images. The method comprises two contributions: First, a fast and scalable engine to generate synthetic images of text in clutter. This engine overlays synthetic text to existing background images in a natural way, accounting for the local 3D scene geometry. Second, we use the synthetic images to train a Fully-Convolutional Regression Network (FCRN) which efficiently performs text detection and bounding-box regression at all locations and multiple scales in an image. We discuss the relation of FCRN to the recently-introduced YOLO detector, as well as other end-to-end object detection systems based on deep learning. The resulting detection network significantly out performs current methods for text detection in natural images, achieving an F-measure of 84.2% on the standard ICDAR 2013 benchmark. Furthermore, it can process 15 images per second on a GPU.

##### Abstract (translated by Google)
在本文中，我们介绍一种新的自然图像文本检测方法。该方法包括两个方面的贡献：首先，一个快速和可扩展的引擎来生成杂乱的文本合成图像。该引擎以合适的方式将合成文本叠加到现有的背景图像上，从而说明本地3D场景几何。其次，我们使用合成图像来训练全卷积回归网络（FCRN），该网络可以在图像中的所有位置和多个尺度上高效地进行文本检测和边界框回归。我们讨论了FCRN与最近推出的YOLO探测器以及其他基于深度学习的端到端物体探测系统的关系。由此产生的检测网络显着地执行了自然图像中的文本检测的当前方法，在标准的ICDAR 2013基准中获得了84.2％的F-度量。而且，它可以在GPU上每秒处理15个图像。

##### URL
[https://arxiv.org/abs/1604.06646](https://arxiv.org/abs/1604.06646)

##### PDF
[https://arxiv.org/pdf/1604.06646](https://arxiv.org/pdf/1604.06646)

