---
layout: post
title: "Cognitive Action Laws: The Case of Visual Features"
date: 2018-08-28 08:12:23
categories: arXiv_CV
tags: arXiv_CV Regularization
author: Alessandro Betti, Marco Gori, Stefano Melacci
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a theory for understanding perceptual learning processes within the general framework of laws of nature. Neural networks are regarded as systems whose connections are Lagrangian variables, namely functions depending on time. They are used to minimize the cognitive action, an appropriate functional index that measures the agent interactions with the environment. The cognitive action contains a potential and a kinetic term that nicely resemble the classic formulation of regularization in machine learning. A special choice of the functional index, which leads to forth-order differential equations---Cognitive Action Laws (CAL)---exhibits a structure that mirrors classic formulation of machine learning. In particular, unlike the action of mechanics, the stationarity condition corresponds with the global minimum. Moreover, it is proven that typical asymptotic learning conditions on the weights can coexist with the initialization provided that the system dynamics is driven under a policy referred to as information overloading control. Finally, the theory is experimented for the problem of feature extraction in computer vision.

##### Abstract (translated by Google)
本文提出了一种在自然法则的一般框架内理解感知学习过程的理论。神经网络被认为是其连接是拉格朗日变量的系统，即取决于时间的函数。它们用于最小化认知行为，这是衡量代理与环境交互的适当功能指标。认知行为包含一个潜在的动力学术语，非常类似于机器学习中正则化的经典表述。功能指数的一个特殊选择，导致四阶微分方程---认知行为定律（CAL）---展示了一种反映机器学习的经典表述的结构。特别是，与力学的作用不同，平稳性条件对应于全局最小值。此外，已经证明，权重的典型渐近学习条件可以与初始化共存，条件是系统动态是在称为信息过载控制的策略下驱动的。最后，该理论针对计算机视觉中的特征提取问题进行了实验。

##### URL
[http://arxiv.org/abs/1808.09162](http://arxiv.org/abs/1808.09162)

##### PDF
[http://arxiv.org/pdf/1808.09162](http://arxiv.org/pdf/1808.09162)

