---
layout: post
title: "Twitter Sentiment Analysis: Lexicon Method, Machine Learning Method and Their Combination"
date: 2015-09-18 11:44:33
categories: arXiv_CL
tags: arXiv_CL Sentiment Sentiment_Classification Classification
author: Olga Kolchyna, Tharsis T. P. Souza, Philip Treleaven, Tomaso Aste
mathjax: true
---

* content
{:toc}

##### Abstract
This paper covers the two approaches for sentiment analysis: i) lexicon based method; ii) machine learning method. We describe several techniques to implement these approaches and discuss how they can be adopted for sentiment classification of Twitter messages. We present a comparative study of different lexicon combinations and show that enhancing sentiment lexicons with emoticons, abbreviations and social-media slang expressions increases the accuracy of lexicon-based classification for Twitter. We discuss the importance of feature generation and feature selection processes for machine learning sentiment classification. To quantify the performance of the main sentiment analysis methods over Twitter we run these algorithms on a benchmark Twitter dataset from the SemEval-2013 competition, task 2-B. The results show that machine learning method based on SVM and Naive Bayes classifiers outperforms the lexicon method. We present a new ensemble method that uses a lexicon based sentiment score as input feature for the machine learning approach. The combined method proved to produce more precise classifications. We also show that employing a cost-sensitive classifier for highly unbalanced datasets yields an improvement of sentiment classification performance up to 7%.

##### Abstract (translated by Google)
本文涵盖了情感分析的两种方法：i）基于词典的方法; ii）机器学习方法。我们描述了几种技术来实现这些方法，并讨论如何将它们用于Twitter消息的情感分类。我们提出了不同的词汇组合的比较研究，并表明用表情符号，缩写和社交媒体俚语表达增强情感词典增加了基于词典的Twitter分类的准确性。我们讨论机器学习情感分类的特征生成和特征选择过程的重要性。为了量化Twitter上的主要情感分析方法的性能，我们在SemEval-2013比赛的任务2-B的基准Twitter数据集上运行这些算法。结果表明，基于支持向量机和朴素贝叶斯分类器的机器学习方法优于词典方法。我们提出了一种新的集成方法，使用基于词典的情感分数作为机器学习方法的输入特征。结合的方法被证明能够产生更精确的分类。我们还表明，使用成本敏感的分类器来处理高度不平衡的数据集，会使情感分类性能提高7％。

##### URL
[https://arxiv.org/abs/1507.00955](https://arxiv.org/abs/1507.00955)

##### PDF
[https://arxiv.org/pdf/1507.00955](https://arxiv.org/pdf/1507.00955)

