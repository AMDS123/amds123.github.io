---
layout: post
title: "Convolutional Neural Networks Analyzed via Inverse Problem Theory and Sparse Representations"
date: 2018-07-20 18:45:09
categories: arXiv_AI
tags: arXiv_AI Sparse CNN
author: Cem Tarhan, Gozde Bozdagi Akar
mathjax: true
---

* content
{:toc}

##### Abstract
Inverse problems in imaging such as denoising, deblurring, superresolution (SR) have been addressed for many decades. In recent years, convolutional neural networks (CNNs) have been widely used for many inverse problem areas. Although their indisputable success, CNNs are not mathematically validated as to how and what they learn. In this paper, we prove that during training, CNN elements solve for inverse problems which are optimum solutions stored as CNN neuron filters. We discuss the necessity of mutual coherence between CNN layer elements in order for a network to converge to the optimum solution. We prove that required mutual coherence can be provided by the usage of residual learning and skip connections. We have set rules over training sets and depth of networks for better convergence, i.e. performance.

##### Abstract (translated by Google)
几十年来，人们已经解决了成像中的反问题，例如去噪，去模糊，超分辨率（SR）。近年来，卷积神经网络（CNN）已被广泛用于许多反问题领域。虽然他们无可争议的成功，但CNN在数学上并没有被证实如何以及他们学到了什么。在本文中，我们证明了在训练期间，CNN元素解决了逆问题，这是作为CNN神经元滤波器存储的最优解。我们讨论了CNN层元素之间相互一致性的必要性，以便网络收敛到最优解。我们证明了通过使用残差学习和跳过连接可以提供所需的相互一致性。我们对训练集和网络深度设定了规则，以实现更好的收敛，即性能。

##### URL
[http://arxiv.org/abs/1807.07998](http://arxiv.org/abs/1807.07998)

##### PDF
[http://arxiv.org/pdf/1807.07998](http://arxiv.org/pdf/1807.07998)

