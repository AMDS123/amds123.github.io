---
layout: post
title: "Moviescope: Large-scale Analysis of Movies using Multiple Modalities"
date: 2019-08-08 17:20:24
categories: arXiv_CV
tags: arXiv_CV Deep_Learning Prediction
author: Paola Cascante-Bonilla, Kalpathy Sitaraman, Mengjia Luo, Vicente Ordonez
mathjax: true
---

* content
{:toc}

##### Abstract
Film media is a rich form of artistic expression. Unlike photography, and short videos, movies contain a storyline that is deliberately complex and intricate in order to engage its audience. In this paper we present a large scale study comparing the effectiveness of visual, audio, text, and metadata-based features for predicting high-level information about movies such as their genre or estimated budget. We demonstrate the usefulness of content-based methods in this domain in contrast to human-based and metadata-based predictions in the era of deep learning. Additionally, we provide a comprehensive study of temporal feature aggregation methods for representing video and text and find that simple pooling operations are effective in this domain. We also show to what extent different modalities are complementary to each other. To this end, we also introduce Moviescope, a new large-scale dataset of 5,000 movies with corresponding movie trailers (video + audio), movie posters (images), movie plots (text), and metadata.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.03180](http://arxiv.org/abs/1908.03180)

##### PDF
[http://arxiv.org/pdf/1908.03180](http://arxiv.org/pdf/1908.03180)

