---
layout: post
title: "Temporal Network Representation Learning"
date: 2019-04-12 23:44:25
categories: arXiv_AI
tags: arXiv_AI Embedding Represenation_Learning Prediction
author: John Boaz Lee, Giang Nguyen, Ryan A. Rossi, Nesreen K. Ahmed, Eunyee Koh, Sungchul Kim
mathjax: true
---

* content
{:toc}

##### Abstract
Networks evolve continuously over time with the addition, deletion, and changing of links and nodes. Such temporal networks (or edge streams) consist of a sequence of timestamped edges and are seemingly ubiquitous. Despite the importance of accurately modeling the temporal information, most embedding methods ignore it entirely or approximate the temporal network using a sequence of static snapshot graphs. In this work, we introduce the notion of \emph{temporal walks} for learning dynamic embeddings from temporal networks. Temporal walks capture the temporally valid interactions (\eg, flow of information, spread of disease) in the dynamic network in a lossless fashion. Based on the notion of temporal walks, we describe a general class of embeddings called continuous-time dynamic network embeddings (CTDNEs) that completely avoid the issues and problems that arise when approximating the temporal network as a sequence of static snapshot graphs. Unlike previous work, CTDNEs learn dynamic node embeddings directly from the temporal network at the finest temporal granularity and thus use only temporally valid information. As such CTDNEs naturally support online learning of the node embeddings in a streaming real-time fashion. The experiments demonstrate the effectiveness of this class of embedding methods for prediction in temporal networks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.06449](http://arxiv.org/abs/1904.06449)

##### PDF
[http://arxiv.org/pdf/1904.06449](http://arxiv.org/pdf/1904.06449)

