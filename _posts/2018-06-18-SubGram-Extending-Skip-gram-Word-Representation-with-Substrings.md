---
layout: post
title: "SubGram: Extending Skip-gram Word Representation with Substrings"
date: 2018-06-18 09:31:38
categories: arXiv_CL
tags: arXiv_CL Language_Model
author: Tom Kocmi, Ond&#x159;ej Bojar
mathjax: true
---

* content
{:toc}

##### Abstract
Skip-gram (word2vec) is a recent method for creating vector representations of words ("distributed word representations") using a neural network. The representation gained popularity in various areas of natural language processing, because it seems to capture syntactic and semantic information about words without any explicit supervision in this respect. We propose SubGram, a refinement of the Skip-gram model to consider also the word structure during the training process, achieving large gains on the Skip-gram original test set.

##### Abstract (translated by Google)
Skip-gram（word2vec）是一种使用神经网络创建词的向量表示（“分布式词表示”）的最新方法。这种表现在自然语言处理的各个领域都很受欢迎，因为它似乎在这方面没有任何明确的监督就可以捕捉关于词语的句法和语义信息。我们提议SubGram，Skip-gram模型的改进，以在训练过程中考虑字结构，在Skip-gram原始测试集上实现大幅增益。

##### URL
[http://arxiv.org/abs/1806.06571](http://arxiv.org/abs/1806.06571)

##### PDF
[http://arxiv.org/pdf/1806.06571](http://arxiv.org/pdf/1806.06571)

