---
layout: post
title: "FOIL it! Find One mismatch between Image and Language caption"
date: 2017-05-03 11:07:13
categories: arXiv_CV
tags: arXiv_CV Caption Classification Detection
author: Ravi Shekhar, Sandro Pezzelle, Yauhen Klimovich, Aurelie Herbelot, Moin Nabi, Enver Sangineto, Raffaella Bernardi
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we aim to understand whether current language and vision (LaVi) models truly grasp the interaction between the two modalities. To this end, we propose an extension of the MSCOCO dataset, FOIL-COCO, which associates images with both correct and "foil" captions, that is, descriptions of the image that are highly similar to the original ones, but contain one single mistake ("foil word"). We show that current LaVi models fall into the traps of this data and perform badly on three tasks: a) caption classification (correct vs. foil); b) foil word detection; c) foil word correction. Humans, in contrast, have near-perfect performance on those tasks. We demonstrate that merely utilising language cues is not enough to model FOIL-COCO and that it challenges the state-of-the-art by requiring a fine-grained understanding of the relation between text and image.

##### Abstract (translated by Google)
在本文中，我们的目的是了解目前的语言和视觉（LaVi）模型是否真正掌握了这两种模式之间的相互作用。为此，我们提出了一个MSCOCO数据集FOIL-COCO的扩展，它将图像与正确和“箔”字幕相关联，即与原始图像高度相似的图像描述，但包含一个单一的错误（“箔字”）。我们表明，目前的LaVi模型陷入这个数据的陷阱，并执行三项任务：a）标题分类（正确与箔）; b）箔字检测; c）箔字修正。相比之下，人类在这些任务上表现近乎完美。我们证明，仅仅利用语言提示并不足以模拟FOIL-COCO，并且要求对文本和图像之间的关系进行细致的理解，从而挑战最新的技术水平。

##### URL
[https://arxiv.org/abs/1705.01359](https://arxiv.org/abs/1705.01359)

##### PDF
[https://arxiv.org/pdf/1705.01359](https://arxiv.org/pdf/1705.01359)

