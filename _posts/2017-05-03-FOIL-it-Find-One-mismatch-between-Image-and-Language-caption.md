---
layout: post
title: "FOIL it! Find One mismatch between Image and Language caption"
date: 2017-05-03 11:07:13
categories: arXiv_CV
tags: arXiv_CV Caption Classification Detection Relation
author: Ravi Shekhar, Sandro Pezzelle, Yauhen Klimovich, Aurelie Herbelot, Moin Nabi, Enver Sangineto, Raffaella Bernardi
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we aim to understand whether current language and vision (LaVi) models truly grasp the interaction between the two modalities. To this end, we propose an extension of the MSCOCO dataset, FOIL-COCO, which associates images with both correct and "foil" captions, that is, descriptions of the image that are highly similar to the original ones, but contain one single mistake ("foil word"). We show that current LaVi models fall into the traps of this data and perform badly on three tasks: a) caption classification (correct vs. foil); b) foil word detection; c) foil word correction. Humans, in contrast, have near-perfect performance on those tasks. We demonstrate that merely utilising language cues is not enough to model FOIL-COCO and that it challenges the state-of-the-art by requiring a fine-grained understanding of the relation between text and image.

##### Abstract (translated by Google)
在本文中，我们的目的是了解当前语言和视觉（LaVi）模型是否真正掌握了两种模式之间的相互作用。为此，我们提出了MSCOCO数据集FOIL-COCO的扩展，它将图像与正确和“箔”字幕相关联，即图像描述与原始图像高度相似，但包含一个错误（“箔字”）。我们发现当前的LaVi模型属于这些数据的陷阱并且在三个任务上表现不佳：a）字幕分类（正确与箔片）; b）箔字检测; c）箔字修正。相比之下，人类在这些任务上的表现几近完美。我们证明仅仅利用语言线索不足以模拟FOIL-COCO，并且通过要求对文本和图像之间的关系进行细粒度的理解来挑战最新技术。

##### URL
[https://arxiv.org/abs/1705.01359](https://arxiv.org/abs/1705.01359)

##### PDF
[https://arxiv.org/pdf/1705.01359](https://arxiv.org/pdf/1705.01359)

