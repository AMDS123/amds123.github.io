---
layout: post
title: "X-View: Graph-Based Semantic Multi-View Localization"
date: 2017-09-28 11:58:58
categories: arXiv_CV
tags: arXiv_CV
author: Abel Gawel, Carlo Del Don, Roland Siegwart, Juan Nieto, Cesar Cadena
mathjax: true
---

* content
{:toc}

##### Abstract
Global registration of multi-view robot data is a challenging task. Appearance-based global localization approaches often fail under drastic view-point changes, as representations have limited view-point invariance. This work is based on the idea that human-made environments contain rich semantics which can be used to disambiguate global localization. Here, we present X-View, a Multi-View Semantic Global Localization system. X-View leverages semantic graph descriptor matching for global localization, enabling localization under drastically different view-points. While the approach is general in terms of the semantic input data, we present and evaluate an implementation on visual data. We demonstrate the system in experiments on the publicly available SYNTHIA dataset, and a realistic urban dataset recorded with a simulator. On these data, our findings show that X-View is able to globally localize aerial-to-ground, and ground-to-ground robot data of drastically different view-points. Our approach achieves an accuracy of up to 85 % on global localizations in the multi-view case, while the benchmarked traditional appearance based method reaches up to 50 %.

##### Abstract (translated by Google)
多视图机器人数据的全球注册是一项具有挑战性的任务。基于外观的全局本地化方法通常在剧烈的视点变化下失败，因为表示具有有限的视点不变性。这项工作的基础是人造环境包含丰富的语义，可以用来消除全球本地化的歧义。在这里，我们提出一个多视图语义全球本地化系统X-View。 X-View利用语义图描述符匹配来进行全球本地化，从而能够在截然不同的视点下进行本地化。虽然这种方法在语义输入数据方面是一般的，但是我们提出并评估了一个关于可视化数据的实现。我们在公开可用的SYNTHIA数据集上演示实验系统，用模拟器记录现实的城市数据集。根据这些数据，我们的研究结果显示，X-View能够在全球范围内定位空中到地面以及地对地机器人数据截然不同的视点。我们的方法在多视图的情况下在全球本地化方面达到高达85％的准确度，而基准的基于传统外观的方法则高达50％。

##### URL
[https://arxiv.org/abs/1709.09905](https://arxiv.org/abs/1709.09905)

##### PDF
[https://arxiv.org/pdf/1709.09905](https://arxiv.org/pdf/1709.09905)

