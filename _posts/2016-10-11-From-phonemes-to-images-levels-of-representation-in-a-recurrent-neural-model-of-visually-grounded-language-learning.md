---
layout: post
title: "From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning"
date: 2016-10-11 14:00:28
categories: arXiv_CL
tags: arXiv_CL Image_Caption Face RNN
author: Lieke Gelderloos, Grzegorz Chrupała
mathjax: true
---

* content
{:toc}

##### Abstract
We present a model of visually-grounded language learning based on stacked gated recurrent neural networks which learns to predict visual features given an image description in the form of a sequence of phonemes. The learning task resembles that faced by human language learners who need to discover both structure and meaning from noisy and ambiguous data across modalities. We show that our model indeed learns to predict features of the visual context given phonetically transcribed image descriptions, and show that it represents linguistic information in a hierarchy of levels: lower layers in the stack are comparatively more sensitive to form, whereas higher layers are more sensitive to meaning.

##### Abstract (translated by Google)
我们提出了一种基于叠加门控递归神经网络的视觉接地语言学习模型，学习如何预测以音素序列形式给出图像描述的视觉特征。学习任务类似于人类语言学习者所面临的问题，他们需要从各种模式的嘈杂和模糊的数据中发现结构和意义。我们表明，我们的模型确实学会了预测语音转录图像描述的视觉环境的特征，并且表明它在层次层次上代表语言信息：堆栈中的下层对形式相对更敏感，而更高层次更多对意义敏感。

##### URL
[https://arxiv.org/abs/1610.03342](https://arxiv.org/abs/1610.03342)

##### PDF
[https://arxiv.org/pdf/1610.03342](https://arxiv.org/pdf/1610.03342)

