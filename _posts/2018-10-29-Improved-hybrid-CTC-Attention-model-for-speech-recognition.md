---
layout: post
title: "Improved hybrid CTC-Attention model for speech recognition"
date: 2018-10-29 09:28:33
categories: arXiv_SD
tags: arXiv_SD Attention Speech_Recognition RNN Classification Relation Recognition
author: Zhe Yuan, Zhuoran Lyu, Jiwei Li, Xi Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, end-to-end speech recognition with a hybrid model consisting of connectionist temporal classification(CTC) and the attention-based encoder-decoder achieved state-of-the-art results. In this paper, we propose a novel CTC decoder structure based on the experiments we conducted and explore the relation between decoding performance and the depth of encoder. We also apply attention smoothing mechanism to acquire more context information for subword-based decoding. Taken together, these strategies allow us to achieve a word error rate(WER) of 4.43% without LM and 3.34% with RNN-LM on the test-clean subset of the LibriSpeech corpora, which by far are the best reported WERs for end-to-end ASR systems on this dataset.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.12020](http://arxiv.org/abs/1810.12020)

##### PDF
[http://arxiv.org/pdf/1810.12020](http://arxiv.org/pdf/1810.12020)

