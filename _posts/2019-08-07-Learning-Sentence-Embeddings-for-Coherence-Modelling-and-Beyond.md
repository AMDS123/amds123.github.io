---
layout: post
title: "Learning Sentence Embeddings for Coherence Modelling and Beyond"
date: 2019-08-07 20:23:30
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Tanner Bohn, Yining Hu, Jinhang Zhang, Charles X. Ling
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel and effective technique for performing text coherence tasks while facilitating deeper insights into the data. Despite obtaining ever-increasing task performance, modern deep-learning approaches to NLP tasks often only provide users with the final network decision and no additional understanding of the data. In this work, we show that a new type of sentence embedding learned through self-supervision can be applied effectively to text coherence tasks while serving as a window through which deeper understanding of the data can be obtained. To produce these sentence embeddings, we train a recurrent neural network to take individual sentences and predict their location in a document in the form of a distribution over locations. We demonstrate that these embeddings, combined with simple visual heuristics, can be used to achieve performance competitive with state-of-the-art on multiple text coherence tasks, outperforming more complex and specialized approaches. Additionally, we demonstrate that these embeddings can provide insights useful to writers for improving writing quality and informing document structuring, and assisting readers in summarizing and locating information.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1804.08053](http://arxiv.org/abs/1804.08053)

##### PDF
[http://arxiv.org/pdf/1804.08053](http://arxiv.org/pdf/1804.08053)

