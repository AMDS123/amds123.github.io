---
layout: post
title: "3D Hand Pose Tracking and Estimation Using Stereo Matching"
date: 2016-10-23 18:39:53
categories: arXiv_CV
tags: arXiv_CV Segmentation Tracking Quantitative
author: Jiawei Zhang, Jianbo Jiao, Mingliang Chen, Liangqiong Qu, Xiaobin Xu, Qingxiong Yang
mathjax: true
---

* content
{:toc}

##### Abstract
3D hand pose tracking/estimation will be very important in the next generation of human-computer interaction. Most of the currently available algorithms rely on low-cost active depth sensors. However, these sensors can be easily interfered by other active sources and require relatively high power consumption. As a result, they are currently not suitable for outdoor environments and mobile devices. This paper aims at tracking/estimating hand poses using passive stereo which avoids these limitations. A benchmark with 18,000 stereo image pairs and 18,000 depth images captured from different scenarios and the ground-truth 3D positions of palm and finger joints (obtained from the manual label) is thus proposed. This paper demonstrates that the performance of the state-of-the art tracking/estimation algorithms can be maintained with most stereo matching algorithms on the proposed benchmark, as long as the hand segmentation is correct. As a result, a novel stereo-based hand segmentation algorithm specially designed for hand tracking/estimation is proposed. The quantitative evaluation demonstrates that the proposed algorithm is suitable for the state-of-the-art hand pose tracking/estimation algorithms and the tracking quality is comparable to the use of active depth sensors under different challenging scenarios.

##### Abstract (translated by Google)
3D手势的跟踪/估计在下一代人机交互中将非常重要。目前大部分可用的算法依赖于低成本的有源深度传感器。但是，这些传感器很容易受到其他活动源的干扰，并且需要相对较高的功耗。因此，他们目前不适合户外环境和移动设备。本文旨在使用被动立体声来追踪/估计手势，避免了这些限制。因此，提出了从不同场景拍摄的18,000个立体图像对和18,000个深度图像以及手掌和手指关节（从手动标签获得）的地面真实3D位置的基准。本文表明，只要手部分割正确，在所提出的基准测试中，大多数立体匹配算法可以保持最先进的跟踪/估计算法的性能。因此，提出了一种专门为手部跟踪/估计而设计的基于立体声的新型手部分割算法。定量评估表明，所提出的算法适合于最先进的手势跟踪/估计算法，并且跟踪质量与在不同具有挑战性的场景下使用主动深度传感器相当。

##### URL
[https://arxiv.org/abs/1610.07214](https://arxiv.org/abs/1610.07214)

##### PDF
[https://arxiv.org/pdf/1610.07214](https://arxiv.org/pdf/1610.07214)

