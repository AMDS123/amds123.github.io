---
layout: post
title: "ExpIt-OOS: Towards Learning from Planning in Imperfect Information Games"
date: 2018-08-30 05:04:44
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Andy Kitchen, Michela Benedetti
mathjax: true
---

* content
{:toc}

##### Abstract
The current state of the art in playing many important perfect information games, including Chess and Go, combines planning and deep reinforcement learning with self-play. We extend this approach to imperfect information games and present ExIt-OOS, a novel approach to playing imperfect information games within the Expert Iteration framework and inspired by AlphaZero. We use Online Outcome Sampling, an online search algorithm for imperfect information games in place of MCTS. While training online, our neural strategy is used to improve the accuracy of playouts in OOS, allowing a learning and planning feedback loop for imperfect information games.

##### Abstract (translated by Google)
在玩包括国际象棋和围棋在内的许多重要的完美信息游戏方面，目前的技术水平将计划和深度强化学习与自我游戏相结合。我们将这种方法扩展到不完美的信息游戏，并提出了ExIt-OOS，这是一种在Expert Iteration框架内播放不完美信息游戏并受AlphaZero启发的新方法。我们使用Online Outcome Sampling，一种用于代替MCTS的不完美信息游戏的在线搜索算法。在线培训时，我们的神经策略用于提高OOS中的播出准确性，允许学习和规划反馈循环用于不完美的信息游戏。

##### URL
[http://arxiv.org/abs/1808.10120](http://arxiv.org/abs/1808.10120)

##### PDF
[http://arxiv.org/pdf/1808.10120](http://arxiv.org/pdf/1808.10120)

