---
layout: post
title: "Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks"
date: 2017-08-23 12:35:56
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan
mathjax: true
---

* content
{:toc}

##### Abstract
Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images often fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant. In this work, we present a new approach that learns, in an unsupervised manner, a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training.

##### Abstract (translated by Google)
收集注释良好的图像数据集以训练现代机器学习算法对于许多任务而言过于昂贵。一个有吸引力的选择是渲染合成数据，在其中自动生成地面真实注释。不幸的是，纯粹在渲染图像上进行训练的模型往往不能推广到真实的图像。为了解决这个缺点，以前的工作引入了无监督域自适应算法，试图映射两个域之间的表示或学习提取域不变的特征。在这项工作中，我们提出了一种新的方法，以无监督的方式学习像素空间从一个域到另一个域的转换。我们的生成对抗网络（GAN）为基础的方法适应源域图像似乎从目标域绘制。我们的方法不仅产生合理的样本，而且在大量无监督的领域适应情景下，也大大优于现有技术。最后，我们证明了适应过程在训练过程中推广到了不可见的对象类。

##### URL
[https://arxiv.org/abs/1612.05424](https://arxiv.org/abs/1612.05424)

##### PDF
[https://arxiv.org/pdf/1612.05424](https://arxiv.org/pdf/1612.05424)

