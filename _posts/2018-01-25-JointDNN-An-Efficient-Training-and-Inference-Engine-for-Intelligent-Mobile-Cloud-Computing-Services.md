---
layout: post
title: "JointDNN: An Efficient Training and Inference Engine for Intelligent Mobile Cloud Computing Services"
date: 2018-01-25 22:20:11
categories: arXiv_AI
tags: arXiv_AI Optimization Inference Deep_Learning
author: Amir Erfan Eshratifar, Mohammad Saeed Abrishami, Massoud Pedram
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks are among the most influential architectures of deep learning algorithms, being deployed in many mobile intelligent applications. End-side services, such as intelligent personal assistants (IPAs), autonomous cars, and smart home services often employ either simple local models or complex remote models on the cloud. Mobile-only and cloud-only computations are currently the status quo approaches. In this paper, we propose an efficient, adaptive, and practical engine, JointDNN, for collaborative computation between a mobile device and cloud for DNNs in both inference and training phase. JointDNN not only provides an energy and performance efficient method of querying DNNs for the mobile side, but also benefits the cloud server by reducing the amount of its workload and communications compared to the cloud-only approach. Given the DNN architecture, we investigate the efficiency of processing some layers on the mobile device and some layers on the cloud server. We provide optimization formulations at layer granularity for forward and backward propagation in DNNs, which can adapt to mobile battery limitations and cloud server load constraints and quality of service. JointDNN achieves up to 18X and 32X reductions on the latency and mobile energy consumption of querying DNNs, respectively.

##### Abstract (translated by Google)
深度神经网络是深度学习算法中最有影响力的架构之一，被部署在许多移动智能应用中。终端服务，如智能个人助理（IPA），自动驾驶汽车和智能家居服务通常在云上采用简单的本地模型或复杂的远程模型。目前只有手机和纯云计算是现状。在本文中，我们提出了一个高效的，自适应的，实用的发动机JointDNN，用于DNN在移动设备和云之间的推理和训练阶段的协作计算。 JointDNN不仅为移动端提供了一种能量和性能高效的查询DNN的方法，而且与云端方法相比，通过减少工作负载和通信量，使云服务器受益。鉴于DNN体系结构，我们调查处理移动设备上的一些层以及云服务器上的一些层的效率。我们针对DNN中的前向和后向传播提供层级粒度的优化公式，可以适应移动电池的限制和云服务器的负载限制和服务质量。 JointDNN分别实现了查询DNN的延迟和移动能耗分别降低了18倍和32倍。

##### URL
[http://arxiv.org/abs/1801.08618](http://arxiv.org/abs/1801.08618)

##### PDF
[http://arxiv.org/pdf/1801.08618](http://arxiv.org/pdf/1801.08618)

