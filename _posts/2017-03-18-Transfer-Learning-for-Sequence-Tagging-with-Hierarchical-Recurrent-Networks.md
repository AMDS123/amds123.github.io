---
layout: post
title: "Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks"
date: 2017-03-18 20:21:44
categories: arXiv_SD
tags: arXiv_SD Transfer_Learning
author: Zhilin Yang, Ruslan Salakhutdinov, William W. Cohen
mathjax: true
---

* content
{:toc}

##### Abstract
Recent papers have shown that neural networks obtain state-of-the-art performance on several different sequence tagging tasks. One appealing property of such systems is their generality, as excellent performance can be achieved with a unified architecture and without task-specific feature engineering. However, it is unclear if such systems can be used for tasks without large amounts of training data. In this paper we explore the problem of transfer learning for neural sequence taggers, where a source task with plentiful annotations (e.g., POS tagging on Penn Treebank) is used to improve performance on a target task with fewer available annotations (e.g., POS tagging for microblogs). We examine the effects of transfer learning for deep hierarchical recurrent networks across domains, applications, and languages, and show that significant improvement can often be obtained. These improvements lead to improvements over the current state-of-the-art on several well-studied tasks.

##### Abstract (translated by Google)
最近的论文已经表明，神经网络在几个不同的序列标记任务上获得了最新的性能。这样的系统的一个吸引人的属性是它们的普遍性，因为通过统一的架构并且没有任务特定的特征工程可以实现出色的性能。然而，目前还不清楚这样的系统是否可以用于没有大量训练数据的任务。在本文中，我们探讨了神经序列标记器的转移学习问题，其中具有丰富注释的源任务（例如宾州树库上的POS标记）被用来改善具有较少可用注释的目标任务的性能（例如，POS标记微博）。我们研究跨领域，应用程序和语言的深层次递归网络的转移学习的效果，并显示经常可以获得显着的改进。这些改进导致了对当前最先进的几项研究得很好的任务的改进。

##### URL
[https://arxiv.org/abs/1703.06345](https://arxiv.org/abs/1703.06345)

##### PDF
[https://arxiv.org/pdf/1703.06345](https://arxiv.org/pdf/1703.06345)

