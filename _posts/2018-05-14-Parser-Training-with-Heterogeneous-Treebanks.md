---
layout: post
title: "Parser Training with Heterogeneous Treebanks"
date: 2018-05-14 09:52:27
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Sara Stymne, Miryam de Lhoneux, Aaron Smith, Joakim Nivre
mathjax: true
---

* content
{:toc}

##### Abstract
How to make the most of multiple heterogeneous treebanks when training a monolingual dependency parser is an open question. We start by investigating previously suggested, but little evaluated, strategies for exploiting multiple treebanks based on concatenating training sets, with or without fine-tuning. We go on to propose a new method based on treebank embeddings. We perform experiments for several languages and show that in many cases fine-tuning and treebank embeddings lead to substantial improvements over single treebanks or concatenation, with average gains of 2.0--3.5 LAS points. We argue that treebank embeddings should be preferred due to their conceptual simplicity, flexibility and extensibility.

##### Abstract (translated by Google)
在培训单语依赖解析器时如何充分利用多种异构树库是一个悬而未决的问题。我们从调查以前的建议开始，但很少评估，基于连接训练集利用多个树库的策略，无论是否进行微调。我们继续提出一种基于树库嵌入的新方法。我们对多种语言进行实验，结果表明在许多情况下，微调和树库嵌入导致对单树库或级联的实质性改进，平均增益为2.0-3.5个LAS点。我们认为树库嵌入应该是优选的，因为它们的概念简单，灵活性和可扩展性。

##### URL
[https://arxiv.org/abs/1805.05089](https://arxiv.org/abs/1805.05089)

##### PDF
[https://arxiv.org/pdf/1805.05089](https://arxiv.org/pdf/1805.05089)

