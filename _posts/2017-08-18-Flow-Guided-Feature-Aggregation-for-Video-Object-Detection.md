---
layout: post
title: "Flow-Guided Feature Aggregation for Video Object Detection"
date: 2017-08-18 12:30:38
categories: arXiv_CV
tags: arXiv_CV Object_Detection Detection Recognition
author: Xizhou Zhu, Yujie Wang, Jifeng Dai, Lu Yuan, Yichen Wei
mathjax: true
---

* content
{:toc}

##### Abstract
Extending state-of-the-art object detectors from image to video is challenging. The accuracy of detection suffers from degenerated object appearances in videos, e.g., motion blur, video defocus, rare poses, etc. Existing work attempts to exploit temporal information on box level, but such methods are not trained end-to-end. We present flow-guided feature aggregation, an accurate and end-to-end learning framework for video object detection. It leverages temporal coherence on feature level instead. It improves the per-frame features by aggregation of nearby features along the motion paths, and thus improves the video recognition accuracy. Our method significantly improves upon strong single-frame baselines in ImageNet VID, especially for more challenging fast moving objects. Our framework is principled, and on par with the best engineered systems winning the ImageNet VID challenges 2016, without additional bells-and-whistles. The proposed method, together with Deep Feature Flow, powered the winning entry of ImageNet VID challenges 2017. The code is available at this https URL

##### Abstract (translated by Google)
将最先进的物体检测器从图像扩展到视频是具有挑战性的。检测的准确性受到视频中退化的对象外观的影响，例如，运动模糊，视频离焦，稀有姿势等。现有的工作试图利用盒级的时间信息，但是这种方法不是端对端训练。我们提出了流引导的特征聚合，一个视频对象检测的准确和端到端的学习框架。它在功能级别上利用时间相干性。它通过沿着运动路径聚集附近的特征来改进每帧特征，从而提高了视频识别的准确性。我们的方法显着提高了ImageNet VID中强大的单帧基线，特别是对于更具挑战性的快速移动物体。我们的框架是有原则的，与获得2016年ImageNet VID挑战的最佳工程系统一样，没有额外的花招。所提议的方法与Deep Feature Flow一起，推动了2017年ImageNet VID挑战的获胜条目。该代码可在此https URL

##### URL
[https://arxiv.org/abs/1703.10025](https://arxiv.org/abs/1703.10025)

##### PDF
[https://arxiv.org/pdf/1703.10025](https://arxiv.org/pdf/1703.10025)

