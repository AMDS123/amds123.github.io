---
layout: post
title: "Been There, Done That: Meta-Learning with Episodic Recall"
date: 2018-05-24 14:15:27
categories: arXiv_AI
tags: arXiv_AI RNN
author: Samuel Ritter, Jane X. Wang, Zeb Kurth-Nelson, Siddhant M. Jayakumar, Charles Blundell, Razvan Pascanu, Matthew Botvinick
mathjax: true
---

* content
{:toc}

##### Abstract
Meta-learning agents excel at rapidly learning new tasks from open-ended task distributions; yet, they forget what they learn about each task as soon as the next begins. When tasks reoccur - as they do in natural environments - metalearning agents must explore again instead of immediately exploiting previously discovered solutions. We propose a formalism for generating open-ended yet repetitious environments, then develop a meta-learning architecture for solving these environments. This architecture melds the standard LSTM working memory with a differentiable neural episodic memory. We explore the capabilities of agents with this episodic LSTM in five meta-learning environments with reoccurring tasks, ranging from bandits to navigation and stochastic sequential decision problems.

##### Abstract (translated by Google)
元学习代理擅长从开放式任务分配中快速学习新任务;但是，一旦下一次开始，他们就会忘记他们对每项任务的了解。当任务再次发生时 - 就像他们在自然环境中所做的那样 - 元认知代理必须重新探索，而不是立即开发先前发现的解决方案。我们提出了一种生成开放式但又重复的环境的形式化方法，然后开发出一种解决这些环境的元学习体系结构。这种架构融合了标准LSTM工作记忆与可微的神经情节记忆。我们在5个元学习环境中探索具有这种情景式LSTM的智能体的能力，其中包含从土匪到导航以及随机顺序决策问题的重复任务。

##### URL
[http://arxiv.org/abs/1805.09692](http://arxiv.org/abs/1805.09692)

##### PDF
[http://arxiv.org/pdf/1805.09692](http://arxiv.org/pdf/1805.09692)

