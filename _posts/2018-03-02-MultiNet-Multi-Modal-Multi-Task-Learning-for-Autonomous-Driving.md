---
layout: post
title: "MultiNet: Multi-Modal Multi-Task Learning for Autonomous Driving"
date: 2018-03-02 01:39:52
categories: arXiv_RO
tags: arXiv_RO Deep_Learning
author: Sauhaarda Chowdhuri, Tushar Pankaj, Karl Zipser
mathjax: true
---

* content
{:toc}

##### Abstract
Several deep learning approaches have been applied to the autonomous driving task, many employing end-to-end deep neural networks. Autonomous driving is complex, utilizing multiple behavioral modalities ranging from lane changing to turning and stopping. However, most existing approaches do not factor in the different behavioral modalities of the driving task into the training strategy. This paper describes a technique for using Multi-Modal Multi-Task Learning, which we denote as MultiNet which considers multiple behavioral modalities as distinct modes of operation for an end-to-end autonomous deep neural network utilizing the insertion of modal information as secondary input data. Using labeled data from hours of driving our fleet of 1/10th scale model cars, we trained different neural networks to imitate the steering angle and driving speed of human control of a car. We show that in each case, MultiNet models outperform networks trained on individual tasks, while using a fraction of the number of parameters.

##### Abstract (translated by Google)
几种深度学习方法已经应用于自动驾驶任务，许多采用端到端的深度神经网络。自动驾驶是复杂的，利用从车道变换到转弯和停车等多种行为模式。然而，大多数现有的方法并没有将驾驶任务的不同行为模式纳入训练策略。本文描述了一种使用多模式多任务学习的技术，我们将其称为MultiNet，它将多种行为模式视为一种端到端自主深度神经网络的独特操作模式，该模式利用插入模态信息作为辅助输入数据。使用驾驶我们的1/10比例模型车的小时数的标记数据，我们训练了不同的神经网络来模拟汽车人体控制的转向角和驾驶速度。我们表明，在每种情况下，MultiNet模型在使用参数数量的一小部分的同时，胜过在单个任务上训练的网络。

##### URL
[http://arxiv.org/abs/1709.05581](http://arxiv.org/abs/1709.05581)

##### PDF
[http://arxiv.org/pdf/1709.05581](http://arxiv.org/pdf/1709.05581)

