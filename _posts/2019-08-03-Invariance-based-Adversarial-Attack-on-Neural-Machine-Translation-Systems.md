---
layout: post
title: "Invariance-based Adversarial Attack on Neural Machine Translation Systems"
date: 2019-08-03 12:59:40
categories: arXiv_CL
tags: arXiv_CL Adversarial Attention NMT RNN
author: Akshay Chaturvedi, Abijith KP, Utpal Garain
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, NLP models have been shown to be susceptible to adversarial attacks. In this paper, we explore adversarial attacks on neural machine translation (NMT) systems. Given a sentence in the source language, the goal of the proposed attack is to change multiple words while ensuring that the predicted translation remains unchanged. In order to choose the word from the source vocabulary, we propose a soft-attention based technique. The experiments are conducted on two language pairs: English-German (en-de) and English-French (en-fr) and two state-of-the-art NMT systems: BLSTM-based encoder-decoder with attention and Transformer. The proposed soft-attention based technique outperforms existing methods like HotFlip by a significant margin for all the conducted experiments The results demonstrate that state-of-the-art NMT systems are unable to capture the semantics of the source language.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.01165](http://arxiv.org/abs/1908.01165)

##### PDF
[http://arxiv.org/pdf/1908.01165](http://arxiv.org/pdf/1908.01165)

