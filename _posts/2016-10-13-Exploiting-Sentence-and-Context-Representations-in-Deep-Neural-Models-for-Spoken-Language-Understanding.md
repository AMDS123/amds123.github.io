---
layout: post
title: "Exploiting Sentence and Context Representations in Deep Neural Models for Spoken Language Understanding"
date: 2016-10-13 15:11:40
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition CNN Represenation_Learning Deep_Learning Recognition
author: Lina M. Rojas Barahona, Milica Gasic, Nikola Mrkšić, Pei-Hao Su, Stefan Ultes, Tsung-Hsien Wen, Steve Young
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a deep learning architecture for the semantic decoder component of a Statistical Spoken Dialogue System. In a slot-filling dialogue, the semantic decoder predicts the dialogue act and a set of slot-value pairs from a set of n-best hypotheses returned by the Automatic Speech Recognition. Most current models for spoken language understanding assume (i) word-aligned semantic annotations as in sequence taggers and (ii) delexicalisation, or a mapping of input words to domain-specific concepts using heuristics that try to capture morphological variation but that do not scale to other domains nor to language variation (e.g., morphology, synonyms, paraphrasing ). In this work the semantic decoder is trained using unaligned semantic annotations and it uses distributed semantic representation learning to overcome the limitations of explicit delexicalisation. The proposed architecture uses a convolutional neural network for the sentence representation and a long-short term memory network for the context representation. Results are presented for the publicly available DSTC2 corpus and an In-car corpus which is similar to DSTC2 but has a significantly higher word error rate (WER).

##### Abstract (translated by Google)
本文为统计口语对话系统的语义解码器组件提供了一个深度的学习架构。在时隙填充对话中，语义解码器从自动语音识别返回的一组n个最佳假设中预测对话行为和一组时隙值对。目前大多数用于口头语言理解的模型都假定：（i）与序列标注器中的字对齐的语义注释和（ii）delexicalisation，或者使用尝试捕获形态变化但不能缩放的启发式将输入字映射到领域特定概念到其他领域或语言变体（例如形态学，同义词，释义）。在这项工作中，语义解码器使用未对齐的语义注释进行训练，并且使用分布式语义表示学习来克服显式的错误化的局限性。所提出的架构针对句子表示使用卷积神经网络，并且针对上下文表示使用长短期记忆网络。针对公开可用的DSTC2语料库和类似于DSTC2但具有显着较高的字错误率（WER）的车内语料库，提供结果。

##### URL
[https://arxiv.org/abs/1610.04120](https://arxiv.org/abs/1610.04120)

##### PDF
[https://arxiv.org/pdf/1610.04120](https://arxiv.org/pdf/1610.04120)

