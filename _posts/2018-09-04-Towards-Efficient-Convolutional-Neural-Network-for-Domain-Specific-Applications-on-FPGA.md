---
layout: post
title: "Towards Efficient Convolutional Neural Network for Domain-Specific Applications on FPGA"
date: 2018-09-04 13:58:22
categories: arXiv_CV
tags: arXiv_CV CNN Transfer_Learning Recognition
author: Ruizhe Zhao, Ho-Cheung Ng, Wayne Luk, Xinyu Niu
mathjax: true
---

* content
{:toc}

##### Abstract
FPGA becomes a popular technology for implementing Convolutional Neural Network (CNN) in recent years. Most CNN applications on FPGA are domain-specific, e.g., detecting objects from specific categories, in which commonly-used CNN models pre-trained on general datasets may not be efficient enough. This paper presents TuRF, an end-to-end CNN acceleration framework to efficiently deploy domain-specific applications on FPGA by transfer learning that adapts pre-trained models to specific domains, replacing standard convolution layers with efficient convolution blocks, and applying layer fusion to enhance hardware design performance. We evaluate TuRF by deploying a pre-trained VGG-16 model for a domain-specific image recognition task onto a Stratix V FPGA. Results show that designs generated by TuRF achieve better performance than prior methods for the original VGG-16 and ResNet-50 models, while for the optimised VGG-16 model TuRF designs are more accurate and easier to process.

##### Abstract (translated by Google)
近年来，FPGA成为实现卷积神经网络（CNN）的流行技术。 FPGA上的大多数CNN应用是特定于域的，例如，检测来自特定类别的对象，其中在一般数据集上预先训练的常用CNN模型可能不够有效。本文介绍了TuRF，这是一种端到端的CNN加速框架，可通过传输学习在FPGA上有效地部署特定于域的应用程序，使预先训练的模型适应特定的域，用高效的卷积块替换标准卷积层，并应用层融合增强硬件设计性能。我们通过在Stratix V FPGA上部署针对特定领域的图像识别任务的预先训练的VGG-16模型来评估TuRF。结果表明，TuRF生成的设计比原始VGG-16和ResNet-50模型的先前方法具有更好的性能，而对于优化的VGG-16模型，TuRF设计更精确，更易于处理。

##### URL
[http://arxiv.org/abs/1809.03318](http://arxiv.org/abs/1809.03318)

##### PDF
[http://arxiv.org/pdf/1809.03318](http://arxiv.org/pdf/1809.03318)

