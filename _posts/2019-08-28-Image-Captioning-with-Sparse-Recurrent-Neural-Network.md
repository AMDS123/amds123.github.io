---
layout: post
title: "Image Captioning with Sparse Recurrent Neural Network"
date: 2019-08-28 15:53:13
categories: arXiv_CV
tags: arXiv_CV Image_Caption Sparse Attention Caption RNN
author: Jia Huei Tan, Chee Seng Chan, Joon Huang Chuah
mathjax: true
---

* content
{:toc}

##### Abstract
Recurrent Neural Network (RNN) has been deployed as the de facto model to tackle a wide variety of language generation problems and achieved state-of-the-art (SOTA) performance. However despite its impressive results, the large number of parameters in the RNN model makes deployment in mobile and embedded devices infeasible. Driven by this problem, many works have proposed a number of pruning methods to reduce the sizes of the RNN model. In this work, we propose an end-to-end pruning method for image captioning models equipped with visual attention. Our proposed method is able to achieve sparsity levels up to 97.5% without significant performance loss relative to the baseline (around 1% loss at 40x compression of GRU model). Our method is also simple to use and tune, facilitating faster development times for neural network practitioners. We perform extensive experiments on the popular MS-COCO dataset in order to empirically validate the efficacy of our proposed method.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.10797](http://arxiv.org/abs/1908.10797)

##### PDF
[http://arxiv.org/pdf/1908.10797](http://arxiv.org/pdf/1908.10797)

