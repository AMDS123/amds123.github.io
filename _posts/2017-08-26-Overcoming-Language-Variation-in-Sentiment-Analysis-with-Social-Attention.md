---
layout: post
title: "Overcoming Language Variation in Sentiment Analysis with Social Attention"
date: 2017-08-26 15:11:01
categories: arXiv_CL
tags: arXiv_CL Sentiment Review Attention Classification
author: Yi Yang, Jacob Eisenstein
mathjax: true
---

* content
{:toc}

##### Abstract
Variation in language is ubiquitous, particularly in newer forms of writing such as social media. Fortunately, variation is not random, it is often linked to social properties of the author. In this paper, we show how to exploit social networks to make sentiment analysis more robust to social language variation. The key idea is linguistic homophily: the tendency of socially linked individuals to use language in similar ways. We formalize this idea in a novel attention-based neural network architecture, in which attention is divided among several basis models, depending on the author's position in the social network. This has the effect of smoothing the classification function across the social network, and makes it possible to induce personalized classifiers even for authors for whom there is no labeled data or demographic metadata. This model significantly improves the accuracies of sentiment analysis on Twitter and on review data.

##### Abstract (translated by Google)
语言的变化无处不在，尤其是在社交媒体等较新的写作形式中。幸运的是，变化不是随机的，它往往与作者的社会属性有关。在本文中，我们展示了如何利用社交网络使情感分析对于社交语言的变化更加强大。关键的思想是语言同质化：社会联系的个人以类似的方式使用语言的倾向。我们将这个想法在一个基于注意力的神经网络架构中形式化，其中注意力根据作者在社交网络中的位置在多个基础模型之间进行划分。这具有平滑整个社交网络的分类功能的效果，并且使得即使对于没有标签化数据或人口元数据的作者也能够引入个性化的分类器。这个模型显着提高了Twitter上的情感分析的准确性和审查数据。

##### URL
[https://arxiv.org/abs/1511.06052](https://arxiv.org/abs/1511.06052)

##### PDF
[https://arxiv.org/pdf/1511.06052](https://arxiv.org/pdf/1511.06052)

