---
layout: post
title: "ADAGIO: Interactive Experimentation with Adversarial Attack and Defense for Audio"
date: 2018-05-30 08:24:52
categories: arXiv_SD
tags: arXiv_SD Adversarial Speech_Recognition Recognition
author: Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Li Chen, Michael E. Kounavis, Duen Horng Chau
mathjax: true
---

* content
{:toc}

##### Abstract
Adversarial machine learning research has recently demonstrated the feasibility to confuse automatic speech recognition (ASR) models by introducing acoustically imperceptible perturbations to audio samples. To help researchers and practitioners gain better understanding of the impact of such attacks, and to provide them with tools to help them more easily evaluate and craft strong defenses for their models, we present ADAGIO, the first tool designed to allow interactive experimentation with adversarial attacks and defenses on an ASR model in real time, both visually and aurally. ADAGIO incorporates AMR and MP3 audio compression techniques as defenses, which users can interactively apply to attacked audio samples. We show that these techniques, which are based on psychoacoustic principles, effectively eliminate targeted attacks, reducing the attack success rate from 92.5% to 0%. We will demonstrate ADAGIO and invite the audience to try it on the Mozilla Common Voice dataset.

##### Abstract (translated by Google)
对抗机器学习研究最近证明了通过引入对音频样本的声学微不稳定扰动来混淆自动语音识别（ASR）模型的可行性。为了帮助研究人员和从业人员更好地了解此类攻击的影响，并为他们提供工具以帮助他们更轻松地为他们的模型评估和制定强大的防御措施，我们提供了ADAGIO，这是第一款旨在允许交互式实验与敌对攻击的工具并在视觉和听觉上实时防御ASR模型。 ADAGIO采用了AMR和MP3音频压缩技术作为防御措施，用户可以交互式应用于受到攻击的音频样本。我们表明，这些基于心理声学原理的技术有效地消除了有针对性的攻击，将攻击成功率从92.5％降低到了0％。我们将演示ADAGIO并邀请观众在Mozilla Common Voice数据集上进行试用。

##### URL
[http://arxiv.org/abs/1805.11852](http://arxiv.org/abs/1805.11852)

##### PDF
[http://arxiv.org/pdf/1805.11852](http://arxiv.org/pdf/1805.11852)

