---
layout: post
title: "Learning how to Active Learn: A Deep Reinforcement Learning Approach"
date: 2017-08-08 07:06:48
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning Recognition
author: Meng Fang, Yuan Li, Trevor Cohn
mathjax: true
---

* content
{:toc}

##### Abstract
Active learning aims to select a small subset of data for annotation such that a classifier learned on the data is highly accurate. This is usually done using heuristic selection methods, however the effectiveness of such methods is limited and moreover, the performance of heuristics varies between datasets. To address these shortcomings, we introduce a novel formulation by reframing the active learning as a reinforcement learning problem and explicitly learning a data selection policy, where the policy takes the role of the active learning heuristic. Importantly, our method allows the selection policy learned using simulation on one language to be transferred to other languages. We demonstrate our method using cross-lingual named entity recognition, observing uniform improvements over traditional active learning.

##### Abstract (translated by Google)
主动学习的目标是选择一小部分数据进行注释，使得从数据上学习的分类器具有高度的准确性。这通常使用启发式选择方法来完成，但是这种方法的有效性是有限的，而且启发式的性能在数据集之间是不同的。为了解决这些缺点，我们引入了一种新的方法，将主动学习作为强化学习问题，并明确地学习数据选择策略，其中策略扮演主动学习启发式的角色。重要的是，我们的方法允许使用一种语言的模拟学习的选择策略转移到其他语言。我们证明我们的方法使用跨语言命名实体识别，观察统一改进，超过传统的主动学习。

##### URL
[https://arxiv.org/abs/1708.02383](https://arxiv.org/abs/1708.02383)

##### PDF
[https://arxiv.org/pdf/1708.02383](https://arxiv.org/pdf/1708.02383)

