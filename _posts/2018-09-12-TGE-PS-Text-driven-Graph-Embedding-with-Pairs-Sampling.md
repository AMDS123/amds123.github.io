---
layout: post
title: "TGE-PS: Text-driven Graph Embedding with Pairs Sampling"
date: 2018-09-12 02:53:00
categories: arXiv_AI
tags: arXiv_AI Face Embedding Prediction
author: Liheng Chen, Yanru Qu, Zhenghui Wang, Lin Qiu, Weinan Zhang, Ken Chen, Shaodian Zhang, Yong Yu
mathjax: true
---

* content
{:toc}

##### Abstract
In graphs with rich text information, constructing expressive graph representations requires incorporating textual information with structural information. Graph embedding models are becoming more and more popular in representing graphs, yet they are faced with two issues: sampling efficiency and text utilization. Through analyzing existing models, we find their training objectives are composed of pairwise proximities, and there are large amounts of redundant node pairs in Random Walk-based methods. Besides, inferring graph structures directly from texts (also known as zero-shot scenario) is a problem that requires higher text utilization. To solve these problems, we propose a novel Text-driven Graph Embedding with Pairs Sampling (TGE-PS) framework. TGE-PS uses Pairs Sampling (PS) to generate training samples which reduces ~99% training samples and is competitive compared to Random Walk. TGE-PS uses Text-driven Graph Embedding (TGE) which adopts word- and character-level embeddings to generate node embeddings. We evaluate TGE-PS on several real-world datasets, and experimental results demonstrate that TGE-PS produces state-of-the-art results in traditional and zero-shot link prediction tasks.

##### Abstract (translated by Google)
在具有丰富文本信息的图中，构建表达图表示需要将文本信息与结构信息相结合。图形嵌入模型在表示图形时变得越来越流行，但它们面临两个问题：采样效率和文本利用率。通过对现有模型的分析，我们发现它们的训练目标由成对的邻近性组成，并且在基于随机游走的方法中存在大量的冗余节点对。此外，直接从文本推断图形结构（也称为零镜头场景）是一个需要更高文本利用率的问题。为了解决这些问题，我们提出了一种新的带对采样的文本驱动图嵌入（TGE-PS）框架。 TGE-PS使用对采样（PS）生成训练样本，这些样本减少了约99％的训练样本，并且与随机漫步相比具有竞争力。 TGE-PS使用文本驱动图嵌入（TGE），它采用字和字符级嵌入来生成节点嵌入。我们在几个真实数据集上评估TGE-PS，实验结果表明TGE-PS在传统和零射击链路预测任务中产生了最先进的结果。

##### URL
[http://arxiv.org/abs/1809.04234](http://arxiv.org/abs/1809.04234)

##### PDF
[http://arxiv.org/pdf/1809.04234](http://arxiv.org/pdf/1809.04234)

