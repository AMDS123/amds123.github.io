---
layout: post
title: "Global-and-local attention networks for visual recognition"
date: 2018-05-22 19:12:47
categories: arXiv_CV
tags: arXiv_CV Salient Attention CNN Recognition
author: Drew Linsley, Dan Scheibler, Sven Eberhardt, Thomas Serre
mathjax: true
---

* content
{:toc}

##### Abstract
State-of-the-art deep convolutional networks (DCNs) such as squeeze-and- excitation (SE) residual networks implement a form of attention, also known as contextual guidance, which is derived from global image features. Here, we explore a complementary form of attention, known as visual saliency, which is derived from local image features. We extend the SE module with a novel global-and-local attention (GALA) module which combines both forms of attention -- resulting in state-of-the-art accuracy on ILSVRC. We further describe ClickMe.ai, a large-scale online experiment designed for human participants to identify diagnostic image regions to co-train a GALA network. Adding humans-in-the-loop is shown to significantly improve network accuracy, while also yielding visual features that are more interpretable and more similar to those used by human observers.

##### Abstract (translated by Google)
诸如挤压和激励（SE）残余网络之类的最先进的深度卷积网络（DCN）实现了一种形式的关注，也被称为上下文引导，其从全局图像特征导出。在这里，我们探索了一种补充形式的注意力，称为视觉显着性，它来源于局部图像特征。我们用一种新颖的全球和地方注意力（GALA）模块来扩展SE模块，该模块将两种形式的注意力结合在一起，从而在ILSVRC上获得最新的准确性。我们进一步描述了ClickMe.ai，这是一个为人类参与者设计的大型在线实验，用于识别诊断图像区域以共同训练GALA网络。加入人类在环路中显示出可以显着提高网络的准确性，同时还产生更多的可解释和更类似于人类观察者所使用的视觉特征。

##### URL
[http://arxiv.org/abs/1805.08819](http://arxiv.org/abs/1805.08819)

##### PDF
[http://arxiv.org/pdf/1805.08819](http://arxiv.org/pdf/1805.08819)

