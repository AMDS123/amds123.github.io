---
layout: post
title: "The Effects of JPEG and JPEG2000 Compression on Attacks using Adversarial Examples"
date: 2018-03-28 05:20:46
categories: arXiv_CV
tags: arXiv_CV Adversarial Classification
author: Ayse Elvan Aydemir, Alptekin Temizel, Tugba Taskaya Temizel
mathjax: true
---

* content
{:toc}

##### Abstract
Adversarial examples are known to have a negative effect on the performance of classifiers which have otherwise good performance on undisturbed images. These examples are generated by adding non-random noise to the testing samples in order to make classifier misclassify the given data. Adversarial attacks use these intentionally generated examples and they pose a security risk to the machine learning based systems. To be immune to such attacks, it is desirable to have a pre-processing mechanism which removes these effects causing misclassification while keeping the content of the image. JPEG and JPEG2000 image compression techniques suppress the high-frequency content taking the human visual system into account. In this paper, to reduce adversarial noise, JPEG and JPEG2000 compressions are applied to adversarial examples and their classification performance was measured.

##### Abstract (translated by Google)
已知敌对的例子对分类器的性能具有负面影响，所述分类器在未受干扰的图像上具有其他良好性能。这些示例是通过向测试样本添加非随机噪声来生成的，以使分类器对给定数据进行错误分类。敌对攻击使用这些有意生成的例子，它们对基于机器学习的系统构成安全风险。为了不受此类攻击的影响，需要有一个预处理机制，在保留图像内容的同时消除导致错误分类的这些效应。 JPEG和JPEG2000图像压缩技术可抑制考虑到人类视觉系统的高频内容。在本文中，为了减少对抗噪声，JPEG和JPEG2000压缩应用于对抗性例子，并测量它们的分类性能。

##### URL
[https://arxiv.org/abs/1803.10418](https://arxiv.org/abs/1803.10418)

##### PDF
[https://arxiv.org/pdf/1803.10418](https://arxiv.org/pdf/1803.10418)

