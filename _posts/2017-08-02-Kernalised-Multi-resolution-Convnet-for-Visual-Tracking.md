---
layout: post
title: "Kernalised Multi-resolution Convnet for Visual Tracking"
date: 2017-08-02 02:20:12
categories: arXiv_CV
tags: arXiv_CV Tracking CNN Object_Tracking RNN Deep_Learning Relation
author: Di Wu, Wenbin Zou, Xia Li, Yong Zhao
mathjax: true
---

* content
{:toc}

##### Abstract
Visual tracking is intrinsically a temporal problem. Discriminative Correlation Filters (DCF) have demonstrated excellent performance for high-speed generic visual object tracking. Built upon their seminal work, there has been a plethora of recent improvements relying on convolutional neural network (CNN) pretrained on ImageNet as a feature extractor for visual tracking. However, most of their works relying on ad hoc analysis to design the weights for different layers either using boosting or hedging techniques as an ensemble tracker. In this paper, we go beyond the conventional DCF framework and propose a Kernalised Multi-resolution Convnet (KMC) formulation that utilises hierarchical response maps to directly output the target movement. When directly deployed the learnt network to predict the unseen challenging UAV tracking dataset without any weight adjustment, the proposed model consistently achieves excellent tracking performance. Moreover, the transfered multi-reslution CNN renders it possible to be integrated into the RNN temporal learning framework, therefore opening the door on the end-to-end temporal deep learning (TDL) for visual tracking.

##### Abstract (translated by Google)
视觉追踪本质上是一个时间问题。鉴别相关滤波器（DCF）已经证明了高速通用视觉对象跟踪的出色性能。基于他们开创性的工作，最近有很多改进，依靠在ImageNet上预处理的卷积神经网络（CNN）作为视觉跟踪的特征提取器。然而，他们大多数的作品依靠特设分析来设计不同层次的权重，或者使用增强或套期保值技术作为整体跟踪器。在本文中，我们超越了传统的DCF框架，提出了利用分层响应图直接输出目标运动的核化多分辨率通信（KMC）公式。当直接部署学习网络来预测看不见的具有挑战性的无人机跟踪数据集时，无需调整任何权重，所提出的模型一直实现出色的跟踪性能。此外，传输的多分辨CNN使其有可能被整合到RNN时间学习框架中，从而开启了视频跟踪的端到端时间深度学习（TDL）的大门。

##### URL
[https://arxiv.org/abs/1708.00577](https://arxiv.org/abs/1708.00577)

##### PDF
[https://arxiv.org/pdf/1708.00577](https://arxiv.org/pdf/1708.00577)

