---
layout: post
title: "Combining Representation Learning with Logic for Language Processing"
date: 2017-12-27 21:09:36
categories: arXiv_CL
tags: arXiv_CL Knowledge Represenation_Learning Optimization
author: Tim Rockt&#xe4;schel
mathjax: true
---

* content
{:toc}

##### Abstract
The current state-of-the-art in many natural language processing and automated knowledge base completion tasks is held by representation learning methods which learn distributed vector representations of symbols via gradient-based optimization. They require little or no hand-crafted features, thus avoiding the need for most preprocessing steps and task-specific assumptions. However, in many cases representation learning requires a large amount of annotated training data to generalize well to unseen data. Such labeled training data is provided by human annotators who often use formal logic as the language for specifying annotations. This thesis investigates different combinations of representation learning methods with logic for reducing the need for annotated training data, and for improving generalization.

##### Abstract (translated by Google)
目前在许多自然语言处理和自动化知识库完成任务中的最新技术是通过表示学习方法进行的，该方法通过基于梯度的优化学习符号的分布向量表示。它们只需要很少的手工特征，因此避免了大多数预处理步骤和任务特定的假设。然而，在很多情况下，表示学习需要大量的注释训练数据来很好地概括看不见的数据。这种标记的训练数据由人类注释者提供，他们经常使用形式逻辑作为用于指定注释的语言。本文研究表征学习方法与逻辑的不同组合，以减少对注释训练数据的需求，并提高泛化能力。

##### URL
[http://arxiv.org/abs/1712.09687](http://arxiv.org/abs/1712.09687)

##### PDF
[http://arxiv.org/pdf/1712.09687](http://arxiv.org/pdf/1712.09687)

