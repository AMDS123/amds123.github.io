---
layout: post
title: "Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data"
date: 2018-03-22 11:52:10
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption
author: Xihui Liu, Hongsheng Li, Jing Shao, Dapeng Chen, Xiaogang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
The aim of image captioning is to generate similar captions by machine as human do to describe image contents. Despite many efforts, generating discriminative captions for images remains non-trivial. Most traditional approaches imitate the language structure patterns, thus tend to fall into a stereotype of replicating frequent phrases or sentences and neglect unique aspects of each image. In this work, we propose an image captioning framework with a self-retrieval module as training guidance, which encourages generating discriminative captions. It brings unique advantages: (1) the self-retrieval guidance can act as a metric and an evaluator of caption discriminativeness to assure the quality of generated captions. (2) The correspondence between generated captions and images are naturally incorporated in the generation process without human annotations, and hence our approach could utilize a large amount of unlabeled images to boost captioning performance with no additional laborious annotations. We demonstrate the effectiveness of the proposed retrieval-guided method on MS-COCO and Flickr30k captioning datasets, and show its superior captioning performance with more discriminative captions.

##### Abstract (translated by Google)
图像字幕的目的是通过机器生成类似的字幕来描述图像内容。尽管做了很多努力，为图像生成有区别的标题仍然不是微不足道的。大多数传统方法都模仿语言结构模式，因此倾向于复制频繁的短语或句子并忽略每个图像的独特方面。在这项工作中，我们提出了一个带有自我检索模块的图像字幕框架作为培训指导，鼓励生成具有区别性的标题。它带来了独特的优势：（1）自我检索指导可以作为一个度量标准和字幕判别的评估者来保证生成字幕的质量。 （2）生成字幕和图像之间的对应关系自然包含在生成过程中，没有人类注释，因此我们的方法可以利用大量未标记的图像来提高字幕性能，而不需要额外的费力注释。我们在MS-COCO和Flickr30k字幕数据集上展示了所提出的检索引导方法的有效性，并用更多区分性字幕显示了其优越的字幕性能。

##### URL
[https://arxiv.org/abs/1803.08314](https://arxiv.org/abs/1803.08314)

##### PDF
[https://arxiv.org/pdf/1803.08314](https://arxiv.org/pdf/1803.08314)

