---
layout: post
title: "Value Alignment, Fair Play, and the Rights of Service Robots"
date: 2018-03-07 19:33:08
categories: arXiv_AI
tags: arXiv_AI
author: Daniel Estrada
mathjax: true
---

* content
{:toc}

##### Abstract
Ethics and safety research in artificial intelligence is increasingly framed in terms of "alignment" with human values and interests. I argue that Turing's call for "fair play for machines" is an early and often overlooked contribution to the alignment literature. Turing's appeal to fair play suggests a need to correct human behavior to accommodate our machines, a surprising inversion of how value alignment is treated today. Reflections on "fair play" motivate a novel interpretation of Turing's notorious "imitation game" as a condition not of intelligence but instead of value alignment: a machine demonstrates a minimal degree of alignment (with the norms of conversation, for instance) when it can go undetected when interrogated by a human. I carefully distinguish this interpretation from the Moral Turing Test, which is not motivated by a principle of fair play, but instead depends on imitation of human moral behavior. Finally, I consider how the framework of fair play can be used to situate the debate over robot rights within the alignment literature. I argue that extending rights to service robots operating in public spaces is "fair" in precisely the sense that it encourages an alignment of interests between humans and machines.

##### Abstract (translated by Google)
人工智能方面的伦理和安全研究越来越多地被视为与人类价值观和利益“保持一致”。我认为图灵公司呼吁“公平竞争机器”是一个早期的，经常被忽略的对齐文献贡献。图灵对公平竞争的吸引力表明需要纠正人类行为以适应我们的机器，这是今天如何处理价值对准的令人惊讶的倒置。对“公平竞争”的反思激发了对图灵的臭名昭着的“模仿游戏”的新颖解释，认为它不是智力的条件，而是价值取向：机器展示最小程度的一致性（例如谈话的规范）被人类审问时未被发现。我仔细地将这种解释与道德图灵测试区分开来，这不是出于公平竞争原则的动机，而是取决于对人类道德行为的模仿。最后，我考虑公平竞争的框架如何用于调整机器人权利的辩论。我认为，扩大在公共场所使用服务机器人的权利是“公平的”，正是因为它鼓励人与机器之间的利益协调一致。

##### URL
[http://arxiv.org/abs/1803.02852](http://arxiv.org/abs/1803.02852)

##### PDF
[http://arxiv.org/pdf/1803.02852](http://arxiv.org/pdf/1803.02852)

