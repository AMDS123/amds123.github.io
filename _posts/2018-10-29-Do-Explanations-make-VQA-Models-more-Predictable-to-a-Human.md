---
layout: post
title: "Do Explanations make VQA Models more Predictable to a Human?"
date: 2018-10-29 19:14:26
categories: arXiv_AI
tags: arXiv_AI QA VQA
author: Arjun Chandrasekaran, Viraj Prabhu, Deshraj Yadav, Prithvijit Chattopadhyay, Devi Parikh
mathjax: true
---

* content
{:toc}

##### Abstract
A rich line of research attempts to make deep neural networks more transparent by generating human-interpretable 'explanations' of their decision process, especially for interactive tasks like Visual Question Answering (VQA). In this work, we analyze if existing explanations indeed make a VQA model -- its responses as well as failures -- more predictable to a human. Surprisingly, we find that they do not. On the other hand, we find that human-in-the-loop approaches that treat the model as a black-box do.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.12366](http://arxiv.org/abs/1810.12366)

##### PDF
[http://arxiv.org/pdf/1810.12366](http://arxiv.org/pdf/1810.12366)

