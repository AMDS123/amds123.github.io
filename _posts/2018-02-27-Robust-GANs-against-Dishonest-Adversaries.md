---
layout: post
title: "Robust GANs against Dishonest Adversaries"
date: 2018-02-27 03:21:44
categories: arXiv_CV
tags: arXiv_CV Regularization Adversarial Attention GAN Deep_Learning
author: Zhi Xu, Chengtao Li, Stefanie Jegelka
mathjax: true
---

* content
{:toc}

##### Abstract
Robustness of deep learning models is a property that has recently gained increasing attention. We formally define a notion of robustness for generative adversarial models, and show that, perhaps surprisingly, the GAN in its original form is not robust. Indeed, the discriminator in GANs may be viewed as merely offering "teaching feedback". Our notion of robustness relies on a dishonest discriminator, or noisy, adversarial interference with its feedback. We explore, theoretically and empirically, the effect of model and training properties on this robustness. In particular, we show theoretical conditions for robustness that are supported by empirical evidence. We also test the effect of regularization. Our results suggest variations of GANs that are indeed more robust to noisy attacks, and have overall more stable training behavior.

##### Abstract (translated by Google)
深度学习模型的稳健性是一个近来越来越受到关注的属性。我们正式定义了生成对抗模型的鲁棒性概念，并且可能令人惊讶地表明，原始形式的GAN并不健壮。事实上，GAN中的鉴别者可能被视为仅仅提供“教学反馈”。我们的鲁棒性概念依赖于不诚实的鉴别器或嘈杂的对抗干扰其反馈。我们在理论和实证上探索模型和训练属性对这种鲁棒性的影响。特别是，我们展示了经验证据支持的鲁棒性的理论条件。我们也测试正规化的效果。我们的研究结果表明GANs的变化确实对嘈杂的攻击更加稳健，并且具有更稳定的整体训练行为。

##### URL
[https://arxiv.org/abs/1802.09700](https://arxiv.org/abs/1802.09700)

##### PDF
[https://arxiv.org/pdf/1802.09700](https://arxiv.org/pdf/1802.09700)

