---
layout: post
title: "Learning Conceptual-Contexual Embeddings for Medical Text"
date: 2019-08-16 23:27:25
categories: arXiv_CL
tags: arXiv_CL Knowledge_Graph Knowledge Embedding Language_Model
author: Xiao Zhang, Dejing Dou, Ji Wu
mathjax: true
---

* content
{:toc}

##### Abstract
External knowledge is often useful for natural language understanding tasks. We introduce a contextual text representation model called Conceptual-Contextual (CC) embeddings, which incorporates structured knowledge into text representations. Unlike entity embedding methods, our approach encodes a knowledge graph into a context model. CC embeddings can be easily reused for a wide range of tasks just like pre-trained language models. Our model effectively encodes the huge UMLS database by leveraging semantic generalizability. Experiments on electronic health records (EHRs) and medical text processing benchmarks showed our model gives a major boost to the performance of supervised medical NLP tasks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.06203](http://arxiv.org/abs/1908.06203)

##### PDF
[http://arxiv.org/pdf/1908.06203](http://arxiv.org/pdf/1908.06203)

