---
layout: post
title: "Deep Feature Consistent Variational Autoencoder"
date: 2016-10-02 15:48:36
categories: arXiv_CV
tags: arXiv_CV Face Style_Transfer CNN Deep_Learning Prediction Relation
author: Xianxu Hou, Linlin Shen, Ke Sun, Guoping Qiu
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel method for constructing Variational Autoencoder (VAE). Instead of using pixel-by-pixel loss, we enforce deep feature consistency between the input and the output of a VAE, which ensures the VAE's output to preserve the spatial correlation characteristics of the input, thus leading the output to have a more natural visual appearance and better perceptual quality. Based on recent deep learning works such as style transfer, we employ a pre-trained deep convolutional neural network (CNN) and use its hidden features to define a feature perceptual loss for VAE training. Evaluated on the CelebA face dataset, we show that our model produces better results than other methods in the literature. We also show that our method can produce latent vectors that can capture the semantic information of face expressions and can be used to achieve state-of-the-art performance in facial attribute prediction.

##### Abstract (translated by Google)
我们提出了一种构建变分自动编码器（VAE）的新方法。我们不是逐像素损失，而是强调VAE输入和输出之间的深度特征一致性，确保VAE的输出保持输入的空间相关特性，从而使输出具有更自然的视觉效果外观和更好的感知质量。基于最近的深度学习作品，如样式转换，我们采用预先训练的深度卷积神经网络（CNN），并利用其隐藏特征为VAE训练定义特征感知损失。在CelebA面部数据集上进行评估，我们发现我们的模型比文献中的其他方法产生更好的结果。我们还表明，我们的方法可以产生潜在的向量，可以捕获面部表情的语义信息，并可用于达到在面部属性预测的最先进的性能。

##### URL
[https://arxiv.org/abs/1610.00291](https://arxiv.org/abs/1610.00291)

##### PDF
[https://arxiv.org/pdf/1610.00291](https://arxiv.org/pdf/1610.00291)

