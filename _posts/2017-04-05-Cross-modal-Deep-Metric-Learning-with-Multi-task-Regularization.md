---
layout: post
title: "Cross-modal Deep Metric Learning with Multi-task Regularization"
date: 2017-04-05 05:02:20
categories: arXiv_CV
tags: arXiv_CV Regularization Relation
author: Xin Huang, Yuxin Peng
mathjax: true
---

* content
{:toc}

##### Abstract
DNN-based cross-modal retrieval has become a research hotspot, by which users can search results across various modalities like image and text. However, existing methods mainly focus on the pairwise correlation and reconstruction error of labeled data. They ignore the semantically similar and dissimilar constraints between different modalities, and cannot take advantage of unlabeled data. This paper proposes Cross-modal Deep Metric Learning with Multi-task Regularization (CDMLMR), which integrates quadruplet ranking loss and semi-supervised contrastive loss for modeling cross-modal semantic similarity in a unified multi-task learning architecture. The quadruplet ranking loss can model the semantically similar and dissimilar constraints to preserve cross-modal relative similarity ranking information. The semi-supervised contrastive loss is able to maximize the semantic similarity on both labeled and unlabeled data. Compared to the existing methods, CDMLMR exploits not only the similarity ranking information but also unlabeled cross-modal data, and thus boosts cross-modal retrieval accuracy.

##### Abstract (translated by Google)
基于DNN的跨模式检索已经成为研究的热点，用户可以通过图像和文本等多种形式来搜索结果。然而，现有的方法主要集中在标记数据的成对相关性和重构误差上。他们忽略了不同模式之间的语义相似和不相似的约束，而不能利用无标签的数据。本文提出了一种多任务正则化的跨模态深度学习算法（CDMLMR），该模型将统一的多任务学习架构中的四元组排序损失和半监督的对比损失相结合，进行跨模态语义相似度建模。四元组排序损失可以对语义上相似和不相似的约束进行建模以保留跨模态相对相似性排名信息。半监督对比损失能够最大化标记和未标记数据的语义相似性。与现有方法相比，CDMLMR不仅利用了相似性排序信息，而且还利用了未标记的跨模态数据，从而提高了跨模式检索的准确性。

##### URL
[https://arxiv.org/abs/1703.07026](https://arxiv.org/abs/1703.07026)

##### PDF
[https://arxiv.org/pdf/1703.07026](https://arxiv.org/pdf/1703.07026)

