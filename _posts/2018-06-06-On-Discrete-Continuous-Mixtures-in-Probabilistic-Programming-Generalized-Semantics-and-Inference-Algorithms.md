---
layout: post
title: "On Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms"
date: 2018-06-06 06:37:46
categories: arXiv_AI
tags: arXiv_AI Inference
author: Yi Wu, Siddharth Srivastava, Nicholas Hay, Simon Du, Stuart Russell
mathjax: true
---

* content
{:toc}

##### Abstract
Despite of the recent successes of probabilistic programming languages (PPLs) in AI applications, PPLs offer only limited support for discrete-continuous mixture random variables. We develop the notion of measure-theoretic Bayesian networks (MTBNs), and use it to provide more general semantics for PPLs with arbitrarily many random variables defined over arbitrary measure spaces. We develop two new general sampling algorithms which are provably correct under the MTBN framework: lexicographic likelihood weighting (LLW) for general MTBNs and lexicographic particle filter (LPF), a specialized algorithm for state space models. We further integrate MTBN into a widely used PPL system, BLOG, and verify the effectiveness of our new inference algorithms through representative examples.

##### Abstract (translated by Google)
尽管最近在AI应用中概率编程语言（PPLs）取得了成功，但PPLs对离散连续混合随机变量的支持有限。我们发展了测量理论贝叶斯网络（MTBN）的概念，并使用它为PPLs提供更一般的语义，并且在任意测量空间上定义了任意多个随机变量。我们开发了两种新的通用采样算法，这些算法在MTBN框架下证明是正确的：针对一般MTBN的词典似然加权（LLW）和用于状态空间模型的专用算法的词典粒子滤波器（LPF）。我们进一步将MTBN整合到广泛使用的PPL系统BLOG中，并通过代表性的例子来验证我们新的推理算法的有效性。

##### URL
[http://arxiv.org/abs/1806.02027](http://arxiv.org/abs/1806.02027)

##### PDF
[http://arxiv.org/pdf/1806.02027](http://arxiv.org/pdf/1806.02027)

