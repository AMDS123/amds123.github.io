---
layout: post
title: "Generative Adversarial Networks and Perceptual Losses for Video Super-Resolution"
date: 2018-06-14 23:14:14
categories: arXiv_CV
tags: arXiv_CV Adversarial Super_Resolution GAN Deep_Learning Quantitative
author: Alice Lucas, Santiago Lopez Tapia, Rafael Molina, Aggelos K. Katsaggelos
mathjax: true
---

* content
{:toc}

##### Abstract
Video super-resolution has become one of the most critical problems in video processing. In the deep learning literature, recent works have shown the benefits of using perceptual losses to improve the performance on various image restoration tasks; however, these have yet to be applied for video super-resolution. In this work, we present the use of a very deep residual neural network, VSRResNet, for performing high-quality video super-resolution. We show that VSRResNet surpasses the current state-of-the-art VSR model, when compared with the PSNR/SSIM metric across most scale factors. Furthermore, we train this architecture with a convex combination of adversarial, feature-space and pixel-space loss to obtain the VSRResFeatGAN model. Finally, we compare the resulting VSR model with current state-of-the-art models using the PSNR, SSIM, and a novel perceptual distance metric, the PercepDist metric. With this latter metric, we show that the VSRResFeatGAN outperforms current state-of-the-art SR models, both quantitatively and qualitatively.

##### Abstract (translated by Google)
视频超分辨率已成为视频处理中最关键的问题之一。在深度学习文献中，最近的研究表明使用感知损失来改善各种图像恢复任务的性能是有益的;然而，这些还没有被应用于视频超分辨率。在这项工作中，我们提出使用非常深的残余神经网络VSRResNet来执行高质量的视频超分辨率。我们发现VSRResNet与大多数比例因子的PSNR / SSIM指标相比超越了当前最先进的VSR模型。此外，我们利用对抗，特征空间和像素空间损失的凸组合来训练此架构，以获得VSRResFeatGAN模型。最后，我们使用PSNR，SSIM和一种新颖的感知距离度量PercepDist度量来比较产生的VSR模型与当前最先进的模型。使用后一种度量，我们证明VSRResFeatGAN在数量和质量上均优于当前最先进的SR模型。

##### URL
[http://arxiv.org/abs/1806.05764](http://arxiv.org/abs/1806.05764)

##### PDF
[http://arxiv.org/pdf/1806.05764](http://arxiv.org/pdf/1806.05764)

