---
layout: post
title: "The University of Cambridge's Machine Translation Systems for WMT18"
date: 2018-08-28 18:02:31
categories: arXiv_CL
tags: arXiv_CL Attention CNN
author: Felix Stahlberg, Adria de Gispert, Bill Byrne
mathjax: true
---

* content
{:toc}

##### Abstract
The University of Cambridge submission to the WMT18 news translation task focuses on the combination of diverse models of translation. We compare recurrent, convolutional, and self-attention-based neural models on German-English, English-German, and Chinese-English. Our final system combines all neural models together with a phrase-based SMT system in an MBR-based scheme. We report small but consistent gains on top of strong Transformer ensembles.

##### Abstract (translated by Google)
剑桥大学提交的WMT18新闻翻译任务侧重于各种翻译模式的组合。我们比较了基于德语 - 英语，英语 - 德语和中英文的复发，卷积和基于自我注意的神经模型。我们的最终系统将所有神经模型与基于短语的SMT系统结合在一个基于MBR的方案中。我们在强大的变压器合奏之上报告小而稳定的收益。

##### URL
[http://arxiv.org/abs/1808.09465](http://arxiv.org/abs/1808.09465)

##### PDF
[http://arxiv.org/pdf/1808.09465](http://arxiv.org/pdf/1808.09465)

