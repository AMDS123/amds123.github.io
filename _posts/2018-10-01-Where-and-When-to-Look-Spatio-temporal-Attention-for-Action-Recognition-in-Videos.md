---
layout: post
title: "Where and When to Look? Spatio-temporal Attention for Action Recognition in Videos"
date: 2018-10-01 04:23:35
categories: arXiv_CV
tags: arXiv_CV Salient Attention Action_Recognition Video_Classification Classification Quantitative Recognition
author: Lili Meng, Bo Zhao, Bo Chang, Gao Huang, Frederick Tung, Leonid Sigal
mathjax: true
---

* content
{:toc}

##### Abstract
Inspired by the observation that humans are able to process videos efficiently by only paying attention when and where it is needed, we propose a novel spatial-temporal attention mechanism for video-based action recognition. For spatial attention, we learn a saliency mask to allow the model to focus on the most salient parts of the feature maps. For temporal attention, we employ a soft temporal attention mechanism to identify the most relevant frames from an input video. Further, we propose a set of regularizers that ensure that our attention mechanism attends to coherent regions in space and time. Our model is efficient, as it proposes a separable spatio-temporal mechanism for video attention, while being able to identify important parts of the video both spatially and temporally. We demonstrate the efficacy of our approach on three public video action recognition datasets. The proposed approach leads to state-of-the-art performance on all of them, including the new large-scale Moments in Time dataset. Furthermore, we quantitatively and qualitatively evaluate our model's ability to accurately localize discriminative regions spatially and critical frames temporally. This is despite our model only being trained with per video classification labels.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1810.04511](https://arxiv.org/abs/1810.04511)

##### PDF
[https://arxiv.org/pdf/1810.04511](https://arxiv.org/pdf/1810.04511)

