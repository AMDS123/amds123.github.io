---
layout: post
title: "Procedural Modeling and Physically Based Rendering for Synthetic Data Generation in Automotive Applications"
date: 2017-10-18 06:46:05
categories: arXiv_CV
tags: arXiv_CV Segmentation GAN Semantic_Segmentation Deep_Learning
author: Apostolia Tsirikoglou (1), Joel Kronander (1), Magnus Wrenninge (2), Jonas Unger (1) ((1) Linköping University (2) 7DLabs)
mathjax: true
---

* content
{:toc}

##### Abstract
We present an overview and evaluation of a new, systematic approach for generation of highly realistic, annotated synthetic data for training of deep neural networks in computer vision tasks. The main contribution is a procedural world modeling approach enabling high variability coupled with physically accurate image synthesis, and is a departure from the hand-modeled virtual worlds and approximate image synthesis methods used in real-time applications. The benefits of our approach include flexible, physically accurate and scalable image synthesis, implicit wide coverage of classes and features, and complete data introspection for annotations, which all contribute to quality and cost efficiency. To evaluate our approach and the efficacy of the resulting data, we use semantic segmentation for autonomous vehicles and robotic navigation as the main application, and we train multiple deep learning architectures using synthetic data with and without fine tuning on organic (i.e. real-world) data. The evaluation shows that our approach improves the neural network's performance and that even modest implementation efforts produce state-of-the-art results.

##### Abstract (translated by Google)
我们提出了一个新的，系统的方法的概述和评估，用于生成高度真实的带注释的合成数据，用于在计算机视觉任务中训练深度神经网络。主要贡献是一种程序化的世界建模方法，使得高度的可变性与物理上精确的图像合成相结合，并且与实时应用中使用的手工建模的虚拟世界和近似图像合成方法不同。我们的方法的好处包括灵活的，物理准确的和可伸缩的图像合成，类和特征的隐含的广泛覆盖，以及对注释的完整的数据内省，这全部有助于质量和成本效率。为了评估我们的方法和结果数据的有效性，我们使用自主车辆的语义分割和机器人导航作为主要应用，并且使用合成数据来训练多个深度学习架构，有和没有对有机（即真实世界）数据。评估表明，我们的方法提高了神经网络的性能，即使是适度的实施努力也能产生最新的结果。

##### URL
[https://arxiv.org/abs/1710.06270](https://arxiv.org/abs/1710.06270)

##### PDF
[https://arxiv.org/pdf/1710.06270](https://arxiv.org/pdf/1710.06270)

