---
layout: post
title: "MultiNet: Multi-Modal Multi-Task Learning for Autonomous Driving"
date: 2018-08-23 05:07:47
categories: arXiv_RO
tags: arXiv_RO Deep_Learning
author: Sauhaarda Chowdhuri, Tushar Pankaj, Karl Zipser
mathjax: true
---

* content
{:toc}

##### Abstract
Several deep learning approaches have been applied to the autonomous driving task, many employing end-to-end deep neural networks. Autonomous driving is complex, utilizing multiple behavioral modalities ranging from lane changing to turning and stopping. However, most existing approaches do not factor in the different behavioral modalities of the driving task into the training strategy. This paper describes a technique for using Multi-Modal Multi-Task Learning, which we denote as MultiNet which considers multiple behavioral modalities as distinct modes of operation for an end-to-end autonomous deep neural network utilizing the insertion of modal information as secondary input data. Using labeled data from hours of driving our fleet of 1/10th scale model cars, we trained different neural networks to imitate the steering angle and driving speed of human control of a car. We show that in each case, MultiNet models outperform networks trained on individual tasks, while using a fraction of the number of parameters.

##### Abstract (translated by Google)
几种深度学习方法已应用于自动驾驶任务，许多采用端到端深度神经网络。自动驾驶是复杂的，利用从车道变换到转弯和停止的多种行为模式。然而，大多数现有方法并未将驾驶任务的不同行为方式纳入训练策略。本文描述了一种使用多模态多任务学习的技术，我们将其称为MultiNet，它将多个行为模态视为端到端自主深度神经网络的不同操作模式，利用模态信息的插入作为次要输入数据。使用标记数据来驱动我们的1/10比例模型车队，我们训练不同的神经网络模仿转向角度和人类控制汽车的行驶速度。我们表明，在每种情况下，MultiNet模型都优于在单个任务上训练的网络，同时使用一小部分参数。

##### URL
[http://arxiv.org/abs/1709.05581](http://arxiv.org/abs/1709.05581)

##### PDF
[http://arxiv.org/pdf/1709.05581](http://arxiv.org/pdf/1709.05581)

