---
layout: post
title: "Human-centric Indoor Scene Synthesis Using Stochastic Grammar"
date: 2018-08-25 21:44:18
categories: arXiv_CV
tags: arXiv_CV Relation
author: Siyuan Qi, Yixin Zhu, Siyuan Huang, Chenfanfu Jiang, Song-Chun Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
We present a human-centric method to sample and synthesize 3D room layouts and 2D images thereof, to obtain large-scale 2D/3D image data with perfect per-pixel ground truth. An attributed spatial And-Or graph (S-AOG) is proposed to represent indoor scenes. The S-AOG is a probabilistic grammar model, in which the terminal nodes are object entities. Human contexts as contextual relations are encoded by Markov Random Fields (MRF) on the terminal nodes. We learn the distributions from an indoor scene dataset and sample new layouts using Monte Carlo Markov Chain. Experiments demonstrate that our method can robustly sample a large variety of realistic room layouts based on three criteria: (i) visual realism comparing to a state-of-the-art room arrangement method, (ii) accuracy of the affordance maps with respect to groundtruth, and (ii) the functionality and naturalness of synthesized rooms evaluated by human subjects. The code is available at https://github.com/SiyuanQi/human-centric-scene-synthesis.

##### Abstract (translated by Google)
我们提出了一种以人为中心的方法来采样和合成3D房间布局及其2D图像，以获得具有完美的每像素地面实况的大规模2D / 3D图像数据。提出了属于空间的And-Or图（S-AOG）来表示室内场景。 S-AOG是概率语法模型，其中终端节点是对象实体。作为上下文关系的人类上下文由终端节点上的马尔可夫随机字段（MRF）编码。我们从室内场景数据集中学习分布，并使用蒙特卡罗马尔可夫链对新布局进行采样。实验证明，我们的方法可以基于三个标准对大量真实的房间布局进行稳健的采样：（i）与最先进的房间布置方法相比的视觉真实感，（ii）相对于可供性图的准确性。 groundtruth，以及（ii）由人类受试者评估的合成房间的功能性和自然性。该代码可在https://github.com/SiyuanQi/human-centric-scene-synthesis上找到。

##### URL
[http://arxiv.org/abs/1808.08473](http://arxiv.org/abs/1808.08473)

##### PDF
[http://arxiv.org/pdf/1808.08473](http://arxiv.org/pdf/1808.08473)

