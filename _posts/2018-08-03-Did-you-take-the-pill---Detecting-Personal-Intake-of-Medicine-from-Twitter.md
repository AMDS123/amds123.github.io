---
layout: post
title: "Did you take the pill? - Detecting Personal Intake of Medicine from Twitter"
date: 2018-08-03 02:39:38
categories: arXiv_CL
tags: arXiv_CL Sentiment Face Tracking CNN Prediction
author: Debanjan Mahata, Jasper Friedrichs, Rajiv Ratn Shah, Jing Jiang
mathjax: true
---

* content
{:toc}

##### Abstract
Mining social media messages such as tweets, articles, and Facebook posts for health and drug related information has received significant interest in pharmacovigilance research. Social media sites (e.g., Twitter), have been used for monitoring drug abuse, adverse reactions of drug usage and analyzing expression of sentiments related to drugs. Most of these studies are based on aggregated results from a large population rather than specific sets of individuals. In order to conduct studies at an individual level or specific cohorts, identifying posts mentioning intake of medicine by the user is necessary. Towards this objective we develop a classifier for identifying mentions of personal intake of medicine in tweets. We train a stacked ensemble of shallow convolutional neural network (CNN) models on an annotated dataset. We use random search for tuning the hyper-parameters of the CNN models and present an ensemble of best models for the prediction task. Our system produces state-of-the-art result, with a micro-averaged F-score of 0.693. We believe that the developed classifier has direct uses in the areas of psychology, health informatics, pharmacovigilance and affective computing for tracking moods, emotions and sentiments of patients expressing intake of medicine in social media.

##### Abstract (translated by Google)
针对健康和药物相关信息挖掘诸如推文，文章和Facebook帖子之类的社交媒体消息已经引起了对药物警戒研究的极大兴趣。社交媒体网站（例如Twitter）已被用于监测药物滥用，药物使用的不良反应和分析与药物相关的情绪表达。大多数这些研究都是基于大量人群而非特定人群的综合结果。为了在个人层面或特定群组进行研究，需要确定提及用户摄入药物的帖子。为了实现这一目标，我们开发了一种分类器，用于识别推文中个人摄入药物的情况。我们在带注释的数据集上训练叠加的浅卷积神经网络（CNN）模型集合。我们使用随机搜索来调整CNN模型的超参数，并为预测任务提供最佳模型的集合。我们的系统产生了最先进的结果，微观平均F值为0.693。我们相信，开发的分类器在心理学，健康信息学，药物警戒和情感计算领域具有直接用途，用于跟踪在社交媒体中表达药物摄入的患者的情绪，情绪和情绪。

##### URL
[http://arxiv.org/abs/1808.02082](http://arxiv.org/abs/1808.02082)

##### PDF
[http://arxiv.org/pdf/1808.02082](http://arxiv.org/pdf/1808.02082)

