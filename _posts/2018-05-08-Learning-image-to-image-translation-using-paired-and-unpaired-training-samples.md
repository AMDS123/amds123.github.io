---
layout: post
title: "Learning image-to-image translation using paired and unpaired training samples"
date: 2018-05-08 17:44:28
categories: arXiv_CV
tags: arXiv_CV Knowledge Quantitative
author: Soumya Tripathy, Juho Kannala, Esa Rahtu
mathjax: true
---

* content
{:toc}

##### Abstract
Image-to-image translation is a general name for a task where an image from one domain is converted to a corresponding image in another domain, given sufficient training data. Traditionally different approaches have been proposed depending on whether aligned image pairs or two sets of (unaligned) examples from both domains are available for training. While paired training samples might be difficult to obtain, the unpaired setup leads to a highly under-constrained problem and inferior results. In this paper, we propose a new general purpose image-to-image translation model that is able to utilize both paired and unpaired training data simultaneously. We compare our method with two strong baselines and obtain both qualitatively and quantitatively improved results. Our model outperforms the baselines also in the case of purely paired and unpaired training data. To our knowledge, this is the first work to consider such hybrid setup in image-to-image translation.

##### Abstract (translated by Google)
图像到图像的转换是一个任务的通用名称，如果有足够的训练数据，将来自一个域的图像转换为另一个域的相应图像。传统上已经提出了不同的方法，取决于对齐的图像对还是来自两个域的两组（未对齐的）示例可用于训练。虽然配对训练样本可能难以获得，但不成对的训练样本会导致严重不足的问题和较差的结果。在本文中，我们提出了一种新的通用图像到图像转换模型，它能够同时使用配对和不配对的训练数据。我们将我们的方法与两个强基线进行比较，并获得定性和定量改进的结果。在纯配对和不配对的训练数据情况下，我们的模型也优于基线。就我们所知，这是在图像到图像转换中考虑这种混合设置的第一项工作。

##### URL
[https://arxiv.org/abs/1805.03189](https://arxiv.org/abs/1805.03189)

##### PDF
[https://arxiv.org/pdf/1805.03189](https://arxiv.org/pdf/1805.03189)

