---
layout: post
title: "On the Compactness, Efficiency, and Representation of 3D Convolutional Networks: Brain Parcellation as a Pretext Task"
date: 2017-07-06 23:13:03
categories: arXiv_CV
tags: arXiv_CV Segmentation CNN Transfer_Learning
author: Wenqi Li, Guotai Wang, Lucas Fidon, Sebastien Ourselin, M. Jorge Cardoso, Tom Vercauteren
mathjax: true
---

* content
{:toc}

##### Abstract
Deep convolutional neural networks are powerful tools for learning visual representations from images. However, designing efficient deep architectures to analyse volumetric medical images remains challenging. This work investigates efficient and flexible elements of modern convolutional networks such as dilated convolution and residual connection. With these essential building blocks, we propose a high-resolution, compact convolutional network for volumetric image segmentation. To illustrate its efficiency of learning 3D representation from large-scale image data, the proposed network is validated with the challenging task of parcellating 155 neuroanatomical structures from brain MR images. Our experiments show that the proposed network architecture compares favourably with state-of-the-art volumetric segmentation networks while being an order of magnitude more compact. We consider the brain parcellation task as a pretext task for volumetric image segmentation; our trained network potentially provides a good starting point for transfer learning. Additionally, we show the feasibility of voxel-level uncertainty estimation using a sampling approximation through dropout.

##### Abstract (translated by Google)
深卷积神经网络是用于从图像学习视觉表示的有力工具。但是，设计高效的深层架构来分析容积医学图像仍然是一个挑战。这项工作调查现代卷积网络，如扩张卷积和残留连接的高效和灵活的元素。有了这些基本的组成部分，我们提出了一个高分辨率，紧凑卷积网络体积图像分割。为了说明其从大规模图像数据学习3D表示的效率，所提出的网络通过对来自脑MR图像的155个神经解剖结构进行分段的具有挑战性的任务来验证。我们的实验表明，所提出的网络体系结构与最先进的体积分割网络相比是有利的，而数量级更紧凑。我们认为脑区划任务是体积图像分割的一个借口任务;我们训练有素的网络可能为转学提供了一个很好的起点。另外，我们通过采用退出的抽样近似来展示体素级不确定性估计的可行性。

##### URL
[https://arxiv.org/abs/1707.01992](https://arxiv.org/abs/1707.01992)

##### PDF
[https://arxiv.org/pdf/1707.01992](https://arxiv.org/pdf/1707.01992)

