---
layout: post
title: "ADC: Automated Deep Compression and Acceleration with Reinforcement Learning"
date: 2018-02-10 01:32:44
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning
author: Yihui He, Song Han
mathjax: true
---

* content
{:toc}

##### Abstract
Model compression is an effective technique facilitating the deployment of neural network models on mobile devices that have limited computation resources and a tight power budget. However, conventional model compression techniques use hand-crafted features and require domain experts to explore the large design space trading off model size, speed, and accuracy, which is usually sub-optimal and time-consuming. In this paper, we propose Automated Deep Compression (ADC) that leverages reinforcement learning in order to efficiently sample the design space and greatly improve the model compression quality. We achieved state-of-the-art model compression results in a fully automated way without any human efforts. Under 4x FLOPs reduction, we achieved 2.7% better accuracy than hand-crafted model compression method for VGG-16 on ImageNet. We applied this automated, push-the-button compression pipeline to MobileNet and achieved a 2x reduction in FLOPs, and a speedup of 1.49x on Titan Xp and 1.65x on an Android phone (Samsung Galaxy S7), with negligible loss of accuracy.

##### Abstract (translated by Google)
模型压缩是一种有效的技术，有助于在计算资源有限且功耗预算紧张的移动设备上部署神经网络模型。然而，传统的模型压缩技术使用手工制作的特征，并要求领域专家探索大型设计空间，以交换模型大小，速度和准确度，这通常是次优和耗时的。在本文中，我们提出了利用强化学习的自动深度压缩（ADC），以便有效地采样设计空间并大大提高模型压缩质量。我们以完全自动化的方式实现了最先进的模型压缩结果，无需任何人工努力。在4x FLOPs减少的情况下，我们比ImageNet上的VGG-16的手工模型压缩方法的准确度提高了2.7％。我们将这种自动化的按钮式压缩流水线应用于MobileNet，实现了FLOP的2倍缩减，Titan Xp上的1.49倍加速和Android手机（Samsung Galaxy S7）上的1.65倍加速，精度损失微不足道。

##### URL
[http://arxiv.org/abs/1802.03494](http://arxiv.org/abs/1802.03494)

##### PDF
[http://arxiv.org/pdf/1802.03494](http://arxiv.org/pdf/1802.03494)

