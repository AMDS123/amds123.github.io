---
layout: post
title: "Evaluating the State-of-the-Art of End-to-End Natural Language Generation: The E2E NLG Challenge"
date: 2019-01-23 14:54:53
categories: arXiv_CL
tags: arXiv_CL
author: Ond&#x159;ej Du&#x161;ek, Jekaterina Novikova, Verena Rieser
mathjax: true
---

* content
{:toc}

##### Abstract
This paper provides a detailed summary of the first shared task on End-to-End Natural Language Generation (NLG) and identifies avenues for future research based on the results. This shared task aimed to assess whether recent end-to-end NLG systems can generate more complex output by learning from datasets containing higher lexical richness, syntactic complexity and diverse discourse phenomena. We compare 62 systems submitted by 17 institutions, covering a wide range of approaches, including machine learning architectures -- with the majority implementing sequence-to-sequence models (seq2seq) -- as well as systems based on grammatical rules and templates. 
 Seq2seq-based systems have demonstrated a great potential for NLG in the challenge. We find that seq2seq systems generally score high in terms of word-overlap metrics and human evaluations of naturalness -- with the winning SLUG system (Juraska et al. 2018) being seq2seq-based. However, vanilla seq2seq models often fail to correctly express a given meaning representation if they lack a strong semantic control mechanism applied during decoding. Moreover, seq2seq models can be outperformed by hand-engineered systems in terms of overall quality, as well as complexity, length and diversity of outputs.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1901.07931](http://arxiv.org/abs/1901.07931)

##### PDF
[http://arxiv.org/pdf/1901.07931](http://arxiv.org/pdf/1901.07931)

