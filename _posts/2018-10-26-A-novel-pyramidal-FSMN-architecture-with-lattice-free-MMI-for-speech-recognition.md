---
layout: post
title: "A novel pyramidal-FSMN architecture with lattice-free MMI for speech recognition"
date: 2018-10-26 14:44:00
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition RNN Language_Model Recognition
author: Xuerui Yang, Jiwei Li, Xi Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
Deep Feedforward Sequential Memory Network (DFSMN) has shown superior performance on speech recognition tasks. Based on this work, we propose a novel network architecture which introduces pyramidal memory structure to represent various context information. Additionally, res-CNN layers are added in the front to extract more sophisticated features as well. Together with lattice-free maximum mutual information (LF-MMI) and cross entropy (CE) joint training criteria, experimental results show that this approach achieves word error rates (WERs) of 3.62% and 10.89% respectively on Librispeech and Switchboard corpora. Furthermore, Recurrent neural network language model (RNNLM) rescoring is applied and a WER of above 1% absolute improvement is obtained.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.11352](http://arxiv.org/abs/1810.11352)

##### PDF
[http://arxiv.org/pdf/1810.11352](http://arxiv.org/pdf/1810.11352)

