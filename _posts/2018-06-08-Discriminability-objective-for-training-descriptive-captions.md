---
layout: post
title: "Discriminability objective for training descriptive captions"
date: 2018-06-08 18:09:36
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption
author: Ruotian Luo, Brian Price, Scott Cohen, Gregory Shakhnarovich
mathjax: true
---

* content
{:toc}

##### Abstract
One property that remains lacking in image captions generated by contemporary methods is discriminability: being able to tell two images apart given the caption for one of them. We propose a way to improve this aspect of caption generation. By incorporating into the captioning training objective a loss component directly related to ability (by a machine) to disambiguate image/caption matches, we obtain systems that produce much more discriminative caption, according to human evaluation. Remarkably, our approach leads to improvement in other aspects of generated captions, reflected by a battery of standard scores such as BLEU, SPICE etc. Our approach is modular and can be applied to a variety of model/loss combinations commonly proposed for image captioning.

##### Abstract (translated by Google)
现代方法产生的图像标题中缺少的一个属性是可辨别性：考虑到其中一个图像的标题，能够分辨两个图像。我们提出了一种方法来改进字幕生成的这一方面。通过将与能力（通过机器）直接相关的损失成分结合到字幕训练目标中以消除图像/字幕匹配的歧义，我们获得了根据人类评估产生更多判别性字幕的系统。值得注意的是，我们的方法可以改善生成字幕的其他方面，通过一系列标准分数（如BLEU，SPICE等）反映出来。我们的方法是模块化的，可以应用于通常用于图像字幕的各种模型/损耗组合。

##### URL
[https://arxiv.org/abs/1803.04376](https://arxiv.org/abs/1803.04376)

##### PDF
[https://arxiv.org/pdf/1803.04376](https://arxiv.org/pdf/1803.04376)

