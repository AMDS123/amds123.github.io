---
layout: post
title: "Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control"
date: 2018-02-13 17:57:21
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Transfer_Learning
author: Glen Berseth, Cheng Xie, Paul Cernek, Michiel Van de Panne
mathjax: true
---

* content
{:toc}

##### Abstract
Deep reinforcement learning has demonstrated increasing capabilities for continuous control problems, including agents that can move with skill and agility through their environment. An open problem in this setting is that of developing good strategies for integrating or merging policies for multiple skills, where each individual skill is a specialist in a specific skill and its associated state distribution. We extend policy distillation methods to the continuous action setting and leverage this technique to combine expert policies, as evaluated in the domain of simulated bipedal locomotion across different classes of terrain. We also introduce an input injection method for augmenting an existing policy network to exploit new input features. Lastly, our method uses transfer learning to assist in the efficient acquisition of new skills. The combination of these methods allows a policy to be incrementally augmented with new skills. We compare our progressive learning and integration via distillation (PLAID) method against three alternative baselines.

##### Abstract (translated by Google)
深度强化学习已经证明了持续控制问题的能力正在不断提高，其中包括能够在其环境中通过技能和敏捷进行移动的代理。在这种情况下，一个公开的问题是制定好的战略来整合或合并多种技能的政策，其中每个技能都是特定技能专家和相关的国家分配。我们将策略蒸馏方法扩展到连续动作设置，并利用这种技术来结合专家策略，就像在不同类型的地形上模拟双足步行运动领域所评估的一样。我们还引入了一种输入注入方法来增强现有策略网络以利用新的输入功能。最后，我们的方法使用转移学习来帮助高效获取新技能。这些方法的结合使得政策可以增加新的技能。我们通过蒸馏（PLAID）方法与三种替代基线比较了我们的逐步学习和整合。

##### URL
[http://arxiv.org/abs/1802.04765](http://arxiv.org/abs/1802.04765)

##### PDF
[http://arxiv.org/pdf/1802.04765](http://arxiv.org/pdf/1802.04765)

