---
layout: post
title: "ScreenerNet: Learning Self-Paced Curriculum for Deep Neural Networks"
date: 2018-02-20 06:48:12
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning
author: Tae-Hoon Kim, Jonghyun Choi
mathjax: true
---

* content
{:toc}

##### Abstract
We propose to learn a curriculum or a syllabus for supervised learning and deep reinforcement learning with deep neural networks by an attachable deep neural network, called ScreenerNet. Specifically, we learn a weight for each sample by jointly training the ScreenerNet and the main network in an end-to-end self-paced fashion. The ScreenerNet neither has sampling bias nor requires to remember the past learning history. We show the networks augmented with the ScreenerNet achieve early convergence with better accuracy than the state-of-the-art curricular learning methods in extensive experiments using three popular vision datasets such as MNIST, CIFAR10 and Pascal VOC2012, and a Cart-pole task using Deep Q-learning. Moreover, the ScreenerNet can extend other curriculum learning methods such as Prioritized Experience Replay (PER) for further accuracy improvement.

##### Abstract (translated by Google)
我们建议通过可附着的深度神经网络（称为ScreenerNet）为监督式学习和深度神经网络深度强化学习提供课程或教学大纲。具体来说，我们通过联合培训ScreenerNet和主网络以端到端的自我节奏的方式学习每个样本的权重。 ScreenerNet既没有采样偏差也没有要求记住过去的学习历史。我们展示了使用ScreenerNet增强的网络在使用三种常用视觉数据集（如MNIST，CIFAR10和Pascal VOC2012）以及Cart-pole任务的广泛实验中使用比最先进的课程学习方法更高的准确性实现了早期收敛深入的Q学习。此外，ScreenerNet可以扩展其他课程学习方法，例如优先体验重播（PER），以进一步提高准确性。

##### URL
[http://arxiv.org/abs/1801.00904](http://arxiv.org/abs/1801.00904)

##### PDF
[http://arxiv.org/pdf/1801.00904](http://arxiv.org/pdf/1801.00904)

