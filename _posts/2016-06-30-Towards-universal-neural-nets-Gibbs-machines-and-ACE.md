---
layout: post
title: "Towards universal neural nets: Gibbs machines and ACE"
date: 2016-06-30 06:26:34
categories: arXiv_CV
tags: arXiv_CV Classification
author: Galin Georgiev
mathjax: true
---

* content
{:toc}

##### Abstract
We study from a physics viewpoint a class of generative neural nets, Gibbs machines, designed for gradual learning. While including variational auto-encoders, they offer a broader universal platform for incrementally adding newly learned features, including physical symmetries. Their direct connection to statistical physics and information geometry is established. A variational Pythagorean theorem justifies invoking the exponential/Gibbs class of probabilities for creating brand new objects. Combining these nets with classifiers, gives rise to a brand of universal generative neural nets - stochastic auto-classifier-encoders (ACE). ACE have state-of-the-art performance in their class, both for classification and density estimation for the MNIST data set.

##### Abstract (translated by Google)
我们从物理学的角度研究一类生成神经网络，Gibbs机器，为渐进式学习而设计。在包含变分自动编码器的同时，它们提供了一个更广泛的通用平台，用于逐步添加新学习的功能，包括物理对称性。它们与统计物理学和信息几何学的直接联系已经建立。变分毕达哥拉斯定理证明了调用指数/吉布斯概率来创建全新的对象。将这些网络与分类器相结合，产生了通用生成神经网络 - 随机自动分类器 - 编码器（ACE）的品牌。 ACE在同类中具有最先进的性能，既可用于MNIST数据集的分类和密度估计。

##### URL
[https://arxiv.org/abs/1508.06585](https://arxiv.org/abs/1508.06585)

##### PDF
[https://arxiv.org/pdf/1508.06585](https://arxiv.org/pdf/1508.06585)

