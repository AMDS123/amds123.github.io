---
layout: post
title: "A Joint Sequence Fusion Model for Video Question Answering and Retrieval"
date: 2018-08-07 21:33:37
categories: arXiv_CV
tags: arXiv_CV QA Attention CNN VQA
author: Youngjae Yu, Jongseok Kim, Gunhee Kim
mathjax: true
---

* content
{:toc}

##### Abstract
We present an approach named JSFusion (Joint Sequence Fusion) that can measure semantic similarity between any pairs of multimodal sequence data (e.g. a video clip and a language sentence). Our multimodal matching network consists of two key components. First, the Joint Semantic Tensor composes a dense pairwise representation of two sequence data into a 3D tensor. Then, the Convolutional Hierarchical Decoder computes their similarity score by discovering hidden hierarchical matches between the two sequence modalities. Both modules leverage hierarchical attention mechanisms that learn to promote well-matched representation patterns while prune out misaligned ones in a bottom-up manner. Although the JSFusion is a universal model to be applicable to any multimodal sequence data, this work focuses on video-language tasks including multimodal retrieval and video QA. We evaluate the JSFusion model in three retrieval and VQA tasks in LSMDC, for which our model achieves the best performance reported so far. We also perform multiple-choice and movie retrieval tasks for the MSR-VTT dataset, on which our approach outperforms many state-of-the-art methods.

##### Abstract (translated by Google)
我们提出了一种名为JSFusion（联合序列融合）的方法，其可以测量任何多模式序列数据对（例如视频剪辑和语言句子）之间的语义相似性。我们的多模式匹配网络由两个关键组件组成。首先，联合语义张量将两个序列数据的密集成对表示组成一个3D张量。然后，卷积层次解码器通过发现两个序列模态之间的隐藏层次匹配来计算它们的相似性得分。这两个模块都利用分层注意机制，学习如何促进匹配良好的表示模式，同时以自下而上的方式删除未对齐的表示模式。虽然JSFusion是适用于任何多模式序列数据的通用模型，但这项工作主要关注视频语言任务，包括多模式检索和视频质量保证。我们在LSMDC中的三个检索和VQA任务中评估JSFusion模型，为此我们的模型实现了迄今为止报告的最佳性能。我们还为MSR-VTT数据集执行多项选择和电影检索任务，我们的方法优于许多最先进的方法。

##### URL
[http://arxiv.org/abs/1808.02559](http://arxiv.org/abs/1808.02559)

##### PDF
[http://arxiv.org/pdf/1808.02559](http://arxiv.org/pdf/1808.02559)

