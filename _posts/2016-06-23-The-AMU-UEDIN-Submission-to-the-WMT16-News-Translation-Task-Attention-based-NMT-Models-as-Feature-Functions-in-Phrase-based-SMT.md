---
layout: post
title: 'The AMU-UEDIN Submission to the WMT16 News Translation Task: Attention-based NMT Models as Feature Functions in Phrase-based SMT'
date: 2016-06-23 13:22:46
categories: arXiv_CL
tags: arXiv_CL NMT
author: Marcin Junczys-Dowmunt, Tomasz Dwojak, Rico Sennrich
---

* content
{:toc}

##### Abstract
This paper describes the AMU-UEDIN submissions to the WMT 2016 shared task on news translation. We explore methods of decode-time integration of attention-based neural translation models with phrase-based statistical machine translation. Efficient batch-algorithms for GPU-querying are proposed and implemented. For English-Russian, our system stays behind the state-of-the-art pure neural models in terms of BLEU. Among restricted systems, manual evaluation places it in the first cluster tied with the pure neural model. For the Russian-English task, our submission achieves the top BLEU result, outperforming the best pure neural system by 1.1 BLEU points and our own phrase-based baseline by 1.6 BLEU. After manual evaluation, this system is the best restricted system in its own cluster. In follow-up experiments we improve results by additional 0.8 BLEU.

##### Abstract (translated by Google)
本文介绍AMU-UEDIN提交WMT 2016新闻翻译共享任务。我们探讨了基于注意的神经翻译模型与基于短语的统计机器翻译的解码时间整合方法。提出并实现了GPU查询的高效批处理算法。对于英语 - 俄语，我们的系统在BLEU方面落后于最先进的纯神经模型。在受限制的系统中，人工评估将其放在与纯神经模型相关的第一个群集中。对于俄语 - 英语的任务，我们的提交实现了BLEU的最高结果，以1.1 BLEU点和我们自己的基于短语的基线1.6 BLEU超越了最好的纯神经系统。经过人工评估，该系统是自己的集群中最好的限制系统。在后续实验中，我们通过额外的0.8 BLEU提高了结果。

##### URL
[https://arxiv.org/abs/1605.04809](https://arxiv.org/abs/1605.04809)

