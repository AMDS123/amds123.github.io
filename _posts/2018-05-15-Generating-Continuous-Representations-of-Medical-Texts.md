---
layout: post
title: "Generating Continuous Representations of Medical Texts"
date: 2018-05-15 10:32:53
categories: arXiv_CL
tags: arXiv_CL Adversarial Caption RNN Quantitative
author: Graham Spinks, Marie-Francine Moens
mathjax: true
---

* content
{:toc}

##### Abstract
We present an architecture that generates medical texts while learning an informative, continuous representation with discriminative features. During training the input to the system is a dataset of captions for medical X-Rays. The acquired continuous representations are of particular interest for use in many machine learning techniques where the discrete and high-dimensional nature of textual input is an obstacle. We use an Adversarially Regularized Autoencoder to create realistic text in both an unconditional and conditional setting. We show that this technique is applicable to medical texts which often contain syntactic and domain-specific shorthands. A quantitative evaluation shows that we achieve a lower model perplexity than a traditional LSTM generator.

##### Abstract (translated by Google)
我们提出了一种能够生成医学文本的体系结构，同时学习具有区别性特征的信息性连续表示。在训练期间，对系统的输入是用于医用X射线的字幕的数据集。所获得的连续表示对于许多机器学习技术特别有用，其中文本输入的离散和高维性质是障碍。我们使用Adversarially Regularized Autoencoder在无条件和条件设置下创建逼真的文本。我们表明，这种技术适用于医疗文本，通常包含句法和领域特定的短文。定量评估表明，与传统的LSTM发生器相比，我们获得了更低的模型困惑度。

##### URL
[http://arxiv.org/abs/1805.05691](http://arxiv.org/abs/1805.05691)

##### PDF
[http://arxiv.org/pdf/1805.05691](http://arxiv.org/pdf/1805.05691)

