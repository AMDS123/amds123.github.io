---
layout: post
title: "Online Hashing"
date: 2017-04-06 15:44:29
categories: arXiv_CV
tags: arXiv_CV
author: Long-Kai Huang, Qiang Yang, Wei-Shi Zheng
mathjax: true
---

* content
{:toc}

##### Abstract
Although hash function learning algorithms have achieved great success in recent years, most existing hash models are off-line, which are not suitable for processing sequential or online data. To address this problem, this work proposes an online hash model to accommodate data coming in stream for online learning. Specifically, a new loss function is proposed to measure the similarity loss between a pair of data samples in hamming space. Then, a structured hash model is derived and optimized in a passive-aggressive way. Theoretical analysis on the upper bound of the cumulative loss for the proposed online hash model is provided. Furthermore, we extend our online hashing from a single-model to a multi-model online hashing that trains multiple models so as to retain diverse online hashing models in order to avoid biased update. The competitive efficiency and effectiveness of the proposed online hash models are verified through extensive experiments on several large-scale datasets as compared to related hashing methods.

##### Abstract (translated by Google)
尽管近年来哈希函数学习算法取得了很大的成功，但大多数现有的哈希模型都是离线的，不适合处理顺序或在线数据。为了解决这个问题，这项工作提出了一个在线哈希模型，以适应在线学习的数据流。具体而言，提出了一种新的损失函数来衡量海明空间中一对数据样本之间的相似性损失。然后，一个结构化的散列模型被导出和优化在被动积极的方式。提出了在线散列模型的累积损失上限的理论分析。此外，我们将在线哈希从单一模式扩展到多模式在线哈希，以训练多个模型，从而保留各种在线哈希模型以避免偏差更新。所提出的在线哈希模型的竞争效率和有效性通过与相关哈希方法相比在几个大规模数据集上的广泛实验来验证。

##### URL
[https://arxiv.org/abs/1704.01897](https://arxiv.org/abs/1704.01897)

##### PDF
[https://arxiv.org/pdf/1704.01897](https://arxiv.org/pdf/1704.01897)

