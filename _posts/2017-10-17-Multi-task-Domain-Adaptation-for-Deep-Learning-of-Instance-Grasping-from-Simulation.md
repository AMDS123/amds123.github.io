---
layout: post
title: "Multi-task Domain Adaptation for Deep Learning of Instance Grasping from Simulation"
date: 2017-10-17 17:54:50
categories: arXiv_CV
tags: arXiv_CV Adversarial Segmentation Transfer_Learning Deep_Learning
author: Kuan Fang, Yunfei Bai, Stefan Hinterstoisser, Mrinal Kalakrishnan
mathjax: true
---

* content
{:toc}

##### Abstract
Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.

##### Abstract (translated by Google)
基于学习的机器人操作方法受限于数据收集的可扩展性和标签的可访问性。在本文中，我们提出了一个多任务领域的适应框架，例如抓住杂乱的场景，利用模拟机器人实验。我们的神经网络将单目RGB图像和指定目标对象的实例分割蒙板作为输入，并预测了成功抓取每个候选马达命令的指定对象的概率。所提出的转移学习框架训练一个模拟例如抓住模拟，并使用领域对抗损失转移训练模型到真正的机器人使用不分青红皂白的抓取数据，这是在模拟和现实世界。我们在真实世界中的机器人实验中评估我们的模型，将其与其他模型体系结构以及不分青红皂白的抓取基线进行比较。

##### URL
[https://arxiv.org/abs/1710.06422](https://arxiv.org/abs/1710.06422)

##### PDF
[https://arxiv.org/pdf/1710.06422](https://arxiv.org/pdf/1710.06422)

