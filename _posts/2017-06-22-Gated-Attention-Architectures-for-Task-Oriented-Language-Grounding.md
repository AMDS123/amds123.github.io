---
layout: post
title: "Gated-Attention Architectures for Task-Oriented Language Grounding"
date: 2017-06-22 09:39:17
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention Quantitative
author: Devendra Singh Chaplot, Kanthashree Mysore Sathyendra, Rama Kumar Pasumarthi, Dheeraj Rajagopal, Ruslan Salakhutdinov
mathjax: true
---

* content
{:toc}

##### Abstract
To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called task-oriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states.

##### Abstract (translated by Google)
为了执行由自然语言指令指定的任务，自主代理需要提取语义上有意义的语言表示，并将其映射到环境中的可视元素和动作。这个问题被称为面向任务的语言接地。我们提出了一种端到端的可训练神经架构，用于在三维环境中进行面向任务的语言接地，它假设没有任何语言知识或感知知识，只需要来自环境的原始像素和自然语言指令作为输入。所提出的模型使用门控注意机制将图像和文本表示结合起来，并学习使用标准强化和模仿学习方法来执行自然语言指令的策略。我们在看不见的指示以及看不见的地图上显示出所提议模型的有效性，无论是在数量上还是质量上。我们还引入了一个基于3D游戏引擎的新颖环境，以模拟面向任务的语言接地在丰富的指令和环境状态上的挑战。

##### URL
[https://arxiv.org/abs/1706.07230](https://arxiv.org/abs/1706.07230)

##### PDF
[https://arxiv.org/pdf/1706.07230](https://arxiv.org/pdf/1706.07230)

