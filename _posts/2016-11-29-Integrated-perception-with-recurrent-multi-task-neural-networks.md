---
layout: post
title: "Integrated perception with recurrent multi-task neural networks"
date: 2016-11-29 14:38:00
categories: arXiv_CV
tags: arXiv_CV Image_Caption Image_Classification Classification Detection
author: Hakan Bilen, Andrea Vedaldi
mathjax: true
---

* content
{:toc}

##### Abstract
Modern discriminative predictors have been shown to match natural intelligences in specific perceptual tasks in image classification, object and part detection, boundary extraction, etc. However, a major advantage that natural intelligences still have is that they work well for "all" perceptual problems together, solving them efficiently and coherently in an "integrated manner". In order to capture some of these advantages in machine perception, we ask two questions: whether deep neural networks can learn universal image representations, useful not only for a single task but for all of them, and how the solutions to the different tasks can be integrated in this framework. We answer by proposing a new architecture, which we call "MultiNet", in which not only deep image features are shared between tasks, but where tasks can interact in a recurrent manner by encoding the results of their analysis in a common shared representation of the data. In this manner, we show that the performance of individual tasks in standard benchmarks can be improved first by sharing features between them and then, more significantly, by integrating their solutions in the common representation.

##### Abstract (translated by Google)
现代判别预测因子在图像分类，目标和部分检测，边界提取等特定的感知任务中已经被证明与自然智能相匹配。然而，自然智能仍然具有的一个主要优点是，它们可以很好地适用于“所有”感知问题以“一体化”的方式高效率和一致地解决问题。为了捕捉机器感知中的这些优点，我们提出了两个问题：深度神经网络是否可以学习通用图像表示，不仅对于单个任务，而且对于所有这些表示都是有用的，以及对不同任务的解决方案集成在这个框架中。我们通过提出一种新的体系结构来回答这个问题，我们称之为“多网络”，其中不仅是任务之间共享深度图像特征，而且任务可以通过将分析结果编码为数据。以这种方式，我们表明，标准基准测试中的单个任务的性能可以通过共享它们之间的特征，然后更重要的是通过将它们的解决方案集成到通用表示中来改进。

##### URL
[https://arxiv.org/abs/1606.01735](https://arxiv.org/abs/1606.01735)

##### PDF
[https://arxiv.org/pdf/1606.01735](https://arxiv.org/pdf/1606.01735)

