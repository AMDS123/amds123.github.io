---
layout: post
title: "Can LSTM Learn to Capture Agreement? The Case of Basque"
date: 2018-09-11 16:44:02
categories: arXiv_CL
tags: arXiv_CL RNN Prediction
author: Shauli Ravfogel, Francis M. Tyers, Yoav Goldberg
mathjax: true
---

* content
{:toc}

##### Abstract
Sequential neural networks models are powerful tools in a variety of Natural Language Processing (NLP) tasks. The sequential nature of these models raises the questions: to what extent can these models implicitly learn hierarchical structures typical to human language, and what kind of grammatical phenomena can they acquire? 
 We focus on the task of agreement prediction in Basque, as a case study for a task that requires implicit understanding of sentence structure and the acquisition of a complex but consistent morphological system. Analyzing experimental results from two syntactic prediction tasks -- verb number prediction and suffix recovery -- we find that sequential models perform worse on agreement prediction in Basque than one might expect on the basis of a previous agreement prediction work in English. Tentative findings based on diagnostic classifiers suggest the network makes use of local heuristics as a proxy for the hierarchical structure of the sentence. We propose the Basque agreement prediction task as challenging benchmark for models that attempt to learn regularities in human language.

##### Abstract (translated by Google)
顺序神经网络模型是各种自然语言处理（NLP）任务中的强大工具。这些模型的连续性提出了这样的问题：这些模型在多大程度上可以隐含地学习人类语言的典型层次结构，以及它们可以获得什么样的语法现象？
 我们专注于巴斯克协议预测的任务，作为一项需要隐含理解句子结构和获得复杂但一致的形态系统的任务的案例研究。分析两个句法预测任务的实验结果 - 动词数预测和后缀恢复 - 我们发现顺序模型在巴斯克语中的协议预测表现比在英语先前的协议预测工作的基础上表现差。基于诊断分类器的初步发现表明，网络利用局部启发式作为句子层次结构的代理。我们建议将巴斯克协议预测任务作为试图学习人类语言规律的模型的挑战性基准。

##### URL
[http://arxiv.org/abs/1809.04022](http://arxiv.org/abs/1809.04022)

##### PDF
[http://arxiv.org/pdf/1809.04022](http://arxiv.org/pdf/1809.04022)

