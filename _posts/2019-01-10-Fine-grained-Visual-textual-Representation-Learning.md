---
layout: post
title: "Fine-grained Visual-textual Representation Learning"
date: 2019-01-10 11:30:58
categories: arXiv_CV
tags: arXiv_CV Adversarial Object_Detection Knowledge Attention GAN Represenation_Learning Detection
author: Xiangteng He, Yuxin Peng
mathjax: true
---

* content
{:toc}

##### Abstract
Fine-grained visual categorization is to recognize hundreds of subcategories belonging to the same basic-level category, which is a highly challenging task due to the quite subtle and local visual distinctions among similar subcategories. Most existing methods generally learn part detectors to discover discriminative regions for better categorization performance. However, not all parts are beneficial and indispensable for visual categorization, and the setting of part detector number heavily relies on prior knowledge as well as experimental validation. As is known to all, when we describe the object of an image via textual descriptions, we mainly focus on the pivotal characteristics, and rarely pay attention to common characteristics as well as the background areas. This is an involuntary transfer from human visual attention to textual attention, which leads to the fact that textual attention tells us how many and which parts are discriminative and significant to categorization. So textual attention could help us to discover visual attention in image. Inspired by this, we propose a fine-grained visual-textual representation learning (VTRL) approach, and its main contributions are: (1) Fine-grained visual-textual pattern mining devotes to discovering discriminative visual-textual pairwise information for boosting categorization performance through jointly modeling vision and text with generative adversarial networks (GANs), which automatically and adaptively discovers discriminative parts. (2) Visual-textual representation learning jointly combines visual and textual information, which preserves the intra-modality and inter-modality information to generate complementary fine-grained representation, as well as further improves categorization performance.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1709.00340](http://arxiv.org/abs/1709.00340)

##### PDF
[http://arxiv.org/pdf/1709.00340](http://arxiv.org/pdf/1709.00340)

