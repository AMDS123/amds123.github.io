---
layout: post
title: "Beat-Event Detection in Action Movie Franchises"
date: 2015-08-15 17:04:50
categories: arXiv_CV
tags: arXiv_CV Classification Detection
author: Danila Potapov (LEAR), Matthijs Douze (LEAR), Jerome Revaud (LEAR), Zaid Harchaoui (LEAR, CIMS), Cordelia Schmid (LEAR)
mathjax: true
---

* content
{:toc}

##### Abstract
While important advances were recently made towards temporally localizing and recognizing specific human actions or activities in videos, efficient detection and classification of long video chunks belonging to semantically defined categories such as "pursuit" or "romance" remains challenging.We introduce a new dataset, Action Movie Franchises, consisting of a collection of Hollywood action movie franchises. We define 11 non-exclusive semantic categories - called beat-categories - that are broad enough to cover most of the movie footage. The corresponding beat-events are annotated as groups of video shots, possibly overlapping.We propose an approach for localizing beat-events based on classifying shots into beat-categories and learning the temporal constraints between shots. We show that temporal constraints significantly improve the classification performance. We set up an evaluation protocol for beat-event localization as well as for shot classification, depending on whether movies from the same franchise are present or not in the training data.

##### Abstract (translated by Google)
虽然近期在视频中对人类特定的行为或活动进行时间定位和识别方面取得了重大进展，但对于属于“追求”或“浪漫”等语义定义范畴的长视频块的有效检测和分类仍然具有挑战性。我们引入一个新的数据集，动作电影特许经营，由好莱坞动作电影特许经营组成。我们定义了11个非排他性的语义类别 - 被称为节拍类别 - 足够广泛的覆盖大部分电影片段。相应的拍子事件被注释为可能重叠的视频镜头组。我们提出一种基于拍摄分类镜头来定位拍子事件并学习镜头之间的时间约束的方法。我们表明，时间约束显着提高分类性能。我们为拍子事件定位和镜头分类建立了评估协议，取决于来自同一专营权的电影是否存在于训练数据中。

##### URL
[https://arxiv.org/abs/1508.03755](https://arxiv.org/abs/1508.03755)

##### PDF
[https://arxiv.org/pdf/1508.03755](https://arxiv.org/pdf/1508.03755)

