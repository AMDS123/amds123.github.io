---
layout: post
title: "Learning to diagnose from scratch by exploiting dependencies among labels"
date: 2017-10-28 17:25:23
categories: arXiv_CV
tags: arXiv_CV RNN Classification
author: Li Yao, Eric Poblenz, Dmitry Dagunts, Ben Covington, Devon Bernard, Kevin Lyman
mathjax: true
---

* content
{:toc}

##### Abstract
The field of medical diagnostics contains a wealth of challenges which closely resemble classical machine learning problems; practical constraints, however, complicate the translation of these endpoints naively into classical architectures. Many tasks in radiology, for example, are largely problems of multi-label classification wherein medical images are interpreted to indicate multiple present or suspected pathologies. Clinical settings drive the necessity for high accuracy simultaneously across a multitude of pathological outcomes and greatly limit the utility of tools which consider only a subset. This issue is exacerbated by a general scarcity of training data and maximizes the need to extract clinically relevant features from available samples -- ideally without the use of pre-trained models which may carry forward undesirable biases from tangentially related tasks. We present and evaluate a partial solution to these constraints in using LSTMs to leverage interdependencies among target labels in predicting 14 pathologic patterns from chest x-rays and establish state of the art results on the largest publicly available chest x-ray dataset from the NIH without pre-training. Furthermore, we propose and discuss alternative evaluation metrics and their relevance in clinical practice.

##### Abstract (translated by Google)
医学诊断领域包含了与经典机器学习问题非常相似的大量挑战;然而，实际的限制使这些端点天真地转化为古典建筑变得复杂。例如，放射学中的许多任务主要是多标签分类的问题，其中医学图像被解释为指示多个存在的或可疑的病状。临床设置驱动高精确度的同时跨越多种病理结果的必要性，并极大地限制了仅考虑子集的工具的效用。这个问题由于训练数据的普遍缺乏而加剧，并且最大限度地需要从可用样本中提取临床相关特征 - 理想情况下不使用预先训练的模型，这可能带来与切向相关的任务不期望的偏差。我们提出并评估这些限制的部分解决方案，使用LSTM来利用目标标签间的相互依赖关系来预测胸部X光的14种病理模式，并在NIH提供的最大的公开胸部X射线数据集上建立最先进的结果前培训。此外，我们提出并讨论替代评估指标及其在临床实践中的相关性。

##### URL
[https://arxiv.org/abs/1710.10501](https://arxiv.org/abs/1710.10501)

##### PDF
[https://arxiv.org/pdf/1710.10501](https://arxiv.org/pdf/1710.10501)

