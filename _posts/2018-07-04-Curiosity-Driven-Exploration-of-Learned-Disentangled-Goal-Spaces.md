---
layout: post
title: "Curiosity Driven Exploration of Learned Disentangled Goal Spaces"
date: 2018-07-04 11:23:57
categories: arXiv_AI
tags: arXiv_AI Represenation_Learning
author: Adrien Laversanne-Finot, Alexandre P&#xe9;r&#xe9;, Pierre-Yves Oudeyer
mathjax: true
---

* content
{:toc}

##### Abstract
Intrinsically motivated goal exploration processes enable agents to autonomously sample goals to explore efficiently complex environments with high-dimensional continuous actions. They have been applied successfully to real world robots to discover repertoires of policies producing a wide diversity of effects. Often these algorithms relied on engineered goal spaces but it was recently shown that one can use deep representation learning algorithms to learn an adequate goal space in simple environments. However, in the case of more complex environments containing multiple objects or distractors, an efficient exploration requires that the structure of the goal space reflects the one of the environment. In this paper we show that using a disentangled goal space leads to better exploration performances than an entangled goal space. We further show that when the representation is disentangled, one can leverage it by sampling goals that maximize learning progress in a modular manner. Finally, we show that the measure of learning progress, used to drive curiosity-driven exploration, can be used simultaneously to discover abstract independently controllable features of the environment.

##### Abstract (translated by Google)
本质上激励的目标探索过程使代理能够自主地对目标进行抽样，以便通过高维连续动作有效地探索复杂环境。它们已成功应用于现实世界的机器人，以发现产生各种各样效果的政策曲目。这些算法通常依赖于工程目标空间，但最近证明，人们可以使用深度表示学习算法在简单环境中学习足够的目标空间。然而，在包含多个对象或干扰物的更复杂环境的情况下，有效的探索要求目标空间的结构反映环境之一。在本文中，我们表明，使用解开的目标空间导致比纠缠的目标空间更好的探索性能。我们进一步表明，当表示被解开时，可以通过抽样目标来利用它，以模块化方式最大化学习进度。最后，我们表明，用于驱动好奇心驱动的探索的学习进度的测量可以同时用于发现抽象的独立可控的环境特征。

##### URL
[http://arxiv.org/abs/1807.01521](http://arxiv.org/abs/1807.01521)

##### PDF
[http://arxiv.org/pdf/1807.01521](http://arxiv.org/pdf/1807.01521)

