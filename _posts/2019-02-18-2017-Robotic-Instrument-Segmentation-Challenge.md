---
layout: post
title: "2017 Robotic Instrument Segmentation Challenge"
date: 2019-02-18 07:08:36
categories: arXiv_CV
tags: arXiv_CV Segmentation
author: Max Allan, Alex Shvets, Thomas Kurmann, Zichen Zhang, Rahul Duggal, Yun-Hsuan Su, Nicola Rieke, Iro Laina, Niveditha Kalavakonda, Sebastian Bodenstedt, Luis Herrera, Wenqi Li, Vladimir Iglovikov, Huoling Luo, Jian Yang, Danail Stoyanov, Lena Maier-Hein, Stefanie Speidel, Mahdi Azizian
mathjax: true
---

* content
{:toc}

##### Abstract
In mainstream computer vision and machine learning, public datasets such as ImageNet, COCO and KITTI have helped drive enormous improvements by enabling researchers to understand the strengths and limitations of different algorithms via performance comparison. However, this type of approach has had limited translation to problems in robotic assisted surgery as this field has never established the same level of common datasets and benchmarking methods. In 2015 a sub-challenge was introduced at the EndoVis workshop where a set of robotic images were provided with automatically generated annotations from robot forward kinematics. However, there were issues with this dataset due to the limited background variation, lack of complex motion and inaccuracies in the annotation. In this work we present the results of the 2017 challenge on robotic instrument segmentation which involved 10 teams participating in binary, parts and type based segmentation of articulated da Vinci robotic instruments.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.06426](http://arxiv.org/abs/1902.06426)

##### PDF
[http://arxiv.org/pdf/1902.06426](http://arxiv.org/pdf/1902.06426)

