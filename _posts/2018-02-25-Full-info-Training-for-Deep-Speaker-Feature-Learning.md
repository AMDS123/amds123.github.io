---
layout: post
title: "Full-info Training for Deep Speaker Feature Learning"
date: 2018-02-25 05:42:01
categories: arXiv_SD
tags: arXiv_SD Knowledge CNN
author: Lantian Li, Zhiyuan Tang, Dong Wang
mathjax: true
---

* content
{:toc}

##### Abstract
In recent studies, it has shown that speaker patterns can be learned from very short speech segments (e.g., 0.3 seconds) by a carefully designed convolutional &amp; time-delay deep neural network (CT-DNN) model. By enforcing the model to discriminate the speakers in the training data, frame-level speaker features can be derived from the last hidden layer. In spite of its good performance, a potential problem of the present model is that it involves a parametric classifier, i.e., the last affine layer, which may consume some discriminative knowledge, thus leading to `information leak' for the feature learning. This paper presents a full-info training approach that discards the parametric classifier and enforces all the discriminative knowledge learned by the feature net. Our experiments on the Fisher database demonstrate that this new training scheme can produce more coherent features, leading to consistent and notable performance improvement on the speaker verification task.

##### Abstract (translated by Google)
在最近的研究中，已经表明可以通过精心设计的卷积和卷积来从非常短的语音段（例如0.3秒）中学习说话人模式。时延深度神经网络（CT-DNN）模型。通过强制模型区分训练数据中的扬声器，帧级扬声器特征可以从最后一个隐藏层得到。尽管其性能良好，但本模型的潜在问题在于它涉及参数分类器，即最后的仿射层，其可能消耗一些有区别的知识，从而导致特征学习的“信息泄露”。本文提出了一种完全信息的训练方法，丢弃参数分类器并强制执行所有由特征网学习的判别性知识。我们在Fisher数据库上的实验表明，这种新的训练方案可以产生更多连贯的特征，从而在说话者验证任务上得到一致且显着的性能改进。

##### URL
[http://arxiv.org/abs/1711.00366](http://arxiv.org/abs/1711.00366)

##### PDF
[http://arxiv.org/pdf/1711.00366](http://arxiv.org/pdf/1711.00366)

