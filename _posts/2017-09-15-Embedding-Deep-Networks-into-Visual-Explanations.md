---
layout: post
title: "Embedding Deep Networks into Visual Explanations"
date: 2017-09-15 18:16:34
categories: arXiv_CV
tags: arXiv_CV Sparse Embedding Image_Classification Classification Deep_Learning Prediction Quantitative
author: Zhongang Qi, Fuxin Li
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a novel explanation module to explain the predictions made by deep learning. Explanation modules work by embedding a high-dimensional deep network layer nonlinearly into a low-dimensional explanation space, while retaining faithfulness in that the original deep learning predictions can be constructed from the few concepts extracted by the explanation module. We then visualize such concepts so that human can learn about the high-level concepts deep learning is using to make decisions. We propose an algorithm called Sparse Reconstruction Autoencoder (SRAE) for learning the embedding to the explanation space, SRAE aims to reconstruct part of the original feature space while retaining faithfulness. A visualization system is then introduced for human understanding of features in the explanation space. The proposed method is applied to explain CNN models in image classification tasks, and several novel metrics are introduced to evaluate the performance of explanations quantitatively without human involvement. Experiments show that the proposed approach could generate better explanations of the mechanisms CNN use for making predictions in the task.

##### Abstract (translated by Google)
在本文中，我们提出了一个新的解释模块来解释深度学习的预测。解释模块通过非线性地将高维深层网络层嵌入到低维解释空间中，同时保留忠实性，原始的深度学习预测可以由解释模块提取的少量概念构建。然后，我们将这些概念可视化，以便人们可以了解深度学习用于制定决策的高级概念。我们提出了一种称为稀疏重构自动编码器（SRAE）的算法，用于学习向解释空间的嵌入，SRAE旨在在保留忠实的同时重建部分原始特征空间。然后引入可视化系统，以便人类理解解释空间中的特征。将该方法应用于图像分类任务中的CNN模型的解释，引入了几种新的度量方法来定量评估解释的性能，而不需要人为参与。实验表明，所提出的方法可以更好地解释CNN在预测任务中使用的机制。

##### URL
[https://arxiv.org/abs/1709.05360](https://arxiv.org/abs/1709.05360)

##### PDF
[https://arxiv.org/pdf/1709.05360](https://arxiv.org/pdf/1709.05360)

