---
layout: post
title: "Sentence Directed Video Object Codetection"
date: 2016-01-26 20:38:42
categories: arXiv_CV
tags: arXiv_CV Salient Object_Detection Detection Recognition
author: Haonan Yu, Jeffrey Mark Siskind
mathjax: true
---

* content
{:toc}

##### Abstract
We tackle the problem of video object codetection by leveraging the weak semantic constraint implied by sentences that describe the video content. Unlike most existing work that focuses on codetecting large objects which are usually salient both in size and appearance, we can codetect objects that are small or medium sized. Our method assumes no human pose or depth information such as is required by the most recent state-of-the-art method. We employ weak semantic constraint on the codetection process by pairing the video with sentences. Although the semantic information is usually simple and weak, it can greatly boost the performance of our codetection framework by reducing the search space of the hypothesized object detections. Our experiment demonstrates an average IoU score of 0.423 on a new challenging dataset which contains 15 object classes and 150 videos with 12,509 frames in total, and an average IoU score of 0.373 on a subset of an existing dataset, originally intended for activity recognition, which contains 5 object classes and 75 videos with 8,854 frames in total.

##### Abstract (translated by Google)
我们利用描述视频内容的句子所隐含的弱语义约束来解决视频对象编码问题。与大多数关注对通常在尺寸和外观上显着的大型对象进行代码化的现有工作不同，我们可以对中小型对象进行代码化。我们的方法不假设人类的姿势或深度信息，如最新的最先进的方法所要求的。通过将视频与句子配对，我们在编码过程中采用弱语义约束。虽然语义信息通常简单而弱，但是通过减少虚拟对象检测的搜索空间，可以大大提高我们的检测框架的性能。我们的实验显示，在一个新的具有挑战性的数据集上，平均IoU得分为0.423，其中包含15个对象类别和150个视频，总共有12,509帧，并且原始用于活动识别的现有数据集的子集上的平均IoU得分为0.373，包含5个对象类和75个视频共8,854帧。

##### URL
[https://arxiv.org/abs/1506.02059](https://arxiv.org/abs/1506.02059)

##### PDF
[https://arxiv.org/pdf/1506.02059](https://arxiv.org/pdf/1506.02059)

