---
layout: post
title: "Hand Gesture Controlled Drones: An Open Source Library"
date: 2018-03-27 22:10:59
categories: arXiv_RO
tags: arXiv_RO Drone Classification Recognition
author: Kathiravan Natarajan, Truong-Huy D. Nguyen, Mutlu Mete
mathjax: true
---

* content
{:toc}

##### Abstract
Drones are conventionally controlled using joysticks, remote controllers, mobile applications, and embedded computers. A few significant issues with these approaches are that drone control is limited by the range of electromagnetic radiation and susceptible to interference noise. In this study we propose the use of hand gestures as a method to control drones. We investigate the use of computer vision methods to develop an intuitive way of agent-less communication between a drone and its operator. Computer vision-based methods rely on the ability of a drone's camera to capture surrounding images and use pattern recognition to translate images to meaningful and/or actionable information. The proposed framework involves a few key parts toward an ultimate action to be taken. They are: image segregation from the video streams of front camera, creating a robust and reliable image recognition based on segregated images, and finally conversion of classified gestures into actionable drone movement, such as takeoff, landing, hovering and so forth. A set of five gestures are studied in this work. Haar feature-based AdaBoost classifier is employed for gesture recognition. We also envisage safety of the operator and drone's action calculating the distance based on computer vision for this task. A series of experiments are conducted to measure gesture recognition accuracies considering the major scene variabilities, illumination, background, and distance. Classification accuracies show that well-lit, clear background, and within 3 ft gestures are recognized correctly over 90%. Limitations of current framework and feasible solutions for better gesture recognition are discussed, too. The software library we developed, and hand gesture data sets are open-sourced at project website.

##### Abstract (translated by Google)
无人机通常使用游戏杆，遥控器，移动应用程序和嵌入式计算机进行控制。这些方法的一些重要问题是无人机控制受到电磁辐射范围的限制并且容易受到干扰噪声的影响。在这项研究中，我们建议使用手势作为控制无人机的方法。我们调查计算机视觉方法的使用，以开发无人驾驶飞机与其操作员之间无代理通信的直观方式。基于计算机视觉的方法依赖于无人机摄像头捕捉周围图像的能力，并使用模式识别将图像转化为有意义的和/或可操作的信息。拟议的框架涉及到要采取的最终行动的几个关键部分。它们是：从前置摄像头的视频流中分离图像，基于分离的图像创建稳健可靠的图像识别，最后将分类手势转换为可操作的无人机运动，例如起飞，着陆，悬停等等。这项工作研究了一套五个手势。基于哈尔特征的AdaBoost分类器用于手势识别。我们还设想操作员的安全和无人驾驶飞机根据计算机视觉计算距离的操作。考虑主要场景变化，照明，背景和距离，进行一系列实验以测量手势识别精度。分类精度表明，光线充足，背景清晰，并且3英尺以内的姿势可以正确识别90％以上。还讨论了当前框架的局限性以及更好的手势识别的可行解决方案。我们开发的软件库和手势数据集在项目网站上是开源的。

##### URL
[https://arxiv.org/abs/1803.10344](https://arxiv.org/abs/1803.10344)

##### PDF
[https://arxiv.org/pdf/1803.10344](https://arxiv.org/pdf/1803.10344)

