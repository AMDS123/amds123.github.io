---
layout: post
title: "Deep Multimodal Learning: An Effective Method for Video Classification"
date: 2018-11-30 01:05:41
categories: arXiv_CV
tags: arXiv_CV Attention Video_Classification RNN Classification Language_Model
author: Tianqi Zhao
mathjax: true
---

* content
{:toc}

##### Abstract
Videos have become ubiquitous on the Internet. And video analysis can provide lots of information for detecting and recognizing objects as well as help people understand human actions and interactions with the real world. However, facing data as huge as TB level, effective methods should be applied. Recurrent neural network (RNN) architecture has wildly been used on many sequential learning problems such as Language Model, Time-Series Analysis, etc. In this paper, we propose some variations of RNN such as stacked bidirectional LSTM/GRU network with attention mechanism to categorize large-scale video data. We also explore different multimodal fusion methods. Our model combines both visual and audio information on both video and frame level and received great result. Ensemble methods are also applied. Because of its multimodal characteristics, we decide to call this method Deep Multimodal Learning(DML). Our DML-based model was trained on Google Cloud and our own server and was tested in a well-known video classification competition on Kaggle held by Google.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.12563](http://arxiv.org/abs/1811.12563)

##### PDF
[http://arxiv.org/pdf/1811.12563](http://arxiv.org/pdf/1811.12563)

