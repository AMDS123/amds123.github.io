---
layout: post
title: "When Not to Classify: Detection of Reverse Engineering Attacks on DNN Image Classifiers"
date: 2018-10-31 20:59:49
categories: arXiv_CV
tags: arXiv_CV Knowledge Detection
author: Yujia Wang, David J. Miller, George Kesidis
mathjax: true
---

* content
{:toc}

##### Abstract
This paper addresses detection of a reverse engineering (RE) attack targeting a deep neural network (DNN) image classifier; by querying, RE's aim is to discover the classifier's decision rule. RE can enable test-time evasion attacks, which require knowledge of the classifier. Recently, we proposed a quite effective approach (ADA) to detect test-time evasion attacks. In this paper, we extend ADA to detect RE attacks (ADA-RE). We demonstrate our method is successful in detecting "stealthy" RE attacks before they learn enough to launch effective test-time evasion attacks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.02658](http://arxiv.org/abs/1811.02658)

##### PDF
[http://arxiv.org/pdf/1811.02658](http://arxiv.org/pdf/1811.02658)

