---
layout: post
title: "Multimodal speech synthesis architecture for unsupervised speaker adaptation"
date: 2018-08-20 02:36:19
categories: arXiv_CL
tags: arXiv_CL
author: Hieu-Thi Luong, Junichi Yamagishi
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a new architecture for speaker adaptation of multi-speaker neural-network speech synthesis systems, in which an unseen speaker's voice can be built using a relatively small amount of speech data without transcriptions. This is sometimes called "unsupervised speaker adaptation". More specifically, we concatenate the layers to the audio inputs when performing unsupervised speaker adaptation while we concatenate them to the text inputs when synthesizing speech from text. Two new training schemes for the new architecture are also proposed in this paper. These training schemes are not limited to speech synthesis, other applications are suggested. Experimental results show that the proposed model not only enables adaptation to unseen speakers using untranscribed speech but it also improves the performance of multi-speaker modeling and speaker adaptation using transcribed audio files.

##### Abstract (translated by Google)
本文提出了一种新的多说话者神经网络语音合成系统的说话人自适应结构，其中可以使用相对少量的语音数据构建看不见的说话者的语音，而无需转录。这有时被称为“无监督的扬声器适应”。更具体地说，我们在执行无监督的说话者适应时将层连接到音频输入，而我们在从文本合成语音时将它们连接到文本输入。本文还提出了两种新的体系结构培训方案。这些训练方案不限于语音合成，建议其他应用。实验结果表明，所提出的模型不仅能够适应使用未转录语音的看不见的扬声器，而且还提高了使用转录音频文件的多扬声器建模和扬声器适应的性能。

##### URL
[http://arxiv.org/abs/1808.06288](http://arxiv.org/abs/1808.06288)

##### PDF
[http://arxiv.org/pdf/1808.06288](http://arxiv.org/pdf/1808.06288)

