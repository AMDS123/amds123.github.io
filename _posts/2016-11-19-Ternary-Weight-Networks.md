---
layout: post
title: "Ternary Weight Networks"
date: 2016-11-19 02:23:03
categories: arXiv_CV
tags: arXiv_CV
author: Fengfu Li, Bo Zhang, Bin Liu
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce ternary weight networks (TWNs) - neural networks with weights constrained to +1, 0 and -1. The Euclidian distance between full (float or double) precision weights and the ternary weights along with a scaling factor is minimized. Besides, a threshold-based ternary function is optimized to get an approximated solution which can be fast and easily computed. TWNs have stronger expressive abilities than the recently proposed binary precision counterparts and are thus more effective than the latter. Meanwhile, TWNs achieve up to 16$\times$ or 32$\times$ model compression rate and need fewer multiplications compared with the full precision counterparts. Benchmarks on MNIST, CIFAR-10, and large scale ImageNet datasets show that the performance of TWNs is only slightly worse than the full precision counterparts but outperforms the analogous binary precision counterparts a lot.

##### Abstract (translated by Google)
我们引入三元权重网络（TWN） - 权重限制为+1，0和-1的神经网络。完整（浮点或双精度）权重与三元权重之间的欧几里得距离以及比例因子被最小化。此外，基于阈值的三元函数被优化以获得可以快速且容易地计算的近似解。 TWN具有比最近提出的二进制精度对手更强的表现能力，因此比后者更有效。同时，与全精度对应相比，TWN实现了高达16倍的倍数或32倍的倍数模型压缩率，并且需要更少的乘法。在MNIST，CIFAR-10和大规模ImageNet数据集上的基准测试表明，TWNs的性能仅比全精度对应物差一些，但是胜过类似的二进制精度对应物。

##### URL
[https://arxiv.org/abs/1605.04711](https://arxiv.org/abs/1605.04711)

##### PDF
[https://arxiv.org/pdf/1605.04711](https://arxiv.org/pdf/1605.04711)

