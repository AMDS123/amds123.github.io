---
layout: post
title: "Speaker-independent machine lip-reading with speaker-dependent viseme classifiers"
date: 2017-10-03 13:02:41
categories: arXiv_CV
tags: arXiv_CV
author: Helen L. Bear, Stephen J. Cox, Richard W. Harvey
mathjax: true
---

* content
{:toc}

##### Abstract
In machine lip-reading, which is identification of speech from visual-only information, there is evidence to show that visual speech is highly dependent upon the speaker [1]. Here, we use a phoneme-clustering method to form new phoneme-to-viseme maps for both individual and multiple speakers. We use these maps to examine how similarly speakers talk visually. We conclude that broadly speaking, speakers have the same repertoire of mouth gestures, where they differ is in the use of the gestures.

##### Abstract (translated by Google)
在机器唇读中，从可视信息中识别言语，有证据表明可视言语高度依赖于说话人[1]。在这里，我们使用音素聚类方法来为单个和多个讲话者形成新的音素 - 视位图。我们使用这些地图来检查讲话者是如何类似地进行视觉交谈我们得出的结论是，广义而言，发言者具有相同的口头表达方式，不同之处在于使用手势。

##### URL
[https://arxiv.org/abs/1710.01122](https://arxiv.org/abs/1710.01122)

##### PDF
[https://arxiv.org/pdf/1710.01122](https://arxiv.org/pdf/1710.01122)

