---
layout: post
title: "Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review"
date: 2018-05-03 16:14:58
categories: arXiv_AI
tags: arXiv_AI Review Reinforcement_Learning Inference
author: Sergey Levine
mathjax: true
---

* content
{:toc}

##### Abstract
The framework of reinforcement learning or optimal control provides a mathematical formalization of intelligent decision making that is powerful and broadly applicable. While the general form of the reinforcement learning problem enables effective reasoning about uncertainty, the connection between reinforcement learning and inference in probabilistic models is not immediately obvious. However, such a connection has considerable value when it comes to algorithm design: formalizing a problem as probabilistic inference in principle allows us to bring to bear a wide array of approximate inference tools, extend the model in flexible and powerful ways, and reason about compositionality and partial observability. In this article, we will discuss how a generalization of the reinforcement learning or optimal control problem, which is sometimes termed maximum entropy reinforcement learning, is equivalent to exact probabilistic inference in the case of deterministic dynamics, and variational inference in the case of stochastic dynamics. We will present a detailed derivation of this framework, overview prior work that has drawn on this and related ideas to propose new reinforcement learning and control algorithms, and describe perspectives on future research.

##### Abstract (translated by Google)
强化学习或最优控制的框架提供了一种强大且广泛适用的智能决策的数学形式化。虽然强化学习问题的一般形式能够对不确定性进行有效的推理，但强化学习和概率模型中的推理之间的联系并不是很明显。然而，当涉及到算法设计时，这样的连接具有相当大的价值：将概念推理形式化原则上允许我们带来大量的近似推理工具，以灵活而强大的方式扩展模型，以及关于组合性的理由和部分可观察性。在本文中，我们将讨论强化学习或最优控制问题（有时称为最大熵强化学习）的泛化如何等同于确定性动力学情况下的精确概率推理，以及随机动力学情况下的变分推理。我们将详细推导这个框架，概述以前的工作，并借鉴相关思想提出新的强化学习和控制算法，并描述未来研究的观点。

##### URL
[http://arxiv.org/abs/1805.00909](http://arxiv.org/abs/1805.00909)

##### PDF
[http://arxiv.org/pdf/1805.00909](http://arxiv.org/pdf/1805.00909)

