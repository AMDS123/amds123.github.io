---
layout: post
title: "Robust Spoken Language Understanding via Paraphrasing"
date: 2018-09-17 21:01:35
categories: arXiv_CL
tags: arXiv_CL Adversarial RNN
author: Avik Ray, Yilin Shen, Hongxia Jin
mathjax: true
---

* content
{:toc}

##### Abstract
Learning intents and slot labels from user utterances is a fundamental step in all spoken language understanding (SLU) and dialog systems. State-of-the-art neural network based methods, after deployment, often suffer from performance degradation on encountering paraphrased utterances, and out-of-vocabulary words, rarely observed in their training set. We address this challenging problem by introducing a novel paraphrasing based SLU model which can be integrated with any existing SLU model in order to improve their overall performance. We propose two new paraphrase generators using RNN and sequence-to-sequence based neural networks, which are suitable for our application. Our experiments on existing benchmark and in house datasets demonstrate the robustness of our models to rare and complex paraphrased utterances, even under adversarial test distributions.

##### Abstract (translated by Google)
从用户话语中学习意图和插槽标签是所有口语理解（SLU）和对话系统中的基本步骤。在部署之后，基于现有技术的基于神经网络的方法在遇到释义的话语时经常遭受性能下降，并且在他们的训练集中很少观察到词汇外单词。我们通过引入一种新颖的基于释义的SLU模型来解决这一具有挑战性的问题，该模型可以与任何现有的SLU模型集成，以提高其整体性能。我们提出了两种新的复述使用RNN和基于序列到序列的神经网络，它们适用于我们的应用。我们对现有基准和内部数据集的实验证明了我们的模型对稀有和复杂的释义话语的稳健性，即使在对抗性测试分布下也是如此。

##### URL
[http://arxiv.org/abs/1809.06444](http://arxiv.org/abs/1809.06444)

##### PDF
[http://arxiv.org/pdf/1809.06444](http://arxiv.org/pdf/1809.06444)

