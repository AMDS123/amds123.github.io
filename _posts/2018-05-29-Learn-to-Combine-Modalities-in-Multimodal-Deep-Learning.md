---
layout: post
title: "Learn to Combine Modalities in Multimodal Deep Learning"
date: 2018-05-29 22:24:48
categories: arXiv_AI
tags: arXiv_AI Classification Deep_Learning Relation
author: Kuan Liu, Yanen Li, Ning Xu, Prem Natarajan
mathjax: true
---

* content
{:toc}

##### Abstract
Combining complementary information from multiple modalities is intuitively appealing for improving the performance of learning-based approaches. However, it is challenging to fully leverage different modalities due to practical challenges such as varying levels of noise and conflicts between modalities. Existing methods do not adopt a joint approach to capturing synergies between the modalities while simultaneously filtering noise and resolving conflicts on a per sample basis. In this work we propose a novel deep neural network based technique that multiplicatively combines information from different source modalities. Thus the model training process automatically focuses on information from more reliable modalities while reducing emphasis on the less reliable modalities. Furthermore, we propose an extension that multiplicatively combines not only the single-source modalities, but a set of mixtured source modalities to better capture cross-modal signal correlations. We demonstrate the effectiveness of our proposed technique by presenting empirical results on three multimodal classification tasks from different domains. The results show consistent accuracy improvements on all three tasks.

##### Abstract (translated by Google)
结合多种形式的补充信息直观地促进了基于学习的方法的性能提升。然而，由于诸如不同程度的噪音和形式之间的冲突等实际挑战而充分利用不同的模式是具有挑战性的。现有方法不采用联合方法来捕获模式之间的协同作用，同时过滤噪声并以每个样本为基础解决冲突。在这项工作中，我们提出了一种新的基于深度神经网络的技术，可以将来自不同来源模式的信息进行乘法组合。因此，模型训练过程自动关注来自更可靠模态的信息，同时减少对不可靠模态的重视。此外，我们提出了一种扩展方法，它不仅可以乘法地结合单源模态，而且还可以使用一组混合源模态来更好地捕获跨模态信号相关性。我们通过介绍来自不同领域的三种多模式分类任务的实证结果来证明我们提出的技术的有效性。结果显示，所有三项任务的准确度都有所提高。

##### URL
[https://arxiv.org/abs/1805.11730](https://arxiv.org/abs/1805.11730)

##### PDF
[https://arxiv.org/pdf/1805.11730](https://arxiv.org/pdf/1805.11730)

