---
layout: post
title: "BOOK: Storing Algorithm-Invariant Episodes for Deep Reinforcement Learning"
date: 2018-02-12 08:44:59
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning
author: Simyung Chang, YoungJoon Yoo, Jaeseok Choi, Nojun Kwak
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a novel method to train agents of reinforcement learning (RL) by sharing knowledge in a way similar to the concept of using a book. The recorded information in the form of a book is the main means by which humans learn knowledge. Nevertheless, the conventional deep RL methods have mainly focused either on experiential learning where the agent learns through interactions with the environment from the start or on imitation learning that tries to mimic the teacher. Contrary to these, our proposed book learning shares key information among different agents in a book-like manner by delving into the following two characteristic features: (1) By defining the linguistic function, input states can be clustered semantically into a relatively small number of core clusters, which are forwarded to other RL agents in a prescribed manner. (2) By defining state priorities and the contents for recording, core experiences can be selected and stored in a small container. We call this container as `BOOK'. Our method learns hundreds to thousand times faster than the conventional methods by learning only a handful of core cluster information, which shows that deep RL agents can effectively learn through the shared knowledge from other agents.

##### Abstract (translated by Google)
我们引入了一种新的方法，通过以类似于使用书籍的概念分享知识来训练强化学习（RL）的代理。以书本形式记录的信息是人类学习知识的主要手段。然而，传统的深度RL方法主要侧重于经验学习，即从一开始就通过与环境的相互作用来学习，或者尝试模仿老师的模仿学习。与此相反，我们提出的书本学习通过深入研究以下两个特征来分享不同代理人之间的关键信息：（1）通过定义语言功能，输入状态可以在语义上聚类为相对较少的核心集群，以规定的方式转发给其他RL代理。 （2）通过定义状态优先级和记录内容，可以选择核心经验并存储在一个小容器中。我们称这个容器为'书'。我们的方法学习的速度比传统方法快数百到数千倍，通过学习一些核心集群信息，这表明深度RL代理可以通过来自其他代理的共享知识有效地学习。

##### URL
[http://arxiv.org/abs/1709.01308](http://arxiv.org/abs/1709.01308)

##### PDF
[http://arxiv.org/pdf/1709.01308](http://arxiv.org/pdf/1709.01308)

