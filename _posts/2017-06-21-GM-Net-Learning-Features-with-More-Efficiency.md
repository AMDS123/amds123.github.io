---
layout: post
title: "GM-Net: Learning Features with More Efficiency"
date: 2017-06-21 08:45:15
categories: arXiv_CV
tags: arXiv_CV CNN Image_Classification Classification Relation Recognition
author: Yujia Chen, Ce Li
mathjax: true
---

* content
{:toc}

##### Abstract
Deep Convolutional Neural Networks (CNNs) are capable of learning unprecedentedly effective features from images. Some researchers have struggled to enhance the parameters' efficiency using grouped convolution. However, the relation between the optimal number of convolutional groups and the recognition performance remains an open problem. In this paper, we propose a series of Basic Units (BUs) and a two-level merging strategy to construct deep CNNs, referred to as a joint Grouped Merging Net (GM-Net), which can produce joint grouped and reused deep features while maintaining the feature discriminability for classification tasks. Our GM-Net architectures with the proposed BU_A (dense connection) and BU_B (straight mapping) lead to significant reduction in the number of network parameters and obtain performance improvement in image classification tasks. Extensive experiments are conducted to validate the superior performance of the GM-Net than the state-of-the-arts on the benchmark datasets, e.g., MNIST, CIFAR-10, CIFAR-100 and SVHN.

##### Abstract (translated by Google)
深卷积神经网络（CNN）能够从图像学习空前有效的特征。一些研究人员一直在努力使用分组卷积来提高参数的效率。然而，卷积组的最佳数目与识别性能之间的关系仍然是一个悬而未决的问题。在本文中，我们提出了一系列基本单位（BU）和一个两级合并策略来构建深度CNN，称为联合分组合并网（GM-Net），它可以产生联合分组和重用的深度特征保持分类任务的特征辨别能力。我们的GM-Net架构与所提出的BU_A（密集连接）和BU_B（直接映射）导致网络参数数量的显着减少，并且在图像分类任务中获得性能改善。进行了大量的实验来验证GM-Net在基准数据集（例如，MNIST，CIFAR-10，CIFAR-100和SVHN）上的性能优于现有技术的性能。

##### URL
[https://arxiv.org/abs/1706.06792](https://arxiv.org/abs/1706.06792)

##### PDF
[https://arxiv.org/pdf/1706.06792](https://arxiv.org/pdf/1706.06792)

