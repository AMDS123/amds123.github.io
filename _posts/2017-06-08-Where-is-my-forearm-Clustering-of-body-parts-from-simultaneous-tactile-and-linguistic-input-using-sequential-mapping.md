---
layout: post
title: "Where is my forearm? Clustering of body parts from simultaneous tactile and linguistic input using sequential mapping"
date: 2017-06-08 09:31:42
categories: arXiv_CL
tags: arXiv_CL
author: Karla Stepanova, Matej Hoffmann, Zdenek Straka, Frederico B. Klein, Angelo Cangelosi, Michal Vavrecka
mathjax: true
---

* content
{:toc}

##### Abstract
Humans and animals are constantly exposed to a continuous stream of sensory information from different modalities. At the same time, they form more compressed representations like concepts or symbols. In species that use language, this process is further structured by this interaction, where a mapping between the sensorimotor concepts and linguistic elements needs to be established. There is evidence that children might be learning language by simply disambiguating potential meanings based on multiple exposures to utterances in different contexts (cross-situational learning). In existing models, the mapping between modalities is usually found in a single step by directly using frequencies of referent and meaning co-occurrences. In this paper, we present an extension of this one-step mapping and introduce a newly proposed sequential mapping algorithm together with a publicly available Matlab implementation. For demonstration, we have chosen a less typical scenario: instead of learning to associate objects with their names, we focus on body representations. A humanoid robot is receiving tactile stimulations on its body, while at the same time listening to utterances of the body part names (e.g., hand, forearm and torso). With the goal at arriving at the correct "body categories", we demonstrate how a sequential mapping algorithm outperforms one-step mapping. In addition, the effect of data set size and noise in the linguistic input are studied.

##### Abstract (translated by Google)
人类和动物不断暴露于来自不同形式的连续的感官信息。与此同时，他们形成更多的压缩表示，如概念或符号。在使用语言的物种中，这个过程是通过这种相互作用进一步构成的，需要建立感觉运动概念和语言元素之间的映射。有证据表明，儿童可能是通过在不同环境下多次暴露于话语的潜在含义（交叉情境学习）来消除歧义，从而学习语言。在现有的模型中，模态之间的映射通常是通过直接使用指示对象的频率和意义共现来一步完成的。在本文中，我们展示了这个一步映射的扩展，并且引入了一个新提出的顺序映射算法和一个公开的Matlab实现。为了演示，我们选择了一个不那么典型的场景：我们不是学习将对象与他们的名字联系起来，而是专注于身体表征。人形机器人在其身体上接受触觉刺激，同时听到身体部位名称（例如，手，前臂和躯干）的话语。为了达到正确的“身体类别”，我们演示了顺序映射算法如何优于单步映射。此外，还研究了语言输入中数据集大小和噪声的影响。

##### URL
[https://arxiv.org/abs/1706.02490](https://arxiv.org/abs/1706.02490)

##### PDF
[https://arxiv.org/pdf/1706.02490](https://arxiv.org/pdf/1706.02490)

