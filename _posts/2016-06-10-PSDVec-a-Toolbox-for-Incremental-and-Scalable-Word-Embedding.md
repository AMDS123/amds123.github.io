---
layout: post
title: "PSDVec: a Toolbox for Incremental and Scalable Word Embedding"
date: 2016-06-10 05:55:58
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Shaohua Li, Jun Zhu, Chunyan Miao
mathjax: true
---

* content
{:toc}

##### Abstract
PSDVec is a Python/Perl toolbox that learns word embeddings, i.e. the mapping of words in a natural language to continuous vectors which encode the semantic/syntactic regularities between the words. PSDVec implements a word embedding learning method based on a weighted low-rank positive semidefinite approximation. To scale up the learning process, we implement a blockwise online learning algorithm to learn the embeddings incrementally. This strategy greatly reduces the learning time of word embeddings on a large vocabulary, and can learn the embeddings of new words without re-learning the whole vocabulary. On 9 word similarity/analogy benchmark sets and 2 Natural Language Processing (NLP) tasks, PSDVec produces embeddings that has the best average performance among popular word embedding tools. PSDVec provides a new option for NLP practitioners.

##### Abstract (translated by Google)
PSDVec是一个Python / Perl工具箱，用于学习单词嵌入，即将自然语言中的单词映射到编码单词之间的语义/句法规则的连续向量。 PSDVec实现了一种基于加权低秩半正定近似的词嵌入学习方法。为了扩大学习过程，我们实施了一种逐块在线学习算法，以逐步学习嵌入。这种策略大大缩短了词汇嵌入到一个大词汇表的学习时间，并且可以在不重新学习整个词汇的情况下学习新词的嵌入。在9个词相似性/类比基准集和2个自然语言处理（NLP）任务中，PSDVec产生在流行词嵌入工具中具有最佳平均性能的嵌入。 PSDVec为NLP从业者提供了一个新的选择。

##### URL
[https://arxiv.org/abs/1606.03192](https://arxiv.org/abs/1606.03192)

##### PDF
[https://arxiv.org/pdf/1606.03192](https://arxiv.org/pdf/1606.03192)

