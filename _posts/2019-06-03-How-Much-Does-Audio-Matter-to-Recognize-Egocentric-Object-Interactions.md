---
layout: post
title: "How Much Does Audio Matter to Recognize Egocentric Object Interactions?"
date: 2019-06-03 08:40:49
categories: arXiv_AI
tags: arXiv_AI Action_Recognition Classification Recognition
author: Alejandro Cartas, Jordi Luque, Petia Radeva, Carlos Segura, Mariella Dimiccoli
mathjax: true
---

* content
{:toc}

##### Abstract
Sounds are an important source of information on our daily interactions with objects. For instance, a significant amount of people can discern the temperature of water that it is being poured just by using the sense of hearing. However, only a few works have explored the use of audio for the classification of object interactions in conjunction with vision or as single modality. In this preliminary work, we propose an audio model for egocentric action recognition and explore its usefulness on the parts of the problem (noun, verb, and action classification). Our model achieves a competitive result in terms of verb classification (34.26% accuracy) on a standard benchmark with respect to vision-based state of the art systems, using a comparatively lighter architecture.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.00634](http://arxiv.org/abs/1906.00634)

##### PDF
[http://arxiv.org/pdf/1906.00634](http://arxiv.org/pdf/1906.00634)

