---
layout: post
title: "Learning On-Road Visual Control for Self-Driving Vehicles with Auxiliary Tasks"
date: 2018-12-19 05:29:53
categories: arXiv_CV
tags: arXiv_CV Knowledge Segmentation CNN Semantic_Segmentation RNN Recognition
author: Yilun Chen, Praveen Palanisamy, Priyantha Mudalige, Katharina Muelling, John M. Dolan
mathjax: true
---

* content
{:toc}

##### Abstract
A safe and robust on-road navigation system is a crucial component of achieving fully automated vehicles. NVIDIA recently proposed an End-to-End algorithm that can directly learn steering commands from raw pixels of a front camera by using one convolutional neural network. In this paper, we leverage auxiliary information aside from raw images and design a novel network structure, called Auxiliary Task Network (ATN), to help boost the driving performance while maintaining the advantage of minimal training data and an End-to-End training method. In this network, we introduce human prior knowledge into vehicle navigation by transferring features from image recognition tasks. Image semantic segmentation is applied as an auxiliary task for navigation. We consider temporal information by introducing an LSTM module and optical flow to the network. Finally, we combine vehicle kinematics with a sensor fusion step. We discuss the benefits of our method over state-of-the-art visual navigation methods both in the Udacity simulation environment and on the real-world Comma.ai dataset.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.07760](http://arxiv.org/abs/1812.07760)

##### PDF
[http://arxiv.org/pdf/1812.07760](http://arxiv.org/pdf/1812.07760)

