---
layout: post
title: "Object Counts! Bringing Explicit Detections Back into Image Captioning"
date: 2018-04-23 14:51:46
categories: arXiv_AI
tags: arXiv_AI Image_Caption Object_Detection Caption Embedding Language_Model Detection
author: Josiah Wang, Pranava Madhyastha, Lucia Specia
mathjax: true
---

* content
{:toc}

##### Abstract
The use of explicit object detectors as an intermediate step to image captioning - which used to constitute an essential stage in early work - is often bypassed in the currently dominant end-to-end approaches, where the language model is conditioned directly on a mid-level image embedding. We argue that explicit detections provide rich semantic information, and can thus be used as an interpretable representation to better understand why end-to-end image captioning systems work well. We provide an in-depth analysis of end-to-end image captioning by exploring a variety of cues that can be derived from such object detections. Our study reveals that end-to-end image captioning systems rely on matching image representations to generate captions, and that encoding the frequency, size and position of objects are complementary and all play a role in forming a good image representation. It also reveals that different object categories contribute in different ways towards image captioning.

##### Abstract (translated by Google)
使用明确的对象检测器作为图像字幕的中间步骤 - 过去构成早期工作的基本阶段 - 通常在目前占主导地位的端对端方法中被忽略，其中语言模型直接在中期阶段进行调整，高级图像嵌入。我们认为显式检测提供了丰富的语义信息，因此可以用作可解释的表示，以更好地理解为什么端到端图像字幕系统运行良好。我们通过探索可以从这种对象检测中获得的各种线索来提供对端到端图像字幕的深入分析。我们的研究表明，端对端图像字幕系统依赖匹配图像表示来生成字幕，并且编码对象的频率，大小和位置是互补的，并且都在形成良好的图像表示方面发挥作用。它还揭示了不同的对象类别对图像字幕有不同的贡献。

##### URL
[https://arxiv.org/abs/1805.00314](https://arxiv.org/abs/1805.00314)

##### PDF
[https://arxiv.org/pdf/1805.00314](https://arxiv.org/pdf/1805.00314)

