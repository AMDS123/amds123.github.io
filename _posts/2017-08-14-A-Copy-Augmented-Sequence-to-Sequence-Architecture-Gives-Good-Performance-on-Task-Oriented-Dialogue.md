---
layout: post
title: "A Copy-Augmented Sequence-to-Sequence Architecture Gives Good Performance on Task-Oriented Dialogue"
date: 2017-08-14 22:18:38
categories: arXiv_SD
tags: arXiv_SD QA Attention Embedding
author: Mihail Eric, Christopher D. Manning
mathjax: true
---

* content
{:toc}

##### Abstract
Task-oriented dialogue focuses on conversational agents that participate in user-initiated dialogues on domain-specific topics. In contrast to chatbots, which simply seek to sustain open-ended meaningful discourse, existing task-oriented agents usually explicitly model user intent and belief states. This paper examines bypassing such an explicit representation by depending on a latent neural embedding of state and learning selective attention to dialogue history together with copying to incorporate relevant prior context. We complement recent work by showing the effectiveness of simple sequence-to-sequence neural architectures with a copy mechanism. Our model outperforms more complex memory-augmented models by 7% in per-response generation and is on par with the current state-of-the-art on DSTC2.

##### Abstract (translated by Google)
面向任务的对话侧重于参与关于特定领域主题的用户发起的对话的会话代理。与chatbots相比，chatbots只是试图维持开放式的有意义的话语，现有的面向任务的代理人通常明确地建模用户意图和信念状态。本文通过依赖于潜在的神经嵌入状态，并通过复制并结合相关的先前的语境，对对话历史进行选择性的关注来考察绕过这种明确的表示。我们补充最近的工作，展示简单的序列到序列神经架构与复制机制的有效性。我们的模型在每个响应代中胜过了更复杂的记忆增强模型7％，并且与当前DSTC2的最新技术水平相当。

##### URL
[https://arxiv.org/abs/1701.04024](https://arxiv.org/abs/1701.04024)

##### PDF
[https://arxiv.org/pdf/1701.04024](https://arxiv.org/pdf/1701.04024)

