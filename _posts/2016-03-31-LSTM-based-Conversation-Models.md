---
layout: post
title: "LSTM based Conversation Models"
date: 2016-03-31 05:14:10
categories: arXiv_SD
tags: arXiv_SD RNN Language_Model
author: Yi Luan, Yangfeng Ji, Mari Ostendorf
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present a conversational model that incorporates both context and participant role for two-party conversations. Different architectures are explored for integrating participant role and context information into a Long Short-term Memory (LSTM) language model. The conversational model can function as a language model or a language generation model. Experiments on the Ubuntu Dialog Corpus show that our model can capture multiple turn interaction between participants. The proposed method outperforms a traditional LSTM model as measured by language model perplexity and response ranking. Generated responses show characteristic differences between the two participant roles.

##### Abstract (translated by Google)
在本文中，我们提出了一个会话模型，它包含了双方对话的背景和参与者角色。探索将不同的体系结构与参与者角色和上下文信息集成到一个长期短期记忆（LSTM）语言模型中。会话模型可以用作语言模型或语言生成模型。在Ubuntu Dialog Corpus上的实验表明，我们的模型可以捕获参与者之间的多重转向交互。所提出的方法优于传统的LSTM模型，以语言模型的困惑性和响应排名来衡量。生成的回答显示两个参与者角色之间的特征差异。

##### URL
[https://arxiv.org/abs/1603.09457](https://arxiv.org/abs/1603.09457)

##### PDF
[https://arxiv.org/pdf/1603.09457](https://arxiv.org/pdf/1603.09457)

