---
layout: post
title: "Spatial-Temporal Memory Networks for Video Object Detection"
date: 2017-12-18 10:02:23
categories: arXiv_CV
tags: arXiv_CV Object_Detection Knowledge Prediction Detection Memory_Networks
author: Fanyi Xiao, Yong Jae Lee
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce Spatial-Temporal Memory Networks (STMN) for video object detection. At its core, we propose a novel Spatial-Temporal Memory module (STMM) as the recurrent computation unit to model long-term temporal appearance and motion dynamics. The STMM's design enables the integration of ImageNet pre-trained backbone CNN weights for both the feature stack as well as the prediction head, which we find to be critical for accurate detection. Furthermore, in order to tackle object motion in videos, we propose a novel MatchTrans module to align the spatial-temporal memory from frame to frame. We compare our method to state-of-the-art detectors on ImageNet VID, and conduct ablative studies to dissect the contribution of our different design choices. We obtain state-of-the-art results with the VGG backbone, and competitive results with the ResNet backbone. To our knowledge, this is the first video object detector that is equipped with an explicit memory mechanism to model long-term temporal dynamics.

##### Abstract (translated by Google)
我们引入时空记忆网络（STMN）进行视频对象检测。在其核心，我们提出了一个新颖的时空记忆模块（STMM）作为经常性的计算单元来模拟长时间的外观和运动动态。 STMM的设计能够将ImageNet预先训练的骨干CNN权重集成到特征堆栈以及预测头，我们发现这对于精确检测是至关重要的。此外，为了解决视频中的对象运动，我们提出了一种新颖的MatchTrans模块来对齐帧到帧的时空记忆。我们将我们的方法与ImageNet VID上的最先进的检测器进行比较，并进行消融研究以剖析我们不同设计选择的贡献。我们通过VGG骨干获得了最先进的结果，以及与ResNet骨干的竞争结果。就我们所知，这是第一个配备了显式记忆机制来模拟长期时间动态的视频对象检测器。

##### URL
[http://arxiv.org/abs/1712.06317](http://arxiv.org/abs/1712.06317)

##### PDF
[http://arxiv.org/pdf/1712.06317](http://arxiv.org/pdf/1712.06317)

