---
layout: post
title: "Rethinking the Form of Latent States in Image Captioning"
date: 2018-07-26 05:26:15
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption RNN
author: Bo Dai, Deming Ye, Dahua Lin
mathjax: true
---

* content
{:toc}

##### Abstract
RNNs and their variants have been widely adopted for image captioning. In RNNs, the production of a caption is driven by a sequence of latent states. Existing captioning models usually represent latent states as vectors, taking this practice for granted. We rethink this choice and study an alternative formulation, namely using two-dimensional maps to encode latent states. This is motivated by the curiosity about a question: how the spatial structures in the latent states affect the resultant captions? Our study on MSCOCO and Flickr30k leads to two significant observations. First, the formulation with 2D states is generally more effective in captioning, consistently achieving higher performance with comparable parameter sizes. Second, 2D states preserve spatial locality. Taking advantage of this, we visually reveal the internal dynamics in the process of caption generation, as well as the connections between input visual domain and output linguistic domain.

##### Abstract (translated by Google)
RNN及其变体已被广泛用于图像字幕。在RNN中，字幕的产生由一系列潜在状态驱动。现有的字幕模型通常将潜在状态表示为向量，将此做法视为理所当然。我们重新考虑这个选择并研究另一种公式，即使用二维图来编码潜状态。这是出于对一个问题的好奇心的推动：潜在状态中的空间结构如何影响最终的字幕？我们对MSCOCO和Flickr30k的研究得出了两个重要的观察结果。首先，具有2D状态的配方通常在字幕中更有效，在可比较的参数尺寸下始终实现更高的性能。其次，2D状态保留空间局部性。利用这一点，我们直观地揭示了字幕生成过程中的内部动态，以及输入视觉域和输出语言域之间的联系。

##### URL
[http://arxiv.org/abs/1807.09958](http://arxiv.org/abs/1807.09958)

##### PDF
[http://arxiv.org/pdf/1807.09958](http://arxiv.org/pdf/1807.09958)

