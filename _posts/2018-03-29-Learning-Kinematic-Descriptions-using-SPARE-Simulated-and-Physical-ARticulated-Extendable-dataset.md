---
layout: post
title: "Learning Kinematic Descriptions using SPARE: Simulated and Physical ARticulated Extendable dataset"
date: 2018-03-29 16:49:14
categories: arXiv_CV
tags: arXiv_CV Knowledge Tracking
author: Abhishek Venkataraman, Brent Griffin, Jason J. Corso
mathjax: true
---

* content
{:toc}

##### Abstract
Next generation robots will need to understand intricate and articulated objects as they cooperate in human environments. To do so, these robots will need to move beyond their current abilities--- working with relatively simple objects in a task-indifferent manner--- toward more sophisticated abilities that dynamically estimate the properties of complex, articulated objects. To that end, we make two compelling contributions toward general articulated (physical) object understanding in this paper. First, we introduce a new dataset, SPARE: Simulated and Physical ARticulated Extendable dataset. SPARE is an extendable open-source dataset providing equivalent simulated and physical instances of articulated objects (kinematic chains), providing the greater research community with a training and evaluation tool for methods generating kinematic descriptions of articulated objects. To the best of our knowledge, this is the first joint visual and physical (3D-printable) dataset for the Vision community. Second, we present a deep neural network that can predit the number of links and the length of the links of an articulated object. These new ideas outperform classical approaches to understanding kinematic chains, such tracking-based methods, which fail in the case of occlusion and do not leverage multiple views when available.

##### Abstract (translated by Google)
下一代机器人需要了解在人类环境中合作的复杂和明确的物体。要做到这一点，这些机器人将需要超越目前的能力---在任务中以相对简单的对象工作 - 无所谓的方式---朝着更复杂的能力来动态估计复杂的关节物体的属性。为此，我们对本文中的一般表达（物理）对象理解做出了两个有力的贡献。首先，我们介绍一个新的数据集SPARE：Simulated and Physical ARticulated Extendable dataset。 SPARE是一个可扩展的开源数据集，提供了关联对象（运动链）的等效模拟和物理实例，为更多的研究团体提供了一个培训和评估工具，用于生成关节对象的运动描述方法。据我们所知，这是Vision社区的第一个联合视觉和物理（3D打印）数据集。其次，我们提出一个深度神经网络，它可以预测链接的数量和链接对象的链接的长度。这些新想法超越了传统方法来理解运动链，这种基于跟踪的方法在遮挡的情况下失败，并且在可用时不利用多个视图。

##### URL
[http://arxiv.org/abs/1803.11147](http://arxiv.org/abs/1803.11147)

##### PDF
[http://arxiv.org/pdf/1803.11147](http://arxiv.org/pdf/1803.11147)

