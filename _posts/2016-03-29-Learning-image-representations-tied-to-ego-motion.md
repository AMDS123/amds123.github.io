---
layout: post
title: "Learning image representations tied to ego-motion"
date: 2016-03-29 19:30:18
categories: arXiv_CV
tags: arXiv_CV Image_Caption Regularization CNN Prediction Recognition
author: Dinesh Jayaraman, Kristen Grauman
mathjax: true
---

* content
{:toc}

##### Abstract
Understanding how images of objects and scenes behave in response to specific ego-motions is a crucial aspect of proper visual development, yet existing visual learning methods are conspicuously disconnected from the physical source of their images. We propose to exploit proprioceptive motor signals to provide unsupervised regularization in convolutional neural networks to learn visual representations from egocentric video. Specifically, we enforce that our learned features exhibit equivariance i.e. they respond predictably to transformations associated with distinct ego-motions. With three datasets, we show that our unsupervised feature learning approach significantly outperforms previous approaches on visual recognition and next-best-view prediction tasks. In the most challenging test, we show that features learned from video captured on an autonomous driving platform improve large-scale scene recognition in static images from a disjoint domain.

##### Abstract (translated by Google)
了解物体和场景的图像如何对特定的自我运动做出反应是正确的视觉发展的一个关键方面，但是现有的视觉学习方法显然与其图像的物理来源脱节。我们建议利用本体感受运动信号在卷积神经网络中提供无监督的正则化，以学习以自我为中心的视频的视觉表现。具体而言，我们强调我们学习的特征表现出等量变化，即他们可以预测地反应与不同的自我运动相关的变化。有了三个数据集，我们发现我们的无监督特征学习方法在视觉识别和次最佳视图预测任务方面明显优于先前的方法。在最具挑战性的测试中，我们展示了从自动驾驶平台上捕获的视频中学习的功能可以改善来自不相交域的静态图像中的大规模场景识别。

##### URL
[https://arxiv.org/abs/1505.02206](https://arxiv.org/abs/1505.02206)

##### PDF
[https://arxiv.org/pdf/1505.02206](https://arxiv.org/pdf/1505.02206)

