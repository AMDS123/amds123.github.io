---
layout: post
title: "SurfNet: Generating 3D shape surfaces using deep residual networks"
date: 2017-03-12 07:21:50
categories: arXiv_CV
tags: arXiv_CV Face CNN
author: Ayan Sinha, Asim Unmesh, Qixing Huang, Karthik Ramani
mathjax: true
---

* content
{:toc}

##### Abstract
3D shape models are naturally parameterized using vertices and faces, \ie, composed of polygons forming a surface. However, current 3D learning paradigms for predictive and generative tasks using convolutional neural networks focus on a voxelized representation of the object. Lifting convolution operators from the traditional 2D to 3D results in high computational overhead with little additional benefit as most of the geometry information is contained on the surface boundary. Here we study the problem of directly generating the 3D shape surface of rigid and non-rigid shapes using deep convolutional neural networks. We develop a procedure to create consistent `geometry images' representing the shape surface of a category of 3D objects. We then use this consistent representation for category-specific shape surface generation from a parametric representation or an image by developing novel extensions of deep residual networks for the task of geometry image generation. Our experiments indicate that our network learns a meaningful representation of shape surfaces allowing it to interpolate between shape orientations and poses, invent new shape surfaces and reconstruct 3D shape surfaces from previously unseen images.

##### Abstract (translated by Google)
3D形状模型自然是使用顶点和面来参数化的，也就是由形成曲面的多边形组成。然而，目前使用卷积神经网络进行预测和生成任务的3D学习范式关注于对象的体素化表示。由于大多数几何信息都包含在曲面边界上，所以将卷积算子从传统的2D提升到3D结果的计算开销很高，几乎没有额外的好处。在这里，我们研究了使用深度卷积神经网络直接生成刚性和非刚性形状的三维形状表面的问题。我们开发了一个程序来创建一个一致的`几何图像'，代表一个3D物体类别的形状表面。然后，我们使用这种一致的表示方法，通过为几何图像生成任务开发深度残留网络的新颖扩展，从参数表示或图像中为特定类别的形状表面生成。我们的实验表明，我们的网络学习了形状表面的有意义的表示，允许它在形状取向和姿势之间进行插值，发现新的形状表面，并从以前看不见的图像重建3D形状表面。

##### URL
[https://arxiv.org/abs/1703.04079](https://arxiv.org/abs/1703.04079)

##### PDF
[https://arxiv.org/pdf/1703.04079](https://arxiv.org/pdf/1703.04079)

