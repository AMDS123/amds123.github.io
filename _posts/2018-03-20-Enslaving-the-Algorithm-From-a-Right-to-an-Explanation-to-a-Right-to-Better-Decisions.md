---
layout: post
title: "Enslaving the Algorithm: From a 'Right to an Explanation' to a 'Right to Better Decisions'?"
date: 2018-03-20 17:27:03
categories: arXiv_AI
tags: arXiv_AI Review Attention
author: Lilian Edwards, Michael Veale
mathjax: true
---

* content
{:toc}

##### Abstract
As concerns about unfairness and discrimination in "black box" machine learning systems rise, a legal "right to an explanation" has emerged as a compellingly attractive approach for challenge and redress. We outline recent debates on the limited provisions in European data protection law, and introduce and analyze newer explanation rights in French administrative law and the draft modernized Council of Europe Convention 108. While individual rights can be useful, in privacy law they have historically unreasonably burdened the average data subject. "Meaningful information" about algorithmic logics is more technically possible than commonly thought, but this exacerbates a new "transparency fallacy"---an illusion of remedy rather than anything substantively helpful. While rights-based approaches deserve a firm place in the toolbox, other forms of governance, such as impact assessments, "soft law," judicial review, and model repositories deserve more attention, alongside catalyzing agencies acting for users to control algorithmic system design.

##### Abstract (translated by Google)
随着对“黑匣子”机器学习系统不公平和歧视的担忧的增加，法律“解释权”已成为挑战和补救的极具吸引力的方法。我们概述了最近关于欧洲数据保护法有限条款的辩论，并介绍和分析了法国行政法和现代化欧洲委员会第108号公约草案中新的解释权。虽然个人权利可能是有用的，但在隐私法中，它们在历史上承担了不合理的负担平均数据主题。有关算法逻辑的“有意义的信息”在技术上比通常认为的更可能，但是这加剧了新的“透明度谬误” - 补救的幻觉，而不是任何实质性帮助。虽然基于权利的方法应该在工具箱中占有一席之地，但影响评估，“软法”，司法审查和模型库等其他治理形式值得关注，而催化机构则负责为用户控制算法系统设计。

##### URL
[http://arxiv.org/abs/1803.07540](http://arxiv.org/abs/1803.07540)

##### PDF
[http://arxiv.org/pdf/1803.07540](http://arxiv.org/pdf/1803.07540)

