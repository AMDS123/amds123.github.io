---
layout: post
title: "DeepFeat: A Bottom Up and Top Down Saliency Model Based on Deep Features of Convolutional Neural Nets"
date: 2017-09-08 01:15:16
categories: arXiv_CV
tags: arXiv_CV Salient Attention CNN Prediction
author: Ali Mahdi, Jun Qin
mathjax: true
---

* content
{:toc}

##### Abstract
A deep feature based saliency model (DeepFeat) is developed to leverage the understanding of the prediction of human fixations. Traditional saliency models often predict the human visual attention relying on few level image cues. Although such models predict fixations on a variety of image complexities, their approaches are limited to the incorporated features. In this study, we aim to provide an intuitive interpretation of convolu- tional neural network deep features by combining low and high level visual factors. We exploit four evaluation metrics to evaluate the correspondence between the proposed framework and the ground-truth fixations. The key findings of the results demon- strate that the DeepFeat algorithm, incorporation of bottom up and top down saliency maps, outperforms the individual bottom up and top down approach. Moreover, in comparison to nine 9 state-of-the-art saliency models, our proposed DeepFeat model achieves satisfactory performance based on all four evaluation metrics.

##### Abstract (translated by Google)
基于深度特征的显着性模型（DeepFeat）被开发用于利用对人类注意力的预测的理解。传统的显着性模型往往依靠少量图像线索预测人类的视觉注意力。尽管这些模型预测了各种图像复杂性的注意事项，但是它们的方法仅限于并入的特征。在这项研究中，我们的目标是通过结合低层次和高层次的视觉因素，直观地解释卷积神经网络的深层特征。我们利用四个评估指标来评估拟议框架与地面真相的对应关系。结果的主要研究结果表明DeepFeat算法，自底向上和自顶向下的显着性图的结合，优于单独的自下而上和自上而下的方法。而且，与九个最先进的显着性模型相​​比，我们提出的DeepFeat模型在所有四个评估指标的基础上都达到了令人满意的效果。

##### URL
[https://arxiv.org/abs/1709.02495](https://arxiv.org/abs/1709.02495)

##### PDF
[https://arxiv.org/pdf/1709.02495](https://arxiv.org/pdf/1709.02495)

