---
layout: post
title: "Using Human Brain Activity to Guide Machine Learning"
date: 2017-09-19 21:49:59
categories: arXiv_CV
tags: arXiv_CV Caption CNN Recognition
author: Ruth Fong, Walter Scheirer, David Cox
mathjax: true
---

* content
{:toc}

##### Abstract
Machine learning is a field of computer science that builds algorithms that learn. In many cases, machine learning algorithms are used to recreate a human ability like adding a caption to a photo, driving a car, or playing a game. While the human brain has long served as a source of inspiration for machine learning, little effort has been made to directly use data collected from working brains as a guide for machine learning algorithms. Here we demonstrate a new paradigm of "neurally-weighted" machine learning, which takes fMRI measurements of human brain activity from subjects viewing images, and infuses these data into the training process of an object recognition learning algorithm to make it more consistent with the human brain. After training, these neurally-weighted classifiers are able to classify images without requiring any additional neural data. We show that our neural-weighting approach can lead to large performance gains when used with traditional machine vision features, as well as to significant improvements with already high-performing convolutional neural network features. The effectiveness of this approach points to a path forward for a new class of hybrid machine learning algorithms which take both inspiration and direct constraints from neuronal data.

##### Abstract (translated by Google)
机器学习是计算机科学领域，它构建了学习的算法。在许多情况下，机器学习算法用于重建人类能力，例如为照片添加标题，驾驶汽车或玩游戏。虽然人类的大脑长期以来一直是机器学习的灵感来源，但是直接使用从工作大脑收集的数据作为机器学习算法的指南已经做了很少的努力。在这里，我们展示了一种新的“神经加权”机器学习范式，它从观察图像的受试者中获取人类大脑活动的fMRI测量值，并将这些数据注入到物体识别学习算法的训练过程中，使其与人类更加一致。脑。训练后，这些神经加权分类器能够对图像进行分类，而无需任何额外的神经数据。我们表明，当与传统的机器视觉特征一起使用时，我们的神经加权方法可以带来巨大的性能提升，并且已经具有已经高性能的卷积神经网络特征的显着改进。这种方法的有效性为一类新的混合机器学习算法提供了一条前进的道路，该算法既吸收了神经元数据的灵感，也吸收了直接约束。

##### URL
[https://arxiv.org/abs/1703.05463](https://arxiv.org/abs/1703.05463)

##### PDF
[https://arxiv.org/pdf/1703.05463](https://arxiv.org/pdf/1703.05463)

