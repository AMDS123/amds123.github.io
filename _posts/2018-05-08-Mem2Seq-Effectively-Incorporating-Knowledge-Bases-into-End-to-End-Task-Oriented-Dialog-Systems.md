---
layout: post
title: "Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems"
date: 2018-05-08 09:15:07
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention Relation
author: Andrea Madotto, Chien-Sheng Wu, Pascale Fung
mathjax: true
---

* content
{:toc}

##### Abstract
End-to-end task-oriented dialog systems usually suffer from the challenge of incorporating knowledge bases. In this paper, we propose a novel yet simple end-to-end differentiable model called memory-to-sequence (Mem2Seq) to address this issue. Mem2Seq is the first neural generative model that combines the multi-hop attention over memories with the idea of pointer network. We empirically show how Mem2Seq controls each generation step, and how its multi-hop attention mechanism helps in learning correlations between memories. In addition, our model is quite general without complicated task-specific designs. As a result, we show that Mem2Seq can be trained faster and attain the state-of-the-art performance on three different task-oriented dialog datasets.

##### Abstract (translated by Google)
端到端的面向任务的对话系统通常面临着结合知识库的挑战。在本文中，我们提出了一种称为存储器到序列（Mem2Seq）的新颖但简单的端到端可微模型来解决这个问题。 Mem2Seq是第一个将多跳记忆与指针网络思想相结合的神经生成模型。我们凭经验展示了Mem2Seq如何控制每个生成步骤，以及它的多跳注意机制如何帮助学习记忆之间的相关性。另外，我们的模型相当一般，没有复杂的任务特定设计。因此，我们展示了Mem2Seq可以更快地训练，并在三种不同的面向任务的对话数据集上实现最先进的性能。

##### URL
[http://arxiv.org/abs/1804.08217](http://arxiv.org/abs/1804.08217)

##### PDF
[http://arxiv.org/pdf/1804.08217](http://arxiv.org/pdf/1804.08217)

