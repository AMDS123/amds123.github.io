---
layout: post
title: "Sync-DRAW: Automatic Video Generation using Deep Recurrent Attentive Architectures"
date: 2017-10-21 21:02:46
categories: arXiv_CV
tags: arXiv_CV Knowledge Attention Caption
author: Gaurav Mittal, Tanya Marwah, Vineeth N. Balasubramanian
mathjax: true
---

* content
{:toc}

##### Abstract
This paper introduces a novel approach for generating videos called Synchronized Deep Recurrent Attentive Writer (Sync-DRAW). Sync-DRAW can also perform text-to-video generation which, to the best of our knowledge, makes it the first approach of its kind. It combines a Variational Autoencoder~(VAE) with a Recurrent Attention Mechanism in a novel manner to create a temporally dependent sequence of frames that are gradually formed over time. The recurrent attention mechanism in Sync-DRAW attends to each individual frame of the video in sychronization, while the VAE learns a latent distribution for the entire video at the global level. Our experiments with Bouncing MNIST, KTH and UCF-101 suggest that Sync-DRAW is efficient in learning the spatial and temporal information of the videos and generates frames with high structural integrity, and can generate videos from simple captions on these datasets. (Accepted as oral paper in ACM-Multimedia 2017)

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1611.10314](https://arxiv.org/abs/1611.10314)

##### PDF
[https://arxiv.org/pdf/1611.10314](https://arxiv.org/pdf/1611.10314)

