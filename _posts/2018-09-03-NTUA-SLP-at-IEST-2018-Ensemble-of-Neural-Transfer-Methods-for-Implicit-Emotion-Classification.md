---
layout: post
title: "NTUA-SLP at IEST 2018: Ensemble of Neural Transfer Methods for Implicit Emotion Classification"
date: 2018-09-03 21:00:10
categories: arXiv_CL
tags: arXiv_CL Sentiment Attention GAN Embedding Transfer_Learning RNN Classification Language_Model
author: Alexandra Chronopoulou, Aikaterini Margatina, Christos Baziotis, Alexandros Potamianos
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we present our approach to tackle the Implicit Emotion Shared Task (IEST) organized as part of WASSA 2018 at EMNLP 2018. Given a tweet, from which a certain word has been removed, we are asked to predict the emotion of the missing word. In this work, we experiment with neural Transfer Learning (TL) methods. Our models are based on LSTM networks, augmented with a self-attention mechanism. We use the weights of various pretrained models, for initializing specific layers of our networks. We leverage a big collection of unlabeled Twitter messages, for pretraining word2vec word embeddings and a set of diverse language models. Moreover, we utilize a sentiment analysis dataset for pretraining a model, which encodes emotion related information. The submitted model consists of an ensemble of the aforementioned TL models. Our team ranked 3rd out of 30 participants, achieving an F1 score of 0.703.

##### Abstract (translated by Google)
在本文中，我们介绍了我们在EMNLP 2018中作为WASSA 2018的一部分组织的内隐情感共享任务（IEST）的方法。给出了一条推文，从中删除了某个词，我们被要求预测失踪的情绪字。在这项工作中，我们尝试神经传递学习（TL）方法。我们的模型基于LSTM网络，并增加了自我关注机制。我们使用各种预训练模型的权重来初始化我们网络的特定层。我们利用大量未标记的Twitter消息，预训练word2vec单词嵌入和一组不同的语言模型。此外，我们利用情绪分析数据集来预训练模型，该模型对情绪相关信息进行编码。提交的模型由上述TL模型的集合组成。我们的团队在30名参赛者中排名第3，获得了0.703的F1分数。

##### URL
[http://arxiv.org/abs/1809.00717](http://arxiv.org/abs/1809.00717)

##### PDF
[http://arxiv.org/pdf/1809.00717](http://arxiv.org/pdf/1809.00717)

