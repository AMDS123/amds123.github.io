---
layout: post
title: "Real-time marker-less multi-person 3D pose estimation in RGB-Depth camera networks"
date: 2017-10-17 12:27:23
categories: arXiv_CV
tags: arXiv_CV Pose_Estimation Tracking
author: Marco Carraro, Matteo Munaro, Jeff Burke, Emanuele Menegatti
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a novel system to estimate and track the 3D poses of multiple persons in calibrated RGB-Depth camera networks. The multi-view 3D pose of each person is computed by a central node which receives the single-view outcomes from each camera of the network. Each single-view outcome is computed by using a CNN for 2D pose estimation and extending the resulting skeletons to 3D by means of the sensor depth. The proposed system is marker-less, multi-person, independent of background and does not make any assumption on people appearance and initial pose. The system provides real-time outcomes, thus being perfectly suited for applications requiring user interaction. Experimental results show the effectiveness of this work with respect to a baseline multi-view approach in different scenarios. To foster research and applications based on this work, we released the source code in OpenPTrack, an open source project for RGB-D people tracking.

##### Abstract (translated by Google)
本文提出了一个新的系统来估计和跟踪校准的RGB深度摄像机网络中的多个人的三维姿态。每个人的多视图3D姿态由中央节点计算，该中央节点从网络的每个相机接收单视图结果。通过使用用于2D姿态估计的CNN来计算每个单视图结果，并且通过传感器深度将所得到的骨架扩展到3D。所提出的系统是无标记的，多人的，与背景无关，并且不对人的外貌和初始姿势做出任何假设。该系统提供实时结果，因此非常适合需要用户交互的应用程序。实验结果显示了这项工作在不同场景下的基线多视角方法的有效性。为了促进基于这项工作的研究和应用，我们在OpenPTrack（一个RGB-D人员跟踪的开源项目）中发布了源代码。

##### URL
[https://arxiv.org/abs/1710.06235](https://arxiv.org/abs/1710.06235)

##### PDF
[https://arxiv.org/pdf/1710.06235](https://arxiv.org/pdf/1710.06235)

