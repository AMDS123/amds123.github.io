---
layout: post
title: "Effective Combination of Language and Vision Through Model Composition and the R-CCA Method"
date: 2016-10-04 09:59:50
categories: arXiv_CL
tags: arXiv_CL Represenation_Learning Relation
author: Hagar Loeub, Roi Reichart
mathjax: true
---

* content
{:toc}

##### Abstract
We address the problem of integrating textual and visual information in vector space models for word meaning representation. We first present the Residual CCA (R-CCA) method, that complements the standard CCA method by representing, for each modality, the difference between the original signal and the signal projected to the shared, max correlation, space. We then show that constructing visual and textual representations and then post-processing them through composition of common modeling motifs such as PCA, CCA, R-CCA and linear interpolation (a.k.a sequential modeling) yields high quality models. On five standard semantic benchmarks our sequential models outperform recent multimodal representation learning alternatives, including ones that rely on joint representation learning. For two of these benchmarks our R-CCA method is part of the Best configuration our algorithm yields.

##### Abstract (translated by Google)
我们解决了在向量空间模型中整合文本和视觉信息以用于词义表示的问题。我们首先提出了剩余CCA（R-CCA）方法，它补充了标准的CCA方法，通过表示原始信号和投影到共享最大相关空间的信号之间的差异。然后，我们表明，构建视觉和文本表示，然后通过组合PCA，CCA，R-CCA和线性插值（也称为顺序建模）等通用建模图案进行后处理，得到高质量的模型。在五个标准语义基准测试中，我们的顺序模型胜过了最近的多模式表示学习方法，包括依赖于联合表示学习的方法。对于这些基准中的两个，我们的R-CCA方法是我们算法产生的最佳配置的一部分。

##### URL
[https://arxiv.org/abs/1609.08810](https://arxiv.org/abs/1609.08810)

##### PDF
[https://arxiv.org/pdf/1609.08810](https://arxiv.org/pdf/1609.08810)

