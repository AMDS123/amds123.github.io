---
layout: post
title: "Online Motion Generation with Sensory Information and Instructions by Hierarchical RNN"
date: 2017-12-17 16:20:37
categories: arXiv_RO
tags: arXiv_RO RNN Relation
author: Kanata Suzuki, Hiroki Mori, Tetsuya Ogata
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes an approach for robots to perform co-working task alongside humans by using neuro-dynamical models. The proposed model comprised two models: an Autoencoder and a hierarchical recurrent neural network (RNN). We trained hierarchical RNN with various sensory-motor sequences and instructions. To acquire the interactive ability to switch and combine appropriate motions according to visual information and instructions from outside, we embedded the cyclic neuronal dynamics in a network. To evaluate our model, we designed a cloth-folding task that consists of four short folding motions and three patterns of instruction that indicate the direction of each short motion. The results showed that the robot can perform the task by switching or combining short motions with instructions and visual information. We also showed that the proposed model acquired relationships between the instructions and sensory-motor information in its internal neuronal dynamics. Supplementary video: https://www.youtube.com/watch?v=oUBTJNpXW4A

##### Abstract (translated by Google)
本文提出了一种机器人通过使用神经动力学模型与人类共同执行任务的方法。所提出的模型包括两个模型：自动编码器和分层递归神经网络（RNN）。我们用各种感觉运动序列和指令来训练分层的RNN。为了获得根据来自外部的视觉信息和指令来切换和合并适当运动的交互能力，我们将循环神经元动力学嵌入到网络中。为了评估我们的模型，我们设计了一个布折叠任务，它由四个短折叠运动和三个指示模式组成，指示每个短运动的方向。结果表明，机器人可以通过切换或组合短时间运动与指令和视觉信息来完成任务。我们还表明，提出的模型获得了内部神经元动力学中的指令和感觉运动信息之间的关系。补充视频：https：//www.youtube.com/watch？v = oUBTJNpXW4A

##### URL
[http://arxiv.org/abs/1712.05109](http://arxiv.org/abs/1712.05109)

##### PDF
[http://arxiv.org/pdf/1712.05109](http://arxiv.org/pdf/1712.05109)

