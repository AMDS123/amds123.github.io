---
layout: post
title: "Saliency Prediction for Mobile User Interfaces"
date: 2017-11-28 05:26:59
categories: arXiv_CV
tags: arXiv_CV Salient Face Deep_Learning Prediction
author: Prakhar Gupta, Shubh Gupta, Ajaykrishnan Jayagopal, Sourav Pal, Ritwik Sinha
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce models for saliency prediction for mobile user interfaces. A mobile interface may include elements like buttons, text, etc. in addition to natural images which enable performing a variety of tasks. Saliency in natural images is a well studied area. However, given the difference in what constitutes a mobile interface, and the usage context of these devices, we postulate that saliency prediction for mobile interface images requires a fresh approach. Mobile interface design involves operating on elements, the building blocks of the interface. We first collected eye-gaze data from mobile devices for free viewing task. Using this data, we develop a novel autoencoder based multi-scale deep learning model that provides saliency prediction at the mobile interface element level. Compared to saliency prediction approaches developed for natural images, we show that our approach performs significantly better on a range of established metrics.

##### Abstract (translated by Google)
我们为移动用户界面引入了显着性预测模型。除了能够执行各种任务的自然图像之外，移动界面还可以包括诸如按钮，文本等元素。自然图像中的显着性是一个研究得很好的领域。然而，考虑到移动界面的构成以及这些设备的使用环境的不同，我们假定移动界面图像的显着性预测需要一个全新的方法。移动界面设计涉及操作元素，界面的构建块。我们首先收集来自移动设备的视线数据以免费观看任务。使用这些数据，我们开发了一种基于自动编码器的多尺度深度学习模型，在移动界面元素级别提供显着性预测。与为自然图像开发的显着性预测方法相比，我们展示了我们的方法在一系列已建立的度量上显着改善。

##### URL
[https://arxiv.org/abs/1711.03726](https://arxiv.org/abs/1711.03726)

##### PDF
[https://arxiv.org/pdf/1711.03726](https://arxiv.org/pdf/1711.03726)

