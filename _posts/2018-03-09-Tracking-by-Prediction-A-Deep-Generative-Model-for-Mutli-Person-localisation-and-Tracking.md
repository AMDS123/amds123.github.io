---
layout: post
title: "Tracking by Prediction: A Deep Generative Model for Mutli-Person localisation and Tracking"
date: 2018-03-09 01:14:30
categories: arXiv_CV
tags: arXiv_CV Re-identification Adversarial Tracking Person_Re-identification Deep_Learning Prediction Detection
author: Tharindu Fernando, Simon Denman, Sridha Sridharan, Clinton Fookes
mathjax: true
---

* content
{:toc}

##### Abstract
Current multi-person localisation and tracking systems have an over reliance on the use of appearance models for target re-identification and almost no approaches employ a complete deep learning solution for both objectives. We present a novel, complete deep learning framework for multi-person localisation and tracking. In this context we first introduce a light weight sequential Generative Adversarial Network architecture for person localisation, which overcomes issues related to occlusions and noisy detections, typically found in a multi person environment. In the proposed tracking framework we build upon recent advances in pedestrian trajectory prediction approaches and propose a novel data association scheme based on predicted trajectories. This removes the need for computationally expensive person re-identification systems based on appearance features and generates human like trajectories with minimal fragmentation. The proposed method is evaluated on multiple public benchmarks including both static and dynamic cameras and is capable of generating outstanding performance, especially among other recently proposed deep neural network based approaches.

##### Abstract (translated by Google)
当前的多人定位和跟踪系统过度依赖于使用外观模型进行目标重新识别，并且几乎没有方法针对两个目标都采用完整的深度学习解决方案。我们提出了一种新颖，完整的多人定位和跟踪深度学习框架。在这种情况下，我们首先引入一个轻量级的顺序生成对抗网络体系结构，用于人体定位，它克服了通常在多人环境中发现的与闭塞和噪声检测有关的问题。在所提出的追踪框架中，我们基于行人轨迹预测方法的最新进展并提出基于预测轨迹的新型数据关联方案。这消除了对基于外观特征的计算昂贵的人重新识别系统的需求，并产生具有最小碎片的人类轨迹。所提出的方法在包括静态和动态相机在内的多个公共基准上进行评估，并且能够产生出色的性能，尤其是在其他最近提出的基于深度神经网络的方法中。

##### URL
[http://arxiv.org/abs/1803.03347](http://arxiv.org/abs/1803.03347)

##### PDF
[http://arxiv.org/pdf/1803.03347](http://arxiv.org/pdf/1803.03347)

