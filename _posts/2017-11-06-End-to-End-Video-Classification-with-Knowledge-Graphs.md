---
layout: post
title: "End-to-End Video Classification with Knowledge Graphs"
date: 2017-11-06 03:50:35
categories: arXiv_CV
tags: arXiv_CV Video_Caption Knowledge_Graph Knowledge Attention Video_Classification Classification
author: Fang Yuan, Zhe Wang, Jie Lin, Luis Fernando D'Haro, Kim Jung Jae, Zeng Zeng, Vijay Chandrasekhar
mathjax: true
---

* content
{:toc}

##### Abstract
Video understanding has attracted much research attention especially since the recent availability of large-scale video benchmarks. In this paper, we address the problem of multi-label video classification. We first observe that there exists a significant knowledge gap between how machines and humans learn. That is, while current machine learning approaches including deep neural networks largely focus on the representations of the given data, humans often look beyond the data at hand and leverage external knowledge to make better decisions. Towards narrowing the gap, we propose to incorporate external knowledge graphs into video classification. In particular, we unify traditional "knowledgeless" machine learning models and knowledge graphs in a novel end-to-end framework. The framework is flexible to work with most existing video classification algorithms including state-of-the-art deep models. Finally, we conduct extensive experiments on the largest public video dataset YouTube-8M. The results are promising across the board, improving mean average precision by up to 2.9%.

##### Abstract (translated by Google)
视频理解已经引起了很多研究的关注，特别是自从大规模的视频基准测试以来。在本文中，我们解决了多标签视频分类的问题。我们首先观察到，机器和人类的学习方式之间存在显着的知识差距。也就是说，尽管包括深度神经网络在内的当前的机器学习方法主要集中在给定数据的表示上，但人们往往超越手边的数据并利用外部知识来做出更好的决策。为了缩小差距，我们建议将外部知识图表纳入视频分类。特别是，我们将传统的“无知识”机器学习模型和知识图形统一在一个新的端到端框架中。该框架可以灵活地处理大多数现有的视频分类算法，包括最新的深度模型。最后，我们对最大的公共视频数据集YouTube-8M进行了广泛的实验。结果令人鼓舞，平均精确度提高了2.9％。

##### URL
[https://arxiv.org/abs/1711.01714](https://arxiv.org/abs/1711.01714)

##### PDF
[https://arxiv.org/pdf/1711.01714](https://arxiv.org/pdf/1711.01714)

