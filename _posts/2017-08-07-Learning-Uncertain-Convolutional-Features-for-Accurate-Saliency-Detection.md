---
layout: post
title: "Learning Uncertain Convolutional Features for Accurate Saliency Detection"
date: 2017-08-07 08:18:04
categories: arXiv_CV
tags: arXiv_CV Salient Object_Detection CNN Inference Detection
author: Pingping Zhang, Dong Wang, Huchuan Lu, Hongyu Wang, Baocai Yin
mathjax: true
---

* content
{:toc}

##### Abstract
Deep convolutional neural networks (CNNs) have delivered superior performance in many computer vision tasks. In this paper, we propose a novel deep fully convolutional network model for accurate salient object detection. The key contribution of this work is to learn deep uncertain convolutional features (UCF), which encourage the robustness and accuracy of saliency detection. We achieve this via introducing a reformulated dropout (R-dropout) after specific convolutional layers to construct an uncertain ensemble of internal feature units. In addition, we propose an effective hybrid upsampling method to reduce the checkerboard artifacts of deconvolution operators in our decoder network. The proposed methods can also be applied to other deep convolutional networks. Compared with existing saliency detection methods, the proposed UCF model is able to incorporate uncertainties for more accurate object boundary inference. Extensive experiments demonstrate that our proposed saliency model performs favorably against state-of-the-art approaches. The uncertain feature learning mechanism as well as the upsampling method can significantly improve performance on other pixel-wise vision tasks.

##### Abstract (translated by Google)
深卷积神经网络（CNN）在许多计算机视觉任务中提供了优越的性能。在本文中，我们提出了一种新的深度全卷积网络模型来进行精确的显着物体检测。这项工作的主要贡献是学习深度不确定卷积特征（UCF），鼓励显着性检测的鲁棒性和准确性。我们通过在特定的卷积层之后引入一个重新配置的丢失（R-dropout）来构造一个不确定的内部特征单元集合。另外，我们提出了一种有效的混合上采样方法来减少我们的解码器网络中去卷积算子的棋盘伪影。所提出的方法也可以应用于其他深度卷积网络。与现有的显着性检测方法相比，所提出的UCF模型能够结合不确定性来获得更精确的对象边界推断。大量的实验证明，我们所提出的显着性模型对最先进的方法是有利的。不确定的特征学习机制以及上采样方法可以显着提高其他像素视觉任务的性能。

##### URL
[https://arxiv.org/abs/1708.02031](https://arxiv.org/abs/1708.02031)

##### PDF
[https://arxiv.org/pdf/1708.02031](https://arxiv.org/pdf/1708.02031)

