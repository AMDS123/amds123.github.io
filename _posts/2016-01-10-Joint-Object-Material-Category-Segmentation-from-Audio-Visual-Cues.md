---
layout: post
title: "Joint Object-Material Category Segmentation from Audio-Visual Cues"
date: 2016-01-10 14:14:53
categories: arXiv_CV
tags: arXiv_CV Sparse Segmentation
author: Anurag Arnab, Michael Sapienza, Stuart Golodetz, Julien Valentin, Ondrej Miksik, Shahram Izadi, Philip Torr
mathjax: true
---

* content
{:toc}

##### Abstract
It is not always possible to recognise objects and infer material properties for a scene from visual cues alone, since objects can look visually similar whilst being made of very different materials. In this paper, we therefore present an approach that augments the available dense visual cues with sparse auditory cues in order to estimate dense object and material labels. Since estimates of object class and material properties are mutually informative, we optimise our multi-output labelling jointly using a random-field framework. We evaluate our system on a new dataset with paired visual and auditory data that we make publicly available. We demonstrate that this joint estimation of object and material labels significantly outperforms the estimation of either category in isolation.

##### Abstract (translated by Google)
从视觉线索中单独识别对象并推断场景的材料属性并不总是可能的，因为对象可以看起来在视觉上相似而由非常不同的材料制成。因此，在本文中，我们提出了一种方法，用稀疏的听觉线索来增加可用的密集视觉线索，以便估计密集的对象和材料标签。由于对象类别和材料属性的估计是相互提供信息的，我们使用随机场框架来共同优化我们的多输出标签。我们在一个新的数据集上评估我们的系统，使用公开的视觉和听觉数据。我们证明这个对象和材料标签的联合估计明显优于任一个类别的估计。

##### URL
[https://arxiv.org/abs/1601.02220](https://arxiv.org/abs/1601.02220)

##### PDF
[https://arxiv.org/pdf/1601.02220](https://arxiv.org/pdf/1601.02220)

