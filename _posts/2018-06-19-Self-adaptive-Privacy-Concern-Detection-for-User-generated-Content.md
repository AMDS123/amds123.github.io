---
layout: post
title: "Self-adaptive Privacy Concern Detection for User-generated Content"
date: 2018-06-19 13:40:27
categories: arXiv_CL
tags: arXiv_CL Detection
author: Xuan-Son Vu, Lili Jiang
mathjax: true
---

* content
{:toc}

##### Abstract
To protect user privacy in data analysis, a state-of-the-art strategy is differential privacy in which scientific noise is injected into the real analysis output. The noise masks individual's sensitive information contained in the dataset. However, determining the amount of noise is a key challenge, since too much noise will destroy data utility while too little noise will increase privacy risk. Though previous research works have designed some mechanisms to protect data privacy in different scenarios, most of the existing studies assume uniform privacy concerns for all individuals. Consequently, putting an equal amount of noise to all individuals leads to insufficient privacy protection for some users, while over-protecting others. To address this issue, we propose a self-adaptive approach for privacy concern detection based on user personality. Our experimental studies demonstrate the effectiveness to address a suitable personalized privacy protection for cold-start users (i.e., without their privacy-concern information in training data).

##### Abstract (translated by Google)
为了保护用户在数据分析中的隐私，最先进的策略是将科学噪音注入真实分析输出中的差异隐私。噪声掩盖了数据集中包含的个人敏感信息。但是，确定噪声量是一个关键挑战，因为太多的噪声会破坏数据效用，而噪声太少会增加隐私风险。虽然以前的研究工作已经设计了一些机制来保护不同场景下的数据隐私，但大多数现有研究都假设所有人都有一致的隐私担忧。因此，对所有用户施加相同数量的噪声会导致某些用户的隐私保护不足，同时过度保护其他用户。为了解决这个问题，我们提出了一种基于用户个性的隐私关心检测的自适应方法。我们的实验研究表明，为冷启动用户提供合适的个性化隐私保护（即，在培训数据中没有隐私关注信息）的有效性。

##### URL
[http://arxiv.org/abs/1806.07221](http://arxiv.org/abs/1806.07221)

##### PDF
[http://arxiv.org/pdf/1806.07221](http://arxiv.org/pdf/1806.07221)

