---
layout: post
title: "TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition"
date: 2017-03-30 20:45:00
categories: arXiv_CV
tags: arXiv_CV CNN RNN Recognition
author: Chih-Yao Ma, Min-Hung Chen, Zsolt Kira, Ghassan AlRegib
mathjax: true
---

* content
{:toc}

##### Abstract
Recent two-stream deep Convolutional Neural Networks (ConvNets) have made significant progress in recognizing human actions in videos. Despite their success, methods extending the basic two-stream ConvNet have not systematically explored possible network architectures to further exploit spatiotemporal dynamics within video sequences. Further, such networks often use different baseline two-stream networks. Therefore, the differences and the distinguishing factors between various methods using Recurrent Neural Networks (RNN) or convolutional networks on temporally-constructed feature vectors (Temporal-ConvNet) are unclear. In this work, we first demonstrate a strong baseline two-stream ConvNet using ResNet-101. We use this baseline to thoroughly examine the use of both RNNs and Temporal-ConvNets for extracting spatiotemporal information. Building upon our experimental results, we then propose and investigate two different networks to further integrate spatiotemporal information: 1) temporal segment RNN and 2) Inception-style Temporal-ConvNet. We demonstrate that using both RNNs (using LSTMs) and Temporal-ConvNets on spatiotemporal feature matrices are able to exploit spatiotemporal dynamics to improve the overall performance. However, each of these methods require proper care to achieve state-of-the-art performance; for example, LSTMs require pre-segmented data or else they cannot fully exploit temporal information. Our analysis identifies specific limitations for each method that could form the basis of future work. Our experimental results on UCF101 and HMDB51 datasets achieve state-of-the-art performances, 94.1% and 69.0%, respectively, without requiring extensive temporal augmentation.

##### Abstract (translated by Google)
最近的双流深度卷积神经网络（ConvNets）在认识视频中的人类行为方面取得了重大进展。尽管它们取得了成功，但扩展基本的双流ConvNet的方法还没有系统地探索可能的网络架构，以进一步利用视频序列中的时空动态。此外，这样的网络通常使用不同的基线双流网络。因此，使用递归神经网络（RNN）或卷积网络构建时间 - 特征向量（Temporal-ConvNet）的各种方法之间的差异和区别因素尚不清楚。在这项工作中，我们首先使用ResNet-101演示了一个强大的基线双流ConvNet。我们使用这个基线来彻底检查RNN和Temporal-ConvNets用于提取时空信息的用法。在我们的实验结果的基础上，我们提出并研究了两个不同的网络，以进一步整合时空信息：1）时间段RNN和2）初始式时空ConvNet。我们证明，在时空特征矩阵上使用两个RNN（使用LSTM）和时空ConvNets都能够利用时空动态来提高整体性能。但是，这些方法中的每一种都需要适当的照顾才能达到最新的性能。例如，LSTM需要预先分段的数据，否则他们不能充分利用时间信息。我们的分析确定了每种方法的具体限制，可以构成未来工作的基础。我们的UCF101和HMDB51数据集的实验结果分别达到了最新的性能，分别为94.1％和69.0％，而不需要大量的时间增量。

##### URL
[https://arxiv.org/abs/1703.10667](https://arxiv.org/abs/1703.10667)

##### PDF
[https://arxiv.org/pdf/1703.10667](https://arxiv.org/pdf/1703.10667)

