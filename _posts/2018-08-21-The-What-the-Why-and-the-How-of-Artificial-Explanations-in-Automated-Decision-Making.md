---
layout: post
title: "The What, the Why, and the How of Artificial Explanations in Automated Decision-Making"
date: 2018-08-21 18:06:22
categories: arXiv_AI
tags: arXiv_AI Review Relation
author: Tarek R. Besold, Sara L. Uckelman
mathjax: true
---

* content
{:toc}

##### Abstract
The increasing incorporation of Artificial Intelligence in the form of automated systems into decision-making procedures highlights not only the importance of decision theory for automated systems but also the need for these decision procedures to be explainable to the people involved in them. Traditional realist accounts of explanation, wherein explanation is a relation that holds (or does not hold) eternally between an explanans and an explanandum, are not adequate to account for the notion of explanation required for artificial decision procedures. We offer an alternative account of explanation as used in the context of automated decision-making that makes explanation an epistemic phenomenon, and one that is dependent on context. This account of explanation better accounts for the way that we talk about, and use, explanations and derived concepts, such as `explanatory power', and also allows us to differentiate between reasons or causes on the one hand, which do not need to have an epistemic aspect, and explanations on the other, which do have such an aspect. Against this theoretical backdrop we then review existing approaches to explanation in Artificial Intelligence and Machine Learning, and suggest desiderata which truly explainable decision systems should fulfill.

##### Abstract (translated by Google)
越来越多地将人工智能以自动化系统的形式纳入决策程序，不仅突出了决策理论对自动化系统的重要性，而且突出了这些决策程序可以向参与其中的人员解释的必要性。解释的传统现实主义说明，其中解释是在解释者和解释书之间永久保持（或不成立）的关系，不足以解释人工决策程序所需的解释概念。我们提供了另一种解释说明，用于自动决策的背景下，使解释成为一种认知现象，并且依赖于背景。这个解释说明更好地说明了我们谈论和使用，解释和派生概念的方式，例如“解释力”，并且还允许我们一方面区分原因或原因，而不需要一个认知方面，另一方面的解释，确实有这样的方面。在这个理论背景下，我们回顾了人工智能和机器学习中现有的解释方法，并提出了真正可解释的决策系统应该实现的需求。

##### URL
[http://arxiv.org/abs/1808.07074](http://arxiv.org/abs/1808.07074)

##### PDF
[http://arxiv.org/pdf/1808.07074](http://arxiv.org/pdf/1808.07074)

