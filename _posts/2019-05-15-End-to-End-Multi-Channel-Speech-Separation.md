---
layout: post
title: "End-to-End Multi-Channel Speech Separation"
date: 2019-05-15 16:38:16
categories: arXiv_AI
tags: arXiv_AI
author: Rongzhi Gu, Jian Wu, Shi-Xiong Zhang, Lianwu Chen, Yong Xu, Meng Yu, Dan Su, Yuexian Zou, Dong Yu
mathjax: true
---

* content
{:toc}

##### Abstract
The end-to-end approach for single-channel speech separation has been studied recently and shown promising results. This paper extended the previous approach and proposed a new end-to-end model for multi-channel speech separation. The primary contributions of this work include 1) an integrated waveform-in waveform-out separation system in a single neural network architecture. 2) We reformulate the traditional short time Fourier transform (STFT) and inter-channel phase difference (IPD) as a function of time-domain convolution with a special kernel. 3) We further relaxed those fixed kernels to be learnable, so that the entire architecture becomes purely data-driven and can be trained from end-to-end. We demonstrate on the WSJ0 far-field speech separation task that, with the benefit of learnable spatial features, our proposed end-to-end multi-channel model significantly improved the performance of previous end-to-end single-channel method and traditional multi-channel methods.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.06286](http://arxiv.org/abs/1905.06286)

##### PDF
[http://arxiv.org/pdf/1905.06286](http://arxiv.org/pdf/1905.06286)

