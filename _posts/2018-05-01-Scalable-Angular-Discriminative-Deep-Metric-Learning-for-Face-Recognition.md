---
layout: post
title: "Scalable Angular Discriminative Deep Metric Learning for Face Recognition"
date: 2018-05-01 01:30:56
categories: arXiv_AI
tags: arXiv_AI Face Deep_Learning Recognition Face_Recognition
author: Bowen Wu, Huaming Wu, Monica M.Y. Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
With the development of deep learning, Deep Metric Learning (DML) has achieved great improvements in face recognition. Specifically, the widely used softmax loss in the training process often bring large intra-class variations, and feature normalization is only exploited in the testing process to compute the pair similarities. To bridge the gap, we impose the intra-class cosine similarity between the features and weight vectors in softmax loss larger than a margin in the training step, and extend it from four aspects. First, we explore the effect of a hard sample mining strategy. To alleviate the human labor of adjusting the margin hyper-parameter, a self-adaptive margin updating strategy is proposed. Then, a normalized version is given to take full advantage of the cosine similarity constraint. Furthermore, we enhance the former constraint to force the intra-class cosine similarity larger than the mean inter-class cosine similarity with a margin in the exponential feature projection space. Extensive experiments on Labeled Face in the Wild (LFW), Youtube Faces (YTF) and IARPA Janus Benchmark A (IJB-A) datasets demonstrate that the proposed methods outperform the mainstream DML methods and approach the state-of-the-art performance.

##### Abstract (translated by Google)
随着深度学习的发展，深度度量学习（DML）在人脸识别方面取得了很大的进步。具体而言，在训练过程中广泛使用的softmax损失通常会带来较大的类内变化，并且特征归一化仅在测试过程中被利用来计算这些配对相似性。为弥补差距，我们在softmax损失中的特征和权重向量之间的类内余弦相似性大于训练步骤中的边际，并从四个方面扩展它。首先，我们探索一个硬采样策略的效果。为缓解调整边缘超参数的人力劳动，提出了一种自适应边缘更新策略。然后，给出一个规范化版本以充分利用余弦相似性约束。此外，我们增强了前一个约束，迫使类内余弦相似度大于指数特征投影空间中具有余量的平均类间余弦相似度。在野外标记人脸（LFW），Youtube人脸（YTF）和IARPA Janus基准A（IJB-A）数据集上的大量实验表明，所提出的方法优于主流DML方法并接近最先进的性能。

##### URL
[https://arxiv.org/abs/1804.10899](https://arxiv.org/abs/1804.10899)

##### PDF
[https://arxiv.org/pdf/1804.10899](https://arxiv.org/pdf/1804.10899)

