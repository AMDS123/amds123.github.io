---
layout: post
title: "Keynote: Small Neural Nets Are Beautiful: Enabling Embedded Systems with Small Deep-Neural-Network Architectures"
date: 2017-10-07 23:33:31
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition Recognition
author: Forrest Iandola, Kurt Keutzer
mathjax: true
---

* content
{:toc}

##### Abstract
Over the last five years Deep Neural Nets have offered more accurate solutions to many problems in speech recognition, and computer vision, and these solutions have surpassed a threshold of acceptability for many applications. As a result, Deep Neural Networks have supplanted other approaches to solving problems in these areas, and enabled many new applications. While the design of Deep Neural Nets is still something of an art form, in our work we have found basic principles of design space exploration used to develop embedded microprocessor architectures to be highly applicable to the design of Deep Neural Net architectures. In particular, we have used these design principles to create a novel Deep Neural Net called SqueezeNet that requires as little as 480KB of storage for its model parameters. We have further integrated all these experiences to develop something of a playbook for creating small Deep Neural Nets for embedded systems.

##### Abstract (translated by Google)
在过去的五年里，深度神经网络为语音识别和计算机视觉等许多问题提供了更准确的解决方案，而这些解决方案已经超越了许多应用的可接受性阈值。因此，深度神经网络已经取代了其他解决这些问题的方法，并启用了许多新的应用。虽然深度神经网络的设计仍然是一种艺术形式，但是在我们的工作中，我们发现用于开发嵌入式微处理器架构的设计空间探索的基本原理非常适用于深度神经网络结构的设计。特别是，我们已经使用这些设计原则来创建一个名为SqueezeNet的新型深度神经网络，其模型参数只需要480KB的存储空间。我们进一步整合了所有这些经验，为嵌入式系统开发小型深度神经网络的剧本。

##### URL
[https://arxiv.org/abs/1710.02759](https://arxiv.org/abs/1710.02759)

##### PDF
[https://arxiv.org/pdf/1710.02759](https://arxiv.org/pdf/1710.02759)

