---
layout: post
title: "Ask Me Even More: Dynamic Memory Tensor Networks"
date: 2017-03-11 10:05:19
categories: arXiv_CV
tags: arXiv_CV QA Dynamic_Memory_Network Attention Weakly_Supervised Face Memory_Networks
author: Govardana Sachithanandam Ramachandran, Ajay Sohmshetty
mathjax: true
---

* content
{:toc}

##### Abstract
We examine Memory Networks for the task of question answering (QA), under common real world scenario where training examples are scarce and under weakly supervised scenario, that is only extrinsic labels are available for training. We propose extensions for the Dynamic Memory Network (DMN), specifically within the attention mechanism, we call the resulting Neural Architecture as Dynamic Memory Tensor Network (DMTN). Ultimately, we see that our proposed extensions results in over 80% improvement in the number of task passed against the baselined standard DMN and 20% more task passed compared to state-of-the-art End-to-End Memory Network for Facebook's single task weakly trained 1K bAbi dataset.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1703.03939](https://arxiv.org/abs/1703.03939)

##### PDF
[https://arxiv.org/pdf/1703.03939](https://arxiv.org/pdf/1703.03939)

