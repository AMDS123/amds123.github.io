---
layout: post
title: "The Enemy Among Us: Detecting Hate Speech with Threats Based 'Othering' Language Embeddings"
date: 2018-03-08 12:25:38
categories: arXiv_CL
tags: arXiv_CL Embedding Classification Detection
author: Wafa Alorainy, Pete Burnap, Han Liu, Matthew Williams
mathjax: true
---

* content
{:toc}

##### Abstract
Offensive or antagonistic language targeted at individuals and social groups based on their personal characteristics (also known as cyber hate speech or cyberhate) has been frequently posted and widely circulated viathe World Wide Web. This can be considered as a key risk factor for individual and societal tension linked toregional instability. Automated Web-based cyberhate detection is important for observing and understandingcommunity and regional societal tension - especially in online social networks where posts can be rapidlyand widely viewed and disseminated. While previous work has involved using lexicons, bags-of-words orprobabilistic language parsing approaches, they often suffer from a similar issue which is that cyberhate can besubtle and indirect - thus depending on the occurrence of individual words or phrases can lead to a significantnumber of false negatives, providing inaccurate representation of the trends in cyberhate. This problemmotivated us to challenge thinking around the representation of subtle language use, such as references toperceived threats from "the other" including immigration or job prosperity in a hateful context. We propose anovel framework that utilises language use around the concept of "othering" and intergroup threat theory toidentify these subtleties and we implement a novel classification method using embedding learning to computesemantic distances between parts of speech considered to be part of an "othering" narrative. To validate ourapproach we conduct several experiments on different types of cyberhate, namely religion, disability, race andsexual orientation, with F-measure scores for classifying hateful instances obtained through applying ourmodel of 0.93, 0.86, 0.97 and 0.98 respectively, providing a significant improvement in classifier accuracy overthe state-of-the-art

##### Abstract (translated by Google)
基于个人特征（也称为网络仇恨言论或网络仇恨）针对个人和社会群体的攻击性或对抗性语言经常在万维网上发布并广泛流传。这可能被认为是与地区不稳定有关的个人和社会紧张的关键风险因素。自动化的基于Web的网络检测对于观察和了解社区和地区社会紧张情况非常重要 - 特别是在可以迅速广泛查看和传播职位的在线社交网络中。虽然以前的工作涉及到使用词汇，词组或词法分析的方法，但他们经常会遇到类似的问题，即网络聊天室可能非常细微和间接 - 因此取决于个别单词或短语的出现可能会导致大量的错误的否定，提供了网络化趋势的不准确表示。这使我们无法挑战围绕微妙语言使用的表达方式的思考，例如提到来自“其他”的知觉威胁，包括移民或可恶的背景下的工作繁荣。我们提出了一种利用围绕“其他”和群际威胁理论的语言使用的语言框架来识别这些微妙之处，并且我们实现了一种使用嵌入学习来计算被认为是“其他”叙述的一部分的语言部分之间的语义距离的新颖分类方法。为验证我们的做法，我们对不同类型的网络犯罪进行了多次实验，即宗教，残疾，种族和性取向，通过应用我们的模型分别获得0.93,0.86,0.97和0.98分类的仇恨实例的F-measure分数，显着改善分类器的精度超过了最新的水平

##### URL
[http://arxiv.org/abs/1801.07495](http://arxiv.org/abs/1801.07495)

##### PDF
[http://arxiv.org/pdf/1801.07495](http://arxiv.org/pdf/1801.07495)

