---
layout: post
title: "BodyNet: Volumetric Inference of 3D Human Body Shapes"
date: 2018-07-31 22:49:49
categories: arXiv_CV
tags: arXiv_CV Segmentation Inference
author: G&#xfc;l Varol, Duygu Ceylan, Bryan Russell, Jimei Yang, Ersin Yumer, Ivan Laptev, Cordelia Schmid
mathjax: true
---

* content
{:toc}

##### Abstract
Human shape estimation is an important task for video editing, animation and fashion industry. Predicting 3D human body shape from natural images, however, is highly challenging due to factors such as variation in human bodies, clothing and viewpoint. Prior methods addressing this problem typically attempt to fit parametric body models with certain priors on pose and shape. In this work we argue for an alternative representation and propose BodyNet, a neural network for direct inference of volumetric body shape from a single image. BodyNet is an end-to-end trainable network that benefits from (i) a volumetric 3D loss, (ii) a multi-view re-projection loss, and (iii) intermediate supervision of 2D pose, 2D body part segmentation, and 3D pose. Each of them results in performance improvement as demonstrated by our experiments. To evaluate the method, we fit the SMPL model to our network output and show state-of-the-art results on the SURREAL and Unite the People datasets, outperforming recent approaches. Besides achieving state-of-the-art performance, our method also enables volumetric body-part segmentation.

##### Abstract (translated by Google)
人体形状估计是视频编辑，动画和时尚产业的重要任务。然而，由于诸如人体，衣服和视点的变化等因素，从自然图像预测3D人体形状是非常具有挑战性的。解决该问题的现有方法通常试图使参数身体模型适合姿势和形状的某些先验。在这项工作中，我们争论一个替代表示，并提出BodyNet，一个神经网络，用于从单个图像直接推断体积体形。 BodyNet是一个端到端的可训练网络，受益于（i）体积3D损失，（ii）多视图重投影损失，以及（iii）2D姿势，2D身体部位分割和3D的中间监督姿势。如我们的实验所证明的，它们中的每一个都导致性能提高。为了评估该方法，我们将SMPL模型与我们的网络输出相匹配，并在SURREAL和Unite the People数据集上显示最新结果，优于最近的方法。除了实现最先进的性能，我们的方法还可以实现体积分量。

##### URL
[http://arxiv.org/abs/1804.04875](http://arxiv.org/abs/1804.04875)

##### PDF
[http://arxiv.org/pdf/1804.04875](http://arxiv.org/pdf/1804.04875)

