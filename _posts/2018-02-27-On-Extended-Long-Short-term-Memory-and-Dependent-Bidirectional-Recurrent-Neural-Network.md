---
layout: post
title: "On Extended Long Short-term Memory and Dependent Bidirectional Recurrent Neural Network"
date: 2018-02-27 02:47:13
categories: arXiv_CL
tags: arXiv_CL RNN Prediction
author: Yuanhang Su, Yuzhong Huang, C.-C. Jay Kuo
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we investigate the memory capability of recurrent neural networks (RNNs), where this capability is defined as a function that maps an element in a sequence to the current output. We first analyze the system function of a recurrent neural network (RNN) cell, and provide analytical results for three RNNs. They are the simple recurrent neural network (SRN), the long short-term memory (LSTM), and the gated recurrent unit (GRU). Based on the analysis, we propose a new design to extend the memory length of a cell, and call it the extended long short-term memory (ELSTM). Next, we present a dependent bidirectional recurrent neural network (DBRNN) for the sequence-in-sequence-out (SISO) problem, which is more robust to previous erroneous predictions. Extensive experiments are carried out on different language tasks to demonstrate the superiority of our proposed ELSTM and DBRNN solutions.

##### Abstract (translated by Google)
在这项工作中，我们研究循环神经网络（RNN）的记忆能力，其中这种能力被定义为一个函数，将序列中的一个元素映射到当前输出。我们首先分析循环神经网络（RNN）的系统功能，并为三个RNN提供分析结果。它们是简单的递归神经网络（SRN），长期的短期记忆（LSTM）和门控循环单元（GRU）。根据分析，我们提出了一种新的设计来延长单元的内存长度，并称之为扩展的长期短期内存（ELSTM）。接下来，我们针对序列输出（SISO）问题提出了一个依赖双向递归神经网络（DBRNN），该问题对以前的错误预测更加稳健。对不同的语言任务进行了大量的实验，以证明我们提出的ELSTM和DBRNN解决方案的优越性。

##### URL
[http://arxiv.org/abs/1803.01686](http://arxiv.org/abs/1803.01686)

##### PDF
[http://arxiv.org/pdf/1803.01686](http://arxiv.org/pdf/1803.01686)

