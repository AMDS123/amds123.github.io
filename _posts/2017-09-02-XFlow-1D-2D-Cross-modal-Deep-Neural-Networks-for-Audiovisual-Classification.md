---
layout: post
title: "XFlow: 1D-2D Cross-modal Deep Neural Networks for Audiovisual Classification"
date: 2017-09-02 12:43:59
categories: arXiv_CV
tags: arXiv_CV Classification Deep_Learning Relation
author: Cătălina Cangea, Petar Veličković, Pietro Liò
mathjax: true
---

* content
{:toc}

##### Abstract
We propose two multimodal deep learning architectures that allow for cross-modal dataflow (XFlow) between the feature extractors, thereby extracting more interpretable features and obtaining a better representation than through unimodal learning, for the same amount of training data. These models can usefully exploit correlations between audio and visual data, which have a different dimensionality and are therefore nontrivially exchangeable. Our work improves on existing multimodal deep learning metholodogies in two essential ways: (1) it presents a novel method for performing cross-modality (before features are learned from individual modalities) and (2) extends the previously proposed cross-connections, which only transfer information between streams that process compatible data. Both cross-modal architectures outperformed their baselines (by up to 7.5%) when evaluated on the AVletters dataset.

##### Abstract (translated by Google)
我们提出了两种多模式深度学习架构，允许特征提取器之间的跨模态数据流（XFlow），从而提取更多的可解释的特征，并获得比通过单峰学习更好的表示，用于相同数量的训练数据。这些模型可以有效地利用音频和视觉数据之间的相关性，这些数据具有不同的维度，因此是非平凡的可交换的。我们的工作改进了现有的多模态深度学习方法：（1）提出了一种执行交叉模态的新方法（在从各个模态中学习特征之前），（2）扩展了以前提出的交叉连接，在处理兼容数据的流之间传输信息。在AVletters数据集上进行评估时，这两种跨模式体系结构的性能均优于基准（高达7.5％）。

##### URL
[https://arxiv.org/abs/1709.00572](https://arxiv.org/abs/1709.00572)

##### PDF
[https://arxiv.org/pdf/1709.00572](https://arxiv.org/pdf/1709.00572)

