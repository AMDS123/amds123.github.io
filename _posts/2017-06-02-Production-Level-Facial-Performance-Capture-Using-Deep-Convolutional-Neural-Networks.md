---
layout: post
title: "Production-Level Facial Performance Capture Using Deep Convolutional Neural Networks"
date: 2017-06-02 13:54:51
categories: arXiv_CV
tags: arXiv_CV Face Tracking CNN Inference Deep_Learning
author: Samuli Laine, Tero Karras, Timo Aila, Antti Herva, Shunsuke Saito, Ronald Yu, Hao Li, Jaakko Lehtinen
mathjax: true
---

* content
{:toc}

##### Abstract
We present a real-time deep learning framework for video-based facial performance capture -- the dense 3D tracking of an actor's face given a monocular video. Our pipeline begins with accurately capturing a subject using a high-end production facial capture pipeline based on multi-view stereo tracking and artist-enhanced animations. With 5-10 minutes of captured footage, we train a convolutional neural network to produce high-quality output, including self-occluded regions, from a monocular video sequence of that subject. Since this 3D facial performance capture is fully automated, our system can drastically reduce the amount of labor involved in the development of modern narrative-driven video games or films involving realistic digital doubles of actors and potentially hours of animated dialogue per character. We compare our results with several state-of-the-art monocular real-time facial capture techniques and demonstrate compelling animation inference in challenging areas such as eyes and lips.

##### Abstract (translated by Google)
我们提出了一个基于视频的面部表情捕捉的实时深度学习框架 - 在给定单目视频的情况下对演员脸部的密集3D跟踪。我们的流程开始于使用基于多视点立体声跟踪和艺术家增强动画的高端制作面部捕捉流水线来准确捕捉主体。利用5-10分钟的捕捉画面，我们训练卷积神经网络，以从该主题的单眼视频序列产生高质量的输出，包括自遮挡区域。由于3D面部表情捕捉是完全自动化的，因此我们的系统可以大幅度减少现代叙事驱动的视频游戏或涉及演员实际数字双打的影片所需的劳动量，以及每个角色的动画对话数小时。我们将我们的成果与几种最先进的单眼实时面部捕捉技术进行比较，并在具有挑战性的领域（如眼睛和嘴唇）中展示令人信服的动画推理。

##### URL
[https://arxiv.org/abs/1609.06536](https://arxiv.org/abs/1609.06536)

##### PDF
[https://arxiv.org/pdf/1609.06536](https://arxiv.org/pdf/1609.06536)

