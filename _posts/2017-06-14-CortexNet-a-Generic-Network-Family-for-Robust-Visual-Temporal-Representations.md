---
layout: post
title: "CortexNet: a Generic Network Family for Robust Visual Temporal Representations"
date: 2017-06-14 17:53:32
categories: arXiv_CV
tags: arXiv_CV Weakly_Supervised Detection Recognition
author: Alfredo Canziani, Eugenio Culurciello
mathjax: true
---

* content
{:toc}

##### Abstract
In the past five years we have observed the rise of incredibly well performing feed-forward neural networks trained supervisedly for vision related tasks. These models have achieved super-human performance on object recognition, localisation, and detection in still images. However, there is a need to identify the best strategy to employ these networks with temporal visual inputs and obtain a robust and stable representation of video data. Inspired by the human visual system, we propose a deep neural network family, CortexNet, which features not only bottom-up feed-forward connections, but also it models the abundant top-down feedback and lateral connections, which are present in our visual cortex. We introduce two training schemes - the unsupervised MatchNet and weakly supervised TempoNet modes - where a network learns how to correctly anticipate a subsequent frame in a video clip or the identity of its predominant subject, by learning egomotion clues and how to automatically track several objects in the current scene. Find the project website at this https URL

##### Abstract (translated by Google)
在过去的五年中，我们观察到了令人难以置信的表现良好的前馈神经网络监督训练视觉相关的任务的兴起。这些模型已经在静止图像中的物体识别，定位和检测上实现了超人类的性能。然而，有必要确定采用这些具有时间视觉输入的网络的最佳策略，并获得稳健和稳定的视频数据表示。受到人类视觉系统的启发，我们提出了一个深度神经网络家族CortexNet，它不仅具有自下而上的前馈连接，而且还模拟了存在于我们的视觉皮层中的丰富的自顶向下反馈和横向连接。我们介绍两种训练方案 - 无监督的MatchNet和弱监督的TempoNet模式 - 网络学习如何正确预测视频片段中的后续帧或其主要主题的身份，通过学习自我线索以及如何自动跟踪多个对象当前的情景。在此https网址找到项目网站

##### URL
[https://arxiv.org/abs/1706.02735](https://arxiv.org/abs/1706.02735)

##### PDF
[https://arxiv.org/pdf/1706.02735](https://arxiv.org/pdf/1706.02735)

