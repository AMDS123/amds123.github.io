---
layout: post
title: "Learning Scene Gist with Convolutional Neural Networks to Improve Object Recognition"
date: 2018-03-06 00:45:33
categories: arXiv_CV
tags: arXiv_CV CNN Recognition
author: Kevin Wu, Eric Wu, Gabriel Kreiman
mathjax: true
---

* content
{:toc}

##### Abstract
Advancements in convolutional neural networks (CNNs) have made significant strides toward achieving high performance levels on multiple object recognition tasks. While some approaches utilize information from the entire scene to propose regions of interest, the task of interpreting a particular region or object is still performed independently of other objects and features in the image. Here we demonstrate that a scene's 'gist' can significantly contribute to how well humans can recognize objects. These findings are consistent with the notion that humans foveate on an object and incorporate information from the periphery to aid in recognition. We use a biologically inspired two-part convolutional neural network ('GistNet') that models the fovea and periphery to provide a proof-of-principle demonstration that computational object recognition can significantly benefit from the gist of the scene as contextual information. Our model yields accuracy improvements of up to 50% in certain object categories when incorporating contextual gist, while only increasing the original model size by 5%. This proposed model mirrors our intuition about how the human visual system recognizes objects, suggesting specific biologically plausible constraints to improve machine vision and building initial steps towards the challenge of scene understanding.

##### Abstract (translated by Google)
卷积神经网络（CNN）的进步已经取得了很大的进展，以实现多个对象识别任务的高性能水平。尽管一些方法利用来自整个场景的信息来提出兴趣区域，但解释特定区域或对象的任务仍然独立于图像中的其他对象和特征来执行。在这里，我们展示了一个场景的“要点”可以对人类如何识别物体做出重大贡献。这些发现与人类在物体上产生的信息以及从外围收集信息以帮助识别这一观点是一致的。我们使用生物启发的两部分卷积神经网络（'GistNet'）来模拟中心凹和周边，以提供原理证明，证明计算对象识别可以作为上下文信息从场景的要点中获益。我们的模型在合并上下文的要点时，可以在某些对象类别中提高多达50％的准确度，同时仅将原始模型大小增加5％。这个建议的模型反映了我们关于人类视觉系统如何识别物体的直觉，提出了改善机器视觉的具体生物学上合理的约束条件，并建立了对场景理解挑战的初始步骤。

##### URL
[http://arxiv.org/abs/1803.01967](http://arxiv.org/abs/1803.01967)

##### PDF
[http://arxiv.org/pdf/1803.01967](http://arxiv.org/pdf/1803.01967)

