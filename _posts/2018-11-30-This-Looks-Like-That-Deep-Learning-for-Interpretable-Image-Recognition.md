---
layout: post
title: "This Looks Like That: Deep Learning for Interpretable Image Recognition"
date: 2018-11-30 16:44:23
categories: arXiv_AI
tags: arXiv_AI Face Image_Classification Classification Deep_Learning Recognition
author: Chaofan Chen, Oscar Li, Chaofan Tao, Alina Barnett, Cynthia Rudin
mathjax: true
---

* content
{:toc}

##### Abstract
When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, geologists, architects, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training, meaning that there are no labels for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the CBIS-DDSM dataset. Our experiments show that our interpretable network can achieve comparable accuracy with its analogous standard non-interpretable counterpart as well as other interpretable deep models.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1806.10574](http://arxiv.org/abs/1806.10574)

##### PDF
[http://arxiv.org/pdf/1806.10574](http://arxiv.org/pdf/1806.10574)

