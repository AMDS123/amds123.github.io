---
layout: post
title: "Parametrized Deep Q-Networks Learning: Reinforcement Learning with Discrete-Continuous Hybrid Action Space"
date: 2018-10-10 07:38:44
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Jiechao Xiong, Qing Wang, Zhuoran Yang, Peng Sun, Lei Han, Yang Zheng, Haobo Fu, Tong Zhang, Ji Liu, Han Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Most existing deep reinforcement learning (DRL) frameworks consider either discrete action space or continuous action space solely. Motivated by applications in computer games, we consider the scenario with discrete-continuous hybrid action space. To handle hybrid action space, previous works either approximate the hybrid space by discretization, or relax it into a continuous set. In this paper, we propose a parametrized deep Q-network (P- DQN) framework for the hybrid action space without approximation or relaxation. Our algorithm combines the spirits of both DQN (dealing with discrete action space) and DDPG (dealing with continuous action space) by seamlessly integrating them. Empirical results on a simulation example, scoring a goal in simulated RoboCup soccer and the solo mode in game King of Glory (KOG) validate the efficiency and effectiveness of our method.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1810.06394](https://arxiv.org/abs/1810.06394)

##### PDF
[https://arxiv.org/pdf/1810.06394](https://arxiv.org/pdf/1810.06394)

