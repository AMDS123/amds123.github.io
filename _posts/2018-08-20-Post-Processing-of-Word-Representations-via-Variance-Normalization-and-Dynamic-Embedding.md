---
layout: post
title: "Post-Processing of Word Representations via Variance Normalization and Dynamic Embedding"
date: 2018-08-20 04:51:33
categories: arXiv_CL
tags: arXiv_CL Embedding Language_Model
author: Bin Wang, Fenxiao Chen, Angela Wang, C.-C. Jay Kuo
mathjax: true
---

* content
{:toc}

##### Abstract
Although embedded vector representations of words offer impressive performance on many natural language processing (NLP) applications, the information of ordered input sequences is lost to some extent if only context-based samples are used in the training. For further performance improvement, two new post-processing techniques, called post-processing via variance normalization (PVN) and post-processing via dynamic embedding (PDE), are proposed in this work. The PVN method normalizes the variance of principal components of word vectors while the PDE method learns orthogonal latent variables from ordered input sequences. The PVN and the PDE methods can be integrated to achieve better performance. We apply these post-processing techniques to two popular word embedding methods (i.e., word2vec and GloVe) to yield their post-processed representations. Extensive experiments are conducted to demonstrate the effectiveness of the proposed post-processing techniques.

##### Abstract (translated by Google)
虽然单词的嵌入向量表示在许多自然语言处理（NLP）应用程序上提供了令人印象深刻的性能，但是如果在训练中仅使用基于上下文的样本，则有序输入序列的信息在某种程度上会丢失。为了进一步提高性能，本文提出了两种新的后处理技术，称为通过方差归一化（PVN）的后处理和通过动态嵌入（PDE）的后处理。 PVN方法规范化单词向量的主成分的方差，而PDE方法从有序输入序列中学习正交潜在变量。可以集成PVN和PDE方法以实现更好的性能。我们将这些后处理技术应用于两种流行的字嵌入方法（即word2vec和GloVe）以产生它们的后处理表示。进行了大量实验以证明所提出的后处理技术的有效性。

##### URL
[http://arxiv.org/abs/1808.06305](http://arxiv.org/abs/1808.06305)

##### PDF
[http://arxiv.org/pdf/1808.06305](http://arxiv.org/pdf/1808.06305)

