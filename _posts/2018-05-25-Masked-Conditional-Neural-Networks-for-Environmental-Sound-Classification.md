---
layout: post
title: "Masked Conditional Neural Networks for Environmental Sound Classification"
date: 2018-05-25 07:02:38
categories: arXiv_SD
tags: arXiv_SD Sparse Embedding CNN Classification Recognition
author: Fady Medhat, David Chesmore, John Robinson
mathjax: true
---

* content
{:toc}

##### Abstract
The ConditionaL Neural Network (CLNN) exploits the nature of the temporal sequencing of the sound signal represented in a spectrogram, and its variant the Masked ConditionaL Neural Network (MCLNN) induces the network to learn in frequency bands by embedding a filterbank-like sparseness over the network's links using a binary mask. Additionally, the masking automates the exploration of different feature combinations concurrently analogous to handcrafting the optimum combination of features for a recognition task. We have evaluated the MCLNN performance using the Urbansound8k dataset of environmental sounds. Additionally, we present a collection of manually recorded sounds for rail and road traffic, YorNoise, to investigate the confusion rates among machine generated sounds possessing low-frequency components. MCLNN has achieved competitive results without augmentation and using 12% of the trainable parameters utilized by an equivalent model based on state-of-the-art Convolutional Neural Networks on the Urbansound8k. We extended the Urbansound8k dataset with YorNoise, where experiments have shown that common tonal properties affect the classification performance.

##### Abstract (translated by Google)
ConditionaL神经网络（CLNN）利用频谱图中表示的声音信号的时间序列的性质，其变体Masked ConditionaL神经网络（MCLNN）通过将类似滤波器组的稀疏性嵌入到频带中来诱导网络学习网络的链接使用二进制掩码。此外，掩蔽自动探索不同的特征组合，同时类似于手工识别任务的特征的最佳组合。我们使用Urbansound8k环境声音数据集评估了MCLNN的性能。此外，我们还为轨道和道路交通YorNoise提供手动录制的声音集合，以调查机器生成的声音中拥有低频分量的混淆率。 MCLNN在没有增强的情况下取得了有竞争力的成果，并且使用了基于Urbansound8k上现有技术的卷积神经网络的等效模型所使用的12％的可训练参数。我们使用YorNoise扩展了Urbansound8k数据集，实验表明常见的色调属性会影响分类性能。

##### URL
[http://arxiv.org/abs/1805.10004](http://arxiv.org/abs/1805.10004)

##### PDF
[http://arxiv.org/pdf/1805.10004](http://arxiv.org/pdf/1805.10004)

