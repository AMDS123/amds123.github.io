---
layout: post
title: "Integrating both Visual and Audio Cues for Enhanced Video Caption"
date: 2017-12-09 04:03:21
categories: arXiv_CV
tags: arXiv_CV Video_Caption Caption Inference
author: Wangli Hao, Zhaoxiang Zhang, He Guan, Guibo Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
Video caption refers to generating a descriptive sentence for a specific short video clip automatically, which has achieved remarkable success recently. However, most of the existing methods focus more on visual information while ignoring the synchronized audio cues. We propose three multimodal deep fusion strategies to maximize the benefits of visual-audio resonance information. The first one explores the impact on cross-modalities feature fusion from low to high order. The second establishes the visual-audio short-term dependency by sharing weights of corresponding front-end networks. The third extends the temporal dependency to long-term through sharing multimodal memory across visual and audio modalities. Extensive experiments have validated the effectiveness of our three cross-modalities fusion strategies on two benchmark datasets, including Microsoft Research Video to Text (MSRVTT) and Microsoft Video Description (MSVD). It is worth mentioning that sharing weight can coordinate visual-audio feature fusion effectively and achieve the state-of-art performance on both BELU and METEOR metrics. Furthermore, we first propose a dynamic multimodal feature fusion framework to deal with the part modalities missing case. Experimental results demonstrate that even in the audio absence mode, we can still obtain comparable results with the aid of the additional audio modality inference module.

##### Abstract (translated by Google)
视频标题是指自动生成特定短视频片段的描述性句子，最近取得了显着的成功。然而，大多数现有方法更多地关注视觉信息而忽略同步音频提示。我们提出三种多模式深度融合策略，以最大化视听共振信息的好处。第一个探讨了从低到高的顺序对交叉模态特征融合的影响。第二种是通过共享相应前端网络的权重来建立视觉 - 音频短期依赖性。第三种方法通过跨视觉和音频模式共享多模式记忆，将时间依赖性扩展到长期。大量实验验证了我们的三种跨模式融合策略在两个基准数据集上的有效性，包括Microsoft Research Video to Text（MSRVTT）和Microsoft Video Description（MSVD）。值得一提的是，共享权重可以有效地协调视觉 - 音频特征融合，并在BELU和METEOR指标上实现最先进的性能。此外，我们首先提出动态多模特征融合框架来处理缺少案​​例的部分模态。实验结果表明，即使在音频缺席模式下，我们仍然可以借助附加音频模态推理模块获得可比较的结果。

##### URL
[https://arxiv.org/abs/1711.08097](https://arxiv.org/abs/1711.08097)

##### PDF
[https://arxiv.org/e-print/1711.08097](https://arxiv.org/e-print/1711.08097)

