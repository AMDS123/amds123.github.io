---
layout: post
title: "Memory Fusion Network for Multi-view Sequential Learning"
date: 2018-02-03 06:37:46
categories: arXiv_AI
tags: arXiv_AI Attention RNN
author: Amir Zadeh, Paul Pu Liang, Navonil Mazumder, Soujanya Poria, Erik Cambria, Louis-Philippe Morency
mathjax: true
---

* content
{:toc}

##### Abstract
Multi-view sequential learning is a fundamental problem in machine learning dealing with multi-view sequences. In a multi-view sequence, there exists two forms of interactions between different views: view-specific interactions and cross-view interactions. In this paper, we present a new neural architecture for multi-view sequential learning called the Memory Fusion Network (MFN) that explicitly accounts for both interactions in a neural architecture and continuously models them through time. The first component of the MFN is called the System of LSTMs, where view-specific interactions are learned in isolation through assigning an LSTM function to each view. The cross-view interactions are then identified using a special attention mechanism called the Delta-memory Attention Network (DMAN) and summarized through time with a Multi-view Gated Memory. Through extensive experimentation, MFN is compared to various proposed approaches for multi-view sequential learning on multiple publicly available benchmark datasets. MFN outperforms all the existing multi-view approaches. Furthermore, MFN outperforms all current state-of-the-art models, setting new state-of-the-art results for these multi-view datasets.

##### Abstract (translated by Google)
多视点顺序学习是机器学习处理多视点序列的一个基本问题。在多视图序列中，不同视图之间存在两种形式的交互：特定于视图的交互和交叉视图交互。在本文中，我们提出了一种新的多视图顺序学习神经架构，称为内存融合网络（MFN），明确说明神经架构中的两种相互作用，并持续模拟它们。 MFN的第一个组成部分被称为LSTMs系统，通过为每个视图分配一个LSTM函数来独立学习视图特定的交互。然后使用称为增量记忆注意网络（DMAN）的特别关注机制来识别交叉视图交互，并通过多视图门控存储器进行总结。通过广泛的实验，将MFN与多种公开可用的基准数据集上的多视图顺序学习的各种提议的方法进行比较。最惠国待遇优于所有现有的多观点办法。此外，最惠国待遇优于目前所有最先进的模式，为这些多视角数据集设定了最新的最新成果。

##### URL
[http://arxiv.org/abs/1802.00927](http://arxiv.org/abs/1802.00927)

##### PDF
[http://arxiv.org/pdf/1802.00927](http://arxiv.org/pdf/1802.00927)

