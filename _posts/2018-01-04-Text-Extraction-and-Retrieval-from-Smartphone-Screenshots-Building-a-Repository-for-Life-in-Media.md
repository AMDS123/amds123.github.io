---
layout: post
title: "Text Extraction and Retrieval from Smartphone Screenshots: Building a Repository for Life in Media"
date: 2018-01-04 11:51:26
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval OCR GAN RNN Recognition
author: Agnese Chiatti, Mu Jung Cho, Anupriya Gagneja, Xiao Yang, Miriam Brinberg, Katie Roehrick, Sagnik Ray Choudhury, Nilam Ram, Byron Reeves, C. Lee Giles
mathjax: true
---

* content
{:toc}

##### Abstract
Daily engagement in life experiences is increasingly interwoven with mobile device use. Screen capture at the scale of seconds is being used in behavioral studies and to implement "just-in-time" health interventions. The increasing psychological breadth of digital information will continue to make the actual screens that people view a preferred if not required source of data about life experiences. Effective and efficient Information Extraction and Retrieval from digital screenshots is a crucial prerequisite to successful use of screen data. In this paper, we present the experimental workflow we exploited to: (i) pre-process a unique collection of screen captures, (ii) extract unstructured text embedded in the images, (iii) organize image text and metadata based on a structured schema, (iv) index the resulting document collection, and (v) allow for Image Retrieval through a dedicated vertical search engine application. The adopted procedure integrates different open source libraries for traditional image processing, Optical Character Recognition (OCR), and Image Retrieval. Our aim is to assess whether and how state-of-the-art methodologies can be applied to this novel data set. We show how combining OpenCV-based pre-processing modules with a Long short-term memory (LSTM) based release of Tesseract OCR, without ad hoc training, led to a 74% character-level accuracy of the extracted text. Further, we used the processed repository as baseline for a dedicated Image Retrieval system, for the immediate use and application for behavioral and prevention scientists. We discuss issues of Text Information Extraction and Retrieval that are particular to the screenshot image case and suggest important future work.

##### Abstract (translated by Google)
日常参与的生活体验越来越与移动设备的使用交织在一起。以秒为单位的屏幕截图正被用于行为研究，并实施“及时”的健康干预措施。数字信息越来越多的心理广度将继续使人们认为的实际屏幕成为人们如果不需要的关于人生体验的数据的首选来源。从数字屏幕截图中有效和高效的信息提取和检索是成功使用屏幕数据的关键先决条件。在本文中，我们展示了我们利用的实验工作流程：（i）预处理独特的屏幕捕捉集合，（ii）提取嵌入在图像中的非结构化文本，（iii）基于结构化模式组织图像文本和元数据，（iv）索引所得到的文件收集，以及（v）通过专用的垂直搜索引擎应用程序允许图像检索。采用的程序集成了用于传统图像处理，光学字符识别（OCR）和图像检索的不同开源库。我们的目标是评估是否以及如何将最先进的方法应用于这一新颖的数据集。我们展示了如何将基于OpenCV的预处理模块与基于长时间短记忆（LSTM）的Tesseract OCR版本相结合，而不需要特别的培训，从而提高了文本的74％字符级别的准确性。此外，我们使用处理后的存储库作为专用图像检索系统的基线，供行为和预防科学家立即使用和应用。我们讨论截屏图像案例特有的文本信息提取和检索问题，并提出重要的未来工作。

##### URL
[http://arxiv.org/abs/1801.01316](http://arxiv.org/abs/1801.01316)

##### PDF
[http://arxiv.org/pdf/1801.01316](http://arxiv.org/pdf/1801.01316)

