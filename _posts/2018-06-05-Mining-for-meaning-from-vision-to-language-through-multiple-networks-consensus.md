---
layout: post
title: "Mining for meaning: from vision to language through multiple networks consensus"
date: 2018-06-05 22:50:09
categories: arXiv_CV
tags: arXiv_CV
author: Iulia Duta, Andrei Liviu Nicolicioiu, Simion-Vlad Bogolin, Marius Leordeanu
mathjax: true
---

* content
{:toc}

##### Abstract
Describing visual data into natural language is a very challenging task, at the intersection of computer vision, natural language processing and machine learning. Language goes well beyond the description of physical objects and their interactions and can convey the same abstract idea in many ways. It is both about content at the highest semantic level as well as about fluent form. Here we propose an approach to describe videos in natural language by reaching a consensus among multiple encoder-decoder networks. Finding such a consensual linguistic description, which shares common properties with a larger group, has a better chance to convey the correct meaning. We propose and train several network architectures and use different types of image, audio and video features. Each model produces its own description of the input video and the best one is chosen through an efficient, two-phase consensus process. We demonstrate the strength of our approach by obtaining state of the art results on the challenging MSR-VTT dataset.

##### Abstract (translated by Google)
在计算机视觉，自然语言处理和机器学习的交叉处，将视觉数据描述为自然语言是一项非常具有挑战性的任务。语言远远超出物理对象及其相互作用的描述，并且可以通过多种方式传达相同的抽象概念。它既是关于最高语义层次的内容，也是关于流利形式的内容。在这里我们提出一种通过在多个编码器 - 解码器网络之间达成共识来描述自然语言视频的方法。找到这样一个共识性的语言学描述，它与一个更大的群体共享共同的属性，有更好的机会传达正确的意思。我们提出并培训几种网络架构，并使用不同类型的图像，音频和视频功能。每个模型都会生成自己对输入视频的描述，最好的模型是通过高效的两阶段共识流程来选择的。我们通过在具有挑战性的MSR-VTT数据集上获得最先进的结果来展示我们方法的优势。

##### URL
[http://arxiv.org/abs/1806.01954](http://arxiv.org/abs/1806.01954)

##### PDF
[http://arxiv.org/pdf/1806.01954](http://arxiv.org/pdf/1806.01954)

