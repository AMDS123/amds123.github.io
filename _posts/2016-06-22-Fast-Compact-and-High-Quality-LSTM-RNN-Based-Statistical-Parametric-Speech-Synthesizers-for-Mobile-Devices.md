---
layout: post
title: "Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices"
date: 2016-06-22 15:11:30
categories: arXiv_CL
tags: arXiv_CL Optimization Inference RNN
author: Heiga Zen, Yannis Agiomyrgiannakis, Niels Egberts, Fergus Henderson, Przemysław Szczepaniak
mathjax: true
---

* content
{:toc}

##### Abstract
Acoustic models based on long short-term memory recurrent neural networks (LSTM-RNNs) were applied to statistical parametric speech synthesis (SPSS) and showed significant improvements in naturalness and latency over those based on hidden Markov models (HMMs). This paper describes further optimizations of LSTM-RNN-based SPSS for deployment on mobile devices; weight quantization, multi-frame inference, and robust inference using an {\epsilon}-contaminated Gaussian loss function. Experimental results in subjective listening tests show that these optimizations can make LSTM-RNN-based SPSS comparable to HMM-based SPSS in runtime speed while maintaining naturalness. Evaluations between LSTM-RNN- based SPSS and HMM-driven unit selection speech synthesis are also presented.

##### Abstract (translated by Google)
基于长期短期记忆递归神经网络（LSTM-RNN）的声学模型被应用于统计参数语音合成（SPSS），并且在基于隐马尔可夫模型（HMM）的自然度和延迟方面显着改善。本文描述了进一步优化基于LSTM-RNN的SPSS以部署在移动设备上;加权量化，多帧推理以及使用经过信噪比的高斯损失函数的鲁棒推理。在主观听力测试中的实验结果表明，这些优化可以使基于LSTM-RNN的SPSS在运行速度上与基于HMM的SPSS相当，同时保持自然。也提出了基于LSTM-RNN的SPSS和HMM驱动的单元选择语音合成之间的评估。

##### URL
[https://arxiv.org/abs/1606.06061](https://arxiv.org/abs/1606.06061)

##### PDF
[https://arxiv.org/pdf/1606.06061](https://arxiv.org/pdf/1606.06061)

