---
layout: post
title: "Visual Wake Words Dataset"
date: 2019-06-12 17:47:21
categories: arXiv_CV
tags: arXiv_CV
author: Aakanksha Chowdhery, Pete Warden, Jonathon Shlens, Andrew Howard, Rocky Rhodes
mathjax: true
---

* content
{:toc}

##### Abstract
The emergence of Internet of Things (IoT) applications requires intelligence on the edge. Microcontrollers provide a low-cost compute platform to deploy intelligent IoT applications using machine learning at scale, but have extremely limited on-chip memory and compute capability. To deploy computer vision on such devices, we need tiny vision models that fit within a few hundred kilobytes of memory footprint in terms of peak usage and model size on device storage. To facilitate the development of microcontroller friendly models, we present a new dataset, Visual Wake Words, that represents a common microcontroller vision use-case of identifying whether a person is present in the image or not, and provides a realistic benchmark for tiny vision models. Within a limited memory footprint of 250 KB, several state-of-the-art mobile models achieve accuracy of 85-90% on the Visual Wake Words dataset. We anticipate the proposed dataset will advance the research on tiny vision models that can push the pareto-optimal boundary in terms of accuracy versus memory usage for microcontroller applications.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1906.05721](https://arxiv.org/abs/1906.05721)

##### PDF
[https://arxiv.org/pdf/1906.05721](https://arxiv.org/pdf/1906.05721)

