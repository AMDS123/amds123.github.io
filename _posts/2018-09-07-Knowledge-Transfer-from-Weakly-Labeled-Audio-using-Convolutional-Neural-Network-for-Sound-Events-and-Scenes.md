---
layout: post
title: "Knowledge Transfer from Weakly Labeled Audio using Convolutional Neural Network for Sound Events and Scenes"
date: 2018-09-07 05:22:27
categories: arXiv_SD
tags: arXiv_SD Knowledge CNN Transfer_Learning Classification Detection Relation
author: Anurag Kumar, Maksim Khadkevich, Christian Fugen
mathjax: true
---

* content
{:toc}

##### Abstract
In this work we propose approaches to effectively transfer knowledge from weakly labeled web audio data. We first describe a convolutional neural network (CNN) based framework for sound event detection and classification using weakly labeled audio data. Our model trains efficiently from audios of variable lengths; hence, it is well suited for transfer learning. We then propose methods to learn representations using this model which can be effectively used for solving the target task. We study both transductive and inductive transfer learning tasks, showing the effectiveness of our methods for both domain and task adaptation. We show that the learned representations using the proposed CNN model generalizes well enough to reach human level accuracy on ESC-50 sound events dataset and set state of art results on this dataset. We further use them for acoustic scene classification task and once again show that our proposed approaches suit well for this task as well. We also show that our methods are helpful in capturing semantic meanings and relations as well. Moreover, in this process we also set state-of-art results on Audioset dataset, relying on balanced training set.

##### Abstract (translated by Google)
在这项工作中，我们提出了从弱标签的网络音频数据中有效传递知识的方法。我们首先描述基于卷积神经网络（CNN）的框架，用于使用弱标记音频数据进行声音事件检测和分类。我们的模型从可变长度的音频中有效地训练;因此，它非常适合转学习。然后，我们提出了使用该模型学习表示的方法，该模型可以有效地用于解决目标任务。我们研究转导和归纳转移学习任务，显示我们的方法对领域和任务适应的有效性。我们展示了使用所提出的CNN模型的学习表示足以在ESC-50声音事件数据集上达到人类水平准确度并在该数据集上设置艺术状态结果。我们进一步将它们用于声学场景分类任务，并再次表明我们提出的方法也适合这项任务。我们还表明，我们的方法也有助于捕获语义和关系。此外，在此过程中，我们还在Audioset数据集上设置了最先进的结果，依赖于平衡训练集。

##### URL
[http://arxiv.org/abs/1711.01369](http://arxiv.org/abs/1711.01369)

##### PDF
[http://arxiv.org/pdf/1711.01369](http://arxiv.org/pdf/1711.01369)

