---
layout: post
title: "Differential Geometric Retrieval of Deep Features"
date: 2017-11-12 09:01:35
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Sparse CNN
author: Y Qian, E Vazquez, B Sengupta
mathjax: true
---

* content
{:toc}

##### Abstract
Comparing images to recommend items from an image-inventory is a subject of continued interest. Added with the scalability of deep-learning architectures the once `manual' job of hand-crafting features have been largely alleviated, and images can be compared according to features generated from a deep convolutional neural network. In this paper, we compare distance metrics (and divergences) to rank features generated from a neural network, for content-based image retrieval. Specifically, after modelling individual images using approximations of mixture models or sparse covariance estimators, we resort to their information-theoretic and Riemann geometric comparisons. We show that using approximations of mixture models enable us to compute a distance measure based on the Wasserstein metric that requires less effort than other computationally intensive optimal transport plans; finally, an affine invariant metric is used to compare the optimal transport metric to its Riemann geometric counterpart -- we conclude that although expensive, retrieval metric based on Wasserstein geometry is more suitable than information theoretic comparison of images. In short, we combine GPU scalability in learning deep feature vectors with statistically efficient metrics that we foresee being utilised in a commercial setting.

##### Abstract (translated by Google)
比较图像以从图像库存中推荐项目是持续兴趣的主题。除了深度学习架构的可扩展性之外，手工特征的“手动”工作大大减轻了，图像可以根据深度卷积神经网络产生的特征进行比较。在本文中，我们比较距离度量（和分歧），以对从神经网络生成的特征进行排名，以用于基于内容的图像检索。具体来说，在使用混合模型或稀疏协方差估计量的近似来对单个图像进行建模之后，我们使用它们的信息论和黎曼几何比较。我们表明，使用混合模型的近似使我们能够计算基于Wasserstein度量的距离度量，这需要比其他计算密集型最优运输计划更少的努力;最后，仿射不变量度量被用来比较最优传输度量和它的黎曼几何对应物 - 我们得出这样的结论：虽然昂贵，但基于Wasserstein几何的检索度量比信息理论比较更适合。简而言之，我们将GPU的可扩展性结合在学习深度特征向量中，同时我们预测在商业环境中可以使用统计有效的度量。

##### URL
[https://arxiv.org/abs/1702.06383](https://arxiv.org/abs/1702.06383)

##### PDF
[https://arxiv.org/pdf/1702.06383](https://arxiv.org/pdf/1702.06383)

