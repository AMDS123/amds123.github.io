---
layout: post
title: "Modeling AGI Safety Frameworks with Causal Influence Diagrams"
date: 2019-06-20 14:35:03
categories: arXiv_AI
tags: arXiv_AI Optimization
author: Tom Everitt, Ramana Kumar, Victoria Krakovna, Shane Legg
mathjax: true
---

* content
{:toc}

##### Abstract
Proposals for safe AGI systems are typically made at the level of frameworks, specifying how the components of the proposed system should be trained and interact with each other. In this paper, we model and compare the most promising AGI safety frameworks using causal influence diagrams. The diagrams show the optimization objective and causal assumptions of the framework. The unified representation permits easy comparison of frameworks and their assumptions. We hope that the diagrams will serve as an accessible and visual introduction to the main AGI safety frameworks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.08663](http://arxiv.org/abs/1906.08663)

##### PDF
[http://arxiv.org/pdf/1906.08663](http://arxiv.org/pdf/1906.08663)

