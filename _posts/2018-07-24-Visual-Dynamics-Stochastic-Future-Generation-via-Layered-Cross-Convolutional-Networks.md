---
layout: post
title: "Visual Dynamics: Stochastic Future Generation via Layered Cross Convolutional Networks"
date: 2018-07-24 17:28:31
categories: arXiv_AI
tags: arXiv_AI CNN
author: Tianfan Xue, Jiajun Wu, Katherine L. Bouman, William T. Freeman
mathjax: true
---

* content
{:toc}

##### Abstract
We study the problem of synthesizing a number of likely future frames from a single input image. In contrast to traditional methods that have tackled this problem in a deterministic or non-parametric way, we propose to model future frames in a probabilistic manner. Our probabilistic model makes it possible for us to sample and synthesize many possible future frames from a single input image. To synthesize realistic movement of objects, we propose a novel network structure, namely a Cross Convolutional Network; this network encodes image and motion information as feature maps and convolutional kernels, respectively. In experiments, our model performs well on synthetic data, such as 2D shapes and animated game sprites, and on real-world video frames. We present analyses of the learned network representations, showing it is implicitly learning a compact encoding of object appearance and motion. We also demonstrate a few of its applications, including visual analogy-making and video extrapolation.

##### Abstract (translated by Google)
我们研究了从单个输入图像合成许多可能的未来帧的问题。与以确定性或非参数方式解决该问题的传统方法相比，我们建议以概率方式对未来帧进行建模。我们的概率模型使我们可以从单个输入图像中采样和合成许多可能的未来帧。为了综合物体的真实运动，我们提出了一种新颖的网络结构，即交叉卷积网络;该网络分别将图像和运动信息编码为特征映射和卷积核。在实验中，我们的模型在合成数据上表现良好，例如2D形状和动画游戏精灵，以及真实世界的视频帧。我们提出了对所学习的网络表示的分析，表明它隐含地学习了对象外观和运动的紧凑编码。我们还展示了它的一些应用，包括视觉类比制作和视频外推。

##### URL
[https://arxiv.org/abs/1807.09245](https://arxiv.org/abs/1807.09245)

##### PDF
[https://arxiv.org/pdf/1807.09245](https://arxiv.org/pdf/1807.09245)

