---
layout: post
title: "Towards Robust Deep Neural Networks with BANG"
date: 2018-01-30 20:59:56
categories: arXiv_CV
tags: arXiv_CV Adversarial Classification
author: Andras Rozsa, Manuel Gunther, Terrance E. Boult
mathjax: true
---

* content
{:toc}

##### Abstract
Machine learning models, including state-of-the-art deep neural networks, are vulnerable to small perturbations that cause unexpected classification errors. This unexpected lack of robustness raises fundamental questions about their generalization properties and poses a serious concern for practical deployments. As such perturbations can remain imperceptible - the formed adversarial examples demonstrate an inherent inconsistency between vulnerable machine learning models and human perception - some prior work casts this problem as a security issue. Despite the significance of the discovered instabilities and ensuing research, their cause is not well understood and no effective method has been developed to address the problem. In this paper, we present a novel theory to explain why this unpleasant phenomenon exists in deep neural networks. Based on that theory, we introduce a simple, efficient, and effective training approach, Batch Adjusted Network Gradients (BANG), which significantly improves the robustness of machine learning models. While the BANG technique does not rely on any form of data augmentation or the utilization of adversarial images for training, the resultant classifiers are more resistant to adversarial perturbations while maintaining or even enhancing the overall classification performance.

##### Abstract (translated by Google)
机器学习模型（包括最先进的深度神经网络）容易受到导致意外分类错误的小扰动的影响。这种意想不到的鲁棒性提出了关于其泛化特性的基本问题，并且对实际部署提出了严重的关注。由于这样的扰动可能保持不可察觉 - 所形成的对抗性例子表明脆弱的机器学习模型和人类感知之间固有的不一致性 - 以前的一些工作把这个问题当作安全问题。尽管发现的不稳定性和随后的研究的意义，他们的原因还没有很好的理解，没有有效的方法来解决这个问题。在本文中，我们提出一个新的理论来解释为什么这个不愉快的现象存在于深度神经网络中。基于这一理论，我们引入了一种简单，高效，有效的训练方法 - 批调整网络梯度（BANG Adjusted Network Gradients，BANG），大大提高了机器学习模型的鲁棒性。尽管BANG技术不依赖于任何形式的数据增强或利用对抗图像进行训练，但所得到的分类器更能抵抗对抗性扰动，同时维持或甚至增强整体分类性能。

##### URL
[http://arxiv.org/abs/1612.00138](http://arxiv.org/abs/1612.00138)

##### PDF
[http://arxiv.org/pdf/1612.00138](http://arxiv.org/pdf/1612.00138)

