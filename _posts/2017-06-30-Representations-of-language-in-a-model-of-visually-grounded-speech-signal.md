---
layout: post
title: "Representations of language in a model of visually grounded speech signal"
date: 2017-06-30 07:34:55
categories: arXiv_SD
tags: arXiv_SD Knowledge
author: Grzegorz Chrupała, Lieke Gelderloos, Afra Alishahi
mathjax: true
---

* content
{:toc}

##### Abstract
We present a visually grounded model of speech perception which projects spoken utterances and images to a joint semantic space. We use a multi-layer recurrent highway network to model the temporal nature of spoken speech, and show that it learns to extract both form and meaning-based linguistic knowledge from the input signal. We carry out an in-depth analysis of the representations used by different components of the trained model and show that encoding of semantic aspects tends to become richer as we go up the hierarchy of layers, whereas encoding of form-related aspects of the language input tends to initially increase and then plateau or decrease.

##### Abstract (translated by Google)
我们提出了一个视觉基础的语音感知模型，将语言和图像投影到一个联合的语义空间。我们使用一个多层循环高速公路网络来模拟口语的时间性质，并表明它学习从输入信号中提取形式和基于意义的语言知识。我们深入分析了训练模型中不同组件所使用的表示，并且显示语义方面的编码随着我们走上层次层次而趋于变得更丰富，而语言输入的形式相关方面的编码趋于初始增加，然后升高或降低。

##### URL
[https://arxiv.org/abs/1702.01991](https://arxiv.org/abs/1702.01991)

##### PDF
[https://arxiv.org/pdf/1702.01991](https://arxiv.org/pdf/1702.01991)

