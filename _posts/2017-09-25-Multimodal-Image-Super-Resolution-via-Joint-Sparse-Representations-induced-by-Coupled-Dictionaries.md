---
layout: post
title: "Multimodal Image Super-Resolution via Joint Sparse Representations induced by Coupled Dictionaries"
date: 2017-09-25 19:04:08
categories: arXiv_CV
tags: arXiv_CV Super_Resolution Sparse
author: Pingfan Song (Student Member, IEEE), Xin Deng (Student Member, IEEE), João F. C. Mota (Member, IEEE), Nikos Deligiannis (Member, IEEE), Pier Luigi Dragotti (Fellow, IEEE), Miguel R. D. Rodrigues (Senior Member, IEEE)
mathjax: true
---

* content
{:toc}

##### Abstract
Real-world data processing problems often involve various image modalities associated with a certain scene, including RGB images, infrared images or multispectral images. The fact that different image modalities often share diverse attributes, such as certain edges, textures and other structure primitives, represents an opportunity to enhance various image processing tasks. This paper proposes a new approach to construct a high-resolution (HR) version of a low-resolution (LR) image given another HR image modality as reference, based on joint sparse representations induced by coupled dictionaries. Our approach, which captures the similarities and disparities between different image modalities in a learned sparse feature domain in lieu of the original image domain, consists of two phases. The coupled dictionary learning phase is used to learn a set of dictionaries that couple different image modalities in the sparse feature domain given a set of training data. In turn, the coupled super-resolution phase leverages such coupled dictionaries to construct a HR version of the LR target image given another related image modality. One of the merits of our sparsity-driven approach relates to the fact that it overcomes drawbacks such as the texture copying artifacts commonly resulting from inconsistency between the guidance and target images. Experiments on both synthetic data and real multimodal images demonstrate that incorporating appropriate guidance information via joint sparse representation induced by coupled dictionary learning brings notable benefits in the super-resolution task with respect to the state-of-the-art.

##### Abstract (translated by Google)
真实世界的数据处理问题通常涉及与特定场景相关的各种图像模态，包括RGB图像，红外图像或多光谱图像。事实上，不同的图像模态经常共享不同的属性，例如某些边缘，纹理和其他结构基元，这代表了增强各种图像处理任务的机会。本文提出了一种基于耦合字典引入的联合稀疏表示的方法来构建低分辨率（LR）图像的高分辨率（HR）版本，给出另一个HR图像模态作为参考。我们的方法捕捉了学习稀疏特征域中的不同图像模态之间的相似性和差异，而不是原始图像域，它由两个阶段组成。耦合的字典学习阶段用于学习一组字典，其在给定一组训练数据的情况下耦合稀疏特征域中的不同图像模态。接着，耦合的超分辨率阶段利用这种耦合的字典来构建LR目标图像的HR版本，给出另一相关图像模态。我们的稀疏驱动方法的优点之一涉及这样的事实：它克服了通常由于引导和目标图像之间的不一致而导致的纹理复制伪像的缺陷。对合成数据和真实多模态图像的实验证明，通过联合字典学习引入的联合稀疏表示合并适当的引导信息在超分辨率任务方面与现有技术相比带来显着的益处。

##### URL
[https://arxiv.org/abs/1709.08680](https://arxiv.org/abs/1709.08680)

##### PDF
[https://arxiv.org/pdf/1709.08680](https://arxiv.org/pdf/1709.08680)

