---
layout: post
title: "Joint Projection and Dictionary Learning using Low-rank Regularization and Graph Constraints"
date: 2016-12-06 00:08:19
categories: arXiv_CV
tags: arXiv_CV Regularization Image_Classification Classification
author: Homa Foroughi, Nilanjan Ray, Hong Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we aim at learning simultaneously a discriminative dictionary and a robust projection matrix from noisy data. The joint learning, makes the learned projection and dictionary a better fit for each other, so a more accurate classification can be obtained. However, current prevailing joint dimensionality reduction and dictionary learning methods, would fail when the training samples are noisy or heavily corrupted. To address this issue, we propose a joint projection and dictionary learning using low-rank regularization and graph constraints (JPDL-LR). Specifically, the discrimination of the dictionary is achieved by imposing Fisher criterion on the coding coefficients. In addition, our method explicitly encodes the local structure of data by incorporating a graph regularization term, that further improves the discriminative ability of the projection matrix. Inspired by recent advances of low-rank representation for removing outliers and noise, we enforce a low-rank constraint on sub-dictionaries of all classes to make them more compact and robust to noise. Experimental results on several benchmark datasets verify the effectiveness and robustness of our method for both dimensionality reduction and image classification, especially when the data contains considerable noise or variations.

##### Abstract (translated by Google)
在本文中，我们的目标是同时学习一个歧视字典和鲁棒的投影矩阵从嘈杂的数据。联合学习，使得学习的投影和字典更适合彼此，从而可以获得更准确的分类。然而，目前流行的联合降维和字典学习方法，当训练样本噪声或严重损坏时将失败。为了解决这个问题，我们提出了使用低秩正则化和图约束（JPDL-LR）的联合投影和字典学习。具体而言，字典的判别是通过对编码系数施加Fisher判据来实现的。另外，我们的方法通过结合图正则化项明确地编码数据的局部结构，进一步提高了投影矩阵的判别能力。受低级表示法去除异常值和噪声的最新进展的启发，我们对所有类别的子字典执行低级约束，使其对噪声更紧凑和更鲁棒。在几个基准数据集上的实验结果验证了我们的方法对降维和图像分类的有效性和鲁棒性，特别是当数据包含相当大的噪声或变化时。

##### URL
[https://arxiv.org/abs/1603.07697](https://arxiv.org/abs/1603.07697)

##### PDF
[https://arxiv.org/pdf/1603.07697](https://arxiv.org/pdf/1603.07697)

