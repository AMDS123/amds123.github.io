---
layout: post
title: "Learning to Interrupt: A Hierarchical Deep Reinforcement Learning Framework for Efficient Exploration"
date: 2018-07-30 02:39:10
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning
author: Tingguang Li, Jin Pan, Delong Zhu, Max Q.-H. Meng
mathjax: true
---

* content
{:toc}

##### Abstract
To achieve scenario intelligence, humans must transfer knowledge to robots by developing goal-oriented algorithms, which are sometimes insensitive to dynamically changing environments. While deep reinforcement learning achieves significant success recently, it is still extremely difficult to be deployed in real robots directly. In this paper, we propose a hybrid structure named Option-Interruption in which human knowledge is embedded into a hierarchical reinforcement learning framework. Our architecture has two key components: options, represented by existing human-designed methods, can significantly speed up the training process and interruption mechanism, based on learnable termination functions, enables our system to quickly respond to the external environment. To implement this architecture, we derive a set of update rules based on policy gradient methods and present a complete training process. In the experiment part, our method is evaluated in Four-room navigation and exploration task, which shows the efficiency and flexibility of our framework.

##### Abstract (translated by Google)
为了实现情景智能，人类必须通过开发面向目标的算法将知识传递给机器人，这些算法有时对动态变化的环境不敏感。虽然深度强化学习最近取得了重大成功，但直接在真实机器人中部署仍然非常困难。在本文中，我们提出了一种名为Option-Interruption的混合结构，其中人类知识被嵌入到分层强化学习框架中。我们的架构有两个关键组件：选项，由现有的人工设计方法代表，可以显着加快培训过程和中断机制，基于可学习的终止功能，使我们的系统能够快速响应外部环境。为了实现这种架构，我们基于策略梯度方法推导出一组更新规则，并提供完整的培训流程。在实验部分，我们的方法在四室导航和探索任务中进行了评估，显示了我们框架的效率和灵活性。

##### URL
[http://arxiv.org/abs/1807.11150](http://arxiv.org/abs/1807.11150)

##### PDF
[http://arxiv.org/pdf/1807.11150](http://arxiv.org/pdf/1807.11150)

