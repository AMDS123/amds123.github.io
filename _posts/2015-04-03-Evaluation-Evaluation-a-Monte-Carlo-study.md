---
layout: post
title: "Evaluation Evaluation a Monte Carlo study"
date: 2015-04-03 14:46:29
categories: arXiv_CL
tags: arXiv_CL Knowledge Relation
author: David M. W. Powers
mathjax: true
---

* content
{:toc}

##### Abstract
Over the last decade there has been increasing concern about the biases embodied in traditional evaluation methods for Natural Language Processing/Learning, particularly methods borrowed from Information Retrieval. Without knowledge of the Bias and Prevalence of the contingency being tested, or equivalently the expectation due to chance, the simple conditional probabilities Recall, Precision and Accuracy are not meaningful as evaluation measures, either individually or in combinations such as F-factor. The existence of bias in NLP measures leads to the 'improvement' of systems by increasing their bias, such as the practice of improving tagging and parsing scores by using most common value (e.g. water is always a Noun) rather than the attempting to discover the correct one. The measures Cohen Kappa and Powers Informedness are discussed as unbiased alternative to Recall and related to the psychologically significant measure DeltaP. In this paper we will analyze both biased and unbiased measures theoretically, characterizing the precise relationship between all these measures as well as evaluating the evaluation measures themselves empirically using a Monte Carlo simulation.

##### Abstract (translated by Google)
在过去十年中，人们越来越关注传统的自然语言处理/学习评估方法所体现的偏见，特别是从信息检索中借鉴的方法。如果不知道被测试偶然事件的偏倚和普遍程度，或者相当于偶然发生的期望，则简单的条件概率Recall，Precision和Accuracy作为评估测量，无论是单独还是组合如F因子都没有意义。 NLP测度中偏见的存在导致了系统的“改进”，例如通过使用最常见的价值（例如，水总是一个名词）来改进标记和解析分数的做法，而不是试图发现正确的一个。 Cohen Kappa和Powers Informedness的措施被作为Recall的无偏倚的替代方法进行讨论，并与心理上重要的DeltaP指标相关。在本文中，我们将从理论上分析偏倚和无偏倚的措施，描述所有这些措施之间的准确关系，以及使用蒙特卡洛模拟对经验性评估措施本身进行评估。

##### URL
[https://arxiv.org/abs/1504.00854](https://arxiv.org/abs/1504.00854)

##### PDF
[https://arxiv.org/pdf/1504.00854](https://arxiv.org/pdf/1504.00854)

