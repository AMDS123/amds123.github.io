---
layout: post
title: "VizWiz Grand Challenge: Answering Visual Questions from Blind People"
date: 2018-05-09 17:26:40
categories: arXiv_CV
tags: arXiv_CV QA VQA
author: Danna Gurari, Qing Li, Abigale J. Stangl, Anhong Guo, Chi Lin, Kristen Grauman, Jiebo Luo, Jeffrey P. Bigham
mathjax: true
---

* content
{:toc}

##### Abstract
The study of algorithms to automatically answer visual questions currently is motivated by visual question answering (VQA) datasets constructed in artificial VQA settings. We propose VizWiz, the first goal-oriented VQA dataset arising from a natural VQA setting. VizWiz consists of over 31,000 visual questions originating from blind people who each took a picture using a mobile phone and recorded a spoken question about it, together with 10 crowdsourced answers per visual question. VizWiz differs from the many existing VQA datasets because (1) images are captured by blind photographers and so are often poor quality, (2) questions are spoken and so are more conversational, and (3) often visual questions cannot be answered. Evaluation of modern algorithms for answering visual questions and deciding if a visual question is answerable reveals that VizWiz is a challenging dataset. We introduce this dataset to encourage a larger community to develop more generalized algorithms that can assist blind people.

##### Abstract (translated by Google)
目前通过在人工VQA设置中构建的视觉问答（VQA）数据集来激发对自动回答视觉问题的算法的研究。我们提出VizWiz，这是第一个面向目标的VQA数据集，源于自然的VQA设置。 VizWiz包含来自盲人的31,000多个视觉问题，每个人使用手机拍照并记录有关它的口头问题，每个视觉问题有10个众包答案。 VizWiz与许多现有的VQA数据集不同，因为（1）图像由盲人摄影师捕获，因此质量通常较差;（2）提出问题，因此更具会话性;（3）视觉问题通常无法回答。评估用于回答视觉问题和判断视觉问题是否可回答的现代算法表明VizWiz是具有挑战性的数据集。我们引入此数据集以鼓励更大的社区开发更多可以帮助盲人的通用算法。

##### URL
[https://arxiv.org/abs/1802.08218](https://arxiv.org/abs/1802.08218)

##### PDF
[https://arxiv.org/pdf/1802.08218](https://arxiv.org/pdf/1802.08218)

