---
layout: post
title: "Invariant feature extraction from event based stimuli"
date: 2016-06-21 04:38:31
categories: arXiv_CV
tags: arXiv_CV Object_Detection Classification Detection Recognition
author: Thusitha N. Chandrapala, Bertram E. Shi
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel architecture, the event-based GASSOM for learning and extracting invariant representations from event streams originating from neuromorphic vision sensors. The framework is inspired by feed-forward cortical models for visual processing. The model, which is based on the concepts of sparsity and temporal slowness, is able to learn feature extractors that resemble neurons in the primary visual cortex. Layers of units in the proposed model can be cascaded to learn feature extractors with different levels of complexity and selectivity. We explore the applicability of the framework on real world tasks by using the learned network for object recognition. The proposed model achieve higher classification accuracy compared to other state-of-the-art event based processing methods. Our results also demonstrate the generality and robustness of the method, as the recognizers for different data sets and different tasks all used the same set of learned feature detectors, which were trained on data collected independently of the testing data.

##### Abstract (translated by Google)
我们提出了一种新颖的架构，即基于事件的GASSOM，用于从源自神经形态视觉传感器的事件流中学习和提取不变表示。该框架的灵感来自前馈皮质模型的视觉处理。该模型基于稀疏性和暂时性迟缓的概念，能够学习与初级视觉皮层中的神经元类似的特征提取器。所提出的模型中的单元层可以级联来学习具有不同级别的复杂性和选择性的特征提取器。我们通过使用学习网络进行物体识别来探索框架在现实世界任务上的适用性。与其他先进的基于事件的处理方法相比，所提出的模型实现更高的分类准确度。我们的结果也证明了该方法的通用性和鲁棒性，因为不同数据集和不同任务的识别器都使用相同的学习特征检测器集合，这些特征检测器在独立于测试数据收集的数据上进行训练。

##### URL
[https://arxiv.org/abs/1604.04327](https://arxiv.org/abs/1604.04327)

##### PDF
[https://arxiv.org/pdf/1604.04327](https://arxiv.org/pdf/1604.04327)

