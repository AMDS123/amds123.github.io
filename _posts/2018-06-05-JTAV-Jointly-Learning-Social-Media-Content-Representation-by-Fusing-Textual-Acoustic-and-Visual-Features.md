---
layout: post
title: "JTAV: Jointly Learning Social Media Content Representation by Fusing Textual, Acoustic, and Visual Features"
date: 2018-06-05 03:50:50
categories: arXiv_CL
tags: arXiv_CL RNN Recommendation
author: Hongru Liang, Haozheng Wang, Jun Wang, Shaodi You, Zhe Sun, Jin-Mao Wei, Zhenglu Yang
mathjax: true
---

* content
{:toc}

##### Abstract
Learning social media content is the basis of many real-world applications, including information retrieval and recommendation systems, among others. In contrast with previous works that focus mainly on single modal or bi-modal learning, we propose to learn social media content by fusing jointly textual, acoustic, and visual information (JTAV). Effective strategies are proposed to extract fine-grained features of each modality, that is, attBiGRU and DCRNN. We also introduce cross-modal fusion and attentive pooling techniques to integrate multi-modal information comprehensively. Extensive experimental evaluation conducted on real-world datasets demonstrates our proposed model outperforms the state-of-the-art approaches by a large margin.

##### Abstract (translated by Google)
学习社交媒体内容是许多实际应用的基础，包括信息检索和推荐系统等。与之前主要关注单一模态或双模式学习的作品相比，我们建议通过融合文本，声音和视觉信息（JTAV）来学习社交媒体内容。提出了有效的策略来提取每种模式的细粒度特征，即attBiGRU和DCRNN。我们还引入了跨模式融合和细致的池化技术来全面整合多模态信息。对现实世界的数据集进行广泛的实验评估表明，我们提出的模型大大优于最先进的方法。

##### URL
[http://arxiv.org/abs/1806.01483](http://arxiv.org/abs/1806.01483)

##### PDF
[http://arxiv.org/pdf/1806.01483](http://arxiv.org/pdf/1806.01483)

