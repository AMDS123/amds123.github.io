---
layout: post
title: "Path Evaluation via HMM on Semantical Occupancy Grid Maps"
date: 2018-05-08 11:02:02
categories: arXiv_RO
tags: arXiv_RO Segmentation
author: Timo Korthals, Julian Exner, Thomas Sch&#xf6;pping, Marc Hesse
mathjax: true
---

* content
{:toc}

##### Abstract
Traditional approaches to mapping of environments in robotics make use of spatially discretized representations, such as occupancy grid maps. Modern systems, e.g. in agriculture or automotive applications, are equipped with a variety of different sensors to gather diverse process-relevant modalities from the environment. The amount of data and its associated semantic information demand for broader data structures and frameworks, like semantical occupancy grid maps (SOGMs). This multi-modal representation also calls for novel methods of path planning. Due to the sequential nature of path planning as a consecutive execution of tasks and their ability to handle multi-modal data as provided by SOGMs, Markovian models, such as Hidden Markov Models (HMM) or Partially Observable Markov Decision Processes, are applicable. Furthermore, for these techniques to be applied effectively and efficiently, data from SOGMs must be extracted and refined. Superpixel algorithms, originating from computer vision, provide a method to de-noise and re-express SOGMs in an alternative representation. This publication explores and extends the use of superpixel segmentation as a post-processing step and applies Markovian models for path decoding on SOGMs.

##### Abstract (translated by Google)
传统的机器人环境映射方法利用空间离散化表示，例如占用网格地图。现代系统，例如在农业或汽车应用中，都配备了各种不同的传感器，以收集来自环境的各种与过程相关的模式。数据量及其相关语义信息需要更广泛的数据结构和框架，如语义占用网格图（SOGM）。这种多模态表示还需要新的路径规划方法。由于路径规划作为连续执行任务的顺序特性，以及SOGM提供的处理多模式数据的能力，因此可应用马尔可夫模型（如隐马尔可夫模型（HMM）或部分可观察马尔可夫决策过程）。此外，为了有效和高效地应用这些技术，必须提取和优化来自SOGM的数据。源自计算机视觉的超像素算法提供了一种方法去除噪声并且以替代表示重新表达SOGM。本出版物探讨并扩展了超像素分割的使用作为后处理步骤，并将马尔可夫模型应用于SOGM上的路径解码。

##### URL
[http://arxiv.org/abs/1805.02944](http://arxiv.org/abs/1805.02944)

##### PDF
[http://arxiv.org/pdf/1805.02944](http://arxiv.org/pdf/1805.02944)

