---
layout: post
title: "Cross-Paced Representation Learning with Partial Curricula for Sketch-based Image Retrieval"
date: 2018-03-05 05:30:08
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Knowledge Represenation_Learning
author: Dan Xu, Xavier Alameda-Pineda, Jingkuan Song, Elisa Ricci, Nicu Sebe
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we address the problem of learning robust cross-domain representations for sketch-based image retrieval (SBIR). While most SBIR approaches focus on extracting low- and mid-level descriptors for direct feature matching, recent works have shown the benefit of learning coupled feature representations to describe data from two related sources. However, cross-domain representation learning methods are typically cast into non-convex minimization problems that are difficult to optimize, leading to unsatisfactory performance. Inspired by self-paced learning, a learning methodology designed to overcome convergence issues related to local optima by exploiting the samples in a meaningful order (i.e. easy to hard), we introduce the cross-paced partial curriculum learning (CPPCL) framework. Compared with existing self-paced learning methods which only consider a single modality and cannot deal with prior knowledge, CPPCL is specifically designed to assess the learning pace by jointly handling data from dual sources and modality-specific prior information provided in the form of partial curricula. Additionally, thanks to the learned dictionaries, we demonstrate that the proposed CPPCL embeds robust coupled representations for SBIR. Our approach is extensively evaluated on four publicly available datasets (i.e. CUFS, Flickr15K, QueenMary SBIR and TU-Berlin Extension datasets), showing superior performance over competing SBIR methods.

##### Abstract (translated by Google)
在本文中，我们解决了基于草图的图像检索（SBIR）学习鲁棒跨域表示的问题。虽然大多数SBIR方法专注于提取用于直接特征匹配的低级和中级描述符，但近期的研究表明学习耦合特征表示来描述来自两个相关来源的数据的好处。然而，跨领域表示学习方法通​​常投射到难以优化的非凸最小化问题中，导致不令人满意的性能。受到自主学习的启发，我们设计了一种学习方法，旨在通过以有意义的顺序（即容易到难）开发样本来解决与局部最优化有关的收敛问题，我们引入了跨节奏的部分课程学习（CPPCL）框架。与仅考虑单一形式并且不能处理先前知识的现有自学步式学习方法相比，CPPCL专门设计用于通过联合处理来自双重来源的数据和以部分课程形式提供的特定于模式的先前信息来评估学习速度。此外，由于学习字典，我们证明了所提出的CPPCL嵌入了SBIR的鲁棒耦合表示。我们的方法在四个公开可用的数据集（即CUFS，Flickr15K，QueenMary SBIR和TU-Berlin扩展数据集）上进行了广泛评估，显示出优于竞争SBIR方法的优越性能。

##### URL
[http://arxiv.org/abs/1803.01504](http://arxiv.org/abs/1803.01504)

##### PDF
[http://arxiv.org/pdf/1803.01504](http://arxiv.org/pdf/1803.01504)

