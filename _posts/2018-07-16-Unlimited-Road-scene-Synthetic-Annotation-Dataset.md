---
layout: post
title: "Unlimited Road-scene Synthetic Annotation Dataset"
date: 2018-07-16 18:45:49
categories: arXiv_CV
tags: arXiv_CV Segmentation Semantic_Segmentation Quantitative
author: Matt Angus, Mohamed ElBalkini, Samin Khan, Ali Harakeh, Oles Andrienko, Cody Reading, Steven Waslander, Krzysztof Czarnecki
mathjax: true
---

* content
{:toc}

##### Abstract
In training deep neural networks for semantic segmentation, the main limiting factor is the low amount of ground truth annotation data that is available in currently existing datasets. The limited availability of such data is due to the time cost and human effort required to accurately and consistently label real images on a pixel level. Modern sandbox video game engines provide open world environments where traffic and pedestrians behave in a pseudo-realistic manner. This caters well to the collection of a believable road-scene dataset. Utilizing open-source tools and resources found in single-player modding communities, we provide a method for persistent, ground truth, asset annotation of a game world. By collecting a synthetic dataset containing upwards of $1,000,000$ images, we demonstrate real-time, on-demand, ground truth data annotation capability of our method. Supplementing this synthetic data to Cityscapes dataset, we show that our data generation method provides qualitative as well as quantitative improvements---for training networks---over previous methods that use video games as surrogate.

##### Abstract (translated by Google)
在训练深度神经网络进行语义分割时，主要限制因素是当前现有数据集中可用的地面实况注释数据量较少。这种数据的有限可用性是由于在像素级上准确且一致地标记真实图像所需的时间成本和人力。现代沙箱视频游戏引擎提供开放的世界环境，其中交通和行人以伪现实的方式表现。这非常适合收集可信的道路场景数据集。利用单人模拟社区中的开源工具和资源，我们提供了一种持久的，真实的，游戏世界的资产注释方法。通过收集包含超过$ 1,000,000 $图像的合成数据集，我们展示了我们方法的实时，按需，地面实况数据注释功能。将这些合成数据补充到Cityscapes数据集中，我们表明我们的数据生成方法提供了定性和定量的改进 - 用于训练网络 - 超过以前使用视频游戏作为替代的方法。

##### URL
[http://arxiv.org/abs/1807.06056](http://arxiv.org/abs/1807.06056)

##### PDF
[http://arxiv.org/pdf/1807.06056](http://arxiv.org/pdf/1807.06056)

