---
layout: post
title: "State Representation Learning for Control: An Overview"
date: 2018-02-12 16:53:48
categories: arXiv_AI
tags: arXiv_AI Review Reinforcement_Learning Survey Represenation_Learning
author: Timoth&#xe9;e Lesort, Natalia D&#xed;az-Rodr&#xed;guez, Jean-Fran&#xe7;ois Goudou, David Filliat
mathjax: true
---

* content
{:toc}

##### Abstract
Representation learning algorithms are designed to learn abstract features that characterize data. State representation learning (SRL) focuses on a particular kind of representation learning where learned features are in low dimension, evolve through time, and are influenced by actions of an agent. As the representation learned captures the variation in the environment generated by agents, this kind of representation is particularly suitable for robotics and control scenarios. In particular, the low dimension helps to overcome the curse of dimensionality, provides easier interpretation and utilization by humans and can help improve performance and speed in policy learning algorithms such as reinforcement learning. 
 This survey aims at covering the state-of-the-art on state representation learning in the most recent years. It reviews different SRL methods that involve interaction with the environment, their implementations and their applications in robotics control tasks (simulated or real). In particular, it highlights how generic learning objectives are differently exploited in the reviewed algorithms. Finally, it discusses evaluation methods to assess the representation learned and summarizes current and future lines of research.

##### Abstract (translated by Google)
表示学习算法旨在学习表征数据的抽象特征。状态表征学习（SRL）侧重于特定类型的表征学习，其中学习特征处于低维度，随时间推移并受到代理人行为的影响。由于所学的表示捕获了由代理生成的环境变化，这种表示特别适用于机器人和控制场景。特别是，低维度有助于克服维度的诅咒，提供人类更容易的解释和利用，并有助于提高策略学习算法（如强化学习）中的性能和速度。
 本调查旨在涵盖最近几年国家代表性学习的最新状况。它回顾了不同的SRL方法，涉及与环境的交互，它们的实现以及它们在机器人控制任务（模拟或真实）中的应用。特别是，它强调了在所评估的算法中泛型学习目标如何被不同地利用。最后，它讨论评估所学知识的评估方法，并总结当前和未来的研究路线。

##### URL
[http://arxiv.org/abs/1802.04181](http://arxiv.org/abs/1802.04181)

##### PDF
[http://arxiv.org/pdf/1802.04181](http://arxiv.org/pdf/1802.04181)

