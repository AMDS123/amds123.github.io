---
layout: post
title: "Consistent Alignment of Word Embedding Models"
date: 2017-02-24 17:40:28
categories: arXiv_SD
tags: arXiv_SD Embedding Relation
author: Cem Safak Sahin, Rajmonda S. Caceres, Brandon Oselio, William M. Campbell
mathjax: true
---

* content
{:toc}

##### Abstract
Word embedding models offer continuous vector representations that can capture rich contextual semantics based on their word co-occurrence patterns. While these word vectors can provide very effective features used in many NLP tasks such as clustering similar words and inferring learning relationships, many challenges and open research questions remain. In this paper, we propose a solution that aligns variations of the same model (or different models) in a joint low-dimensional latent space leveraging carefully generated synthetic data points. This generative process is inspired by the observation that a variety of linguistic relationships is captured by simple linear operations in embedded space. We demonstrate that our approach can lead to substantial improvements in recovering embeddings of local neighborhoods.

##### Abstract (translated by Google)
字嵌入模型提供了连续的矢量表示，可以捕获丰富的上下文语义基于他们的单词共现模式。虽然这些单词向量可以提供许多NLP任务中使用的非常有效的特征，例如对类似词汇进行聚类并推断学习关系，但仍然存在许多挑战和开放的研究问题。在本文中，我们提出了一种解决方案，该方案利用仔细生成的合成数据点在相关的低维空间中调整相同模型（或不同模型）的变化。这种生成过程受到以下观察的启发：在嵌入式空间中通过简单的线性操作捕捉各种语言关系。我们证明，我们的方法可以导致恢复当地社区的嵌入的实质性改进。

##### URL
[https://arxiv.org/abs/1702.07680](https://arxiv.org/abs/1702.07680)

##### PDF
[https://arxiv.org/pdf/1702.07680](https://arxiv.org/pdf/1702.07680)

