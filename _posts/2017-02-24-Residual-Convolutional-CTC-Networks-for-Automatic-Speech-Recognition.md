---
layout: post
title: "Residual Convolutional CTC Networks for Automatic Speech Recognition"
date: 2017-02-24 22:49:13
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition CNN Classification Deep_Learning Recognition
author: Yisen Wang, Xuejiao Deng, Songbai Pu, Zhiheng Huang
mathjax: true
---

* content
{:toc}

##### Abstract
Deep learning approaches have been widely used in Automatic Speech Recognition (ASR) and they have achieved a significant accuracy improvement. Especially, Convolutional Neural Networks (CNNs) have been revisited in ASR recently. However, most CNNs used in existing work have less than 10 layers which may not be deep enough to capture all human speech signal information. In this paper, we propose a novel deep and wide CNN architecture denoted as RCNN-CTC, which has residual connections and Connectionist Temporal Classification (CTC) loss function. RCNN-CTC is an end-to-end system which can exploit temporal and spectral structures of speech signals simultaneously. Furthermore, we introduce a CTC-based system combination, which is different from the conventional frame-wise senone-based one. The basic subsystems adopted in the combination are different types and thus mutually complementary to each other. Experimental results show that our proposed single system RCNN-CTC can achieve the lowest word error rate (WER) on WSJ and Tencent Chat data sets, compared to several widely used neural network systems in ASR. In addition, the proposed system combination can offer a further error reduction on these two data sets, resulting in relative WER reductions of $14.91\%$ and $6.52\%$ on WSJ dev93 and Tencent Chat data sets respectively.

##### Abstract (translated by Google)
深度学习方法已被广泛应用于自动语音识别（ASR）中，并且已经实现了显着的准确度提高。特别是卷积神经网络（CNN）近来在ASR中被重新研究。然而，现有工作中使用的大多数CNN只有不到10层，不足以捕获所有人类语音信号信息。在本文中，我们提出了一种新的深层CNN架构，表示为RCNN-CTC，它具有剩余连接和连接时间分类（CTC）损失函数。 RCNN-CTC是一个端到端的系统，可以同时利用语音信号的时间和频谱结构。此外，我们介绍一个基于CTC的系统组合，这是不同于传统的逐帧语音系统组合。组合中采用的基本子系统是不同类型的，因此相互补充。实验结果表明，与ASR中广泛使用的神经网络系统相比，我们提出的单个系统RCNN-CTC可以在WSJ和腾讯聊天数据集上达到最低的误码率（WER）。另外，所提出的系统组合可以在这两个数据集上进一步降低误差，从而分别在WSJ dev93和腾讯聊天数据集上分别减少$ 14.91 \％$和$ 6.52 \％$。

##### URL
[https://arxiv.org/abs/1702.07793](https://arxiv.org/abs/1702.07793)

##### PDF
[https://arxiv.org/pdf/1702.07793](https://arxiv.org/pdf/1702.07793)

