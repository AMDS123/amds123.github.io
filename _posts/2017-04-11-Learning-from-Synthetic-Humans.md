---
layout: post
title: "Learning from Synthetic Humans"
date: 2017-04-11 14:24:17
categories: arXiv_CV
tags: arXiv_CV Segmentation Pose_Estimation CNN
author: Gül Varol, Javier Romero, Xavier Martin, Naureen Mahmood, Michael J. Black, Ivan Laptev, Cordelia Schmid
mathjax: true
---

* content
{:toc}

##### Abstract
Estimating human pose, shape, and motion from images and videos are fundamental challenges with many applications. Recent advances in 2D human pose estimation use large amounts of manually-labeled training data for learning convolutional neural networks (CNNs). Such data is time consuming to acquire and difficult to extend. Moreover, manual labeling of 3D pose, depth and motion is impractical. In this work we present SURREAL (Synthetic hUmans foR REAL tasks): a new large-scale dataset with synthetically-generated but realistic images of people rendered from 3D sequences of human motion capture data. We generate more than 6 million frames together with ground truth pose, depth maps, and segmentation masks. We show that CNNs trained on our synthetic dataset allow for accurate human depth estimation and human part segmentation in real RGB images. Our results and the new dataset open up new possibilities for advancing person analysis using cheap and large-scale synthetic data.

##### Abstract (translated by Google)
根据图像和视频估计人体姿势，形状和运动是许多应用程序的基本挑战。 2D人体姿态估计的最新进展使用大量手动标记的训练数据来学习卷积神经网络（CNN）。这样的数据耗费时间，难以扩展。而且，3D姿势，深度和运动的手动标记是不切实际的。在这项工作中，我们展示了SURREAL（真实任务的合成hUmans）：一个新的大规模数据集合人造运动捕捉数据的3D序列渲染的人的合成生成的图像。我们与地面真实姿势，深度图和分割蒙版一起生成了600多万个帧。我们表明，我们的合成数据集训练CNNs允许准确的人体深度估计和真实的RGB图像中的人体部分分割。我们的研究结果和新的数据集为利用廉价和大规模合成数据推进人员分析开辟了新的可能性。

##### URL
[https://arxiv.org/abs/1701.01370](https://arxiv.org/abs/1701.01370)

##### PDF
[https://arxiv.org/pdf/1701.01370](https://arxiv.org/pdf/1701.01370)

