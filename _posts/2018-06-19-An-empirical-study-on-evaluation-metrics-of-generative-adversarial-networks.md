---
layout: post
title: "An empirical study on evaluation metrics of generative adversarial networks"
date: 2018-06-19 14:01:27
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Qiantong Xu, Gao Huang, Yang Yuan, Chuan Guo, Yu Sun, Felix Wu, Kilian Weinberger
mathjax: true
---

* content
{:toc}

##### Abstract
Evaluating generative adversarial networks (GANs) is inherently challenging. In this paper, we revisit several representative sample-based evaluation metrics for GANs, and address the problem of how to evaluate the evaluation metrics. We start with a few necessary conditions for metrics to produce meaningful scores, such as distinguishing real from generated samples, identifying mode dropping and mode collapsing, and detecting overfitting. With a series of carefully designed experiments, we comprehensively investigate existing sample-based metrics and identify their strengths and limitations in practical settings. Based on these results, we observe that kernel Maximum Mean Discrepancy (MMD) and the 1-Nearest-Neighbor (1-NN) two-sample test seem to satisfy most of the desirable properties, provided that the distances between samples are computed in a suitable feature space. Our experiments also unveil interesting properties about the behavior of several popular GAN models, such as whether they are memorizing training samples, and how far they are from learning the target distribution.

##### Abstract (translated by Google)
评估生成对抗网络（GAN）固有地具有挑战性。在本文中，我们重新审视了几个有代表性的基于样本的GAN评估指标，并解决了如何评估评估指标的问题。我们从一些必要的条件开始，以产生有意义的分数，例如区分实际与生成的样本，识别模式下降和模式崩溃，以及检测过度拟合。通过一系列精心设计的实验，我们全面调查现有的基于样本的度量标准，并在实际环境中确定其优势和局限性。基于这些结果，我们观察到，核心最大平均差异（MMD）和1-最近邻（1-NN）双样本测试似乎满足大多数理想的属性，只要样本之间的距离是以适合的特征空间。我们的实验还揭示了几个流行的GAN模型的行为的有趣属性，例如他们是否记忆训练样本，以及他们从学习目标分布到多远。

##### URL
[http://arxiv.org/abs/1806.07755](http://arxiv.org/abs/1806.07755)

##### PDF
[http://arxiv.org/pdf/1806.07755](http://arxiv.org/pdf/1806.07755)

