---
layout: post
title: "How2: A Large-scale Dataset for Multimodal Language Understanding"
date: 2018-11-01 12:47:11
categories: arXiv_CL
tags: arXiv_CL Summarization Speech_Recognition Recognition
author: Ramon Sanabria, Ozan Caglayan, Shruti Palaskar, Desmond Elliott, Lo&#xef;c Barrault, Lucia Specia, Florian Metze
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we introduce How2, a multimodal collection of instructional videos with English subtitles and crowdsourced Portuguese translations. We also present integrated sequence-to-sequence baselines for machine translation, automatic speech recognition, spoken language translation, and multimodal summarization. By making available data and code for several multimodal natural language tasks, we hope to stimulate more research on these and similar challenges, to obtain a deeper understanding of multimodality in language processing.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.00347](http://arxiv.org/abs/1811.00347)

##### PDF
[http://arxiv.org/pdf/1811.00347](http://arxiv.org/pdf/1811.00347)

