---
layout: post
title: "Improving LSTM-CTC based ASR performance in domains with limited training data"
date: 2018-05-23 15:26:14
categories: arXiv_CL
tags: arXiv_CL Regularization Speech_Recognition RNN Classification Recognition
author: Jayadev Billa
mathjax: true
---

* content
{:toc}

##### Abstract
This paper addresses the observed performance gap between automatic speech recognition (ASR) systems based on Long Short Term Memory (LSTM) neural networks trained with the connectionist temporal classification (CTC) loss function and systems based on hybrid Deep Neural Networks (DNNs) trained with the cross entropy (CE) loss function on domains with limited data. We step through a number of experiments that show incremental improvements on a baseline EESEN toolkit based LSTM-CTC ASR system trained on the Librispeech 100hr (train-clean-100) corpus. Our results show that with effective combination of data augmentation and regularization, a LSTM-CTC based system can exceed the performance of a strong Kaldi based baseline trained on the same data.

##### Abstract (translated by Google)
本文讨论了基于长时短期记忆（LSTM）神经网络的自动语音识别（ASR）系统与连接主义时间分类（CTC）损失函数训练和基于混合深度神经网络（DNN）训练的系统之间观察到的性能差距数据有限的域上的交叉熵（CE）损失函数。我们逐步进行了一些实验，对基于EESEN工具包的基于LBSM-CTC ASR系统的基线进行了逐步改进，该系统在Librispeech 100hr（train-clean-100）语料库上接受培训。我们的研究结果表明，通过数据增强和正则化的有效结合，基于LSTM-CTC的系统可以超过基于相同数据训练的强基于Kaldi的基线的性能。

##### URL
[http://arxiv.org/abs/1707.00722](http://arxiv.org/abs/1707.00722)

##### PDF
[http://arxiv.org/pdf/1707.00722](http://arxiv.org/pdf/1707.00722)

