---
layout: post
title: "Clustering-Oriented Representation Learning with Attractive-Repulsive Loss"
date: 2018-12-18 20:07:56
categories: arXiv_AI
tags: arXiv_AI CNN Represenation_Learning Classification
author: Kian Kenyon-Dean, Andre Cianflone, Lucas Page-Caccia, Guillaume Rabusseau, Jackie Chi Kit Cheung, Doina Precup
mathjax: true
---

* content
{:toc}

##### Abstract
The standard loss function used to train neural network classifiers, categorical cross-entropy (CCE), seeks to maximize accuracy on the training data; building useful representations is not a necessary byproduct of this objective. In this work, we propose clustering-oriented representation learning (COREL) as an alternative to CCE in the context of a generalized attractive-repulsive loss framework. COREL has the consequence of building latent representations that collectively exhibit the quality of natural clustering within the latent space of the final hidden layer, according to a predefined similarity function. Despite being simple to implement, COREL variants outperform or perform equivalently to CCE in a variety of scenarios, including image and news article classification using both feed-forward and convolutional neural networks. Analysis of the latent spaces created with different similarity functions facilitates insights on the different use cases COREL variants can satisfy, where the Cosine-COREL variant makes a consistently clusterable latent space, while Gaussian-COREL consistently obtains better classification accuracy than CCE.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.07627](http://arxiv.org/abs/1812.07627)

##### PDF
[http://arxiv.org/pdf/1812.07627](http://arxiv.org/pdf/1812.07627)

