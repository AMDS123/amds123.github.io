---
layout: post
title: "Prune the Convolutional Neural Networks with Sparse Shrink"
date: 2017-08-08 10:28:20
categories: arXiv_CV
tags: arXiv_CV Sparse CNN
author: Xin Li, Changsong Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Nowadays, it is still difficult to adapt Convolutional Neural Network (CNN) based models for deployment on embedded devices. The heavy computation and large memory footprint of CNN models become the main burden in real application. In this paper, we propose a "Sparse Shrink" algorithm to prune an existing CNN model. By analyzing the importance of each channel via sparse reconstruction, the algorithm is able to prune redundant feature maps accordingly. The resulting pruned model thus directly saves computational resource. We have evaluated our algorithm on CIFAR-100. As shown in our experiments, we can reduce 56.77% parameters and 73.84% multiplication in total with only minor decrease in accuracy. These results have demonstrated the effectiveness of our "Sparse Shrink" algorithm.

##### Abstract (translated by Google)
目前，基于卷积神经网络（CNN）的模型在嵌入式设备上的部署仍然很困难。 CNN模型的计算量大，内存占用大，成为实际应用中的主要负担。在本文中，我们提出了“稀疏收缩”算法来修剪现有的CNN模型。通过稀疏重构分析每个信道的重要性，该算法能够相应地修剪冗余特征图。由此产生的修剪模型因此直接节省了计算资源。我们已经在CIFAR-100上评估了我们的算法。正如我们的实验所显示的，我们可以减少56.77％的参数和73.84％的总体乘法，只有很小的精度下降。这些结果已经证明了我们的“稀疏收缩”算法的有效性。

##### URL
[https://arxiv.org/abs/1708.02439](https://arxiv.org/abs/1708.02439)

##### PDF
[https://arxiv.org/pdf/1708.02439](https://arxiv.org/pdf/1708.02439)

