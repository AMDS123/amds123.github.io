---
layout: post
title: "Deep Attentional Structured Representation Learning for Visual Recognition"
date: 2018-05-14 19:13:16
categories: arXiv_CV
tags: arXiv_CV Attention Represenation_Learning Recognition
author: Krishna Kanth Nakka, Mathieu Salzmann
mathjax: true
---

* content
{:toc}

##### Abstract
Structured representations, such as Bags of Words, VLAD and Fisher Vectors, have proven highly effective to tackle complex visual recognition tasks. As such, they have recently been incorporated into deep architectures. However, while effective, the resulting deep structured representation learning strategies typically aggregate local features from the entire image, ignoring the fact that, in complex recognition tasks, some regions provide much more discriminative information than others. 
 In this paper, we introduce an attentional structured representation learning framework that incorporates an image-specific attention mechanism within the aggregation process. Our framework learns to predict jointly the image class label and an attention map in an end-to-end fashion and without any other supervision than the target label. As evidenced by our experiments, this consistently outperforms attention-less structured representation learning and yields state-of-the-art results on standard scene recognition and fine-grained categorization benchmarks.

##### Abstract (translated by Google)
结构化表示，例如字袋，VLAD和Fisher矢量，已经证明对于处理复杂的视觉识别任务非常有效。因此，他们最近已被纳入深层架构。然而，虽然有效，但由此产生的深层结构表示学习策略通常会聚集整个图像的局部特征，而忽略了这样一个事实：在复杂的识别任务中，某些区域比其他区域提供更多的区分性信息。
 在本文中，我们引入了注意结构化表示学习框架，该框架在聚合过程中结合了图像特定关注机制。我们的框架学习以端对端的方式联合预测图像类标签和注意图，并且除目标标签外没有任何其他监督。正如我们的实验所证明的那样，这一贯地超越了无关注结构的表示学习，并在标准场景识别和细粒度分类基准测试中获得了最先进的结果。

##### URL
[http://arxiv.org/abs/1805.05389](http://arxiv.org/abs/1805.05389)

##### PDF
[http://arxiv.org/pdf/1805.05389](http://arxiv.org/pdf/1805.05389)

