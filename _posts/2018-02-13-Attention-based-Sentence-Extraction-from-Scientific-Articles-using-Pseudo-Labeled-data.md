---
layout: post
title: "Attention based Sentence Extraction from Scientific Articles using Pseudo-Labeled data"
date: 2018-02-13 15:13:28
categories: arXiv_AI
tags: arXiv_AI Attention Weakly_Supervised Embedding RNN Deep_Learning
author: Parth Mehta, Gaurav Arora, Prasenjit Majumder
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we present a weakly supervised sentence extraction technique for identifying important sentences in scientific papers that are worthy of inclusion in the abstract. We propose a new attention based deep learning architecture that jointly learns to identify important content, as well as the cue phrases that are indicative of summary worthy sentences. We propose a new context embedding technique for determining the focus of a given paper using topic models and use it jointly with an LSTM based sequence encoder to learn attention weights across the sentence words. We use a collection of articles publicly available through ACL anthology for our experiments. Our system achieves a performance that is better, in terms of several ROUGE metrics, as compared to several state of art extractive techniques. It also generates more coherent summaries and preserves the overall structure of the document.

##### Abstract (translated by Google)
在这项工作中，我们提出了一个弱监督的句子提取技术，用于识别科学论文中重要的句子，这些文章值得收录在摘要中。我们提出了一种新的基于注意力的深度学习体系结构，它共同学习识别重要内容，以及指示总结性值得的句子的提示短语。我们提出了一种新的上下文嵌入技术，用于使用主题模型来确定给定论文的焦点，并将其与基于LSTM的序列编码器一起使用以学习整个句子单词的注意力权重。我们使用一系列通过ACL文选公开获得的文章进行实验。与几种最先进的提取技术相比，我们的系统在几个ROUGE指标方面实现了更好的性能。它还生成更一致的摘要并保留文档的整体结构。

##### URL
[http://arxiv.org/abs/1802.04675](http://arxiv.org/abs/1802.04675)

##### PDF
[http://arxiv.org/pdf/1802.04675](http://arxiv.org/pdf/1802.04675)

