---
layout: post
title: "Measuring and modeling the perception of natural and unconstrained gaze in humans and machines"
date: 2016-11-29 20:11:09
categories: arXiv_CV
tags: arXiv_CV Attention Face
author: Daniel Harari, Tao Gao, Nancy Kanwisher, Joshua Tenenbaum, Shimon Ullman
mathjax: true
---

* content
{:toc}

##### Abstract
Humans are remarkably adept at interpreting the gaze direction of other individuals in their surroundings. This skill is at the core of the ability to engage in joint visual attention, which is essential for establishing social interactions. How accurate are humans in determining the gaze direction of others in lifelike scenes, when they can move their heads and eyes freely, and what are the sources of information for the underlying perceptual processes? These questions pose a challenge from both empirical and computational perspectives, due to the complexity of the visual input in real-life situations. Here we measure empirically human accuracy in perceiving the gaze direction of others in lifelike scenes, and study computationally the sources of information and representations underlying this cognitive capacity. We show that humans perform better in face-to-face conditions compared with recorded conditions, and that this advantage is not due to the availability of input dynamics. We further show that humans are still performing well when only the eyes-region is visible, rather than the whole face. We develop a computational model, which replicates the pattern of human performance, including the finding that the eyes-region contains on its own, the required information for estimating both head orientation and direction of gaze. Consistent with neurophysiological findings on task-specific face regions in the brain, the learned computational representations reproduce perceptual effects such as the Wollaston illusion, when trained to estimate direction of gaze, but not when trained to recognize objects or faces.

##### Abstract (translated by Google)
人类非常善于解释周围其他人的注视方向。这项技能是参与联合视觉注意力的核心，这对建立社交互动至关重要。人类在栩栩如生的场景中确定他人注视方向的准确程度，何时可以自由移动头部和眼睛，以及底层知觉过程的信息来源有多少？由于实际情况下的视觉输入的复杂性，这些问题从经验和计算的角度来看都是一个挑战。在这里，我们用实验的方法来测量人类在栩栩如生场景中观察别人的注视方向的准确性，并计算研究这种认知能力背后的信息来源和表征。我们证明，与记录的条件相比，人类在面对面的情况下表现更好，而且这种优势不是由于输入动态的可用性。我们进一步表明，只有眼睛可见时，人类仍然表现良好，而不是整个脸部。我们开发了一个计算模型，它复制人类的表现模式，包括眼睛区域包含它自己的发现，估计头部方向和注视方向所需的信息。与大脑中特定于任务的人脸区域的神经生理学发现相一致，所学习的计算表示再现了感知效果，例如沃拉斯顿（Wollaston）错觉，当被训练用于估计注视方向时，而不是被训练成识别物体或面部时。

##### URL
[https://arxiv.org/abs/1611.09819](https://arxiv.org/abs/1611.09819)

##### PDF
[https://arxiv.org/pdf/1611.09819](https://arxiv.org/pdf/1611.09819)

