---
layout: post
title: "Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs"
date: 2019-05-03 10:09:09
categories: arXiv_AI
tags: arXiv_AI Image_Retrieval Knowledge_Graph Knowledge Embedding CNN Prediction Relation
author: Daniel O&#xf1;oro-Rubio, Mathias Niepert, Alberto Garc&#xed;a-Dur&#xe1;n, Roberto Gonz&#xe1;lez, Roberto J. L&#xf3;pez-Sastre
mathjax: true
---

* content
{:toc}

##### Abstract
A visual-relational knowledge graph (KG) is a multi-relational graph whose entities are associated with images. We explore novel machine learning approaches for answering visual-relational queries in web-extracted knowledge graphs. To this end, we have created ImageGraph, a KG with 1,330 relation types, 14,870 entities, and 829,931 images crawled from the web. With visual-relational KGs such as ImageGraph one can introduce novel probabilistic query types in which images are treated as first-class citizens. Both the prediction of relations between unseen images as well as multi-relational image retrieval can be expressed with specific families of visual-relational queries. We introduce novel combinations of convolutional networks and knowledge graph embedding methods to answer such queries. We also explore a zero-shot learning scenario where an image of an entirely new entity is linked with multiple relations to entities of an existing KG. The resulting multi-relational grounding of unseen entity images into a knowledge graph serves as a semantic entity representation. We conduct experiments to demonstrate that the proposed methods can answer these visual-relational queries efficiently and accurately.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1709.02314](http://arxiv.org/abs/1709.02314)

##### PDF
[http://arxiv.org/pdf/1709.02314](http://arxiv.org/pdf/1709.02314)

