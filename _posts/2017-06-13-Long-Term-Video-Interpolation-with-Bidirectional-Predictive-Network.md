---
layout: post
title: "Long-Term Video Interpolation with Bidirectional Predictive Network"
date: 2017-06-13 08:15:32
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Xiongtao Chen, Wenmin Wang, Jinzhuo Wang, Weimian Li, Baoyang Chen
mathjax: true
---

* content
{:toc}

##### Abstract
This paper considers the challenging task of long-term video interpolation. Unlike most existing methods that only generate few intermediate frames between existing adjacent ones, we attempt to speculate or imagine the procedure of an episode and further generate multiple frames between two non-consecutive frames in videos. In this paper, we present a novel deep architecture called bidirectional predictive network (BiPN) that predicts intermediate frames from two opposite directions. The bidirectional architecture allows the model to learn scene transformation with time as well as generate longer video sequences. Besides, our model can be extended to predict multiple possible procedures by sampling different noise vectors. A joint loss composed of clues in image and feature spaces and adversarial loss is designed to train our model. We demonstrate the advantages of BiPN on two benchmarks Moving 2D Shapes and UCF101 and report competitive results to recent approaches.

##### Abstract (translated by Google)
本文考虑长期视频插值的挑战性任务。与大多数现有的仅在现有相邻帧之间产生少量中间帧的方法不同，我们试图推测或想象一个片段的过程，并进一步在视频中的两个非连续帧之间产生多个帧。在本文中，我们提出了一种称为双向预测网络（BiPN）的新型深层体系结构，预测来自两个相反方向的中间帧。双向架构允许模型随时间学习场景转换，并生成更长的视频序列。此外，我们的模型可以扩展到预测多个可能的程序，通过采样不同的噪声向量。图像和特征空间的线索组成的联合损失和对抗性损失被设计为训练我们的模型。我们展示BiPN在两个基准移动2D形状和UCF101的优势，并报告竞争的结果，以最近的办法。

##### URL
[https://arxiv.org/abs/1706.03947](https://arxiv.org/abs/1706.03947)

##### PDF
[https://arxiv.org/pdf/1706.03947](https://arxiv.org/pdf/1706.03947)

