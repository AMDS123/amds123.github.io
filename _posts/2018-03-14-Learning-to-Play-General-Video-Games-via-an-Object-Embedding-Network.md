---
layout: post
title: "Learning to Play General Video-Games via an Object Embedding Network"
date: 2018-03-14 13:26:44
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Embedding
author: William Woof, Ke Chen
mathjax: true
---

* content
{:toc}

##### Abstract
Deep reinforcement learning (DRL) has proven to be an effective tool for creating general video-game AI. However most current DRL video-game agents learn end-to-end from the video-output of the game, which is superfluous for many applications and creates a number of additional problems. More importantly, directly working on pixel-based raw video data is substantially distinct from what a human player does.In this paper, we present a novel method which enables DRL agents to learn directly from object information. This is obtained via use of an object embedding network (OEN) that compresses a set of object feature vectors of different lengths into a single fixed-length unified feature vector representing the current game-state and fulfills the DRL simultaneously. We evaluate our OEN-based DRL agent by comparing to several state-of-the-art approaches on a selection of games from the GVG-AI Competition. Experimental results suggest that our object-based DRL agent yields performance comparable to that of those approaches used in our comparative study.

##### Abstract (translated by Google)
深度强化学习（DRL）已被证明是创建一般视频游戏AI的有效工具。然而，大多数当前的DRL视频游戏代理从游戏的视频输出端到端地学习，这对于许多应用来说是多余的，并且产生了许多额外的问题。更重要的是，直接处理基于像素的原始视频数据与人类玩家的作用截然不同。在本文中，我们提出了一种使DRL代理可以直接从对象信息中学习的新方法。这是通过使用将不同长度的一组对象特征向量压缩成代表当前游戏状态并同时满足DRL的单个固定长度统一特征向量的对象嵌入网络（OEN）获得的。我们通过比较GVG-AI竞赛中选择的几种最先进的方法来评估我们基于OEN的DRL代理。实验结果表明我们的基于对象的DRL代理产生的性能可与我们比较研究中使用的方法相媲美。

##### URL
[https://arxiv.org/abs/1803.05262](https://arxiv.org/abs/1803.05262)

##### PDF
[https://arxiv.org/pdf/1803.05262](https://arxiv.org/pdf/1803.05262)

