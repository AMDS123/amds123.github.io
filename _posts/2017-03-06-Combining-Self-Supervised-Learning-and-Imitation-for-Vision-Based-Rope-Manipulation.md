---
layout: post
title: "Combining Self-Supervised Learning and Imitation for Vision-Based Rope Manipulation"
date: 2017-03-06 18:40:29
categories: arXiv_CV
tags: arXiv_CV
author: Ashvin Nair, Dian Chen, Pulkit Agrawal, Phillip Isola, Pieter Abbeel, Jitendra Malik, Sergey Levine
mathjax: true
---

* content
{:toc}

##### Abstract
Manipulation of deformable objects, such as ropes and cloth, is an important but challenging problem in robotics. We present a learning-based system where a robot takes as input a sequence of images of a human manipulating a rope from an initial to goal configuration, and outputs a sequence of actions that can reproduce the human demonstration, using only monocular images as input. To perform this task, the robot learns a pixel-level inverse dynamics model of rope manipulation directly from images in a self-supervised manner, using about 60K interactions with the rope collected autonomously by the robot. The human demonstration provides a high-level plan of what to do and the low-level inverse model is used to execute the plan. We show that by combining the high and low-level plans, the robot can successfully manipulate a rope into a variety of target shapes using only a sequence of human-provided images for direction.

##### Abstract (translated by Google)
对诸如绳索和布等可变形物体的操纵是机器人技术中一个重要而又具有挑战性的问题。我们提出了一个基于学习的系统，其中一个机器人从一个初始的目标配置中输入一个人操纵绳索的图像序列，并且输出一系列能够再现人类演示的动作，仅使用单目图像作为输入。为了执行这个任务，机器人通过与机器人自主收集的绳索的约60K的相互作用，以自监督的方式直接从图像学习绳索操纵的像素级逆动力学模型。人类示范提供了一个高层次的计划，使用低级逆模型来执行计划。我们证明，通过结合高层和低层计划，机器人可以成功地使用人工提供的图像序列来操纵绳索成各种目标形状。

##### URL
[https://arxiv.org/abs/1703.02018](https://arxiv.org/abs/1703.02018)

##### PDF
[https://arxiv.org/pdf/1703.02018](https://arxiv.org/pdf/1703.02018)

