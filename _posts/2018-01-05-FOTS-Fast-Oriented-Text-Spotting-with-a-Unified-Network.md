---
layout: post
title: "FOTS: Fast Oriented Text Spotting with a Unified Network"
date: 2018-01-05 08:41:57
categories: arXiv_CV
tags: arXiv_CV CNN Detection Recognition
author: Xuebo Liu, Ding Liang, Shi Yan, Dagui Chen, Yu Qiao, Junjie Yan
mathjax: true
---

* content
{:toc}

##### Abstract
Incidental scene text spotting is considered one of the most difficult and valuable challenges in the document analysis community. Most existing methods treat text detection and recognition as separate tasks. In this work, we propose a unified end-to-end trainable Fast Oriented Text Spotting (FOTS) network for simultaneous detection and recognition, sharing computation and visual information among the two complementary tasks. Specially, RoIRotate is introduced to share convolutional features between detection and recognition. Benefiting from convolution sharing strategy, our FOTS has little computation overhead compared to baseline text detection network, and the joint training method learns more generic features to make our method perform better than these two-stage methods. Experiments on ICDAR 2015, ICDAR 2017 MLT, and ICDAR 2013 datasets demonstrate that the proposed method outperforms state-of-the-art methods significantly, which further allows us to develop the first real-time oriented text spotting system which surpasses all previous state-of-the-art results by more than 5% on ICDAR 2015 text spotting task while keeping 22.6 fps.

##### Abstract (translated by Google)
附带的场景文本识别被认为是文档分析社区中最困难和最有价值的挑战之一。大多数现有的方法将文本检测和识别视为单独的任务。在这项工作中，我们提出了一个统一的端到端可训练的快速定向文本识别（FOTS）网络，用于同时检测和识别，在两个相辅相成的任务中共享计算和视觉信息。特别地，引入了RoIRotate来共享检测和识别之间的卷积特征。受益于卷积共享策略，与基线文本检测网络相比，我们的FOTS计算开销较小，联合训练方法学习到更多的通用特征，使得我们的方法比这两个阶段的方法表现更好。在ICDAR 2015，ICDAR 2017 MLT和ICDAR 2013数据集上的实验表明，所提出的方法显着优于最先进的方法，这进一步使我们能够开发出首个实时导向的文本识别系统，在ICDAR 2015文本识别任务中保持了22.6 fps的超过5％的最新结果。

##### URL
[http://arxiv.org/abs/1801.01671](http://arxiv.org/abs/1801.01671)

##### PDF
[http://arxiv.org/pdf/1801.01671](http://arxiv.org/pdf/1801.01671)

