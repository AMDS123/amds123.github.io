---
layout: post
title: "A Dataset and Architecture for Visual Reasoning with a Working Memory"
date: 2018-07-20 14:12:49
categories: arXiv_CV
tags: arXiv_CV QA Deep_Learning VQA
author: Guangyu Robert Yang, Igor Ganichev, Xiao-Jing Wang, Jonathon Shlens, David Sussillo
mathjax: true
---

* content
{:toc}

##### Abstract
A vexing problem in artificial intelligence is reasoning about events that occur in complex, changing visual stimuli such as in video analysis or game play. Inspired by a rich tradition of visual reasoning and memory in cognitive psychology and neuroscience, we developed an artificial, configurable visual question and answer dataset (COG) to parallel experiments in humans and animals. COG is much simpler than the general problem of video analysis, yet it addresses many of the problems relating to visual and logical reasoning and memory -- problems that remain challenging for modern deep learning architectures. We additionally propose a deep learning architecture that performs competitively on other diagnostic VQA datasets (i.e. CLEVR) as well as easy settings of the COG dataset. However, several settings of COG result in datasets that are progressively more challenging to learn. After training, the network can zero-shot generalize to many new tasks. Preliminary analyses of the network architectures trained on COG demonstrate that the network accomplishes the task in a manner interpretable to humans.

##### Abstract (translated by Google)
人工智能中一个棘手的问题是推理复杂的，变化的视觉刺激中发生的事件，例如视频分析或游戏。受到认知心理学和神经科学中丰富的视觉推理和记忆传统的启发，我们开发了一种人工的，可配置的视觉问答数据集（COG），用于人类和动物的平行实验。 COG比视频分析的一般问题简单得多，但它解决了许多与视觉和逻辑推理和记忆相关的问题 - 这些问题对于现代深度学习架构仍然具有挑战性。我们还提出了一种深度学习架构，可以在其他诊断VQA数据集（即CLEVR）上进行竞争，并且可以轻松设置COG数据集。但是，COG的一些设置会导致逐渐更难学习的数据集。经过培训，网络可以零射击推广到许多新任务。对在COG上训练的网络架构的初步分析表明，网络以可以向人类解释的方式完成任务。

##### URL
[https://arxiv.org/abs/1803.06092](https://arxiv.org/abs/1803.06092)

##### PDF
[https://arxiv.org/pdf/1803.06092](https://arxiv.org/pdf/1803.06092)

