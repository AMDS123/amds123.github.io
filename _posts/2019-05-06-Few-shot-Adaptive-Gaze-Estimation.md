---
layout: post
title: "Few-shot Adaptive Gaze Estimation"
date: 2019-05-06 11:48:39
categories: arXiv_CV
tags: arXiv_CV
author: Seonwook Park, Shalini De Mello, Pavlo Molchanov, Umar Iqbal, Otmar Hilliges, Jan Kautz
mathjax: true
---

* content
{:toc}

##### Abstract
Inter-personal anatomical differences limit the accuracy of person-independent gaze estimation networks. Yet there is a need to lower gaze errors further to enable applications requiring higher quality. Further gains can be achieved by personalizing gaze networks, ideally with few calibration samples. However, over-parameterized neural networks are not amenable to learning from few examples as they can quickly over-fit. We embrace these challenges and propose a novel framework for Few-shot Adaptive GaZE Estimation (FAZE) for learning person-specific gaze networks with very few (less than 9) calibration samples. FAZE learns a rotation-aware latent representation of gaze via a disentangling encoder-decoder architecture along with a highly adaptable gaze estimator trained using meta-learning. It is capable of adapting to any new person to yield significant performance gains with as few as 3 samples, yielding state-of-the-art performance of 3.18-deg on GazeCapture, a 19% improvement over prior art.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.01941](http://arxiv.org/abs/1905.01941)

##### PDF
[http://arxiv.org/pdf/1905.01941](http://arxiv.org/pdf/1905.01941)

