---
layout: post
title: "Multi-lingual Intent Detection and Slot Filling in a Joint BERT-based Model"
date: 2019-07-05 15:11:29
categories: arXiv_CL
tags: arXiv_CL Attention Text_Classification Classification Deep_Learning Detection
author: Giuseppe Castellucci, Valentina Bellomaria, Andrea Favalli, Raniero Romagnoli
mathjax: true
---

* content
{:toc}

##### Abstract
Intent Detection and Slot Filling are two pillar tasks in Spoken Natural Language Understanding. Common approaches adopt joint Deep Learning architectures in attention-based recurrent frameworks. In this work, we aim at exploiting the success of "recurrence-less" models for these tasks. We introduce Bert-Joint, i.e., a multi-lingual joint text classification and sequence labeling framework. The experimental evaluation over two well-known English benchmarks demonstrates the strong performances that can be obtained with this model, even when few annotated data is available. Moreover, we annotated a new dataset for the Italian language, and we observed similar performances without the need for changing the model.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.02884](http://arxiv.org/abs/1907.02884)

##### PDF
[http://arxiv.org/pdf/1907.02884](http://arxiv.org/pdf/1907.02884)

