---
layout: post
title: "Generating Videos with Scene Dynamics"
date: 2016-10-26 13:58:10
categories: arXiv_CV
tags: arXiv_CV Adversarial Video_Caption CNN Represenation_Learning Classification Prediction Recognition
author: Carl Vondrick, Hamed Pirsiavash, Antonio Torralba
mathjax: true
---

* content
{:toc}

##### Abstract
We capitalize on large amounts of unlabeled video in order to learn a model of scene dynamics for both video recognition tasks (e.g. action classification) and video generation tasks (e.g. future prediction). We propose a generative adversarial network for video with a spatio-temporal convolutional architecture that untangles the scene's foreground from the background. Experiments suggest this model can generate tiny videos up to a second at full frame rate better than simple baselines, and we show its utility at predicting plausible futures of static images. Moreover, experiments and visualizations show the model internally learns useful features for recognizing actions with minimal supervision, suggesting scene dynamics are a promising signal for representation learning. We believe generative video models can impact many applications in video understanding and simulation.

##### Abstract (translated by Google)
为了学习视频识别任务（例如动作分类）和视频生成任务（例如未来预测）的场景动态模型，我们利用大量的未标记视频。我们提出了一个生成视频对抗网络与时空卷积架构，从背景解开场景的前景。实验表明，这种模式可以在全帧速率下生成比简单的基线更多的微小视频，并且我们在预测静态图像的合理期待方面显示出它的实用性。此外，实验和可视化表明，模型在内部学习有用的功能，用最小的监督来识别动作，表明场景动态是表示学习的有希望的信号。我们相信生成视频模型可以影响视频理解和模拟的许多应用。

##### URL
[https://arxiv.org/abs/1609.02612](https://arxiv.org/abs/1609.02612)

##### PDF
[https://arxiv.org/pdf/1609.02612](https://arxiv.org/pdf/1609.02612)

