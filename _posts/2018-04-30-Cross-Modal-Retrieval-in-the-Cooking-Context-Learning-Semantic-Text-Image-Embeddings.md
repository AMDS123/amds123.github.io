---
layout: post
title: "Cross-Modal Retrieval in the Cooking Context: Learning Semantic Text-Image Embeddings"
date: 2018-04-30 12:14:32
categories: arXiv_AI
tags: arXiv_AI Embedding
author: Micael Carvalho, Rémi Cadène, David Picard, Laure Soulier, Nicolas Thome, Matthieu Cord
mathjax: true
---

* content
{:toc}

##### Abstract
Designing powerful tools that support cooking activities has rapidly gained popularity due to the massive amounts of available data, as well as recent advances in machine learning that are capable of analyzing them. In this paper, we propose a cross-modal retrieval model aligning visual and textual data (like pictures of dishes and their recipes) in a shared representation space. We describe an effective learning scheme, capable of tackling large-scale problems, and validate it on the Recipe1M dataset containing nearly 1 million picture-recipe pairs. We show the effectiveness of our approach regarding previous state-of-the-art models and present qualitative results over computational cooking use cases.

##### Abstract (translated by Google)
由于大量的可用数据以及能够分析它们的机器学习的最新进展，设计支持烹饪活动的强大工具已迅速流行起来。在本文中，我们提出了一个跨模态检索模型，在共享表示空间中对齐视觉和文本数据（如菜肴图片和食谱）。我们描述了一个有效的学习方案，能够解决大规模问题，并在包含近100万个图片配方对的Recipe1M数据集上进行验证。我们展示了我们的方法对先前的最新模型的有效性，并在计算烹饪用例上呈现定性结果。

##### URL
[https://arxiv.org/abs/1804.11146](https://arxiv.org/abs/1804.11146)

##### PDF
[https://arxiv.org/pdf/1804.11146](https://arxiv.org/pdf/1804.11146)

