---
layout: post
title: "Simulation Study on a New Peer Review Approach"
date: 2018-06-11 23:34:59
categories: arXiv_AI
tags: arXiv_AI Review
author: Albert Steppi, Jinchan Qu, Minjing Tao, Tingting Zhao, Xiaodong Pang, Jinfeng Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
The increasing volume of scientific publications and grant proposals has generated an unprecedentedly high workload to scientific communities. Consequently, review quality has been decreasing and review outcomes have become less correlated with the real merits of the papers and proposals. A novel distributed peer review (DPR) approach has recently been proposed to address these issues. The new approach assigns principal investigators (PIs) who submitted proposals (or papers) to the same program as reviewers. Each PI reviews and ranks a small number (such as seven) of other PIs' proposals. The individual rankings are then used to estimate a global ranking of all proposals using the Modified Borda Count (MBC). In this study, we perform simulation studies to investigate several parameters important for the decision making when adopting this new approach. We also propose a new method called Concordance Index-based Global Ranking (CIGR) to estimate global ranking from individual rankings. An efficient simulated annealing algorithm is designed to search the optimal Concordance Index (CI). Moreover, we design a new balanced review assignment procedure, which can result in significantly better performance for both MBC and CIGR methods. We found that CIGR performs better than MBC when the review quality is relatively high. As review quality and review difficulty are tightly correlated, we constructed a boundary in the space of review quality vs review difficulty that separates the CIGR-superior and MBC-superior regions. Finally, we propose a multi-stage DPR strategy based on CIGR, which has the potential to substantially improve the overall review performance while reducing the review workload.

##### Abstract (translated by Google)
科学出版物和赠款提案数量的增加为科学界带来了前所未有的高工作量。因此，审查质量一直在下降，审查结果与论文和提案的实际价值之间的关联性降低。最近提出了一种新型的分布式同行评议（DPR）方法来解决这些问题。新方法将主要研究人员（PI）委派给同一计划的评审人员（或论文）。每个效绩指标审核并排列少数（如7个）其他效绩指标的提案。然后使用个人排名来估算所有使用修正博达计数（MBC）的提案的全球排名。在这项研究中，我们进行模拟研究，以调查采用这种新方法时决策制定的重要参数。我们还提出了一种称为基于协调指数的全球排名（CIGR）的新方法，用于根据个人排名估算全球排名。设计了一种有效的模拟退火算法来搜索最优的一致性指数（CI）。此外，我们设计了一种新的平衡评审分配程序，可以为MBC和CIGR方法带来明显更好的性能。我们发现，当审查质量相对较高时，CIGR的绩效优于MBC。由于评审质量和评审难度紧密相关，我们在评审质量与评审CIGR优先和MBC优先区域的难度之间建立了界限。最后，我们提出了一个基于CIGR的多阶段DPR战略，该战略有可能大幅提高总体审查绩效，同时减少审查工作量。

##### URL
[http://arxiv.org/abs/1806.08663](http://arxiv.org/abs/1806.08663)

##### PDF
[http://arxiv.org/pdf/1806.08663](http://arxiv.org/pdf/1806.08663)

