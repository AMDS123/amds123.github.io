---
layout: post
title: "Multi-Layer Ensembling Techniques for Multilingual Intent Classification"
date: 2018-06-20 18:17:40
categories: arXiv_CL
tags: arXiv_CL Classification
author: Charles Costello, Ruixi Lin, Vishwas Mruthyunjaya, Bettina Bolla, Charles Jankowski
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we determine how multi-layer ensembling improves performance on multilingual intent classification. We develop a novel multi-layer ensembling approach that ensembles both different model initializations and different model architectures. We also introduce a new banking domain dataset and compare results against the standard ATIS dataset and the Chinese SMP2017 dataset to determine ensembling performance in multilingual and multi-domain contexts. We run ensemble experiments across all three datasets, and conclude that ensembling provides significant performance increases, and that multi-layer ensembling is a no-risk way to improve performance on intent classification. We also find that a diverse ensemble of simple models can reach perform comparable to much more sophisticated state-of-the-art models. Our best F 1 scores on ATIS, Banking, and SMP are 97.54%, 91.79%, and 93.55% respectively, which compare well with the state-of-the-art on ATIS and best submission to the SMP2017 competition. The total ensembling performance increases we achieve are 0.23%, 1.96%, and 4.04% F 1 respectively.

##### Abstract (translated by Google)
在本文中，我们确定多层集成如何提高多语言意图分类的性能。我们开发了一种新颖的多层集成方法，可集合不同的模型初始化和不同的模型体系结构。我们还引入了一个新的银行业务领域数据集，并将结果与​​标准ATIS数据集和中国SMP2017数据集进行比较，以确定多语言和多领域环境下的集成性能。我们在所有三个数据集上运行集合实验，并得出结论：集合提供显着的性能提升，并且多层集成是提高意图分类性能的无风险方法。我们还发现，各种简单模型的集合可以达到与更复杂的最先进模型相媲美的性能。我们对ATIS，银行和SMP的最佳F 1分数分别为97.54％，91.79％和93.55％，这与ATIS的最新水平相比并且与SMP2017竞赛最为相符。我们实现的总体综合性能增长分别为0.23％，1.96％和4.04％F 1。

##### URL
[http://arxiv.org/abs/1806.07914](http://arxiv.org/abs/1806.07914)

##### PDF
[http://arxiv.org/pdf/1806.07914](http://arxiv.org/pdf/1806.07914)

