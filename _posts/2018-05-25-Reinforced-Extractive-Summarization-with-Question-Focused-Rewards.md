---
layout: post
title: "Reinforced Extractive Summarization with Question-Focused Rewards"
date: 2018-05-25 23:05:48
categories: arXiv_CL
tags: arXiv_CL Salient Summarization Reinforcement_Learning
author: Kristjan Arumae, Fei Liu
mathjax: true
---

* content
{:toc}

##### Abstract
We investigate a new training paradigm for extractive summarization. Traditionally, human abstracts are used to derive goldstandard labels for extraction units. However, the labels are often inaccurate, because human abstracts and source documents cannot be easily aligned at the word level. In this paper we convert human abstracts to a set of Cloze-style comprehension questions. System summaries are encouraged to preserve salient source content useful for answering questions and share common words with the abstracts. We use reinforcement learning to explore the space of possible extractive summaries and introduce a question-focused reward function to promote concise, fluent, and informative summaries. Our experiments show that the proposed method is effective. It surpasses state-of-the-art systems on the standard summarization dataset.

##### Abstract (translated by Google)
我们调查了一种新的用于抽取摘要的训练范式。传统上，人类文摘被用来为提取单元推导出金标准标签。但是，标签通常不准确，因为人类摘要和源文档不能轻易地在单词级别对齐。在本文中，我们将人类的摘要转换成一系列完形填空问题。鼓励系统总结，以保留对回答问题有用的重要内容，并与摘要共享常用词汇。我们使用强化学习来探索可能的抽取摘要的空间，并引入一个以问题为中心的奖励函数来促进简明，流畅和翔实的摘要。我们的实验表明，所提出的方法是有效的。它超越了标准摘要数据集中最先进的系统。

##### URL
[http://arxiv.org/abs/1805.10392](http://arxiv.org/abs/1805.10392)

##### PDF
[http://arxiv.org/pdf/1805.10392](http://arxiv.org/pdf/1805.10392)

