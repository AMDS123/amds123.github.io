---
layout: post
title: "Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising"
date: 2018-02-23 02:29:06
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Di Wu, Xiujun Chen, Xun Yang, Hao Wang, Qing Tan, Xiaoxun Zhang, Kun Gai
mathjax: true
---

* content
{:toc}

##### Abstract
Real-time bidding (RTB) is almost the most important mechanism in online display advertising, where proper bid for each page view plays a vital and essential role for good marketing results. Budget constrained bidding is a typical scenario in RTB mechanism where the advertisers hope to maximize total value of winning impressions under a pre-set budget constraint. However, the optimal strategy is hard to be derived due to complexity and volatility of the auction environment. To address the challenges, in this paper, we formulate budget constrained bidding as a Markov Decision Process. Quite different from prior model-based work, we propose a novel framework based on model-free reinforcement learning which sequentially regulates the bidding parameter rather than directly producing bid. Along this line, we further innovate a reward function which deploys a deep neural network to learn appropriate reward and thus leads the agent to deliver the optimal policy effectively; we also design an adaptive $\epsilon$-greedy strategy which adjusts the exploration behaviour dynamically and further improves the performance. Experimental results on real dataset demonstrate the effectiveness of our framework.

##### Abstract (translated by Google)
实时出价（RTB）几乎是在线展示广告中最重要的机制，对每个页面视图进行适当出价对良好市场营销结果起着至关重要的作用。预算约束竞价是实时出价机制中的典型场景，广告客户希望在预先设定的预算限制下最大化获胜展示的总价值。然而，由于拍卖环境的复杂性和波动性，最优策略很难得出。为了应对这些挑战，在本文中，我们将预算约束竞标制定为马尔可夫决策过程。与以往基于模型的工作不同，我们提出了一种基于无模型强化学习的新框架，它依次调节投标参数而不是直接生成投标。沿着这条线，我们进一步创新奖励功能，部署深度神经网络来学习适当的奖励，从而导致代理人有效地提供最优策略;我们还设计了一个自适应的$ \ epsilon $ -greedy策略，可以动态调整探索行为并进一步提高性能。实际数据集的实验结果证明了我们框架的有效性。

##### URL
[http://arxiv.org/abs/1802.08365](http://arxiv.org/abs/1802.08365)

##### PDF
[http://arxiv.org/pdf/1802.08365](http://arxiv.org/pdf/1802.08365)

