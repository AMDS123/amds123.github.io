---
layout: post
title: "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"
date: 2018-01-16 23:37:25
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Ryan Lowe, Yi Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, Igor Mordatch
mathjax: true
---

* content
{:toc}

##### Abstract
We explore deep reinforcement learning methods for multi-agent domains. We begin by analyzing the difficulty of traditional algorithms in the multi-agent case: Q-learning is challenged by an inherent non-stationarity of the environment, while policy gradient suffers from a variance that increases as the number of agents grows. We then present an adaptation of actor-critic methods that considers action policies of other agents and is able to successfully learn policies that require complex multi-agent coordination. Additionally, we introduce a training regimen utilizing an ensemble of policies for each agent that leads to more robust multi-agent policies. We show the strength of our approach compared to existing methods in cooperative as well as competitive scenarios, where agent populations are able to discover various physical and informational coordination strategies.

##### Abstract (translated by Google)
我们探索多智能体领域的深度强化学习方法。我们首先分析多智能体案例中传统算法的难点：Q学习受到环境固有的非平稳性的挑战，而政策梯度则随着智能体数量增长而增加。然后，我们提出一种考虑其他代理的行为策略的演员 - 评论者方法的改编，并且能够成功地学习需要复杂的多代理协调的策略。此外，我们引入了一个培训方案，利用每个代理人的政策集合，导致更强大的多代理人政策。我们展示了我们的方法与现有方法相比在合作以及竞争场景中的强度，其中代理人群能够发现各种物理和信息协调策略。

##### URL
[http://arxiv.org/abs/1706.02275](http://arxiv.org/abs/1706.02275)

##### PDF
[http://arxiv.org/pdf/1706.02275](http://arxiv.org/pdf/1706.02275)

