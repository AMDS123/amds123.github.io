---
layout: post
title: "Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video"
date: 2017-07-26 14:13:23
categories: arXiv_CV
tags: arXiv_CV Action_Recognition CNN Detection Recognition
author: Davide Moltisanti, Michael Wray, Walterio Mayol-Cuevas, Dima Damen
mathjax: true
---

* content
{:toc}

##### Abstract
Manual annotations of temporal bounds for object interactions (i.e. start and end times) are typical training input to recognition, localization and detection algorithms. For three publicly available egocentric datasets, we uncover inconsistencies in ground truth temporal bounds within and across annotators and datasets. We systematically assess the robustness of state-of-the-art approaches to changes in labeled temporal bounds, for object interaction recognition. As boundaries are trespassed, a drop of up to 10% is observed for both Improved Dense Trajectories and Two-Stream Convolutional Neural Network. We demonstrate that such disagreement stems from a limited understanding of the distinct phases of an action, and propose annotating based on the Rubicon Boundaries, inspired by a similarly named cognitive model, for consistent temporal bounds of object interactions. Evaluated on a public dataset, we report a 4% increase in overall accuracy, and an increase in accuracy for 55% of classes when Rubicon Boundaries are used for temporal annotations.

##### Abstract (translated by Google)
对象交互的时间界限（即开始和结束时间）的手动注释是对识别，定位和检测算法的典型训练输入。对于三个公开可用的以自我为中心的数据集，我们揭示注释者和数据集内部和之间的地面真实时间范围的不一致性。我们系统地评估了标记时间范围变化的最先进方法对物体相互作用识别的鲁棒性。当边界被侵入时，对于改进的密集轨迹和双流卷积神经网络观察到高达10％的下降。我们证明这种分歧源于对行为的不同阶段的有限理解，并且提出了基于Rubicon边界的注释，其由类似命名的认知模型启发，用于一致的对象交互的时间界限。在公共数据集上进行评估时，我们报告总体准确性提高了4％，而当Rubicon边界用于时间注释时，提高了55％的准确性。

##### URL
[https://arxiv.org/abs/1703.09026](https://arxiv.org/abs/1703.09026)

##### PDF
[https://arxiv.org/pdf/1703.09026](https://arxiv.org/pdf/1703.09026)

