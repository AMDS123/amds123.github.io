---
layout: post
title: "Model-based Lookahead Reinforcement Learning"
date: 2019-08-15 04:10:13
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Zhang-Wei Hong, Joni Pajarinen, Jan Peters
mathjax: true
---

* content
{:toc}

##### Abstract
Model-based Reinforcement Learning (MBRL) allows data-efficient learning which is required in real world applications such as robotics. However, despite the impressive data-efficiency, MBRL does not achieve the final performance of state-of-the-art Model-free Reinforcement Learning (MFRL) methods. We leverage the strengths of both realms and propose an approach that obtains high performance with a small amount of data. In particular, we combine MFRL and Model Predictive Control (MPC). While MFRL's strength in exploration allows us to train a better forward dynamics model for MPC, MPC improves the performance of the MFRL policy by sampling-based planning. The experimental results in standard continuous control benchmarks show that our approach can achieve MFRL`s level of performance while being as data-efficient as MBRL.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1908.06012](https://arxiv.org/abs/1908.06012)

##### PDF
[https://arxiv.org/pdf/1908.06012](https://arxiv.org/pdf/1908.06012)

