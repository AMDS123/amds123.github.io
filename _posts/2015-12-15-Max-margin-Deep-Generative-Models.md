---
layout: post
title: "Max-margin Deep Generative Models"
date: 2015-12-15 03:01:06
categories: arXiv_CV
tags: arXiv_CV CNN Inference Prediction Recognition
author: Chongxuan Li, Jun Zhu, Tianlin Shi, Bo Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Deep generative models (DGMs) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability. However, little work has been done on examining or empowering the discriminative ability of DGMs on making accurate predictions. This paper presents max-margin deep generative models (mmDGMs), which explore the strongly discriminative principle of max-margin learning to improve the discriminative power of DGMs, while retaining the generative capability. We develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objective. Empirical results on MNIST and SVHN datasets demonstrate that (1) max-margin learning can significantly improve the prediction performance of DGMs and meanwhile retain the generative ability; and (2) mmDGMs are competitive to the state-of-the-art fully discriminative networks by employing deep convolutional neural networks (CNNs) as both recognition and generative models.

##### Abstract (translated by Google)
深度生成模型（DGM）对于学习复杂数据的多层表示以及通过探索生成能力来对输入数据进行推理是有效的。然而，在检查或授权DGM的准确预测的区分能力方面做了很少的工作。本文提出了最大边缘深度生成模型（mmDGMs），探讨了最大边缘学习的强歧视性原则，提高了DGMs的判别能力，同时保留了生成能力。我们为分段线性目标开发了一个高效的双随机次梯度算法。对MNIST和SVHN数据集的实证结果表明：（1）最大边缘学习能显着提高DGMs的预测性能，同时保留生成能力; （2）mmDGM通过采用深度卷积神经网络（CNN）作为识别和生成模型，与最先进的全识别网络相竞争。

##### URL
[https://arxiv.org/abs/1504.06787](https://arxiv.org/abs/1504.06787)

##### PDF
[https://arxiv.org/pdf/1504.06787](https://arxiv.org/pdf/1504.06787)

