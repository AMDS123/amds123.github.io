---
layout: post
title: "Training an adaptive dialogue policy for interactive learning of visually grounded word meanings"
date: 2017-09-29 14:28:31
categories: arXiv_CL
tags: arXiv_CL
author: Yanchao Yu, Arash Eshghi, Oliver Lemon
mathjax: true
---

* content
{:toc}

##### Abstract
We present a multi-modal dialogue system for interactive learning of perceptually grounded word meanings from a human tutor. The system integrates an incremental, semantic parsing/generation framework - Dynamic Syntax and Type Theory with Records (DS-TTR) - with a set of visual classifiers that are learned throughout the interaction and which ground the meaning representations that it produces. We use this system in interaction with a simulated human tutor to study the effects of different dialogue policies and capabilities on the accuracy of learned meanings, learning rates, and efforts/costs to the tutor. We show that the overall performance of the learning agent is affected by (1) who takes initiative in the dialogues; (2) the ability to express/use their confidence level about visual attributes; and (3) the ability to process elliptical and incrementally constructed dialogue turns. Ultimately, we train an adaptive dialogue policy which optimises the trade-off between classifier accuracy and tutoring costs.

##### Abstract (translated by Google)
我们提出了一个多模式的对话系统，用于交互式学习来自人类导师的感知上的词义。该系统集成了一个增量的语义分析/生成框架 - 动态语法和类型理论与记录（DS-TTR） - 以及一系列可视分类器，这些分类器在整个交互过程中得到了学习，并将其产生的含义表示形式化。我们使用这个系统与模拟人类导师交互，研究不同的对话政策和能力对导师的学习意义，学习率，努力/成本的准确性的影响。我们发现学习代理的整体表现受到以下几方面的影响：（1）主动对话; （2）表达/使用关于视觉属性的置信度的能力;和（3）处理椭圆和增量构建的对话轮的能力。最终，我们训练一个自适应对话政策，优化分类器准确性和辅导成本之间的权衡。

##### URL
[https://arxiv.org/abs/1709.10426](https://arxiv.org/abs/1709.10426)

##### PDF
[https://arxiv.org/pdf/1709.10426](https://arxiv.org/pdf/1709.10426)

