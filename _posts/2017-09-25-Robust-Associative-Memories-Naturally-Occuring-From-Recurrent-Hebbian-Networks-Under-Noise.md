---
layout: post
title: "Robust Associative Memories Naturally Occuring From Recurrent Hebbian Networks Under Noise"
date: 2017-09-25 08:29:39
categories: arXiv_CV
tags: arXiv_CV Sparse
author: Eliott Coyac, Vincent Gripon, Charlotte Langlais, Claude Berrou
mathjax: true
---

* content
{:toc}

##### Abstract
The brain is a noisy system subject to energy constraints. These facts are rarely taken into account when modelling artificial neural networks. In this paper, we are interested in demonstrating that those factors can actually lead to the appearance of robust associative memories. We first propose a simplified model of noise in the brain, taking into account synaptic noise and interference from neurons external to the network. When coarsely quantized, we show that this noise can be reduced to insertions and erasures. We take a neural network with recurrent modifiable connections, and subject it to noisy external inputs. We introduce an energy usage limitation principle in the network as well as consolidated Hebbian learning, resulting in an incremental processing of inputs. We show that the connections naturally formed correspond to state-of-the-art binary sparse associative memories.

##### Abstract (translated by Google)
大脑是一个受制于能量限制的嘈杂系统。建模人工神经网络时很少考虑到这些事实。在本文中，我们感兴趣的是证明这些因素实际上可以导致强健的联想记忆的出现。我们首先提出一个简化的大脑噪声模型，考虑到突触噪声和网络外部神经元的干扰。当粗量化时，我们表明这个噪声可以被减少到插入和删除。我们采用具有反复可修改连接的神经网络，并将其接受嘈杂的外部输入。我们在网络中引入能量使用限制原理以及巩固的Hebbian学习，导致输入的增量处理。我们表明，自然形成的连接符合最先进的二进制稀疏联想记忆。

##### URL
[https://arxiv.org/abs/1709.08367](https://arxiv.org/abs/1709.08367)

##### PDF
[https://arxiv.org/pdf/1709.08367](https://arxiv.org/pdf/1709.08367)

