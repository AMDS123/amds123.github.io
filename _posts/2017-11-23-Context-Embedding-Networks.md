---
layout: post
title: "Context Embedding Networks"
date: 2017-11-23 22:47:50
categories: arXiv_CV
tags: arXiv_CV Embedding
author: Kun ho Kim, Oisin Mac Aodha, Pietro Perona
mathjax: true
---

* content
{:toc}

##### Abstract
Low dimensional embeddings that capture the main variations of interest in collections of data are important for many applications. One way to construct these embeddings is to acquire estimates of similarity from the crowd. However, similarity is a multi-dimensional concept that varies from individual to individual. Existing models for learning embeddings from the crowd typically make simplifying assumptions such as all individuals estimate similarity using the same criteria, the list of criteria is known in advance, or that the crowd workers are not influenced by the data that they see. To overcome these limitations we introduce Context Embedding Networks (CENs). In addition to learning interpretable embeddings from images, CENs also model worker biases for different attributes along with the visual context i.e. the visual attributes highlighted by a set of images. Experiments on two noisy crowd annotated datasets show that modeling both worker bias and visual context results in more interpretable embeddings compared to existing approaches.

##### Abstract (translated by Google)
捕捉数据集合中感兴趣的主要变化的低维嵌入对于许多应用来说是重要的。构建这些嵌入的一种方法是从人群中获取相似度的估计。然而，相似性是一个多维度的概念，因人而异。现有的从人群中学习嵌入的模型通常会做出简化的假设，例如所有的个人使用相同的标准来估计相似性，事先知道标准列表，或者群众工作人员不受他们所看到的数据的影响。为了克服这些限制，我们引入了上下文嵌入网络（CEN）。除了从图像中学习可解释的嵌入之外，CEN还为不同属性的工作者偏好以及视觉上下文（即由一组图像突出显示的视觉属性）建模。在两个有噪声的人群注释数据集上的实验表明，与现有方法相比，建模工作者偏好和视觉上下文导致更多可解释的嵌入。

##### URL
[https://arxiv.org/abs/1710.01691](https://arxiv.org/abs/1710.01691)

##### PDF
[https://arxiv.org/pdf/1710.01691](https://arxiv.org/pdf/1710.01691)

