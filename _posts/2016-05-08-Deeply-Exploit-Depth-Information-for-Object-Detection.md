---
layout: post
title: "Deeply Exploit Depth Information for Object Detection"
date: 2016-05-08 01:56:50
categories: arXiv_CV
tags: arXiv_CV Object_Detection Detection
author: Saihui Hou, Zilei Wang, Feng Wu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper addresses the issue on how to more effectively coordinate the depth with RGB aiming at boosting the performance of RGB-D object detection. Particularly, we investigate two primary ideas under the CNN model: property derivation and property fusion. Firstly, we propose that the depth can be utilized not only as a type of extra information besides RGB but also to derive more visual properties for comprehensively describing the objects of interest. So a two-stage learning framework consisting of property derivation and fusion is constructed. Here the properties can be derived either from the provided color/depth or their pairs (e.g. the geometry contour adopted in this paper). Secondly, we explore the fusion method of different properties in feature learning, which is boiled down to, under the CNN model, from which layer the properties should be fused together. The analysis shows that different semantic properties should be learned separately and combined before passing into the final classifier. Actually, such a detection way is in accordance with the mechanism of the primary neural cortex (V1) in brain. We experimentally evaluate the proposed method on the challenging dataset, and have achieved state-of-the-art performance.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1605.02260](https://arxiv.org/abs/1605.02260)

##### PDF
[https://arxiv.org/pdf/1605.02260](https://arxiv.org/pdf/1605.02260)

