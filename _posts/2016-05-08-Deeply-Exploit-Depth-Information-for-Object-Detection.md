---
layout: post
title: "Deeply Exploit Depth Information for Object Detection"
date: 2016-05-08 01:56:50
categories: arXiv_CV
tags: arXiv_CV Object_Detection Detection
author: Saihui Hou, Zilei Wang, Feng Wu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper addresses the issue on how to more effectively coordinate the depth with RGB aiming at boosting the performance of RGB-D object detection. Particularly, we investigate two primary ideas under the CNN model: property derivation and property fusion. Firstly, we propose that the depth can be utilized not only as a type of extra information besides RGB but also to derive more visual properties for comprehensively describing the objects of interest. So a two-stage learning framework consisting of property derivation and fusion is constructed. Here the properties can be derived either from the provided color/depth or their pairs (e.g. the geometry contour adopted in this paper). Secondly, we explore the fusion method of different properties in feature learning, which is boiled down to, under the CNN model, from which layer the properties should be fused together. The analysis shows that different semantic properties should be learned separately and combined before passing into the final classifier. Actually, such a detection way is in accordance with the mechanism of the primary neural cortex (V1) in brain. We experimentally evaluate the proposed method on the challenging dataset, and have achieved state-of-the-art performance.

##### Abstract (translated by Google)
本文针对如何更有效地协调深度与RGB的问题，以提高RGB-D对象检测的性能为目标。特别是我们研究了CNN模型下的两个主要思想：属性推导和属性融合。首先，我们提出，深度不仅可以作为一种除了RGB之外的额外信息，而且还可以导出更多的视觉特性来全面地描述感兴趣的对象。因此构建了一个由属性派生和融合组成的两阶段学习框架。在这里，属性可以从所提供的颜色/深度或它们的对（例如本文中采用的几何轮廓）导出。其次，研究了特征学习中不同属性的融合方法，归结为在CNN模型下，属性应该从哪一层融合到一起。分析表明，不同的语义属性在传递到最终的分类器之前应该分别学习和组合。实际上，这种检测方式与大脑中主要神经皮层（V1）的机制是一致的。我们在具有挑战性的数据集上实验性地评估了所提出的方法，并取得了最先进的性能。

##### URL
[https://arxiv.org/abs/1605.02260](https://arxiv.org/abs/1605.02260)

