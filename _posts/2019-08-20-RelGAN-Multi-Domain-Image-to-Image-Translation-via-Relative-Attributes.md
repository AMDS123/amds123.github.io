---
layout: post
title: "RelGAN: Multi-Domain Image-to-Image Translation via Relative Attributes"
date: 2019-08-20 10:54:34
categories: arXiv_CV
tags: arXiv_CV Attention GAN Quantitative
author: Po-Wei Wu, Yu-Jing Lin, Che-Han Chang, Edward Y. Chang, Shih-Wei Liao
mathjax: true
---

* content
{:toc}

##### Abstract
Multi-domain image-to-image translation has gained increasing attention recently. Previous methods take an image and some target attributes as inputs and generate an output image with the desired attributes. However, such methods have two limitations. First, these methods assume binary-valued attributes and thus cannot yield satisfactory results for fine-grained control. Second, these methods require specifying the entire set of target attributes, even if most of the attributes would not be changed. To address these limitations, we propose RelGAN, a new method for multi-domain image-to-image translation. The key idea is to use relative attributes, which describes the desired change on selected attributes. Our method is capable of modifying images by changing particular attributes of interest in a continuous manner while preserving the other attributes. Experimental results demonstrate both the quantitative and qualitative effectiveness of our method on the tasks of facial attribute transfer and interpolation.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.07269](http://arxiv.org/abs/1908.07269)

##### PDF
[http://arxiv.org/pdf/1908.07269](http://arxiv.org/pdf/1908.07269)

