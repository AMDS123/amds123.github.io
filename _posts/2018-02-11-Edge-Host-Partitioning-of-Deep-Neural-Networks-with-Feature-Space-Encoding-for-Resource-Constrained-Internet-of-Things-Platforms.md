---
layout: post
title: "Edge-Host Partitioning of Deep Neural Networks with Feature Space Encoding for Resource-Constrained Internet-of-Things Platforms"
date: 2018-02-11 23:04:36
categories: arXiv_CV
tags: arXiv_CV CNN Inference
author: Jong Hwan Ko, Taesik Na, Mohammad Faisal Amir, Saibal Mukhopadhyay
mathjax: true
---

* content
{:toc}

##### Abstract
This paper introduces partitioning an inference task of a deep neural network between an edge and a host platform in the IoT environment. We present a DNN as an encoding pipeline, and propose to transmit the output feature space of an intermediate layer to the host. The lossless or lossy encoding of the feature space is proposed to enhance the maximum input rate supported by the edge platform and/or reduce the energy of the edge platform. Simulation results show that partitioning a DNN at the end of convolutional (feature extraction) layers coupled with feature space encoding enables significant improvement in the energy-efficiency and throughput over the baseline configurations that perform the entire inference at the edge or at the host.

##### Abstract (translated by Google)
本文介绍了物联网环境中边缘与主机平台之间深度神经网络的推理任务划分。我们提出一个DNN作为编码流水线，并建议将中间层的输出特征空间传输给主机。提出特征空间的无损或有损编码以增强边缘平台支持的最大输入速率和/或减少边缘平台的能量。仿真结果表明，在特征空间编码的卷积（特征提取）层末端对DNN进行分割，可以显着提高在边缘或主机执行完整推理的基线配置的能量效率和吞吐量。

##### URL
[http://arxiv.org/abs/1802.03835](http://arxiv.org/abs/1802.03835)

##### PDF
[http://arxiv.org/pdf/1802.03835](http://arxiv.org/pdf/1802.03835)

