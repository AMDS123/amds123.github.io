---
layout: post
title: "Bach2Bach: Generating Music Using A Deep Reinforcement Learning Approach"
date: 2018-12-03 20:09:05
categories: arXiv_SD
tags: arXiv_SD Reinforcement_Learning CNN RNN Quantitative
author: Nikhil Kotecha
mathjax: true
---

* content
{:toc}

##### Abstract
A model of music needs to have the ability to recall past details and have a clear, coherent understanding of musical structure. Detailed in the paper is a deep reinforcement learning architecture that predicts and generates polyphonic music aligned with musical rules. The probabilistic model presented is a Bi-axial LSTM trained with a pseudo-kernel reminiscent of a convolutional kernel. To encourage exploration and impose greater global coherence on the generated music, a deep reinforcement learning approach DQN is adopted. When analyzed quantitatively and qualitatively, this approach performs well in composing polyphonic music.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.01060](http://arxiv.org/abs/1812.01060)

##### PDF
[http://arxiv.org/pdf/1812.01060](http://arxiv.org/pdf/1812.01060)

