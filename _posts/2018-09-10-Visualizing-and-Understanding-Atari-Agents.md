---
layout: post
title: "Visualizing and Understanding Atari Agents"
date: 2018-09-10 18:42:40
categories: arXiv_AI
tags: arXiv_AI Salient Reinforcement_Learning
author: Sam Greydanus, Anurag Koul, Jonathan Dodge, Alan Fern
mathjax: true
---

* content
{:toc}

##### Abstract
While deep reinforcement learning (deep RL) agents are effective at maximizing rewards, it is often unclear what strategies they use to do so. In this paper, we take a step toward explaining deep RL agents through a case study using Atari 2600 environments. In particular, we focus on using saliency maps to understand how an agent learns and executes a policy. We introduce a method for generating useful saliency maps and use it to show 1) what strong agents attend to, 2) whether agents are making decisions for the right or wrong reasons, and 3) how agents evolve during learning. We also test our method on non-expert human subjects and find that it improves their ability to reason about these agents. Overall, our results show that saliency information can provide significant insight into an RL agent's decisions and learning behavior.

##### Abstract (translated by Google)
虽然深度强化学习（深度RL）代理在最大化奖励方面是有效的，但通常不清楚他们使用什么策略来做到这一点。在本文中，我们通过使用Atari 2600环境的案例研究向前解释深度RL代理。特别是，我们专注于使用显着性图来了解代理如何学习和执行策略。我们介绍了一种生成有用显着性图的方法，并用它来表示1）强有力的代理人应该注意什么，2）代理人是否出于正确或错误的原因做出决策，以及3）代理人在学习过程中如何进化。我们还测试了我们对非专业人类受试者的方法，并发现它提高了他们推理这些药物的能力。总的来说，我们的结果表明，显着性信息可以提供对RL代理人的决策和学习行为的重要洞察力。

##### URL
[http://arxiv.org/abs/1711.00138](http://arxiv.org/abs/1711.00138)

##### PDF
[http://arxiv.org/pdf/1711.00138](http://arxiv.org/pdf/1711.00138)

