---
layout: post
title: "Robust Convolutional Neural Networks under Adversarial Noise"
date: 2016-02-25 16:30:04
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN Classification
author: Jonghoon Jin, Aysegul Dundar, Eugenio Culurciello
mathjax: true
---

* content
{:toc}

##### Abstract
Recent studies have shown that Convolutional Neural Networks (CNNs) are vulnerable to a small perturbation of input called "adversarial examples". In this work, we propose a new feedforward CNN that improves robustness in the presence of adversarial noise. Our model uses stochastic additive noise added to the input image and to the CNN models. The proposed model operates in conjunction with a CNN trained with either standard or adversarial objective function. In particular, convolution, max-pooling, and ReLU layers are modified to benefit from the noise model. Our feedforward model is parameterized by only a mean and variance per pixel which simplifies computations and makes our method scalable to a deep architecture. From CIFAR-10 and ImageNet test, the proposed model outperforms other methods and the improvement is more evident for difficult classification tasks or stronger adversarial noise.

##### Abstract (translated by Google)
最近的研究表明，卷积神经网络（CNN）很容易受到一种被称为“对抗性例子”的小扰动输入的影响。在这项工作中，我们提出了一个新的前馈CNN，在对抗噪声的情况下提高了鲁棒性。我们的模型使用添加到输入图像和CNN模型的随机加性噪声。所提出的模型与通过标准或敌对目标函数训练的CNN一起运行。具体来说，卷积，最大池和ReLU层被修改以受益于噪声模型。我们的前馈模型仅通过每个像素的均值和方差进行参数化，这简化了计算，并使我们的方法可以扩展到深度架构。从CIFAR-10和ImageNet测试结果来看，所提出的模型优于其他方法，对于困难的分类任务或较强的对抗噪声，其改进更为明显。

##### URL
[https://arxiv.org/abs/1511.06306](https://arxiv.org/abs/1511.06306)

##### PDF
[https://arxiv.org/pdf/1511.06306](https://arxiv.org/pdf/1511.06306)

