---
layout: post
title: "Look, Listen and Learn"
date: 2017-08-01 12:04:50
categories: arXiv_CV
tags: arXiv_CV Classification Recognition
author: Relja Arandjelović, Andrew Zisserman
mathjax: true
---

* content
{:toc}

##### Abstract
We consider the question: what can be learnt by looking at and listening to a large number of unlabelled videos? There is a valuable, but so far untapped, source of information contained in the video itself -- the correspondence between the visual and the audio streams, and we introduce a novel "Audio-Visual Correspondence" learning task that makes use of this. Training visual and audio networks from scratch, without any additional supervision other than the raw unconstrained videos themselves, is shown to successfully solve this task, and, more interestingly, result in good visual and audio representations. These features set the new state-of-the-art on two sound classification benchmarks, and perform on par with the state-of-the-art self-supervised approaches on ImageNet classification. We also demonstrate that the network is able to localize objects in both modalities, as well as perform fine-grained recognition tasks.

##### Abstract (translated by Google)
我们考虑这个问题：通过观看和聆听大量未标记的视频可以学到什么？视频本身所包含的信息来源（视觉和音频流之间的对应关系）是有价值但尚未开发的，而且我们引入了一个利用这一点的新颖的“视听对话”学习任务。从头开始培训视觉和音频网络，除了原始非约束视频本身之外，没有任何额外的监督，被证明能够成功地解决这个任务，而且更有趣的是，产生了良好的视觉和音频表现。这些功能在两个完善的分类基准上设置了最新的最新技术，并与ImageNet分类中最先进的自我监督方法相媲美。我们还证明，网络能够在两种模式下本地化对象，并执行细粒度的识别任务。

##### URL
[https://arxiv.org/abs/1705.08168](https://arxiv.org/abs/1705.08168)

##### PDF
[https://arxiv.org/pdf/1705.08168](https://arxiv.org/pdf/1705.08168)

