---
layout: post
title: "Video-to-Video Synthesis"
date: 2018-08-20 17:58:42
categories: arXiv_CV
tags: arXiv_CV Adversarial Segmentation Semantic_Segmentation Prediction
author: Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Guilin Liu, Andrew Tao, Jan Kautz, Bryan Catanzaro
mathjax: true
---

* content
{:toc}

##### Abstract
We study the problem of video-to-video synthesis, whose goal is to learn a mapping function from an input source video (e.g., a sequence of semantic segmentation masks) to an output photorealistic video that precisely depicts the content of the source video. While its image counterpart, the image-to-image synthesis problem, is a popular topic, the video-to-video synthesis problem is less explored in the literature. Without understanding temporal dynamics, directly applying existing image synthesis approaches to an input video often results in temporally incoherent videos of low visual quality. In this paper, we propose a novel video-to-video synthesis approach under the generative adversarial learning framework. Through carefully-designed generator and discriminator architectures, coupled with a spatio-temporal adversarial objective, we achieve high-resolution, photorealistic, temporally coherent video results on a diverse set of input formats including segmentation masks, sketches, and poses. Experiments on multiple benchmarks show the advantage of our method compared to strong baselines. In particular, our model is capable of synthesizing 2K resolution videos of street scenes up to 30 seconds long, which significantly advances the state-of-the-art of video synthesis. Finally, we apply our approach to future video prediction, outperforming several state-of-the-art competing systems.

##### Abstract (translated by Google)
我们研究视频到视频合成的问题，其目的是学习从输入源视频（例如，语义分段掩模序列）到精确描绘源视频内容的输出照片级真实视频的映射函数。虽然其图像对应的图像到图像合成问题是一个热门话题，但文献中对视频到视频合成问题的研究较少。在不了解时间动态的情况下，将现有的图像合成方法直接应用于输入视频通常会导致视觉质量低的时间不连贯的视频。在本文中，我们在生成对抗性学习框架下提出了一种新颖的视频到视频合成方法。通过精心设计的发生器和鉴别器架构，再加上时空对抗物镜，我们可以在多种输入格式（包括分割蒙版，草图和姿势）上实现高分辨率，逼真，时间相干的视频效果。多个基准测试的实验表明，与强基线相比，我们的方法具有优势。特别是，我们的模型能够合成长达30秒的街景2K分辨率视频，从而显着提升了视频合成的最新技术水平。最后，我们将我们的方法应用于未来的视频预测，超越了几个最先进的竞争系统。

##### URL
[http://arxiv.org/abs/1808.06601](http://arxiv.org/abs/1808.06601)

##### PDF
[http://arxiv.org/pdf/1808.06601](http://arxiv.org/pdf/1808.06601)

