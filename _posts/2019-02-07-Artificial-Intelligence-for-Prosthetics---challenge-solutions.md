---
layout: post
title: "Artificial Intelligence for Prosthetics - challenge solutions"
date: 2019-02-07 01:17:17
categories: arXiv_RO
tags: arXiv_RO Knowledge Reinforcement_Learning
author: &#x141;ukasz Kidzi&#x144;ski, Carmichael Ong, Sharada Prasanna Mohanty, Jennifer Hicks, Sean F. Carroll, Bo Zhou, Hongsheng Zeng, Fan Wang, Rongzhong Lian, Hao Tian, Wojciech Ja&#x15b;kowski, Garrett Andersen, Odd Rune Lykkeb&#xf8;, Nihat Engin Toklu, Pranav Shyam, Rupesh Kumar Srivastava, Sergey Kolesnikov, Oleksii Hrinchuk, Anton Pechenko, Mattias Ljungstr&#xf6;m, Zhen Wang, Xu Hu, Zehong Hu, Minghui Qiu, Jun Huang, Aleksei Shpilman, Ivan Sosin, Oleg Svidchenko, Aleksandra Malysheva, Daniel Kudenko, Lance Rane, Aditya Bhatt, Zhengfei Wang, Penghui Qi, Zeyang Yu, Peng Peng, Quan Yuan, Wenxin Li, Yunsheng Tian, Ruihan Yang, Pingchuan Ma, Shauharda Khadka, Somdeb Majumdar, Zach Dwiel, Yinyin Liu, Evren Tumer, Jeremy Watson, Marcel Salath&#xe9;, Sergey Levine, Scott Delp
mathjax: true
---

* content
{:toc}

##### Abstract
In the NeurIPS 2018 Artificial Intelligence for Prosthetics challenge, participants were tasked with building a controller for a musculoskeletal model with a goal of matching a given time-varying velocity vector. Top participants were invited to describe their algorithms. In this work, we describe the challenge and present thirteen solutions that used deep reinforcement learning approaches. Many solutions use similar relaxations and heuristics, such as reward shaping, frame skipping, discretization of the action space, symmetry, and policy blending. However, each team implemented different modifications of the known algorithms by, for example, dividing the task into subtasks, learning low-level control, or by incorporating expert knowledge and using imitation learning.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.02441](http://arxiv.org/abs/1902.02441)

##### PDF
[http://arxiv.org/pdf/1902.02441](http://arxiv.org/pdf/1902.02441)

