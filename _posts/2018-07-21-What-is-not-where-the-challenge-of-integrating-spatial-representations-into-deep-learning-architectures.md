---
layout: post
title: "What is not where: the challenge of integrating spatial representations into deep learning architectures"
date: 2018-07-21 11:55:17
categories: arXiv_AI
tags: arXiv_AI Image_Caption Object_Detection Knowledge Caption Deep_Learning Language_Model Detection Relation
author: John D. Kelleher, Simon Dobnik
mathjax: true
---

* content
{:toc}

##### Abstract
This paper examines to what degree current deep learning architectures for image caption generation capture spatial language. On the basis of the evaluation of examples of generated captions from the literature we argue that systems capture what objects are in the image data but not where these objects are located: the captions generated by these systems are the output of a language model conditioned on the output of an object detector that cannot capture fine-grained location information. Although language models provide useful knowledge for image captions, we argue that deep learning image captioning architectures should also model geometric relations between objects.

##### Abstract (translated by Google)
本文探讨了当前用于图像标题生成的深度学习架构捕获空间语言的程度。在对文献中生成的标题示例进行评估的基础上，我们认为系统捕获图像数据中的对象，而不是这些对象所在的位置：这些系统生成的标题是以条件为基础的语言模型的输出。无法捕获细粒度位置信息的对象检测器的输出。虽然语言模型为图像标题提供了有用的知识，但我们认为深度学习图像标题体系结构还应该模拟对象之间的几何关系。

##### URL
[http://arxiv.org/abs/1807.08133](http://arxiv.org/abs/1807.08133)

##### PDF
[http://arxiv.org/pdf/1807.08133](http://arxiv.org/pdf/1807.08133)

