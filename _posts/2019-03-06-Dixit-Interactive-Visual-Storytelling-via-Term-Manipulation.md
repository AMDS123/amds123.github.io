---
layout: post
title: "Dixit: Interactive Visual Storytelling via Term Manipulation"
date: 2019-03-06 08:08:01
categories: arXiv_CL
tags: arXiv_CL Image_Caption Caption RNN
author: Chao-Chun Hsu, Yu-Hua Chen, Zi-Yuan Chen, Hsin-Yu Lin, Ting-Hao (Kenneth) Huang, Lun-Wei Ku
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we introduceDixit, an interactive visual storytelling system that the user interacts with iteratively to compose a short story for a photo sequence. The user initiates the process by up-loading a sequence of photos. Dixit first extracts text terms from each photo which describe the objects (e.g., boy, bike) or actions(e.g., sleep) in the photo, and then allows the user to add new terms or remove existing terms. Dixit then generates a short story based on these terms. Behind the scenes, Dixit uses an LSTM-based model trained on image caption data and FrameNet to distill terms from each image and utilizes a transformer decoder to compose a context-coherent story. Users change images or terms iteratively with Dixit to create the most ideal story. Dixit also allows users to manually edit and rate stories. The proposed procedure opens up possibilities for interpretable and controllable visual storytelling, allowing users to understand the story formation rationale and to intervene in the generation process.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.02230](http://arxiv.org/abs/1903.02230)

##### PDF
[http://arxiv.org/pdf/1903.02230](http://arxiv.org/pdf/1903.02230)

