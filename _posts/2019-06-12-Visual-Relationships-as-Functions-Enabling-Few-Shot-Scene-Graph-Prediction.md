---
layout: post
title: "Visual Relationships as Functions: Enabling Few-Shot Scene Graph Prediction"
date: 2019-06-12 01:27:15
categories: arXiv_CV
tags: arXiv_CV Transfer_Learning Prediction Relation
author: Apoorva Dornadula, Austin Narcomey, Ranjay Krishna, Michael Bernstein, Li Fei-Fei
mathjax: true
---

* content
{:toc}

##### Abstract
Scene graph prediction --- classifying the set of objects and predicates in a visual scene --- requires substantial training data. The long-tailed distribution of relationships can be an obstacle for such approaches, however, as they can only be trained on the small set of predicates that carry sufficient labels. We introduce the first scene graph prediction model that supports few-shot learning of predicates, enabling scene graph approaches to generalize to a set of new predicates. First, we introduce a new model of predicates as functions that operate on object features or image locations. Next, we define a scene graph model where these functions are trained as message passing protocols within a new graph convolution framework. We train the framework with a frequently occurring set of predicates and show that our approach outperforms those that use the same amount of supervision by 1.78 at recall@50 and performs on par with other scene graph models. Next, we extract object representations generated by the trained predicate functions to train few-shot predicate classifiers on rare predicates with as few as 1 labeled example. When compared to strong baselines like transfer learning from existing state-of-the-art representations, we show improved 5-shot performance by 4.16 recall@1. Finally, we show that our predicate functions generate interpretable visualizations, enabling the first interpretable scene graph model.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.04876](http://arxiv.org/abs/1906.04876)

##### PDF
[http://arxiv.org/pdf/1906.04876](http://arxiv.org/pdf/1906.04876)

