---
layout: post
title: "Detecting Adversarial Samples Using Density Ratio Estimates"
date: 2017-11-20 16:17:18
categories: arXiv_CV
tags: arXiv_CV Adversarial Classification Detection
author: Lovedeep Gondara
mathjax: true
---

* content
{:toc}

##### Abstract
Machine learning models, especially based on deep architectures are used in everyday applications ranging from self driving cars to medical diagnostics. It has been shown that such models are dangerously susceptible to adversarial samples, indistinguishable from real samples to human eye, adversarial samples lead to incorrect classifications with high confidence. Impact of adversarial samples is far-reaching and their efficient detection remains an open problem. We propose to use direct density ratio estimation as an efficient model agnostic measure to detect adversarial samples. Our proposed method works equally well with single and multi-channel samples, and with different adversarial sample generation methods. We also propose a method to use density ratio estimates for generating adversarial samples with an added constraint of preserving density ratio.

##### Abstract (translated by Google)
机器学习模型，尤其是基于深度架构的机器学习模型被用于日常应用，从自驾车到医疗诊断。已经表明，这样的模型对于对抗样本是危险的，与真实样本不可区分，对抗样本导致不正确的分类，具有高置信度。敌对样本的影响是深远的，它们的有效检测仍然是一个悬而未决的问题。我们建议使用直接密度比估计作为检测敌​​对样本的有效模型不可知测量。我们提出的方法同样适用于单通道和多通道样本，以及不同的对抗样本生成方法。我们还提出了一种使用密度比估计来生成对抗样本的方法，其中保留密度比受到了额外的限制。

##### URL
[https://arxiv.org/abs/1705.02224](https://arxiv.org/abs/1705.02224)

##### PDF
[https://arxiv.org/pdf/1705.02224](https://arxiv.org/pdf/1705.02224)

