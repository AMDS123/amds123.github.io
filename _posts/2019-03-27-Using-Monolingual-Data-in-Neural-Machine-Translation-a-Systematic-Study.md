---
layout: post
title: "Using Monolingual Data in Neural Machine Translation: a Systematic Study"
date: 2019-03-27 14:11:18
categories: arXiv_CL
tags: arXiv_CL Language_Model
author: Franck Burlot, Fran&#xe7;ois Yvon
mathjax: true
---

* content
{:toc}

##### Abstract
Neural Machine Translation (MT) has radically changed the way systems are developed. A major difference with the previous generation (Phrase-Based MT) is the way monolingual target data, which often abounds, is used in these two paradigms. While Phrase-Based MT can seamlessly integrate very large language models trained on billions of sentences, the best option for Neural MT developers seems to be the generation of artificial parallel data through \textsl{back-translation} - a technique that fails to fully take advantage of existing datasets. In this paper, we conduct a systematic study of back-translation, comparing alternative uses of monolingual data, as well as multiple data generation procedures. Our findings confirm that back-translation is very effective and give new explanations as to why this is the case. We also introduce new data simulation techniques that are almost as effective, yet much cheaper to implement.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.11437](http://arxiv.org/abs/1903.11437)

##### PDF
[http://arxiv.org/pdf/1903.11437](http://arxiv.org/pdf/1903.11437)

