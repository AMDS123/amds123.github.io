---
layout: post
title: "Expanded Parts Model for Semantic Description of Humans in Still Images"
date: 2016-02-25 12:14:05
categories: arXiv_CV
tags: arXiv_CV Sparse Quantitative
author: Gaurav Sharma, Frederic Jurie, Cordelia Schmid
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce an Expanded Parts Model (EPM) for recognizing human attributes (e.g. young, short hair, wearing suit) and actions (e.g. running, jumping) in still images. An EPM is a collection of part templates which are learnt discriminatively to explain specific scale-space regions in the images (in human centric coordinates). This is in contrast to current models which consist of a relatively few (i.e. a mixture of) 'average' templates. EPM uses only a subset of the parts to score an image and scores the image sparsely in space, i.e. it ignores redundant and random background in an image. To learn our model, we propose an algorithm which automatically mines parts and learns corresponding discriminative templates together with their respective locations from a large number of candidate parts. We validate our method on three recent challenging datasets of human attributes and actions. We obtain convincing qualitative and state-of-the-art quantitative results on the three datasets.

##### Abstract (translated by Google)
我们引入了扩展部件模型（EPM）来识别静态图像中的人的属性（例如年轻，短发，穿着西装）和动作（例如奔跑，跳跃）。 EPM是部分模板的集合，其被区别地学习以解释图像中的特定尺度空间区域（以人类中心为坐标）。这与由“平均”模板相对较少（即混合）组成的当前模型形成对比。 EPM仅使用部分子集来对图像进行评分，并在空间中对图像进行稀疏评分，即忽略图像中多余和随机的背景。为了学习我们的模型，我们提出了一种自动挖掘零件的算法，并从大量的候选零件中学习相应的识别模板以及它们各自的位置。我们验证了我们的方法在最近的三个具有挑战性的人类属性和行为的数据集。我们在三个数据集上获得了令人信服的定性和最先进的定量结果。

##### URL
[https://arxiv.org/abs/1509.04186](https://arxiv.org/abs/1509.04186)

##### PDF
[https://arxiv.org/pdf/1509.04186](https://arxiv.org/pdf/1509.04186)

