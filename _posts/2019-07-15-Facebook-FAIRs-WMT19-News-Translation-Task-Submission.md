---
layout: post
title: "Facebook FAIR's WMT19 News Translation Task Submission"
date: 2019-07-15 17:22:54
categories: arXiv_CL
tags: arXiv_CL Face
author: Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, Sergey Edunov
mathjax: true
---

* content
{:toc}

##### Abstract
This paper describes Facebook FAIR's submission to the WMT19 shared news translation task. We participate in two language pairs and four language directions, English &lt;-&gt; German and English &lt;-&gt; Russian. Following our submission from last year, our baseline systems are large BPE-based transformer models trained with the Fairseq sequence modeling toolkit which rely on sampled back-translations. This year we experiment with different bitext data filtering schemes, as well as with adding filtered back-translated data. We also ensemble and fine-tune our models on domain-specific data, then decode using noisy channel model reranking. Our submissions are ranked first in all four directions of the human evaluation campaign. On En-&gt;De, our system significantly outperforms other systems as well as human translations. This system improves upon our WMT'18 submission by 4.5 BLEU points.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.06616](http://arxiv.org/abs/1907.06616)

##### PDF
[http://arxiv.org/pdf/1907.06616](http://arxiv.org/pdf/1907.06616)

