---
layout: post
title: "Natural Language Generation as Planning under Uncertainty Using Reinforcement Learning"
date: 2016-06-15 09:05:56
categories: arXiv_CL
tags: arXiv_CL Face Reinforcement_Learning
author: Verena Rieser, Oliver Lemon
mathjax: true
---

* content
{:toc}

##### Abstract
We present and evaluate a new model for Natural Language Generation (NLG) in Spoken Dialogue Systems, based on statistical planning, given noisy feedback from the current generation context (e.g. a user and a surface realiser). We study its use in a standard NLG problem: how to present information (in this case a set of search results) to users, given the complex trade- offs between utterance length, amount of information conveyed, and cognitive load. We set these trade-offs by analysing existing MATCH data. We then train a NLG pol- icy using Reinforcement Learning (RL), which adapts its behaviour to noisy feed- back from the current generation context. This policy is compared to several base- lines derived from previous work in this area. The learned policy significantly out- performs all the prior approaches.

##### Abstract (translated by Google)
我们提出并评估了口语对话系统中的自然语言生成（NLG）的新模型，基于统计规划，给出当前世代背景（例如用户和表面实现者）的嘈杂反馈。我们研究了它在标准NLG问题中的使用：给定用户的信息（在这种情况下是一组搜索结果），给出了在话语长度，传达的信息量和认知负荷之间的复杂折衷。我们通过分析现有的MATCH数据来设置这些权衡。然后，我们使用强化学习（RL）来训练NLG策略，该策略将其行为适应当前环境中的嘈杂反馈。这一政策与以前在这个领域的工作得出的几条基线进行比较。学到的政策大大超越了以前的所有方法。

##### URL
[https://arxiv.org/abs/1606.04686](https://arxiv.org/abs/1606.04686)

##### PDF
[https://arxiv.org/pdf/1606.04686](https://arxiv.org/pdf/1606.04686)

