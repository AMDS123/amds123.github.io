---
layout: post
title: "Grassmannian Discriminant Maps for Manifold Dimensionality Reduction with Application to Image Set Classification"
date: 2018-06-28 08:50:24
categories: arXiv_CV
tags: arXiv_CV Face Classification Recognition Face_Recognition
author: Rui Wang, Xiao-Jun Wu, Kai-Xuan Chen, Josef Kittler
mathjax: true
---

* content
{:toc}

##### Abstract
In image set classification, a considerable progress has been made by representing original image sets on Grassmann manifolds. In order to extend the advantages of the Euclidean based dimensionality reduction methods to the Grassmann Manifold, several methods have been suggested recently which jointly perform dimensionality reduction and metric learning on Grassmann manifold to improve performance. Nevertheless, when applied to complex datasets, the learned features do not exhibit enough discriminatory power. To overcome this problem, we propose a new method named Grassmannian Discriminant Maps (GDM) for manifold dimensionality reduction problems. The core of the method is a new discriminant function for metric learning and dimensionality reduction. For comparison and better understanding, we also study a simple variations to GDM. The key difference between them is the discriminant function. We experiment on data sets corresponding to three tasks: face recognition, object categorization, and hand gesture recognition to evaluate the proposed method and its simple extensions. Compared with the state of the art, the results achieved show the effectiveness of the proposed algorithm.

##### Abstract (translated by Google)
在图像集分类中，通过在Grassmann流形上表示原始图像集已经取得了相当大的进展。为了将基于欧几里德的降维方法的优点扩展到格拉斯曼流形，最近提出了几种在Grassmann流形上联合执行降维和度量学习以提高性能的方法。尽管如此，当应用于复杂数据集时，学习功能不具有足够的区分能力。为了克服这个问题，我们提出了一种新的格拉斯曼判别映射（Grassmannian Discriminant Maps，GDM）方法用于多维降维问题。该方法的核心是度量学习和降维的一种新的判别函数。为了比较和更好的理解，我们还研究了GDM的一个简单变体。它们之间的关键区别在于判别函数。我们对与三个任务相对应的数据集进行实验：人脸识别，对象分类和手势识别，以评估所提出的方法及其简单扩展。与现有技术相比，所获得的结果显示了所提出算法的有效性。

##### URL
[http://arxiv.org/abs/1806.10830](http://arxiv.org/abs/1806.10830)

##### PDF
[http://arxiv.org/pdf/1806.10830](http://arxiv.org/pdf/1806.10830)

