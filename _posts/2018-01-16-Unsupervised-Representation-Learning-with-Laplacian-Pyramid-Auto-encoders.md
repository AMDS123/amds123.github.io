---
layout: post
title: "Unsupervised Representation Learning with Laplacian Pyramid Auto-encoders"
date: 2018-01-16 14:59:05
categories: arXiv_CV
tags: arXiv_CV CNN Represenation_Learning Classification
author: Qilu Zhao, Zongmin Li
mathjax: true
---

* content
{:toc}

##### Abstract
Scale-space representation has been popular in computer vision community due to its theoretical foundation. The motivation for generating a scale-space representation of a given data set originates from the basic observation that real-world objects are composed of different structures at different scales. Hence, it's reasonable to consider learning features with image pyramids generated by smoothing and down-sampling operations. In this paper we propose Laplacian pyramid auto-encoders, a straightforward modification of the deep convolutional auto-encoder architecture, for unsupervised representation learning. The method uses multiple encoding-decoding sub-networks within a Laplacian pyramid framework to reconstruct the original image and the low pass filtered images. The last layer of each encoding sub-network also connects to an encoding layer of the sub-network in the next level, which aims to reverse the process of Laplacian pyramid generation. Experimental results showed that Laplacian pyramid benefited the classification and reconstruction performance of deep auto-encoder approaches, and batch normalization is critical to get deep auto-encoders approaches to begin learning.

##### Abstract (translated by Google)
尺度空间表示在计算机视觉领域受到理论基础的欢迎。生成给定数据集的尺度空间表示的动机源于基本观察，即真实世界对象由不同尺度的不同结构组成。因此，考虑通过平滑和降采样操作产生的图像金字塔来学习特征是合理的。在本文中，我们提出拉普拉斯金字塔自动编码器，深层卷积自动编码器体系结构的一个直接修改，无监督表示学习。该方法使用拉普拉斯金字塔框架内的多个编码 - 解码子网络来重建原始图像和低通滤波图像。每个编码子网的最后一层还连接到下一级子网的编码层，旨在扭转拉普拉斯金字塔生成的过程。实验结果表明拉普拉斯金字塔有利于深度自动编码器方法的分类和重构性能，而批量规范化对于深度自动编码器方法开始学习至关重要。

##### URL
[http://arxiv.org/abs/1801.05278](http://arxiv.org/abs/1801.05278)

##### PDF
[http://arxiv.org/pdf/1801.05278](http://arxiv.org/pdf/1801.05278)

