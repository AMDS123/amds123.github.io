---
layout: post
title: "Unsupervised Feature Learning for Dense Correspondences across Scenes"
date: 2015-04-23 09:58:37
categories: arXiv_CV
tags: arXiv_CV
author: Chao Zhang, Chunhua Shen, Tingzhi Shen
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a fast, accurate matching method for estimating dense pixel correspondences across scenes. It is a challenging problem to estimate dense pixel correspondences between images depicting different scenes or instances of the same object category. While most such matching methods rely on hand-crafted features such as SIFT, we learn features from a large amount of unlabeled image patches using unsupervised learning. Pixel-layer features are obtained by encoding over the dictionary, followed by spatial pooling to obtain patch-layer features. The learned features are then seamlessly embedded into a multi-layer match- ing framework. We experimentally demonstrate that the learned features, together with our matching model, outperforms state-of-the-art methods such as the SIFT flow, coherency sensitive hashing and the recent deformable spatial pyramid matching methods both in terms of accuracy and computation efficiency. Furthermore, we evaluate the performance of a few different dictionary learning and feature encoding methods in the proposed pixel correspondences estimation framework, and analyse the impact of dictionary learning and feature encoding with respect to the final matching performance.

##### Abstract (translated by Google)
我们提出了一个快速，准确的匹配方法来估计跨场景的密集像素对应。估计描绘不同场景或相同对象类别的实例的图像之间的密集像素对应是具有挑战性的问题。尽管大多数这样的匹配方法依赖于手工制作的特征，例如SIFT，但是我们使用无监督学习来从大量未标记的图像块中学习特征。像素层特征是通过在字典上编码获得的，然后是空间池以获得补丁层特征。然后将学习的功能无缝嵌入到多层匹配框架中。我们通过实验证明，学习的特征和我们的匹配模型一起，在精度和计算效率方面都优于最先进的方法，如SIFT流，相干敏感散列和最近可变形的空间金字塔匹配方法。此外，我们在所提出的像素对应估计框架中评估了几种不同的字典学习和特征编码方法的性能，并分析了字典学习和特征编码对于最终匹配性能的影响。

##### URL
[https://arxiv.org/abs/1501.00642](https://arxiv.org/abs/1501.00642)

##### PDF
[https://arxiv.org/pdf/1501.00642](https://arxiv.org/pdf/1501.00642)

