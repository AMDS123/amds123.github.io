---
layout: post
title: "Learning to Adapt: Meta-Learning for Model-Based Control"
date: 2018-05-30 23:44:09
categories: arXiv_RO
tags: arXiv_RO Reinforcement_Learning
author: Ignasi Clavera, Anusha Nagabandi, Ronald S. Fearing, Pieter Abbeel, Sergey Levine, Chelsea Finn
mathjax: true
---

* content
{:toc}

##### Abstract
Although reinforcement learning methods can achieve impressive results in simulation, the real world presents two major challenges: generating samples is exceedingly expensive, and unexpected perturbations can cause proficient but narrowly-learned policies to fail at test time. In this work, we propose to learn how to quickly and effectively adapt online to new situations as well as to perturbations. To enable sample-efficient meta-learning, we consider learning online adaptation in the context of model-based reinforcement learning. Our approach trains a global model such that, when combined with recent data, the model can be be rapidly adapted to the local context. Our experiments demonstrate that our approach can enable simulated agents to adapt their behavior online to novel terrains, to a crippled leg, and in highly-dynamic environments.

##### Abstract (translated by Google)
虽然强化学习方法可以在仿真中取得令人印象深刻的结果，但真实世界存在两个主要挑战：生成样本非常昂贵，并且意外的扰动可能导致熟练但狭义的学习策略在测试时失败。在这项工作中，我们建议学习如何快速有效地适应在线新环境以及扰动。为了实现高效的元学习，我们考虑在基于模型的强化学习环境中学习在线适应。我们的方法培养了一个全球模型，以便当与最新数据结合使用时，模型可以迅速适应当地情况。我们的实验表明，我们的方法可以使模拟代理能够将他们的行为在线修改为新颖的地形，跛脚的腿以及高度动态的环境。

##### URL
[http://arxiv.org/abs/1803.11347](http://arxiv.org/abs/1803.11347)

##### PDF
[http://arxiv.org/pdf/1803.11347](http://arxiv.org/pdf/1803.11347)

