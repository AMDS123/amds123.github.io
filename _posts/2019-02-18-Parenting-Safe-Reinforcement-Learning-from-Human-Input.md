---
layout: post
title: "Parenting: Safe Reinforcement Learning from Human Input"
date: 2019-02-18 19:10:18
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Christopher Frye, Ilya Feige
mathjax: true
---

* content
{:toc}

##### Abstract
Autonomous agents trained via reinforcement learning present numerous safety concerns: reward hacking, negative side effects, and unsafe exploration, among others. In the context of near-future autonomous agents, operating in environments where humans understand the existing dangers, human involvement in the learning process has proved a promising approach to AI Safety. Here we demonstrate that a precise framework for learning from human input, loosely inspired by the way humans parent children, solves a broad class of safety problems in this context. We show that our Parenting algorithm solves these problems in the relevant AI Safety gridworlds of Leike et al. (2017), that an agent can learn to outperform its parent as it "matures", and that policies learnt through Parenting are generalisable to new environments.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.06766](http://arxiv.org/abs/1902.06766)

##### PDF
[http://arxiv.org/pdf/1902.06766](http://arxiv.org/pdf/1902.06766)

