---
layout: post
title: "Learning Better Word Embedding by Asymmetric Low-Rank Projection of Knowledge Graph"
date: 2015-06-14 08:21:24
categories: arXiv_CL
tags: arXiv_CL Knowledge_Graph Knowledge Embedding Relation
author: Fei Tian, Bin Gao, Enhong Chen, Tie-Yan Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Word embedding, which refers to low-dimensional dense vector representations of natural words, has demonstrated its power in many natural language processing tasks. However, it may suffer from the inaccurate and incomplete information contained in the free text corpus as training data. To tackle this challenge, there have been quite a few works that leverage knowledge graphs as an additional information source to improve the quality of word embedding. Although these works have achieved certain success, they have neglected some important facts about knowledge graphs: (i) many relationships in knowledge graphs are \emph{many-to-one}, \emph{one-to-many} or even \emph{many-to-many}, rather than simply \emph{one-to-one}; (ii) most head entities and tail entities in knowledge graphs come from very different semantic spaces. To address these issues, in this paper, we propose a new algorithm named ProjectNet. ProjecNet models the relationships between head and tail entities after transforming them with different low-rank projection matrices. The low-rank projection can allow non \emph{one-to-one} relationships between entities, while different projection matrices for head and tail entities allow them to originate in different semantic spaces. The experimental results demonstrate that ProjectNet yields more accurate word embedding than previous works, thus leads to clear improvements in various natural language processing tasks.

##### Abstract (translated by Google)
词嵌入指的是自然语言的低维密集向量表示，在许多自然语言处理任务中已经证明了它的能力。但是，自由文本语料库中包含的不准确和不完整的信息可能会作为训练数据受到影响。为了应对这一挑战，已经有相当多的作品利用知识图作为附加信息来提高词嵌入的质量。尽管这些作品取得了一定的成功，但他们忽略了关于知识图的一些重要事实：（i）知识图中的许多关系是“多对一”，“一对多”或甚至是“一对多” {多对多}，而不仅仅是\ emph {one-to-one}; （ii）知识图中的大多数头部实体和尾部实体来自非常不同的语义空间。为了解决这些问题，在本文中，我们提出了一个名为ProjectNet的新算法。 ProjecNet在用不同的低秩投影矩阵对它们进行变换之后对头部和尾部实体之间的关系进行建模。低秩投影可以允许实体之间的非一对一（one-to-one）关系，而头尾实体的不同投影矩阵允许它们起源于不同的语义空间。实验结果表明ProjectNet比以前的作品能够产生更精确的词嵌入，从而导致各种自然语言处理任务的明显改进。

##### URL
[https://arxiv.org/abs/1505.04891](https://arxiv.org/abs/1505.04891)

##### PDF
[https://arxiv.org/pdf/1505.04891](https://arxiv.org/pdf/1505.04891)

