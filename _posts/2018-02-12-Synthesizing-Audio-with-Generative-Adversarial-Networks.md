---
layout: post
title: "Synthesizing Audio with Generative Adversarial Networks"
date: 2018-02-12 17:50:43
categories: arXiv_SD
tags: arXiv_SD Adversarial GAN
author: Chris Donahue, Julian McAuley, Miller Puckette
mathjax: true
---

* content
{:toc}

##### Abstract
While Generative Adversarial Networks (GANs) have seen wide success at the problem of synthesizing realistic images, they have seen little application to the problem of unsupervised audio generation. Unlike for images, a barrier to success is that the best discriminative representations for audio tend to be non-invertible, and thus cannot be used to synthesize listenable outputs. In this paper, we introduce WaveGAN, a first attempt at applying GANs to raw audio synthesis in an unsupervised setting. Our experiments on speech demonstrate that WaveGAN can produce intelligible words from a small vocabulary of human speech, as well as synthesize audio from other domains such as bird vocalizations, drums, and piano. Qualitatively, we find that human judges prefer the generated examples from WaveGAN over those from a method which naively apply GANs on image-like audio feature representations.

##### Abstract (translated by Google)
虽然生成对抗网络（GAN）在合成逼真图像的问题上取得了广泛的成功，但它们在无监督音频生成问题上几乎没有应用。与图像不同，成功的障碍在于音频的最佳区别表示法往往是不可逆的，因此不能用于合成可收听的输出。在本文中，我们介绍了WaveGAN，这是第一次尝试将GAN应用于原始音频合成中的无监督设置。我们的演讲实验表明，WaveGAN可以从人类言语的小词汇中产生可理解的词汇，并且可以合成来自其他领域的音频，如鸟鸣，鼓和钢琴。定性地说，我们发现人类法官更喜欢WaveGAN生成的例子，而不是那些天真地将GAN应用于类似图像的音频特征表示的方法。

##### URL
[http://arxiv.org/abs/1802.04208](http://arxiv.org/abs/1802.04208)

##### PDF
[http://arxiv.org/pdf/1802.04208](http://arxiv.org/pdf/1802.04208)

