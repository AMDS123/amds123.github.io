---
layout: post
title: "Deep RTS: A Game Environment for Deep Reinforcement Learning in Real-Time Strategy Games"
date: 2018-08-15 10:30:41
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning CNN
author: Per-Arne Andersen, Morten Goodwin, Ole-Christoffer Granmo
mathjax: true
---

* content
{:toc}

##### Abstract
Reinforcement learning (RL) is an area of research that has blossomed tremendously in recent years and has shown remarkable potential for artificial intelligence based opponents in computer games. This success is primarily due to the vast capabilities of convolutional neural networks, that can extract useful features from noisy and complex data. Games are excellent tools to test and push the boundaries of novel RL algorithms because they give valuable insight into how well an algorithm can perform in isolated environments without the real-life consequences. Real-time strategy games (RTS) is a genre that has tremendous complexity and challenges the player in short and long-term planning. There is much research that focuses on applied RL in RTS games, and novel advances are therefore anticipated in the not too distant future. However, there are to date few environments for testing RTS AIs. Environments in the literature are often either overly simplistic, such as microRTS, or complex and without the possibility for accelerated learning on consumer hardware like StarCraft II. This paper introduces the Deep RTS game environment for testing cutting-edge artificial intelligence algorithms for RTS games. Deep RTS is a high-performance RTS game made specifically for artificial intelligence research. It supports accelerated learning, meaning that it can learn at a magnitude of 50 000 times faster compared to existing RTS games. Deep RTS has a flexible configuration, enabling research in several different RTS scenarios, including partially observable state-spaces and map complexity. We show that Deep RTS lives up to our promises by comparing its performance with microRTS, ELF, and StarCraft II on high-end consumer hardware. Using Deep RTS, we show that a Deep Q-Network agent beats random-play agents over 70% of the time. Deep RTS is publicly available at https://github.com/cair/DeepRTS.

##### Abstract (translated by Google)
强化学习（RL）是近年来蓬勃发展的一个研究领域，并且已经在计算机游戏中以人工智能为基础的对手显示出巨大的潜力。这种成功主要归功于卷积神经网络的巨大能力，它可以从嘈杂和复杂的数据中提取有用的特征。游戏是测试和推动新型RL算法边界的优秀工具，因为它们可以提供有价值的洞察力，了解算法在隔离环境中的性能，而不会产生实际后果。实时战略游戏（RTS）是一种具有巨大复杂性的类型，并且在短期和长期规划中挑战玩家。有许多研究侧重于RTS游戏中的应用RL，因此预计在不久的将来会有新的进步。但是，迄今为止，很少有用于测试RTS AI的环境。文献中的环境通常过于简单化，例如microRTS，或者复杂，并且没有像星际争霸II那样加速学习消费者硬件的可能性。本文介绍了Deep RTS游戏环境，用于测试RTS游戏的尖端人工智能算法。 Deep RTS是一款专为人工智能研究而设计的高性能RTS游戏。它支持加速学习，这意味着与现有的RTS游戏相比，它可以以5万倍的速度学习。 Deep RTS具有灵活的配置，可以在几种不同的RTS场景中进行研究，包括部分可观察的状态空间和地图复杂性。我们通过将其性能与microRTS，ELF和StarCraft II在高端消费硬件上进行比较，表明Deep RTS符合我们的承诺。使用Deep RTS，我们发现Deep Q-Network代理在70％的时间内击败了随机播放代理。 Deep RTS可在https://github.com/cair/DeepRTS上公开获取。

##### URL
[http://arxiv.org/abs/1808.05032](http://arxiv.org/abs/1808.05032)

##### PDF
[http://arxiv.org/pdf/1808.05032](http://arxiv.org/pdf/1808.05032)

