---
layout: post
title: "Visual gesture variability between talkers in continuous visual speech"
date: 2017-10-03 17:59:43
categories: arXiv_CV
tags: arXiv_CV Knowledge Deep_Learning Recognition
author: Helen L Bear
mathjax: true
---

* content
{:toc}

##### Abstract
Recent adoption of deep learning methods to the field of machine lipreading research gives us two options to pursue to improve system performance. Either, we develop end-to-end systems holistically or, we experiment to further our understanding of the visual speech signal. The latter option is more difficult but this knowledge would enable researchers to both improve systems and apply the new knowledge to other domains such as speech therapy. One challenge in lipreading systems is the correct labeling of the classifiers. These labels map an estimated function between visemes on the lips and the phonemes uttered. Here we ask if such maps are speaker-dependent? Prior work investigated isolated word recognition from speaker-dependent (SD) visemes, we extend this to continuous speech. Benchmarked against SD results, and the isolated words performance, we test with RMAV dataset speakers and observe that with continuous speech, the trajectory between visemes has a greater negative effect on the speaker differentiation.

##### Abstract (translated by Google)
最近在机器唇线研究领域采用深度学习方法为我们提供了两种方法来改善系统性能。要么我们全面开发端到端的系统，要么尝试进一步理解视觉语音信号。后一种选择更加困难，但是这种知识将使研究人员既能改进系统，又能将新知识应用到语言治疗等其他领域。在唇读系统中的一个挑战是分类器的正确标签。这些标签映射嘴唇上的视位与所发音素之间的估计函数。这里我们问这些地图是否依赖于说话者？之前的研究从独立于说话者（SD）的视角研究孤立的单词识别，我们将其扩展为连续的语音。基于SD结果的标杆，以及孤立词的表现，我们使用RMAV数据集说话者进行测试，并观察到在连续语音的情况下，视距之间的轨迹对说话者分化具有更大的负面影响。

##### URL
[https://arxiv.org/abs/1710.01297](https://arxiv.org/abs/1710.01297)

##### PDF
[https://arxiv.org/pdf/1710.01297](https://arxiv.org/pdf/1710.01297)

