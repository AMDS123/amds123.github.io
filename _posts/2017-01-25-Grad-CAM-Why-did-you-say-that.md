---
layout: post
title: "Grad-CAM: Why did you say that?"
date: 2017-01-25 16:33:29
categories: arXiv_CV
tags: arXiv_CV Image_Caption QA Caption CNN Prediction Relation VQA
author: Ramprasaath R Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell, Devi Parikh, Dhruv Batra
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a technique for making Convolutional Neural Network (CNN)-based models more transparent by visualizing input regions that are 'important' for predictions -- or visual explanations. Our approach, called Gradient-weighted Class Activation Mapping (Grad-CAM), uses class-specific gradient information to localize important regions. These localizations are combined with existing pixel-space visualizations to create a novel high-resolution and class-discriminative visualization called Guided Grad-CAM. These methods help better understand CNN-based models, including image captioning and visual question answering (VQA) models. We evaluate our visual explanations by measuring their ability to discriminate between classes, to inspire trust in humans, and their correlation with occlusion maps. Grad-CAM provides a new way to understand CNN-based models. We have released code, an online demo hosted on CloudCV, and a full version of this extended abstract.

##### Abstract (translated by Google)
我们提出了一种技术，使基于卷积神经网络（CNN）的模型更加透明，可视化输入区域对于预测“重要”或视觉解释。我们的方法称为梯度加权类激活映射（Grad-CAM），它使用类特定梯度信息来定位重要区域。这些定位与现有的像素空间可视化相结合，以创建一种新的高分辨率和类别判别式可视化，称为引导渐变CAM。这些方法有助于更好地理解基于CNN的模型，包括图像字幕和视觉问答（VQA）模型。我们评估我们的视觉解释，通过测量他们之间的歧视能力，激发人类的信任，以及他们与遮挡地图的相关性。 Grad-CAM为理解基于CNN的模型提供了一种新的方法。我们已经发布了代码，一个在CloudCV上托管的在线演示，以及这个扩展摘要的完整版本。

##### URL
[https://arxiv.org/abs/1611.07450](https://arxiv.org/abs/1611.07450)

##### PDF
[https://arxiv.org/pdf/1611.07450](https://arxiv.org/pdf/1611.07450)

