---
layout: post
title: "Grad-CAM: Why did you say that?"
date: 2017-01-25 16:33:29
categories: arXiv_CV
tags: arXiv_CV Image_Caption QA Caption CNN Prediction Relation VQA
author: Ramprasaath R Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell, Devi Parikh, Dhruv Batra
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a technique for making Convolutional Neural Network (CNN)-based models more transparent by visualizing input regions that are 'important' for predictions -- or visual explanations. Our approach, called Gradient-weighted Class Activation Mapping (Grad-CAM), uses class-specific gradient information to localize important regions. These localizations are combined with existing pixel-space visualizations to create a novel high-resolution and class-discriminative visualization called Guided Grad-CAM. These methods help better understand CNN-based models, including image captioning and visual question answering (VQA) models. We evaluate our visual explanations by measuring their ability to discriminate between classes, to inspire trust in humans, and their correlation with occlusion maps. Grad-CAM provides a new way to understand CNN-based models. We have released code, an online demo hosted on CloudCV, and a full version of this extended abstract.

##### Abstract (translated by Google)
我们提出了一种技术，通过可视化对预测“重要”的输入区域或视觉解释，使基于卷积神经网络（CNN）的模型更加透明。我们的方法称为梯度加权类激活映射（Grad-CAM），使用特定于类的梯度信息来定位重要区域。这些本地化与现有的像素空间可视化相结合，创建了一种新颖的高分辨率和类辨别可视化，称为Guided Grad-CAM。这些方法有助于更好地理解基于CNN的模型，包括图像字幕和视觉问答（VQA）模型。我们通过测量他们区分不同类别的能力，激发对人类的信任以及它们与遮挡图的相关性来评估我们的视觉解释。 Grad-CAM提供了一种理解基于CNN的模型的新方法。我们已经发布了代码，在CloudCV上托管的在线演示，以及此扩展摘要的完整版本。

##### URL
[https://arxiv.org/abs/1611.07450](https://arxiv.org/abs/1611.07450)

##### PDF
[https://arxiv.org/pdf/1611.07450](https://arxiv.org/pdf/1611.07450)

