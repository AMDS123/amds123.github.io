---
layout: post
title: "Low-Shot Learning from Imaginary Data"
date: 2018-01-16 18:38:35
categories: arXiv_CV
tags: arXiv_CV Classification
author: Yu-Xiong Wang, Ross Girshick, Martial Hebert, Bharath Hariharan
mathjax: true
---

* content
{:toc}

##### Abstract
Humans can quickly learn new visual concepts, perhaps because they can easily visualize or imagine what novel objects look like from different views. Incorporating this ability to hallucinate novel instances of new concepts might help machine vision systems perform better low-shot learning, i.e., learning concepts from few examples. We present a novel approach to low-shot learning that uses this idea. Our approach builds on recent progress in meta-learning ("learning to learn") by combining a meta-learner with a "hallucinator" that produces additional training examples, and optimizing both models jointly. Our hallucinator can be incorporated into a variety of meta-learners and provides significant gains: up to a 6 point boost in classification accuracy when only a single training example is available, yielding state-of-the-art performance on the challenging ImageNet low-shot classification benchmark.

##### Abstract (translated by Google)
人类可以快速学习新的视觉概念，也许是因为他们可以很容易地从不同的角度想象或想象新颖的物体。结合这种能力来幻觉新概念的新实例可能有助于机器视觉系统执行更好的低射击学习，即从少数例子中学习概念。我们提出一个新颖的方法来使用这个想法低射击学习。我们的方法建立在元学习（“学习学习”）的最新进展上，将元学习者与产生额外训练样例的“幻觉者”相结合，并共同优化两种模型。我们的幻觉者可以被整合到各种元学习者中，并提供显着的收益：当只有一个训练样例时，分类精度提高了6个点，在具有挑战性的ImageNet低成本解决方案上产生了最先进的性能，镜头分类基准。

##### URL
[http://arxiv.org/abs/1801.05401](http://arxiv.org/abs/1801.05401)

##### PDF
[http://arxiv.org/pdf/1801.05401](http://arxiv.org/pdf/1801.05401)

