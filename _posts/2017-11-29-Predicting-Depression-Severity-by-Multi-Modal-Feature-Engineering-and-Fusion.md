---
layout: post
title: "Predicting Depression Severity by Multi-Modal Feature Engineering and Fusion"
date: 2017-11-29 23:39:43
categories: arXiv_CV
tags: arXiv_CV
author: Aven Samareh, Yan Jin, Zhangyang Wang, Xiangyu Chang, Shuai Huang
mathjax: true
---

* content
{:toc}

##### Abstract
We present our preliminary work to determine if patient's vocal acoustic, linguistic, and facial patterns could predict clinical ratings of depression severity, namely Patient Health Questionnaire depression scale (PHQ-8). We proposed a multi modal fusion model that combines three different modalities: audio, video , and text features. By training over AVEC 2017 data set, our proposed model outperforms each single modality prediction model, and surpasses the data set baseline with ice margin.

##### Abstract (translated by Google)
我们目前的初步工作，以确定病人的声音，语言和面部模式可以预测抑郁症严重程度的临床评分，即病人健康问卷抑郁量表（PHQ-8）。我们提出了一种多模式融合模型，它结合了三种不同的模式：音频，视频和文本特征。通过对AVEC 2017数据集进行训练，我们提出的模型优于每个单一的模态预测模型，并且超过了具有冰缘的数据集基线。

##### URL
[https://arxiv.org/abs/1711.11155](https://arxiv.org/abs/1711.11155)

