---
layout: post
title: 'Multimodal Storytelling via Generative Adversarial Imitation Learning'
date: 2017-12-05 02:51:35
categories: arXiv_CL
tags: arXiv_CL Adversarial GAN
author: Zhiqian Chen, Xuchao Zhang, Arnold P. Boedihardjo, Jing Dai, Chang-Tien Lu
---

* content
{:toc}

##### Abstract
Deriving event storylines is an effective summarization method to succinctly organize extensive information, which can significantly alleviate the pain of information overload. The critical challenge is the lack of widely recognized definition of storyline metric. Prior studies have developed various approaches based on different assumptions about users' interests. These works can extract interesting patterns, but their assumptions do not guarantee that the derived patterns will match users' preference. On the other hand, their exclusiveness of single modality source misses cross-modality information. This paper proposes a method, multimodal imitation learning via generative adversarial networks(MIL-GAN), to directly model users' interests as reflected by various data. In particular, the proposed model addresses the critical challenge by imitating users' demonstrated storylines. Our proposed model is designed to learn the reward patterns given user-provided storylines and then applies the learned policy to unseen data. The proposed approach is demonstrated to be capable of acquiring the user's implicit intent and outperforming competing methods by a substantial margin with a user study.

##### Abstract (translated by Google)
导出事件故事情节是一种有效的概括方法，可以简洁的组织大量的信息，显着减轻信息过载的痛苦。关键的挑战是缺乏广为认可的故事情节度量的定义。之前的研究已经基于对用户兴趣的不同假设开发了各种方法。这些作品可以提取有趣的模式，但是他们的假设并不能保证派生模式将匹配用户的偏好。另一方面，它们对单一模态源的排他性却忽略了交叉模态信息。本文提出了一种通过生成对抗网络（MIL-GAN）进行多模态学习的方法，可以直接模拟各种数据反映的用户兴趣。特别是，所提出的模型通过模仿用户展示的故事情节来解决关键的挑战。我们提出的模型旨在学习用户提供的故事情节的奖励模式，然后将学习到的策略应用于看不见的数据。所提出的方法被证明能够通过用户研究以相当大的余量获得用户的隐含意图并优于竞争方法。

##### URL
[http://arxiv.org/abs/1712.01455](http://arxiv.org/abs/1712.01455)

