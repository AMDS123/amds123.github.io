---
layout: post
title: "Improved Explainability of Capsule Networks: Relevance Path by Agreement"
date: 2018-02-27 23:08:17
categories: arXiv_CV
tags: arXiv_CV CNN Deep_Learning
author: Atefeh Shahroudnejad, Arash Mohammadi, Konstantinos N. Plataniotis
mathjax: true
---

* content
{:toc}

##### Abstract
Recent advancements in signal processing and machine learning domains have resulted in an extensive surge of interest in deep learning models due to their unprecedented performance and high accuracy for different and challenging problems of significant engineering importance. However, when such deep learning architectures are utilized for making critical decisions such as the ones that involve human lives (e.g., in medical applications), it is of paramount importance to understand, trust, and in one word "explain" the rational behind deep models' decisions. Currently, deep learning models are typically considered as black-box systems, which do not provide any clue on their internal processing actions. Although some recent efforts have been initiated to explain behavior and decisions of deep networks, explainable artificial intelligence (XAI) domain is still in its infancy. In this regard, we consider capsule networks (referred to as CapsNets), which are novel deep structures; recently proposed as an alternative counterpart to convolutional neural networks (CNNs), and posed to change the future of machine intelligence. In this paper, we investigate and analyze structures and behaviors of the CapsNets and illustrate potential explainability properties of such networks. Furthermore, we show possibility of transforming deep learning architectures in to transparent networks via incorporation of capsules in different layers instead of convolution layers of the CNNs.

##### Abstract (translated by Google)
信号处理和机器学习领域的最新进展已经引起对深度学习模型的广泛兴趣，因为它们对于具有重要工程重要性的不同和具有挑战性的问题具有前所未有的性能和高精度。然而，当这种深度学习架构被用于做出关键决策时，例如涉及人类生命的决策（例如，在医疗应用中）时，理解，信任以及用一个词“解释”深处的理性是至关重要的模型的决定。目前，深度学习模型通常被认为是黑盒系统，它们不能提供关于其内部处理行为的任何线索。尽管最近一些努力已经开始解释深层网络的行为和决策，但可解释的人工智能（XAI）领域仍处于起步阶段。在这方面，我们考虑胶囊网络（简称CapsNets），这是新颖的深层结构;最近被提议作为卷积神经网络（CNN）的备选对应物，并提出改变机器智能的未来。在本文中，我们调查和分析CapsNets的结构和行为，并说明这些网络的潜在可解释性特性。此外，我们展示了通过将胶囊并入不同层而不是CNN的卷积层来将深度学习体系结构转变为透明网络的可能性。

##### URL
[http://arxiv.org/abs/1802.10204](http://arxiv.org/abs/1802.10204)

##### PDF
[http://arxiv.org/pdf/1802.10204](http://arxiv.org/pdf/1802.10204)

