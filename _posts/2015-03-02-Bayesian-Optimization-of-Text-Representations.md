---
layout: post
title: "Bayesian Optimization of Text Representations"
date: 2015-03-02 20:23:18
categories: arXiv_SD
tags: arXiv_SD Sentiment Optimization Classification
author: Dani Yogatama, Noah A. Smith
mathjax: true
---

* content
{:toc}

##### Abstract
When applying machine learning to problems in NLP, there are many choices to make about how to represent input texts. These choices can have a big effect on performance, but they are often uninteresting to researchers or practitioners who simply need a module that performs well. We propose an approach to optimizing over this space of choices, formulating the problem as global optimization. We apply a sequential model-based optimization technique and show that our method makes standard linear models competitive with more sophisticated, expensive state-of-the-art methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems. Our approach is a first step towards black-box NLP systems that work with raw text and do not require manual tuning.

##### Abstract (translated by Google)
将机器学习应用于NLP中的问题时，如何表示输入文本有很多选择。这些选择可能会对性能产生重大影响，但对于只需要一个性能良好的模块的研究人员或从业人员来说，这些选择通常是不感兴趣的。我们提出了一个在这个选择空间上进行优化的方法，将问题定义为全局优化。我们应用了一种基于序列模型的优化技术，并表明我们的方法使标准线性模型与基于潜在变量模型或神经网络的更复杂，更昂贵的最先进方法竞争各种主题分类和情感分析问题。我们的方法是使用原始文本并且不需要手动调整的黑盒NLP系统的第一步。

##### URL
[https://arxiv.org/abs/1503.00693](https://arxiv.org/abs/1503.00693)

##### PDF
[https://arxiv.org/pdf/1503.00693](https://arxiv.org/pdf/1503.00693)

