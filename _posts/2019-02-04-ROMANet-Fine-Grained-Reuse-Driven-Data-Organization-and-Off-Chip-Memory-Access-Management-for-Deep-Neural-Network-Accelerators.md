---
layout: post
title: "ROMANet: Fine-Grained Reuse-Driven Data Organization and Off-Chip Memory Access Management for Deep Neural Network Accelerators"
date: 2019-02-04 20:04:37
categories: arXiv_CV
tags: arXiv_CV GAN CNN Inference
author: Rachmad Vidya Wicaksana Putra, Muhammad Abdullah Hanif, Muhammad Shafique
mathjax: true
---

* content
{:toc}

##### Abstract
Many hardware accelerators have been proposed to improve the computational efficiency of the inference process in deep neural networks (DNNs). However, off-chip memory accesses, being the most energy consuming operation in such architectures, limit the designs from achieving efficiency gains at the full potential. Towards this, we propose ROMANet, a methodology to investigate efficient dataflow patterns for reducing the number of the off-chip accesses. ROMANet adaptively determine the data reuse patterns for each convolutional layer of a network by considering the reuse factor of weights, input activations, and output activations. It also considers the data mapping inside off-chip memory to reduce row buffer misses and increase parallelism. Our experimental results show that ROMANet methodology is able to achieve up to 50% dynamic energy savings in state-of-the-art DNN accelerators.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1902.10222](https://arxiv.org/abs/1902.10222)

##### PDF
[https://arxiv.org/pdf/1902.10222](https://arxiv.org/pdf/1902.10222)

