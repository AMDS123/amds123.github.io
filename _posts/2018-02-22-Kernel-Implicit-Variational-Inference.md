---
layout: post
title: "Kernel Implicit Variational Inference"
date: 2018-02-22 13:49:00
categories: arXiv_AI
tags: arXiv_AI Attention Face Inference Classification
author: Jiaxin Shi, Shengyang Sun, Jun Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
Recent progress in variational inference has paid much attention to the flexibility of variational posteriors. One promising direction is to use implicit distributions, i.e., distributions without tractable densities as the variational posterior. However, existing methods on implicit posteriors still face challenges of noisy estimation and computational infeasibility when applied to models with high-dimensional latent variables. In this paper, we present a new approach named Kernel Implicit Variational Inference that addresses these challenges. As far as we know, for the first time implicit variational inference is successfully applied to Bayesian neural networks, which shows promising results on both regression and classification tasks.

##### Abstract (translated by Google)
变分推断的最新进展已经引起了变分后验的灵活性。一个有希望的方向是使用隐式分布，即不具有易处理密度的分布作为变分后验。然而，当应用于具有高维潜变量的模型时，现有的隐式后验方法仍然面临着噪声估计和计算不可行性的挑战。在本文中，我们提出了一种新的方法，称为核心隐式变分推理，以解决这些挑战。据我们所知，隐式变分推理首次成功地应用于贝叶斯神经网络，这对于回归和分类任务都显示出有希望的结果。

##### URL
[http://arxiv.org/abs/1705.10119](http://arxiv.org/abs/1705.10119)

##### PDF
[http://arxiv.org/pdf/1705.10119](http://arxiv.org/pdf/1705.10119)

