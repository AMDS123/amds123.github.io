---
layout: post
title: "Statistics of Deep Generated Images"
date: 2017-08-11 06:53:14
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN CNN Deep_Learning
author: Yu Zeng, Huchuan Lu, Ali Borji
mathjax: true
---

* content
{:toc}

##### Abstract
Here, we explore the low-level statistics of images generated by state-of-the-art deep generative models. First, Wasserstein generative adversarial network (WGAN) and deep convolutional generative adversarial network (DCGAN) are trained on the ImageNet dataset and a large set of cartoon frames from animations. Then, for images generated by these models as well as natural scenes and cartoons, statistics including mean power spectrum, the number of connected components in a given image area, distribution of random filter responses, and contrast distribution are computed. Our analyses on training images support current findings on scale invariance, non-Gaussianity, and Weibull contrast distribution of natural scenes. We find that although similar results hold over cartoon images, there is still a significant difference between statistics of natural scenes and images generated by both DCGAN and WGAN models. In particular, generated images do not have scale invariant mean power spectrum magnitude, which indicates existence of extra structures in these images caused by deconvolution operations. We also find that replacing deconvolution layers in the deep generative models by sub-pixel convolution helps them generate images with a mean power spectrum more similar to the mean power spectrum of natural images. Inspecting how well the statistics of deep generated images match the known statistical properties of natural images, such as scale invariance, non-Gaussianity, and Weibull contrast distribution, can a) reveal the degree to which deep learning models capture the essence of the natural scenes, b) provide a new dimension to evaluate models, and c) allow possible improvement of image generative models (e.g., via defining new loss functions).

##### Abstract (translated by Google)
在这里，我们探索由最先进的深度生成模型生成的图像的低级统计。首先，在ImageNet数据集和来自动画的大量动画帧上训练Wasserstein生成对抗网络（WGAN）和深度卷积生成对抗网络（DCGAN）。然后，对于由这些模型生成的图像以及自然场景和漫画，计算包括平均功率谱，给定图像区域中的连通分量的数量，随机滤波器响应的分布和对比度分布的统计量。我们对训练图像的分析支持关于自然场景的尺度不变性，非高斯性和威布尔对比度分布的当前发现。我们发现尽管类似的结果在卡通图像上仍然存在，但是由DCGAN和WGAN模型生成的自然场景和图像统计数据仍然存在显着差异。特别地，生成的图像没有尺度不变的平均功率谱幅度，这表明由去卷积操作引起的这些图像中存在额外的结构。我们还发现，通过亚像元卷积替代深生成模型中的去卷积层有助于它们生成具有与自然图像的平均功率谱更相似的平均功率谱的图像。检查深度生成图像的统计量与已知的自然图像的统计特性（例如尺度不变性，非高斯性和威布尔对比度分布）的匹配程度如何，可以a）揭示深度学习模型捕捉自然场景的本质，b）为评估模型提供了新的维度，c）允许图像生成模型的可能改进（例如，通过定义新的损失函数）。

##### URL
[https://arxiv.org/abs/1708.02688](https://arxiv.org/abs/1708.02688)

##### PDF
[https://arxiv.org/pdf/1708.02688](https://arxiv.org/pdf/1708.02688)

