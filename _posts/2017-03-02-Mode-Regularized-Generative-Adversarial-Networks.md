---
layout: post
title: "Mode Regularized Generative Adversarial Networks"
date: 2017-03-02 06:28:13
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Tong Che, Yanran Li, Athul Paul Jacob, Yoshua Bengio, Wenjie Li
mathjax: true
---

* content
{:toc}

##### Abstract
Although Generative Adversarial Networks achieve state-of-the-art results on a variety of generative tasks, they are regarded as highly unstable and prone to miss modes. We argue that these bad behaviors of GANs are due to the very particular functional shape of the trained discriminators in high dimensional spaces, which can easily make training stuck or push probability mass in the wrong direction, towards that of higher concentration than that of the data generating distribution. We introduce several ways of regularizing the objective, which can dramatically stabilize the training of GAN models. We also show that our regularizers can help the fair distribution of probability mass across the modes of the data generating distribution, during the early phases of training and thus providing a unified solution to the missing modes problem.

##### Abstract (translated by Google)
虽然生成敌对网络在各种生成任务上获得了最新的结果，但它们被认为是非常不稳定的，并且容易丢失模式。我们认为，GAN的这些不良行为是由于高维空间中被训练的鉴别器的非常特殊的功能形状造成的，它可能容易使得训练卡住或推动概率质量在错误的方向上朝向高于数据的浓度生成分配。我们介绍几种调整目标的方法，可以显着地稳定GAN模型的训练。我们还表明，在训练的早期阶段，我们的调整者可以在数据生成分布的模式中帮助概率质量的公平分布，从而为缺失模式问题提供统一的解决方案。

##### URL
[https://arxiv.org/abs/1612.02136](https://arxiv.org/abs/1612.02136)

##### PDF
[https://arxiv.org/pdf/1612.02136](https://arxiv.org/pdf/1612.02136)

