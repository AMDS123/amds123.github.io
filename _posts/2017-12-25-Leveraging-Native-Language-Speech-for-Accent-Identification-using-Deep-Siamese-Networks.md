---
layout: post
title: "Leveraging Native Language Speech for Accent Identification using Deep Siamese Networks"
date: 2017-12-25 02:28:32
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition Classification Recognition
author: Aditya Siddhant, Preethi Jyothi, Sriram Ganapathy
mathjax: true
---

* content
{:toc}

##### Abstract
The problem of automatic accent identification is important for several applications like speaker profiling and recognition as well as for improving speech recognition systems. The accented nature of speech can be primarily attributed to the influence of the speaker's native language on the given speech recording. In this paper, we propose a novel accent identification system whose training exploits speech in native languages along with the accented speech. Specifically, we develop a deep Siamese network-based model which learns the association between accented speech recordings and the native language speech recordings. The Siamese networks are trained with i-vector features extracted from the speech recordings using either an unsupervised Gaussian mixture model (GMM) or a supervised deep neural network (DNN) model. We perform several accent identification experiments using the CSLU Foreign Accented English (FAE) corpus. In these experiments, our proposed approach using deep Siamese networks yield significant relative performance improvements of 15.4 percent on a 10-class accent identification task, over a baseline DNN-based classification system that uses GMM i-vectors. Furthermore, we present a detailed error analysis of the proposed accent identification system.

##### Abstract (translated by Google)
自动口音识别的问题对于诸如扬声器分析和识别以及用于改进语音识别系统的多个应用是重要的。言语的重音本质可以主要归因于说话者母语对给定语音记录的影响。在本文中，我们提出了一种新的口音识别系统，其训练利用了母语的语音以及重音语音。具体而言，我们开发了一个深度的连体网络模型，学习重音语音记录与母语语音记录之间的关联。使用无监督的高斯混合模型（GMM）或监督的深度神经网络（DNN）模型，利用从语音记录中提取的i矢量特征对连体网络进行训练。我们使用CSLU外语重音英语（FAE）语料库进行多个口音识别实验。在这些实验中，我们提出的使用深度连体网络的方法在基于基于DNN的使用GMM i向量的分类系统上对10类重音识别任务产生显着的相对性能提高，为15.4％。此外，我们提出了一个详细的错误分析建议的口音识别系统。

##### URL
[http://arxiv.org/abs/1712.08992](http://arxiv.org/abs/1712.08992)

##### PDF
[http://arxiv.org/pdf/1712.08992](http://arxiv.org/pdf/1712.08992)

