---
layout: post
title: "Alternating Optimisation and Quadrature for Robust Control"
date: 2017-12-18 10:12:32
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Supratik Paul, Konstantinos Chatzilygeroudis, Kamil Ciosek, Jean-Baptiste Mouret, Michael A. Osborne, Shimon Whiteson
mathjax: true
---

* content
{:toc}

##### Abstract
Bayesian optimisation has been successfully applied to a variety of reinforcement learning problems. However, the traditional approach for learning optimal policies in simulators does not utilise the opportunity to improve learning by adjusting certain environment variables: state features that are unobservable and randomly determined by the environment in a physical setting but are controllable in a simulator. This paper considers the problem of finding a robust policy while taking into account the impact of environment variables. We present Alternating Optimisation and Quadrature (ALOQ), which uses Bayesian optimisation and Bayesian quadrature to address such settings. ALOQ is robust to the presence of significant rare events, which may not be observable under random sampling, but play a substantial role in determining the optimal policy. Experimental results across different domains show that ALOQ can learn more efficiently and robustly than existing methods.

##### Abstract (translated by Google)
贝叶斯优化已成功应用于各种强化学习问题。然而，在模拟器中学习最优策略的传统方法并没有利用机会通过调整某些环境变量来改善学习：在物理环境中由环境随机确定但是在模拟器中可控的状态特征。本文考虑到在考虑到环境变量的影响的同时寻求一个强有力的政策的问题。我们提出交替优化和正交（ALOQ），它使用贝叶斯优化和贝叶斯正交来解决这样的设置。 ALOQ对显着的罕见事件是强有力的，这在随机抽样下可能是不可观察的，但在确定最佳政策方面起着实质性的作用。不同领域的实验结果表明，ALOQ可以比现有方法更高效，更有效地学习。

##### URL
[http://arxiv.org/abs/1605.07496](http://arxiv.org/abs/1605.07496)

##### PDF
[http://arxiv.org/pdf/1605.07496](http://arxiv.org/pdf/1605.07496)

