---
layout: post
title: "Neural Networks and Quantifier Conservativity: Does Data Distribution Affect Learnability?"
date: 2018-09-15 15:44:54
categories: arXiv_CL
tags: arXiv_CL Face
author: Vishwali Mhasawade, Ildik&#xf3; Emese Szab&#xf3;, Melanie Tosik, Sheng-Fu Wang
mathjax: true
---

* content
{:toc}

##### Abstract
All known natural language determiners are conservative. Psycholinguistic experiments indicate that children exhibit a corresponding learnability bias when faced with the task of learning new determiners. However, recent work indicates that this bias towards conservativity is not observed during the training stage of artificial neural networks. In this work, we investigate whether the learnability bias exhibited by children is in part due to the distribution of quantifiers in natural language. We share results of five experiments, contrasted by the distribution of conservative vs. non-conservative determiners in the training data. We demonstrate that the aquisitional issues with non-conservative quantifiers can not be explained by the distribution of natural language data, which favors conservative quantifiers. This finding indicates that the bias in language acquisition data might be innate or representational.

##### Abstract (translated by Google)
所有已知的自然语言决定者都是保守的。心理语言学实验表明，儿童在面对学习新决定者的任务时表现出相应的学习偏差。然而，最近的研究表明，在人工神经网络的训练阶段没有观察到这种对保守性的偏见。在这项工作中，我们调查儿童所表现出的学习偏差是否部分归因于自然语言中量词的分布。我们分享了五个实验的结果，与训练数据中保守与非保守决定者的分布形成对比。我们证明了非保守量词的获取问题不能用自然语言数据的分布来解释，这有利于保守量词。这一发现表明语言习得数据的偏差可能是天生的或具有代表性的。

##### URL
[http://arxiv.org/abs/1809.05733](http://arxiv.org/abs/1809.05733)

##### PDF
[http://arxiv.org/pdf/1809.05733](http://arxiv.org/pdf/1809.05733)

