---
layout: post
title: "Construction of Latent Descriptor Space and Inference Model of Hand-Object Interactions"
date: 2017-09-12 08:34:23
categories: arXiv_CV
tags: arXiv_CV Inference Classification Quantitative Relation Recognition
author: Tadashi Matsuo, Nobutaka Shimada
mathjax: true
---

* content
{:toc}

##### Abstract
Appearance-based generic object recognition is a challenging problem because all possible appearances of objects cannot be registered, especially as new objects are produced every day. Function of objects, however, has a comparatively small number of prototypes. Therefore, function-based classification of new objects could be a valuable tool for generic object recognition. Object functions are closely related to hand-object interactions during handling of a functional object; i.e., how the hand approaches the object, which parts of the object and contact the hand, and the shape of the hand during interaction. Hand-object interactions are helpful for modeling object functions. However, it is difficult to assign discrete labels to interactions because an object shape and grasping hand-postures intrinsically have continuous variations. To describe these interactions, we propose the interaction descriptor space which is acquired from unlabeled appearances of human hand-object interactions. By using interaction descriptors, we can numerically describe the relation between an object's appearance and its possible interaction with the hand. The model infers the quantitative state of the interaction from the object image alone. It also identifies the parts of objects designed for hand interactions such as grips and handles. We demonstrate that the proposed method can unsupervisedly generate interaction descriptors that make clusters corresponding to interaction types. And also we demonstrate that the model can infer possible hand-object interactions.

##### Abstract (translated by Google)
基于外观的通用对象识别是一个具有挑战性的问题，因为所有可能出现的对象都不能被注册，特别是每天都会产生新的对象。然而，物体的功能只有相对较少的原型。因此，基于功能的新对象分类可能是通用对象识别的有价值的工具。对象函数在处理函数对象的过程中与手对象的交互密切相关;即手在接近物体的方式，物体的哪些部分和手接触的方式，以及在相互作用过程中手的形状。手对象交互有助于建模对象功能。然而，由于对象的形状和抓握的手势本质上具有连续的变化，因此将离散的标签分配给交互是困难的。为了描述这些相互作用，我们提出了从未标记的人手对象相互作用的外观获得的交互描述符空间。通过使用交互描述符，我们可以用数字来描述一个对象的外观和它与手的可能交互之间的关系。该模型仅从对象图像推断出交互的定量状态。它还标识了为手部交互而设计的对象的部分，如手柄和手柄。我们证明了所提出的方法可以无监督地产生交互描述符，使得群集对应于交互类型。而且我们还证明该模型可以推断出可能的手对象交互。

##### URL
[https://arxiv.org/abs/1709.03739](https://arxiv.org/abs/1709.03739)

##### PDF
[https://arxiv.org/pdf/1709.03739](https://arxiv.org/pdf/1709.03739)

