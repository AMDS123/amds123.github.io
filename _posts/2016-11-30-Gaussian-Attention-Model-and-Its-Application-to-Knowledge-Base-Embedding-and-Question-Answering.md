---
layout: post
title: "Gaussian Attention Model and Its Application to Knowledge Base Embedding and Question Answering"
date: 2016-11-30 16:44:17
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention Embedding Relation
author: Liwen Zhang, John Winn, Ryota Tomioka
mathjax: true
---

* content
{:toc}

##### Abstract
We propose the Gaussian attention model for content-based neural memory access. With the proposed attention model, a neural network has the additional degree of freedom to control the focus of its attention from a laser sharp attention to a broad attention. It is applicable whenever we can assume that the distance in the latent space reflects some notion of semantics. We use the proposed attention model as a scoring function for the embedding of a knowledge base into a continuous vector space and then train a model that performs question answering about the entities in the knowledge base. The proposed attention model can handle both the propagation of uncertainty when following a series of relations and also the conjunction of conditions in a natural way. On a dataset of soccer players who participated in the FIFA World Cup 2014, we demonstrate that our model can handle both path queries and conjunctive queries well.

##### Abstract (translated by Google)
我们提出了基于内容的神经记忆访问的高斯关注模型。在提出的关注模型中，神经网络具有额外的自由度，以将其关注的焦点从激光锐利的注意力控制到广泛的关注。只要我们可以假设在潜在空间中的距离反映了一些语义的概念，它就适用。我们使用提出的注意模型作为知识库嵌入连续向量空间的评分函数，然后训练一个对知识库中的实体进行问题回答的模型。所提出的关注模型既能处理一系列关系的不确定性传播，又能处理条件的自然结合。在参加2014年FIFA世界杯的足球运动员数据集中，我们证明了我们的模型能够很好地处理路径查询和联合查询。

##### URL
[https://arxiv.org/abs/1611.02266](https://arxiv.org/abs/1611.02266)

##### PDF
[https://arxiv.org/pdf/1611.02266](https://arxiv.org/pdf/1611.02266)

