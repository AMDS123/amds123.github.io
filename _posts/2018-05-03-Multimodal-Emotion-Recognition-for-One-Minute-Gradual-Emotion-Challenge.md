---
layout: post
title: "Multimodal Emotion Recognition for One-Minute-Gradual Emotion Challenge"
date: 2018-05-03 00:10:10
categories: arXiv_CV
tags: arXiv_CV Prediction Relation Recognition
author: Ziqi Zheng, Chenjie Cao, Xingwei Chen, Guoqiang Xu
mathjax: true
---

* content
{:toc}

##### Abstract
The continuous dimensional emotion modelled by arousal and valence can depict complex changes of emotions. In this paper, we present our works on arousal and valence predictions for One-Minute-Gradual (OMG) Emotion Challenge. Multimodal representations are first extracted from videos using a variety of acoustic, video and textual models and support vector machine (SVM) is then used for fusion of multimodal signals to make final predictions. Our solution achieves Concordant Correlation Coefficient (CCC) scores of 0.397 and 0.520 on arousal and valence respectively for the validation dataset, which outperforms the baseline systems with the best CCC scores of 0.15 and 0.23 on arousal and valence by a large margin.

##### Abstract (translated by Google)
以唤起和效价为模型的连续维度情感可以描述情绪的复杂变化。在本文中，我们介绍我们的关于唤醒和价值预测的一分钟渐进（OMG）情绪挑战的作品。首先使用各种声学，视频和文本模型从视频中提取多模态表示，然后将支持向量机（SVM）用于多模态信号的融合以做出最终预测。我们的解决方案对于验证数据集分别在觉醒和价态上获得0.397和0.520的一致相关系数（CCC）得分，其在唤醒和价值上大幅优于CCC得分为0.15和0.23的基线系统。

##### URL
[http://arxiv.org/abs/1805.01060](http://arxiv.org/abs/1805.01060)

##### PDF
[http://arxiv.org/pdf/1805.01060](http://arxiv.org/pdf/1805.01060)

