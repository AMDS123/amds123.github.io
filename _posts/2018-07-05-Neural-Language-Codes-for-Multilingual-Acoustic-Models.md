---
layout: post
title: "Neural Language Codes for Multilingual Acoustic Models"
date: 2018-07-05 12:15:34
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition Recognition
author: Markus M&#xfc;ller, Sebastian St&#xfc;ker, Alex Waibel
mathjax: true
---

* content
{:toc}

##### Abstract
Multilingual Speech Recognition is one of the most costly AI problems, because each language (7,000+) and even different accents require their own acoustic models to obtain best recognition performance. Even though they all use the same phoneme symbols, each language and accent imposes its own coloring or "twang". Many adaptive approaches have been proposed, but they require further training, additional data and generally are inferior to monolingually trained models. In this paper, we propose a different approach that uses a large multilingual model that is \emph{modulated} by the codes generated by an ancillary network that learns to code useful differences between the "twangs" or human language. 
 We use Meta-Pi networks to have one network (the language code net) gate the activity of neurons in another (the acoustic model nets). Our results show that during recognition multilingual Meta-Pi networks quickly adapt to the proper language coloring without retraining or new data, and perform better than monolingually trained networks. The model was evaluated by training acoustic modeling nets and modulating language code nets jointly and optimize them for best recognition performance.

##### Abstract (translated by Google)
多语言语音识别是最昂贵的AI问题之一，因为每种语言（7,000+）甚至不同的口音需要他们自己的声学模型来获得最佳识别性能。即使它们都使用相同的音素符号，每种语言和口音都会强加自己的颜色或“twang”。已经提出了许多自适应方法，但是它们需要进一步的训练，额外的数据并且通常不如单语训练的模型。在本文中，我们提出了一种使用大型多语言模型的不同方法，该模型由辅助网络生成的代码“调制”，该辅助网络学习编码“twangs”或人类语言之间的有用差异。
 我们使用Meta-Pi网络让一个网络（语言代码网）控制另一个网络中的神经元活动（声学模型网）。我们的结果表明，在识别过程中，多语言Meta-Pi网络可以快速适应正确的语言着色而无需重新训练或新数据，并且比单语训练的网络表现更好。通过训练声学建模网和联合调制语言代码网来评估该模型，并优化它们以获得最佳识别性能。

##### URL
[http://arxiv.org/abs/1807.01956](http://arxiv.org/abs/1807.01956)

##### PDF
[http://arxiv.org/pdf/1807.01956](http://arxiv.org/pdf/1807.01956)

