---
layout: post
title: "Balancing Two-Player Stochastic Games with Soft Q-Learning"
date: 2018-02-09 12:03:15
categories: arXiv_AI
tags: arXiv_AI Adversarial Face Reinforcement_Learning
author: Jordi Grau-Moya, Felix Leibfried, Haitham Bou-Ammar
mathjax: true
---

* content
{:toc}

##### Abstract
Within the context of video games the notion of perfectly rational agents can be undesirable as it leads to uninteresting situations, where humans face tough adversarial decision makers. Current frameworks for stochastic games and reinforcement learning prohibit tuneable strategies as they seek optimal performance. In this paper, we enable such tuneable behaviour by generalising soft Q-learning to stochastic games, where more than one agent interact strategically. We contribute both theoretically and empirically. On the theory side, we show that games with soft Q-learning exhibit a unique value and generalise team games and zero-sum games far beyond these two extremes to cover a continuous spectrum of gaming behaviour. Experimentally, we show how tuning agents' constraints affect performance and demonstrate, through a neural network architecture, how to reliably balance games with high-dimensional representations.

##### Abstract (translated by Google)
在视频游戏的背景下，完美理性的代理人的概念可能是不受欢迎的，因为它会导致人们面对强硬的对抗决策者无趣的局面。随机游戏和强化学习的当前框架在寻求最佳性能时禁止可调策略。在本文中，我们通过将软Q学习推广到随机游戏来实现这种可调整行为，在随机游戏中，不止一个代理人在战略上进行交互。我们在理论上和经验上做出贡献。在理论方面，我们表明具有软Q学习的游戏表现出独特的价值，并将团队游戏和零和游戏推广到远远超出这两个极端的范围，以涵盖连续的游戏行为。在实验上，我们展示了调节代理的约束如何影响性能，并通过神经网络架构演示如何可靠地平衡高维表示的游戏。

##### URL
[http://arxiv.org/abs/1802.03216](http://arxiv.org/abs/1802.03216)

##### PDF
[http://arxiv.org/pdf/1802.03216](http://arxiv.org/pdf/1802.03216)

