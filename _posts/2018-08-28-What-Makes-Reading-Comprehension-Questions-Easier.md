---
layout: post
title: "What Makes Reading Comprehension Questions Easier?"
date: 2018-08-28 16:17:43
categories: arXiv_AI
tags: arXiv_AI Knowledge Inference
author: Saku Sugawara, Kentaro Inui, Satoshi Sekine, Akiko Aizawa
mathjax: true
---

* content
{:toc}

##### Abstract
A challenge in creating a dataset for machine reading comprehension (MRC) is to collect questions that require a sophisticated understanding of language to answer beyond using superficial cues. In this work, we investigate what makes questions easier across recent 12 MRC datasets with three question styles (answer extraction, description, and multiple choice). We propose to employ simple heuristics to split each dataset into easy and hard subsets and examine the performance of two baseline models for each of the subsets. We then manually annotate questions sampled from each subset with both validity and requisite reasoning skills to investigate which skills explain the difference between easy and hard questions. From this study, we observed that (i) the baseline performances for the hard subsets remarkably degrade compared to those of entire datasets, (ii) hard questions require knowledge inference and multiple-sentence reasoning in comparison with easy questions, and (iii) multiple-choice questions tend to require a broader range of reasoning skills than answer extraction and description questions. These results suggest that one might overestimate recent advances in MRC.

##### Abstract (translated by Google)
创建机器阅读理解（MRC）数据集的一个挑战是收集需要对语言进行复杂理解的问题，以便在使用肤浅线索之外做出回答。在这项工作中，我们研究了使用三种问题样式（答案提取，描述和多项选择）在最近12个MRC数据集中使问题更容易的问题。我们建议使用简单的启发式方法将每个数据集拆分为简单和硬的子集，并检查每个子集的两个基线模型的性能。然后，我们使用有效性和必要的推理技巧手动注释从每个子集中抽样的问题，以调查哪些技能解释了简单问题和难题之间的区别。从这项研究中，我们观察到（i）与整个数据集相比，硬子集的基线性能显着下降，（ii）与简单问题相比，难题需要知识推理和多句推理，以及（iii）多个选择问题往往需要比答案提取和描述问题更广泛的推理技巧。这些结果表明人们可能高估了MRC的最新进展。

##### URL
[http://arxiv.org/abs/1808.09384](http://arxiv.org/abs/1808.09384)

##### PDF
[http://arxiv.org/pdf/1808.09384](http://arxiv.org/pdf/1808.09384)

