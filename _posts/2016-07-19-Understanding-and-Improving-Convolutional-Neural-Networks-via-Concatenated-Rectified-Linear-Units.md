---
layout: post
title: "Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units"
date: 2016-07-19 05:18:36
categories: arXiv_CV
tags: arXiv_CV CNN Recognition
author: Wenling Shang, Kihyuk Sohn, Diogo Almeida, Honglak Lee
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, convolutional neural networks (CNNs) have been used as a powerful tool to solve many problems of machine learning and computer vision. In this paper, we aim to provide insight on the property of convolutional neural networks, as well as a generic method to improve the performance of many CNN architectures. Specifically, we first examine existing CNN models and observe an intriguing property that the filters in the lower layers form pairs (i.e., filters with opposite phase). Inspired by our observation, we propose a novel, simple yet effective activation scheme called concatenated ReLU (CRelu) and theoretically analyze its reconstruction property in CNNs. We integrate CRelu into several state-of-the-art CNN architectures and demonstrate improvement in their recognition performance on CIFAR-10/100 and ImageNet datasets with fewer trainable parameters. Our results suggest that better understanding of the properties of CNNs can lead to significant performance improvement with a simple modification.

##### Abstract (translated by Google)
最近，卷积神经网络（CNN）被用作解决机器学习和计算机视觉的许多问题的有力工具。在本文中，我们的目的是提供有关卷积神经网络的性质，以及一个通用的方法来提高许多CNN架构的性能。具体而言，我们首先检查现有的CNN模型，并观察下层滤波器形成对（即，具有相反相位的滤波器）的有趣特性。受我们的观察启发，我们提出了一种新颖，简单而有效的激活方案，称为级联ReLU（CRelu），并从理论上分析了它在CNNs中的重构特性。我们将CRelu集成到多个最先进的CNN架构中，并在CIFAR-10/100和ImageNet数据集上识别性能的提高，并减少了可训练参数。我们的结果表明，更好地理解CNN的属性可以通过简单的修改导致显着的性能改进。

##### URL
[https://arxiv.org/abs/1603.05201](https://arxiv.org/abs/1603.05201)

##### PDF
[https://arxiv.org/pdf/1603.05201](https://arxiv.org/pdf/1603.05201)

