---
layout: post
title: "Speaker-adaptive neural vocoders for statistical parametric speech synthesis systems"
date: 2018-11-08 08:26:03
categories: arXiv_SD
tags: arXiv_SD
author: Eunwoo Song, Jinseob Kim, Kyungguen Byun, Hong-Goo Kang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes speaker-adaptive neural vocoders for statistical parametric speech synthesis (SPSS) systems. Recently proposed WaveNet-based neural vocoding systems successfully generate a time sequence of speech signal with an autoregressive framework. However, building high-quality speech synthesis systems with limited training data for a target speaker remains a challenge. To generate more natural speech signals with the constraint of limited training data, we employ a speaker adaptation task with an effective variation of neural vocoding models. In the proposed method, a speaker-independent training method is applied to capture universal attributes embedded in multiple speakers, and the trained model is then fine-tuned to represent the specific characteristics of the target speaker. Experimental results verify that the proposed SPSS systems with speaker-adaptive neural vocoders outperform those with traditional source-filter model-based vocoders and those with WaveNet vocoders, trained either speaker-dependently or speaker-independently.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.03311](http://arxiv.org/abs/1811.03311)

##### PDF
[http://arxiv.org/pdf/1811.03311](http://arxiv.org/pdf/1811.03311)

