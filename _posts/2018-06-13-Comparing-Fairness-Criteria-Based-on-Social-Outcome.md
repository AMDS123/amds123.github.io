---
layout: post
title: "Comparing Fairness Criteria Based on Social Outcome"
date: 2018-06-13 15:34:13
categories: arXiv_AI
tags: arXiv_AI
author: Junpei Komiyama, Hajime Shimao
mathjax: true
---

* content
{:toc}

##### Abstract
Fairness in algorithmic decision-making processes is attracting increasing concern. When an algorithm is applied to human-related decision-making an estimator solely optimizing its predictive power can learn biases on the existing data, which motivates us the notion of fairness in machine learning. while several different notions are studied in the literature, little studies are done on how these notions affect the individuals. We demonstrate such a comparison between several policies induced by well-known fairness criteria, including the color-blind (CB), the demographic parity (DP), and the equalized odds (EO). We show that the EO is the only criterion among them that removes group-level disparity. Empirical studies on the social welfare and disparity of these policies are conducted.

##### Abstract (translated by Google)
算法决策过程中的公平正引起越来越多的关注。当一种算法应用于与人相关的决策时，单纯优化其预测能力的估计器可以学习对现有数据的偏见，这激发了我们机器学习中公平的概念。虽然在文献中研究了几种不同的概念，但对这些概念如何影响个体的研究很少。我们证明了众所周知的公平标准（包括色盲（CB），人口平价（DP）和均衡赔率（EO））引发的几种政策之间的这种比较。我们表明，EO是消除群体级别差异的唯一标准。对这些政策的社会福利和差距进行了实证研究。

##### URL
[http://arxiv.org/abs/1806.05112](http://arxiv.org/abs/1806.05112)

##### PDF
[http://arxiv.org/pdf/1806.05112](http://arxiv.org/pdf/1806.05112)

