---
layout: post
title: "Transferring GANs: generating images from limited data"
date: 2018-05-04 09:23:20
categories: arXiv_CV
tags: arXiv_CV Adversarial Knowledge GAN Image_Generation
author: Yaxing Wang, Chenshen Wu, Luis Herranz, Joost van de Weijer, Abel Gonzalez-Garcia, Bogdan Raducanu
mathjax: true
---

* content
{:toc}

##### Abstract
Transferring the knowledge of pretrained networks to new domains by means of finetuning is a widely used practice for applications based on discriminative models. To the best of our knowledge this practice has not been studied within the context of generative deep networks. Therefore, we study domain adaptation applied to image generation with generative adversarial networks. We evaluate several aspects of domain adaptation, including the impact of target domain size, the relative distance between source and target domain, and the initialization of conditional GANs. Our results show that using knowledge from pretrained networks can shorten the convergence time and can significantly improve the quality of the generated images, especially when the target data is limited. We show that these conclusions can also be drawn for conditional GANs even when the pretrained model was trained without conditioning. Our results also suggest that density may be more important than diversity and a dataset with one or few densely sampled classes may be a better source model than more diverse datasets such as ImageNet or Places.

##### Abstract (translated by Google)
通过微调将预训练网络的知识转移到新领域是基于区别模型的应用广泛使用的实践。就我们所知，这种做法尚未在生成深度网络的背景下进行研究。因此，我们研究了应用于生成对抗网络的图像生成的领域适应。我们评估领域适应的几个方面，包括目标领域大小的影响，源和目标领域之间的相对距离，以及条件GAN的初始化。我们的研究结果表明，使用来自预训练网络的知识可以缩短收敛时间，并且可以显着提高生成图像的质量，特别是当目标数据有限时。我们表明，即使预训练模型没有进行调节训练，也可以得出这些结论，即有条件的GANs。我们的结果还表明，密度可能比多样性更重要，一个或一些密集采样类的数据集可能是更多的不同的数据集，如ImageNet或地方，是一个更好的源模型。

##### URL
[http://arxiv.org/abs/1805.01677](http://arxiv.org/abs/1805.01677)

##### PDF
[http://arxiv.org/pdf/1805.01677](http://arxiv.org/pdf/1805.01677)

