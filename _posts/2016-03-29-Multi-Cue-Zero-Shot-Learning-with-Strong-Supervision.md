---
layout: post
title: "Multi-Cue Zero-Shot Learning with Strong Supervision"
date: 2016-03-29 13:04:21
categories: arXiv_CV
tags: arXiv_CV Knowledge Embedding Recognition
author: Zeynep Akata, Mateusz Malinowski, Mario Fritz, Bernt Schiele
mathjax: true
---

* content
{:toc}

##### Abstract
Scaling up visual category recognition to large numbers of classes remains challenging. A promising research direction is zero-shot learning, which does not require any training data to recognize new classes, but rather relies on some form of auxiliary information describing the new classes. Ultimately, this may allow to use textbook knowledge that humans employ to learn about new classes by transferring knowledge from classes they know well. The most successful zero-shot learning approaches currently require a particular type of auxiliary information -- namely attribute annotations performed by humans -- that is not readily available for most classes. Our goal is to circumvent this bottleneck by substituting such annotations by extracting multiple pieces of information from multiple unstructured text sources readily available on the web. To compensate for the weaker form of auxiliary information, we incorporate stronger supervision in the form of semantic part annotations on the classes from which we transfer knowledge. We achieve our goal by a joint embedding framework that maps multiple text parts as well as multiple semantic parts into a common space. Our results consistently and significantly improve on the state-of-the-art in zero-short recognition and retrieval.

##### Abstract (translated by Google)
将视觉类别识别扩展到大量类别仍然具有挑战性。一个有前途的研究方向是零射击学习，它不需要任何训练数据来识别新的类，而是依赖于描述新类的某种形式的辅助信息。最终，这可以允许人们使用教科书知识，通过从他们熟知的课程中传授知识来学习新课程。目前最成功的零点学习方法需要特定类型的辅助信息 - 即由人类执行的属性注释 - 这对于大多数类是不容易得到的。我们的目标是通过从网络上容易获得的多个非结构化文本源中提取多条信息来代替这些注释来绕过这个瓶颈。为弥补辅助信息的较弱形式，我们在语义部分注释的形式上加入了更强的监督，从而将知识传递给了我们。我们通过联合嵌入框架实现我们的目标，该框架将多个文本部分以及多个语义部分映射到公共空间中。我们的结果在零短识别和检索方面始终如一地显着提高。

##### URL
[https://arxiv.org/abs/1603.08754](https://arxiv.org/abs/1603.08754)

##### PDF
[https://arxiv.org/pdf/1603.08754](https://arxiv.org/pdf/1603.08754)

