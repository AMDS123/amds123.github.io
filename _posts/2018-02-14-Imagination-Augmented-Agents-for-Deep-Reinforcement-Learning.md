---
layout: post
title: "Imagination-Augmented Agents for Deep Reinforcement Learning"
date: 2018-02-14 17:26:18
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Prediction
author: Th&#xe9;ophane Weber, S&#xe9;bastien Racani&#xe8;re, David P. Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adria Puigdom&#xe8;nech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia, Demis Hassabis, David Silver, Daan Wierstra
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce Imagination-Augmented Agents (I2As), a novel architecture for deep reinforcement learning combining model-free and model-based aspects. In contrast to most existing model-based reinforcement learning and planning methods, which prescribe how a model should be used to arrive at a policy, I2As learn to interpret predictions from a learned environment model to construct implicit plans in arbitrary ways, by using the predictions as additional context in deep policy networks. I2As show improved data efficiency, performance, and robustness to model misspecification compared to several baselines.

##### Abstract (translated by Google)
我们引入了Imagination-Augmented Agents（I2As），这是一种结合了无模型和基于模型的深层强化学习的新型架构。与大多数现有的基于模型的强化学习和规划方法（规定应该如何使用模型来实现策略）相反，I2As学习解释来自学习环境模型的预测，以任意方式构建隐式计划，通过使用预测作为深度政策网络的附加背景。与几个基线相比，I2As显示出改进的数据效率，性能和模型错误指定的鲁棒性。

##### URL
[http://arxiv.org/abs/1707.06203](http://arxiv.org/abs/1707.06203)

##### PDF
[http://arxiv.org/pdf/1707.06203](http://arxiv.org/pdf/1707.06203)

