---
layout: post
title: "Disfluency Detection using Auto-Correlational Neural Networks"
date: 2018-08-28 02:28:12
categories: arXiv_CL
tags: arXiv_CL CNN Language_Model Detection Relation
author: Paria Jamshid Lou, Peter Anderson, Mark Johnson
mathjax: true
---

* content
{:toc}

##### Abstract
In recent years, the natural language processing community has moved away from task-specific feature engineering, i.e., researchers discovering ad-hoc feature representations for various tasks, in favor of general-purpose methods that learn the input representation by themselves. However, state-of-the-art approaches to disfluency detection in spontaneous speech transcripts currently still depend on an array of hand-crafted features, and other representations derived from the output of pre-existing systems such as language models or dependency parsers. As an alternative, this paper proposes a simple yet effective model for automatic disfluency detection, called an auto-correlational neural network (ACNN). The model uses a convolutional neural network (CNN) and augments it with a new auto-correlation operator at the lowest layer that can capture the kinds of "rough copy" dependencies that are characteristic of repair disfluencies in speech. In experiments, the ACNN model outperforms the baseline CNN on a disfluency detection task with a 5% increase in f-score, which is close to the previous best result on this task.

##### Abstract (translated by Google)
近年来，自然语言处理社区已经远离任务特定的特征工程，即研究人员发现各种任务的特殊特征表示，有利于通过自身学习输入表示的通用方法。然而，自发语音转录本中的不流畅检测的最新方法目前仍然依赖于手工制作的特征阵列，以及源自诸如语言模型或依赖性解析器的预先存在的系统的输出的其他表示。作为替代方案，本文提出了一种简单而有效的自动不流动检测模型，称为自相关神经网络（ACNN）。该模型使用卷积神经网络（CNN）并在最低层使用新的自相关算子对其进行增强，该算子可以捕获语音中修复不流畅特征的“粗略复制”依赖性。在实验中，ACNN模型在不流畅检测任务上优于基线CNN，f分数增加5％，接近此任务的先前最佳结果。

##### URL
[http://arxiv.org/abs/1808.09092](http://arxiv.org/abs/1808.09092)

##### PDF
[http://arxiv.org/pdf/1808.09092](http://arxiv.org/pdf/1808.09092)

