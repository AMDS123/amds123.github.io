---
layout: post
title: "Learning Conceptual Space Representations of Interrelated Concepts"
date: 2018-05-03 13:08:47
categories: arXiv_AI
tags: arXiv_AI Knowledge
author: Zied Bouraoui, Steven Schockaert
mathjax: true
---

* content
{:toc}

##### Abstract
Several recently proposed methods aim to learn conceptual space representations from large text collections. These learned representations asso- ciate each object from a given domain of interest with a point in a high-dimensional Euclidean space, but they do not model the concepts from this do- main, and can thus not directly be used for catego- rization and related cognitive tasks. A natural solu- tion is to represent concepts as Gaussians, learned from the representations of their instances, but this can only be reliably done if sufficiently many in- stances are given, which is often not the case. In this paper, we introduce a Bayesian model which addresses this problem by constructing informative priors from background knowledge about how the concepts of interest are interrelated with each other. We show that this leads to substantially better pre- dictions in a knowledge base completion task.

##### Abstract (translated by Google)
最近提出的几种方法旨在从大型文本集合中学习概念空间表示。这些学习表示将来自给定感兴趣区域的每个对象与高维欧几里得空间中的一个点相关联，但是它们并没有从这个领域对模型概念进行建模，因此不能直接用于分类和相关的认知任务。自然的解决方案是将概念表示为高斯，从他们的实例的表示中学习，但只有在给出足够多的实例时才能可靠地完成这个过程，而实际情况往往不是这样。在本文中，我们引入了一个贝叶斯模型来解决这个问题，通过从关于感兴趣的概念如何相互关联的背景知识构建信息丰富的先验。我们证明这会导致知识库完成任务中的预测实质上更好。

##### URL
[http://arxiv.org/abs/1805.01276](http://arxiv.org/abs/1805.01276)

##### PDF
[http://arxiv.org/pdf/1805.01276](http://arxiv.org/pdf/1805.01276)

