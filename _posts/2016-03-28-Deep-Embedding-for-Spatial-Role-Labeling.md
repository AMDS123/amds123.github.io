---
layout: post
title: "Deep Embedding for Spatial Role Labeling"
date: 2016-03-28 18:38:46
categories: arXiv_SD
tags: arXiv_SD Knowledge Embedding RNN Relation
author: Oswaldo Ludwig, Xiao Liu, Parisa Kordjamshidi, Marie-Francine Moens
mathjax: true
---

* content
{:toc}

##### Abstract
This paper introduces the visually informed embedding of word (VIEW), a continuous vector representation for a word extracted from a deep neural model trained using the Microsoft COCO data set to forecast the spatial arrangements between visual objects, given a textual description. The model is composed of a deep multilayer perceptron (MLP) stacked on the top of a Long Short Term Memory (LSTM) network, the latter being preceded by an embedding layer. The VIEW is applied to transferring multimodal background knowledge to Spatial Role Labeling (SpRL) algorithms, which recognize spatial relations between objects mentioned in the text. This work also contributes with a new method to select complementary features and a fine-tuning method for MLP that improves the $F1$ measure in classifying the words into spatial roles. The VIEW is evaluated with the Task 3 of SemEval-2013 benchmark data set, SpaceEval.

##### Abstract (translated by Google)
本文介绍了视觉信息嵌入的单词（VIEW），一个连续的矢量表示，从一个深度神经模型中提取的一个单词，使用Microsoft COCO数据集进行训练，预测视觉对象之间的空间排列，给出文字描述。该模型由堆叠在长期短期记忆（LSTM）网络顶部的深层​​多层感知器（MLP）组成，后者之前是嵌入层。 VIEW被用于将多模式背景知识转换为空间角色标注（SpRL）算法，该算法可以识别文中提到的对象之间的空间关系。这项工作也有助于提供一种新的方法来选择补充特征和MLP的微调方法，从而改善了将单词分类为空间角色的$ F1 $度量。 VIEW使用SemEval-2013基准数据集的任务3（SpaceEval）进行评估。

##### URL
[https://arxiv.org/abs/1603.08474](https://arxiv.org/abs/1603.08474)

##### PDF
[https://arxiv.org/pdf/1603.08474](https://arxiv.org/pdf/1603.08474)

