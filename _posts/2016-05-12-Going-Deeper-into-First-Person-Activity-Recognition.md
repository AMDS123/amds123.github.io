---
layout: post
title: "Going Deeper into First-Person Activity Recognition"
date: 2016-05-12 05:59:50
categories: arXiv_CV
tags: arXiv_CV Knowledge Action_Recognition CNN Recognition
author: Minghuang Ma, Haoqi Fan, Kris M. Kitani
mathjax: true
---

* content
{:toc}

##### Abstract
We bring together ideas from recent work on feature design for egocentric action recognition under one framework by exploring the use of deep convolutional neural networks (CNN). Recent work has shown that features such as hand appearance, object attributes, local hand motion and camera ego-motion are important for characterizing first-person actions. To integrate these ideas under one framework, we propose a twin stream network architecture, where one stream analyzes appearance information and the other stream analyzes motion information. Our appearance stream encodes prior knowledge of the egocentric paradigm by explicitly training the network to segment hands and localize objects. By visualizing certain neuron activation of our network, we show that our proposed architecture naturally learns features that capture object attributes and hand-object configurations. Our extensive experiments on benchmark egocentric action datasets show that our deep architecture enables recognition rates that significantly outperform state-of-the-art techniques -- an average $6.6\%$ increase in accuracy over all datasets. Furthermore, by learning to recognize objects, actions and activities jointly, the performance of individual recognition tasks also increase by $30\%$ (actions) and $14\%$ (objects). We also include the results of extensive ablative analysis to highlight the importance of network design decisions..

##### Abstract (translated by Google)
通过探索深度卷积神经网络（CNN）的使用，我们将来自最近关于自我中心行为识别的特征设计工作的想法集中在一个框架下。最近的研究表明，诸如手相，物体属性，局部手部运动和相机自我运动等特征对于表征第一人称动作非常重要。为了将这些思想融合在一个框架下，我们提出了一个双流网络架构，一个流分析外观信息，另一个流分析运动信息。我们的外观流通过明确地训练网络来分割手和本地化对象来编码先前的自我中心范式的知识。通过可视化我们网络的某些神经元激活，我们展示了我们提出的架构自然地学习捕捉对象属性和手对象配置的特征。我们在基准自我中心动作数据集上进行的大量实验表明，我们的深层架构使得识别率明显优于最先进的技术 - 在所有数据集上的平均精确度提高了6.6％。此外，通过学习共同识别对象，动作和活动，个人识别任务的表现也增加$ 30％（行动）和$ 14％（对象）。我们还包括广泛烧蚀分析的结果，以突出网络设计决策的重要性。

##### URL
[https://arxiv.org/abs/1605.03688](https://arxiv.org/abs/1605.03688)

##### PDF
[https://arxiv.org/pdf/1605.03688](https://arxiv.org/pdf/1605.03688)

