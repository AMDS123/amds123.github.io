---
layout: post
title: "Model-based Hand Pose Estimation for Generalized Hand Shape with Appearance Normalization"
date: 2018-07-02 21:27:08
categories: arXiv_CV
tags: arXiv_CV Pose_Estimation Deep_Learning
author: Jan Wöhlke, Shile Li, Dongheui Lee
mathjax: true
---

* content
{:toc}

##### Abstract
Since the emergence of large annotated datasets, state-of-the-art hand pose estimation methods have been mostly based on discriminative learning. Recently, a hybrid approach has embedded a kinematic layer into the deep learning structure in such a way that the pose estimates obey the physical constraints of human hand kinematics. However, the existing approach relies on a single person's hand shape parameters, which are fixed constants. Therefore, the existing hybrid method has problems to generalize to new, unseen hands. In this work, we extend the kinematic layer to make the hand shape parameters learnable. In this way, the learnt network can generalize towards arbitrary hand shapes. Furthermore, inspired by the idea of Spatial Transformer Networks, we apply a cascade of appearance normalization networks to decrease the variance in the input data. The input images are shifted, rotated, and globally scaled to a similar appearance. The effectiveness and limitations of our proposed approach are extensively evaluated on the Hands 2017 challenge dataset and the NYU dataset.

##### Abstract (translated by Google)
自大量注释数据集出现以来，最先进的手部姿势估计方法主要基于判别性学习。最近，混合方法已经将运动层嵌入到深度学习结构中，使得姿势估计遵循人手运动学的物理约束。但是，现有方法依赖于单个人的手形参数，这些参数是固定常数。因此，现有的混合方法存在问题，无法推广到新的，看不见的手。在这项工作中，我们扩展了运动层，使手形参数可以学习。以这种方式，学习的网络可以概括为任意手形。此外，受空间变换器网络概念的启发，我们应用级联的外观归一化网络来减少输入数据的方差。输入图像被移位，旋转和全局缩放到类似的外观。我们提出的方法的有效性和局限性在Hands 2017挑战数据集和NYU数据集上得到了广泛的评估。

##### URL
[https://arxiv.org/abs/1807.00898](https://arxiv.org/abs/1807.00898)

##### PDF
[https://arxiv.org/pdf/1807.00898](https://arxiv.org/pdf/1807.00898)

