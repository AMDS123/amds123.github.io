---
layout: post
title: "High-Resolution Talking Face Generation via Mutual Information Approximation"
date: 2018-12-17 02:56:09
categories: arXiv_CV
tags: arXiv_CV Attention Face
author: Hao Zhu, Aihua Zheng, Huaibo Huang, Ran He
mathjax: true
---

* content
{:toc}

##### Abstract
Given an arbitrary speech clip and a facial image, talking face generation aims to synthesize a talking face video with precise lip synchronization as well as a smooth transition of facial motion over the entire video speech. Most existing methods mainly focus on either disentangling the information in a single image or learning temporal information between frames. However, speech audio and video often have cross-modality coherence that has not been well addressed during synthesis. Therefore, this paper proposes a novel high-resolution talking face generation model for arbitrary person by discovering the cross-modality coherence via Mutual Information Approximation (MIA). By assuming the modality difference between audio and video is larger that of real video and generated video, we estimate mutual information between real audio and video, and then use a discriminator to enforce generated video distribution approach real video distribution. Furthermore, we introduce a dynamic attention technique on the mouth to enhance the robustness during the training stage. Experimental results on benchmark dataset LRW transcend the state-of-the-art methods on prevalent metrics with robustness on gender, pose variations and high-resolution synthesizing.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.06589](http://arxiv.org/abs/1812.06589)

##### PDF
[http://arxiv.org/pdf/1812.06589](http://arxiv.org/pdf/1812.06589)

