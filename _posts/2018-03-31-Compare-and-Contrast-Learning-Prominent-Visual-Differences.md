---
layout: post
title: "Compare and Contrast: Learning Prominent Visual Differences"
date: 2018-03-31 03:20:18
categories: arXiv_CV
tags: arXiv_CV Face
author: Steven Chen, Kristen Grauman
mathjax: true
---

* content
{:toc}

##### Abstract
Relative attribute models can compare images in terms of all detected properties or attributes, exhaustively predicting which image is fancier, more natural, and so on without any regard to ordering. However, when humans compare images, certain differences will naturally stick out and come to mind first. These most noticeable differences, or prominent differences, are likely to be described first. In addition, many differences, although present, may not be mentioned at all. In this work, we introduce and model prominent differences, a rich new functionality for comparing images. We collect instance-level annotations of most noticeable differences, and build a model trained on relative attribute features that predicts prominent differences for unseen pairs. We test our model on the challenging UT-Zap50K shoes and LFW10 faces datasets, and outperform an array of baseline methods. We then demonstrate how our prominence model improves two vision tasks, image search and description generation, enabling more natural communication between people and vision systems.

##### Abstract (translated by Google)
相对属性模型可以根据所有检测到的属性或属性比较图像，详尽地预测哪个图像更有趣，更自然，等等，而不考虑排序。然而，当人类比较图像时，某些差异会自然突出并首先浮现在脑海中。这些最显着的差异或显着差异可能首先被描述。另外，虽然存在许多差异，但可能根本没有提及。在这项工作中，我们介绍并建模了显着差异，这是一种用于比较图像的丰富新功能。我们收集最显着差异的实例级注释，并构建一个模型，对相关属性特征进行训练，预测未注册对的显着差异。我们在具有挑战性的UT-Zap50K鞋和LFW10面向数据集上测试我们的模型，并且胜过一系列基准方法。然后，我们将展示我们的突出模型如何改进两个视觉任务，图像搜索和描述生成，实现人与视觉系统之间更自然的通信。

##### URL
[http://arxiv.org/abs/1804.00112](http://arxiv.org/abs/1804.00112)

##### PDF
[http://arxiv.org/pdf/1804.00112](http://arxiv.org/pdf/1804.00112)

