---
layout: post
title: "Diversified Texture Synthesis with Feed-forward Networks"
date: 2017-03-05 21:09:19
categories: arXiv_CV
tags: arXiv_CV
author: Yijun Li, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, Ming-Hsuan Yang
mathjax: true
---

* content
{:toc}

##### Abstract
Recent progresses on deep discriminative and generative modeling have shown promising results on texture synthesis. However, existing feed-forward based methods trade off generality for efficiency, which suffer from many issues, such as shortage of generality (i.e., build one network per texture), lack of diversity (i.e., always produce visually identical output) and suboptimality (i.e., generate less satisfying visual effects). In this work, we focus on solving these issues for improved texture synthesis. We propose a deep generative feed-forward network which enables efficient synthesis of multiple textures within one single network and meaningful interpolation between them. Meanwhile, a suite of important techniques are introduced to achieve better convergence and diversity. With extensive experiments, we demonstrate the effectiveness of the proposed model and techniques for synthesizing a large number of textures and show its applications with the stylization.

##### Abstract (translated by Google)
近来在深度辨别和生成建模方面的进展已经在纹理合成上显示出有希望的结果。然而，现有的基于前馈的方法是为了效率而折衷的，其中存在许多问题，如普遍性不足（即每个纹理构建一个网络），缺乏多样性（即始终产生视觉上相同的输出）和次优性即产生较不令人满意的视觉效果）。在这项工作中，我们专注于解决这些问题以改善纹理合成。我们提出了一个深度生成的前馈网络，可以在一个网络内有效地合成多个纹理，并在它们之间进行有意义的插值。同时引入一套重要的技术手段，实现更好的融合和多样性。通过大量的实验，我们证明了所提出的用于合成大量纹理的模型和技术的有效性，并用程式化来展示其应用。

##### URL
[https://arxiv.org/abs/1703.01664](https://arxiv.org/abs/1703.01664)

##### PDF
[https://arxiv.org/pdf/1703.01664](https://arxiv.org/pdf/1703.01664)

