---
layout: post
title: "Customizing First Person Image Through Desired Actions"
date: 2017-04-01 01:55:28
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Shan Su, Jianbo Shi, Hyun Soo Park
mathjax: true
---

* content
{:toc}

##### Abstract
This paper studies a problem of inverse visual path planning: creating a visual scene from a first person action. Our conjecture is that the spatial arrangement of a first person visual scene is deployed to afford an action, and therefore, the action can be inversely used to synthesize a new scene such that the action is feasible. As a proof-of-concept, we focus on linking visual experiences induced by walking. A key innovation of this paper is a concept of ActionTunnel---a 3D virtual tunnel along the future trajectory encoding what the wearer will visually experience as moving into the scene. This connects two distinctive first person images through similar walking paths. Our method takes a first person image with a user defined future trajectory and outputs a new image that can afford the future motion. The image is created by combining present and future ActionTunnels in 3D where the missing pixels in adjoining area are computed by a generative adversarial network. Our work can provide a travel across different first person experiences in diverse real world scenes.

##### Abstract (translated by Google)
本文研究了反向视觉路径规划问题：从第一人称动作创建视觉场景。我们的猜想是，第一人称视觉场景的空间布置被部署起来以提供一个动作，因此这个动作可以被相反地用来合成一个新的场景，使得这个动作是可行的。作为一个概念验证，我们重点关注由步行引起的视觉体验。本文的一个关键创新是ActionTunnel的概念---一个沿着未来轨迹的3D虚拟隧道，用于编码佩戴者在进入现场时将视觉体验到的内容。这通过类似的步行路径连接两个独特的第一人称图像。我们的方法采用用户定义的未来轨迹的第一人称图像，并输出一个新的图像，可以提供未来的运动。该图像是通过将现在和未来的三维动作隧道结合在一起创建的，其中毗邻区域中的缺失像素由生成对抗网络计算。我们的工作可以提供不同的第一人称经验在不同的现实世界场景的旅行。

##### URL
[https://arxiv.org/abs/1704.00098](https://arxiv.org/abs/1704.00098)

##### PDF
[https://arxiv.org/pdf/1704.00098](https://arxiv.org/pdf/1704.00098)

