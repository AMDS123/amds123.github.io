---
layout: post
title: "Skeleton-based Action Recognition Using LSTM and CNN"
date: 2017-07-06 11:06:26
categories: arXiv_CV
tags: arXiv_CV Action_Recognition CNN RNN Deep_Learning Recognition
author: Chuankun Li, Pichao Wang, Shuang Wang, Yonghong Hou, Wanqing Li
mathjax: true
---

* content
{:toc}

##### Abstract
Recent methods based on 3D skeleton data have achieved outstanding performance due to its conciseness, robustness, and view-independent representation. With the development of deep learning, Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM)-based learning methods have achieved promising performance for action recognition. However, for CNN-based methods, it is inevitable to loss temporal information when a sequence is encoded into images. In order to capture as much spatial-temporal information as possible, LSTM and CNN are adopted to conduct effective recognition with later score fusion. In addition, experimental results show that the score fusion between CNN and LSTM performs better than that between LSTM and LSTM for the same feature. Our method achieved state-of-the-art results on NTU RGB+D datasets for 3D human action analysis. The proposed method achieved 87.40% in terms of accuracy and ranked $1^{st}$ place in Large Scale 3D Human Activity Analysis Challenge in Depth Videos.

##### Abstract (translated by Google)
基于三维骨架数据的最新方法由于其简洁性，鲁棒性和独立于视图的表示而取得了出色的性能。随着深度学习的发展，卷积神经网络（CNN）和基于长时间短记忆（LSTM）的学习方法在动作识别方面取得了良好的效果。然而，对于基于CNN的方法，当序列被编码成图像时，不可避免地丢失时间信息。为了获取尽可能多的时空信息，采用LSTM和CNN进行有效识别，并进行后期分数融合。另外，实验结果表明，对于同一特征，CNN和LSTM之间的分数融合比LSTM和LSTM之间的分数融合更好。我们的方法在三维人体动作分析的NTU RGB + D数据集上取得了最先进的成果。该方法在精度方面达到了87.40％，并在深度视频中的大规模三维人体活动分析挑战中排名第一。

##### URL
[https://arxiv.org/abs/1707.02356](https://arxiv.org/abs/1707.02356)

##### PDF
[https://arxiv.org/pdf/1707.02356](https://arxiv.org/pdf/1707.02356)

