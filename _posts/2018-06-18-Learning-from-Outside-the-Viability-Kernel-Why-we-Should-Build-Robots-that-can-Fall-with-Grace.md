---
layout: post
title: "Learning from Outside the Viability Kernel: Why we Should Build Robots that can Fall with Grace"
date: 2018-06-18 09:28:52
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Steve Heim, Alexander Spr&#xf6;witz
mathjax: true
---

* content
{:toc}

##### Abstract
Despite impressive results using reinforcement learning to solve complex problems from scratch, in robotics this has still been largely limited to model-based learning with very informative reward functions. One of the major challenges is that the reward landscape often has large patches with no gradient, making it difficult to sample gradients effectively. We show here that the robot state-initialization can have a more important effect on the reward landscape than is generally expected. In particular, we show the counter-intuitive benefit of including initializations that are unviable, in other words initializing in states that are doomed to fail.

##### Abstract (translated by Google)
尽管使用强化学习从头开始解决复杂问题，但在机器人技术方面仍然取得了令人印象深刻的成果，但它仍然基本上局限于具有非常丰富奖励功能的模型学习。其中一个主要挑战是奖励景观通常具有大的斑块而没有梯度，使得难以有效地采样梯度。我们在这里展示的是，机器人状态初始化可以比通常预期的对奖励景观产生更重要的影响。特别是，我们展示了包含不可行的初始化的逆直觉好处，换言之，在注定要失败的状态中初始化。

##### URL
[http://arxiv.org/abs/1806.06569](http://arxiv.org/abs/1806.06569)

##### PDF
[http://arxiv.org/pdf/1806.06569](http://arxiv.org/pdf/1806.06569)

