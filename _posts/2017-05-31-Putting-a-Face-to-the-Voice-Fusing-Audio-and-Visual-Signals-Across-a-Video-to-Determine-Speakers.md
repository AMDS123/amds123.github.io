---
layout: post
title: "Putting a Face to the Voice: Fusing Audio and Visual Signals Across a Video to Determine Speakers"
date: 2017-05-31 20:35:26
categories: arXiv_CV
tags: arXiv_CV Face Tracking
author: Ken Hoover, Sourish Chaudhuri, Caroline Pantofaru, Malcolm Slaney, Ian Sturdy
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present a system that associates faces with voices in a video by fusing information from the audio and visual signals. The thesis underlying our work is that an extremely simple approach to generating (weak) speech clusters can be combined with visual signals to effectively associate faces and voices by aggregating statistics across a video. This approach does not need any training data specific to this task and leverages the natural coherence of information in the audio and visual streams. It is particularly applicable to tracking speakers in videos on the web where a priori information about the environment (e.g., number of speakers, spatial signals for beamforming) is not available. We performed experiments on a real-world dataset using this analysis framework to determine the speaker in a video. Given a ground truth labeling determined by human rater consensus, our approach had ~71% accuracy.

##### Abstract (translated by Google)
在本文中，我们提出了一个通过融合音频和视频信号中的信息来将人脸与视频中的声音相关联的系统。我们的工作的基础是一个非常简单的方法来产生（弱）语音群集可以结合视觉信号，通过聚合统计视频有效地联系人脸和声音。这种方法不需要特定于该任务的任何训练数据，并利用音频和视频流中信息的自然一致性。特别适用于跟踪网络上的视频中的讲话者，其中关于环境的先验信息（例如讲话者的数量，用于波束形成的空间信号）不可用。我们使用这个分析框架在真实世界的数据集上进行实验，以确定视频中的说话人。由于人类评价者共识确定的地面实况标签，我们的方法有71％的准确性。

##### URL
[https://arxiv.org/abs/1706.00079](https://arxiv.org/abs/1706.00079)

##### PDF
[https://arxiv.org/pdf/1706.00079](https://arxiv.org/pdf/1706.00079)

