---
layout: post
title: "Video Imagination from a Single Image with Transformation Generation"
date: 2017-06-15 07:51:22
categories: arXiv_CV
tags: arXiv_CV Adversarial QA
author: Baoyang Chen, Wenmin Wang, Jinzhuo Wang, Xiongtao Chen
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we focus on a challenging task: synthesizing multiple imaginary videos given a single image. Major problems come from high dimensionality of pixel space and the ambiguity of potential motions. To overcome those problems, we propose a new framework that produce imaginary videos by transformation generation. The generated transformations are applied to the original image in a novel volumetric merge network to reconstruct frames in imaginary video. Through sampling different latent variables, our method can output different imaginary video samples. The framework is trained in an adversarial way with unsupervised learning. For evaluation, we propose a new assessment metric $RIQA$. In experiments, we test on 3 datasets varying from synthetic data to natural scene. Our framework achieves promising performance in image quality assessment. The visual inspection indicates that it can successfully generate diverse five-frame videos in acceptable perceptual quality.

##### Abstract (translated by Google)
在这项工作中，我们专注于一个具有挑战性的任务：合成多个假想的视频给一个单一的图像。主要问题来自像素空间的高维和潜在运动的模糊性。为了克服这些问题，我们提出了一个通过转换生成虚拟视频的新框架。所产生的变换被应用到原始图像在一个新颖的体积合并网络重建虚构的视频帧。通过采样不同的潜在变量，我们的方法可以输出不同的虚拟视频样本。这个框架是用无监督学习的方式进行对抗训练的。为了评估，我们提出一个新的评估指标$ RIQA $。在实验中，我们测试了从合成数据到自然场景的3个数据集。我们的框架在图像质量评估方面取得了很好的效果视觉检查表明，它可以成功地生成具有可接受的感知质量的多种五帧视频。

##### URL
[https://arxiv.org/abs/1706.04124](https://arxiv.org/abs/1706.04124)

##### PDF
[https://arxiv.org/pdf/1706.04124](https://arxiv.org/pdf/1706.04124)

