---
layout: post
title: "Stacked Attention Networks for Image Question Answering"
date: 2016-01-26 20:37:49
categories: arXiv_CL
tags: arXiv_CL QA Attention
author: Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents stacked attention networks (SANs) that learn to answer natural language questions from images. SANs use semantic representation of a question as query to search for the regions in an image that are related to the answer. We argue that image question answering (QA) often requires multiple steps of reasoning. Thus, we develop a multiple-layer SAN in which we query an image multiple times to infer the answer progressively. Experiments conducted on four image QA data sets demonstrate that the proposed SANs significantly outperform previous state-of-the-art approaches. The visualization of the attention layers illustrates the progress that the SAN locates the relevant visual clues that lead to the answer of the question layer-by-layer.

##### Abstract (translated by Google)
本文介绍了堆叠的关注网络（SAN），学会了从图像中回答自然语言问题。 SAN使用问题的语义表示作为查询来搜索图像中与答案相关的区域。我们认为形象问题回答（QA）通常需要多个推理步骤。因此，我们开发了一个多层的SAN，我们可以多次查询一个图像，逐步推断答案。对四个图像QA数据集进行的实验表明，所提出的SAN明显优于先前的最新方法。关注层的可视化说明了SAN找到导致问题逐层回答的相关视觉线索的进展。

##### URL
[https://arxiv.org/abs/1511.02274](https://arxiv.org/abs/1511.02274)

##### PDF
[https://arxiv.org/pdf/1511.02274](https://arxiv.org/pdf/1511.02274)

