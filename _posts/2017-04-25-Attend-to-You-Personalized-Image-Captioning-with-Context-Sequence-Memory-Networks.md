---
layout: post
title: "Attend to You: Personalized Image Captioning with Context Sequence Memory Networks"
date: 2017-04-25 23:30:43
categories: arXiv_CV
tags: arXiv_CV Image_Caption Knowledge Caption Prediction Quantitative Memory_Networks
author: Cesc Chunseong Park, Byeongchang Kim, Gunhee Kim
mathjax: true
---

* content
{:toc}

##### Abstract
We address personalization issues of image captioning, which have not been discussed yet in previous research. For a query image, we aim to generate a descriptive sentence, accounting for prior knowledge such as the user's active vocabularies in previous documents. As applications of personalized image captioning, we tackle two post automation tasks: hashtag prediction and post generation, on our newly collected Instagram dataset, consisting of 1.1M posts from 6.3K users. We propose a novel captioning model named Context Sequence Memory Network (CSMN). Its unique updates over previous memory network models include (i) exploiting memory as a repository for multiple types of context information, (ii) appending previously generated words into memory to capture long-term information without suffering from the vanishing gradient problem, and (iii) adopting CNN memory structure to jointly represent nearby ordered memory slots for better context understanding. With quantitative evaluation and user studies via Amazon Mechanical Turk, we show the effectiveness of the three novel features of CSMN and its performance enhancement for personalized image captioning over state-of-the-art captioning models.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1704.06485](https://arxiv.org/abs/1704.06485)

##### PDF
[https://arxiv.org/pdf/1704.06485](https://arxiv.org/pdf/1704.06485)

