---
layout: post
title: "Translating Visual Art into Music"
date: 2019-09-03 14:36:19
categories: arXiv_AI
tags: arXiv_AI Quantitative
author: Maximilian MÃ¼ller-Eberstein, Nanne van Noord
mathjax: true
---

* content
{:toc}

##### Abstract
The Synesthetic Variational Autoencoder (SynVAE) introduced in this research is able to learn a consistent mapping between visual and auditive sensory modalities in the absence of paired datasets. A quantitative evaluation on MNIST as well as the Behance Artistic Media dataset (BAM) shows that SynVAE is capable of retaining sufficient information content during the translation while maintaining cross-modal latent space consistency. In a qualitative evaluation trial, human evaluators were furthermore able to match musical samples with the images which generated them with accuracies of up to 73%.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1909.01218](https://arxiv.org/abs/1909.01218)

##### PDF
[https://arxiv.org/pdf/1909.01218](https://arxiv.org/pdf/1909.01218)

