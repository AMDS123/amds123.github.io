---
layout: post
title: "Convolutional neural network compression for natural language processing"
date: 2018-05-28 07:40:33
categories: arXiv_CL
tags: arXiv_CL Sentiment CNN Classification
author: Krzysztof Wr&#xf3;bel, Marcin Pietro&#x144;, Maciej Wielgosz, Micha&#x142; Karwatowski, Kazimierz Wiatr
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional neural networks are modern models that are very efficient in many classification tasks. They were originally created for image processing purposes. Then some trials were performed to use them in different domains like natural language processing. The artificial intelligence systems (like humanoid robots) are very often based on embedded systems with constraints on memory, power consumption etc. Therefore convolutional neural network because of its memory capacity should be reduced to be mapped to given hardware. In this paper, results are presented of compressing the efficient convolutional neural networks for sentiment analysis. The main steps are quantization and pruning processes. The method responsible for mapping compressed network to FPGA and results of this implementation are presented. The described simulations showed that 5-bit width is enough to have no drop in accuracy from floating point version of the network. Additionally, significant memory footprint reduction was achieved (from 85% up to 93%).

##### Abstract (translated by Google)
卷积神经网络是在许多分类任务中非常有效的现代模型。它们最初是为图像处理目的而创建的。然后进行了一些试验，将其用于不同的领域，如自然语言处理。人工智能系统（如人形机器人）通常基于嵌入式系统，存储器容量和功耗等方面受到限制。因此，卷积神经网络由于其存储容量应该减少以映射到给定硬件。在本文中，结果提出了压缩高效卷积神经网络的情绪分析。主要步骤是量化和修剪过程。介绍了负责将压缩网络映射到FPGA的方法和实现结果。所描述的仿真表明，5位宽度足以使网络的浮点版本的准确度没有下降。此外，显着减少内存占用（从85％上升到93％）。

##### URL
[http://arxiv.org/abs/1805.10796](http://arxiv.org/abs/1805.10796)

##### PDF
[http://arxiv.org/pdf/1805.10796](http://arxiv.org/pdf/1805.10796)

