---
layout: post
title: "Learning to select computations"
date: 2018-02-26 22:12:17
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Falk Lieder, Frederick Callaway, Sayan Gul, Paul M. Krueger, Thomas L. Griffiths
mathjax: true
---

* content
{:toc}

##### Abstract
Efficient use of limited computational resources is essential to intelligence. Selecting computations optimally according to rational metareasoning would achieve this, but rational metareasoning is computationally intractable. Inspired by psychology and neuroscience, we propose the first learning algorithm for approximating the optimal selection of computations. We derive a general, sample-efficient reinforcement learning algorithm for learning to select computations from the insight that the value of computation lies between the myopic value of computation and the value of perfect information. We evaluate the performance of our method against two state-of-the-art methods for approximate metareasoning--the meta-greedy heuristic and the blinkered policy--on three increasingly difficult metareasoning problems: metareasoning about when to terminate computation, metareasoning about how to choose between multiple actions, and metareasoning about planning. Across all three domains, our method achieved near-optimal performance and significantly outperformed the meta-greedy heuristic. The blinkered policy performed on par with our method in metareasoning about decision-making, but it is not directly applicable to metareasoning about planning where our method outperformed both the meta-greedy heuristic and a generalization of the blinkered policy. Our results are a step towards building self-improving AI systems that can learn to make optimal use of their limited computational resources to efficiently solve complex problems in real-time.

##### Abstract (translated by Google)
有效利用有限的计算资源对于情报是必不可少的。根据合理的元理论选择最佳计算可以实现这一点，但理性的元理论在计算上难以处理。受心理学和神经科学的启发，我们提出了第一种用于近似计算最优选择的学习算法。我们推导出一种通用的，高效的样本强化学习算法，用于从计算的价值介于计算的近视值和完美信息的值之间的洞察力中选择计算。我们评估我们的方法与两种最新的近似metareasoning方法 - 元贪婪启发式和blinkered策略 - 在三个越来越困难的metareasoning问题上的性能：关于何时终止计算的metareasoning，关于如何在多种行为之间进行选择，以及关于计划的理论。在所有三个领域中，我们的方法实现了近乎最佳的性能，并且明显优于元贪心启发式。这种盲目的政策与我们的方法在决策的元理论上完全相同，但它并不直接适用于规划中的元理论，而我们的方法超越了元贪婪启发式和盲目政策的普遍化。我们的结果是朝着构建自我改进的AI系统迈出的一步，该系统可以学习如何最佳地利用其有限的计算资源来实时有效地解决复杂的问题。

##### URL
[http://arxiv.org/abs/1711.06892](http://arxiv.org/abs/1711.06892)

##### PDF
[http://arxiv.org/pdf/1711.06892](http://arxiv.org/pdf/1711.06892)

