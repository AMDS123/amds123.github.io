---
layout: post
title: "Learning Multimodal Fixed-Point Weights using Gradient Descent"
date: 2019-07-16 19:11:01
categories: arXiv_CV
tags: arXiv_CV Optimization Gradient_Descent
author: Lukas Enderich, Fabian Timm, Lars Rosenbaum, Wolfram Burgard
mathjax: true
---

* content
{:toc}

##### Abstract
Due to their high computational complexity, deep neural networks are still limited to powerful processing units. To promote a reduced model complexity by dint of low-bit fixed-point quantization, we propose a gradient-based optimization strategy to generate a symmetric mixture of Gaussian modes (SGM) where each mode belongs to a particular quantization stage. We achieve 2-bit state-of-the-art performance and illustrate the model's ability for self-dependent weight adaptation during training.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.07220](http://arxiv.org/abs/1907.07220)

##### PDF
[http://arxiv.org/pdf/1907.07220](http://arxiv.org/pdf/1907.07220)

