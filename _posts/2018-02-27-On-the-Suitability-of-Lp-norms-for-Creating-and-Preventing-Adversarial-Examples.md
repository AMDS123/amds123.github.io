---
layout: post
title: "On the Suitability of $L_p$-norms for Creating and Preventing Adversarial Examples"
date: 2018-02-27 00:04:12
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Mahmood Sharif, Lujo Bauer, Michael K. Reiter
mathjax: true
---

* content
{:toc}

##### Abstract
Much research effort has been devoted to better understanding adversarial examples, which are specially crafted inputs to machine-learning models that are perceptually similar to benign inputs, but are classified differently (i.e., misclassified). Both algorithms that create adversarial examples and strategies for defending against them typically use $L_p$-norms to measure the perceptual similarity between an adversarial input and its benign original. Prior work has already shown, however, that two images need not be close to each other as measured by an $L_p$-norm to be perceptually similar. In this work, we show that nearness according to an $L_p$-norm is not just unnecessary for perceptual similarity, but is also insufficient. Specifically, focusing on datasets (CIFAR10 and MNIST), $L_p$-norms, and thresholds used in prior work, we show through 299-participant online user studies that "adversarial examples" that are closer to their benign counterparts than required by commonly used $L_p$-norm thresholds can nevertheless be perceptually different to humans from the corresponding benign examples. Namely, the perceptual distance between two images that are "near" each other according to an $L_p$-norm can be high enough that participants frequently classify the two images as representing different objects or digits. Combined with prior work, we thus demonstrate that nearness of inputs as measured by $L_p$-norms is neither necessary nor sufficient for perceptual similarity, which has implications for both creating and defending against adversarial examples.

##### Abstract (translated by Google)
许多研究工作致力于更好地理解对抗性的例子，这些例子是特别制作的机器学习模型的输入，它们与良性输入在感知上类似，但被分类不同（即错误分类）。这两种算法可以创造对抗性的例子和策略来防御它们，通常使用$ L_p $ -norms来衡量敌对投入与其良性原始投入之间的感知相似性。然而，之前的工作已经显示，两个图像不需要彼此靠近，如通过$ L_p $ -norm所测量的那样在感知上相似。在这项工作中，我们表明根据$ L_p $ -norm的接近度不仅对知觉相似性不是必要的，而且也是不够的。具体来说，关注以前工作中使用的数据集（CIFAR10和MNIST），$ L_p $ -norms和阈值，我们通过299位参与者的在线用户研究显示，“敌对案例”比常用的更接近其良性对应尽管如此，$ L_p $ -norm阈值可能与相应的良性例子中的人类在感知上不同。即，根据$ L_p $ -norm彼此“接近”的两个图像之间的感知距离可能足够高，以至于参与者经常将两个图像分类为代表不同的对象或数字。结合之前的工作，我们因此证明，用L $ p $ -norms度量的投入接近度对于感知相似性既不是必要也不足够的，这对创造和防御敌对的例子都有影响。

##### URL
[https://arxiv.org/abs/1802.09653](https://arxiv.org/abs/1802.09653)

##### PDF
[https://arxiv.org/pdf/1802.09653](https://arxiv.org/pdf/1802.09653)

