---
layout: post
title: "Adversarial Examples to Fool Iris Recognition Systems"
date: 2019-06-21 19:30:41
categories: arXiv_CV
tags: arXiv_CV Adversarial Deep_Learning Recognition
author: Sobhan Soleymani, Ali Dabouei, Jeremy Dawson, Nasser M. Nasrabadi
mathjax: true
---

* content
{:toc}

##### Abstract
Adversarial examples have recently proven to be able to fool deep learning methods by adding carefully crafted small perturbation to the input space image. In this paper, we study the possibility of generating adversarial examples for code-based iris recognition systems. Since generating adversarial examples requires back-propagation of the adversarial loss, conventional filter bank-based iris-code generation frameworks cannot be employed in such a setup. Therefore, to compensate for this shortcoming, we propose to train a deep auto-encoder surrogate network to mimic the conventional iris code generation procedure. This trained surrogate network is then deployed to generate the adversarial examples using the iterative gradient sign method algorithm. We consider non-targeted and targeted attacks through three attack scenarios. Considering these attacks, we study the possibility of fooling an iris recognition system in white-box and black-box frameworks.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.09300](http://arxiv.org/abs/1906.09300)

##### PDF
[http://arxiv.org/pdf/1906.09300](http://arxiv.org/pdf/1906.09300)

