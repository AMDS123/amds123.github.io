---
layout: post
title: "Learning Generic Sentence Representations Using Convolutional Neural Networks"
date: 2017-07-26 20:48:52
categories: arXiv_CL
tags: arXiv_CL CNN Prediction
author: Zhe Gan, Yunchen Pu, Ricardo Henao, Chunyuan Li, Xiaodong He, Lawrence Carin
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a new encoder-decoder approach to learn distributed sentence representations that are applicable to multiple purposes. The model is learned by using a convolutional neural network as an encoder to map an input sentence into a continuous vector, and using a long short-term memory recurrent neural network as a decoder. Several tasks are considered, including sentence reconstruction and future sentence prediction. Further, a hierarchical encoder-decoder model is proposed to encode a sentence to predict multiple future sentences. By training our models on a large collection of novels, we obtain a highly generic convolutional sentence encoder that performs well in practice. Experimental results on several benchmark datasets, and across a broad range of applications, demonstrate the superiority of the proposed model over competing methods.

##### Abstract (translated by Google)
我们提出了一种新的编码器 - 解码器方法来学习适用于多种目的的分布式句子表示。通过使用卷积神经网络作为编码器将输入句子映射为连续向量，并使用长的短期记忆递归神经网络作为解码器来学习该模型。考虑几个任务，包括句子重建和将来的句子预测。此外，提出了分层编码器 - 解码器模型来对句子进行编码以预测多个将来的句子。通过在大量的小说集上训练我们的模型，我们获得了一个高度通用的卷积句子编码器，在实践中表现良好。在几个基准数据集上以及在广泛的应用中的实验结果证明了所提出的模型优于竞争方法的优势。

##### URL
[https://arxiv.org/abs/1611.07897](https://arxiv.org/abs/1611.07897)

##### PDF
[https://arxiv.org/pdf/1611.07897](https://arxiv.org/pdf/1611.07897)

