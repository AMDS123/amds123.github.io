---
layout: post
title: "Deep Underwater Image Enhancement"
date: 2018-07-10 08:44:04
categories: arXiv_CV
tags: arXiv_CV Image_Enhancement CNN Quantitative
author: Saeed Anwar, Chongyi Li, Fatih Porikli
mathjax: true
---

* content
{:toc}

##### Abstract
In an underwater scene, wavelength-dependent light absorption and scattering degrade the visibility of images, causing low contrast and distorted color casts. To address this problem, we propose a convolutional neural network based image enhancement model, i.e., UWCNN, which is trained efficiently using a synthetic underwater image database. Unlike the existing works that require the parameters of underwater imaging model estimation or impose inflexible frameworks applicable only for specific scenes, our model directly reconstructs the clear latent underwater image by leveraging on an automatic end-to-end and data-driven training mechanism. Compliant with underwater imaging models and optical properties of underwater scenes, we first synthesize ten different marine image databases. Then, we separately train multiple UWCNN models for each underwater image formation type. Experimental results on real-world and synthetic underwater images demonstrate that the presented method generalizes well on different underwater scenes and outperforms the existing methods both qualitatively and quantitatively. Besides, we conduct an ablation study to demonstrate the effect of each component in our network.

##### Abstract (translated by Google)
在水下场景中，依赖于波长的光吸收和散射会降低图像的可见度，从而导致低对比度和失真的色偏。为了解决这个问题，我们提出了一种基于卷积神经网络的图像增强模型，即UWCNN，它使用合成水下图像数据库进行有效训练。与需要水下成像模型估计参数或仅适用于特定场景的不灵活框架的现有工作不同，我们的模型通过利用自动端到端和数据驱动的训练机制直接重建清晰的潜在水下图像。我们首先合成了十种不同的海洋图像数据库，符合水下成像模型和水下场景的光学特性。然后，我们为每个水下图像形成类型分别训练多个UWCNN模型。实际和合成水下图像的实验结果表明，所提出的方法在不同的水下场景中得到了很好的推广，并且在质量和数量上均优于现有方法。此外，我们进行消融研究，以证明我们网络中每个组成部分的影响。

##### URL
[http://arxiv.org/abs/1807.03528](http://arxiv.org/abs/1807.03528)

##### PDF
[http://arxiv.org/pdf/1807.03528](http://arxiv.org/pdf/1807.03528)

