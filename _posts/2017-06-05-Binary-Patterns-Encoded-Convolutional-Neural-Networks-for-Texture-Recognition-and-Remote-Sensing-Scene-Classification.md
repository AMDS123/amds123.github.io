---
layout: post
title: "Binary Patterns Encoded Convolutional Neural Networks for Texture Recognition and Remote Sensing Scene Classification"
date: 2017-06-05 00:53:06
categories: arXiv_CV
tags: arXiv_CV Knowledge CNN Classification Recognition
author: Rao Muhammad Anwer, Fahad Shahbaz Khan, Joost van de Weijer, Matthieu Molinier, Jorma Laaksonen
mathjax: true
---

* content
{:toc}

##### Abstract
Designing discriminative powerful texture features robust to realistic imaging conditions is a challenging computer vision problem with many applications, including material recognition and analysis of satellite or aerial imagery. In the past, most texture description approaches were based on dense orderless statistical distribution of local features. However, most recent approaches to texture recognition and remote sensing scene classification are based on Convolutional Neural Networks (CNNs). The d facto practice when learning these CNN models is to use RGB patches as input with training performed on large amounts of labeled data (ImageNet). In this paper, we show that Binary Patterns encoded CNN models, codenamed TEX-Nets, trained using mapped coded images with explicit texture information provide complementary information to the standard RGB deep models. Additionally, two deep architectures, namely early and late fusion, are investigated to combine the texture and color information. To the best of our knowledge, we are the first to investigate Binary Patterns encoded CNNs and different deep network fusion architectures for texture recognition and remote sensing scene classification. We perform comprehensive experiments on four texture recognition datasets and four remote sensing scene classification benchmarks: UC-Merced with 21 scene categories, WHU-RS19 with 19 scene classes, RSSCN7 with 7 categories and the recently introduced large scale aerial image dataset (AID) with 30 aerial scene types. We demonstrate that TEX-Nets provide complementary information to standard RGB deep model of the same network architecture. Our late fusion TEX-Net architecture always improves the overall performance compared to the standard RGB network on both recognition problems. Our final combination outperforms the state-of-the-art without employing fine-tuning or ensemble of RGB network architectures.

##### Abstract (translated by Google)
设计具有鲁棒逼真成像条件的差异化强大纹理特征是一个具有挑战性的计算机视觉问题，其中包括对卫星或航空影像的材料识别和分析。过去，大多数纹理描述方法都是基于局部特征的密集无序统计分布。然而，最近的纹理识别和遥感场景分类方法是基于卷积神经网络（CNN）。学习这些CNN模型时的实际做法是使用RGB补丁作为对大量标记数据（ImageNet）进行训练的输入。在本文中，我们展示二进制编码编码CNN模型，代号为TEX-Nets，使用具有显式纹理信息的映射编码图像进行训练，为标准RGB深模型提供补充信息。此外，还研究了两种深度架构，即早期和晚期融合，以结合纹理和颜色信息。据我们所知，我们是第一个研究二进制编码的CNN和不同的深度网络融合架构的纹理识别和遥感场景分类。我们在四个纹理识别数据集和四个遥感场景分类基准上进行了综合实验：具有21个场景类别的UC-Merced，19个场景类别的WHU-RS19，7个类别的RSSCN7以及最近引入的大规模航空图像数据集（AID） 30个空中场景类型。我们证明了TEX-Nets为相同网络体系结构的标准RGB深层模型提供了补充信息。我们后期的融合TEX-Net体系结构与标准RGB网络相比，在识别问题上始终提高整体性能。我们的最终组合胜过最先进的技术，无需采用微调或RGB网络体系结构。

##### URL
[https://arxiv.org/abs/1706.01171](https://arxiv.org/abs/1706.01171)

##### PDF
[https://arxiv.org/pdf/1706.01171](https://arxiv.org/pdf/1706.01171)

