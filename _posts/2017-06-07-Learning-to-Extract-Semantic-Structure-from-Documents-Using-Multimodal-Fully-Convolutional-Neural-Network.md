---
layout: post
title: "Learning to Extract Semantic Structure from Documents Using Multimodal Fully Convolutional Neural Network"
date: 2017-06-07 18:51:31
categories: arXiv_CV
tags: arXiv_CV Segmentation CNN
author: Xiao Yang, Ersin Yumer, Paul Asente, Mike Kraley, Daniel Kifer, C. Lee Giles
mathjax: true
---

* content
{:toc}

##### Abstract
We present an end-to-end, multimodal, fully convolutional network for extracting semantic structures from document images. We consider document semantic structure extraction as a pixel-wise segmentation task, and propose a unified model that classifies pixels based not only on their visual appearance, as in the traditional page segmentation task, but also on the content of underlying text. Moreover, we propose an efficient synthetic document generation process that we use to generate pretraining data for our network. Once the network is trained on a large set of synthetic documents, we fine-tune the network on unlabeled real documents using a semi-supervised approach. We systematically study the optimum network architecture and show that both our multimodal approach and the synthetic data pretraining significantly boost the performance.

##### Abstract (translated by Google)
我们提出了一个从文档图像中提取语义结构的端到端多模态完全卷积网络。我们将文档语义结构提取视为一个像素明智的分割任务，并提出了一个统一的模型，不仅像传统的页面分割任务一样，而且还基于文本的内容，不仅基于其视觉外观对像素进行分类。此外，我们提出了一个高效的合成文件生成过程，我们用它来为我们的网络生成预训练数据。一旦网络在大量的合成文档上被训练，我们使用半监督方法对未标记的真实文档上的网络进行微调。我们系统地研究了最佳的网络结构，表明我们的多模式方法和合成数据预训练显着地提高了性能。

##### URL
[https://arxiv.org/abs/1706.02337](https://arxiv.org/abs/1706.02337)

##### PDF
[https://arxiv.org/pdf/1706.02337](https://arxiv.org/pdf/1706.02337)

