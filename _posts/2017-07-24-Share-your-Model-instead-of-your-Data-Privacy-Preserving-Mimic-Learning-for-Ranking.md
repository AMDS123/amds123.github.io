---
layout: post
title: "Share your Model instead of your Data: Privacy Preserving Mimic Learning for Ranking"
date: 2017-07-24 15:23:41
categories: arXiv_CL
tags: arXiv_CL Knowledge Prediction
author: Mostafa Dehghani, Hosein Azarbonyad, Jaap Kamps, Maarten de Rijke
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks have become a primary tool for solving problems in many fields. They are also used for addressing information retrieval problems and show strong performance in several tasks. Training these models requires large, representative datasets and for most IR tasks, such data contains sensitive information from users. Privacy and confidentiality concerns prevent many data owners from sharing the data, thus today the research community can only benefit from research on large-scale datasets in a limited manner. In this paper, we discuss privacy preserving mimic learning, i.e., using predictions from a privacy preserving trained model instead of labels from the original sensitive training data as a supervision signal. We present the results of preliminary experiments in which we apply the idea of mimic learning and privacy preserving mimic learning for the task of document re-ranking as one of the core IR tasks. This research is a step toward laying the ground for enabling researchers from data-rich environments to share knowledge learned from actual users' data, which should facilitate research collaborations.

##### Abstract (translated by Google)
深度神经网络已经成为解决许多领域问题的主要工具。它们也用于解决信息检索问题，并在几个任务中表现出强大的表现。培训这些模型需要大量的，有代表性的数据集，对于大多数IR任务，这些数据包含来自用户的敏感信息。隐私和机密性问题妨碍了许多数据所有者共享数据，因此今天研究界只能从有限的大规模数据集的研究中受益。在本文中，我们讨论隐私保护模仿学习，即使用来自隐私保护训练模型的预测而不是来自原始敏感训练数据的标签作为监督信号。我们提出了初步实验的结果，其中我们将模拟学习和隐私保护模拟学习的思想应用于文档重新排序的任务，作为核心IR任务之一。这项研究是为使数据丰富的环境中的研究人员分享从实际用户数据中获得的知识奠定基础的一个步骤，这将有助于研究合作。

##### URL
[https://arxiv.org/abs/1707.07605](https://arxiv.org/abs/1707.07605)

##### PDF
[https://arxiv.org/pdf/1707.07605](https://arxiv.org/pdf/1707.07605)

