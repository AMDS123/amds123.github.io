---
layout: post
title: "War: Detecting adversarial examples by pre-processing input data"
date: 2019-05-15 05:38:29
categories: arXiv_CV
tags: arXiv_CV Adversarial Speech_Recognition Image_Classification Classification Detection Recognition
author: Hua Wang, Jie Wang, Zhaoxia Yin
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks (DNNs) have demonstrated their outstanding performance in many fields such as image classification and speech recognition. However, DNNs image classifiers are susceptible to interference from adversarial examples, which ultimately leads to incorrect classification output of neural network models. Based on this, this paper proposes a method based on War (WebPcompression and resize) to detect adversarial examples. The method takes WebP compression as the core, firstly performs WebP compression on the input image, and then appropriately resizes the compressed image, so that the label of the adversarial example changes, thereby detecting the existence of the adversarial image. The experimental results show that the proposed method can effectively resist IFGSM, DeepFool and C&amp;W attacks, and the recognition accuracy is improved by more than 10% compared with the HGD method, the detection success rate of adversarial examples is 5% higher than that of the Feature Squeezing method. The method in this paper can effectively reduce the small noise disturbance in the adversarial image, and accurately detect the adversarial example according to the change of the samplelabelwhileensuringtheaccuracyoftheoriginalsampleidentification.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.08614](http://arxiv.org/abs/1905.08614)

##### PDF
[http://arxiv.org/pdf/1905.08614](http://arxiv.org/pdf/1905.08614)

