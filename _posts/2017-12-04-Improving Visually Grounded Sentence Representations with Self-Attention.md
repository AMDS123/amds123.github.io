---
layout: post
title:  'Improving Visually Grounded Sentence Representations with Self-Attention'
date:   2017-12-05 19:45:32
categories: arXiv_CL
arXiv_CL
author: Kang Min Yoo, Youhyun Shin, Sang-goo Lee
---

* content
{:toc}

##### Abstract
Sentence representation models trained only on language could potentially suffer from the grounding problem. Recent work has shown promising results in improving the qualities of sentence representations by jointly training them with associated image features. However, the grounding capability is limited due to distant connection between input sentences and image features by the design of the architecture. In order to further close the gap, we propose applying self-attention mechanism to the sentence encoder to deepen the grounding effect. Our results on transfer tasks show that self-attentive encoders are better for visual grounding, as they exploit specific words with strong visual associations.

##### Abstract (translated by Google)
只用语言训练的句子表示模型可能会受到接地问题的困扰。最近的研究表明，通过联合培训他们的相关图像特征来提高句子表征的质量，是有希望的结果。然而，由于架构的设计，输入语句与图像特征之间的距离较远，因此接地能力有限。为了进一步缩小差距，我们建议在句子编码器中应用自我注意机制来加深接地效应。我们在转移任务上的结果表明，自我关注的编码器更适合视觉基础，因为他们利用具有强烈视觉关联的特定词语。

##### URL
[http://arxiv.org/abs/1712.00609](http://arxiv.org/abs/1712.00609)

