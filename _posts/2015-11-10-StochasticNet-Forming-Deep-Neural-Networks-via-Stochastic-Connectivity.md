---
layout: post
title: "StochasticNet: Forming Deep Neural Networks via Stochastic Connectivity"
date: 2015-11-10 20:30:05
categories: arXiv_CV
tags: arXiv_CV
author: Mohammad Javad Shafiee, Parthipan Siva, Alexander Wong
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks is a branch in machine learning that has seen a meteoric rise in popularity due to its powerful abilities to represent and model high-level abstractions in highly complex data. One area in deep neural networks that is ripe for exploration is neural connectivity formation. A pivotal study on the brain tissue of rats found that synaptic formation for specific functional connectivity in neocortical neural microcircuits can be surprisingly well modeled and predicted as a random formation. Motivated by this intriguing finding, we introduce the concept of StochasticNet, where deep neural networks are formed via stochastic connectivity between neurons. As a result, any type of deep neural networks can be formed as a StochasticNet by allowing the neuron connectivity to be stochastic. Stochastic synaptic formations, in a deep neural network architecture, can allow for efficient utilization of neurons for performing specific tasks. To evaluate the feasibility of such a deep neural network architecture, we train a StochasticNet using four different image datasets (CIFAR-10, MNIST, SVHN, and STL-10). Experimental results show that a StochasticNet, using less than half the number of neural connections as a conventional deep neural network, achieves comparable accuracy and reduces overfitting on the CIFAR-10, MNIST and SVHN dataset. Interestingly, StochasticNet with less than half the number of neural connections, achieved a higher accuracy (relative improvement in test error rate of ~6% compared to ConvNet) on the STL-10 dataset than a conventional deep neural network. Finally, StochasticNets have faster operational speeds while achieving better or similar accuracy performances.

##### Abstract (translated by Google)
深度神经网络是机器学习中的一个分支，由于其在高度复杂的数据中表现和建模高级抽象的强大能力，因此深受其欢迎。深度神经网络中一个成熟的探索领域是神经连接的形成。关于大鼠脑组织的关键研究发现，新皮质神经微循环中特定功能连接的突触形成可以令人惊讶地很好地模拟和预测为随机形成。受这个有趣的发现的启发，我们引入了随机网络的概念，在那里通过神经元之间的随机连接形成深度神经网络。因此，任何类型的深度神经网络都可以通过允许神经元连接性是随机的而形成为随机网络。在深度神经网络体系结构中，随机突触形成可以允许有效地利用神经元来执行特定的任务。为了评估这种深度神经网络架构的可行性，我们使用四个不同的图像数据集（CIFAR-10，MNIST，SVHN和STL-10）来训练一个随机网络。实验结果表明，一个随机网络，使用少于神经连接的数量的一半作为传统的深度神经网络，达到相当的准确性，并减少CIFAR-10，MNIST和SVHN数据集的过度拟合。有趣的是，与传统的深度神经网络相比，STL-10数据集中的神经连接数量少于一半的随机网络具有更高的准确性（与ConvNet相比测试误差率相对提高了约6％）。最后，随机网具有更快的运行速度，同时达到更好或相似的精度性能。

##### URL
[https://arxiv.org/abs/1508.05463](https://arxiv.org/abs/1508.05463)

##### PDF
[https://arxiv.org/pdf/1508.05463](https://arxiv.org/pdf/1508.05463)

