---
layout: post
title: "Adversarial Attacks on Variational Autoencoders"
date: 2018-06-12 16:59:14
categories: arXiv_CV
tags: arXiv_CV Adversarial Attention CNN Quantitative
author: George Gondim-Ribeiro, Pedro Tabacof, Eduardo Valle
mathjax: true
---

* content
{:toc}

##### Abstract
Adversarial attacks are malicious inputs that derail machine-learning models. We propose a scheme to attack autoencoders, as well as a quantitative evaluation framework that correlates well with the qualitative assessment of the attacks. We assess --- with statistically validated experiments --- the resistance to attacks of three variational autoencoders (simple, convolutional, and DRAW) in three datasets (MNIST, SVHN, CelebA), showing that both DRAW's recurrence and attention mechanism lead to better resistance. As autoencoders are proposed for compressing data --- a scenario in which their safety is paramount --- we expect more attention will be given to adversarial attacks on them.

##### Abstract (translated by Google)
敌对攻击是破坏机器学习模型的恶意输入。我们提出攻击自动编码器的方案，以及与攻击的定性评估相关的定量评估框架。我们通过统计验证的实验评估---在三个数据集（MNIST，SVHN，CelebA）中对三种变异自动编码器（简单，卷积和DRAW）攻击的抵抗能力，表明DRAW的复发和关注机制导致更好抵抗性。由于自动编码器被建议用于压缩数据---一种安全性至关重要的场景---我们期望对它们的对抗性攻击给予更多的关注。

##### URL
[http://arxiv.org/abs/1806.04646](http://arxiv.org/abs/1806.04646)

##### PDF
[http://arxiv.org/pdf/1806.04646](http://arxiv.org/pdf/1806.04646)

