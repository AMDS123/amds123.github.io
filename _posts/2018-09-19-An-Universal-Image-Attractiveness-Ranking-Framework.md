---
layout: post
title: "An Universal Image Attractiveness Ranking Framework"
date: 2018-09-19 06:27:01
categories: arXiv_CV
tags: arXiv_CV CNN
author: Ning Ma, Alexey Volkov, Aleksandr Livshits, Pawel Pietrusinski, Houdong Hu, Mark Bolin
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a new framework to rank image attractiveness using a novel pairwise deep network trained with a large set of side-by-side multi-labeled image pairs from a web image index. The judges only provide relative ranking between two images without the need to directly assign an absolute score, or rate any predefined image attribute, thus making the rating more intuitive and straightforward. We investigate a deep attractiveness rank net (DARN), a combination of deep convolutional neural network and rank net, to directly learn an attractiveness score mean and variance for each image and the underlying criteria the judges use to label each pair. The extension of this model (DARN-V2) is able to adapt to individual judge's personal preference. We also show the attractiveness of search results are significantly improved by using this attractiveness information in a real commercial search engine. We evaluate our model against other state-of-the-art models on our side-by-side web test data and another public aesthetic data set. Our model outperforms on side-by-side labeled data, and is competitive on data labeled by absolute score.

##### Abstract (translated by Google)
我们提出了一种新的框架，使用来自网络图像索引的大量并排多标记图像对训练的新型成对深度网络对图像吸引力进行排序。评委仅提供两个图像之间的相对排名，而无需直接分配绝对分数，或对任何预定义图像属性进行评级，从而使评级更直观和直接。我们研究深度吸引力等级网（DARN），深度卷积神经网络和等级网络的组合，直接学习每个图像的吸引力得分均值和方差以及评判者用来标记每对的基本标准。该模型（DARN-V2）的扩展能够适应个体法官的个人偏好。我们还通过在真实的商业搜索引擎中使用这种吸引力信息来显示搜索结果的吸引力得到显着改善。我们根据我们的并排网络测试数据和另一个公共美学数据集评估我们的模型与其他最先进的模型。我们的模型优于并排标记数据，并且在绝对分数标记的数据上具有竞争力。

##### URL
[http://arxiv.org/abs/1805.00309](http://arxiv.org/abs/1805.00309)

##### PDF
[http://arxiv.org/pdf/1805.00309](http://arxiv.org/pdf/1805.00309)

