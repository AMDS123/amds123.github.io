---
layout: post
title: "Eliminating the Blind Spot: Adapting 3D Object Detection and Monocular Depth Estimation to 360{deg} Panoramic Imagery"
date: 2018-08-19 20:38:08
categories: arXiv_CV
tags: arXiv_CV Object_Detection Quantitative Detection
author: Gr&#xe9;goire Payen de La Garanderie, Amir Atapour Abarghouei, Toby P. Breckon
mathjax: true
---

* content
{:toc}

##### Abstract
Recent automotive vision work has focused almost exclusively on processing forward-facing cameras. However, future autonomous vehicles will not be viable without a more comprehensive surround sensing, akin to a human driver, as can be provided by 360{\deg} panoramic cameras. We present an approach to adapt contemporary deep network architectures developed on conventional rectilinear imagery to work on equirectangular 360{\deg} panoramic imagery. To address the lack of annotated panoramic automotive datasets availability, we adapt a contemporary automotive dataset, via style and projection transformations, to facilitate the cross-domain retraining of contemporary algorithms for panoramic imagery. Following this approach we retrain and adapt existing architectures to recover scene depth and 3D pose of vehicles from monocular panoramic imagery without any panoramic training labels or calibration parameters. Our approach is evaluated qualitatively on crowd-sourced panoramic images and quantitatively using an automotive environment simulator to provide the first benchmark for such techniques within panoramic imagery.

##### Abstract (translated by Google)
最近的汽车视觉工作几乎专注于处理前向摄像头。然而，如果没有更全面的环绕声感应（类似于人类驾驶员），未来的自动驾驶汽车将无法生存，因为可以通过360 {\ deg}全景摄像机提供。我们提出了一种方法，以适应在传统直线图像上开发的当代深度网络架构，以便在equirectangular 360 {\ deg}全景图像上工作。为了解决缺乏注释的全景汽车数据集可用性问题，我们通过风格和投影变换来调整当代汽车数据集，以促进当代算法的跨域重新训练以获得全景图像。按照这种方法，我们重新训练和调整现有的架构，以从单眼全景图像中恢复车辆的场景深度和3D姿态，而无需任何全景训练标签或校准参数。我们的方法在人群全景图像上进行定性评估，并使用汽车环境模拟器进行定量评估，为全景图像中的此类技术提供第一个基准。

##### URL
[http://arxiv.org/abs/1808.06253](http://arxiv.org/abs/1808.06253)

##### PDF
[http://arxiv.org/pdf/1808.06253](http://arxiv.org/pdf/1808.06253)

