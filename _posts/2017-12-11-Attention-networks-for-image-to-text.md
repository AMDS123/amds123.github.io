---
layout: post
title: "Attention networks for image-to-text"
date: 2017-12-11 21:57:03
categories: arXiv_CV
tags: arXiv_CV Image_Caption Attention RNN
author: Jason Poulos, Rafael Valle
mathjax: true
---

* content
{:toc}

##### Abstract
The paper approaches the problem of image-to-text with attention-based encoder-decoder networks that are trained to handle sequences of characters rather than words. We experiment on lines of text from a popular handwriting database with different attention mechanisms for the decoder. The model trained with softmax attention achieves the lowest test error, outperforming several other RNN-based models. Our results show that softmax attention is able to learn a linear alignment whereas the alignment generated by sigmoid attention is linear but much less precise.

##### Abstract (translated by Google)
本文用基于注意力的编码器 - 解码器网络来处理图像到文本的问题，这些网络经过训练处理字符序列而不是单词。我们在流行的手写数据库中对不同的解码器的注意机制进行实验。用softmax注意力训练的模型实现了最低的测试误差，优于其他几种基于RNN的模型。我们的研究结果表明softmax注意力能够学习线性对齐，而由sigmoid注意力产生的对齐是线性的，但不太精确。

##### URL
[http://arxiv.org/abs/1712.04046](http://arxiv.org/abs/1712.04046)

##### PDF
[http://arxiv.org/pdf/1712.04046](http://arxiv.org/pdf/1712.04046)

