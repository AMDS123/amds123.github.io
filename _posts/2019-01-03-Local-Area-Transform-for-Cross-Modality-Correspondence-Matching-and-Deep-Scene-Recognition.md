---
layout: post
title: "Local Area Transform for Cross-Modality Correspondence Matching and Deep Scene Recognition"
date: 2019-01-03 22:12:20
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Recognition
author: Seungchul Ryu
mathjax: true
---

* content
{:toc}

##### Abstract
Establishing correspondences is a fundamental task in variety of image processing and computer vision applications. In particular, finding the correspondences between a non-linearly deformed image pair induced by different modality conditions is a challenging problem. This paper describes a efficient but powerful image transform called local area transform (LAT) for modality-robust correspondence estimation. Specifically, LAT transforms an image from the intensity domain to the local area domain, which is invariant under nonlinear intensity deformations, especially radiometric, photometric, and spectral deformations. In addition, robust feature descriptors are reformulated with LAT for several practical applications. Furthermore, LAT-convolution layer and Aception block are proposed and, with these novel components, deep neural network called LAT-Net is proposed especially for scene recognition task. Experimental results show that LATransformed images provide a consistency for nonlinearly deformed images, even under random intensity deformations. LAT reduces the mean absolute difference as compared to conventional methods. Furthermore, the reformulation of descriptors with LAT shows superiority to conventional methods, which is a promising result for the tasks of cross-spectral and modality correspondence matching. the local area can be considered as an alternative domain to the intensity domain to achieve robust correspondence matching, image recognition, and a lot of applications: such as feature matching, stereo matching, dense correspondence matching, image recognition, and image retrieval.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1901.00927](https://arxiv.org/abs/1901.00927)

##### PDF
[https://arxiv.org/pdf/1901.00927](https://arxiv.org/pdf/1901.00927)

