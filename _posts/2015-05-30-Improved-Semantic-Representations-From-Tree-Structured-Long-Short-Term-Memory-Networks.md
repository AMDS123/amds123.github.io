---
layout: post
title: "Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"
date: 2015-05-30 06:51:20
categories: arXiv_CV
tags: arXiv_CV Sentiment Sentiment_Classification RNN Classification Memory_Networks
author: Kai Sheng Tai, Richard Socher, Christopher D. Manning
mathjax: true
---

* content
{:toc}

##### Abstract
Because of their superior ability to preserve sequence information over time, Long Short-Term Memory (LSTM) networks, a type of recurrent neural network with a more complex computational unit, have obtained strong results on a variety of sequence modeling tasks. The only underlying LSTM structure that has been explored so far is a linear chain. However, natural language exhibits syntactic properties that would naturally combine words to phrases. We introduce the Tree-LSTM, a generalization of LSTMs to tree-structured network topologies. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences (SemEval 2014, Task 1) and sentiment classification (Stanford Sentiment Treebank).

##### Abstract (translated by Google)
由于长期短期记忆（LSTM）网络（一种具有更复杂计算单元的递归神经网络）具有优良的保持序列信息的能力，因此在各种序列建模任务中获得了强大的结果。到目前为止，探索的唯一基础LSTM结构是一个线性链。然而，自然语言展现了自然地将单词与短语结合的句法属性。我们介绍Tree-LSTM，一种LSTM到树形网络拓扑的推广。 Tree-LSTM在两个任务中胜过所有现有系统和强大的LSTM基线：预测两个句子（SemEval 2014，Task 1）和情感分类（Stanford Sentiment Treebank）的语义相关性。

##### URL
[https://arxiv.org/abs/1503.00075](https://arxiv.org/abs/1503.00075)

##### PDF
[https://arxiv.org/pdf/1503.00075](https://arxiv.org/pdf/1503.00075)

