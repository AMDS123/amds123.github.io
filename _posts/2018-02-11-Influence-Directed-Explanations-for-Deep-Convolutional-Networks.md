---
layout: post
title: "Influence-Directed Explanations for Deep Convolutional Networks"
date: 2018-02-11 18:28:56
categories: arXiv_AI
tags: arXiv_AI CNN Classification
author: Klas Leino, Linyi Li, Shayak Sen, Anupam Datta, Matt Fredrikson
mathjax: true
---

* content
{:toc}

##### Abstract
We study the problem of explaining a rich class of behavioral properties of deep neural networks. Distinctively, our influence-directed explanations approach this problem by peering inside the net- work to identify neurons with high influence on the property and distribution of interest using an axiomatically justified influence measure, and then providing an interpretation for the concepts these neurons represent. We evaluate our approach by training convolutional neural net- works on MNIST, ImageNet, Pubfig, and Diabetic Retinopathy datasets. Our evaluation demonstrates that influence-directed explanations (1) identify influential concepts that generalize across instances, (2) help extract the essence of what the network learned about a class, (3) isolate individual features the network uses to make decisions and distinguish related instances, and (4) assist in understanding misclassifications.

##### Abstract (translated by Google)
我们研究解释深度神经网络的一类丰富的行为特性的问题。与此不同的是，我们的影响导向解释通过在网络内部窥视以使用公理化的合理影响度量来识别对性质和感兴趣分布具有高度影响的神经元，然后为这些神经元所代表的概念提供解释。我们通过训练MNIST，ImageNet，Pubfig和糖尿病视网膜病变数据集上的卷积神经网络来评估我们的方法。我们的评估表明，影响导向的解释（1）确定了影响力概念，推广实例，（2）帮助提取网络学习关于类的本质，（3）隔离网络用于制定决策和区分相关的个别特征（4）帮助理解错误分类。

##### URL
[http://arxiv.org/abs/1802.03788](http://arxiv.org/abs/1802.03788)

##### PDF
[http://arxiv.org/pdf/1802.03788](http://arxiv.org/pdf/1802.03788)

