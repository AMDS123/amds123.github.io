---
layout: post
title: "A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs"
date: 2016-12-17 06:47:05
categories: arXiv_CL
tags: arXiv_CL Text_Classification RNN Classification
author: Shayne Longpre, Sabeek Pradhan, Caiming Xiong, Richard Socher
mathjax: true
---

* content
{:toc}

##### Abstract
LSTMs have become a basic building block for many deep NLP models. In recent years, many improvements and variations have been proposed for deep sequence models in general, and LSTMs in particular. We propose and analyze a series of augmentations and modifications to LSTM networks resulting in improved performance for text classification datasets. We observe compounding improvements on traditional LSTMs using Monte Carlo test-time model averaging, average pooling, and residual connections, along with four other suggested modifications. Our analysis provides a simple, reliable, and high quality baseline model.

##### Abstract (translated by Google)
LSTM已经成为许多深度NLP模型的基本构建模块。近年来，对于一般的深度序列模型，尤其是LSTM，已经提出了许多改进和变化。我们提出并分析了一系列对LSTM网络的增强和修改，从而提高了文本分类数据集的性能。我们观察到使用蒙特卡罗测试时间模型平均，平均汇集和剩余连接以及其他四个建议的修改对传统LSTM的复合改进。我们的分析提供了一个简单，可靠，高质量的基准模型。

##### URL
[https://arxiv.org/abs/1611.05104](https://arxiv.org/abs/1611.05104)

##### PDF
[https://arxiv.org/pdf/1611.05104](https://arxiv.org/pdf/1611.05104)

