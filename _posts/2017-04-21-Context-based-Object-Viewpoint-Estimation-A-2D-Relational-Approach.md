---
layout: post
title: "Context-based Object Viewpoint Estimation: A 2D Relational Approach"
date: 2017-04-21 15:55:54
categories: arXiv_CV
tags: arXiv_CV Object_Detection Action_Recognition Prediction Detection Relation Recognition
author: Jose Oramas, Luc De Raedt, Tinne Tuytelaars
mathjax: true
---

* content
{:toc}

##### Abstract
The task of object viewpoint estimation has been a challenge since the early days of computer vision. To estimate the viewpoint (or pose) of an object, people have mostly looked at object intrinsic features, such as shape or appearance. Surprisingly, informative features provided by other, extrinsic elements in the scene, have so far mostly been ignored. At the same time, contextual cues have been proven to be of great benefit for related tasks such as object detection or action recognition. In this paper, we explore how information from other objects in the scene can be exploited for viewpoint estimation. In particular, we look at object configurations by following a relational neighbor-based approach for reasoning about object relations. We show that, starting from noisy object detections and viewpoint estimates, exploiting the estimated viewpoint and location of other objects in the scene can lead to improved object viewpoint predictions. Experiments on the KITTI dataset demonstrate that object configurations can indeed be used as a complementary cue to appearance-based viewpoint estimation. Our analysis reveals that the proposed context-based method can improve object viewpoint estimation by reducing specific types of viewpoint estimation errors commonly made by methods that only consider local information. Moreover, considering contextual information produces superior performance in scenes where a high number of object instances occur. Finally, our results suggest that, following a cautious relational neighbor formulation brings improvements over its aggressive counterpart for the task of object viewpoint estimation.

##### Abstract (translated by Google)
从计算机视觉的早期开始，对象视点估计的任务一直是一个挑战。为了估计物体的视角（或姿态），人们主要观察物体的内在特征，例如形状或外观。令人惊讶的是，由场景中的其他外在因素提供的信息特征迄今为止大部分被忽略。同时，上下文线索已被证明对相关任务（如对象检测或动作识别）有很大的好处。在本文中，我们探索如何利用场景中其他物体的信息进行视点估计。具体来说，我们通过遵循关系相邻的方法来推理对象关系来观察对象配置。我们表明，从噪声对象检测和视点估计开始，利用估计的视点和场景中其他对象的位置可以导致改进的对象视点预测。 KITTI数据集上的实验表明，对象配置确实可以用作基于外观的视点估计的补充提示。我们的分析表明，所提出的基于上下文的方法可以通过减少通常由仅考虑局部信息的方法通常所做的特定类型的视点估计误差来改善对象视点估计。此外，考虑到上下文信息在出现大量对象实例的场景中产生优越的性能。最后，我们的研究结果表明，遵循谨慎的关系邻居公式带来了改善对于对象视点估计任务的积极的对手。

##### URL
[https://arxiv.org/abs/1704.06610](https://arxiv.org/abs/1704.06610)

##### PDF
[https://arxiv.org/pdf/1704.06610](https://arxiv.org/pdf/1704.06610)

