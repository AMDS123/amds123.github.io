---
layout: post
title: "Explaining Predictions of Non-Linear Classifiers in NLP"
date: 2016-06-23 12:53:31
categories: arXiv_CL
tags: arXiv_CL CNN Image_Classification Classification Prediction Quantitative
author: Leila Arras, Franziska Horn, Grégoire Montavon, Klaus-Robert Müller, Wojciech Samek
mathjax: true
---

* content
{:toc}

##### Abstract
Layer-wise relevance propagation (LRP) is a recently proposed technique for explaining predictions of complex non-linear classifiers in terms of input variables. In this paper, we apply LRP for the first time to natural language processing (NLP). More precisely, we use it to explain the predictions of a convolutional neural network (CNN) trained on a topic categorization task. Our analysis highlights which words are relevant for a specific prediction of the CNN. We compare our technique to standard sensitivity analysis, both qualitatively and quantitatively, using a "word deleting" perturbation experiment, a PCA analysis, and various visualizations. All experiments validate the suitability of LRP for explaining the CNN predictions, which is also in line with results reported in recent image classification studies.

##### Abstract (translated by Google)
分层相关传播（LRP）是最近提出的用于解释输入变量的复杂非线性分类器的预测的技术。在本文中，我们首次将LRP应用于自然语言处理（NLP）。更准确地说，我们用它来解释在主题分类任务上训练的卷积神经网络（CNN）的预测。我们的分析强调哪些词与CNN的具体预测有关。我们将我们的技术与定性和定量的标准灵敏度分析进行比较，使用“删除词”微扰实验，PCA分析和各种可视化。所有的实验验证了LRP解释CNN预测的适用性，这也与最近的图像分类研究报道的结果一致。

##### URL
[https://arxiv.org/abs/1606.07298](https://arxiv.org/abs/1606.07298)

##### PDF
[https://arxiv.org/pdf/1606.07298](https://arxiv.org/pdf/1606.07298)

