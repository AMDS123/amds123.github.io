---
layout: post
title: "Normalization Before Shaking Toward Learning Symmetrically Distributed Representation Without Margin in Speech Emotion Recognition"
date: 2018-08-02 15:57:57
categories: arXiv_SD
tags: arXiv_SD Regularization Attention Face RNN Classification Deep_Learning Recognition
author: Che-Wei Huang, Shrikanth S. Narayanan
mathjax: true
---

* content
{:toc}

##### Abstract
Regularization is crucial to the success of many practical deep learning models, in particular in a more often than not scenario where there are only a few to a moderate number of accessible training samples. In addition to weight decay, data augmentation and dropout, regularization based on multi-branch architectures, such as Shake-Shake regularization, has been proven successful in many applications and attracted more and more attention. However, beyond model-based representation augmentation, it is unclear how Shake-Shake regularization helps to provide further improvement on classification tasks, let alone the baffling interaction between batch normalization and shaking. In this work, we present our investigation on Shake-Shake regularization, drawing connections to the vicinal risk minimization principle and discriminative feature learning in face verification. Furthermore, we identify a strong resemblance between batch normalized residual blocks and batch normalized recurrent neural networks, where both of them share a similar convergence behavior, which could be mitigated by a proper initialization of batch normalization. Based on the findings, our experiments on speech emotion recognition demonstrate simultaneously an improvement on the classification accuracy and a reduction on the generalization gap both with statistical significance.

##### Abstract (translated by Google)
正规化对于许多实际深度学习模型的成功至关重要，特别是在通常情况下，只有少数到中等数量的可访问训练样本。除了重量衰减，数据增加和丢失之外，基于多分支架构的正则化，例如Shake-Shake正则化，已经在许多应用中被证明是成功的，并且吸引了越来越多的关注。然而，除了基于模型的表示增强之外，尚不清楚Shake-Shake正则化如何有助于进一步改进分类任务，更不用说批量归一化和抖动之间令人困惑的相互作用。在这项工作中，我们提出了关于Shake-Shake正则化的研究，绘制了与邻域风险最小化原则和面部验证中的判别性特征学习的联系。此外，我们发现批量标准化残差块和批量标准化递归神经网络之间存在强烈的相似性，其中两者共享相似的收敛行为，这可以通过批量标准化的适当初始化来减轻。基于这些发现，我们的语音情感识别实验同时证明了分类准确性的提高和泛化差距的缩小，具有统计学意义。

##### URL
[http://arxiv.org/abs/1808.00876](http://arxiv.org/abs/1808.00876)

##### PDF
[http://arxiv.org/pdf/1808.00876](http://arxiv.org/pdf/1808.00876)

