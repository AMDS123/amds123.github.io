---
layout: post
title: "Analysis and Improvement of Adversarial Training in DQN Agents With Adversarially-Guided Exploration"
date: 2019-06-03 23:31:25
categories: arXiv_AI
tags: arXiv_AI Adversarial
author: Vahid Behzadan, William Hsu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper investigates the effectiveness of adversarial training in enhancing the robustness of Deep Q-Network (DQN) policies to state-space perturbations. We first present a formal analysis of adversarial training in DQN agents and its performance with respect to the proportion of adversarial perturbations to nominal observations used for training. Next, we consider the sample-inefficiency of current adversarial training techniques, and propose a novel Adversarially-Guided Exploration (AGE) mechanism based on a modified hybrid of the $\epsilon$-greedy algorithm and Boltzmann exploration. We verify the feasibility of this exploration mechanism through experimental evaluation of its performance in comparison with the traditional decaying $\epsilon$-greedy and parameter-space noise exploration algorithms.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.01119](http://arxiv.org/abs/1906.01119)

##### PDF
[http://arxiv.org/pdf/1906.01119](http://arxiv.org/pdf/1906.01119)

