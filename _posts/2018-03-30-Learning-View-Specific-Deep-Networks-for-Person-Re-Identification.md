---
layout: post
title: "Learning View-Specific Deep Networks for Person Re-Identification"
date: 2018-03-30 04:10:06
categories: arXiv_CV
tags: arXiv_CV Re-identification Person_Re-identification
author: Zhanxiang Feng, Jianhuang Lai, Xiaohua Xie
mathjax: true
---

* content
{:toc}

##### Abstract
In recent years, a growing body of research has focused on the problem of person re-identification (re-id). The re-id techniques attempt to match the images of pedestrians from disjoint non-overlapping camera views. A major challenge of re-id is the serious intra-class variations caused by changing viewpoints. To overcome this challenge, we propose a deep neural network-based framework which utilizes the view information in the feature extraction stage. The proposed framework learns a view-specific network for each camera view with a cross-view Euclidean constraint (CV-EC) and a cross-view center loss (CV-CL). We utilize CV-EC to decrease the margin of the features between diverse views and extend the center loss metric to a view-specific version to better adapt the re-id problem. Moreover, we propose an iterative algorithm to optimize the parameters of the view-specific networks from coarse to fine. The experiments demonstrate that our approach significantly improves the performance of the existing deep networks and outperforms the state-of-the-art methods on the VIPeR, CUHK01, CUHK03, SYSU-mReId, and Market-1501 benchmarks.

##### Abstract (translated by Google)
近年来，越来越多的研究集中在人员重新识别（re-id）的问题上。重新识别技术试图匹配来自不相交的非重叠摄像机视图的行人图像。 re-id的一个主要挑战是由不断变化的观点引起的严重的班内变化。为了克服这个挑战，我们提出了一个基于深度神经网络的框架，它在特征提取阶段利用视图信息。所提出的框架通过交叉视图欧几里得约束（CV-EC）和交叉视图中心丢失（CV-CL）来学习针对每个摄像机视图的视图特定网络。我们利用CV-EC降低不同视图之间的特征边缘，并将中心损失度量扩展到特定视图版本，以更好地适应重新识别问题。此外，我们提出了一种迭代算法来优化视图特定网络的参数从粗到细。实验证明，我们的方法显着提高了现有深度网络的性能，并且在VIPeR，CUHK01，CUHK03，SYSU-mReId和Market-1501基准测试中的性能优于最新的方法。

##### URL
[https://arxiv.org/abs/1803.11333](https://arxiv.org/abs/1803.11333)

##### PDF
[https://arxiv.org/pdf/1803.11333](https://arxiv.org/pdf/1803.11333)

