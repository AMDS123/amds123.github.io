---
layout: post
title: "Recovering the Missing Link: Predicting Class-Attribute Associations for Unsupervised Zero-Shot Learning"
date: 2016-10-15 21:02:39
categories: arXiv_CV
tags: arXiv_CV Knowledge Embedding Classification Relation
author: Ziad Al-Halah, Makarand Tapaswi, Rainer Stiefelhagen
mathjax: true
---

* content
{:toc}

##### Abstract
Collecting training images for all visual categories is not only expensive but also impractical. Zero-shot learning (ZSL), especially using attributes, offers a pragmatic solution to this problem. However, at test time most attribute-based methods require a full description of attribute associations for each unseen class. Providing these associations is time consuming and often requires domain specific knowledge. In this work, we aim to carry out attribute-based zero-shot classification in an unsupervised manner. We propose an approach to learn relations that couples class embeddings with their corresponding attributes. Given only the name of an unseen class, the learned relationship model is used to automatically predict the class-attribute associations. Furthermore, our model facilitates transferring attributes across data sets without additional effort. Integrating knowledge from multiple sources results in a significant additional improvement in performance. We evaluate on two public data sets: Animals with Attributes and aPascal/aYahoo. Our approach outperforms state-of-the-art methods in both predicting class-attribute associations and unsupervised ZSL by a large margin.

##### Abstract (translated by Google)
收集所有视觉类别的训练图像不仅昂贵而且不切实际。零点学习（ZSL），特别是使用属性，为这个问题提供了一个实用的解决方案。然而，在测试时间，大多数基于属性的方法需要每个看不见的类的属性关联的完整描述。提供这些关联是非常耗时的，并且往往需要特定领域的知识在这项工作中，我们的目标是以无监督的方式进行基于属性的零点分类。我们提出了一种学习关系的方法，将类嵌入和相应的属性结合起来。只给出一个看不见的类的名称，学习的关系模型用于自动预测类属性关联。此外，我们的模型有助于跨数据集传输属性而无需额外的工作。集成来自多个来源的知识会使性能得到显着的进一步提高。我们评估两个公共数据集：具有属性的动物和aPascal / aYahoo。我们的方法在预测类属性关联和无监督的ZSL方面优于最先进的方法。

##### URL
[https://arxiv.org/abs/1610.04787](https://arxiv.org/abs/1610.04787)

##### PDF
[https://arxiv.org/pdf/1610.04787](https://arxiv.org/pdf/1610.04787)

