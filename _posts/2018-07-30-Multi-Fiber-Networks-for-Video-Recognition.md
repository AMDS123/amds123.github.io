---
layout: post
title: "Multi-Fiber Networks for Video Recognition"
date: 2018-07-30 07:08:29
categories: arXiv_CV
tags: arXiv_CV Recognition
author: Yunpeng Chen, Yannis Kalantidis, Jianshu Li, Shuicheng Yan, Jiashi Feng
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we aim to reduce the computational cost of spatio-temporal deep neural networks, making them run as fast as their 2D counterparts while preserving state-of-the-art accuracy on video recognition benchmarks. To this end, we present the novel Multi-Fiber architecture that slices a complex neural network into an ensemble of lightweight networks or fibers that run through the network. To facilitate information flow between fibers we further incorporate multiplexer modules and end up with an architecture that reduces the computational cost of 3D networks by an order of magnitude, while increasing recognition performance at the same time. Extensive experimental results show that our multi-fiber architecture significantly boosts the efficiency of existing convolution networks for both image and video recognition tasks, achieving state-of-the-art performance on UCF-101, HMDB-51 and Kinetics datasets. Our proposed model requires over 9x and 13x less computations than the I3D and R(2+1)D models, respectively, yet providing higher accuracy.

##### Abstract (translated by Google)
在本文中，我们的目标是降低时空深度神经网络的计算成本，使其运行速度与2D对应物一样快，同时在视频识别基准测试中保持最先进的精度。为此，我们提出了新颖的多光纤架构，将复杂的神经网络切割成一系列轻量级网络或光纤，贯穿整个网络。为了促进光纤之间的信息流，我们进一步整合了多路复用器模块，最终建立了一个架构，可以将3D网络的计算成本降低一个数量级，同时提高识别性能。大量实验结果表明，我们的多光纤架构显着提高了现有卷积网络在图像和视频识别任务方面的效率，在UCF-101，HMDB-51和Kinetics数据集上实现了最先进的性能。我们提出的模型分别比I3D和R（2 + 1）D模型的计算量少9倍和13倍，但提供更高的精度。

##### URL
[http://arxiv.org/abs/1807.11195](http://arxiv.org/abs/1807.11195)

##### PDF
[http://arxiv.org/pdf/1807.11195](http://arxiv.org/pdf/1807.11195)

