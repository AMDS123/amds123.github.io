---
layout: post
title: "Inverse Classification for Comparison-based Interpretability in Machine Learning"
date: 2017-12-22 13:51:21
categories: arXiv_AI
tags: arXiv_AI Knowledge Classification Prediction
author: Thibault Laugel, Marie-Jeanne Lesot, Christophe Marsala, Xavier Renard, Marcin Detyniecki
mathjax: true
---

* content
{:toc}

##### Abstract
In the context of post-hoc interpretability, this paper addresses the task of explaining the prediction of a classifier, considering the case where no information is available, neither on the classifier itself, nor on the processed data (neither the training nor the test data). It proposes an instance-based approach whose principle consists in determining the minimal changes needed to alter a prediction: given a data point whose classification must be explained, the proposed method consists in identifying a close neighbour classified differently, where the closeness definition integrates a sparsity constraint. This principle is implemented using observation generation in the Growing Spheres algorithm. Experimental results on two datasets illustrate the relevance of the proposed approach that can be used to gain knowledge about the classifier.

##### Abstract (translated by Google)
在事后解释的背景下，本文提出了解释分类器预测的任务，考虑到没有信息的情况，既不是在分类器本身，也不是在处理的数据（既不是训练也不是测试数据）。它提出了一种基于实例的方法，其原理在于确定改变预测所需的最小改变：给定一个数据点，其分类必须被解释，所提出的方法在于识别不同分类的近邻，其中近亲定义整合了稀疏性约束。这个原理是通过Growing Spheres算法中的观察生成实现的。两个数据集上的实验结果说明了所提出的方法的相关性，可用于获取关于分类器的知识。

##### URL
[https://arxiv.org/abs/1712.08443](https://arxiv.org/abs/1712.08443)

##### PDF
[https://arxiv.org/pdf/1712.08443](https://arxiv.org/pdf/1712.08443)

