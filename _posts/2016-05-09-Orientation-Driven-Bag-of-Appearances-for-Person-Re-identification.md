---
layout: post
title: "Orientation Driven Bag of Appearances for Person Re-identification"
date: 2016-05-09 08:25:33
categories: arXiv_CV
tags: arXiv_CV Re-identification Attention Face Person_Re-identification
author: Liqian Ma, Hong Liu, Liang Hu, Can Wang, Qianru Sun
mathjax: true
---

* content
{:toc}

##### Abstract
Person re-identification (re-id) consists of associating individual across camera network, which is valuable for intelligent video surveillance and has drawn wide attention. Although person re-identification research is making progress, it still faces some challenges such as varying poses, illumination and viewpoints. For feature representation in re-identification, existing works usually use low-level descriptors which do not take full advantage of body structure information, resulting in low representation ability. %discrimination. To solve this problem, this paper proposes the mid-level body-structure based feature representation (BSFR) which introduces body structure pyramid for codebook learning and feature pooling in the vertical direction of human body. Besides, varying viewpoints in the horizontal direction of human body usually causes the data missing problem, $i.e.$, the appearances obtained in different orientations of the identical person could vary significantly. To address this problem, the orientation driven bag of appearances (ODBoA) is proposed to utilize person orientation information extracted by orientation estimation technic. To properly evaluate the proposed approach, we introduce a new re-identification dataset (Market-1203) based on the Market-1501 dataset and propose a new re-identification dataset (PKU-Reid). Both datasets contain multiple images captured in different body orientations for each person. Experimental results on three public datasets and two proposed datasets demonstrate the superiority of the proposed approach, indicating the effectiveness of body structure and orientation information for improving re-identification performance.

##### Abstract (translated by Google)
个人重新识别（Re-id）包括跨摄像机网络关联个人，这对于智能视频监控非常有价值，引起了人们的广泛关注。虽然人的再认识研究正在取得进展，但仍面临着姿态，照度，观点等不同的挑战。对于重新识别中的特征表示，现有的作品通常使用低层次的描述符，这些描述符没有充分利用身体结构信息，导致表示能力低下。 ％的歧视。为解决这个问题，本文提出了基于身体结构的特征表示方法（BSFR），该方法在人体垂直方向上引入身体结构金字塔进行码书学习和特征融合。此外，在人体水平方向上的不同观点通常会导致数据丢失问题，即同一人在不同方向上获得的外观可能会有很大差异。为了解决这个问题，提出了定向驱动包表示（ODBoA），以利用定位估计技术提取的人员定位信息。为了正确评估所提出的方法，我们引入了基于Market-1501数据集的新的重新识别数据集（Market-1203），并提出了一个新的重新识别数据集（PKU-Reid）。两个数据集都包含以不同的身体姿势为每个人拍摄的多个图像。在三个公开数据集和两个提出的数据集上的实验结果证明了所提出的方法的优越性，表明了身体结构和方向信息的有效性，以提高重新识别性能。

##### URL
[https://arxiv.org/abs/1605.02464](https://arxiv.org/abs/1605.02464)

##### PDF
[https://arxiv.org/pdf/1605.02464](https://arxiv.org/pdf/1605.02464)

