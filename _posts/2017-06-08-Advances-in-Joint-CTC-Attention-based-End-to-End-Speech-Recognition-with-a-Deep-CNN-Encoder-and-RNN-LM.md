---
layout: post
title: "Advances in Joint CTC-Attention based End-to-End Speech Recognition with a Deep CNN Encoder and RNN-LM"
date: 2017-06-08 19:30:02
categories: arXiv_CL
tags: arXiv_CL Attention Speech_Recognition CNN RNN Classification Language_Model Prediction Recognition
author: Takaaki Hori, Shinji Watanabe, Yu Zhang, William Chan
mathjax: true
---

* content
{:toc}

##### Abstract
We present a state-of-the-art end-to-end Automatic Speech Recognition (ASR) model. We learn to listen and write characters with a joint Connectionist Temporal Classification (CTC) and attention-based encoder-decoder network. The encoder is a deep Convolutional Neural Network (CNN) based on the VGG network. The CTC network sits on top of the encoder and is jointly trained with the attention-based decoder. During the beam search process, we combine the CTC predictions, the attention-based decoder predictions and a separately trained LSTM language model. We achieve a 5-10\% error reduction compared to prior systems on spontaneous Japanese and Chinese speech, and our end-to-end model beats out traditional hybrid ASR systems.

##### Abstract (translated by Google)
我们提出了一个最先进的端到端自动语音识别（ASR）模型。我们学习用联合时间分类（CTC）和基于注意力的编码器 - 解码器网络来聆听和写字。编码器是基于VGG网络的深度卷积神经网络（CNN）。 CTC网络位于编码器的顶部，并与基于注意力的解码器一起训练。在波束搜索过程中，我们将CTC预测，基于注意力的解码器预测和单独训练的LSTM语言模型相结合。与以前的自发日语和中文语音系统相比，我们实现了5-10％的误差减少，而我们的端到端模式击败了传统的混合ASR系统。

##### URL
[https://arxiv.org/abs/1706.02737](https://arxiv.org/abs/1706.02737)

##### PDF
[https://arxiv.org/pdf/1706.02737](https://arxiv.org/pdf/1706.02737)

