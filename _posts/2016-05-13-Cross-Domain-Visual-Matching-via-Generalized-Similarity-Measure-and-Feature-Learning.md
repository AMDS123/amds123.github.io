---
layout: post
title: "Cross-Domain Visual Matching via Generalized Similarity Measure and Feature Learning"
date: 2016-05-13 03:35:14
categories: arXiv_CV
tags: arXiv_CV Re-identification Face Person_Re-identification CNN Represenation_Learning Optimization
author: Liang Lin, Guangrun Wang, Wangmeng Zuo, Xiangchu Feng, Lei Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Cross-domain visual data matching is one of the fundamental problems in many real-world vision tasks, e.g., matching persons across ID photos and surveillance videos. Conventional approaches to this problem usually involves two steps: i) projecting samples from different domains into a common space, and ii) computing (dis-)similarity in this space based on a certain distance. In this paper, we present a novel pairwise similarity measure that advances existing models by i) expanding traditional linear projections into affine transformations and ii) fusing affine Mahalanobis distance and Cosine similarity by a data-driven combination. Moreover, we unify our similarity measure with feature representation learning via deep convolutional neural networks. Specifically, we incorporate the similarity measure matrix into the deep architecture, enabling an end-to-end way of model optimization. We extensively evaluate our generalized similarity model in several challenging cross-domain matching tasks: person re-identification under different views and face verification over different modalities (i.e., faces from still images and videos, older and younger faces, and sketch and photo portraits). The experimental results demonstrate superior performance of our model over other state-of-the-art methods.

##### Abstract (translated by Google)
跨域视觉数据匹配是许多真实世界视觉任务中的基本问题之一，例如，在ID照片和监视视频之间匹配人员。这个问题的传统方法通常包括两个步骤：1）从不同领域的样本投射到一个共同的空间，2）在这个空间基于一定的距离计算（dis）相似性。在本文中，我们提出了一种新的配对相似性度量，通过i）将传统的线性投影扩展为仿射变换，以及ii）通过数据驱动组合融合仿射马氏距离和余弦相似度，从而推进现有模型。此外，我们通过深度卷积神经网络将我们的相似性度量与特征表示学习相结合。具体而言，我们将相似性度量矩阵纳入深层架构，实现模型优化的端到端方式。我们在几个具有挑战性的跨域匹配任务中广泛地评估了我们的广义相似度模型：在不同视图下的人重新识别和在不同的模态下面对验证（即，来自静止图像和视频，年长面孔和年轻面孔以及素描和照片肖像的面孔） 。实验结果表明，我们的模型优于其他最先进的方法的性能。

##### URL
[https://arxiv.org/abs/1605.04039](https://arxiv.org/abs/1605.04039)

##### PDF
[https://arxiv.org/pdf/1605.04039](https://arxiv.org/pdf/1605.04039)

