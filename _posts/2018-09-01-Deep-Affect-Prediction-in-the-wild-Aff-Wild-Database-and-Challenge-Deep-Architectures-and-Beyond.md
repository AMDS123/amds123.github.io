---
layout: post
title: "Deep Affect Prediction in-the-wild: Aff-Wild Database and Challenge, Deep Architectures, and Beyond"
date: 2018-09-01 13:26:39
categories: arXiv_AI
tags: arXiv_AI GAN CNN RNN Deep_Learning Prediction Recognition
author: Dimitrios Kollias, Panagiotis Tzirakis, Mihalis A. Nicolaou, Athanasios Papaioannou, Guoying Zhao, Bj&#xf6;rn Schuller, Irene Kotsia, Stefanos Zafeiriou
mathjax: true
---

* content
{:toc}

##### Abstract
Automatic understanding of human affect using visual signals is of great importance in everyday human-machine interactions. Appraising human emotional states, behaviors and reactions displayed in real-world settings, can be accomplished using latent continuous dimensions (e.g., the circumplex model of affect). Valence (i.e., how positive or negative is an emotion) and arousal (i.e., power of the activation of the emotion) constitute the most popular and effective affect representations. Nevertheless, the majority of collected datasets this far, although containing naturalistic emotional states, have been captured in highly controlled recording conditions. In this paper, we introduce the Aff-Wild benchmark for training and evaluating affect recognition algorithms. We also report on the results of the First Affect-in-the-wild Challenge (Aff-Wild Challenge) that was recently organized on the Aff-Wild database, and was the first ever challenge on the estimation of valence and arousal in-the-wild. Furthermore, we design and extensively train an end-to-end deep neural architecture which performs prediction of continuous emotion dimensions based on visual cues. The proposed deep learning architecture, AffWildNet, includes convolutional and recurrent neural network (CNN-RNN) layers, exploiting the invariant properties of convolutional features, while also modeling temporal dynamics that arise in human behavior via the recurrent layers. The AffWildNet produced state-of-the-art results on the Aff-Wild Challenge. We then exploit the AffWild database for learning features, which can be used as priors for achieving best performances both for dimensional, as well as categorical emotion recognition, using the RECOLA, AFEW-VA and EmotiW 2017 datasets, compared to all other methods designed for the same goal.

##### Abstract (translated by Google)
使用视觉信号自动理解人类情感在日常人机交互中非常重要。评估在现实世界环境中显示的人类情绪状态，行为和反应可以使用潜在的连续维度（例如，情绪的环形模型）来完成。效价（即情绪的正面或负面）和唤醒（即情绪激活的力量）构成最流行和有效的情感表征。然而，迄今为止，大多数收集的数据集虽然包含自然情绪状态，但已在高度受控的记录条件下捕获。在本文中，我们介绍了Aff-Wild基准，用于训练和评估情感识别算法。我们还报告了最近在Aff-Wild数据库上组织的第一次影响野外挑战（Aff-Wild Challenge）的结果，这是有史以来对价值和唤醒的首次估计的挑战。 -野生。此外，我们设计并广泛训练端到端深度神经结构，该结构基于视觉线索执行连续情绪维度的预测。所提出的深度学习架构AffWildNet包括卷积和递归神经网络（CNN-RNN）层，利用卷积特征的不变特性，同时还通过复发层对人类行为中出现的时间动态进行建模。 AffWildNet在Aff-Wild挑战赛上创造了最先进的成果。然后，我们利用AffWild数据库进行学习功能，使用RECOLA，AFEW-VA和EmotiW 2017数据集，与其他所有设计的方法相比，可以将其用作维度和分类情感识别的最佳性能。同样的目标。

##### URL
[http://arxiv.org/abs/1804.10938](http://arxiv.org/abs/1804.10938)

##### PDF
[http://arxiv.org/pdf/1804.10938](http://arxiv.org/pdf/1804.10938)

