---
layout: post
title: "Video2GIF: Automatic Generation of Animated GIFs from Video"
date: 2016-05-16 17:44:31
categories: arXiv_CV
tags: arXiv_CV Attention
author: Michael Gygli, Yale Song, Liangliang Cao
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce the novel problem of automatically generating animated GIFs from video. GIFs are short looping video with no sound, and a perfect combination between image and video that really capture our attention. GIFs tell a story, express emotion, turn events into humorous moments, and are the new wave of photojournalism. We pose the question: Can we automate the entirely manual and elaborate process of GIF creation by leveraging the plethora of user generated GIF content? We propose a Robust Deep RankNet that, given a video, generates a ranked list of its segments according to their suitability as GIF. We train our model to learn what visual content is often selected for GIFs by using over 100K user generated GIFs and their corresponding video sources. We effectively deal with the noisy web data by proposing a novel adaptive Huber loss in the ranking formulation. We show that our approach is robust to outliers and picks up several patterns that are frequently present in popular animated GIFs. On our new large-scale benchmark dataset, we show the advantage of our approach over several state-of-the-art methods.

##### Abstract (translated by Google)
我们介绍一下从视频自动生成动画GIF的新奇问题。 GIF是没有声音的短循环视频，是真正吸引我们注意的图像和视频之间的完美结合。 GIF讲述一个故事，表达情感，将事件变成幽默时刻，是新闻摄影的新浪潮。我们提出的问题是：我们是否可以通过利用大量用户生成的GIF内容来自动完成手动和精细的GIF创建过程？我们提出了一个强大的Deep RankNet，根据视频，根据其作为GIF的适用性生成其分段的排名列表。我们训练我们的模型，通过使用超过10万个用户生成的GIF及其相应的视频源，了解经常为GIF选择哪些可视内容。我们通过在排序公式中提出一种新的自适应Huber损失来有效地处理噪声网络数据。我们表明，我们的方法是强大的异常值，并拿起了几个模式，经常出现在流行的动画GIFs。在我们新的大型基准数据集上，我们展示了我们在几种最先进的方法上的优势。

##### URL
[https://arxiv.org/abs/1605.04850](https://arxiv.org/abs/1605.04850)

##### PDF
[https://arxiv.org/pdf/1605.04850](https://arxiv.org/pdf/1605.04850)

