---
layout: post
title: "Learning to discover and localize visual objects with open vocabulary"
date: 2018-11-25 19:55:33
categories: arXiv_CV
tags: arXiv_CV Object_Detection Weakly_Supervised Caption Detection Relation
author: Keren Ye, Mingda Zhang, Wei Li, Danfeng Qin, Adriana Kovashka, Jesse Berent
mathjax: true
---

* content
{:toc}

##### Abstract
To alleviate the cost of obtaining accurate bounding boxes for training today's state-of-the-art object detection models, recent weakly supervised detection work has proposed techniques to learn from image-level labels. However, requiring discrete image-level labels is both restrictive and suboptimal. Real-world "supervision" usually consists of more unstructured text, such as captions. In this work we learn association maps between images and captions. We then use a novel objectness criterion to rank the resulting candidate boxes, such that high-ranking boxes have strong gradients along all edges. Thus, we can detect objects beyond a fixed object category vocabulary, if those objects are frequent and distinctive enough. We show that our objectness criterion improves the proposed bounding boxes in relation to prior weakly supervised detection methods. Further, we show encouraging results on object detection from image-level captions only.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1811.10080](https://arxiv.org/abs/1811.10080)

##### PDF
[https://arxiv.org/pdf/1811.10080](https://arxiv.org/pdf/1811.10080)

