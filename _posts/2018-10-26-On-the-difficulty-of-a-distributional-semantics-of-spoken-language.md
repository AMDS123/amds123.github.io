---
layout: post
title: "On the difficulty of a distributional semantics of spoken language"
date: 2018-10-26 13:52:41
categories: arXiv_CL
tags: arXiv_CL Face
author: Grzegorz Chrupa&#x142;a, Lieke Gelderloos, &#xc1;kos K&#xe1;d&#xe1;r, Afra Alishahi
mathjax: true
---

* content
{:toc}

##### Abstract
In the domain of unsupervised learning most work on speech has focused on discovering low-level constructs such as phoneme inventories or word-like units. In contrast, for written language, where there is a large body of work on unsupervised induction of semantic representations of words, whole sentences and longer texts. In this study we examine the challenges of adapting these approaches from written to spoken language. We conjecture that unsupervised learning of the semantics of spoken language becomes feasible if we abstract from the surface variability. We simulate this setting with a dataset of utterances spoken by a realistic but uniform synthetic voice. We evaluate two simple unsupervised models which, to varying degrees of success, learn semantic representations of speech fragments. Finally we present inconclusive results on human speech, and discuss the challenges inherent in learning distributional semantic representations on unrestricted natural spoken language.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1803.08869](http://arxiv.org/abs/1803.08869)

##### PDF
[http://arxiv.org/pdf/1803.08869](http://arxiv.org/pdf/1803.08869)

