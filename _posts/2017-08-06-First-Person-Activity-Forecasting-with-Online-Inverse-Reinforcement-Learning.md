---
layout: post
title: "First-Person Activity Forecasting with Online Inverse Reinforcement Learning"
date: 2017-08-06 22:06:18
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning
author: Nicholas Rhinehart, Kris M. Kitani
mathjax: true
---

* content
{:toc}

##### Abstract
We address the problem of incrementally modeling and forecasting long-term goals of a first-person camera wearer: what the user will do, where they will go, and what goal they seek. In contrast to prior work in trajectory forecasting, our algorithm, DARKO, goes further to reason about semantic states (will I pick up an object?), and future goal states that are far in terms of both space and time. DARKO learns and forecasts from first-person visual observations of the user's daily behaviors via an Online Inverse Reinforcement Learning (IRL) approach. Classical IRL discovers only the rewards in a batch setting, whereas DARKO discovers the states, transitions, rewards, and goals of a user from streaming data. Among other results, we show DARKO forecasts goals better than competing methods in both noisy and ideal settings, and our approach is theoretically and empirically no-regret.

##### Abstract (translated by Google)
我们解决增量建模和预测第一人称摄像机佩戴者的长期目标的问题：用户将做什么，他们将去哪里以及他们寻求什么目标。与之前的轨迹预测工作相比，我们的算法DARKO进一步推理语义状态（我会拾取一个对象吗？），以及未来的目标状态，在时间和空间方面都很远。 DARKO通过在线逆向强化学习（IRL）方法从第一人称视觉观察用户的日常行为中学习和预测。古典IRL仅在批次设置中发现奖励，而DARKO从流数据中发现用户的状态，转换，奖励和目标。除了其他的结果之外，我们还展示了DARKO在嘈杂和理想环境中都比竞争方法更好的预测目标，而我们的方法在理论和实证上都是不容后悔的。

##### URL
[https://arxiv.org/abs/1612.07796](https://arxiv.org/abs/1612.07796)

##### PDF
[https://arxiv.org/pdf/1612.07796](https://arxiv.org/pdf/1612.07796)

