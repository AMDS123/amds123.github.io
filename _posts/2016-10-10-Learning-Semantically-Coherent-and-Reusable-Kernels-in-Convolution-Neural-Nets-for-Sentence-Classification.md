---
layout: post
title: "Learning Semantically Coherent and Reusable Kernels in Convolution Neural Nets for Sentence Classification"
date: 2016-10-10 03:57:26
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention Classification Language_Model
author: Madhusudan Lakshmana, Sundararajan Sellamanickam, Shirish Shevade, Keerthi Selvaraj
mathjax: true
---

* content
{:toc}

##### Abstract
The state-of-the-art CNN models give good performance on sentence classification tasks. The purpose of this work is to empirically study desirable properties such as semantic coherence, attention mechanism and reusability of CNNs in these tasks. Semantically coherent kernels are preferable as they are a lot more interpretable for explaining the decision of the learned CNN model. We observe that the learned kernels do not have semantic coherence. Motivated by this observation, we propose to learn kernels with semantic coherence using clustering scheme combined with Word2Vec representation and domain knowledge such as SentiWordNet. We suggest a technique to visualize attention mechanism of CNNs for decision explanation purpose. Reusable property enables kernels learned on one problem to be used in another problem. This helps in efficient learning as only a few additional domain specific filters may have to be learned. We demonstrate the efficacy of our core ideas of learning semantically coherent kernels and leveraging reusable kernels for efficient learning on several benchmark datasets. Experimental results show the usefulness of our approach by achieving performance close to the state-of-the-art methods but with semantic and reusable properties.

##### Abstract (translated by Google)
最先进的CNN模型在句子分类任务上表现出色。这项工作的目的是实验性地研究理想的属性，如语义连贯性，注意机制和CNN在这些任务中的可重用性。语义上一致的内核是可取的，因为它们对解释学习CNN模型的决定有更多的解释。我们观察到学习的内核没有语义连贯性。受此观察的启发，我们提出使用结合Word2Vec表示和诸如SentiWordNet的领域知识的聚类方案来学习具有语义相干性的内核。我们提出一种技术来形象化CNNs的注意机制，供决策说明之用。可重用属性使得在一个问题上学习的内核可以用于另一个问题。这有助于高效学习，因为只需要学习一些额外的领域特定的过滤器。我们证明了我们核心思想的有效性，即学习语义连贯的内核，并利用可重用的内核在几个基准数据集上进行高效学习。实验结果显示我们的方法的有用性，通过实现性能接近最先进的方法，但具有语义和可重用的属性。

##### URL
[https://arxiv.org/abs/1608.00466](https://arxiv.org/abs/1608.00466)

##### PDF
[https://arxiv.org/pdf/1608.00466](https://arxiv.org/pdf/1608.00466)

