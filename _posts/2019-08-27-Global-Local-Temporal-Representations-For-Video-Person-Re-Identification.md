---
layout: post
title: "Global-Local Temporal Representations For Video Person Re-Identification"
date: 2019-08-27 06:57:03
categories: arXiv_CV
tags: arXiv_CV Re-identification Attention Person_Re-identification Relation
author: Jianing Li, Jingdong Wang, Qi Tian, Wen Gao, Shiliang Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes the Global-Local Temporal Representation (GLTR) to exploit the multi-scale temporal cues in video sequences for video person Re-Identification (ReID). GLTR is constructed by first modeling the short-term temporal cues among adjacent frames, then capturing the long-term relations among inconsecutive frames. Specifically, the short-term temporal cues are modeled by parallel dilated convolutions with different temporal dilation rates to represent the motion and appearance of pedestrian. The long-term relations are captured by a temporal self-attention model to alleviate the occlusions and noises in video sequences. The short and long-term temporal cues are aggregated as the final GLTR by a simple single-stream CNN. GLTR shows substantial superiority to existing features learned with body part cues or metric learning on four widely-used video ReID datasets. For instance, it achieves Rank-1 Accuracy of 87.02% on MARS dataset without re-ranking, better than current state-of-the art.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.10049](http://arxiv.org/abs/1908.10049)

##### PDF
[http://arxiv.org/pdf/1908.10049](http://arxiv.org/pdf/1908.10049)

