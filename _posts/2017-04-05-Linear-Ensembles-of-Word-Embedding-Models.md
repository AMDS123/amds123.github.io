---
layout: post
title: "Linear Ensembles of Word Embedding Models"
date: 2017-04-05 13:38:01
categories: arXiv_CL
tags: arXiv_CL OCR Embedding
author: Avo Muromägi, Kairit Sirts, Sven Laur
mathjax: true
---

* content
{:toc}

##### Abstract
This paper explores linear methods for combining several word embedding models into an ensemble. We construct the combined models using an iterative method based on either ordinary least squares regression or the solution to the orthogonal Procrustes problem. We evaluate the proposed approaches on Estonian---a morphologically complex language, for which the available corpora for training word embeddings are relatively small. We compare both combined models with each other and with the input word embedding models using synonym and analogy tests. The results show that while using the ordinary least squares regression performs poorly in our experiments, using orthogonal Procrustes to combine several word embedding models into an ensemble model leads to 7-10% relative improvements over the mean result of the initial models in synonym tests and 19-47% in analogy tests.

##### Abstract (translated by Google)
本文探讨了将几个词嵌入模型组合成一个集合的线性方法。我们使用基于普通最小二乘回归或正交Procrustes问题的解的迭代方法构造组合模型。我们评估爱沙尼亚语提出的方法 - 一种形态复杂的语言，对于这种语言，用于训练词嵌入的可用语料库相对较小。我们使用同义词和类比测试来比较两个组合模型和输入词嵌入模型。结果表明，尽管在我们的实验中使用普通最小二乘回归方法表现不佳，但使用正交Procrustes将几个词嵌入模型组合到一个集合模型中导致相对于同义词测试中的初始模型的平均结果的7-10％在类比测试中为19-47％。

##### URL
[https://arxiv.org/abs/1704.01419](https://arxiv.org/abs/1704.01419)

##### PDF
[https://arxiv.org/pdf/1704.01419](https://arxiv.org/pdf/1704.01419)

