---
layout: post
title: "Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders"
date: 2017-10-21 04:58:20
categories: arXiv_SD
tags: arXiv_SD Knowledge
author: Tiancheng Zhao, Ran Zhao, Maxine Eskenazi
mathjax: true
---

* content
{:toc}

##### Abstract
While recent neural encoder-decoder models have shown great promise in modeling open-domain conversations, they often generate dull and generic responses. Unlike past work that has focused on diversifying the output of the decoder at word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that captures the discourse-level diversity in the encoder. Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy decoders. We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance. Finally, the training procedure is improved by introducing a bag-of-word loss. Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence in discourse-level decision-making.

##### Abstract (translated by Google)
尽管最近的神经编码器 - 解码器模型已经在建模开放域对话中显示出很大的希望，但是它们通常会产生沉闷和普遍的反应。与以往的着重于在字级别解码器的输出以减轻这个问题的工作不同，我们提出了一种基于条件变分自动编码器的新颖框架，该框架捕捉编码器中的话语级多样性。我们的模型使用潜在变量来学习潜在会话意图的分布，并且仅使用贪婪解码器产生多种响应。我们进一步开发了一个新的变体，与语言学的先验知识相结合，以获得更好的表现。最后，通过引入一个词袋损失来改进训练过程。我们提出的模型已经被验证，可以产生比基线方法更为多样化的反应，并在话语层面的决策过程中展现出能力。

##### URL
[https://arxiv.org/abs/1703.10960](https://arxiv.org/abs/1703.10960)

##### PDF
[https://arxiv.org/pdf/1703.10960](https://arxiv.org/pdf/1703.10960)

