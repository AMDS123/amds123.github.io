---
layout: post
title: "Suppressing the Unusual: towards Robust CNNs using Symmetric Activation Functions"
date: 2016-03-16 15:35:07
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN Classification Prediction
author: Qiyang Zhao, Lewis D Griffin
mathjax: true
---

* content
{:toc}

##### Abstract
Many deep Convolutional Neural Networks (CNN) make incorrect predictions on adversarial samples obtained by imperceptible perturbations of clean samples. We hypothesize that this is caused by a failure to suppress unusual signals within network layers. As remedy we propose the use of Symmetric Activation Functions (SAF) in non-linear signal transducer units. These units suppress signals of exceptional magnitude. We prove that SAF networks can perform classification tasks to arbitrary precision in a simplified situation. In practice, rather than use SAFs alone, we add them into CNNs to improve their robustness. The modified CNNs can be easily trained using popular strategies with the moderate training load. Our experiments on MNIST and CIFAR-10 show that the modified CNNs perform similarly to plain ones on clean samples, and are remarkably more robust against adversarial and nonsense samples.

##### Abstract (translated by Google)
许多深度卷积神经网络（CNN）对干扰样本的不可察觉干扰所获得的对抗样本做出了不正确的预测。我们推测这是由于在网络层内抑制异常信号失败造成的。作为补救措施，我们建议在非线性信号传感器单元中使用对称激活功能（SAF）。这些单位压制超常规的信号。我们证明SAF网络可以在简化的情况下执行任意精度的分类任务。实际上，我们不是单独使用SAF，而是将它们添加到CNN中以提高它们的稳健性。修改后的CNN可以很容易地用中等训练负荷的流行策略训练。我们在MNIST和CIFAR-10上进行的实验表明，改性的CNN在干净的样品上的表现类似于普通的CNN，并且对抗对抗和无意义的样品显着更强健。

##### URL
[https://arxiv.org/abs/1603.05145](https://arxiv.org/abs/1603.05145)

##### PDF
[https://arxiv.org/pdf/1603.05145](https://arxiv.org/pdf/1603.05145)

