---
layout: post
title: "Modeling and Predicting Citation Count via Recurrent Neural Network with Long Short-Term Memory"
date: 2018-11-06 02:19:39
categories: arXiv_CV
tags: arXiv_CV Review Prediction
author: Sha Yuan, Jie Tang, Yu Zhang, Yifan Wang, Tong Xiao
mathjax: true
---

* content
{:toc}

##### Abstract
The rapid evolution of scientific research has been creating a huge volume of publications every year. Among the many quantification measures of scientific impact, citation count stands out for its frequent use in the research community. Although peer review process is the mainly reliable way of predicting a paper's future impact, the ability to foresee lasting impact on the basis of citation records is increasingly important in the scientific impact analysis in the era of big data. This paper focuses on the long-term citation count prediction for individual publications, which has become an emerging and challenging applied research topic. Based on the four key phenomena confirmed independently in previous studies of long-term scientific impact quantification, including the intrinsic quality of publications, the aging effect and the Matthew effect and the recency effect, we unify the formulations of all these observations in this paper. Building on a foundation of the above formulations, we propose a long-term citation count prediction model for individual papers via recurrent neural network with long short-term memory units. Extensive experiments on a real-large citation data set demonstrate that the proposed model consistently outperforms existing methods, and achieves a significant performance improvement.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1811.02129](https://arxiv.org/abs/1811.02129)

##### PDF
[https://arxiv.org/pdf/1811.02129](https://arxiv.org/pdf/1811.02129)

