---
layout: post
title: "Deep Generative Modeling for Scene Synthesis via Hybrid Representations"
date: 2018-08-06 19:42:24
categories: arXiv_CV
tags: arXiv_CV Deep_Learning
author: Zaiwei Zhang, Zhenpei Yang, Chongyang Ma, Linjie Luo, Alexander Huth, Etienne Vouga, Qixing Huang
mathjax: true
---

* content
{:toc}

##### Abstract
We present a deep generative scene modeling technique for indoor environments. Our goal is to train a generative model using a feed-forward neural network that maps a prior distribution (e.g., a normal distribution) to the distribution of primary objects in indoor scenes. We introduce a 3D object arrangement representation that models the locations and orientations of objects, based on their size and shape attributes. Moreover, our scene representation is applicable for 3D objects with different multiplicities (repetition counts), selected from a database. We show a principled way to train this model by combining discriminator losses for both a 3D object arrangement representation and a 2D image-based representation. We demonstrate the effectiveness of our scene representation and the deep learning method on benchmark datasets. We also show the applications of this generative model in scene interpolation and scene completion.

##### Abstract (translated by Google)
我们提出了一种用于室内环境的深度生成场景建模技术。我们的目标是使用前馈神经网络训练生成模型，该前馈神经网络将先前分布（例如，正态分布）映射到室内场景中的主要对象的分布。我们引入了一个3D对象排列表示，它根据对象的大小和形状属性对对象的位置和方向进行建模。此外，我们的场景表示适用于从数据库中选择的具有不同多重性（重复计数）的3D对象。我们通过组合3D对象布置表示和基于2D图像的表示的鉴别器损失来展示训练该模型的原理方式。我们在基准数据集上展示了场景表示和深度学习方法的有效性。我们还展示了这种生成模型在场景插值和场景完成中的应用。

##### URL
[http://arxiv.org/abs/1808.02084](http://arxiv.org/abs/1808.02084)

##### PDF
[http://arxiv.org/pdf/1808.02084](http://arxiv.org/pdf/1808.02084)

