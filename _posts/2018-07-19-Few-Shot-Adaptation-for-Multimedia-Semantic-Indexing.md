---
layout: post
title: "Few-Shot Adaptation for Multimedia Semantic Indexing"
date: 2018-07-19 00:58:33
categories: arXiv_CV
tags: arXiv_CV Object_Detection Knowledge Detection
author: Nakamasa Inoue, Koichi Shinoda
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a few-shot adaptation framework, which bridges zero-shot learning and supervised many-shot learning, for semantic indexing of image and video data. Few-shot adaptation provides robust parameter estimation with few training examples, by optimizing the parameters of zero-shot learning and supervised many-shot learning simultaneously. In this method, first we build a zero-shot detector, and then update it by using the few examples. Our experiments show the effectiveness of the proposed framework on three datasets: TRECVID Semantic Indexing 2010, 2014, and ImageNET. On the ImageNET dataset, we show that our method outperforms recent few-shot learning methods. On the TRECVID 2014 dataset, we achieve 15.19% and 35.98% in Mean Average Precision under the zero-shot condition and the supervised condition, respectively. To the best of our knowledge, these are the best results on this dataset.

##### Abstract (translated by Google)
我们提出了一种适用于图像和视频数据的语义索引的几次调整适应框架，该框架可以连接零射击学习和监督多次射击学习。通过优化零射击学习的参数和同时监督多次射击学习，少量射击自适应提供了强有力的参数估计，几乎没有训练样例。在这种方法中，首先我们构建一个零射击探测器，然后使用几个例子进行更新。我们的实验显示了所提出的框架在三个数据集上的有效性：TRECVID语义索引2010,2014和ImageNET。在ImageNET数据集上，我们表明我们的方法优于最近的几个镜头学习方法。在TRECVID 2014数据集上，我们分别在零射击条件和监督条件下实现平均精度的15.19％和35.98％。据我们所知，这些是该数据集的最佳结果。

##### URL
[https://arxiv.org/abs/1807.07203](https://arxiv.org/abs/1807.07203)

##### PDF
[https://arxiv.org/pdf/1807.07203](https://arxiv.org/pdf/1807.07203)

