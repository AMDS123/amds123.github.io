---
layout: post
title: "Neural Headline Generation with Sentence-wise Optimization"
date: 2016-10-09 07:16:24
categories: arXiv_SD
tags: arXiv_SD Optimization RNN Prediction
author: Ayana, Shiqi Shen, Yu Zhao, Zhiyuan Liu, Maosong Sun
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, neural models have been proposed for headline generation by learning to map documents to headlines with recurrent neural networks. Nevertheless, as traditional neural network utilizes maximum likelihood estimation for parameter optimization, it essentially constrains the expected training objective within word level rather than sentence level. Moreover, the performance of model prediction significantly relies on training data distribution. To overcome these drawbacks, we employ minimum risk training strategy in this paper, which directly optimizes model parameters in sentence level with respect to evaluation metrics and leads to significant improvements for headline generation. Experiment results show that our models outperforms state-of-the-art systems on both English and Chinese headline generation tasks.

##### Abstract (translated by Google)
最近，神经模型已经被提出用于标题生成，通过学习使用递归神经网络将文档映射到标题。然而，由于传统的神经网络采用最大似然估计来进行参数优化，因此它实质上限制了预期的训练目标在单词级别而不是句子级别。而且，模型预测的性能主要依赖于训练数据的分布。为克服这些弊端，本文采用最小风险培训策略，针对评估指标直接优化句子层次的模型参数，使标题生成得到显着改善。实验结果表明，我们的模型在中英文标题生成任务上都优于最新的系统。

##### URL
[https://arxiv.org/abs/1604.01904](https://arxiv.org/abs/1604.01904)

##### PDF
[https://arxiv.org/pdf/1604.01904](https://arxiv.org/pdf/1604.01904)

