---
layout: post
title: "A Read-Write Memory Network for Movie Story Understanding"
date: 2017-11-03 08:40:50
categories: arXiv_CV
tags: arXiv_CV QA CNN Relation
author: Seil Na, Sangho Lee, Jisung Kim, Gunhee Kim
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel memory network model named Read-Write Memory Network (RWMN) to perform question and answering tasks for large-scale, multimodal movie story understanding. The key focus of our RWMN model is to design the read network and the write network that consist of multiple convolutional layers, which enable memory read and write operations to have high capacity and flexibility. While existing memory-augmented network models treat each memory slot as an independent block, our use of multi-layered CNNs allows the model to read and write sequential memory cells as chunks, which is more reasonable to represent a sequential story because adjacent memory blocks often have strong correlations. For evaluation, we apply our model to all the six tasks of the MovieQA benchmark, and achieve the best accuracies on several tasks, especially on the visual QA task. Our model shows a potential to better understand not only the content in the story, but also more abstract information, such as relationships between characters and the reasons for their actions.

##### Abstract (translated by Google)
我们提出了一个名为Read-Write Memory Network（RWMN）的新型存储网络模型来执行大规模，多模式电影故事理解的问题和回答任务。 RWMN模型的关键在于设计由多个卷积层组成的读取网络和写入网络，使得存储器的读写操作具有较高的容量和灵活性。尽管现有的内存扩展网络模型将每个内存插槽当作独立块处理，但是我们使用多层CNN允许模型将连续内存单元作为块读取和写入，这更合理地表示顺序故事，因为相邻内存块经常有很强的相关性。为了评估，我们将模型应用到MovieQA基准测试的所有六个任务中，并且在几个任务中取得了最好的精度，尤其是在视觉QA任务上。我们的模型不仅能够更好地理解故事中的内容，而且还能够更加深入地理解角色之间的关系和行为原因等抽象信息。

##### URL
[https://arxiv.org/abs/1709.09345](https://arxiv.org/abs/1709.09345)

##### PDF
[https://arxiv.org/pdf/1709.09345](https://arxiv.org/pdf/1709.09345)

