---
layout: post
title: "$rho$-hot Lexicon Embedding-based Two-level LSTM for Sentiment Analysis"
date: 2018-03-21 07:13:16
categories: arXiv_CL
tags: arXiv_CL Sentiment Sentiment_Classification Embedding RNN Classification Deep_Learning
author: Ou Wu, Tao Yang, Mengyang Li, Ming Li
mathjax: true
---

* content
{:toc}

##### Abstract
Sentiment analysis is a key component in various text mining applications. Numerous sentiment classification techniques, including conventional and deep learning-based methods, have been proposed in the literature. In most existing methods, a high-quality training set is assumed to be given. Nevertheless, constructing a high-quality training set that consists of highly accurate labels is challenging in real applications. This difficulty stems from the fact that text samples usually contain complex sentiment representations, and their annotation is subjective. We address this challenge in this study by leveraging a new labeling strategy and utilizing a two-level long short-term memory network to construct a sentiment classifier. Lexical cues are useful for sentiment analysis, and they have been utilized in conventional studies. For example, polar and privative words play important roles in sentiment analysis. A new encoding strategy, that is, $\rho$-hot encoding, is proposed to alleviate the drawbacks of one-hot encoding and thus effectively incorporate useful lexical cues. We compile three Chinese data sets on the basis of our label strategy and proposed methodology. Experiments on the three data sets demonstrate that the proposed method outperforms state-of-the-art algorithms.

##### Abstract (translated by Google)
情感分析是各种文本挖掘应用程序中的关键组件。在文献中已经提出了许多情感分类技术，包括常规和基于深度学习的方法。在大多数现有的方法中，假定给出高质量的训练集。尽管如此，构建由高度精确的标签组成的高质量培训集在实际应用中具有挑战性。这种困难源于文本样本通常包含复杂的情感表征，并且其注释是主观的。我们通过利用新的标签策略和利用两层长的短期记忆网络构建情感分类器来解决这一挑战。词汇线索对情绪分析很有用，并且它们已被用于传统研究。例如，极性和隐性词语在情感分析中发挥重要作用。提出了一种新的编码策略，即$ \ rho $ -hot编码，以缓解单热编码的缺点，从而有效地结合有用的词汇线索。我们根据我们的标签策略和提议的方法编制三个中文数据集。三个数据集上的实验表明，所提出的方法优于最先进的算法。

##### URL
[http://arxiv.org/abs/1803.07771](http://arxiv.org/abs/1803.07771)

##### PDF
[http://arxiv.org/pdf/1803.07771](http://arxiv.org/pdf/1803.07771)

