---
layout: post
title: "A Large-Scale Study on Regularization and Normalization in GANs"
date: 2019-05-14 13:41:42
categories: arXiv_CV
tags: arXiv_CV Regularization Adversarial GAN
author: Karol Kurach, Mario Lucic, Xiaohua Zhai, Marcin Michalski, Sylvain Gelly
mathjax: true
---

* content
{:toc}

##### Abstract
Generative adversarial networks (GANs) are a class of deep generative models which aim to learn a target distribution in an unsupervised fashion. While they were successfully applied to many problems, training a GAN is a notoriously challenging task and requires a significant number of hyperparameter tuning, neural architecture engineering, and a non-trivial amount of "tricks". The success in many practical applications coupled with the lack of a measure to quantify the failure modes of GANs resulted in a plethora of proposed losses, regularization and normalization schemes, as well as neural architectures. In this work we take a sober view of the current state of GANs from a practical perspective. We discuss and evaluate common pitfalls and reproducibility issues, open-source our code on Github, and provide pre-trained models on TensorFlow Hub.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1807.04720](https://arxiv.org/abs/1807.04720)

##### PDF
[https://arxiv.org/pdf/1807.04720](https://arxiv.org/pdf/1807.04720)

