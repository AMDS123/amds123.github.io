---
layout: post
title: "Sequential Copying Networks"
date: 2018-07-06 08:09:37
categories: arXiv_CL
tags: arXiv_CL Summarization Text_Generation
author: Qingyu Zhou, Nan Yang, Furu Wei, Ming Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
Copying mechanism shows effectiveness in sequence-to-sequence based neural network models for text generation tasks, such as abstractive sentence summarization and question generation. However, existing works on modeling copying or pointing mechanism only considers single word copying from the source sentences. In this paper, we propose a novel copying framework, named Sequential Copying Networks (SeqCopyNet), which not only learns to copy single words, but also copies sequences from the input sentence. It leverages the pointer networks to explicitly select a sub-span from the source side to target side, and integrates this sequential copying mechanism to the generation process in the encoder-decoder paradigm. Experiments on abstractive sentence summarization and question generation tasks show that the proposed SeqCopyNet can copy meaningful spans and outperforms the baseline models.

##### Abstract (translated by Google)
复制机制显示了基于序列到序列的神经网络模型对文本生成任务的有效性，例如抽象句子摘要和问题生成。然而，关于建模复制或指向机制的现有工作仅考虑来自源句子的单个单词复制。在本文中，我们提出了一种新的复制框架，名为顺序复制网络（SeqCopyNet），它不仅学习复制单个单词，还复制输入句子中的序列。它利用指针网络明确选择从源端到目标端的子跨度，并将此顺序复制机制集成到编码器 - 解码器范例中的生成过程。抽象句子摘要和问题生成任务的实验表明，所提出的SeqCopyNet可以复制有意义的跨度并且优于基线模型。

##### URL
[http://arxiv.org/abs/1807.02301](http://arxiv.org/abs/1807.02301)

##### PDF
[http://arxiv.org/pdf/1807.02301](http://arxiv.org/pdf/1807.02301)

