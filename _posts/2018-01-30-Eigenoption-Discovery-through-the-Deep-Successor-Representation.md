---
layout: post
title: "Eigenoption Discovery through the Deep Successor Representation"
date: 2018-01-30 01:48:36
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Represenation_Learning
author: Marlos C. Machado, Clemens Rosenbaum, Xiaoxiao Guo, Miao Liu, Gerald Tesauro, Murray Campbell
mathjax: true
---

* content
{:toc}

##### Abstract
Options in reinforcement learning allow agents to hierarchically decompose a task into subtasks, having the potential to speed up learning and planning. However, autonomously learning effective sets of options is still a major challenge in the field. In this paper we focus on the recently introduced idea of using representation learning methods to guide the option discovery process. Specifically, we look at eigenoptions, options obtained from representations that encode diffusive information flow in the environment. We extend the existing algorithms for eigenoption discovery to settings with stochastic transitions and in which handcrafted features are not available. We propose an algorithm that discovers eigenoptions while learning non-linear state representations from raw pixels. It exploits recent successes in the deep reinforcement learning literature and the equivalence between proto-value functions and the successor representation. We use traditional tabular domains to provide intuition about our approach and Atari 2600 games to demonstrate its potential.

##### Abstract (translated by Google)
强化学习中的选项允许代理人将任务分层分解为子任务，有可能加快学习和计划。然而，自主学习有效的选择方案仍然是该领域的主要挑战。在本文中，我们重点介绍了最近引入的使用表示学习方法来指导期权发现过程的思想。具体来说，我们看一下特征选项，这些选项是从编码环境中的扩散信息流的表示中获得的。我们将用于特征选择发现的现有算法扩展到具有随机过渡的设置，并且其中手工功能不可用。我们提出一个算法，发现本征选项，同时学习从原始像素的非线性状态表示。它利用最近在深度强化学习文献中取得的成功以及原价值函数和后继代表的等价性。我们使用传统的表格域来提供我们的方法和Atari 2600游戏的直观展示其潜力。

##### URL
[http://arxiv.org/abs/1710.11089](http://arxiv.org/abs/1710.11089)

##### PDF
[http://arxiv.org/pdf/1710.11089](http://arxiv.org/pdf/1710.11089)

