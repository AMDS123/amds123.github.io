---
layout: post
title: "A Continuously Growing Dataset of Sentential Paraphrases"
date: 2017-08-01 15:41:51
categories: arXiv_CL
tags: arXiv_CL
author: Wuwei Lan, Siyu Qiu, Hua He, Wei Xu
mathjax: true
---

* content
{:toc}

##### Abstract
A major challenge in paraphrase research is the lack of parallel corpora. In this paper, we present a new method to collect large-scale sentential paraphrases from Twitter by linking tweets through shared URLs. The main advantage of our method is its simplicity, as it gets rid of the classifier or human in the loop needed to select data before annotation and subsequent application of paraphrase identification algorithms in the previous work. We present the largest human-labeled paraphrase corpus to date of 51,524 sentence pairs and the first cross-domain benchmarking for automatic paraphrase identification. In addition, we show that more than 30,000 new sentential paraphrases can be easily and continuously captured every month at ~70% precision, and demonstrate their utility for downstream NLP tasks through phrasal paraphrase extraction. We make our code and data freely available.

##### Abstract (translated by Google)
释义研究中的一个主要挑战是缺乏平行的语料库。在本文中，我们提出了一个新的方法来收集Twitter的大规模释义，通过共享URL链接推文。我们方法的主要优点是它的简单性，因为在前面的工作中，在注释和随后应用释义识别算法之前，在选择数据所需的循环中摆脱了分类器或人。我们提出了迄今为止最大的人类标记的释义语料库51,524个句子对和第一个用于自动释义识别的跨域基准。另外，我们还发现每个月可以容易地和持续地捕获3万多个新的释义释义，精度达到〜70％，并且通过短语释义提取来证明它们对于下游NLP任务的效用。我们使我们的代码和数据免费提供。

##### URL
[https://arxiv.org/abs/1708.00391](https://arxiv.org/abs/1708.00391)

##### PDF
[https://arxiv.org/pdf/1708.00391](https://arxiv.org/pdf/1708.00391)

