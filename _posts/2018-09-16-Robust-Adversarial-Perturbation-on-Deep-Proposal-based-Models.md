---
layout: post
title: "Robust Adversarial Perturbation on Deep Proposal-based Models"
date: 2018-09-16 21:49:14
categories: arXiv_CV
tags: arXiv_CV Adversarial Object_Detection Segmentation Deep_Learning Detection
author: Yuezun Li, Daniel Tian, Mingching-Chang, Xiao Bian, Siwei Lyu
mathjax: true
---

* content
{:toc}

##### Abstract
Adversarial noises are useful tools to probe the weakness of deep learning based computer vision algorithms. In this paper, we describe a robust adversarial perturbation (R-AP) method to attack deep proposal-based object detectors and instance segmentation algorithms. Our method focuses on attacking the common component in these algorithms, namely Region Proposal Network (RPN), to universally degrade their performance in a black-box fashion. To do so, we design a loss function that combines a label loss and a novel shape loss, and optimize it with respect to image using a gradient based iterative algorithm. Evaluations are performed on the MS COCO 2014 dataset for the adversarial attacking of 6 state-of-the-art object detectors and 2 instance segmentation algorithms. Experimental results demonstrate the efficacy of the proposed method.

##### Abstract (translated by Google)
对抗性噪声是探索基于深度学习的计算机视觉算法的弱点的有用工具。在本文中，我们描述了一种强大的对抗扰动（R-AP）方法来攻击基于提议的深度对象检测器和实例分割算法。我们的方法侧重于攻击这些算法中的公共组件，即区域提议网络（RPN），以便以黑盒方式普遍降低其性能。为此，我们设计了一种损失函数，它结合了标签丢失和新颖的形状损失，并使用基于梯度的迭代算法对图像进行优化。对MS COCO 2014数据集进行评估，以对抗6种最先进的物体探测器和2种实例分割算法的对抗性攻击。实验结果证明了该方法的有效性。

##### URL
[http://arxiv.org/abs/1809.05962](http://arxiv.org/abs/1809.05962)

##### PDF
[http://arxiv.org/pdf/1809.05962](http://arxiv.org/pdf/1809.05962)

