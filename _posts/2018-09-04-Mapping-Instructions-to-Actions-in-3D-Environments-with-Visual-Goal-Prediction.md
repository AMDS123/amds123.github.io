---
layout: post
title: "Mapping Instructions to Actions in 3D Environments with Visual Goal Prediction"
date: 2018-09-04 03:36:21
categories: arXiv_CL
tags: arXiv_CL Prediction
author: Dipendra Misra, Andrew Bennett, Valts Blukis, Eyvind Niklasson, Max Shatkhin, Yoav Artzi
mathjax: true
---

* content
{:toc}

##### Abstract
We propose to decompose instruction execution to goal prediction and action generation. We design a model that maps raw visual observations to goals using LINGUNET, a language-conditioned image generation network, and then generates the actions required to complete them. Our model is trained from demonstration only without external resources. 
 To evaluate our approach, we introduce two benchmarks for instruction following: LANI, a navigation task; and CHAI, where an agent executes household instructions. Our evaluation demonstrates the advantages of our model decomposition, and illustrates the challenges posed by our new benchmarks.

##### Abstract (translated by Google)
我们建议将指令执行分解为目标预测和动作生成。我们设计了一个模型，使用语言条件图像生成网络LINGUNET将原始视觉观察映射到目标，然后生成完成它们所需的操作。我们的模型仅通过演示进行训练，无需外部资源。
 为了评估我们的方法，我们为以下指令引入了两个基准：LANI，一个导航任务;和CHAI，代理人执行家庭指令。我们的评估证明了我们的模型分解的优势，并说明了我们的新基准所带来的挑战。

##### URL
[http://arxiv.org/abs/1809.00786](http://arxiv.org/abs/1809.00786)

##### PDF
[http://arxiv.org/pdf/1809.00786](http://arxiv.org/pdf/1809.00786)

