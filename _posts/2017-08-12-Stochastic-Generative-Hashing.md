---
layout: post
title: "Stochastic Generative Hashing"
date: 2017-08-12 21:36:09
categories: arXiv_CV
tags: arXiv_CV
author: Bo Dai, Ruiqi Guo, Sanjiv Kumar, Niao He, Le Song
mathjax: true
---

* content
{:toc}

##### Abstract
Learning-based binary hashing has become a powerful paradigm for fast search and retrieval in massive databases. However, due to the requirement of discrete outputs for the hash functions, learning such functions is known to be very challenging. In addition, the objective functions adopted by existing hashing techniques are mostly chosen heuristically. In this paper, we propose a novel generative approach to learn hash functions through Minimum Description Length principle such that the learned hash codes maximally compress the dataset and can also be used to regenerate the inputs. We also develop an efficient learning algorithm based on the stochastic distributional gradient, which avoids the notorious difficulty caused by binary output constraints, to jointly optimize the parameters of the hash function and the associated generative model. Extensive experiments on a variety of large-scale datasets show that the proposed method achieves better retrieval results than the existing state-of-the-art methods.

##### Abstract (translated by Google)
基于学习的二进制散列已经成为海量数据库中快速搜索和检索的强大范例。但是，由于散列函数需要离散输出，因此学习这些函数是非常具有挑战性的。另外，现有的哈希技术所采用的目标函数大多是启发式选择的。在本文中，我们提出了一种新的生成方法，通过最小描述长度原则学习哈希函数，学习哈希代码最大限度地压缩数据集，也可以用来重新生成输入。我们还开发了一种基于随机分布梯度的高效学习算法，避免了二元输出约束引起的臭名昭着的难题，联合优化了散列函数和相关生成模型的参数。在各种大规模数据集上的大量实验表明，所提出的方法比现有的最先进的方法获得更好的检索结果。

##### URL
[https://arxiv.org/abs/1701.02815](https://arxiv.org/abs/1701.02815)

##### PDF
[https://arxiv.org/pdf/1701.02815](https://arxiv.org/pdf/1701.02815)

