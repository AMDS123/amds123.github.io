---
layout: post
title: "Neural Latent Extractive Document Summarization"
date: 2018-08-22 02:18:40
categories: arXiv_AI
tags: arXiv_AI Summarization
author: Xingxing Zhang, Mirella Lapata, Furu Wei, Ming Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
Extractive summarization models need sentence level labels, which are usually created with rule-based methods since most summarization datasets only have document summary pairs. These labels might be suboptimal. We propose a latent variable extractive model, where sentences are viewed as latent variables and sentences with activated variables are used to infer gold summaries. During training, the loss can come directly from gold summaries. Experiments on CNN/Dailymail dataset show our latent extractive model outperforms a strong extractive baseline trained on rule-based labels and also performs competitively with several recent models.

##### Abstract (translated by Google)
提取摘要模型需要句子级别标签，通常使用基于规则的方法创建，因为大多数摘要数据集仅具有文档摘要对。这些标签可能不是最理想的。我们提出了潜变量提取模型，其中句子被视为潜在变量，而具有激活变量的句子被用于推断黄金摘要。在培训期间，损失可以直接来自黄金摘要。在CNN / Dailymail数据集上的实验表明，我们的潜在提取模型优于基于规则的标签训练的强大的提取基线，并且还与几个最近的模型竞争性地进行。

##### URL
[http://arxiv.org/abs/1808.07187](http://arxiv.org/abs/1808.07187)

##### PDF
[http://arxiv.org/pdf/1808.07187](http://arxiv.org/pdf/1808.07187)

