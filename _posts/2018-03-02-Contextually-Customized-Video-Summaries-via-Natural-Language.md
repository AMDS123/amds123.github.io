---
layout: post
title: "Contextually Customized Video Summaries via Natural Language"
date: 2018-03-02 06:13:45
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption Embedding
author: Jinsoo Choi, Tae-Hyun Oh, In So Kweon
mathjax: true
---

* content
{:toc}

##### Abstract
The best summary of a long video differs among different people due to its highly subjective nature. Even for the same person, the best summary may change with time or mood. In this paper, we introduce the task of generating customized video summaries through simple text. First, we train a deep architecture to effectively learn semantic embeddings of video frames by leveraging the abundance of image-caption data via a progressive and residual manner. Given a user-specific text description, our algorithm is able to select semantically relevant video segments and produce a temporally aligned video summary. In order to evaluate our textually customized video summaries, we conduct experimental comparison with baseline methods that utilize ground-truth information. Despite the challenging baselines, our method still manages to show comparable or even exceeding performance. We also show that our method is able to generate semantically diverse video summaries by only utilizing the learned visual embeddings.

##### Abstract (translated by Google)
长视频的最佳摘要由于其高度主观性而在不同的人之间不同。即使是同一个人，最好的总结也可能随着时间或情绪而变化。在本文中，我们介绍了通过简单文本生成自定义视频摘要的任务。首先，我们通过渐进和残留的方式利用丰富的图像标题数据来训练深度架构，以有效地学习视频帧的语义嵌入。给定用户特定的文本描述，我们的算法能够选择语义相关的视频片段并产生时间上对齐的视频摘要。为了评估我们的文本定制视频摘要，我们与利用地面实况信息的基线方法进行实验比较。尽管基线具有挑战性，但我们的方法仍然表现出可比性甚至超过性能。我们还表明，我们的方法能够通过仅利用学习的视觉嵌入来生成语义上不同的视频摘要。

##### URL
[https://arxiv.org/abs/1702.01528](https://arxiv.org/abs/1702.01528)

##### PDF
[https://arxiv.org/pdf/1702.01528](https://arxiv.org/pdf/1702.01528)

