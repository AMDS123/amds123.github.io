---
layout: post
title: "Contextually Customized Video Summaries via Natural Language"
date: 2018-03-02 06:13:45
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption Embedding
author: Jinsoo Choi, Tae-Hyun Oh, In So Kweon
mathjax: true
---

* content
{:toc}

##### Abstract
The best summary of a long video differs among different people due to its highly subjective nature. Even for the same person, the best summary may change with time or mood. In this paper, we introduce the task of generating customized video summaries through simple text. First, we train a deep architecture to effectively learn semantic embeddings of video frames by leveraging the abundance of image-caption data via a progressive and residual manner. Given a user-specific text description, our algorithm is able to select semantically relevant video segments and produce a temporally aligned video summary. In order to evaluate our textually customized video summaries, we conduct experimental comparison with baseline methods that utilize ground-truth information. Despite the challenging baselines, our method still manages to show comparable or even exceeding performance. We also show that our method is able to generate semantically diverse video summaries by only utilizing the learned visual embeddings.

##### Abstract (translated by Google)
由于其高度主观性，不同人对长视频的最佳总结不同。即使对于同一个人，最好的总结也可能随时间或心情而改变。在本文中，我们介绍通过简单文本生成定制视频摘要的任务。首先，我们训练一个深层次的体系结构，以有效地学习视频帧的语义嵌入，通过利用丰富的图像标题数据通过渐进式和剩余方式。给定用户特定的文本描述，我们的算法能够选择语义相关的视频片段并产生时间上对齐的视频摘要。为了评估我们的文字定制视频摘要，我们与利用地面真实信息的基线方法进行了实验性比较。尽管基线具有挑战性，但我们的方法仍然表现出相当甚至超出的表现。我们还表明，我们的方法能够通过仅使用学习的视觉嵌入来生成语义上不同的视频摘要。

##### URL
[https://arxiv.org/abs/1702.01528](https://arxiv.org/abs/1702.01528)

##### PDF
[https://arxiv.org/pdf/1702.01528](https://arxiv.org/pdf/1702.01528)

