---
layout: post
title: "Unsupervised Human Action Detection by Action Matching"
date: 2017-05-16 00:56:24
categories: arXiv_CV
tags: arXiv_CV Detection Recognition
author: Basura Fernando, Sareh Shirazi, Stephen Gould
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a new task of unsupervised action detection by action matching. Given two long videos, the objective is to temporally detect all pairs of matching video segments. A pair of video segments are matched if they share the same human action. The task is category independent---it does not matter what action is being performed---and no supervision is used to discover such video segments. Unsupervised action detection by action matching allows us to align videos in a meaningful manner. As such, it can be used to discover new action categories or as an action proposal technique within, say, an action detection pipeline. Moreover, it is a useful pre-processing step for generating video highlights, e.g., from sports videos. We present an effective and efficient method for unsupervised action detection. We use an unsupervised temporal encoding method and exploit the temporal consistency in human actions to obtain candidate action segments. We evaluate our method on this challenging task using three activity recognition benchmarks, namely, the MPII Cooking activities dataset, the THUMOS15 action detection benchmark and a new dataset called the IKEA dataset. On the MPII Cooking dataset we detect action segments with a precision of 21.6% and recall of 11.7% over 946 long video pairs and over 5000 ground truth action segments. Similarly, on THUMOS dataset we obtain 18.4% precision and 25.1% recall over 5094 ground truth action segment pairs.

##### Abstract (translated by Google)
我们提出了一个无监督动作检测的新任务。给定两个长视频，目标是暂时检测所有匹配的视频片段对。一对视频片段如果共享相同的人物动作则匹配。这个任务是独立于类别的---不管什么动作正在执行，也不用监督来发现这样的视频片段。通过行动匹配进行无监督行为检测，可以让我们以有意义的方式对齐视频。因此，它可以用来发现新的行动类别，或作为行动检测管道内的行动建议技术。此外，例如从运动视频生成视频高光是一个有用的预处理步骤。我们提出了一种有效的无监督行为检测方法。我们使用无监督的时间编码方法，利用人类行为的时间一致性来获得候选行动段。我们使用三种活动识别基准评估我们的方法，即MPII烹饪活动数据集，THUMOS15动作检测基准和一个称为IKEA数据集的新数据集。在MPII烹饪数据集中，我们检测到了精确度为21.6％的动作片段，并且在946个长视频对和5000多个地面实况动作片段中回忆了11.7％。同样，在THUMOS数据集中，我们获得了超过5094个地面实况动作片段对的18.4％的精度和25.1％的回忆。

##### URL
[https://arxiv.org/abs/1612.00558](https://arxiv.org/abs/1612.00558)

##### PDF
[https://arxiv.org/pdf/1612.00558](https://arxiv.org/pdf/1612.00558)

