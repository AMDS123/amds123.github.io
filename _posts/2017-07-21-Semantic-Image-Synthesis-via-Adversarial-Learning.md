---
layout: post
title: "Semantic Image Synthesis via Adversarial Learning"
date: 2017-07-21 12:45:46
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Hao Dong, Simiao Yu, Chao Wu, Yike Guo
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a way of synthesizing realistic images directly with natural language description, which has many useful applications, e.g. intelligent image manipulation. We attempt to accomplish such synthesis: given a source image and a target text description, our model synthesizes images to meet two requirements: 1) being realistic while matching the target text description; 2) maintaining other image features that are irrelevant to the text description. The model should be able to disentangle the semantic information from the two modalities (image and text), and generate new images from the combined semantics. To achieve this, we proposed an end-to-end neural architecture that leverages adversarial learning to automatically learn implicit loss functions, which are optimized to fulfill the aforementioned two requirements. We have evaluated our model by conducting experiments on Caltech-200 bird dataset and Oxford-102 flower dataset, and have demonstrated that our model is capable of synthesizing realistic images that match the given descriptions, while still maintain other features of original images.

##### Abstract (translated by Google)
在本文中，我们提出了一种直接用自然语言描述来合成逼真图像的方法，其具有许多有用的应用，例如，智能图像处理。我们试图完成这样的合成：给定源图像和目标文本描述，我们的模型合成图像以满足两个要求：1）在符合目标文本描述的情况下是现实的; 2）维护与文本描述无关的其他图像特征。该模型应该能够从两种模式（图像和文本）中分离语义信息，并从组合的语义生成新的图像。为此，我们提出了一种端到端的神经架构，利用敌对学习自动学习隐式损失函数，这些函数经过优化以满足上述两个要求。我们通过在Caltech-200鸟类数据集和Oxford-102花朵数据集上进行实验来评估我们的模型，并且证明了我们的模型能够合成符合给定描述的逼真图像，同时仍然保持原始图像的其他特征。

##### URL
[https://arxiv.org/abs/1707.06873](https://arxiv.org/abs/1707.06873)

##### PDF
[https://arxiv.org/pdf/1707.06873](https://arxiv.org/pdf/1707.06873)

