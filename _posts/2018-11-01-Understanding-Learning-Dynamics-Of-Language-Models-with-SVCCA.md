---
layout: post
title: "Understanding Learning Dynamics Of Language Models with SVCCA"
date: 2018-11-01 04:51:20
categories: arXiv_CL
tags: arXiv_CL Language_Model
author: Naomi Saphra, Adam Lopez
mathjax: true
---

* content
{:toc}

##### Abstract
Recent work has demonstrated that neural language models encode linguistic structure implicitly in a number of ways. However, existing research has not shed light on the process by which this structure is acquired during training. We use SVCCA as a tool for understanding how a language model is implicitly predicting a variety of word cluster tags. We present experiments suggesting that a single recurrent layer of a language model learns linguistic structure in phases. We find, for example, that a language model naturally stabilizes its representation of part of speech earlier than it learns semantic and topic information.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.00225](http://arxiv.org/abs/1811.00225)

##### PDF
[http://arxiv.org/pdf/1811.00225](http://arxiv.org/pdf/1811.00225)

