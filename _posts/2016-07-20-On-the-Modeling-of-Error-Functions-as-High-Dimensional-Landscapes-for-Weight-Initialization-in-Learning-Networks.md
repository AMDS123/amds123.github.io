---
layout: post
title: "On the Modeling of Error Functions as High Dimensional Landscapes for Weight Initialization in Learning Networks"
date: 2016-07-20 16:25:27
categories: arXiv_CV
tags: arXiv_CV Classification
author: Julius, Gopinath Mahale, Sumana T., C. S. Adityakrishna
mathjax: true
---

* content
{:toc}

##### Abstract
Next generation deep neural networks for classification hosted on embedded platforms will rely on fast, efficient, and accurate learning algorithms. Initialization of weights in learning networks has a great impact on the classification accuracy. In this paper we focus on deriving good initial weights by modeling the error function of a deep neural network as a high-dimensional landscape. We observe that due to the inherent complexity in its algebraic structure, such an error function may conform to general results of the statistics of large systems. To this end we apply some results from Random Matrix Theory to analyse these functions. We model the error function in terms of a Hamiltonian in N-dimensions and derive some theoretical results about its general behavior. These results are further used to make better initial guesses of weights for the learning algorithm.

##### Abstract (translated by Google)
面向嵌入式平台的下一代深度神经网络分类将依靠快速，高效和准确的学习算法。学习网络中权重的初始化对分类精度有很大的影响。在本文中，我们着重于通过将深度神经网络的误差函数建模为高维景观来获得良好的初始权重。我们观察到，由于其代数结构固有的复杂性，这种误差函数可能符合大系统统计的一般结果。为此，我们应用随机矩阵理论的一些结果来分析这些函数。我们用N维哈密尔顿量对误差函数进行建模，并推导出其一般性的一些理论结果。这些结果进一步用于更好的初始学习算法的权重猜测。

##### URL
[https://arxiv.org/abs/1607.06011](https://arxiv.org/abs/1607.06011)

##### PDF
[https://arxiv.org/pdf/1607.06011](https://arxiv.org/pdf/1607.06011)

