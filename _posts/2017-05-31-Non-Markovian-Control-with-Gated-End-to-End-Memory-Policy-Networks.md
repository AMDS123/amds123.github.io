---
layout: post
title: "Non-Markovian Control with Gated End-to-End Memory Policy Networks"
date: 2017-05-31 09:00:44
categories: arXiv_CV
tags: arXiv_CV Attention Reinforcement_Learning
author: Julien Perez, Tomi Silander
mathjax: true
---

* content
{:toc}

##### Abstract
Partially observable environments present an important open challenge in the domain of sequential control learning with delayed rewards. Despite numerous attempts during the two last decades, the majority of reinforcement learning algorithms and associated approximate models, applied to this context, still assume Markovian state transitions. In this paper, we explore the use of a recently proposed attention-based model, the Gated End-to-End Memory Network, for sequential control. We call the resulting model the Gated End-to-End Memory Policy Network. More precisely, we use a model-free value-based algorithm to learn policies for partially observed domains using this memory-enhanced neural network. This model is end-to-end learnable and it features unbounded memory. Indeed, because of its attention mechanism and associated non-parametric memory, the proposed model allows us to define an attention mechanism over the observation stream unlike recurrent models. We show encouraging results that illustrate the capability of our attention-based model in the context of the continuous-state non-stationary control problem of stock trading. We also present an OpenAI Gym environment for simulated stock exchange and explain its relevance as a benchmark for the field of non-Markovian decision process learning.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1705.10993](https://arxiv.org/abs/1705.10993)

##### PDF
[https://arxiv.org/pdf/1705.10993](https://arxiv.org/pdf/1705.10993)

