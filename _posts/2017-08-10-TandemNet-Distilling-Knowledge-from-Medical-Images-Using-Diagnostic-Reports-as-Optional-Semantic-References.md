---
layout: post
title: "TandemNet: Distilling Knowledge from Medical Images Using Diagnostic Reports as Optional Semantic References"
date: 2017-08-10 04:12:00
categories: arXiv_CV
tags: arXiv_CV Knowledge Attention Language_Model Prediction
author: Zizhao Zhang, Pingjun Chen, Manish Sapkota, Lin Yang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we introduce the semantic knowledge of medical images from their diagnostic reports to provide an inspirational network training and an interpretable prediction mechanism with our proposed novel multimodal neural network, namely TandemNet. Inside TandemNet, a language model is used to represent report text, which cooperates with the image model in a tandem scheme. We propose a novel dual-attention model that facilitates high-level interactions between visual and semantic information and effectively distills useful features for prediction. In the testing stage, TandemNet can make accurate image prediction with an optional report text input. It also interprets its prediction by producing attention on the image and text informative feature pieces, and further generating diagnostic report paragraphs. Based on a pathological bladder cancer images and their diagnostic reports (BCIDR) dataset, sufficient experiments demonstrate that our method effectively learns and integrates knowledge from multimodalities and obtains significantly improved performance than comparing baselines.

##### Abstract (translated by Google)
本文从他们的诊断报告中引入医学图像的语义知识，为我们提出的新型多模态神经网络TandemNet提供一个启发式的网络训练和一个可解释的预测机制。在TandemNet内部，语言模型被用来表示报告文本，其与图像模型以串联方案协作。我们提出了一个新的双重注意模型，促进视觉和语义信息之间的高层次交互，并有效地提取有用的特征进行预测。在测试阶段，TandemNet可以使用可选的报告文本输入来进行准确的图像预测。它还通过关注图像和文字信息特征片段来解释其预测，并进一步生成诊断报告段落。基于病理性膀胱癌图像及其诊断报告（BCIDR）数据集，充分的实验表明，我们的方法有效地学习和整合多模态的知识，并获得显着改善的性能比基线。

##### URL
[https://arxiv.org/abs/1708.03070](https://arxiv.org/abs/1708.03070)

##### PDF
[https://arxiv.org/pdf/1708.03070](https://arxiv.org/pdf/1708.03070)

