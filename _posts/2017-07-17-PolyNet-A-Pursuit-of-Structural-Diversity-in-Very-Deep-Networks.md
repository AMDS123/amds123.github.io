---
layout: post
title: "PolyNet: A Pursuit of Structural Diversity in Very Deep Networks"
date: 2017-07-17 05:18:01
categories: arXiv_CV
tags: arXiv_CV CNN Recognition
author: Xingcheng Zhang, Zhizhong Li, Chen Change Loy, Dahua Lin
mathjax: true
---

* content
{:toc}

##### Abstract
A number of studies have shown that increasing the depth or width of convolutional networks is a rewarding approach to improve the performance of image recognition. In our study, however, we observed difficulties along both directions. On one hand, the pursuit for very deep networks is met with a diminishing return and increased training difficulty; on the other hand, widening a network would result in a quadratic growth in both computational cost and memory demand. These difficulties motivate us to explore structural diversity in designing deep networks, a new dimension beyond just depth and width. Specifically, we present a new family of modules, namely the PolyInception, which can be flexibly inserted in isolation or in a composition as replacements of different parts of a network. Choosing PolyInception modules with the guidance of architectural efficiency can improve the expressive power while preserving comparable computational cost. The Very Deep PolyNet, designed following this direction, demonstrates substantial improvements over the state-of-the-art on the ILSVRC 2012 benchmark. Compared to Inception-ResNet-v2, it reduces the top-5 validation error on single crops from 4.9% to 4.25%, and that on multi-crops from 3.7% to 3.45%.

##### Abstract (translated by Google)
大量的研究表明，增加卷积网络的深度或宽度是提高图像识别性能的有效方法。但是，在我们的研究中，我们发现了双向的困难。一方面，对网络深层次的追求收益递减，训练难度加大;另一方面，扩大网络将导致计算成本和内存需求的二次增长。这些困难促使我们探索设计深度网络的结构多样性，这是一个不仅深度和宽度的新的维度。具体而言，我们提出了一个新的模块家族，即PolyInception，它可以灵活地插入到一个网络中，或者作为一个网络的不同部分的替代物。在结构效率的指导下选择PolyInception模块可以提高表达能力，同时保持可比的计算成本。按照这个方向设计的非常深的PolyNet，在ILSVRC 2012基准的最新技术上展现了实质性的改进。与Inception-ResNet-v2相比，单一农作物的前5个验证错误从4.9％减少到4.25％，而多种农作物的验证错误从3.7％减少到3.45％。

##### URL
[https://arxiv.org/abs/1611.05725](https://arxiv.org/abs/1611.05725)

##### PDF
[https://arxiv.org/pdf/1611.05725](https://arxiv.org/pdf/1611.05725)

