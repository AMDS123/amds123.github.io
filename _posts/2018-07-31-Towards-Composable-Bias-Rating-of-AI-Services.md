---
layout: post
title: "Towards Composable Bias Rating of AI Services"
date: 2018-07-31 22:15:13
categories: arXiv_AI
tags: arXiv_AI
author: Biplav Srivastava, Francesca Rossi
mathjax: true
---

* content
{:toc}

##### Abstract
A new wave of decision-support systems are being built today using AI services that draw insights from data (like text and video) and incorporate them in human-in-the-loop assistance. However, just as we expect humans to be ethical, the same expectation needs to be met by automated systems that increasingly get delegated to act on their behalf. A very important aspect of an ethical behavior is to avoid (intended, perceived, or accidental) bias. Bias occurs when the data distribution is not representative enough of the natural phenomenon one wants to model and reason about. The possibly biased behavior of a service is hard to detect and handle if the AI service is merely being used and not developed from scratch, since the training data set is not available. In this situation, we envisage a 3rd party rating agency that is independent of the API producer or consumer and has its own set of biased and unbiased data, with customizable distributions. We propose a 2-step rating approach that generates bias ratings signifying whether the AI service is unbiased compensating, data-sensitive biased, or biased. The approach also works on composite services. We implement it in the context of text translation and report interesting results.

##### Abstract (translated by Google)
今天，正在建立新的决策支持系统浪潮，使用人工智能服务，从数据（如文本和视频）中获取洞察力，并将其纳入人在循环的帮助中。然而，就像我们期望人类是道德的一样，自动化系统也需要满足同样的期望，这些系统越来越多地被委派代表他们行事。道德行为的一个非常重要的方面是避免（预期的，感知的或意外的）偏见。当数据分布不足以代表人们想要建模和推理的自然现象时，就会出现偏差。如果AI服务仅仅被使用而不是从头开发，则服务的可能偏向行为难以检测和处理，因为训练数据集不可用。在这种情况下，我们设想第三方评级机构独立于API生产者或消费者，并拥有自己的一组有偏见和无偏见的数据，并具有可定制的分布。我们建议采用两步评级方法，产生偏差评级，表明AI服务是无偏补偿，数据敏感偏差还是有偏差。该方法也适用于组合服务。我们在文本翻译的背景下实现它并报告有趣的结果。

##### URL
[https://arxiv.org/abs/1808.00089](https://arxiv.org/abs/1808.00089)

##### PDF
[https://arxiv.org/pdf/1808.00089](https://arxiv.org/pdf/1808.00089)

