---
layout: post
title: "Modulating and attending the source image during encoding improves Multimodal Translation"
date: 2017-12-09 23:17:22
categories: arXiv_CL
tags: arXiv_CL Attention
author: Jean-Benoit Delbrouck, St&#xe9;phane Dupont
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a new and fully end-to-end approach for multimodal translation where the source text encoder modulates the entire visual input processing using conditional batch normalization, in order to compute the most informative image features for our task. Additionally, we propose a new attention mechanism derived from this original idea, where the attention model for the visual input is conditioned on the source text encoder representations. In the paper, we detail our models as well as the image analysis pipeline. Finally, we report experimental results. They are, as far as we know, the new state of the art on three different test sets.

##### Abstract (translated by Google)
我们提出了一种全新的端到端多模式翻译方法，其中源文本编码器使用条件批量规范化调制整个视觉输入处理，以便为我们的任务计算最丰富的图像特征。此外，我们提出了一个新的注意机制，从这个原始的想法导出，其中视觉输入的注意模型是在源文本编码器表示的条件。在本文中，我们详细介绍了我们的模型以及图像分析流水线。最后，我们报告实验结果。就我们所知，它们是三种不同测试装置上的新技术。

##### URL
[http://arxiv.org/abs/1712.03449](http://arxiv.org/abs/1712.03449)

##### PDF
[http://arxiv.org/pdf/1712.03449](http://arxiv.org/pdf/1712.03449)

