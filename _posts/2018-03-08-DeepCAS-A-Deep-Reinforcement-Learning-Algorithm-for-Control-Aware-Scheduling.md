---
layout: post
title: "DeepCAS: A Deep Reinforcement Learning Algorithm for Control-Aware Scheduling"
date: 2018-03-08 08:20:43
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Burak Demirel, Arunselvan Ramaswamy, Daniel E. Quevedo, Holger Karl
mathjax: true
---

* content
{:toc}

##### Abstract
We consider networked control systems consisting of multiple independent closed-loop control subsystems, operating over a shared communication network. Such systems are ubiquitous in cyber-physical systems, Internet of Things, and large-scale industrial systems. In many large-scale settings, the size of the communication network is smaller than the size of the system. In consequence, scheduling issues arise. The main contribution of this paper is to develop a deep reinforcement learning-based \emph{control-aware} scheduling (\textsc{DeepCAS}) algorithm to tackle these issues. We use the following (optimal) design strategy: First, we synthesize an optimal controller for each subsystem; next, we design learning algorithm that adapts to the chosen subsystem (plant) and controller. As a consequence of this adaptation, our algorithm finds a schedule that minimizes the \emph{control loss}. We present empirical results to show that \textsc{DeepCAS} finds schedules with better performance than periodic ones. Finally, we illustrate that our algorithm can be used for \emph{scheduling and resource allocation in more general networked control settings than the above-mentioned one}.

##### Abstract (translated by Google)
我们考虑由多个独立的闭环控制子系统组成的网络控制系统，这些子系统通过共享通信网络运行。这种系统在网络物理系统，物联网和大规模工业系统中无处不在。在许多大规模设置中，通信网络的大小小于系统的大小。结果，调度问题出现了。本文的主要贡献是开发一个深度强化学习型\ emph {控制感知}调度（\ textsc {DeepCAS}）算法来解决这些问题。我们使用以下（最佳）设计策略：首先，我们为每个子系统合成一个最优控制器;接下来，我们设计适应所选子系统（工厂）和控制器的学习算法。作为这种适应的结果，我们的算法找到了一个最小化\ emph {控制损失}的时间表。我们提供的实证结果表明\ textsc {DeepCAS}发现具有比周期性更好的性能的时间表。最后，我们说明我们的算法可以用于\ emph {调度和资源分配在更广泛的网络控制设置中，而不是上面提到的}。

##### URL
[http://arxiv.org/abs/1803.02998](http://arxiv.org/abs/1803.02998)

##### PDF
[http://arxiv.org/pdf/1803.02998](http://arxiv.org/pdf/1803.02998)

