---
layout: post
title: "Maximum a Posteriori Adaptation of Network Parameters in Deep Models"
date: 2015-08-12 04:53:53
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition Recognition
author: Zhen Huang, Sabato Marco Siniscalchi, I-Fan Chen, Jiadong Wu, Chin-Hui Lee
mathjax: true
---

* content
{:toc}

##### Abstract
We present a Bayesian approach to adapting parameters of a well-trained context-dependent, deep-neural-network, hidden Markov model (CD-DNN-HMM) to improve automatic speech recognition performance. Given an abundance of DNN parameters but with only a limited amount of data, the effectiveness of the adapted DNN model can often be compromised. We formulate maximum a posteriori (MAP) adaptation of parameters of a specially designed CD-DNN-HMM with an augmented linear hidden networks connected to the output tied states, or senones, and compare it to feature space MAP linear regression previously proposed. Experimental evidences on the 20,000-word open vocabulary Wall Street Journal task demonstrate the feasibility of the proposed framework. In supervised adaptation, the proposed MAP adaptation approach provides more than 10% relative error reduction and consistently outperforms the conventional transformation based methods. Furthermore, we present an initial attempt to generate hierarchical priors to improve adaptation efficiency and effectiveness with limited adaptation data by exploiting similarities among senones.

##### Abstract (translated by Google)
我们提出了一个贝叶斯方法，以适应训练有素的上下文相关，深度神经网络，隐马尔可夫模型（CD-DNN-HMM）的参数，以提高自动语音识别性能。由于大量的DNN参数，但只有有限的数据量，DNN模型的有效性通常会受到影响。我们制定了一个特殊设计的CD-DNN-HMM的参数的最大后验（MAP）自适应，其中增强的线性隐藏网络连接到输出绑定状态或者语音，并将其与先前提出的特征空间MAP线性回归进行比较。 20,000字的开放词汇“华尔街日报”任务的实验证据表明了所提议框架的可行性。在有监督的适应中，所提出的MAP适应方法提供了10％以上的相对误差减少，并且始终优于传统的基于转换的方法。此外，我们提出了一个初步的尝试，通过探索相似度来提高适应效率和有效性。

##### URL
[https://arxiv.org/abs/1503.02108](https://arxiv.org/abs/1503.02108)

##### PDF
[https://arxiv.org/pdf/1503.02108](https://arxiv.org/pdf/1503.02108)

