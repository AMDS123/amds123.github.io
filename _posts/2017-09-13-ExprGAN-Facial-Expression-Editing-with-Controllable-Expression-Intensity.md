---
layout: post
title: "ExprGAN: Facial Expression Editing with Controllable Expression Intensity"
date: 2017-09-13 13:05:23
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Adversarial GAN Face Quantitative Recognition
author: Hui Ding, Kumar Sricharan, Rama Chellappa
mathjax: true
---

* content
{:toc}

##### Abstract
Facial expression editing is a challenging task as it needs a high-level semantic understanding of the input face image. In conventional methods, either paired training data is required or the synthetic face resolution is low. Moreover, only the categories of facial expression can be changed. To address these limitations, we propose an Expression Generative Adversarial Network (ExprGAN) for photo-realistic facial expression editing with controllable expression intensity. An expression controller module is specially designed to learn an expressive and compact expression code in addition to the encoder-decoder network. This novel architecture enables the expression intensity to be continuously adjusted from low to high. We further show that our ExprGAN can be applied for other tasks, such as expression transfer, image retrieval, and data augmentation for training improved face expression recognition models. To tackle the small size of the training database, an effective incremental learning scheme is proposed. Quantitative and qualitative evaluations on the widely used Oulu-CASIA dataset demonstrate the effectiveness of ExprGAN.

##### Abstract (translated by Google)
面部表情编辑是一个具有挑战性的任务，因为它需要对输入的脸部图像进行高级语义理解。在传统的方法中，要么配对训练数据要么合成脸部分辨率低。此外，只有面部表情的类别可以改变。为了解决这些限制，我们提出了一个表达式生成对抗网络（ExprGAN）的照片般逼真的面部表情编辑与表达强度可控。表达控制器模块是专门设计用来学习编码器 - 解码器网络以外的表达式和紧凑的表达式代码。这种新颖的架构使表达强度可以从低到高不断调整。我们进一步表明，我们的ExprGAN可以应用于其他任务，如表达式转换，图像检索和数据增强训练改进的人脸表情识别模型。为了处理小规模的培训数据库，提出了一个有效的增量学习方案。广泛使用的Oulu-CASIA数据集的定量和定性评估证明了ExprGAN的有效性。

##### URL
[https://arxiv.org/abs/1709.03842](https://arxiv.org/abs/1709.03842)

##### PDF
[https://arxiv.org/pdf/1709.03842](https://arxiv.org/pdf/1709.03842)

