---
layout: post
title: "Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge"
date: 2016-09-21 17:40:57
categories: arXiv_CV
tags: arXiv_CV Image_Caption GAN Caption Quantitative
author: Oriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan
mathjax: true
---

* content
{:toc}

##### Abstract
Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. Finally, given the recent surge of interest in this task, a competition was organized in 2015 using the newly released COCO dataset. We describe and analyze the various improvements we applied to our own baseline and show the resulting performance in the competition, which we won ex-aequo with a team from Microsoft Research, and provide an open source implementation in TensorFlow.

##### Abstract (translated by Google)
自动描述图像的内容是连接计算机视觉和自然语言处理的人工智能的一个基本问题。在本文中，我们提出了一个基于深度循环体系结构的生成模型，它结合了计算机视觉和机器翻译方面的最新进展，可以用来生成描述图像的自然语句。训练模型以最大化给定训练图像的目标描述句子的可能性。在几个数据集上的实验显示了模型的精确性以及从图像描述中学习的语言的流畅性。我们的模型通常是相当准确的，我们从定性和定量两方面进行验证。最后，鉴于近期对这一任务的兴趣激增，2015年利用新发布的COCO数据集举办了一场竞赛。我们描述并分析了我们应用于自己的基准的各种改进，并展示了竞争中的结果表现，我们与微软研究院的一个团队一起赢得了前所未有的成果，并在TensorFlow中提供了一个开源实现。

##### URL
[https://arxiv.org/abs/1609.06647](https://arxiv.org/abs/1609.06647)

##### PDF
[https://arxiv.org/pdf/1609.06647](https://arxiv.org/pdf/1609.06647)

