---
layout: post
title: "Interpretable Adversarial Perturbation in Input Embedding Space for Text"
date: 2018-05-08 09:27:46
categories: arXiv_CL
tags: arXiv_CL Adversarial Embedding
author: Motoki Sato, Jun Suzuki, Hiroyuki Shindo, Yuji Matsumoto
mathjax: true
---

* content
{:toc}

##### Abstract
Following great success in the image processing field, the idea of adversarial training has been applied to tasks in the natural language processing (NLP) field. One promising approach directly applies adversarial training developed in the image processing field to the input word embedding space instead of the discrete input space of texts. However, this approach abandons such interpretability as generating adversarial texts to significantly improve the performance of NLP tasks. This paper restores interpretability to such methods by restricting the directions of perturbations toward the existing words in the input embedding space. As a result, we can straightforwardly reconstruct each input with perturbations to an actual text by considering the perturbations to be the replacement of words in the sentence while maintaining or even improving the task performance.

##### Abstract (translated by Google)
在图像处理领域取得巨大成功之后，对抗训练的思想已经应用于自然语言处理（NLP）领域的任务。一种有前途的方法直接将图像处理领域开发的对抗训练应用于输入词嵌入空间而不是文本的离散输入空间。然而，这种方法放弃了产生敌对文本等显着提高NLP任务性能的可解释性。本文通过限制输入嵌入空间中现有词的扰动方向来恢复对这些方法的可解释性。因此，我们可以通过将扰动考虑为句子中单词的替换，同时保持甚至改进任务性能，直接重构每个输入与实际文本的扰动。

##### URL
[https://arxiv.org/abs/1805.02917](https://arxiv.org/abs/1805.02917)

##### PDF
[https://arxiv.org/pdf/1805.02917](https://arxiv.org/pdf/1805.02917)

