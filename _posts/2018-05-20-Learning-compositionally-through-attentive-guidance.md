---
layout: post
title: "Learning compositionally through attentive guidance"
date: 2018-05-20 10:33:00
categories: arXiv_AI
tags: arXiv_AI Attention
author: Dieuwke Hupkes, Anand Singh, Kris Korrel, German Kruszewski, Elia Bruni
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we introduce Attentive Guidance (AG), a new mechanism to direct a sequence to sequence model equipped with attention to find more compositional solutions that generalise even in cases where the training and testing distribution strongly diverge. We test AG on two tasks, devised precisely to asses the composi- tional capabilities of neural models and show how vanilla sequence to sequence models with attention overfit the training distribution, while the guided versions come up with compositional solutions that, in some cases, fit the training and testing distributions equally well. AG is a simple and intuitive method to provide a learning bias to a sequence to sequence model without the need of including extra components, that we believe allows to inject a component in the training process which is also present in human learning: guidance.

##### Abstract (translated by Google)
在本文中，我们引入了注意引导（AG），这是一种将序列引导到序列模型的新机制，注意寻找更多的组合解决方案，即使在训练和测试分布强烈分歧的情况下也能推广。我们在两个任务上测试AG，精确设计评估神经模型的组成能力，并展示香草序列如何对模型进行排序，注意过度训练分布，而指导版本提供了在某些情况下适合的组合解决方案培训和测试分配同样很好。 AG是一种简单直观的方法，可以为序列模型提供学习偏差，而不需要包含额外的组件，我们相信它允许在培训过程中注入一个组件，这也存在于人类学习中：指导。

##### URL
[http://arxiv.org/abs/1805.09657](http://arxiv.org/abs/1805.09657)

##### PDF
[http://arxiv.org/pdf/1805.09657](http://arxiv.org/pdf/1805.09657)

