---
layout: post
title: "PaperRobot: Incremental Draft Generation of Scientific Ideas"
date: 2019-05-20 04:41:10
categories: arXiv_AI
tags: arXiv_AI Knowledge_Graph Knowledge Attention
author: Qingyun Wang, Lifu Huang, Zhiying Jiang, Kevin Knight, Heng Ji, Mohit Bansal, Yi Luan
mathjax: true
---

* content
{:toc}

##### Abstract
We present a PaperRobot who performs as an automatic research assistant by (1) conducting deep understanding of a large collection of human-written papers in a target domain and constructing comprehensive background knowledge graphs (KGs); (2) creating new ideas by predicting links from the background KGs, by combining graph attention and contextual text attention; (3) incrementally writing some key elements of a new paper based on memory-attention networks: from the input title along with predicted related entities to generate a paper abstract, from the abstract to generate conclusion and future work, and finally from future work to generate a title for a follow-on paper. Turing Tests, where a biomedical domain expert is asked to compare a system output and a human-authored string, show PaperRobot generated abstracts, conclusion and future work sections, and new titles are chosen over human-written ones up to 30%, 24% and 12% of the time, respectively.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.07870](http://arxiv.org/abs/1905.07870)

##### PDF
[http://arxiv.org/pdf/1905.07870](http://arxiv.org/pdf/1905.07870)

