---
layout: post
title: "Self-Balanced Dropout"
date: 2019-08-06 05:57:22
categories: arXiv_CL
tags: arXiv_CL Relation
author: Shen Li, Chenhao Su, Renfen Hu, Zhengdong Lu
mathjax: true
---

* content
{:toc}

##### Abstract
Dropout is known as an effective way to reduce overfitting via preventing co-adaptations of units. In this paper, we theoretically prove that the co-adaptation problem still exists after using dropout due to the correlations among the inputs. Based on the proof, we further propose Self-Balanced Dropout, a novel dropout method which uses a trainable variable to balance the influence of the input correlation on parameter update. We evaluate Self-Balanced Dropout on a range of tasks with both simple and complex models. The experimental results show that the mechanism can effectively solve the co-adaption problem to some extent and significantly improve the performance on all tasks.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1908.01968](https://arxiv.org/abs/1908.01968)

##### PDF
[https://arxiv.org/pdf/1908.01968](https://arxiv.org/pdf/1908.01968)

