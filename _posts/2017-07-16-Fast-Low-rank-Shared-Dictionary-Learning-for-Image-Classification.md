---
layout: post
title: "Fast Low-rank Shared Dictionary Learning for Image Classification"
date: 2017-07-16 02:39:50
categories: arXiv_CV
tags: arXiv_CV Image_Classification Classification
author: Tiep Vu, Vishal Monga
mathjax: true
---

* content
{:toc}

##### Abstract
Despite the fact that different objects possess distinct class-specific features, they also usually share common patterns. This observation has been exploited partially in a recently proposed dictionary learning framework by separating the particularity and the commonality (COPAR). Inspired by this, we propose a novel method to explicitly and simultaneously learn a set of common patterns as well as class-specific features for classification with more intuitive constraints. Our dictionary learning framework is hence characterized by both a shared dictionary and particular (class-specific) dictionaries. For the shared dictionary, we enforce a low-rank constraint, i.e. claim that its spanning subspace should have low dimension and the coefficients corresponding to this dictionary should be similar. For the particular dictionaries, we impose on them the well-known constraints stated in the Fisher discrimination dictionary learning (FDDL). Further, we develop new fast and accurate algorithms to solve the subproblems in the learning step, accelerating its convergence. The said algorithms could also be applied to FDDL and its extensions. The efficiencies of these algorithms are theoretically and experimentally verified by comparing their complexities and running time with those of other well-known dictionary learning methods. Experimental results on widely used image datasets establish the advantages of our method over state-of-the-art dictionary learning methods.

##### Abstract (translated by Google)
尽管不同的物体具有不同的类别特征，但它们通常也具有共同的模式。这个观察在最近提出的词典学习框架中被部分地利用，将特殊性和共性（COPAR）分开。受此启发，我们提出了一种新颖的方法，可以明确地同时学习一系列常见模式以及更直观的约束条件下的分类特征。我们的字典学习框架的特点是共享字典和特定的（特定于类的）字典。对于共享字典，我们强制执行一个低秩约束，即声明它的生成子空间应该具有低维度，并且对应于这个字典的系数应该是相似的。对于特定的字典，我们强加给他们在Fisher判别字典学习（FDDL）中陈述的众所周知的限制。此外，我们开发了新的快速和准确的算法来解决学习步骤中的子问题，加速其收敛。所述算法也可以应用于FDDL及其扩展。通过比较这些算法的复杂性和运行时间与其他着名的字典学习方法的效率，在理论上和实验上验证了这些算法的效率。广泛使用的图像数据集的实验结果确立了我们的方法优于最先进的字典学习方法的优点。

##### URL
[https://arxiv.org/abs/1610.08606](https://arxiv.org/abs/1610.08606)

##### PDF
[https://arxiv.org/pdf/1610.08606](https://arxiv.org/pdf/1610.08606)

