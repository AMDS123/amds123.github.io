---
layout: post
title: "Action-Affect Classification and Morphing using Multi-Task Representation Learning"
date: 2016-03-21 19:38:07
categories: arXiv_CV
tags: arXiv_CV Represenation_Learning Classification
author: Timothy J. Shields, Mohamed R. Amer, Max Ehrlich, Amir Tamrakar
mathjax: true
---

* content
{:toc}

##### Abstract
Most recent work focused on affect from facial expressions, and not as much on body. This work focuses on body affect analysis. Affect does not occur in isolation. Humans usually couple affect with an action in natural interactions; for example, a person could be talking and smiling. Recognizing body affect in sequences requires efficient algorithms to capture both the micro movements that differentiate between happy and sad and the macro variations between different actions. We depart from traditional approaches for time-series data analytics by proposing a multi-task learning model that learns a shared representation that is well-suited for action-affect classification as well as generation. For this paper we choose Conditional Restricted Boltzmann Machines to be our building block. We propose a new model that enhances the CRBM model with a factored multi-task component to become Multi-Task Conditional Restricted Boltzmann Machines (MTCRBMs). We evaluate our approach on two publicly available datasets, the Body Affect dataset and the Tower Game dataset, and show superior classification performance improvement over the state-of-the-art, as well as the generative abilities of our model.

##### Abstract (translated by Google)
最近的工作重点是面部表情的影响，而不是身体的影响。这项工作重点是身体影响分析。影响不会孤立地发生。人类通常在自然界的相互作用中偶然地产生影响;例如，一个人可以说话，微笑。认识到序列中的身体影响需要有效的算法来捕捉区分开心和悲伤的微观运动以及不同行为之间的宏观差异。我们偏离了传统的时间序列数据分析方法，提出了一个多任务学习模型，学习一个非常适合于行为 - 影响分类和代的共享表示。对于本文我们选择条件限制玻尔兹曼机器作为我们的构件。我们提出了一个新的模型，通过一个分解多任务组件来增强CRBM模型，以成为多任务条件限制玻尔兹曼机器（MTCRBM）。我们在两个公开可用的数据集（身体影响数据集和塔式游戏数据集）上评估我们的方法，并且显示出超越最先进的分类性能的改进以及我们模型的生成能力。

##### URL
[https://arxiv.org/abs/1603.06554](https://arxiv.org/abs/1603.06554)

##### PDF
[https://arxiv.org/pdf/1603.06554](https://arxiv.org/pdf/1603.06554)

