---
layout: post
title: "Embracing Error to Enable Rapid Crowdsourcing"
date: 2016-02-14 20:56:01
categories: arXiv_CV
tags: arXiv_CV Sentiment Classification
author: Ranjay Krishna, Kenji Hata, Stephanie Chen, Joshua Kravitz, David A. Shamma, Li Fei-Fei, Michael S. Bernstein
mathjax: true
---

* content
{:toc}

##### Abstract
Microtask crowdsourcing has enabled dataset advances in social science and machine learning, but existing crowdsourcing schemes are too expensive to scale up with the expanding volume of data. To scale and widen the applicability of crowdsourcing, we present a technique that produces extremely rapid judgments for binary and categorical labels. Rather than punishing all errors, which causes workers to proceed slowly and deliberately, our technique speeds up workers' judgments to the point where errors are acceptable and even expected. We demonstrate that it is possible to rectify these errors by randomizing task order and modeling response latency. We evaluate our technique on a breadth of common labeling tasks such as image verification, word similarity, sentiment analysis and topic classification. Where prior work typically achieves a 0.25x to 1x speedup over fixed majority vote, our approach often achieves an order of magnitude (10x) speedup.

##### Abstract (translated by Google)
Microtask众包使数据集在社会科学和机器学习方面取得了进展，但是随着数据量的不断增长，现有的众包计划太昂贵了。为了扩大和扩大众包的适用性，我们提出了一种对二元和分类标签产生极其快速判断的技术。我们的技术并没有惩罚所有导致工人缓慢而刻意地犯下的错误，而是加快了工人的判断，以至于错误是可以接受的，甚至是可以预料的。我们证明可以通过随机化任务顺序和建模响应延迟来纠正这些错误。我们评估我们的技术广泛的常见标签任务，如图像验证，单词相似性，情感分析和主题分类。如果以前的工作通常比固定的多数选票达到0.25x到1x的加速，我们的方法通常达到一个数量级（10倍）的加速。

##### URL
[https://arxiv.org/abs/1602.04506](https://arxiv.org/abs/1602.04506)

##### PDF
[https://arxiv.org/pdf/1602.04506](https://arxiv.org/pdf/1602.04506)

