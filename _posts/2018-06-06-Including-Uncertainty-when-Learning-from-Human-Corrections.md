---
layout: post
title: "Including Uncertainty when Learning from Human Corrections"
date: 2018-06-06 23:08:09
categories: arXiv_RO
tags: arXiv_RO
author: Dylan P. Losey, Marcia K. O&#x27;Malley
mathjax: true
---

* content
{:toc}

##### Abstract
It is difficult for humans to efficiently teach robots how to correctly perform a task. One intuitive solution is for the robot to iteratively learn the human's preferences from corrections, where the human improves the robot's current behavior at each iteration. When learning from corrections, we argue that while the robot should estimate the most likely human preferences, it should also know what it does not know, and integrate this uncertainty when making decisions. We advance the state-of-the-art by introducing a Kalman filter for learning from corrections: this approach also maintains the uncertainty of the estimated human preferences. Next, we demonstrate how uncertainty can be leveraged for active learning and risk-sensitive deployment. Our results indicate that maintaining and leveraging uncertainty leads to faster learning from human corrections.

##### Abstract (translated by Google)
人类难以有效教授机器人如何正确执行任务。一种直观的解决方案是机器人通过修正来反复学习人类的偏好，其中人类在每次迭代中改善机器人的当前行为。当从纠正中学习时，我们认为，虽然机器人应该估计最可能的人类偏好，但它也应该知道它不知道的内容，并在做出决定时整合这种不确定性。我们通过引入卡尔曼滤波器来学习纠正来推进最先进的技术：这种方法也保持了估计的人类偏好的不确定性。接下来，我们演示如何利用不确定性进行主动学习和风险敏感部署。我们的研究结果表明，维持和利用不确定性会加快人为修正的学习速度。

##### URL
[http://arxiv.org/abs/1806.02454](http://arxiv.org/abs/1806.02454)

##### PDF
[http://arxiv.org/pdf/1806.02454](http://arxiv.org/pdf/1806.02454)

