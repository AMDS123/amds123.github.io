---
layout: post
title: "Learning Human-Object Interactions by Graph Parsing Neural Networks"
date: 2018-08-23 23:04:22
categories: arXiv_CV
tags: arXiv_CV Knowledge Inference Detection
author: Siyuan Qi, Wenguan Wang, Baoxiong Jia, Jianbing Shen, Song-Chun Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper addresses the task of detecting and recognizing human-object interactions (HOI) in images and videos. We introduce the Graph Parsing Neural Network (GPNN), a framework that incorporates structural knowledge while being differentiable end-to-end. For a given scene, GPNN infers a parse graph that includes i) the HOI graph structure represented by an adjacency matrix, and ii) the node labels. Within a message passing inference framework, GPNN iteratively computes the adjacency matrices and node labels. We extensively evaluate our model on three HOI detection benchmarks on images and videos: HICO-DET, V-COCO, and CAD-120 datasets. Our approach significantly outperforms state-of-art methods, verifying that GPNN is scalable to large datasets and applies to spatial-temporal settings. The code is available at https://github.com/SiyuanQi/gpnn.

##### Abstract (translated by Google)
本文讨论了检测和识别图像和视频中的人 - 物交互（HOI）的任务。我们引入了图解析神经网络（GPNN），该框架结合了结构知识，同时具有可区分的端到端。对于给定场景，GPNN推断出解析图，其包括i）由邻接矩阵表示的HOI图结构，以及ii）节点标签。在消息传递推理框架内，GPNN迭代地计算邻接矩阵和节点标签。我们在图像和视频的三个HOI检测基准上广泛评估我们的模型：HICO-DET，V-COCO和CAD-120数据集。我们的方法明显优于最先进的方法，验证GPNN可扩展到大型数据集并应用于空间 - 时间设置。该代码可在https://github.com/SiyuanQi/gpnn获得。

##### URL
[http://arxiv.org/abs/1808.07962](http://arxiv.org/abs/1808.07962)

##### PDF
[http://arxiv.org/pdf/1808.07962](http://arxiv.org/pdf/1808.07962)

