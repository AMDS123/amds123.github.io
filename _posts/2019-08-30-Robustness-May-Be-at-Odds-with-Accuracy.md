---
layout: post
title: "Robustness May Be at Odds with Accuracy"
date: 2019-08-30 22:57:22
categories: arXiv_CV
tags: arXiv_CV Salient Adversarial
author: Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, Aleksander Madry
mathjax: true
---

* content
{:toc}

##### Abstract
We show that there exists an inherent tension between the goal of adversarial robustness and that of standard generalization. Specifically, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists even in a fairly simple and natural setting. These findings also corroborate a similar phenomenon observed empirically in more complex settings. Further, we argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. These differences, in particular, seem to result in unexpected benefits: the representations learned by robust models tend to align better with salient data characteristics and human perception.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1805.12152](http://arxiv.org/abs/1805.12152)

##### PDF
[http://arxiv.org/pdf/1805.12152](http://arxiv.org/pdf/1805.12152)

