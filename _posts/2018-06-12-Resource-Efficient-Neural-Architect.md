---
layout: post
title: "Resource-Efficient Neural Architect"
date: 2018-06-12 20:41:32
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Embedding Recognition
author: Yanqi Zhou, Siavash Ebrahimi, Sercan &#xd6;. Ar&#x131;k, Haonan Yu, Hairong Liu, Greg Diamos
mathjax: true
---

* content
{:toc}

##### Abstract
Neural Architecture Search (NAS) is a laborious process. Prior work on automated NAS targets mainly on improving accuracy, but lacks consideration of computational resource use. We propose the Resource-Efficient Neural Architect (RENA), an efficient resource-constrained NAS using reinforcement learning with network embedding. RENA uses a policy network to process the network embeddings to generate new configurations. We demonstrate RENA on image recognition and keyword spotting (KWS) problems. RENA can find novel architectures that achieve high performance even with tight resource constraints. For CIFAR10, it achieves 2.95% test error when compute intensity is greater than 100 FLOPs/byte, and 3.87% test error when model size is less than 3M parameters. For Google Speech Commands Dataset, RENA achieves the state-of-the-art accuracy without resource constraints, and it outperforms the optimized architectures with tight resource constraints.

##### Abstract (translated by Google)
神经架构搜索（NAS）是一个艰巨的过程。自动化NAS的目标主要是提高准确性，但缺乏对计算资源使用的考虑。我们提出资源节约型神经架构师（RENA），这是一种高效的资源受限的NAS，使用网络嵌入强化学习。 RENA使用策略网络处理网络嵌入以生成新的配置。我们在图像识别和关键词识别（KWS）问题上演示RENA。 RENA可以找到即使在资源紧张的情况下也能实现高性能的新架构。对于CIFAR10，当计算强度大于100 FLOP / byte时，它会达到2.95％的测试误差，当模型尺寸小于3M参数时，测试误差为3.87％。对于Google语音命令数据集，RENA在没有资源限制的情况下实现了最先进的准确性，并且在资源紧张的情况下优于优化的体系结构。

##### URL
[http://arxiv.org/abs/1806.07912](http://arxiv.org/abs/1806.07912)

##### PDF
[http://arxiv.org/pdf/1806.07912](http://arxiv.org/pdf/1806.07912)

