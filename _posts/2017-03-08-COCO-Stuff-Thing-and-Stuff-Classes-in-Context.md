---
layout: post
title: "COCO-Stuff: Thing and Stuff Classes in Context"
date: 2017-03-08 12:36:04
categories: arXiv_CV
tags: arXiv_CV Image_Caption Segmentation Caption Semantic_Segmentation Classification Detection
author: Holger Caesar, Jasper Uijlings, Vittorio Ferrari
mathjax: true
---

* content
{:toc}

##### Abstract
Semantic classes can be either things (objects with a well-defined shape, e.g. car, person) or stuff (amorphous background regions, e.g. grass, sky). While lots of classification and detection works focus on thing classes, less attention has been given to stuff classes. Nonetheless, stuff classes are important as they allow to explain important aspects of an image, including (1) scene type; (2) which thing classes are likely to be present and their location (determined through contextual reasoning); (3) physical attributes, material types and geometric properties of the scene. To understand stuff and things in context we annotate 10,000 images of the COCO dataset with a broad range of stuff classes, using a specialized stuff annotation protocol allowing us to efficiently label each pixel. On this dataset, we analyze several aspects: (a) the importance of stuff and thing classes in terms of their surface cover and how frequently they are mentioned in image captions; (b) the importance of several visual criteria to discriminate stuff and thing classes; (c) we study the spatial relations between stuff and things, highlighting the rich contextual relations that make our dataset unique. Furthermore, we show experimentally how modern semantic segmentation methods perform on stuff and thing classes and answer the question whether stuff is easier to segment than things. We release our new dataset and the trained models online, hopefully promoting further research on stuff and stuff-thing contextual relations.

##### Abstract (translated by Google)
语义类可以是事物（具有明确定义的形状的对象，例如汽车，人）或东西（无定形的背景区域，例如草地，天空）。虽然大量的分类和检测工作都集中在事物类上，但对于东西类却没有给予足够的重视。尽管如此，东西类很重要，因为它们可以解释图像的重要方面，包括（1）场景类型; （2）哪些类别可能存在以及它们的位置（通过语境推理确定）; （3）场景的物理属性，材质类型和几何属性。为了理解上下文中的东西和事物，我们使用专门的东西注释协议来为广泛的东西类注释COCO数据集的10,000个图像，从而使我们能够高效地标记每个像素。在这个数据集中，我们分析了几个方面：（a）东西和事物类别在表面覆盖方面的重要性，以及在图像标题中提到的频率; （b）几个视觉标准对歧视东西类别的重要性; （c）我们研究东西之间的空间关系，突出丰富的上下文关系，使我们的数据集独特。此外，我们实验性地展示了现代语义分割方法如何在东西和事物类上执行，并回答东西是否比事物更容易分割的问题。我们在线发布我们的新数据集和训练好的模型，希望能推动对东西和东西上下文关系的进一步研究。

##### URL
[https://arxiv.org/abs/1612.03716](https://arxiv.org/abs/1612.03716)

##### PDF
[https://arxiv.org/pdf/1612.03716](https://arxiv.org/pdf/1612.03716)

