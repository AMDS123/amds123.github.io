---
layout: post
title: "Dataset Construction via Attention for Aspect Term Extraction with Distant Supervision"
date: 2017-09-26 18:54:39
categories: arXiv_CL
tags: arXiv_CL Sentiment Review Attention
author: Athanasios Giannakopoulos, Diego Antognini, Claudiu Musat, Andreea Hossmann, Michael Baeriswyl
mathjax: true
---

* content
{:toc}

##### Abstract
Aspect Term Extraction (ATE) detects opinionated aspect terms in sentences or text spans, with the end goal of performing aspect-based sentiment analysis. The small amount of available datasets for supervised ATE and the fact that they cover only a few domains raise the need for exploiting other data sources in new and creative ways. Publicly available review corpora contain a plethora of opinionated aspect terms and cover a larger domain spectrum. In this paper, we first propose a method for using such review corpora for creating a new dataset for ATE. Our method relies on an attention mechanism to select sentences that have a high likelihood of containing actual opinionated aspects. We thus improve the quality of the extracted aspects. We then use the constructed dataset to train a model and perform ATE with distant supervision. By evaluating on human annotated datasets, we prove that our method achieves a significantly improved performance over various unsupervised and supervised baselines. Finally, we prove that sentence selection matters when it comes to creating new datasets for ATE. Specifically, we show that, using a set of selected sentences leads to higher ATE performance compared to using the whole sentence set.

##### Abstract (translated by Google)
方面术语提取（ATE）检测句子或文本跨度中的自由方面术语，最终目标是执行基于方面的情感分析。有监督ATE的少量可用数据集以及它们仅涵盖少数几个领域的事实提高了以新的和创造性的方式利用其他数据源的需求。公开可用的评论语料库包含大量有意义的方面术语，涵盖更大的领域范围。在本文中，我们首先提出一种使用这种评论语料库来创建ATE的新数据集的方法。我们的方法依赖于一个注意机制来选择含有实际自我观点的可能性很高的句子。因此，我们提高了提取方面的质量。然后，我们使用构建的数据集来训练一个模型，并执行远程监控的ATE。通过对人类注释的数据集进行评估，我们证明了我们的方法在各种无监督和监督的基线上实现了显着改进的性能。最后，我们证明句子选择对于为ATE创建新的数据集很重要。具体而言，我们表明，使用一组选定的句子导致更高的ATE性能相比，使用整个句子集。

##### URL
[https://arxiv.org/abs/1709.09220](https://arxiv.org/abs/1709.09220)

##### PDF
[https://arxiv.org/pdf/1709.09220](https://arxiv.org/pdf/1709.09220)

