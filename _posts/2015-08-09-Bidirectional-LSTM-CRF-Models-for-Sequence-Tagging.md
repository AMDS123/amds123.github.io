---
layout: post
title: "Bidirectional LSTM-CRF Models for Sequence Tagging"
date: 2015-08-09 06:32:47
categories: arXiv_CL
tags: arXiv_CL Embedding RNN
author: Zhiheng Huang, Wei Xu, Kai Yu
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a variety of Long Short-Term Memory (LSTM) based models for sequence tagging. These models include LSTM networks, bidirectional LSTM (BI-LSTM) networks, LSTM with a Conditional Random Field (CRF) layer (LSTM-CRF) and bidirectional LSTM with a CRF layer (BI-LSTM-CRF). Our work is the first to apply a bidirectional LSTM CRF (denoted as BI-LSTM-CRF) model to NLP benchmark sequence tagging data sets. We show that the BI-LSTM-CRF model can efficiently use both past and future input features thanks to a bidirectional LSTM component. It can also use sentence level tag information thanks to a CRF layer. The BI-LSTM-CRF model can produce state of the art (or close to) accuracy on POS, chunking and NER data sets. In addition, it is robust and has less dependence on word embedding as compared to previous observations.

##### Abstract (translated by Google)
在本文中，我们提出了各种基于长短期记忆（LSTM）的序列标记模型。这些模型包括LSTM网络，双向LSTM（BI-LSTM）网络，具有条件随机场（CRF）层的LSTM（LSTM-CRF）和具有CRF层的双向LSTM（BI-LSTM-CRF）。我们的工作是首次将双向LSTM CRF（表示为BI-LSTM-CRF）模型应用于NLP基准序列标记数据集。我们证明，由于双向LSTM组件，BI-LSTM-CRF模型可以有效地使用过去和未来的输入功能。它也可以使用CRF图层的句子级别标签信息。 BI-LSTM-CRF模型可以在POS，分块和NER数据集上产生最新的（或接近）精度。此外，与以前的观察相比，它是强健的，并且对于词嵌入的依赖较小。

##### URL
[https://arxiv.org/abs/1508.01991](https://arxiv.org/abs/1508.01991)

##### PDF
[https://arxiv.org/pdf/1508.01991](https://arxiv.org/pdf/1508.01991)

