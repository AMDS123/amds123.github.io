---
layout: post
title: "Extending Neural Generative Conversational Model using External Knowledge Sources"
date: 2018-09-14 17:53:53
categories: arXiv_AI
tags: arXiv_AI Knowledge Prediction
author: Prasanna Parthasarathi, Joelle Pineau
mathjax: true
---

* content
{:toc}

##### Abstract
The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge.

##### Abstract (translated by Google)
由于大型语料库的可用性，在会话代理中使用连接主义方法一直在迅速发展。然而，目前的生成对话模式往往缺乏连贯性，并且缺乏内容。这项工作提出了一种架构，以结合非结构化知识源，以增强在聊天类型的生成对话模型中的下一个话语预测。我们专注于使用Reddit新闻数据集训练的序列到序列（Seq2Seq）会话代理，并考虑合并来自维基百科摘要以及NELL知识库的外部知识。我们的实验表明，在利用外部知识时，培训时间更快，并且改善了困惑。

##### URL
[http://arxiv.org/abs/1809.05524](http://arxiv.org/abs/1809.05524)

##### PDF
[http://arxiv.org/pdf/1809.05524](http://arxiv.org/pdf/1809.05524)

