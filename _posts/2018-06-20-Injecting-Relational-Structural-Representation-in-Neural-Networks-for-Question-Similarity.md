---
layout: post
title: "Injecting Relational Structural Representation in Neural Networks for Question Similarity"
date: 2018-06-20 22:09:50
categories: arXiv_CL
tags: arXiv_CL Relation
author: Antonio Uva, Daniele Bonadiman, Alessandro Moschitti
mathjax: true
---

* content
{:toc}

##### Abstract
Effectively using full syntactic parsing information in Neural Networks (NNs) to solve relational tasks, e.g., question similarity, is still an open problem. In this paper, we propose to inject structural representations in NNs by (i) learning an SVM model using Tree Kernels (TKs) on relatively few pairs of questions (few thousands) as gold standard (GS) training data is typically scarce, (ii) predicting labels on a very large corpus of question pairs, and (iii) pre-training NNs on such large corpus. The results on Quora and SemEval question similarity datasets show that NNs trained with our approach can learn more accurate models, especially after fine tuning on GS.

##### Abstract (translated by Google)
在神经网络（NN）中有效地使用完整句法分析信息来解决关系任务，例如问题相似性，仍然是一个开放的问题。在本文中，我们建议通过以下方式在神经网络中注入结构化表示：（i）由于黄金标准（GS）训练数据通常很少，所以在相对少的几对问题（几千）上学习使用树内核（TK）的SVM模型;（ii ）在问题对的非常大的语料库上预测标签，以及（iii）在这样的大语料库上预先训练NN。 Quora和SemEval问题相似性数据集的结果显示，使用我们的方法训练的神经网络可以学习更精确的模型，尤其是在对GS进行精细调整之后。

##### URL
[http://arxiv.org/abs/1806.08009](http://arxiv.org/abs/1806.08009)

##### PDF
[http://arxiv.org/pdf/1806.08009](http://arxiv.org/pdf/1806.08009)

