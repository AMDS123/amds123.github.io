---
layout: post
title: "Edinburgh Neural Machine Translation Systems for WMT 16"
date: 2016-06-27 23:02:24
categories: arXiv_CL
tags: arXiv_CL Segmentation Attention
author: Rico Sennrich, Barry Haddow, Alexandra Birch
mathjax: true
---

* content
{:toc}

##### Abstract
We participated in the WMT 2016 shared news translation task by building neural translation systems for four language pairs, each trained in both directions: English<->Czech, English<->German, English<->Romanian and English<->Russian. Our systems are based on an attentional encoder-decoder, using BPE subword segmentation for open-vocabulary translation with a fixed vocabulary. We experimented with using automatic back-translations of the monolingual News corpus as additional training data, pervasive dropout, and target-bidirectional models. All reported methods give substantial improvements, and we see improvements of 4.3--11.2 BLEU over our baseline systems. In the human evaluation, our systems were the (tied) best constrained system for 7 out of 8 translation directions in which we participated.

##### Abstract (translated by Google)
我们参加了WMT 2016的共享新闻翻译任务，为四种语言对构建神经翻译系统，每种语言对都经过双向培训：英语 - 捷克语，英语 - 德语，英语 - 罗马尼亚语和英语 - 俄语。我们的系统基于一个注意力编码器 - 解码器，使用BPE子词分割开放式词汇表翻译与固定的词汇。我们尝试了使用单语新闻语料库的自动回译作为额外的训练数据，普遍的丢失和目标双向模型。所有报告的方法都得到了实质性的改进，我们看到4.3--11.2 BLEU比我们的基准系统有所提高。在人的评价中，我们的系统是我们参与的8个翻译方向中的7个最好的约束系统。

##### URL
[https://arxiv.org/abs/1606.02891](https://arxiv.org/abs/1606.02891)

##### PDF
[https://arxiv.org/pdf/1606.02891](https://arxiv.org/pdf/1606.02891)

