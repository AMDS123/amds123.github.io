---
layout: post
title: "SemEval-2017 Task 1: Semantic Textual Similarity - Multilingual and Cross-lingual Focused Evaluation"
date: 2017-07-31 20:12:06
categories: arXiv_CL
tags: arXiv_CL Review QA Summarization
author: Daniel Cer, Mona Diab, Eneko Agirre, Iñigo Lopez-Gazpio, Lucia Specia
mathjax: true
---

* content
{:toc}

##### Abstract
Semantic Textual Similarity (STS) measures the meaning similarity of sentences. Applications include machine translation (MT), summarization, generation, question answering (QA), short answer grading, semantic search, dialog and conversational systems. The STS shared task is a venue for assessing the current state-of-the-art. The 2017 task focuses on multilingual and cross-lingual pairs with one sub-track exploring MT quality estimation (MTQE) data. The task obtained strong participation from 31 teams, with 17 participating in all language tracks. We summarize performance and review a selection of well performing methods. Analysis highlights common errors, providing insight into the limitations of existing models. To support ongoing work on semantic representations, the STS Benchmark is introduced as a new shared training and evaluation set carefully selected from the corpus of English STS shared task data (2012-2017).

##### Abstract (translated by Google)
语义文本相似性（STS）衡量句子的意义相似性。应用程序包括机器翻译（MT），摘要，生成，问答（QA），简答题分级，语义搜索，对话和会话系统。 STS共享任务是评估当前最新技术水平的场所。 2017年的工作重点是多语种和跨语种对，其中一个子轨道探索MT质量评估（MTQE）数据。这项任务得到了31个团队的强烈参与，17个参与了所有的语言轨道。我们总结表现，并回顾一些表现良好的方法。分析突出了常见错误，提供了对现有模型局限性的深入了解。为了支持正在进行的关于语义表征的工作，STS基准被引入作为从英语STS共享任务数据（2012-2017）的语料中精心挑选的新的共享训练和评估集合。

##### URL
[https://arxiv.org/abs/1708.00055](https://arxiv.org/abs/1708.00055)

##### PDF
[https://arxiv.org/pdf/1708.00055](https://arxiv.org/pdf/1708.00055)

