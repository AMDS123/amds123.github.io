---
layout: post
title: "Discovering Visual Concept Structure with Sparse and Incomplete Tags"
date: 2017-05-30 14:12:43
categories: arXiv_CV
tags: arXiv_CV Sparse Relation
author: Jingya Wang, Xiatian Zhu, Shaogang Gong
mathjax: true
---

* content
{:toc}

##### Abstract
Discovering automatically the semantic structure of tagged visual data (e.g. web videos and images) is important for visual data analysis and interpretation, enabling the machine intelligence for effectively processing the fast-growing amount of multi-media data. However, this is non-trivial due to the need for jointly learning underlying correlations between heterogeneous visual and tag data. The task is made more challenging by inherently sparse and incomplete tags. In this work, we develop a method for modelling the inherent visual data concept structures based on a novel Hierarchical-Multi-Label Random Forest model capable of correlating structured visual and tag information so as to more accurately interpret the visual semantics, e.g. disclosing meaningful visual groups with similar high-level concepts, and recovering missing tags for individual visual data samples. Specifically, our model exploits hierarchically structured tags of different semantic abstractness and multiple tag statistical correlations in addition to modelling visual and tag interactions. As a result, our model is able to discover more accurate semantic correlation between textual tags and visual features, and finally providing favourable visual semantics interpretation even with highly sparse and incomplete tags. We demonstrate the advantages of our proposed approach in two fundamental applications, visual data clustering and missing tag completion, on benchmarking video (i.e. TRECVID MED 2011) and image (i.e. NUS-WIDE) datasets.

##### Abstract (translated by Google)
自动发现标记的视觉数据（例如网络视频和图像）的语义结构对于视觉数据分析和解释是重要的，使得机器智能能够有效地处理快速增长的多媒体数据量。然而，由于需要联合学习异构视觉和标签数据之间的基础相关性，这是不重要的。固有的稀疏和不完整的标签使任务变得更具挑战性。在这项工作中，我们开发了一种基于新颖的分层多标签随机森林模型的内在视觉数据概念结构的建模方法，该模型能够将结构化视觉和标签信息相关联，以便更准确地解释视觉语义。公开具有相似高级概念的有意义的视觉组，并为各个视觉数据样本恢复缺失的标签。具体而言，我们的模型除了建模视觉和标签交互之外，还利用不同语义抽象度的分层结构标签和多标签统计相关性。因此，我们的模型能够发现文本标签和视觉特征之间的更准确的语义关联，并且即使是高度稀疏和不完整的标签也能提供有利的视觉语义解释。我们在基准视频（即TRECVID MED 2011）和图像（即NUS-WIDE）数据集上展示了我们提出的方法在两个基本应用中的优点，即视觉数据聚类和缺失标签完成。

##### URL
[https://arxiv.org/abs/1705.10659](https://arxiv.org/abs/1705.10659)

##### PDF
[https://arxiv.org/pdf/1705.10659](https://arxiv.org/pdf/1705.10659)

