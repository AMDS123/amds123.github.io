---
layout: post
title: "Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples"
date: 2018-05-16 23:42:04
categories: arXiv_CL
tags: arXiv_CL
author: Vidur Joshi, Matthew Peters, Mark Hopkins
mathjax: true
---

* content
{:toc}

##### Abstract
We revisit domain adaptation for parsers in the neural era. First we show that recent advances in word representations greatly diminish the need for domain adaptation when the target domain is syntactically similar to the source domain. As evidence, we train a parser on the Wall Street Jour- nal alone that achieves over 90% F1 on the Brown corpus. For more syntactically dis- tant domains, we provide a simple way to adapt a parser using only dozens of partial annotations. For instance, we increase the percentage of error-free geometry-domain parses in a held-out set from 45% to 73% using approximately five dozen training examples. In the process, we demon- strate a new state-of-the-art single model result on the Wall Street Journal test set of 94.3%. This is an absolute increase of 1.7% over the previous state-of-the-art of 92.6%.

##### Abstract (translated by Google)
我们重新审视了神经时代语法分析器的领域适应。首先我们表明，当目标域在语法上类似于源域时，最近在单词表示方面取得的进展大大减少了域适应的需要。作为证据，我们仅在华尔街日报上培训解析器，在布朗语料库上达到超过90％的F1。对于更多句法上不同的域，我们提供了一种简单的方法来仅使用数十个部分注释来调整解析器。例如，使用大约五十个训练示例，我们将一个未校正几何域分析的百分比从45％增加到73％。在这个过程中，我们在94.3％的华尔街日报测试集上展示了一个新的最先进的单一模型结果。与之前的92.6％相比，这个数字绝对增加了1.7％。

##### URL
[http://arxiv.org/abs/1805.06556](http://arxiv.org/abs/1805.06556)

##### PDF
[http://arxiv.org/pdf/1805.06556](http://arxiv.org/pdf/1805.06556)

