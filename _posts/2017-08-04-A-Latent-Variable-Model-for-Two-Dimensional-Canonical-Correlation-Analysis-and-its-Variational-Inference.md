---
layout: post
title: "A Latent Variable Model for Two-Dimensional Canonical Correlation Analysis and its Variational Inference"
date: 2017-08-04 14:16:25
categories: arXiv_CV
tags: arXiv_CV Attention Inference Relation
author: Mehran Safayani, Saeid Momenzadeh
mathjax: true
---

* content
{:toc}

##### Abstract
Describing the dimension reduction (DR) techniques by means of probabilistic models has recently been given special attention. Probabilistic models, in addition to a better interpretability of the DR methods, provide a framework for further extensions of such algorithms. One of the new approaches to the probabilistic DR methods is to preserving the internal structure of data. It is meant that it is not necessary that the data first be converted from the matrix or tensor format to the vector format in the process of dimensionality reduction. In this paper, a latent variable model for matrix-variate data for canonical correlation analysis (CCA) is proposed. Since in general there is not any analytical maximum likelihood solution for this model, we present two approaches for learning the parameters. The proposed methods are evaluated using the synthetic data in terms of convergence and quality of mappings. Also, real data set is employed for assessing the proposed methods with several probabilistic and none-probabilistic CCA based approaches. The results confirm the superiority of the proposed methods with respect to the competing algorithms. Moreover, this model can be considered as a framework for further extensions.

##### Abstract (translated by Google)
最近，通过概率模型描述降维（DR）技术受到了特别的关注。除了DR方法的更好的可解释性以外，概率模型还为这些算法的进一步扩展提供了框架。概率DR方法的新方法之一是保持数据的内部结构。这意味着在降维过程中数据首先不必从矩阵或张量格式转换成矢量格式。本文提出了典型相关分析（CCA）矩阵变量数据的潜变量模型。由于一般来说这个模型没有任何分析极大似然解，所以我们提出了两种学习参数的方法。所提出的方法使用合成数据在映射的收敛性和质量方面进行评估。此外，真正的数据集被用来评估所提出的方法与几个概率和非概率CCA的方法。结果证实了所提出的方法相对于竞争算法的优越性。而且，这个模型可以被认为是进一步扩展的框架。

##### URL
[https://arxiv.org/abs/1708.01519](https://arxiv.org/abs/1708.01519)

##### PDF
[https://arxiv.org/pdf/1708.01519](https://arxiv.org/pdf/1708.01519)

