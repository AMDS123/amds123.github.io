---
layout: post
title: "Regularization and Optimization strategies in Deep Convolutional Neural Network"
date: 2017-12-13 11:23:45
categories: arXiv_CV
tags: arXiv_CV Regularization CNN Optimization Prediction
author: Pushparaja Murugan, Shanmugasundaram Durairaj
mathjax: true
---

* content
{:toc}

##### Abstract
Convolution Neural Networks, known as ConvNets exceptionally perform well in many complex machine learning tasks. The architecture of ConvNets demands the huge and rich amount of data and involves with a vast number of parameters that leads the learning takes to be computationally expensive, slow convergence towards the global minima, trap in local minima with poor predictions. In some cases, architecture overfits the data and make the architecture difficult to generalise for new samples that were not in the training set samples. To address these limitations, many regularization and optimization strategies are developed for the past few years. Also, studies suggested that these techniques significantly increase the performance of the networks as well as reducing the computational cost. In implementing these techniques, one must thoroughly understand the theoretical concept of how this technique works in increasing the expressive power of the networks. This article is intended to provide the theoretical concepts and mathematical formulation of the most commonly used strategies in developing a ConvNet architecture.

##### Abstract (translated by Google)
被称为ConvNets的卷积神经网络在许多复杂的机器学习任务中表现出色。 ConvNets的体系结构需要大量丰富的数据，并涉及大量参数，导致学习成本高昂，向全球最低收敛速度缓慢，陷入局部最小，预测不佳。在某些情况下，体系结构过度配置数据，使体系结构难以推广到不在训练集样本中的新样本。为了解决这些限制，过去几年制定了许多正规化和优化策略。此外，研究表明，这些技术显着提高了网络的性能，并降低了计算成本。在实施这些技术时，必须彻底理解这种技术如何工作的理论概念，以增加网络的表达能力。本文旨在为开发ConvNet架构提供最常用策略的理论概念和数学表达。

##### URL
[http://arxiv.org/abs/1712.04711](http://arxiv.org/abs/1712.04711)

##### PDF
[http://arxiv.org/pdf/1712.04711](http://arxiv.org/pdf/1712.04711)

