---
layout: post
title: "Can We Gain More from Orthogonality Regularizations in Training Deep CNNs?"
date: 2018-10-22 06:22:54
categories: arXiv_CV
tags: arXiv_CV Regularization CNN
author: Nitin Bansal, Xiaohan Chen, Zhangyang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper seeks to answer the question: as the (near-) orthogonality of weights is found to be a favorable property for training deep convolutional neural networks, how can we enforce it in more effective and easy-to-use ways? We develop novel orthogonality regularizations on training deep CNNs, utilizing various advanced analytical tools such as mutual coherence and restricted isometry property. These plug-and-play regularizations can be conveniently incorporated into training almost any CNN without extra hassle. We then benchmark their effects on state-of-the-art models: ResNet, WideResNet, and ResNeXt, on several most popular computer vision datasets: CIFAR-10, CIFAR-100, SVHN and ImageNet. We observe consistent performance gains after applying those proposed regularizations, in terms of both the final accuracies achieved, and faster and more stable convergences. We have made our codes and pre-trained models publicly available: https://github.com/nbansal90/Can-we-Gain-More-from-Orthogonality.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.09102](http://arxiv.org/abs/1810.09102)

##### PDF
[http://arxiv.org/pdf/1810.09102](http://arxiv.org/pdf/1810.09102)

