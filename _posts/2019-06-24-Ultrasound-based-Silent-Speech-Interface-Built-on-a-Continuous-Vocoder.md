---
layout: post
title: "Ultrasound-based Silent Speech Interface Built on a Continuous Vocoder"
date: 2019-06-24 12:34:29
categories: arXiv_SD
tags: arXiv_SD Face CNN Prediction
author: Tam&#xe1;s G&#xe1;bor Csap&#xf3;, Mohammed Salah Al-Radhi, G&#xe9;za N&#xe9;meth, G&#xe1;bor Gosztolya, Tam&#xe1;s Gr&#xf3;sz, L&#xe1;szl&#xf3; T&#xf3;th, Alexandra Mark&#xf3;
mathjax: true
---

* content
{:toc}

##### Abstract
Recently it was shown that within the Silent Speech Interface (SSI) field, the prediction of F0 is possible from Ultrasound Tongue Images (UTI) as the articulatory input, using Deep Neural Networks for articulatory-to-acoustic mapping. Moreover, text-to-speech synthesizers were shown to produce higher quality speech when using a continuous pitch estimate, which takes non-zero pitch values even when voicing is not present. Therefore, in this paper on UTI-based SSI, we use a simple continuous F0 tracker which does not apply a strict voiced / unvoiced decision. Continuous vocoder parameters (ContF0, Maximum Voiced Frequency and Mel-Generalized Cepstrum) are predicted using a convolutional neural network, with UTI as input. The results demonstrate that during the articulatory-to-acoustic mapping experiments, the continuous F0 is predicted with lower error, and the continuous vocoder produces slightly more natural synthesized speech than the baseline vocoder using standard discontinuous F0.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.09885](http://arxiv.org/abs/1906.09885)

##### PDF
[http://arxiv.org/pdf/1906.09885](http://arxiv.org/pdf/1906.09885)

