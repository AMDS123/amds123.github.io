---
layout: post
title: "The Unconstrained Ear Recognition Challenge 2019 - ArXiv version With Appendix"
date: 2019-03-12 04:09:13
categories: arXiv_CV
tags: arXiv_CV Deep_Learning Recognition
author: &#x17d;iga Emer&#x161;i&#x10d;, Aruna Kumar S. V., B. S. Harish, Weronika Gutfeter, Jalil Nourmohammadi Khiarak, Andrzej Pacut, Earnest Hansley, Mauricio Pamplona Segundo, Sudeep Sarkar, Hyeonjung Park, Gi Pyo Nam, Ig-Jae Kim, Sagar G. Sangodkar, &#xdc;mit Ka&#xe7;ar, Murvet Kirci, Li Yuan, Jishou Yuan, Haonan Zhao, Fei Lu, Junying Mao, Xiaoshuang Zhang, Dogucan Yaman, Fevziye Irem Eyiokur, Kadir Bulut &#xd6;zler, Haz&#x131;m Kemal Ekenel, Debbrota Paul Chowdhury, Sambit Bakshi, Banshidhar Majhi, Peter Peer, Vitomir &#x160;truc
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a summary of the 2019 Unconstrained Ear Recognition Challenge (UERC), the second in a series of group benchmarking efforts centered around the problem of person recognition from ear images captured in uncontrolled settings. The goal of the challenge is to assess the performance of existing ear recognition techniques on a challenging large-scale ear dataset and to analyze performance of the technology from various viewpoints, such as generalization abilities to unseen data characteristics, sensitivity to rotations, occlusions and image resolution and performance bias on sub-groups of subjects, selected based on demographic criteria, i.e. gender and ethnicity. Research groups from 12 institutions entered the competition and submitted a total of 13 recognition approaches ranging from descriptor-based methods to deep-learning models. The majority of submissions focused on deep learning approaches and hybrid techniques combining hand-crafted and learned image descriptors. Our analysis shows that hybrid and deep-learning-based approaches significantly outperform traditional hand-crafted approaches. We argue that this is a good indicator of where ear recognition will be heading in the future. Furthermore, the results in general improve upon the UERC 2017 and display the steady advancement of the ear recognition.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.04143](http://arxiv.org/abs/1903.04143)

##### PDF
[http://arxiv.org/pdf/1903.04143](http://arxiv.org/pdf/1903.04143)

