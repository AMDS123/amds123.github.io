---
layout: post
title: "A Richly Annotated Dataset for Pedestrian Attribute Recognition"
date: 2016-04-27 06:42:25
categories: arXiv_CV
tags: arXiv_CV Re-identification Knowledge Recognition
author: Dangwei Li, Zhang Zhang, Xiaotang Chen, Haibin Ling, Kaiqi Huang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we aim to improve the dataset foundation for pedestrian attribute recognition in real surveillance scenarios. Recognition of human attributes, such as gender, and clothes types, has great prospects in real applications. However, the development of suitable benchmark datasets for attribute recognition remains lagged behind. Existing human attribute datasets are collected from various sources or an integration of pedestrian re-identification datasets. Such heterogeneous collection poses a big challenge on developing high quality fine-grained attribute recognition algorithms. Furthermore, human attribute recognition are generally severely affected by environmental or contextual factors, such as viewpoints, occlusions and body parts, while existing attribute datasets barely care about them. To tackle these problems, we build a Richly Annotated Pedestrian (RAP) dataset from real multi-camera surveillance scenarios with long term collection, where data samples are annotated with not only fine-grained human attributes but also environmental and contextual factors. RAP has in total 41,585 pedestrian samples, each of which is annotated with 72 attributes as well as viewpoints, occlusions, body parts information. To our knowledge, the RAP dataset is the largest pedestrian attribute dataset, which is expected to greatly promote the study of large-scale attribute recognition systems. Furthermore, we empirically analyze the effects of different environmental and contextual factors on pedestrian attribute recognition. Experimental results demonstrate that viewpoints, occlusions and body parts information could assist attribute recognition a lot in real applications.

##### Abstract (translated by Google)
在本文中，我们的目标是提高真实监控场景下行人属性识别的数据集基础。对人的属性（如性别和衣服类型）的认识在实际应用中具有很大的前景。然而，用于属性识别的合适的基准数据集的发展仍然滞后。现有的人类属性数据集是从各种来源收集的，或者是行人重新识别数据集的集成。这种异构集合对开发高质量的细粒度属性识别算法提出了很大的挑战。此外，人的属性识别一般受到环境或背景因素（如观点，遮挡和身体部位）的严重影响，而现有的属性数据集几乎不关心它们。为了解决这些问题，我们从长期采集的实际多摄像机监视场景中构建了一个富有注记的行人（RAP）数据集，数据样本不仅注明了细粒度的人的属性，还注释了环境和背景因素。移民安置行动计划总共有41,585个行人样本，每个样本都注明了72个属性以及观点，遮挡，身体部位信息。据我们所知，RAP数据集是最大的行人属性数据集，有望极大地促进大规模属性识别系统的研究。此外，我们还通过实证分析了不同环境和背景因素对行人属性识别的影响。实验结果表明，在实际应用中，视点，遮挡和身体部分信息可以有助于属性识别。

##### URL
[https://arxiv.org/abs/1603.07054](https://arxiv.org/abs/1603.07054)

##### PDF
[https://arxiv.org/pdf/1603.07054](https://arxiv.org/pdf/1603.07054)

