---
layout: post
title: "Revisiting Cross Modal Retrieval"
date: 2018-07-19 12:35:24
categories: arXiv_CV
tags: arXiv_CV Knowledge Embedding Relation
author: Shah Nawaz, Muhammad Kamran Janjua, Alessandro Calefati, Ignazio Gallo
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a cross-modal retrieval system that leverages on image and text encoding. Most multimodal architectures employ separate networks for each modality to capture the semantic relationship between them. However, in our work image-text encoding can achieve comparable results in terms of cross-modal retrieval without having to use a separate network for each modality. We show that text encodings can capture semantic relationships between multiple modalities. In our knowledge, this work is the first of its kind in terms of employing a single network and fused image-text embedding for cross-modal retrieval. We evaluate our approach on two famous multimodal datasets: MS-COCO and Flickr30K.

##### Abstract (translated by Google)
本文提出了一种利用图像和文本编码的跨模态检索系统。大多数多模式体系结构为每种模态采用单独的网络来捕获它们之间的语义关系。但是，在我们的工作中，图像文本编码可以在跨模态检索方面获得可比较的结果，而无需为每种模态使用单独的网络。我们表明文本编码可以捕获多种形式之间的语义关系。据我们所知，这项工作是第一次采用单一网络和融合图像文本嵌入进行跨模态检索。我们在两个着名的多模态数据集上评估我们的方法：MS-COCO和Flickr30K。

##### URL
[https://arxiv.org/abs/1807.07364](https://arxiv.org/abs/1807.07364)

##### PDF
[https://arxiv.org/pdf/1807.07364](https://arxiv.org/pdf/1807.07364)

