---
layout: post
title: "STAIR Captions: Constructing a Large-Scale Japanese Image Caption Dataset"
date: 2017-05-02 07:07:55
categories: arXiv_CV
tags: arXiv_CV Image_Caption Attention Caption
author: Yuya Yoshikawa, Yutaro Shigeto, Akikazu Takeuchi
mathjax: true
---

* content
{:toc}

##### Abstract
In recent years, automatic generation of image descriptions (captions), that is, image captioning, has attracted a great deal of attention. In this paper, we particularly consider generating Japanese captions for images. Since most available caption datasets have been constructed for English language, there are few datasets for Japanese. To tackle this problem, we construct a large-scale Japanese image caption dataset based on images from MS-COCO, which is called STAIR Captions. STAIR Captions consists of 820,310 Japanese captions for 164,062 images. In the experiment, we show that a neural network trained using STAIR Captions can generate more natural and better Japanese captions, compared to those generated using English-Japanese machine translation after generating English captions.

##### Abstract (translated by Google)
近年来，图像描述（字幕）的自动生成，即图像字幕，引起了极大的关注。在本文中，我们特别考虑为图像生成日文字幕。由于大多数可用的字幕数据集都是为英语构建的，因此日语的数据集很少。为了解决这个问题，我们基于MS-COCO的图像构建了一个大规模的日本图像标题数据集，称为STAIR Captions。 STAIR字幕包含820,310个日文字幕，共164,062张图像。在实验中，我们表明，与生成英文字幕后使用英日机器翻译生成的神经网络相比，使用STAIR Captions训练的神经网络可以生成更自然，更好的日语字幕。

##### URL
[https://arxiv.org/abs/1705.00823](https://arxiv.org/abs/1705.00823)

##### PDF
[https://arxiv.org/pdf/1705.00823](https://arxiv.org/pdf/1705.00823)

