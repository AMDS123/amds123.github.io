---
layout: post
title: "Predicting Human Eye Fixations via an LSTM-based Saliency Attentive Model"
date: 2017-09-05 10:34:02
categories: arXiv_CV
tags: arXiv_CV Salient Attention CNN RNN Prediction
author: Marcella Cornia, Lorenzo Baraldi, Giuseppe Serra, Rita Cucchiara
mathjax: true
---

* content
{:toc}

##### Abstract
Data-driven saliency has recently gained a lot of attention thanks to the use of Convolutional Neural Networks for predicting gaze fixations. In this paper we go beyond standard approaches to saliency prediction, in which gaze maps are computed with a feed-forward network, and we present a novel model which can predict accurate saliency maps by incorporating neural attentive mechanisms. The core of our solution is a Convolutional LSTM that focuses on the most salient regions of the input image to iteratively refine the predicted saliency map. Additionally, to tackle the center bias present in human eye fixations, our model can learn a set of prior maps generated with Gaussian functions. We show, through an extensive evaluation, that the proposed architecture overcomes the current state of the art on two public saliency prediction datasets. We further study the contribution of each key components to demonstrate their robustness on different scenarios.

##### Abstract (translated by Google)
数据驱动显着性最近得到了很多关注，这要归功于使用卷积神经网络来预测凝视注视。在本文中，我们超越了显着性预测的标准方法，其中凝视图是用前馈网络计算的，我们提出了一个新的模型，可以通过引入神经细致机制来预测准确的显着性图。我们的解决方案的核心是卷积LSTM，其侧重于输入图像的最显着的区域以迭代地改进预测的显着图。此外，为了解决目前在人眼中存在的中心偏差，我们的模型可以学习一组使用高斯函数生成的先验地图。通过广泛评估，我们展示了所提出的架构克服了两个公开显着性预测数据集上的当前技术水平。我们进一步研究每个关键组件的贡献，以展示其在不同场景下的稳健性。

##### URL
[https://arxiv.org/abs/1611.09571](https://arxiv.org/abs/1611.09571)

##### PDF
[https://arxiv.org/pdf/1611.09571](https://arxiv.org/pdf/1611.09571)

