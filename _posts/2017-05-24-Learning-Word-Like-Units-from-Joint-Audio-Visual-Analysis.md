---
layout: post
title: "Learning Word-Like Units from Joint Audio-Visual Analysis"
date: 2017-05-24 22:10:25
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition Caption Recognition
author: David Harwath, James R. Glass
mathjax: true
---

* content
{:toc}

##### Abstract
Given a collection of images and spoken audio captions, we present a method for discovering word-like acoustic units in the continuous speech signal and grounding them to semantically relevant image regions. For example, our model is able to detect spoken instances of the word 'lighthouse' within an utterance and associate them with image regions containing lighthouses. We do not use any form of conventional automatic speech recognition, nor do we use any text transcriptions or conventional linguistic annotations. Our model effectively implements a form of spoken language acquisition, in which the computer learns not only to recognize word categories by sound, but also to enrich the words it learns with semantics by grounding them in images.

##### Abstract (translated by Google)
给定一组图像和语音音频字幕，我们提出了一种方法，用于在连续语音信号中发现类似单词的声学单元，并将它们接地到语义相关的图像区域。例如，我们的模型能够在话语中检测“灯塔”一词的口头实例，并将它们与包含灯塔的图像区域相关联。我们不使用任何形式的传统自动语音识别，也不使用任何文本转录或传统的语言注释。我们的模型有效地实现了一种口语习得的形式，其中计算机不仅学习通过声音识别单词类别，而且通过将它们置于图像中来丰富用语义学习的单词。

##### URL
[https://arxiv.org/abs/1701.07481](https://arxiv.org/abs/1701.07481)

##### PDF
[https://arxiv.org/pdf/1701.07481](https://arxiv.org/pdf/1701.07481)

