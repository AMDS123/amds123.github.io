---
layout: post
title: "Dynamic Memory Networks for Visual and Textual Question Answering"
date: 2016-03-04 10:40:28
categories: arXiv_CV
tags: arXiv_CV Dynamic_Memory_Network Attention Memory_Networks VQA
author: Caiming Xiong, Stephen Merity, Richard Socher
mathjax: true
---

* content
{:toc}

##### Abstract
Neural network architectures with memory and attention mechanisms exhibit certain reasoning capabilities required for question answering. One such architecture, the dynamic memory network (DMN), obtained high accuracy on a variety of language tasks. However, it was not shown whether the architecture achieves strong results for question answering when supporting facts are not marked during training or whether it could be applied to other modalities such as images. Based on an analysis of the DMN, we propose several improvements to its memory and input modules. Together with these changes we introduce a novel input module for images in order to be able to answer visual questions. Our new DMN+ model improves the state of the art on both the Visual Question Answering dataset and the \babi-10k text question-answering dataset without supporting fact supervision.

##### Abstract (translated by Google)
具有记忆和注意机制的神经网络体系结构具有问答应答所需的某些推理能力。动态记忆网络（Dynamic Memory Network，DMN）就是这样一种结构，在各种语言任务中获得了高精度。然而，没有显示架构在训练过程中是否标记事实不明显，或者是否可以应用于图像等其他模式，对于问题解答是否取得了很好的结果。基于对DMN的分析，我们提出了对其内存和输入模块的一些改进。加上这些变化，我们引入了一个新的图像输入模块，以便能够回答视觉问题。我们新的DMN +模型改善了视觉问答应用数据集和\ babi-10k文本问答数据集的最新技术水平，而不需要事实监督。

##### URL
[https://arxiv.org/abs/1603.01417](https://arxiv.org/abs/1603.01417)

##### PDF
[https://arxiv.org/pdf/1603.01417](https://arxiv.org/pdf/1603.01417)

