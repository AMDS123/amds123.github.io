---
layout: post
title: "A Primer on Neural Network Models for Natural Language Processing"
date: 2015-10-02 20:17:33
categories: arXiv_CL
tags: arXiv_CL Survey CNN Recognition
author: Yoav Goldberg
mathjax: true
---

* content
{:toc}

##### Abstract
Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.

##### Abstract (translated by Google)
在过去几年中，神经网络已经重新成为强大的机器学习模型，在图像识别和语音处理等领域产生了最先进的成果。最近，神经网络模型也开始应用于文本自然语言信号，同样具有非常有希望的结果。本教程从自然语言处理研究的角度对神经网络模型进行了调查，试图使自然语言的研究人员加速使用神经技术。本教程涵盖自然语言任务，前馈网络，卷积网络，递归网络和递归网络的输入编码，以及用于自动梯度计算的计算图抽象。

##### URL
[https://arxiv.org/abs/1510.00726](https://arxiv.org/abs/1510.00726)

##### PDF
[https://arxiv.org/pdf/1510.00726](https://arxiv.org/pdf/1510.00726)

