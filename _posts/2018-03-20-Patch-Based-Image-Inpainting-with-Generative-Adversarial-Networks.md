---
layout: post
title: "Patch-Based Image Inpainting with Generative Adversarial Networks"
date: 2018-03-20 13:38:52
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Quantitative
author: Ugur Demir, Gozde Unal
mathjax: true
---

* content
{:toc}

##### Abstract
Area of image inpainting over relatively large missing regions recently advanced substantially through adaptation of dedicated deep neural networks. However, current network solutions still introduce undesired artifacts and noise to the repaired regions. We present an image inpainting method that is based on the celebrated generative adversarial network (GAN) framework. The proposed PGGAN method includes a discriminator network that combines a global GAN (G-GAN) architecture with a patchGAN approach. PGGAN first shares network layers between G-GAN and patchGAN, then splits paths to produce two adversarial losses that feed the generator network in order to capture both local continuity of image texture and pervasive global features in images. The proposed framework is evaluated extensively, and the results including comparison to recent state-of-the-art demonstrate that it achieves considerable improvements on both visual and quantitative evaluations.

##### Abstract (translated by Google)
最近，通过调整专用的深度神经网络，图像区域在相对较大的缺失区域上进行修复。然而，目前的网络解决方案仍然会给修复区域带来不希望的伪影和噪音。我们提出一种基于着名的生成对抗网络（GAN）框架的图像修复方法。所提出的PGGAN方法包括将全局GAN（G-GAN）体系结构与patchGAN方法相结合的鉴别器网络。 PGGAN首先在G-GAN和patchGAN之间共享网络层，然后分割路径产生两个敌对损失，这些损失馈给发生器网络，以捕获图像纹理的局部连续性和图像中的普遍全局特征。拟议的框架得到了广泛的评估，结果包括与最近的最新技术进行比较，结果表明它在视觉和定量评估方面取得了显着的进步。

##### URL
[http://arxiv.org/abs/1803.07422](http://arxiv.org/abs/1803.07422)

##### PDF
[http://arxiv.org/pdf/1803.07422](http://arxiv.org/pdf/1803.07422)

