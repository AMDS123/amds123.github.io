---
layout: post
title: "Automatic Model Based Dataset Generation for Fast and Accurate Crop and Weeds Detection"
date: 2017-08-06 17:33:20
categories: arXiv_CV
tags: arXiv_CV Segmentation Face Classification Deep_Learning Detection
author: Maurilio Di Cicco, Ciro Potena, Giorgio Grisetti, Alberto Pretto
mathjax: true
---

* content
{:toc}

##### Abstract
Selective weeding is one of the key challenges in the field of agriculture robotics. To accomplish this task, a farm robot should be able to accurately detect plants and to distinguish them between crop and weeds. Most of the promising state-of-the-art approaches make use of appearance-based models trained on large annotated datasets. Unfortunately, creating large agricultural datasets with pixel-level annotations is an extremely time consuming task, actually penalizing the usage of data-driven techniques. In this paper, we face this problem by proposing a novel and effective approach that aims to dramatically minimize the human intervention needed to train the detection and classification algorithms. The idea is to procedurally generate large synthetic training datasets randomizing the key features of the target environment (i.e., crop and weed species, type of soil, light conditions). More specifically, by tuning these model parameters, and exploiting a few real-world textures, it is possible to render a large amount of realistic views of an artificial agricultural scenario with no effort. The generated data can be directly used to train the model or to supplement real-world images. We validate the proposed methodology by using as testbed a modern deep learning based image segmentation architecture. We compare the classification results obtained using both real and synthetic images as training data. The reported results confirm the effectiveness and the potentiality of our approach.

##### Abstract (translated by Google)
选择性除草是农业机器人领域的关键挑战之一。为了完成这个任务，农场机器人应该能够准确地检测植物并区分作物和杂草。大多数有前途的最先进的方法都是利用在大型注释数据集上训练的基于外观的模型。不幸的是，创建具有像素级注释的大型农业数据集是一项非常耗时的任务，实际上会影响数据驱动技术的使用。在本文中，我们面临这个问题，提出了一种新颖有效的方法，旨在大大减少训练检测和分类算法所需的人为干预。这个想法是程序化地生成随机化目标环境（即作物和杂草种类，土壤类型，光照条件）的关键特征的大型合成训练数据集。更具体地说，通过调整这些模型参数，并利用一些真实世界的纹理，可以毫不费力地渲染大量现实的人造农业场景视图。生成的数据可以直接用于训练模型或补充现实世界的图像。我们通过使用一个现代的基于深度学习的图像分割体系结构来验证所提出的方法。我们比较使用真实和合成图像获得的分类结果作为训练数据。报告的结果证实了我们方法的有效性和潜力。

##### URL
[https://arxiv.org/abs/1612.03019](https://arxiv.org/abs/1612.03019)

##### PDF
[https://arxiv.org/pdf/1612.03019](https://arxiv.org/pdf/1612.03019)

