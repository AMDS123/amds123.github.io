---
layout: post
title: "Concurrent Activity Recognition with Multimodal CNN-LSTM Structure"
date: 2017-02-06 15:01:45
categories: arXiv_CV
tags: arXiv_CV CNN RNN Recognition
author: Xinyu Li, Yanyi Zhang, Jianyu Zhang, Shuhong Chen, Ivan Marsic, Richard A. Farneth, Randall S. Burd
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a system that recognizes concurrent activities from real-world data captured by multiple sensors of different types. The recognition is achieved in two steps. First, we extract spatial and temporal features from the multimodal data. We feed each datatype into a convolutional neural network that extracts spatial features, followed by a long-short term memory network that extracts temporal information in the sensory data. The extracted features are then fused for decision making in the second step. Second, we achieve concurrent activity recognition with a single classifier that encodes a binary output vector in which elements indicate whether the corresponding activity types are currently in progress. We tested our system with three datasets from different domains recorded using different sensors and achieved performance comparable to existing systems designed specifically for those domains. Our system is the first to address the concurrent activity recognition with multisensory data using a single model, which is scalable, simple to train and easy to deploy.

##### Abstract (translated by Google)
我们引入了一个系统来识别来自不同类型的多个传感器捕获的真实世界数据的并发活动。承认分两步实现。首先，我们从多模态数据中提取空间和时间特征。我们将每个数据类型提供给一个提取空间特征的卷积神经网络，然后是提取感官数据中的时间信息的长期短期记忆网络。提取的特征然后融合在第二步决策。其次，我们使用单个分类器实现并发活动识别，该分类器对二进制输出向量进行编码，其中元素指示相应的活动类型是否正在进行中。我们使用不同的传感器记录了来自不同领域的三个数据集，测试了我们的系统，并实现了与专门为这些领域设计的现有系统相比的性能我们的系统是第一个使用单一模型解决多感官数据并发活动识别问题的系统，该系统具有可扩展性，易于培训且易于部署。

##### URL
[https://arxiv.org/abs/1702.01638](https://arxiv.org/abs/1702.01638)

##### PDF
[https://arxiv.org/pdf/1702.01638](https://arxiv.org/pdf/1702.01638)

