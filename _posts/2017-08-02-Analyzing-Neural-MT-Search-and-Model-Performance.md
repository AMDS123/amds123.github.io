---
layout: post
title: "Analyzing Neural MT Search and Model Performance"
date: 2017-08-02 00:48:35
categories: arXiv_CL
tags: arXiv_CL NMT
author: Jan Niehues, Eunah Cho, Thanh-Le Ha, Alex Waibel
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we offer an in-depth analysis about the modeling and search performance. We address the question if a more complex search algorithm is necessary. Furthermore, we investigate the question if more complex models which might only be applicable during rescoring are promising. By separating the search space and the modeling using $n$-best list reranking, we analyze the influence of both parts of an NMT system independently. By comparing differently performing NMT systems, we show that the better translation is already in the search space of the translation systems with less performance. This results indicate that the current search algorithms are sufficient for the NMT systems. Furthermore, we could show that even a relatively small $n$-best list of $50$ hypotheses already contain notably better translations.

##### Abstract (translated by Google)
在本文中，我们对建模和搜索性能进行了深入的分析。我们解决这个问题是否需要更复杂的搜索算法。此外，我们调查的问题，如果更复杂的模型，可能只适用于rescoring是有希望的。通过使用$ n $  -  best list reranking分离搜索空间和建模，我们独立分析NMT系统的两个部分的影响。通过比较不同表演的NMT系统，我们发现更好的翻译已经在翻译系统的搜索空间中，而性能较差。这个结果表明目前的搜索算法对于NMT系统是足够的。此外，我们可以证明，即使是一个相对较小的$ n $  - 最好的$ 50 $假设列表已经包含了更好的翻译。

##### URL
[https://arxiv.org/abs/1708.00563](https://arxiv.org/abs/1708.00563)

##### PDF
[https://arxiv.org/pdf/1708.00563](https://arxiv.org/pdf/1708.00563)

