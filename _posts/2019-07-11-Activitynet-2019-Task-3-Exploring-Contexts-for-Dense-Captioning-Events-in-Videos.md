---
layout: post
title: "Activitynet 2019 Task 3: Exploring Contexts for Dense Captioning Events in Videos"
date: 2019-07-11 10:29:04
categories: arXiv_AI
tags: arXiv_AI Video_Caption Caption
author: Shizhe Chen, Yuqing Song, Yida Zhao, Qin Jin, Zhaoyang Zeng, Bei Liu, Jianlong Fu, Alexander Hauptmann
mathjax: true
---

* content
{:toc}

##### Abstract
Contextual reasoning is essential to understand events in long untrimmed videos. In this work, we systematically explore different captioning models with various contexts for the dense-captioning events in video task, which aims to generate captions for different events in the untrimmed video. We propose five types of contexts as well as two categories of event captioning models, and evaluate their contributions for event captioning from both accuracy and diversity aspects. The proposed captioning models are plugged into our pipeline system for the dense video captioning challenge. The overall system achieves the state-of-the-art performance on the dense-captioning events in video task with 9.91 METEOR score on the challenge testing set.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.05092](http://arxiv.org/abs/1907.05092)

##### PDF
[http://arxiv.org/pdf/1907.05092](http://arxiv.org/pdf/1907.05092)

