---
layout: post
title: "On the Robustness of Convolutional Neural Networks to Internal Architecture and Weight Perturbations"
date: 2017-03-23 22:25:05
categories: arXiv_CV
tags: arXiv_CV CNN Classification
author: Nicholas Cheney, Martin Schrimpf, Gabriel Kreiman
mathjax: true
---

* content
{:toc}

##### Abstract
Deep convolutional neural networks are generally regarded as robust function approximators. So far, this intuition is based on perturbations to external stimuli such as the images to be classified. Here we explore the robustness of convolutional neural networks to perturbations to the internal weights and architecture of the network itself. We show that convolutional networks are surprisingly robust to a number of internal perturbations in the higher convolutional layers but the bottom convolutional layers are much more fragile. For instance, Alexnet shows less than a 30% decrease in classification performance when randomly removing over 70% of weight connections in the top convolutional or dense layers but performance is almost at chance with the same perturbation in the first convolutional layer. Finally, we suggest further investigations which could continue to inform the robustness of convolutional networks to internal perturbations.

##### Abstract (translated by Google)
深卷积神经网络通常被认为是鲁棒函数逼近器。到目前为止，这种直觉是基于对外部刺激的干扰，如要分类的图像。在这里，我们探讨了卷积神经网络对网络内部权重和结构的扰动的鲁棒性。我们证明卷积网络对于较高卷积层中的许多内部扰动是令人惊讶的鲁棒的，但是底部卷积层更脆弱。例如，当在顶层卷积层或密集层中随机移除超过70％的重量连接时，Alexnet显示分类性能下降不到30％，但是在第一个卷积层中，性能几乎是相同的。最后，我们建议进一步的研究可以继续说明卷积网络对内部扰动的鲁棒性。

##### URL
[https://arxiv.org/abs/1703.08245](https://arxiv.org/abs/1703.08245)

##### PDF
[https://arxiv.org/pdf/1703.08245](https://arxiv.org/pdf/1703.08245)

