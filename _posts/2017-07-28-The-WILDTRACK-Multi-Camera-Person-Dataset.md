---
layout: post
title: "The WILDTRACK Multi-Camera Person Dataset"
date: 2017-07-28 16:05:06
categories: arXiv_CV
tags: arXiv_CV Object_Detection Deep_Learning Detection
author: Tatjana Chavdarova, Pierre Baqué, Stéphane Bouquet, Andrii Maksai, Cijo Jose, Louis Lettry, Pascal Fua, Luc Van Gool, François Fleuret
mathjax: true
---

* content
{:toc}

##### Abstract
People detection methods are highly sensitive to the perpetual occlusions among the targets. As multi-camera set-ups become more frequently encountered, joint exploitation of the across views information would allow for improved detection performances. We provide a large-scale HD dataset named WILDTRACK which finally makes advanced deep learning methods applicable to this problem. The seven-static-camera set-up captures realistic and challenging scenarios of walking people. Notably, its camera calibration with jointly high-precision projection widens the range of algorithms which may make use of this dataset. In aim to help accelerate the research on automatic camera calibration, such annotations also accompany this dataset. Furthermore, the rich-in-appearance visual context of the pedestrian class makes this dataset attractive for monocular pedestrian detection as well, since: the HD cameras are placed relatively close to the people, and the size of the dataset further increases seven-fold. In summary, we overview existing multi-camera datasets and detection methods, enumerate details of our dataset, and we benchmark multi-camera state of the art detectors on this new dataset.

##### Abstract (translated by Google)
人的检测方法对目标间的永久性遮挡非常敏感。随着多摄像机设置变得更频繁，跨视点信息的联合利用将允许改进的检测性能。我们提供了一个名为WILDTRACK的大规模HD数据集，最终使得高级深度学习方法适用于这个问题。七静态相机设置捕捉行走人的现实和具有挑战性的场景。值得注意的是，它的相机标定与联合高精度投影扩大了可能使用这个数据集的算法的范围。为了帮助加快自动摄像机标定的研究，这些标注也伴随着这个数据集。此外，行人类的外观丰富的视觉环境也使得这个数据集对于单眼行人检测具有吸引力，因为：高清摄像机放置在相对接近人的地方，数据集的大小进一步增加了七倍。总之，我们概述了现有的多摄像机数据集和检测方法，列举了我们的数据集的细节，并且我们在这个新的数据集上对多摄像机状态的艺术检测器进行了基准测试。

##### URL
[https://arxiv.org/abs/1707.09299](https://arxiv.org/abs/1707.09299)

##### PDF
[https://arxiv.org/pdf/1707.09299](https://arxiv.org/pdf/1707.09299)

