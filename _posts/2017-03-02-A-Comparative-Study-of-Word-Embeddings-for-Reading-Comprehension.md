---
layout: post
title: "A Comparative Study of Word Embeddings for Reading Comprehension"
date: 2017-03-02 23:58:54
categories: arXiv_SD
tags: arXiv_SD Embedding Deep_Learning Recommendation
author: Bhuwan Dhingra, Hanxiao Liu, Ruslan Salakhutdinov, William W. Cohen
mathjax: true
---

* content
{:toc}

##### Abstract
The focus of past machine learning research for Reading Comprehension tasks has been primarily on the design of novel deep learning architectures. Here we show that seemingly minor choices made on (1) the use of pre-trained word embeddings, and (2) the representation of out-of-vocabulary tokens at test time, can turn out to have a larger impact than architectural choices on the final performance. We systematically explore several options for these choices, and provide recommendations to researchers working in this area.

##### Abstract (translated by Google)
过去机器学习研究的重点是阅读理解任务，主要是设计新颖的深度学习架构。在这里，我们展示了在（1）使用预先训练的单词嵌入和（2）在测试时间表示词汇表征的看似较小的选择可以证明比建筑选择具有更大的影响最后的表演。我们系统地探索了这些选择的几种选择，并为在这方面工作的研究人员提供了建议。

##### URL
[https://arxiv.org/abs/1703.00993](https://arxiv.org/abs/1703.00993)

##### PDF
[https://arxiv.org/pdf/1703.00993](https://arxiv.org/pdf/1703.00993)

