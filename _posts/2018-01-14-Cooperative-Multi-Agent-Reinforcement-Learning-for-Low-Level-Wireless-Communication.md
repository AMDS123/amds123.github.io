---
layout: post
title: "Cooperative Multi-Agent Reinforcement Learning for Low-Level Wireless Communication"
date: 2018-01-14 12:05:12
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Colin de Vrieze, Shane Barratt, Daniel Tsai, Anant Sahai
mathjax: true
---

* content
{:toc}

##### Abstract
Traditional radio systems are strictly co-designed on the lower levels of the OSI stack for compatibility and efficiency. Although this has enabled the success of radio communications, it has also introduced lengthy standardization processes and imposed static allocation of the radio spectrum. Various initiatives have been undertaken by the research community to tackle the problem of artificial spectrum scarcity by both making frequency allocation more dynamic and building flexible radios to replace the static ones. There is reason to believe that just as computer vision and control have been overhauled by the introduction of machine learning, wireless communication can also be improved by utilizing similar techniques to increase the flexibility of wireless networks. In this work, we pose the problem of discovering low-level wireless communication schemes ex-nihilo between two agents in a fully decentralized fashion as a reinforcement learning problem. Our proposed approach uses policy gradients to learn an optimal bi-directional communication scheme and shows surprisingly sophisticated and intelligent learning behavior. We present the results of extensive experiments and an analysis of the fidelity of our approach.

##### Abstract (translated by Google)
为了兼容性和效率，传统的无线电系统严格在OSI堆栈的较低层级协同设计。尽管这使得无线电通信成功，但它也引入了漫长的标准化过程，并对无线电频谱进行静态分配。研究机构已经采取了各种措施来解决人造频谱稀缺问题，既要使频率分配更加有活力，又要建设灵活的无线电来代替静态频谱。有理由相信，正如计算机视觉和控制由于机器学习的引入而大刀阔斧，也可以通过利用类似的技术来提高无线网络的灵活性来改善无线通信。在这项工作中，我们提出了以完全分散的方式将两个Agent之间的低层无线通信方案作为强化学习问题发现的问题。我们提出的方法使用政策梯度来学习最佳的双向通信方案，并显示出惊人的复杂和智能的学习行为。我们展示了广泛的实验的结果，并分析了我们的方法的保真度。

##### URL
[https://arxiv.org/abs/1801.04541](https://arxiv.org/abs/1801.04541)

##### PDF
[https://arxiv.org/pdf/1801.04541](https://arxiv.org/pdf/1801.04541)

