---
layout: post
title: "A Neurobiological Cross-domain Evaluation Metric for Predictive Coding Networks"
date: 2018-05-28 01:33:49
categories: arXiv_CV
tags: arXiv_CV Prediction Relation
author: Nathaniel Blanchard, Jeffery Kinnison, Brandon RichardWebster, Pouya Bashivan, Walter J. Scheirer
mathjax: true
---

* content
{:toc}

##### Abstract
Achieving a good measure of model generalization remains a challenge within machine learning. One of the highest-performing learning models is the biological brain, which has unparalleled generalization capabilities. In this work, we propose and evaluate a human-model similarity metric for determining model correspondence to the human brain, as inspired by representational similarity analysis. We evaluate this metric on unsupervised predictive coding networks. These models are designed to mimic the phenomenon of residual error propagation in the visual cortex, implying their potential for biological fidelity. The human-model similarity metric is calculated by measuring the similarity between human brain fMRI activations and predictive coding network activations over a shared set of stimuli. In order to study our metric in relation to standard performance evaluations on cross-domain tasks, we train a multitude of predictive coding models across various conditions. Each unsupervised model is trained on next frame prediction in video and evaluated using three metrics: 1) mean squared error of next frame prediction, 2) object matching accuracy, and 3) our human-model similarity metric. Through this evaluation, we show that models with higher human-model similarity are more likely to generalize to cross-domain tasks. We also show that our metric facilitates a substantial decrease in model search time because the similarity metric stabilizes quickly --- in as few as 10 epochs. We propose that this metric could be deployed in model search to quickly identify and eliminate weaker models.

##### Abstract (translated by Google)
实现模型一般化的一个很好的措施仍然是机器学习中的一个挑战。表现最好的学习模式之一是生物脑，具有无与伦比的泛化能力。在这项工作中，我们提出并评估了人类模型相似性度量，以确定与人类大脑的模型对应关系，这受到了表征相似性分析的启发。我们在无监督预测编码网络上评估这个度量。这些模型旨在模拟视觉皮层残留误差传播现象，意味着它们具有生物保真度的潜力。人类模型相似性度量通过测量人脑fMRI激活与共享激励集上的预测编码网络激活之间的相似性来计算。为了研究我们关于跨领域任务的标准性能评估的度量标准，我们在各种条件下训练了大量的预测编码模型。每个无监督模型在视频中进行下一帧预测的训练，并使用三个度量进行评估：1）下一帧预测的均方误差，2）目标匹配精度，以及3）我们的人体模型相似性度量。通过这个评估，我们发现具有较高人类模型相似度的模型更有可能推广到跨域任务。我们还表明，我们的度量标准有助于大幅缩短模型搜索时间，因为相似性度量可以快速稳定下来 - 只需10个时间点。我们建议可以在模型搜索中部署此度量标准，以快速识别并消除较弱的模型。

##### URL
[http://arxiv.org/abs/1805.10726](http://arxiv.org/abs/1805.10726)

##### PDF
[http://arxiv.org/pdf/1805.10726](http://arxiv.org/pdf/1805.10726)

