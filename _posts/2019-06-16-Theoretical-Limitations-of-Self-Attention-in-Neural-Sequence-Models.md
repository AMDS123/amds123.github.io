---
layout: post
title: "Theoretical Limitations of Self-Attention in Neural Sequence Models"
date: 2019-06-16 19:19:49
categories: arXiv_CL
tags: arXiv_CL Attention RNN
author: Michael Hahn
mathjax: true
---

* content
{:toc}

##### Abstract
Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of self-attention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. Our results precisely describe theoretical limitations of the techniques underlying recent advances in NLP.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.06755](http://arxiv.org/abs/1906.06755)

##### PDF
[http://arxiv.org/pdf/1906.06755](http://arxiv.org/pdf/1906.06755)

