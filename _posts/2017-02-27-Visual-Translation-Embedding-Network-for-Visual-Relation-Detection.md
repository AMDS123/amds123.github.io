---
layout: post
title: "Visual Translation Embedding Network for Visual Relation Detection"
date: 2017-02-27 15:16:47
categories: arXiv_CV
tags: arXiv_CV Object_Detection Knowledge Embedding CNN Represenation_Learning Inference Detection Relation
author: Hanwang Zhang, Zawlin Kyaw, Shih-Fu Chang, Tat-Seng Chua
mathjax: true
---

* content
{:toc}

##### Abstract
Visual relations, such as "person ride bike" and "bike next to car", offer a comprehensive scene understanding of an image, and have already shown their great utility in connecting computer vision and natural language. However, due to the challenging combinatorial complexity of modeling subject-predicate-object relation triplets, very little work has been done to localize and predict visual relations. Inspired by the recent advances in relational representation learning of knowledge bases and convolutional object detection networks, we propose a Visual Translation Embedding network (VTransE) for visual relation detection. VTransE places objects in a low-dimensional relation space where a relation can be modeled as a simple vector translation, i.e., subject + predicate $\approx$ object. We propose a novel feature extraction layer that enables object-relation knowledge transfer in a fully-convolutional fashion that supports training and inference in a single forward/backward pass. To the best of our knowledge, VTransE is the first end-to-end relation detection network. We demonstrate the effectiveness of VTransE over other state-of-the-art methods on two large-scale datasets: Visual Relationship and Visual Genome. Note that even though VTransE is a purely visual model, it is still competitive to the Lu's multi-modal model with language priors.

##### Abstract (translated by Google)
“人骑自行车”和“汽车旁边的自行车”等视觉关系，提供了对图像的全面的场景理解，并且已经在将计算机视觉和自然语言连接起来方面显示出了巨大的实用性。然而，由于建模主客谓语关系三元组的复杂性很复杂，所以在定位和预测视觉关系方面做了很少的工作。受知识库和卷积对象检测网络关系表示学习的最新进展的启发，提出了一种视觉关系检测的视觉翻译嵌入网络（VTransE）。 VTransE将对象放置在低维关系空间中，其中可以将关系建模为简单向量转换，即subject + predicate $ \ approx $ object。我们提出了一个新的特征提取层，使得对象关系知识以全卷积方式传递，支持单向前进/后退过程中的训练和推理。就我们所知，VTransE是第一个端到端的关系检测网络。我们在两个大规模数据集上展示了VTransE优于其他最先进方法的效果：Visual Relationship和Visual Genome。请注意，尽管VTransE是一个纯粹的视觉模型，但它仍然与具有语言先验的Lu的多模态模型相竞争。

##### URL
[https://arxiv.org/abs/1702.08319](https://arxiv.org/abs/1702.08319)

##### PDF
[https://arxiv.org/pdf/1702.08319](https://arxiv.org/pdf/1702.08319)

