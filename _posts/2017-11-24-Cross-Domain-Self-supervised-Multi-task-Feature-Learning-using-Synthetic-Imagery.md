---
layout: post
title: "Cross-Domain Self-supervised Multi-task Feature Learning using Synthetic Imagery"
date: 2017-11-24 18:55:01
categories: arXiv_CV
tags: arXiv_CV Adversarial Face Transfer_Learning Classification Detection
author: Zhongzheng Ren, Yong Jae Lee
mathjax: true
---

* content
{:toc}

##### Abstract
In human learning, it is common to use multiple sources of information jointly. However, most existing feature learning approaches learn from only a single task. In this paper, we propose a novel multi-task deep network to learn generalizable high-level visual representations. Since multi-task learning requires annotations for multiple properties of the same training instance, we look to synthetic images to train our network. To overcome the domain difference between real and synthetic data, we employ an unsupervised feature space domain adaptation method based on adversarial learning. Given an input synthetic RGB image, our network simultaneously predicts its surface normal, depth, and instance contour, while also minimizing the feature space domain differences between real and synthetic data. Through extensive experiments, we demonstrate that our network learns more transferable representations compared to single-task baselines. Our learned representation produces state-of-the-art transfer learning results on PASCAL VOC 2007 classification and 2012 detection.

##### Abstract (translated by Google)
在人类学习中，共同使用多种信息来源是很常见的。然而，大多数现有的特征学习方法仅从单个任务中学习。在本文中，我们提出了一个新的多任务深度网络来学习可普遍化的高级视觉表示。由于多任务学习需要对同一训练实例的多个属性进行注释，所以我们期望合成图像来训练我们的网络。为了克服实际和合成数据之间的领域差异，我们采用基于对抗学习的无监督特征空间域自适应方法。给定输入的合成RGB图像，我们的网络同时预测其表面法线，深度和实例轮廓，同时也使真实和合成数据之间的特征空间区域差异最小化。通过广泛的实验，我们证明了与单任务基线相比，我们的网络学习了更多可转移的表示。我们的学习表现形成了PASCAL VOC 2007分类和2012年检测的最新转移学习结果。

##### URL
[https://arxiv.org/abs/1711.09082](https://arxiv.org/abs/1711.09082)

##### PDF
[https://arxiv.org/pdf/1711.09082](https://arxiv.org/pdf/1711.09082)

