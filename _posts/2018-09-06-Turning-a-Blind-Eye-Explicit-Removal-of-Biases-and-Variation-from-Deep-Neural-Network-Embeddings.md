---
layout: post
title: "Turning a Blind Eye: Explicit Removal of Biases and Variation from Deep Neural Network Embeddings"
date: 2018-09-06 18:44:56
categories: arXiv_CV
tags: arXiv_CV Embedding Image_Classification Classification
author: Mohsan Alvi, Andrew Zisserman, Christoffer Nellaker
mathjax: true
---

* content
{:toc}

##### Abstract
Neural networks achieve the state-of-the-art in image classification tasks. However, they can encode spurious variations or biases that may be present in the training data. For example, training an age predictor on a dataset that is not balanced for gender can lead to gender biased predicitons (e.g. wrongly predicting that males are older if only elderly males are in the training set). We present two distinct contributions: 1) An algorithm that can remove multiple sources of variation from the feature representation of a network. We demonstrate that this algorithm can be used to remove biases from the feature representation, and thereby improve classification accuracies, when training networks on extremely biased datasets. 2) An ancestral origin database of 14,000 images of individuals from East Asia, the Indian subcontinent, sub-Saharan Africa, and Western Europe. We demonstrate on this dataset, for a number of facial attribute classification tasks, that we are able to remove racial biases from the network feature representation.

##### Abstract (translated by Google)
神经网络实现了图像分类任务的最新技术。但是，它们可以编码可能存在于训练数据中的虚假变化或偏差。例如，在不平衡性别的数据集上训练年龄预测因子可导致性别偏见的预测（例如，如果只有老年男性在训练集中，则错误地预测男性年龄较大）。我们提出了两个不同的贡献：1）一种算法，可以从网络的特征表示中删除多个变异源。我们证明，当在极端偏向的数据集上训练网络时，该算法可用于从特征表示中去除偏差，从而提高分类准确度。 2）来自东亚，印度次大陆，撒哈拉以南非洲和西欧的14,000个人的祖先原始数据库。我们在此数据集上演示了一些面部属性分类任务，即我们能够从网络特征表示中删除种族偏见。

##### URL
[http://arxiv.org/abs/1809.02169](http://arxiv.org/abs/1809.02169)

##### PDF
[http://arxiv.org/pdf/1809.02169](http://arxiv.org/pdf/1809.02169)

