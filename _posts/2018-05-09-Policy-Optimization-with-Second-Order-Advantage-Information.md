---
layout: post
title: "Policy Optimization with Second-Order Advantage Information"
date: 2018-05-09 15:23:58
categories: arXiv_AI
tags: arXiv_AI Optimization
author: Jiajin Li, Baoxiang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Policy optimization on high-dimensional continuous control tasks exhibits its difficulty caused by the large variance of the policy gradient estimators. We present the action subspace dependent gradient (ASDG) estimator which incorporates the Rao-Blackwell theorem (RB) and Control Variates (CV) into a unified framework to reduce the variance. To invoke RB, our proposed algorithm (POSA) learns the underlying factorization structure among the action space based on the second-order advantage information. POSA captures the quadratic information explicitly and efficiently by utilizing the wide &amp; deep architecture. Empirical studies show that our proposed approach demonstrates the performance improvements on high-dimensional synthetic settings and OpenAI Gym's MuJoCo continuous control tasks.

##### Abstract (translated by Google)
高维连续控制任务的策略优化表现出由策略梯度估计量的大方差导致的困难。我们提出了行动子空间相关梯度（ASDG）估计器，它将Rao-Blackwell定理（RB）和控制变量（CV）合并到统一的框架中以减少方差。为了调用RB，我们提出的算法（POSA）基于二阶优势信息学习动作空间中的基本因式分解结构。 POSA通过利用宽带和高分辨率显式和高效地捕获二次信息。深层建筑。实证研究表明，我们提出的方法展示了高维综合设置和OpenAI Gym MuJoCo连续控制任务的性能改进。

##### URL
[http://arxiv.org/abs/1805.03586](http://arxiv.org/abs/1805.03586)

##### PDF
[http://arxiv.org/pdf/1805.03586](http://arxiv.org/pdf/1805.03586)

