---
layout: post
title: "Reinforcement Learning for Personalized Dialogue Management"
date: 2019-08-01 09:19:27
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Recommendation
author: Floris den Hengst, Mark Hoogendoorn, Frank van Harmelen, Joost Bosman
mathjax: true
---

* content
{:toc}

##### Abstract
Language systems have been of great interest to the research community and have recently reached the mass market through various assistant platforms on the web. Reinforcement Learning methods that optimize dialogue policies have seen successes in past years and have recently been extended into methods that personalize the dialogue, e.g. take the personal context of users into account. These works, however, are limited to personalization to a single user with whom they require multiple interactions and do not generalize the usage of context across users. This work introduces a problem where a generalized usage of context is relevant and proposes two Reinforcement Learning (RL)-based approaches to this problem. The first approach uses a single learner and extends the traditional POMDP formulation of dialogue state with features that describe the user context. The second approach segments users by context and then employs a learner per context. We compare these approaches in a benchmark of existing non-RL and RL-based methods in three established and one novel application domain of financial product recommendation. We compare the influence of context and training experiences on performance and find that learning approaches generally outperform a handcrafted gold standard.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.00286](http://arxiv.org/abs/1908.00286)

##### PDF
[http://arxiv.org/pdf/1908.00286](http://arxiv.org/pdf/1908.00286)

