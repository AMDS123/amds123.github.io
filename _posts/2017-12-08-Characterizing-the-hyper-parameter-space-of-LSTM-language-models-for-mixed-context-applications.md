---
layout: post
title: "Characterizing the hyper-parameter space of LSTM language models for mixed context applications"
date: 2017-12-08 17:52:32
categories: arXiv_CL
tags: arXiv_CL RNN Deep_Learning Language_Model
author: Victor Akinwande, Sekou L. Remy
mathjax: true
---

* content
{:toc}

##### Abstract
Applying state of the art deep learning models to novel real world datasets gives a practical evaluation of the generalizability of these models. Of importance in this process is how sensitive the hyper parameters of such models are to novel datasets as this would affect the reproducibility of a model. We present work to characterize the hyper parameter space of an LSTM for language modeling on a code-mixed corpus. We observe that the evaluated model shows minimal sensitivity to our novel dataset bar a few hyper parameters.

##### Abstract (translated by Google)
将先进的深度学习模型应用于新的现实世界的数据集给出了这些模型的普遍性的实际评估。在这个过程中重要的是这种模型的超参数对于新颖的数据集有多敏感，因为这会影响模型的再现性。我们提出的工作来描述一个LSTM的超参数空间，用于混合语料库上的语言建模。我们观察到，评估模型显示最小的敏感性，我们的新颖的数据集吧一些超参数。

##### URL
[https://arxiv.org/abs/1712.03199](https://arxiv.org/abs/1712.03199)

##### PDF
[https://arxiv.org/pdf/1712.03199](https://arxiv.org/pdf/1712.03199)

