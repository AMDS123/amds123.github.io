---
layout: post
title: "Exploiting the potential of unlabeled endoscopic video data with self-supervised learning"
date: 2017-11-27 14:56:38
categories: arXiv_CV
tags: arXiv_CV Adversarial Segmentation GAN CNN Deep_Learning
author: Tobias Ross, David Zimmerer, Anant Vemuri, Fabian Isensee, Sebastian Bodenstedt, Fabian Both, Philip Kessler, Martin Wagner, Beat Müller, Hannes Kenngott, Stefanie Speidel, Klaus Maier-Hein, Lena Maier-Hein
mathjax: true
---

* content
{:toc}

##### Abstract
Purpose: Due to the breakthrough successes of deep learning-based solutions for automatic image annotation, the availability of reference annotations for algorithm training is evolving as one of the major bottlenecks in the field of surgical data science. The purpose of this paper was to investigate the concept of self-supervised learning to address this issue. Methods: Guided by the hypothesis that unlabeled video data contains valuable information about the target domain that can be used to boost the performance of state-of-the-art deep learning algorithms, we show how to reduce the required amount of manual labeling with self-supervised learning. The core of the method is an auxiliary task based on raw endoscopic video data of the target domain that is used to initialize the convolutional neural network (CNN) for the target task. In this paper, we propose the re-colorization of medical images with a generative adversarial network (GAN)-based architecture as auxiliary task. A variant of the method involves a second pretraining step based on labeled data for the target task from a related domain. We validate both variants using medical instrument segmentation as target task. Results: The proposed approach can be used to radically reduce the manual annotation effort involved in training CNNs. Compared to the baseline approach of generating annotated data from scratch, our method decreases the number of labeled images by up to 75% without sacrificing performance. Our method also outperforms alternative methods for CNN pretraining, such as pretraining on publicly available non-medical (COCO) or medical data (MICCAI endoscopic vision challenge 2017) using the target task (here: segmentation). Conclusion: As it makes efficient use of available public and non-public, labeled and unlabeled data, the approach has the potential to become a valuable tool for CNN (pre-)training.

##### Abstract (translated by Google)
目的：由于基于深度学习的自动图像标注解决方案的突破性成果，算法训练参考标注的可用性正在演变为手术数据科学领域的主要瓶颈之一。本文的目的是调查自我监督学习的概念来解决这个问题。方法：在未标记的视频数据包含有关目标域的有价值的信息的假设的指导下，可用于提高最先进的深度学习算法的性能，我们展示了如何减少所需的手工标记数量 - 监督学习。该方法的核心是基于目标域的原始内窥镜视频数据的辅助任务，用于初始化目标任务的卷积神经网络（CNN）。在本文中，我们提出了基于生成对抗网络（GAN）的医学图像重新着色的辅助任务。该方法的变体涉及基于来自相关域的目标任务的标记数据的第二预训练步骤。我们使用医疗器械分割来验证两个变体作为目标任务。结果：所提出的方法可以用来从根本上减少培训CNN所涉及的手动注释工作。与从零开始生成注释数据的基准方法相比，我们的方法在不牺牲性能的情况下将标记图像的数量减少了高达75％。我们的方法也优于CNN预训练的其他方法，例如使用目标任务（这里：分割）对公开可用的非医疗（COCO）或医学数据（MICCAI内窥镜视觉挑战2017）进行预训练。结论：由于它有效地利用了现有的公开和非公开的，有标签和无标签的数据，该方法有可能成为CNN（预）培训的宝贵工具。

##### URL
[https://arxiv.org/abs/1711.09726](https://arxiv.org/abs/1711.09726)

##### PDF
[https://arxiv.org/pdf/1711.09726](https://arxiv.org/pdf/1711.09726)

