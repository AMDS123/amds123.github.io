---
layout: post
title: "Deep Learning for Tactile Understanding From Visual and Haptic Data"
date: 2016-04-12 00:16:21
categories: arXiv_CV
tags: arXiv_CV Knowledge Face Classification Deep_Learning Prediction
author: Yang Gao, Lisa Anne Hendricks, Katherine J. Kuchenbecker, Trevor Darrell
mathjax: true
---

* content
{:toc}

##### Abstract
Robots which interact with the physical world will benefit from a fine-grained tactile understanding of objects and surfaces. Additionally, for certain tasks, robots may need to know the haptic properties of an object before touching it. To enable better tactile understanding for robots, we propose a method of classifying surfaces with haptic adjectives (e.g., compressible or smooth) from both visual and physical interaction data. Humans typically combine visual predictions and feedback from physical interactions to accurately predict haptic properties and interact with the world. Inspired by this cognitive pattern, we propose and explore a purely visual haptic prediction model. Purely visual models enable a robot to "feel" without physical interaction. Furthermore, we demonstrate that using both visual and physical interaction signals together yields more accurate haptic classification. Our models take advantage of recent advances in deep neural networks by employing a unified approach to learning features for physical interaction and visual observations. Even though we employ little domain specific knowledge, our model still achieves better results than methods based on hand-designed features.

##### Abstract (translated by Google)
与物理世界相互作用的机器人将受益于对物体和表面的细微的触觉理解。另外，对于某些任务，机器人可能需要在触摸之前知道对象的触觉属性。为了使机器人更好的触觉理解，我们提出了一种从视觉和物理交互数据中分类具有触觉形容词（例如，可压缩或平滑）的表面的方法。人类通常将视觉预测和来自物理相互作用的反馈结合起来，以准确预测触觉特性并与世界进行交互。受这种认知模式的启发，我们提出并探索一个纯粹的视觉触觉预测模型。纯粹的视觉模型使机器人在没有物理交互的情况下“感觉”。此外，我们证明同时使用视觉和物理交互信号产生更准确的触觉分类。我们的模型利用深度神经网络的最新进展，采用统一的方法来学习物理交互和视觉观察的特征。尽管我们只使用领域特定的知识，但我们的模型仍然比基于手工设计特征的方法取得更好的结果。

##### URL
[https://arxiv.org/abs/1511.06065](https://arxiv.org/abs/1511.06065)

##### PDF
[https://arxiv.org/pdf/1511.06065](https://arxiv.org/pdf/1511.06065)

