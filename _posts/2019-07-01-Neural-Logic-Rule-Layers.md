---
layout: post
title: "Neural Logic Rule Layers"
date: 2019-07-01 15:49:06
categories: arXiv_AI
tags: arXiv_AI Relation
author: Jan Niclas Reimann, Andreas Schwung
mathjax: true
---

* content
{:toc}

##### Abstract
Despite their great success in recent years, deep neural networks (DNN) are mainly black boxes where the results obtained by running through the network are difficult to understand and interpret. Compared to e.g. decision trees or bayesian classifiers, DNN suffer from bad interpretability where we understand by interpretability, that a human can easily derive the relations modeled by the network. A reasonable way to provide interpretability for humans are logical rules. In this paper we propose neural logic rule layers (NLRL) which are able to represent arbitrary logic rules in terms of their conjunctive and disjunctive normal forms. Using various NLRL within one layer and correspondingly stacking various layers, we are able to represent arbitrary complex rules by the resulting neural network architecture. The NLRL are end-to-end trainable allowing to learn logic rules directly from available data sets. Experiments show that NLRL-enhanced neural networks can learn to model arbitrary complex logic and perform arithmetic operation over the input values.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.00878](http://arxiv.org/abs/1907.00878)

##### PDF
[http://arxiv.org/pdf/1907.00878](http://arxiv.org/pdf/1907.00878)

