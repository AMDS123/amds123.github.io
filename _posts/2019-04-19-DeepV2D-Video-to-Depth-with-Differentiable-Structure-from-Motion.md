---
layout: post
title: "DeepV2D: Video to Depth with Differentiable Structure from Motion"
date: 2019-04-19 16:17:04
categories: arXiv_CV
tags: arXiv_CV Inference Deep_Learning
author: Zachary Teed, Jia Deng
mathjax: true
---

* content
{:toc}

##### Abstract
We propose DeepV2D, an end-to-end deep learning architecture for predicting depth from video. DeepV2D combines the representation ability of neural networks with the geometric principles governing image formation. We compose a collection of classical geometric algorithms, which are converted into trainable modules and combined into an end-to-end differentiable architecture. DeepV2D interleaves two stages: camera motion estimation and depth estimation. During inference, motion and depth estimation are alternated and quickly converge to accurate depth. Code is available https://github.com/princeton-vl/DeepV2D.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.04605](http://arxiv.org/abs/1812.04605)

##### PDF
[http://arxiv.org/pdf/1812.04605](http://arxiv.org/pdf/1812.04605)

