---
layout: post
title: "Learning High-Level Planning Symbols from Intrinsically Motivated Experience"
date: 2019-07-18 22:42:35
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning
author: Angelo Oddi, Riccardo Rasconi, Emilio Cartoni, Gabriele Sartor, Gianluca Baldassarre, Vieri Giuliano Santucci
mathjax: true
---

* content
{:toc}

##### Abstract
In symbolic planning systems, the knowledge on the domain is commonly provided by an expert. Recently, an automatic abstraction procedure has been proposed in the literature to create a Planning Domain Definition Language (PDDL) representation, which is the most widely used input format for most off-the-shelf automated planners, starting from `options', a data structure used to represent actions within the hierarchical reinforcement learning framework. We propose an architecture that potentially removes the need for human intervention. In particular, the architecture first acquires options in a fully autonomous fashion on the basis of open-ended learning, then builds a PDDL domain based on symbols and operators that can be used to accomplish user-defined goals through a standard PDDL planner. 
 We start from an implementation of the above mentioned procedure tested on a set of benchmark domains in which a humanoid robot can change the state of some objects through direct interaction with the environment. We then investigate some critical aspects of the information abstraction process that have been observed, and propose an extension that mitigates such criticalities, in particular by analysing the type of classifiers that allow a suitable grounding of symbols.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.08313](http://arxiv.org/abs/1907.08313)

##### PDF
[http://arxiv.org/pdf/1907.08313](http://arxiv.org/pdf/1907.08313)

