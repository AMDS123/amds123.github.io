---
layout: post
title: "Order-Preserving Abstractive Summarization for Spoken Content Based on Connectionist Temporal Classification"
date: 2017-11-16 03:26:35
categories: arXiv_CL
tags: arXiv_CL Summarization Speech_Recognition Classification Recognition
author: Bo-Ru Lu, Frank Shyu, Yun-Nung Chen, Hung-Yi Lee, Lin-shan Lee
mathjax: true
---

* content
{:toc}

##### Abstract
Connectionist temporal classification (CTC) is a powerful approach for sequence-to-sequence learning, and has been popularly used in speech recognition. The central ideas of CTC include adding a label "blank" during training. With this mechanism, CTC eliminates the need of segment alignment, and hence has been applied to various sequence-to-sequence learning problems. In this work, we applied CTC to abstractive summarization for spoken content. The "blank" in this case implies the corresponding input data are less important or noisy; thus it can be ignored. This approach was shown to outperform the existing methods in term of ROUGE scores over Chinese Gigaword and MATBN corpora. This approach also has the nice property that the ordering of words or characters in the input documents can be better preserved in the generated summaries.

##### Abstract (translated by Google)
连接主义时态分类（CTC）是序列 - 序列学习的一种强有力的手段，在语音识别中得到了广泛的应用。反恐委员会的核心思想是在培训期间增加一个“空白”标签。通过这种机制，CTC消除了段对齐的需要，因此已被应用于各种序列到序列的学习问题。在这项工作中，我们将CTC应用于口语内容的抽象概括。在这种情况下的“空白”意味着相应的输入数据不那么重要或嘈杂;因此可以忽略。对于中国Gigaword和MATBN语料库，ROUGE得分表明这种方法优于现有方法。这种方法还具有很好的性质，即在生成的摘要中可以更好地保存输入文档中的单词或字符的排序。

##### URL
[https://arxiv.org/abs/1709.05475](https://arxiv.org/abs/1709.05475)

##### PDF
[https://arxiv.org/pdf/1709.05475](https://arxiv.org/pdf/1709.05475)

