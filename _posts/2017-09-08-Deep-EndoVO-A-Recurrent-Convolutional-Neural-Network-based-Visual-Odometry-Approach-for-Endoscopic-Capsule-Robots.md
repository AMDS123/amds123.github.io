---
layout: post
title: "Deep EndoVO: A Recurrent Convolutional Neural Network based Visual Odometry Approach for Endoscopic Capsule Robots"
date: 2017-09-08 13:47:53
categories: arXiv_CV
tags: arXiv_CV Pose_Estimation CNN Inference RNN Detection
author: Mehmet Turan, Yasin Almalioglu, Helder Araujo, Ender Konukoglu, Metin Sitti
mathjax: true
---

* content
{:toc}

##### Abstract
Ingestible wireless capsule endoscopy is an emerging minimally invasive diagnostic technology for inspection of the GI tract and diagnosis of a wide range of diseases and pathologies. Medical device companies and many research groups have recently made substantial progresses in converting passive capsule endoscopes to active capsule robots, enabling more accurate, precise, and intuitive detection of the location and size of the diseased areas. Since a reliable real time pose estimation functionality is crucial for actively controlled endoscopic capsule robots, in this study, we propose a monocular visual odometry (VO) method for endoscopic capsule robot operations. Our method lies on the application of the deep Recurrent Convolutional Neural Networks (RCNNs) for the visual odometry task, where Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are used for the feature extraction and inference of dynamics across the frames, respectively. Detailed analyses and evaluations made on a real pig stomach dataset proves that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories.

##### Abstract (translated by Google)
可摄入无线胶囊内窥镜是一种新兴的微创诊断技术，用于检查胃肠道并诊断各种疾病和病变。医疗器械公司和许多研究小组最近在将被动式胶囊内窥镜转换为主动式胶囊机器人方面取得了实质性的进展，能够更加准确，精确和直观地检测病变部位的位置和大小。由于可靠的实时姿态估计功能对于主动控制的内窥镜胶囊机器人是至关重要的，因此在本研究中，我们提出了用于内窥镜胶囊机器人操作的单眼视觉测距（VO）方法。我们的方法是在视觉测距任务中使用深度递归卷积神经网络（RCNN），其中卷积神经网络（CNN）和递归神经网络（RNN）被用于跨帧的动态特征提取和推断，分别。在一个真实的猪胃数据集上进行的详细分析和评估证明，我们的系统为不同类型的内窥镜胶囊机器人轨迹实现了高平移和旋转精度。

##### URL
[https://arxiv.org/abs/1708.06822](https://arxiv.org/abs/1708.06822)

##### PDF
[https://arxiv.org/pdf/1708.06822](https://arxiv.org/pdf/1708.06822)

