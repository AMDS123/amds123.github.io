---
layout: post
title: "VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions"
date: 2018-03-20 14:50:03
categories: arXiv_CV
tags: arXiv_CV QA Caption Prediction Quantitative VQA
author: Qing Li, Qingyi Tao, Shafiq Joty, Jianfei Cai, Jiebo Luo
mathjax: true
---

* content
{:toc}

##### Abstract
Most existing works in visual question answering (VQA) are dedicated to improving the accuracy of predicted answers, while disregarding the explanations. We argue that the explanation for an answer is of the same or even more importance compared with the answer itself, since it makes the question and answering process more understandable and traceable. To this end, we propose a new task of VQA-E (VQA with Explanation), where the computational models are required to generate an explanation with the predicted answer. We first construct a new dataset, and then frame the VQA-E problem in a multi-task learning architecture. Our VQA-E dataset is automatically derived from the VQA v2 dataset by intelligently exploiting the available captions. We have conducted a user study to validate the quality of explanations synthesized by our method. We quantitatively show that the additional supervision from explanations can not only produce insightful textual sentences to justify the answers, but also improve the performance of answer prediction. Our model outperforms the state-of-the-art methods by a clear margin on the VQA v2 dataset.

##### Abstract (translated by Google)
视觉问答（VQA）中大多数现有的作品致力于提高预测答案的准确性，同时忽视解释。我们认为，答案的解释与答案本身相比甚至更重要，因为它使问题和答案过程更易于理解和追溯。为此，我们提出了VQA-E（带解释的VQA）的新任务，其中计算模型需要用预测的答案产生解释。我们首先构造一个新的数据集，然后在多任务学习架构中构造VQA-E问题。我们的VQA-E数据集通过智能地利用可用标题自动从VQA v2数据集中导出。我们进行了一项用户研究，以验证我们方法合成的解释的质量。我们从数量上表明，解释的额外监督不仅可以产生有洞察力的文本句子来证明答案的正确性，还可以提高答案预测的性能。我们的模型在VQA v2数据集上的表现优于最先进的方法。

##### URL
[http://arxiv.org/abs/1803.07464](http://arxiv.org/abs/1803.07464)

##### PDF
[http://arxiv.org/pdf/1803.07464](http://arxiv.org/pdf/1803.07464)

