---
layout: post
title: "VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions"
date: 2018-03-20 14:50:03
categories: arXiv_CV
tags: arXiv_CV QA Caption Prediction Quantitative VQA
author: Qing Li, Qingyi Tao, Shafiq Joty, Jianfei Cai, Jiebo Luo
mathjax: true
---

* content
{:toc}

##### Abstract
Most existing works in visual question answering (VQA) are dedicated to improving the accuracy of predicted answers, while disregarding the explanations. We argue that the explanation for an answer is of the same or even more importance compared with the answer itself, since it makes the question and answering process more understandable and traceable. To this end, we propose a new task of VQA-E (VQA with Explanation), where the computational models are required to generate an explanation with the predicted answer. We first construct a new dataset, and then frame the VQA-E problem in a multi-task learning architecture. Our VQA-E dataset is automatically derived from the VQA v2 dataset by intelligently exploiting the available captions. We have conducted a user study to validate the quality of explanations synthesized by our method. We quantitatively show that the additional supervision from explanations can not only produce insightful textual sentences to justify the answers, but also improve the performance of answer prediction. Our model outperforms the state-of-the-art methods by a clear margin on the VQA v2 dataset.

##### Abstract (translated by Google)
大多数现有的视觉问答（VQA）工作都致力于提高预测答案的准确性，同时忽略了解释。我们认为答案的解释与答案本身相比具有相同甚至更重要的意义，因为它使问题和答案过程更易理解和可追溯。为此，我们提出了VQA-E（带解释的VQA）的新任务，其中需要计算模型来生成具有预测答案的解释。我们首先构建一个新的数据集，然后在多任务学习架构中构建VQA-E问题。我们的VQA-E数据集通过智能地利用可用字幕自动从VQA v2数据集派生。我们进行了一项用户研究，以验证我们的方法合成的解释的质量。我们定量地表明，来自解释的额外监督不仅可以产生有洞察力的文本句子来证明答案的合理性，而且还可以提高答案预测的性能。我们的模型在VQA v2数据集上的优势明显优于最先进的方法。

##### URL
[https://arxiv.org/abs/1803.07464](https://arxiv.org/abs/1803.07464)

##### PDF
[https://arxiv.org/pdf/1803.07464](https://arxiv.org/pdf/1803.07464)

