---
layout: post
title: "Smart Library: Identifying Books in a Library using Richly Supervised Deep Scene Text Reading"
date: 2016-11-22 16:12:03
categories: arXiv_CV
tags: arXiv_CV Knowledge CNN RNN Detection Recognition
author: Xiao Yang, Dafang He, Wenyi Huang, Zihan Zhou, Alex Ororbia, Dan Kifer, C. Lee Giles
mathjax: true
---

* content
{:toc}

##### Abstract
Physical library collections are valuable and long standing resources for knowledge and learning. However, managing books in a large bookshelf and finding books on it often leads to tedious manual work, especially for large book collections where books might be missing or misplaced. Recently, deep neural models, such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) have achieved great success for scene text detection and recognition. Motivated by these recent successes, we aim to investigate their viability in facilitating book management, a task that introduces further challenges including large amounts of cluttered scene text, distortion, and varied lighting conditions. In this paper, we present a library inventory building and retrieval system based on scene text reading methods. We specifically design our scene text recognition model using rich supervision to accelerate training and achieve state-of-the-art performance on several benchmark datasets. Our proposed system has the potential to greatly reduce the amount of human labor required in managing book inventories as well as the space needed to store book information.

##### Abstract (translated by Google)
物理图书馆收藏是知识和学习的宝贵和长期的资源。然而，在大型书架上管理书籍并在书本上找到书籍往往会导致繁琐的手工工作，特别是对于可能丢失或放错书籍的大型书籍收藏。最近，深度神经网络如卷积神经网络（CNN）和递归神经网络（RNN）在场景文本检测和识别方面取得了巨大的成功。受到最近取得的成功的启发，我们的目标是调查他们在促进图书管理方面的可行性，这一任务将引入更多挑战，包括大量混乱的场景文本，失真以及各种各样的照明条件。在本文中，我们提出了一个基于场景文本阅读方法的图书馆库存建设和检索系统。我们特别使用丰富的监控设计我们的场景文本识别模型，以加速训练，并在多个基准数据集上实现最先进的性能。我们提出的系统有可能大大减少管理书籍库存所需的人力和存储书籍信息所需的空间。

##### URL
[https://arxiv.org/abs/1611.07385](https://arxiv.org/abs/1611.07385)

##### PDF
[https://arxiv.org/pdf/1611.07385](https://arxiv.org/pdf/1611.07385)

