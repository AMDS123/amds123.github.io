---
layout: post
title: "Automatic Rule Extraction from Long Short Term Memory Networks"
date: 2017-02-24 22:20:25
categories: arXiv_CV
tags: arXiv_CV Sentiment Tracking RNN Deep_Learning Quantitative Memory_Networks
author: W. James Murdoch, Arthur Szlam
mathjax: true
---

* content
{:toc}

##### Abstract
Although deep learning models have proven effective at solving problems in natural language processing, the mechanism by which they come to their conclusions is often unclear. As a result, these models are generally treated as black boxes, yielding no insight of the underlying learned patterns. In this paper we consider Long Short Term Memory networks (LSTMs) and demonstrate a new approach for tracking the importance of a given input to the LSTM for a given output. By identifying consistently important patterns of words, we are able to distill state of the art LSTMs on sentiment analysis and question answering into a set of representative phrases. This representation is then quantitatively validated by using the extracted phrases to construct a simple, rule-based classifier which approximates the output of the LSTM.

##### Abstract (translated by Google)
虽然深度学习模式在解决自然语言处理中的问题方面已被证明是有效的，但是他们得出结论的机制往往不清楚。结果，这些模型通常被当作黑匣子，没有深入了解底层的学习模式。在本文中，我们考虑长时间记忆网络（LSTMs），并展示了一种新的方法来跟踪给定输出的给定输入对LSTM的重要性。通过识别一贯重要的单词模式，我们能够提炼出情感分析和问题解答中的最先进的LSTM，并将其归为一组具有代表性的短语。然后通过使用提取的短语来构造一个简单的，基于规则的分类器来近似LSTM的输出，从而对这种表示进行定量验证。

##### URL
[https://arxiv.org/abs/1702.02540](https://arxiv.org/abs/1702.02540)

##### PDF
[https://arxiv.org/pdf/1702.02540](https://arxiv.org/pdf/1702.02540)

