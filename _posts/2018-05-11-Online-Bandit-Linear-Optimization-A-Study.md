---
layout: post
title: "Online Bandit Linear Optimization: A Study"
date: 2018-05-11 18:12:19
categories: arXiv_AI
tags: arXiv_AI Regularization Optimization
author: Vikram Mullachery, Samarth Tiwari
mathjax: true
---

* content
{:toc}

##### Abstract
This article introduces the concepts around Online Bandit Linear Optimization and explores an efficient setup called SCRiBLe (Self-Concordant Regularization in Bandit Learning) created by Abernethy et. al.\cite{abernethy}. The SCRiBLe setup and algorithm yield a $O(\sqrt{T})$ regret bound and polynomial run time complexity bound on the dimension of the input space. In this article we build up to the bandit linear optimization case and study SCRiBLe.

##### Abstract (translated by Google)
本文介绍了围绕在线Bandit线性优化的概念，并探讨了由Abernethy等人创建的称为SCRiBLe（Bandit Learning的自协调正则化）的有效设置。人\ {举}阿伯内西。 SCRiBLe设置和算法产生一个$ O（\ sqrt {T}）$后悔界限和多项式运行时间复杂度约束在输入空间的维度。在本文中，我们构建了土匪线性优化案例并研究了SCRiBLe。

##### URL
[http://arxiv.org/abs/1805.05773](http://arxiv.org/abs/1805.05773)

##### PDF
[http://arxiv.org/pdf/1805.05773](http://arxiv.org/pdf/1805.05773)

