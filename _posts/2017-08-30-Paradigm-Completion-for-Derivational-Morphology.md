---
layout: post
title: "Paradigm Completion for Derivational Morphology"
date: 2017-08-30 07:55:57
categories: arXiv_CL
tags: arXiv_CL
author: Ryan Cotterell, Ekaterina Vylomova, Huda Khayrallah, Christo Kirov, David Yarowsky
mathjax: true
---

* content
{:toc}

##### Abstract
The generation of complex derived word forms has been an overlooked problem in NLP; we fill this gap by applying neural sequence-to-sequence models to the task. We overview the theoretical motivation for a paradigmatic treatment of derivational morphology, and introduce the task of derivational paradigm completion as a parallel to inflectional paradigm completion. State-of-the-art neural models, adapted from the inflection task, are able to learn a range of derivation patterns, and outperform a non-neural baseline by 16.4%. However, due to semantic, historical, and lexical considerations involved in derivational morphology, future work will be needed to achieve performance parity with inflection-generating systems.

##### Abstract (translated by Google)
在NLP中，复杂派生词形式的产生一直是一个被忽视的问题。我们通过将神经序列 - 序列模型应用于任务来填补这个空白。我们概述了对派生形态进行范式处理的理论动机，并将派生范式完成的任务引入到屈折范式完成的平行中。从变形任务改编而成的最新神经模型能够学习一系列的推导模式，并且比非神经基线好16.4％。然而，由于衍生形态学中涉及的语义，历史和词汇考虑，未来的工作将需要实现与拐点生成系统的性能平衡。

##### URL
[https://arxiv.org/abs/1708.09151](https://arxiv.org/abs/1708.09151)

##### PDF
[https://arxiv.org/pdf/1708.09151](https://arxiv.org/pdf/1708.09151)

