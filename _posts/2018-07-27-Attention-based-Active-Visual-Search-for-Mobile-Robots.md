---
layout: post
title: "Attention-based Active Visual Search for Mobile Robots"
date: 2018-07-27 17:48:02
categories: arXiv_RO
tags: arXiv_RO Attention
author: Amir Rasouli, Pablo Lanillos, Gordon Cheng, John K. Tsotsos
mathjax: true
---

* content
{:toc}

##### Abstract
We present an active visual search model for finding objects in unknown environments. The proposed algorithm guides the robot towards the sought object using the relevant stimuli provided by the visual sensors. Existing search strategies are either purely reactive or use simplified sensor models that do not exploit all the visual information available. In this paper, we propose a new model that actively extracts visual information via visual attention techniques and, in conjunction with a non-myopic decision-making algorithm, leads the robot to search more relevant areas of the environment. The attention module couples both top-down and bottom-up attention models enabling the robot to search regions with higher importance first. The proposed algorithm is evaluated on a mobile robot platform in a 3D simulated environment. The results indicate that the use of visual attention significantly improves search, but the degree of improvement depends on the nature of the task and the complexity of the environment. In our experiments, we found that performance enhancements of up to 42\% in structured and 38\% in highly unstructured cluttered environments can be achieved using visual attention mechanisms.

##### Abstract (translated by Google)
我们提出了一种主动视觉搜索模型，用于在未知环境中查找对象所提出的算法使用由视觉传感器提供的相关刺激来引导机器人朝向所寻找的物体。现有的搜索策略要么是纯粹的反应性的，要么是使用不利用所有可用视觉信息的简化传感器模型。在本文中，我们提出了一种新模型，该模型通过视觉注意技术主动提取视觉信息，并结合非近视决策算法，引导机器人搜索更相关的环境区域。注意模块将自上而下和自下而上的注意力模型联系起来，使机器人能够首先搜索具有更高重要性的区域。所提出的算法在3D模拟环境中的移动机器人平台上进行评估。结果表明，视觉注意的使用显着改善了搜索，但改进的程度取决于任务的性质和环境的复杂性。在我们的实验中，我们发现使用视觉注意机制可以在高度非结构化的杂乱环境中实现高达42％的结构化和38％的性能增强。

##### URL
[https://arxiv.org/abs/1807.10744](https://arxiv.org/abs/1807.10744)

##### PDF
[https://arxiv.org/pdf/1807.10744](https://arxiv.org/pdf/1807.10744)

