---
layout: post
title: "Guided Feature Transformation : A Neural Language Grounding Module for Embodied Agents"
date: 2018-09-04 18:16:40
categories: arXiv_AI
tags: arXiv_AI Sparse Reinforcement_Learning Embedding
author: Haonan Yu, Xiaochen Lian, Haichao Zhang, Wei Xu
mathjax: true
---

* content
{:toc}

##### Abstract
Recently there has been a rising interest in training agents, embodied in virtual environments, to perform language-directed tasks by deep reinforcement learning. In this paper, we propose a simple but effective neural language grounding module for embodied agents that can be trained end to end from scratch taking raw pixels, unstructured linguistic commands, and sparse rewards as the inputs. We model the language grounding process as a language-guided transformation of visual features, where latent sentence embeddings are used as the transformation matrices. In several language-directed navigation tasks that feature challenging partial observability and require simple reasoning, our module significantly outperforms the state of the art. We also release XWorld3D, an easy-to-customize 3D environment that can potentially be modified to evaluate a variety of embodied agents.

##### Abstract (translated by Google)
最近，人们越来越关注在虚拟环境中体现的培训代理，通过深度强化学习来执行语言指导的任务。在本文中，我们提出了一个简单但有效的神经语言接地模块，用于体现代理，可以从头开始从头开始训练，将原始像素，非结构化语言命令和稀疏奖励作为输入。我们将语言基础过程建模为语言引导的视觉特征转换，其中潜在句子嵌入被用作转换矩阵。在几个语言导向的导航任务中，具有挑战性的部分可观察性并需要简单的推理，我们的模块明显优于现有技术水平。我们还发布了XWorld3D，这是一个易于定制的3D环境，可以进行修改以评估各种具体的代理。

##### URL
[http://arxiv.org/abs/1805.08329](http://arxiv.org/abs/1805.08329)

##### PDF
[http://arxiv.org/pdf/1805.08329](http://arxiv.org/pdf/1805.08329)

