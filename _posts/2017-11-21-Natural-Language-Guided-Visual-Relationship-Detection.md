---
layout: post
title: "Natural Language Guided Visual Relationship Detection"
date: 2017-11-21 10:51:31
categories: arXiv_CV
tags: arXiv_CV Classification Detection Relation
author: Wentong Liao, Lin Shuai, Bodo Rosenhahn, Michael Ying Yang
mathjax: true
---

* content
{:toc}

##### Abstract
Reasoning about the relationships between object pairs in images is a crucial task for holistic scene understanding. Most of the existing works treat this task as a pure visual classification task: each type of relationship or phrase is classified as a relation category based on the extracted visual features. However, each kind of relationships has a wide variety of object combination and each pair of objects has diverse interactions. Obtaining sufficient training samples for all possible relationship categories is difficult and expensive. In this work, we propose a natural language guided framework to tackle this problem. We propose to use a generic bi-directional recurrent neural network to predict the semantic connection between the participating objects in the relationship from the aspect of natural language. The proposed simple method achieves the state-of-the-art on the Visual Relationship Detection (VRD) and Visual Genome datasets, especially when predicting unseen relationships (e.g. recall improved from 76.42% to 89.79% on VRD zero-shot testing set).

##### Abstract (translated by Google)
推理图像中的对象之间的关系是整体场景理解的关键任务。现有的大部分作品都把这个任务视为一个纯粹的视觉分类任务：根据所提取的视觉特征将每种关系或短语分类为关系类别。然而，每一种关系都有各种各样的对象组合，每一对对象都有不同的相互作用。为所有可能的关系类别获得足够的训练样本是困难且昂贵的。在这项工作中，我们提出了一个自然语言引导框架来解决这个问题。我们建议使用通用的双向递归神经网络从自然语言方面预测参与对象之间的关系。所提出的简单方法实现了视觉关系检测（VRD）和视觉基因组数据集的最新技术，特别是当预测不可见的关系时（例如，在VRD零射击测试集中召回率从76.42％提高到89.79％）。

##### URL
[https://arxiv.org/abs/1711.06032](https://arxiv.org/abs/1711.06032)

##### PDF
[https://arxiv.org/pdf/1711.06032](https://arxiv.org/pdf/1711.06032)

