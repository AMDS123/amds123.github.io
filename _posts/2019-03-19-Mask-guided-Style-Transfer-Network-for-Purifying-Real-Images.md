---
layout: post
title: "Mask-guided Style Transfer Network for Purifying Real Images"
date: 2019-03-19 03:54:55
categories: arXiv_CV
tags: arXiv_CV Segmentation Attention Style_Transfer Quantitative
author: Tongtong Zhao, Yuxiao Yan, Jinjia Peng, Huibing Wang, Xianping Fu
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, the progress of learning-by-synthesis has proposed a training model for synthetic images, which can effectively reduce the cost of human and material resources. However, due to the different distribution of synthetic images compared with real images, the desired performance cannot be achieved. To solve this problem, the previous method learned a model to improve the realism of the synthetic images. Different from the previous methods, this paper try to purify real image by extracting discriminative and robust features to convert outdoor real images to indoor synthetic images. In this paper, we first introduce the segmentation masks to construct RGB-mask pairs as inputs, then we design a mask-guided style transfer network to learn style features separately from the attention and bkgd(background) regions and learn content features from full and attention region. Moreover, we propose a novel region-level task-guided loss to restrain the features learnt from style and content. Experiments were performed using mixed studies (qualitative and quantitative) methods to demonstrate the possibility of purifying real images in complex directions. We evaluate the proposed method on various public datasets, including LPW, COCO and MPIIGaze. Experimental results show that the proposed method is effective and achieves the state-of-the-art results.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.08152](http://arxiv.org/abs/1903.08152)

##### PDF
[http://arxiv.org/pdf/1903.08152](http://arxiv.org/pdf/1903.08152)

