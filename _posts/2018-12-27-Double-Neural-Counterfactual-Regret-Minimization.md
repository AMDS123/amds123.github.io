---
layout: post
title: "Double Neural Counterfactual Regret Minimization"
date: 2018-12-27 03:31:33
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Hui Li, Kailiang Hu, Zhibang Ge, Tao Jiang, Yuan Qi, Le Song
mathjax: true
---

* content
{:toc}

##### Abstract
Counterfactual Regret Minimization (CRF) is a fundamental and effective technique for solving Imperfect Information Games (IIG). However, the original CRF algorithm only works for discrete state and action spaces, and the resulting strategy is maintained as a tabular representation. Such tabular representation limits the method from being directly applied to large games and continuing to improve from a poor strategy profile. In this paper, we propose a double neural representation for the imperfect information games, where one neural network represents the cumulative regret, and the other represents the average strategy. Furthermore, we adopt the counterfactual regret minimization algorithm to optimize this double neural representation. To make neural learning efficient, we also developed several novel techniques including a robust sampling method, mini-batch Monte Carlo Counterfactual Regret Minimization (MCCFR) and Monte Carlo Counterfactual Regret Minimization Plus (MCCFR+) which may be of independent interests. Experimentally, we demonstrate that the proposed double neural algorithm converges significantly better than the reinforcement learning counterpart.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.10607](http://arxiv.org/abs/1812.10607)

##### PDF
[http://arxiv.org/pdf/1812.10607](http://arxiv.org/pdf/1812.10607)

