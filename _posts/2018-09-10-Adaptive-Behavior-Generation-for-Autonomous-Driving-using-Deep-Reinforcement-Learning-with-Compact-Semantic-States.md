---
layout: post
title: "Adaptive Behavior Generation for Autonomous Driving using Deep Reinforcement Learning with Compact Semantic States"
date: 2018-09-10 09:35:27
categories: arXiv_RO
tags: arXiv_RO Knowledge Reinforcement_Learning Relation
author: Peter Wolf, Karl Kurzer, Tobias Wingert, Florian Kuhnt, J. Marius Z&#xf6;llner
mathjax: true
---

* content
{:toc}

##### Abstract
Making the right decision in traffic is a challenging task that is highly dependent on individual preferences as well as the surrounding environment. Therefore it is hard to model solely based on expert knowledge. In this work we use Deep Reinforcement Learning to learn maneuver decisions based on a compact semantic state representation. This ensures a consistent model of the environment across scenarios as well as a behavior adaptation function, enabling on-line changes of desired behaviors without re-training. The input for the neural network is a simulated object list similar to that of Radar or Lidar sensors, superimposed by a relational semantic scene description. The state as well as the reward are extended by a behavior adaptation function and a parameterization respectively. With little expert knowledge and a set of mid-level actions, it can be seen that the agent is capable to adhere to traffic rules and learns to drive safely in a variety of situations.

##### Abstract (translated by Google)
在交通中做出正确的决定是一项具有挑战性的任务，高度依赖于个人偏好以及周围环境。因此，很难仅根据专业知识进行建模。在这项工作中，我们使用Deep Reinforcement Learning来学习基于紧凑语义状态表示的机动决策。这确保了跨场景的环境模型以及行为适应功能，无需重新训练即可实现所需行为的在线更改。神经网络的输入是类似于雷达或激光雷达传感器的模拟对象列表，由关系语义场景描述叠加。状态以及奖励分别通过行为适应功能和参数化来扩展。由于缺乏专业知识和一系列中级操作，可以看出代理能够遵守交通规则并学会在各种情况下安全驾驶。

##### URL
[http://arxiv.org/abs/1809.03214](http://arxiv.org/abs/1809.03214)

##### PDF
[http://arxiv.org/pdf/1809.03214](http://arxiv.org/pdf/1809.03214)

