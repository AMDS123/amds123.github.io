---
layout: post
title: "Sampling Matters in Deep Embedding Learning"
date: 2017-06-23 05:14:55
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Face Embedding CNN
author: Chao-Yuan Wu, R. Manmatha, Alexander J. Smola, Philipp Krähenbühl
mathjax: true
---

* content
{:toc}

##### Abstract
Deep embeddings answer one simple question: How similar are two images? Learning these embeddings is the bedrock of verification, zero-shot learning, and visual search. The most prominent approaches optimize a deep convolutional network with a suitable loss function, such as contrastive loss or triplet loss. While a rich line of work focuses solely on the loss functions, we show in this paper that selecting training examples plays an equally important role. We propose distance weighted sampling, which selects more informative and stable examples than traditional approaches. In addition, we show that a simple margin based loss is sufficient to outperform all other loss functions. We evaluate our approach on the Stanford Online Products, CAR196, and the CUB200-2011 datasets for image retrieval and clustering, and on the LFW dataset for face verification. Our method achieves state-of-the-art performance on all of them.

##### Abstract (translated by Google)
深度嵌入回答一个简单的问题：两幅图像有多相似？学习这些嵌入是验证，零点学习和视觉搜索的基础。最显着的方法是优化具有合适损失函数的深度卷积网络，如对比损失或三重损失。虽然丰富的工作重点仅仅集中在损失函数上，但我们在本文中展示了选择培训实例同样重要的作用。我们提出距离加权抽样，比传统的方法选择更多的信息和稳定的例子。此外，我们表明，一个简单的边际损失足以超越所有其他损失函数。我们评估我们的方法在斯坦福线上产品，CAR196和CUB200-2011数据集的图像检索和聚类，并在LFW数据集面部验证。我们的方法在所有这些方面达到了最先进的性能。

##### URL
[https://arxiv.org/abs/1706.07567](https://arxiv.org/abs/1706.07567)

##### PDF
[https://arxiv.org/pdf/1706.07567](https://arxiv.org/pdf/1706.07567)

