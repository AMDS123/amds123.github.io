---
layout: post
title: "Simplified End-to-End MMI Training and Voting for ASR"
date: 2017-07-16 15:12:39
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition Classification Language_Model Prediction Gradient_Descent Recognition
author: Lior Fritz, David Burshtein
mathjax: true
---

* content
{:toc}

##### Abstract
A simplified speech recognition system that uses the maximum mutual information (MMI) criterion is considered. End-to-end training using gradient descent is suggested, similarly to the training of connectionist temporal classification (CTC). We use an MMI criterion with a simple language model in the training stage, and a standard HMM decoder. Our method compares favorably to CTC in terms of performance, robustness, decoding time, disk footprint and quality of alignments. The good alignments enable the use of a straightforward ensemble method, obtained by simply averaging the predictions of several neural network models, that were trained separately end-to-end. The ensemble method yields a considerable reduction in the word error rate.

##### Abstract (translated by Google)
考虑使用最大互信息（MMI）标准的简化语音识别系统。建议使用梯度下降的端对端训练，类似于连接主义时间分类（CTC）的训练。我们在训练阶段使用简单语言模型的MMI准则，以及标准的HMM解码器。我们的方法在性能，健壮性，解码时间，磁盘占用空间和路线质量方面与CTC相比毫不逊色。良好的对齐使得能够使用直接的集合方法，通过对几个神经网络模型的预测进行简单的平均而得到，这些模型是端对端地分别训练的。整体方法可以显着减少字错误率。

##### URL
[https://arxiv.org/abs/1703.10356](https://arxiv.org/abs/1703.10356)

##### PDF
[https://arxiv.org/pdf/1703.10356](https://arxiv.org/pdf/1703.10356)

