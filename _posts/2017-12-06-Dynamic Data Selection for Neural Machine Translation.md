---
layout: post
title: 'Dynamic Data Selection for Neural Machine Translation'
date: 2017-12-06 02:59:39
categories: arXiv_CL
tags: arXiv_CL
author: Marlies van der Wees, Arianna Bisazza, Christof Monz
---

* content
{:toc}

##### Abstract
Intelligent selection of training data has proven a successful technique to simultaneously increase training efficiency and translation performance for phrase-based machine translation (PBMT). With the recent increase in popularity of neural machine translation (NMT), we explore in this paper to what extent and how NMT can also benefit from data selection. While state-of-the-art data selection (Axelrod et al., 2011) consistently performs well for PBMT, we show that gains are substantially lower for NMT. Next, we introduce dynamic data selection for NMT, a method in which we vary the selected subset of training data between different training epochs. Our experiments show that the best results are achieved when applying a technique we call gradual fine-tuning, with improvements up to +2.6 BLEU over the original data selection approach and up to +3.1 BLEU over a general baseline.

##### Abstract (translated by Google)
智能选择训练数据已被证明是一种成功的技术，可以同时提高基于短语机器翻译（PBMT）的训练效率和翻译性能。随着近年来神经机器翻译（NMT）的普及，我们在本文中探索NMT在多大程度上以及如何从数据选择中受益。尽管最先进的数据选择（Axelrod et al。，2011）对PBMT始终表现良好，但我们表明NMT的收益大大降低。接下来，我们介绍NMT的动态数据选择，这是一种在不同训练时期之间改变所选择的训练数据子集的方法。我们的实验表明，采用我们所说的渐进式微调技术可以获得最好的结果，比原始数据选择方法提高了+ 2.6BLEU，在一般基线上提高了+ 3.1BLEU。

##### URL
[https://arxiv.org/abs/1708.00712](https://arxiv.org/abs/1708.00712)

