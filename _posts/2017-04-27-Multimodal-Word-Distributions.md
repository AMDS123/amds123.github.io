---
layout: post
title: "Multimodal Word Distributions"
date: 2017-04-27 03:59:54
categories: arXiv_CL
tags: arXiv_CL Embedding Language_Model
author: Ben Athiwaratkun, Andrew Gordon Wilson
mathjax: true
---

* content
{:toc}

##### Abstract
Word embeddings provide point representations of words containing useful semantic information. We introduce multimodal word distributions formed from Gaussian mixtures, for multiple word meanings, entailment, and rich uncertainty information. To learn these distributions, we propose an energy-based max-margin objective. We show that the resulting approach captures uniquely expressive semantic information, and outperforms alternatives, such as word2vec skip-grams, and Gaussian embeddings, on benchmark datasets such as word similarity and entailment.

##### Abstract (translated by Google)
单词嵌入提供包含有用语义信息的单词的点表示。我们引入由高斯混合形成的多模态词分布，用于多个词的含义，包含和丰富的不确定性信息。要了解这些分布，我们提出一个基于能量的最大利润率目标。我们表明，由此产生的方法捕捉到独特的表达语义信息，并且在诸如词相似性和包含的基准数据集上优于诸如word2vec skip-grams和高斯嵌入之类的替代方案。

##### URL
[https://arxiv.org/abs/1704.08424](https://arxiv.org/abs/1704.08424)

##### PDF
[https://arxiv.org/pdf/1704.08424](https://arxiv.org/pdf/1704.08424)

