---
layout: post
title: "RNNbow: Visualizing Learning via Backpropagation Gradients in Recurrent Neural Networks"
date: 2019-07-29 17:36:29
categories: arXiv_AI
tags: arXiv_AI RNN
author: Dylan Cashman, Genevieve Patterson, Abigail Mosca, Nathan Watts, Shannon Robinson, Remco Chang
mathjax: true
---

* content
{:toc}

##### Abstract
We present RNNbow, an interactive tool for visualizing the gradient flow during backpropagation training in recurrent neural networks. RNNbow is a web application that displays the relative gradient contributions from Recurrent Neural Network (RNN) cells in a neighborhood of an element of a sequence. We describe the calculation of backpropagation through time (BPTT) that keeps track of itemized gradients, or gradient contributions from one element of a sequence to previous elements of a sequence. By visualizing the gradient, as opposed to activations, RNNbow offers insight into how the network is learning. We use it to explore the learning of an RNN that is trained to generate code in the C programming language. We show how it uncovers insights into the vanishing gradient as well as the evolution of training as the RNN works its way through a corpus.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.12545](http://arxiv.org/abs/1907.12545)

##### PDF
[http://arxiv.org/pdf/1907.12545](http://arxiv.org/pdf/1907.12545)

