---
layout: post
title: "Learning Recurrent Span Representations for Extractive Question Answering"
date: 2017-03-17 18:11:12
categories: arXiv_CL
tags: arXiv_CL Prediction
author: Kenton Lee, Shimi Salant, Tom Kwiatkowski, Ankur Parikh, Dipanjan Das, Jonathan Berant
mathjax: true
---

* content
{:toc}

##### Abstract
The reading comprehension task, that asks questions about a given evidence document, is a central problem in natural language understanding. Recent formulations of this task have typically focused on answer selection from a set of candidates pre-defined manually or through the use of an external NLP pipeline. However, Rajpurkar et al. (2016) recently released the SQuAD dataset in which the answers can be arbitrary strings from the supplied text. In this paper, we focus on this answer extraction task, presenting a novel model architecture that efficiently builds fixed length representations of all spans in the evidence document with a recurrent network. We show that scoring explicit span representations significantly improves performance over other approaches that factor the prediction into separate predictions about words or start and end markers. Our approach improves upon the best published results of Wang & Jiang (2016) by 5% and decreases the error of Rajpurkar et al.'s baseline by > 50%.

##### Abstract (translated by Google)
阅读理解任务，提出一个给定的证据文件的问题，是自然语言理解的核心问题。这个任务的最近的表述通常集中于从手动预定义的候选集合或通过使用外部NLP流水线的答案选择。然而，Rajpurkar等。 （2016）最近发布了SQuAD数据集，其中答案可以是来自所提供文本的任意字符串。在本文中，我们专注于这个答案提取任务，提出了一个新的模型架构，有效地建立在循环网络的证据文件中的所有跨度的定长表示。我们表明，得分显式跨度表示显着提高了性能超过其他方法，将预测分为单词预测或开始和结束标记。我们的方法将Wang＆Jiang（2016）的最佳公布结果提高了5％，并将Rajpurkar等人的基线误差降低了> 50％。

##### URL
[https://arxiv.org/abs/1611.01436](https://arxiv.org/abs/1611.01436)

##### PDF
[https://arxiv.org/pdf/1611.01436](https://arxiv.org/pdf/1611.01436)

