---
layout: post
title: "A general metric for identifying adversarial images"
date: 2018-07-26 19:29:37
categories: arXiv_CV
tags: arXiv_CV Adversarial Detection
author: Siddharth Krishna Kumar
mathjax: true
---

* content
{:toc}

##### Abstract
It is well known that a determined adversary can fool a neural network by making imperceptible adversarial perturbations to an image. Recent studies have shown that these perturbations can be detected even without information about the neural network if the strategy taken by the adversary is known beforehand. Unfortunately, these studies suffer from the generalization limitation -- the detection method has to be recalibrated every time the adversary changes his strategy. In this study, we attempt to overcome the generalization limitation by deriving a metric which reliably identifies adversarial images even when the approach taken by the adversary is unknown. Our metric leverages key differences between the spectra of clean and adversarial images when an image is treated as a matrix. Our metric is able to detect adversarial images across different datasets and attack strategies without any additional re-calibration. In addition, our approach provides geometric insights into several unanswered questions about adversarial perturbations.

##### Abstract (translated by Google)
众所周知，确定的对手可以通过对图像产生难以察觉的对抗性扰动来欺骗神经网络。最近的研究表明，如果事先知道对手采取的策略，即使没有关于神经网络的信息，也可以检测到这些扰动。不幸的是，这些研究受到泛化限制的影响 - 每当对手改变其策略时，必须重新校准检测方法。在本研究中，我们试图通过推导一个可靠地识别对抗图像的度量来克服泛化限制，即使对手采取的方法未知。当图像被视为矩阵时，我们的度量标准利用了干净和对抗图像的光谱之间的关键差异。我们的指标能够检测不同数据集和攻击策略的对抗图像，无需任何额外的重新校准。此外，我们的方法提供了几个关于对抗性扰动的未解答问题的几何见解。

##### URL
[http://arxiv.org/abs/1807.10335](http://arxiv.org/abs/1807.10335)

##### PDF
[http://arxiv.org/pdf/1807.10335](http://arxiv.org/pdf/1807.10335)

