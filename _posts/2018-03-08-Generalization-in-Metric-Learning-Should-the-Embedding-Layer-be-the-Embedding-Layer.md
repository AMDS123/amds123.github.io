---
layout: post
title: "Generalization in Metric Learning: Should the Embedding Layer be the Embedding Layer?"
date: 2018-03-08 21:29:38
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Regularization Embedding Deep_Learning
author: Nam Vo, James Hays
mathjax: true
---

* content
{:toc}

##### Abstract
Many recent works advancing deep learning tend to focus on large scale setting with the goal of more effective training and better fitting. This goal might be less applicable to the case of small to medium scale. Studying deep metric learning under such setting, we reason that better generalization could be a big contributing factor to improvement of previous works, as well as the goal for further improvement. 
 We investigate using other layers in a deep metric learning system (beside the embedding layer) for feature extraction and analyze how well they perform on training data and generalize to testing data. From this study, we suggest a new regularization practice and demonstrate state-of-the-art performance on 3 fine-grained image retrieval benchmarks: Cars-196, CUB-200-2011 and Stanford Online Product.

##### Abstract (translated by Google)
许多近期推进深度学习的作品倾向于将重点放在大规模设置上，以提供更有效的培训和更好的拟合。这个目标可能不适用于中小规模的情况。在这样的背景下研究深度度量学习，我们认为更好的泛化可能是改善以前作品的一个重要因素，也是进一步改进的目标。
 我们在深度度量学习系统（除了嵌入层之外）中使用其他图层进行调查，以进行特征提取并分析它们在训练数据上的表现以及推广到测试数据的表现。从这项研究中，我们建议一个新的正规化实践，并在3个细粒度图像检索基准上展示最先进的性能：Cars-196，CUB-200-2011和Stanford Online Product。

##### URL
[http://arxiv.org/abs/1803.03310](http://arxiv.org/abs/1803.03310)

##### PDF
[http://arxiv.org/pdf/1803.03310](http://arxiv.org/pdf/1803.03310)

