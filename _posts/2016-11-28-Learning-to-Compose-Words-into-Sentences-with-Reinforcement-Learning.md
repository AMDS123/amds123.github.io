---
layout: post
title: "Learning to Compose Words into Sentences with Reinforcement Learning"
date: 2016-11-28 12:57:07
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning
author: Dani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling
mathjax: true
---

* content
{:toc}

##### Abstract
We use reinforcement learning to learn tree-structured neural networks for computing representations of natural language sentences. In contrast with prior work on tree-structured models in which the trees are either provided as input or predicted using supervision from explicit treebank annotations, the tree structures in this work are optimized to improve performance on a downstream task. Experiments demonstrate the benefit of learning task-specific composition orders, outperforming both sequential encoders and recursive encoders based on treebank annotations. We analyze the induced trees and show that while they discover some linguistically intuitive structures (e.g., noun phrases, simple verb phrases), they are different than conventional English syntactic structures.

##### Abstract (translated by Google)
我们使用强化学习来学习用于计算自然语言句子表示的树形结构的神经网络。与之前在树型结构模型（其中树被提供作为输入或使用来自显式树库注释的监督来预测）的工作相比，本工作中的树结构被优化以提高下游任务的性能。实验证明了学习任务特定的合成顺序的好处，它优于基于树库注释的顺序编码器和递归编码器。我们分析诱导树，发现虽然他们发现了一些语言上直观的结构（例如，名词短语，简单的动词短语），但它们与传统的英语句法结构不同。

##### URL
[https://arxiv.org/abs/1611.09100](https://arxiv.org/abs/1611.09100)

##### PDF
[https://arxiv.org/pdf/1611.09100](https://arxiv.org/pdf/1611.09100)

