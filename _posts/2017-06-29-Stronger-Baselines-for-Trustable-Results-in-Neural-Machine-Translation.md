---
layout: post
title: "Stronger Baselines for Trustable Results in Neural Machine Translation"
date: 2017-06-29 13:02:46
categories: arXiv_CL
tags: arXiv_CL NMT
author: Michael Denkowski, Graham Neubig
---

* content
{:toc}

##### Abstract
Interest in neural machine translation has grown rapidly as its effectiveness has been demonstrated across language and data scenarios. New research regularly introduces architectural and algorithmic improvements that lead to significant gains over "vanilla" NMT implementations. However, these new techniques are rarely evaluated in the context of previously published techniques, specifically those that are widely used in state-of-theart production and shared-task systems. As a result, it is often difficult to determine whether improvements from research will carry over to systems deployed for real-world use. In this work, we recommend three specific methods that are relatively easy to implement and result in much stronger experimental systems. Beyond reporting significantly higher BLEU scores, we conduct an in-depth analysis of where improvements originate and what inherent weaknesses of basic NMT models are being addressed. We then compare the relative gains afforded by several other techniques proposed in the literature when starting with vanilla systems versus our stronger baselines, showing that experimental conclusions may change depending on the baseline chosen. This indicates that choosing a strong baseline is crucial for reporting reliable experimental results.

##### Abstract (translated by Google)
对神经机器翻译的兴趣在其语言和数据场景中的有效性得到了显着提高。新的研究定期介绍架构和算法的改进，从而导致“vanilla”NMT实现方面的重大进展。然而，这些新技术很少在先前发表的技术的背景下进行评估，特别是那些在现有技术生产和共享任务系统中广泛使用的技术。因此，通常很难确定研究的改进是否会延伸到部署用于现实世界的系统。在这项工作中，我们推荐三个相对容易实施的具体方法，并产生更强大的实验系统。除了报告BLEU得分显着更高之外，我们还深入分析了哪些方面有所改进，以及基本NMT模型的固有弱点正在得到解决。然后，我们比较文献中提出的其他几种技术提供的相对收益，这些技术是从香草系统开始的，还是比较强的基线，显示实验结论可能会根据所选择的基准而变化。这表明选择强基线对于报告可靠的实验结果至关重要。

##### URL
[https://arxiv.org/abs/1706.09733](https://arxiv.org/abs/1706.09733)

