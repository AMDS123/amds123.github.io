---
layout: post
title: "Learning Goal-Oriented Visual Dialog Agents: Imitating and Surpassing Analytic Experts"
date: 2019-07-24 15:08:38
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Yen-Wei Chang, Wen-Hsiao Peng
mathjax: true
---

* content
{:toc}

##### Abstract
This paper tackles the problem of learning a questioner in the goal-oriented visual dialog task. Several previous works adopt model-free reinforcement learning. Most pretrain the model from a finite set of human-generated data. We argue that using limited demonstrations to kick-start the questioner is insufficient due to the large policy search space. Inspired by a recently proposed information theoretic approach, we develop two analytic experts to serve as a source of high-quality demonstrations for imitation learning. We then take advantage of reinforcement learning to refine the model towards the goal-oriented objective. Experimental results on the GuessWhat?! dataset show that our method has the combined merits of imitation and reinforcement learning, achieving the state-of-the-art performance.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.10500](http://arxiv.org/abs/1907.10500)

##### PDF
[http://arxiv.org/pdf/1907.10500](http://arxiv.org/pdf/1907.10500)

