---
layout: post
title: "MIT Autonomous Vehicle Technology Study: Large-Scale Deep Learning Based Analysis of Driver Behavior and Interaction with Automation"
date: 2017-11-19 06:46:21
categories: arXiv_CV
tags: arXiv_CV Knowledge Face Optimization Deep_Learning
author: Lex Fridman, Daniel E. Brown, Michael Glazer, William Angell, Spencer Dodd, Benedikt Jenik, Jack Terwilliger, Julia Kindelsberger, Li Ding, Sean Seaman, Hillary Abraham, Alea Mehler, Andrew Sipperley, Anthony Pettinato, Bobbie Seppelt, Linda Angell, Bruce Mehler, Bryan Reimer
mathjax: true
---

* content
{:toc}

##### Abstract
Today, and possibly for a long time to come, the full driving task is too complex an activity to be fully formalized as a sensing-acting robotics system that can be explicitly solved through model-based and learning-based approaches in order to achieve full unconstrained vehicle autonomy. Localization, mapping, scene perception, vehicle control, trajectory optimization, and higher-level planning decisions associated with autonomous vehicle development remain full of open challenges. This is especially true for unconstrained, real-world operation where the margin of allowable error is extremely small and the number of edge-cases is extremely large. Until these problems are solved, human beings will remain an integral part of the driving task, monitoring the AI system as it performs anywhere from just over 0% to just under 100% of the driving. The governing objectives of the MIT Autonomous Vehicle Technology (MIT-AVT) study are to (1) undertake large-scale real-world driving data collection, and (2) gain a holistic understanding of how human beings interact with vehicle automation technology. In pursuing these objectives, we have instrumented 21 Tesla Model S and Model X vehicles, 2 Volvo S90 vehicles, and 2 Range Rover Evoque vehicles for both long-term (over a year per driver) and medium term (one month per driver) naturalistic driving data collection. The recorded data streams include IMU, GPS, CAN messages, and high-definition video streams of the driver face, the driver cabin, the forward roadway, and the instrument cluster. The study is on-going and growing. To date, we have 78 participants, 7,146 days of participation, 275,589 miles, and 3.5 billion video frames. This paper presents the design of the study, the data collection hardware, the processing of the data, and the computer vision algorithms currently being used to extract actionable knowledge from the data.

##### Abstract (translated by Google)
今天以及可能很长一段时间，完整的驾驶任务是一个非常复杂的活动，被完全形式化为一个感应代理机器人系统，可以通过基于模型和基于学习的方法明确地解决，以达到完全不受约束的车辆自治。与自主车辆开发相关的本地化，制图，场景感知，车辆控制，轨迹优化以及更高级别的规划决策仍然充满了公开的挑战。对于无限制的现实世界的操作来说尤其如此，其中容许误差的极限非常小并且边缘情况的数量非常大。在这些问题解决之前，人类仍然是驾驶任务中不可或缺的一部分，监测人工智能系统的执行情况，只要从0％到100％不等。麻省理工学院自主车辆技术（MIT-AVT）研究的目标是：（1）开展大规模的现实驾驶数据采集;（2）全面了解人类如何与车辆自动化技术进行互动。在追求这些目标的过程中，我们使用了21辆特斯拉S型和X型汽车，2辆沃尔沃S90汽车和2辆揽胜Evoque汽车，长期（每驾驶一年以上）和中期（每驾驶一个月）驾驶数据收集。记录的数据流包括驾驶员面部，驾驶室，前进道路和仪表盘的IMU，GPS，CAN消息和高清视频流。这项研究正在进行，并在不断发展。迄今为止，我们有78名参与者，7,146天的参与，275,589英里和35亿视频帧。本文介绍了本研究的设计，数据采集硬件，数据处理以及目前用于从数据中提取可操作知识的计算机视觉算法。

##### URL
[https://arxiv.org/abs/1711.06976](https://arxiv.org/abs/1711.06976)

##### PDF
[https://arxiv.org/pdf/1711.06976](https://arxiv.org/pdf/1711.06976)

