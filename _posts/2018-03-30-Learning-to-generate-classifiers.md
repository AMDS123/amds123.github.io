---
layout: post
title: "Learning to generate classifiers"
date: 2018-03-30 07:43:35
categories: arXiv_AI
tags: arXiv_AI Attention Classification
author: Nicholas Guttenberg, Ryota Kanai
mathjax: true
---

* content
{:toc}

##### Abstract
We train a network to generate mappings between training sets and classification policies (a 'classifier generator') by conditioning on the entire training set via an attentional mechanism. The network is directly optimized for test set performance on an training set of related tasks, which is then transferred to unseen 'test' tasks. We use this to optimize for performance in the low-data and unsupervised learning regimes, and obtain significantly better performance in the 10-50 datapoint regime than support vector classifiers, random forests, XGBoost, and k-nearest neighbors on a range of small datasets.

##### Abstract (translated by Google)
我们训练一个网络来生成训练集和分类策略之间的映射（一个“分类器生成器”），通过一个注意机制来调节整个训练集。该网络直接针对相关任务的训练集上的测试集性能进行优化，然后转移到看不见的“测试”任务。我们使用这种方法来优化低数据和无监督学习机制的性能，并且在支持向量分类器，随机森林，XGBoost以及一系列小数据集上的k最近邻居的10-50数据点机制中获得显着更好的性能。

##### URL
[https://arxiv.org/abs/1803.11373](https://arxiv.org/abs/1803.11373)

##### PDF
[https://arxiv.org/pdf/1803.11373](https://arxiv.org/pdf/1803.11373)

