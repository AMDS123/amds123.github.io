---
layout: post
title: "Sequential Deep Trajectory Descriptor for Action Recognition with Three-stream CNN"
date: 2017-02-10 02:49:10
categories: arXiv_CV
tags: arXiv_CV Action_Recognition RNN Recognition
author: Yemin Shi, Yonghong Tian, Yaowei Wang, Tiejun Huang
mathjax: true
---

* content
{:toc}

##### Abstract
Learning the spatial-temporal representation of motion information is crucial to human action recognition. Nevertheless, most of the existing features or descriptors cannot capture motion information effectively, especially for long-term motion. To address this problem, this paper proposes a long-term motion descriptor called sequential Deep Trajectory Descriptor (sDTD). Specifically, we project dense trajectories into two-dimensional planes, and subsequently a CNN-RNN network is employed to learn an effective representation for long-term motion. Unlike the popular two-stream ConvNets, the sDTD stream is introduced into a three-stream framework so as to identify actions from a video sequence. Consequently, this three-stream framework can simultaneously capture static spatial features, short-term motion and long-term motion in the video. Extensive experiments were conducted on three challenging datasets: KTH, HMDB51 and UCF101. Experimental results show that our method achieves state-of-the-art performance on the KTH and UCF101 datasets, and is comparable to the state-of-the-art methods on the HMDB51 dataset.

##### Abstract (translated by Google)
学习运动信息的时空表示对人类行为识别至关重要。尽管如此，现有的大部分特征或描述符都不能有效地捕捉运动信息，特别是对于长时间的运动。为了解决这个问题，本文提出了一个称为顺序深轨迹描述符（sDTD）的长期运动描述符。具体而言，我们将密集的轨迹投影到二维平面，随后使用CNN-RNN网络来学习长期运动的有效表示。与流行的双流ConvNets不同，sDTD流被引入到三流框架中，以便从视频序列中识别动作。因此，这个三流框架可以同时捕捉视频中的静态空间特征，短期运动和长期运动。在三个具有挑战性的数据集上进行了大量的实验：KTH，HMDB51和UCF101。实验结果表明，我们的方法在KTH和UCF101数据集上达到了最先进的性能，并且与HMDB51数据集上的最先进的方法相当。

##### URL
[https://arxiv.org/abs/1609.03056](https://arxiv.org/abs/1609.03056)

##### PDF
[https://arxiv.org/pdf/1609.03056](https://arxiv.org/pdf/1609.03056)

