---
layout: post
title: "Rationalizing Neural Predictions"
date: 2016-11-02 20:26:20
categories: arXiv_CL
tags: arXiv_CL Sentiment Attention Prediction
author: Tao Lei, Regina Barzilay, Tommi Jaakkola
mathjax: true
---

* content
{:toc}

##### Abstract
Prediction without justification has limited applicability. As a remedy, we learn to extract pieces of input text as justifications -- rationales -- that are tailored to be short and coherent, yet sufficient for making the same prediction. Our approach combines two modular components, generator and encoder, which are trained to operate well together. The generator specifies a distribution over text fragments as candidate rationales and these are passed through the encoder for prediction. Rationales are never given during training. Instead, the model is regularized by desiderata for rationales. We evaluate the approach on multi-aspect sentiment analysis against manually annotated test cases. Our approach outperforms attention-based baseline by a significant margin. We also successfully illustrate the method on the question retrieval task.

##### Abstract (translated by Google)
没有正当理由的预测适用性有限。作为一种补救措施，我们学习提取输入文本片段作为理由 - 基本原理 - 这些修改是短而一致的，但足以做出相同的预测。我们的方法结合了两个模块化组件，发电机和编码器，这些组件经过训练可以很好地协调工作生成器将文本片段上的分布指定为候选原理，并通过编码器进行预测。在训练期间从不给予理论。相反，模型是由desiderata为基本原理正规化。我们评估手动注释测试用例的多方面情绪分析方法。我们的方法比基于注意力的基准要高出很多。我们也成功地说明了问题检索任务的方法。

##### URL
[https://arxiv.org/abs/1606.04155](https://arxiv.org/abs/1606.04155)

##### PDF
[https://arxiv.org/pdf/1606.04155](https://arxiv.org/pdf/1606.04155)

