---
layout: post
title: "High-Order Attention Models for Visual Question Answering"
date: 2017-11-12 17:30:05
categories: arXiv_CV
tags: arXiv_CV QA Attention Relation VQA
author: Idan Schwartz, Alexander G. Schwing, Tamir Hazan
mathjax: true
---

* content
{:toc}

##### Abstract
The quest for algorithms that enable cognitive abilities is an important part of machine learning. A common trait in many recently investigated cognitive-like tasks is that they take into account different data modalities, such as visual and textual input. In this paper we propose a novel and generally applicable form of attention mechanism that learns high-order correlations between various data modalities. We show that high-order correlations effectively direct the appropriate attention to the relevant elements in the different data modalities that are required to solve the joint task. We demonstrate the effectiveness of our high-order attention mechanism on the task of visual question answering (VQA), where we achieve state-of-the-art performance on the standard VQA dataset.

##### Abstract (translated by Google)
寻求使认知能力成为可能的算法是机器学习的重要组成部分。许多最近研究认知类任务的一个共同特点是，他们考虑到不同的数据模态，如视觉和文字输入。在本文中，我们提出了一种新颖的，普遍适用的注意机制形式，可以学习各种数据模式之间的高阶相关性。我们表明，高阶相关有效地指导了解决联合任务所需的不同数据模式中的相关要素。我们证明了我们的高阶关注机制对视觉问答（VQA）任务的有效性，我们在标准VQA数据集上实现了最先进的性能。

##### URL
[https://arxiv.org/abs/1711.04323](https://arxiv.org/abs/1711.04323)

##### PDF
[https://arxiv.org/pdf/1711.04323](https://arxiv.org/pdf/1711.04323)

