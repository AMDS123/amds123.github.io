---
layout: post
title: "Unsupervised Learning of Depth and Deep Representation for Visual Odometry from Monocular Videos in a Metric Space"
date: 2019-08-04 15:48:31
categories: arXiv_CV
tags: arXiv_CV Attention Represenation_Learning SLAM
author: Xiaochuan Yin, Chengju Liu
mathjax: true
---

* content
{:toc}

##### Abstract
For ego-motion estimation, the feature representation of the scenes is crucial. Previous methods indicate that both the low-level and semantic feature-based methods can achieve promising results. Therefore, the incorporation of hierarchical feature representation may benefit from both methods. From this perspective, we propose a novel direct feature odometry framework, named DFO, for depth estimation and hierarchical feature representation learning from monocular videos. By exploiting the metric distance, our framework is able to learn the hierarchical feature representation without supervision. The pose is obtained with a coarse-to-fine approach from high-level to low-level features in enlarged feature maps. The pixel-level attention mask can be self-learned to provide the prior information. In contrast to the previous methods, our proposed method calculates the camera motion with a direct method rather than regressing the ego-motion from the pose network. With this approach, the consistency of the scale factor of translation can be constrained. Additionally, the proposed method is thus compatible with the traditional SLAM pipeline. Experiments on the KITTI dataset demonstrate the effectiveness of our method.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.01367](http://arxiv.org/abs/1908.01367)

##### PDF
[http://arxiv.org/pdf/1908.01367](http://arxiv.org/pdf/1908.01367)

