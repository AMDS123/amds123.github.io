---
layout: post
title: "Unpaired Multi-Domain Image Generation via Regularized Conditional GANs"
date: 2018-05-07 11:52:28
categories: arXiv_CV
tags: arXiv_CV GAN Face
author: Xudong Mao, Qing Li
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we study the problem of multi-domain image generation, the goal of which is to generate pairs of corresponding images from different domains. With the recent development in generative models, image generation has achieved great progress and has been applied to various computer vision tasks. However, multi-domain image generation may not achieve the desired performance due to the difficulty of learning the correspondence of different domain images, especially when the information of paired samples is not given. To tackle this problem, we propose Regularized Conditional GAN (RegCGAN) which is capable of learning to generate corresponding images in the absence of paired training data. RegCGAN is based on the conditional GAN, and we introduce two regularizers to guide the model to learn the corresponding semantics of different domains. We evaluate the proposed model on several tasks for which paired training data is not given, including the generation of edges and photos, the generation of faces with different attributes, etc. The experimental results show that our model can successfully generate corresponding images for all these tasks, while outperforms the baseline methods. We also introduce an approach of applying RegCGAN to unsupervised domain adaptation.

##### Abstract (translated by Google)
在本文中，我们研究多域图像生成问题，其目标是生成来自不同域的相应图像对。随着生成模型的近期发展，图像生成取得了很大进展，并已应用于各种计算机视觉任务。然而，由于学习不同区域图像的对应性的困难，特别是当未给出配对样本的信息时，多域图像生成可能无法达到期望的性能。为了解决这个问题，我们提出了Regularized Conditional GAN（RegCGAN），它能够在没有配对训练数据的情况下学习生成相应的图像。 RegCGAN基于条件GAN，我们引入两个正规化器来指导模型学习不同领域的相应语义。我们评估所提出的模型在几个没有配对训练数据的任务上，包括边缘和照片的生成，具有不同属性的人脸的生成等。实验结果表明，我们的模型可以成功地为所有这些生成相应的图像任务，同时胜过基准方法。我们还介绍了一种将RegCGAN应用于无监督域自适应的方法。

##### URL
[http://arxiv.org/abs/1805.02456](http://arxiv.org/abs/1805.02456)

##### PDF
[http://arxiv.org/pdf/1805.02456](http://arxiv.org/pdf/1805.02456)

