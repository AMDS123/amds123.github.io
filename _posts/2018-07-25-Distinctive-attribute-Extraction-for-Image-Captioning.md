---
layout: post
title: "Distinctive-attribute Extraction for Image Captioning"
date: 2018-07-25 04:34:17
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption CNN RNN
author: Boeun Kim, Young Han Lee, Hyedong Jung, Choongsang Cho
mathjax: true
---

* content
{:toc}

##### Abstract
Image captioning, an open research issue, has been evolved with the progress of deep neural networks. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) are employed to compute image features and generate natural language descriptions in the research. In previous works, a caption involving semantic description can be generated by applying additional information into the RNNs. In this approach, we propose a distinctive-attribute extraction (DaE) which explicitly encourages significant meanings to generate an accurate caption describing the overall meaning of the image with their unique situation. Specifically, the captions of training images are analyzed by term frequency-inverse document frequency (TF-IDF), and the analyzed semantic information is trained to extract distinctive-attributes for inferring captions. The proposed scheme is evaluated on a challenge data, and it improves an objective performance while describing images in more detail.

##### Abstract (translated by Google)
图像字幕是一个开放的研究问题，随着深度神经网络的发展而不断发展。卷积神经网络（CNN）和递归神经网络（RNN）用于计算图像特征并在研究中生成自然语言描述。在先前的工作中，可以通过将附加信息应用于RNN来生成涉及语义描述的标题。在这种方法中，我们提出了一种独特属性提取（DaE），它明确地鼓励重要意义来生成描述图像的整体含义及其独特情况的准确标题。具体地，通过术语频率 - 逆文档频率（TF-IDF）分析训练图像的字幕，并且训练分析的语义信息以提取用于推断字幕的区别属性。所提出的方案在挑战数据上进行评估，并且在更详细地描述图像的同时改善了客观性能。

##### URL
[http://arxiv.org/abs/1807.09434](http://arxiv.org/abs/1807.09434)

##### PDF
[http://arxiv.org/pdf/1807.09434](http://arxiv.org/pdf/1807.09434)

