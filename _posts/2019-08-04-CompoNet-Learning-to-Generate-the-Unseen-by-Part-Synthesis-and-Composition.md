---
layout: post
title: "CompoNet: Learning to Generate the Unseen by Part Synthesis and Composition"
date: 2019-08-04 08:25:20
categories: arXiv_CV
tags: arXiv_CV Quantitative
author: Nadav Schor, Oren Katzir, Hao Zhang, Daniel Cohen-Or
mathjax: true
---

* content
{:toc}

##### Abstract
Data-driven generative modeling has made remarkable progress by leveraging the power of deep neural networks. A reoccurring challenge is how to enable a model to generate a rich variety of samples from the entire target distribution, rather than only from a distribution confined to the training data. In other words, we would like the generative model to go beyond the observed samples and learn to generate ``unseen'', yet still plausible, data. In our work, we present CompoNet, a generative neural network for 2D or 3D shapes that is based on a part-based prior, where the key idea is for the network to synthesize shapes by varying both the shape parts and their compositions. Treating a shape not as an unstructured whole, but as a (re-)composable set of deformable parts, adds a combinatorial dimension to the generative process to enrich the diversity of the output, encouraging the generator to venture more into the ``unseen''. We show that our part-based model generates richer variety of plausible shapes compared with baseline generative models. To this end, we introduce two quantitative metrics to evaluate the diversity of a generative model and assess how well the generated data covers both the training data and unseen data from the same target distribution.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.07441](http://arxiv.org/abs/1811.07441)

##### PDF
[http://arxiv.org/pdf/1811.07441](http://arxiv.org/pdf/1811.07441)

