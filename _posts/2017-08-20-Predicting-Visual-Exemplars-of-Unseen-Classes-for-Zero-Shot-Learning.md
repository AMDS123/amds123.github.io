---
layout: post
title: "Predicting Visual Exemplars of Unseen Classes for Zero-Shot Learning"
date: 2017-08-20 05:18:39
categories: arXiv_CV
tags: arXiv_CV Embedding Recognition
author: Soravit Changpinyo, Wei-Lun Chao, Fei Sha
mathjax: true
---

* content
{:toc}

##### Abstract
Leveraging class semantic descriptions and examples of known objects, zero-shot learning makes it possible to train a recognition model for an object class whose examples are not available. In this paper, we propose a novel zero-shot learning model that takes advantage of clustering structures in the semantic embedding space. The key idea is to impose the structural constraint that semantic representations must be predictive of the locations of their corresponding visual exemplars. To this end, this reduces to training multiple kernel-based regressors from semantic representation-exemplar pairs from labeled data of the seen object categories. Despite its simplicity, our approach significantly outperforms existing zero-shot learning methods on standard benchmark datasets, including the ImageNet dataset with more than 20,000 unseen categories.

##### Abstract (translated by Google)
通过利用类语义描述和已知对象的例子，零点学习可以训练其示例不可用的对象类的识别模型。本文提出了一种利用语义嵌入空间中的聚类结构的新型零点学习模型。关键的思想是强加结构性约束，即语义表示必须能够预测相应视觉样例的位置。为此，这减少了从所看到的对象类别的标记数据中从语义表示 - 范例对中训练多个基于内核的回归器。尽管其简单性，我们的方法明显优于标准基准数据集上的现有零点学习方法，其中包括具有超过20,000个未见类别的ImageNet数据集。

##### URL
[https://arxiv.org/abs/1605.08151](https://arxiv.org/abs/1605.08151)

##### PDF
[https://arxiv.org/pdf/1605.08151](https://arxiv.org/pdf/1605.08151)

