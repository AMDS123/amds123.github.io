---
layout: post
title: "Recurrent Fusion Network for Image Captioning"
date: 2018-07-26 07:25:06
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption CNN RNN
author: Wenhao Jiang, Lin Ma, Yu-Gang Jiang, Wei Liu, Tong Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, much advance has been made in image captioning, and an encoder-decoder framework has been adopted by all the state-of-the-art models. Under this framework, an input image is encoded by a convolutional neural network (CNN) and then translated into natural language with a recurrent neural network (RNN). The existing models counting on this framework employ only one kind of CNNs, e.g., ResNet or Inception-X, which describes the image contents from only one specific view point. Thus, the semantic meaning of the input image cannot be comprehensively understood, which restricts improving the performance. In this paper, to exploit the complementary information from multiple encoders, we propose a novel recurrent fusion network (RFNet) for the image captioning task. The fusion process in our model can exploit the interactions among the outputs of the image encoders and generate new compact and informative representations for the decoder. Experiments on the MSCOCO dataset demonstrate the effectiveness of our proposed RFNet, which sets a new state-of-the-art for image captioning.

##### Abstract (translated by Google)
最近，图像字幕已经取得了很大进展，并且所有最先进的模型都采用了编码器 - 解码器框架。在此框架下，输入图像由卷积神经网络（CNN）编码，然后通过递归神经网络（RNN）转换为自然语言。依赖于该框架的现有模型仅使用一种CNN，例如ResNet或Inception-X，其仅描述来自一个特定视点的图像内容。因此，不能全面地理解输入图像的语义含义，这限制了改善性能。在本文中，为了利用来自多个编码器的补充信息，我们提出了一种用于图像字幕任务的新型复现融合网络（RFNet）。我们模型中的融合过程可以利用图像编码器输出之间的相互作用，并为解码器生成新的紧凑和信息表示。 MSCOCO数据集上的实验证明了我们提出的RFNet的有效性，它为图像字幕设置了一种新的先进技术。

##### URL
[http://arxiv.org/abs/1807.09986](http://arxiv.org/abs/1807.09986)

##### PDF
[http://arxiv.org/pdf/1807.09986](http://arxiv.org/pdf/1807.09986)

