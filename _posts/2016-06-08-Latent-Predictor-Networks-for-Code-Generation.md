---
layout: post
title: "Latent Predictor Networks for Code Generation"
date: 2016-06-08 14:46:00
categories: arXiv_SD
tags: arXiv_SD
author: Wang Ling, Edward Grefenstette, Karl Moritz Hermann, Tomáš Kočiský, Andrew Senior, Fumin Wang, Phil Blunsom
mathjax: true
---

* content
{:toc}

##### Abstract
Many language generation tasks require the production of text conditioned on both structured and unstructured inputs. We present a novel neural network architecture which generates an output sequence conditioned on an arbitrary number of input functions. Crucially, our approach allows both the choice of conditioning context and the granularity of generation, for example characters or tokens, to be marginalised, thus permitting scalable and effective training. Using this framework, we address the problem of generating programming code from a mixed natural language and structured specification. We create two new data sets for this paradigm derived from the collectible trading card games Magic the Gathering and Hearthstone. On these, and a third preexisting corpus, we demonstrate that marginalising multiple predictors allows our model to outperform strong benchmarks.

##### Abstract (translated by Google)
许多语言生成任务要求生成以结构化和非结构化输入为条件的文本。我们提出了一种新的神经网络架构，它产生一个输出序列，条件是任意数量的输入函数。至关重要的是，我们的方法允许条件环境的选择和生成的粒度（例如字符或令牌）被边缘化，从而允许可扩展和有效的训练。使用这个框架，我们解决了从混合自然语言和结构化规范中生成编程代码的问题。我们为这个范例创建了两个新的数据集，这些数据来源于可收集的交易卡游戏Magic the Gathering and Hearthstone。在这些以及第三个预先存在的语料库中，我们证明边际化的多个预测因子可以使我们的模型超越强大的基准。

##### URL
[https://arxiv.org/abs/1603.06744](https://arxiv.org/abs/1603.06744)

##### PDF
[https://arxiv.org/pdf/1603.06744](https://arxiv.org/pdf/1603.06744)

