---
layout: post
title: "HotFlip: White-Box Adversarial Examples for NLP"
date: 2017-12-19 02:15:19
categories: arXiv_CL
tags: arXiv_CL Adversarial Text_Classification Classification
author: Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou
mathjax: true
---

* content
{:toc}

##### Abstract
Adversarial examples expose vulnerabilities of machine learning models. We propose an efficient method to generate white-box adversarial examples that trick character-level and word-level neural models. Our method, HotFlip, relies on an atomic flip operation, which swaps one token for another, based on the gradients of the one-hot input vectors. In experiments on text classification and machine translation, we find that only a few manipulations are needed to greatly increase the error rates. We analyze the properties of these examples, and show that employing these adversarial examples in training can improve test-time accuracy on clean examples, as well as defend the models against adversarial examples.

##### Abstract (translated by Google)
敌对的例子揭露了机器学习模型的弱点。我们提出一个有效的方法来产生白盒对抗的例子，欺骗字符级和字级神经模型。我们的方法HotFlip依赖于原子翻转操作，它根据单热输入向量的梯度将一个令牌替换为另一个令牌。在文本分类和机器翻译的实验中，我们发现只需要很少的操作就可以大大提高错误率。我们分析这些例子的性质，并且表明在训练中使用这些对抗例子可以提高清洁例子的测试时间准确性，并且防止对抗例子的模型。

##### URL
[http://arxiv.org/abs/1712.06751](http://arxiv.org/abs/1712.06751)

##### PDF
[http://arxiv.org/pdf/1712.06751](http://arxiv.org/pdf/1712.06751)

