---
layout: post
title: "Representation learning for very short texts using weighted word embedding aggregation"
date: 2016-07-02 23:10:09
categories: arXiv_CL
tags: arXiv_CL Sparse Embedding Represenation_Learning Optimization Detection Recommendation
author: Cedric De Boom, Steven Van Canneyt, Thomas Demeester, Bart Dhoedt
mathjax: true
---

* content
{:toc}

##### Abstract
Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box.

##### Abstract (translated by Google)
诸如推文之类的简短文本消息非常嘈杂，而且对词汇的使用也很少。传统的文本表示，如tf-idf，难以把握这些文本的语义，这在事件检测，意见挖掘，新闻推荐等应用中是非常重要的。我们构建了一种基于语义词嵌入和频率信息以获得用于捕捉语义相似性的短文本的低维表示。为此，我们设计了一个基于权重的模型和一个基于新型中值损失函数的学习过程。本文讨论了我们的模型和优化方法的细节，以及维基百科和Twitter数据的实验结果。我们发现，我们的方法胜过了实验中的基线方法，并且它在不需要再训练的情况下在不同的词嵌入上得到很好的推广。因此，我们的方法能够保留文本中的大部分语义信息，并且可以立即使用。

##### URL
[https://arxiv.org/abs/1607.00570](https://arxiv.org/abs/1607.00570)

##### PDF
[https://arxiv.org/pdf/1607.00570](https://arxiv.org/pdf/1607.00570)

