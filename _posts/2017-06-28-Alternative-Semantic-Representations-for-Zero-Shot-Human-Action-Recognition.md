---
layout: post
title: "Alternative Semantic Representations for Zero-Shot Human Action Recognition"
date: 2017-06-28 14:32:57
categories: arXiv_CV
tags: arXiv_CV Action_Recognition Recognition
author: Qian Wang, Ke Chen
mathjax: true
---

* content
{:toc}

##### Abstract
A proper semantic representation for encoding side information is key to the success of zero-shot learning. In this paper, we explore two alternative semantic representations especially for zero-shot human action recognition: textual descriptions of human actions and deep features extracted from still images relevant to human actions. Such side information are accessible on Web with little cost, which paves a new way in gaining side information for large-scale zero-shot human action recognition. We investigate different encoding methods to generate semantic representations for human actions from such side information. Based on our zero-shot visual recognition method, we conducted experiments on UCF101 and HMDB51 to evaluate two proposed semantic representations . The results suggest that our proposed text- and image-based semantic representations outperform traditional attributes and word vectors considerably for zero-shot human action recognition. In particular, the image-based semantic representations yield the favourable performance even though the representation is extracted from a small number of images per class.

##### Abstract (translated by Google)
编码辅助信息的适当语义表示是零点学习成功的关键。在本文中，我们探索了两种替代的语义表示，特别是零点人类行为识别：人类行为的文本描述和从与人类行为相关的静止图像中提取的深层特征。这样的辅助信息可以在网上以很少的成本获得，这为获得大规模零点人类行为识别的边信息提供了新的途径。我们调查不同的编码方法，从这些辅助信息生成人类行为的语义表示。基于我们的零点视觉识别方法，我们对UCF101和HMDB51进行了实验来评估两个提出的语义表示。结果表明，我们提出的基于文本和图像的语义表示比零传统的人类动作识别具有更好的传统属性和单词向量。特别地，即使表示是从每个类别的少量图像中提取的，基于图像的语义表示仍然产生良好的性能。

##### URL
[https://arxiv.org/abs/1706.09317](https://arxiv.org/abs/1706.09317)

##### PDF
[https://arxiv.org/pdf/1706.09317](https://arxiv.org/pdf/1706.09317)

