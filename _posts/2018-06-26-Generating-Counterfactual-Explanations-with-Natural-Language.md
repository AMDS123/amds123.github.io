---
layout: post
title: "Generating Counterfactual Explanations with Natural Language"
date: 2018-06-26 06:43:36
categories: arXiv_CV
tags: arXiv_CV Image_Classification Classification Quantitative
author: Lisa Anne Hendricks, Ronghang Hu, Trevor Darrell, Zeynep Akata
mathjax: true
---

* content
{:toc}

##### Abstract
Natural language explanations of deep neural network decisions provide an intuitive way for a AI agent to articulate a reasoning process. Current textual explanations learn to discuss class discriminative features in an image. However, it is also helpful to understand which attributes might change a classification decision if present in an image (e.g., "This is not a Scarlet Tanager because it does not have black wings.") We call such textual explanations counterfactual explanations, and propose an intuitive method to generate counterfactual explanations by inspecting which evidence in an input is missing, but might contribute to a different classification decision if present in the image. To demonstrate our method we consider a fine-grained image classification task in which we take as input an image and a counterfactual class and output text which explains why the image does not belong to a counterfactual class. We then analyze our generated counterfactual explanations both qualitatively and quantitatively using proposed automatic metrics.

##### Abstract (translated by Google)
深层神经网络决策的自然语言解释为AI代理提供了一种直观的方式来阐明推理过程。目前的文本解释学习讨论图像中的类别判别特征。然而，理解哪些属性可能会改变图像中存在的分类决定也是有帮助的（例如，“这不是黑猩猩的翅膀，因为它不是黑猩猩”）。我们称这种文本解释为反事实解释，并提出一种直观的方法是通过检查输入中的哪些证据丢失来生成反事实的解释，但如果存在于图像中可能会导致不同的分类决定。为了演示我们的方法，我们考虑一个细粒度的图像分类任务，其中我们将图像和反事实类和输出文本作为输入，从而解释为什么图像不属于反事实类。然后，我们使用提出的自动度量标准定性和定量分析我们生成的反事实解释。

##### URL
[http://arxiv.org/abs/1806.09809](http://arxiv.org/abs/1806.09809)

##### PDF
[http://arxiv.org/pdf/1806.09809](http://arxiv.org/pdf/1806.09809)

