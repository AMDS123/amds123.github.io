---
layout: post
title: "Vid2speech: Speech Reconstruction from Silent Video"
date: 2017-01-09 17:35:17
categories: arXiv_CV
tags: arXiv_CV CNN
author: Ariel Ephrat, Shmuel Peleg
mathjax: true
---

* content
{:toc}

##### Abstract
Speechreading is a notoriously difficult task for humans to perform. In this paper we present an end-to-end model based on a convolutional neural network (CNN) for generating an intelligible acoustic speech signal from silent video frames of a speaking person. The proposed CNN generates sound features for each frame based on its neighboring frames. Waveforms are then synthesized from the learned speech features to produce intelligible speech. We show that by leveraging the automatic feature learning capabilities of a CNN, we can obtain state-of-the-art word intelligibility on the GRID dataset, and show promising results for learning out-of-vocabulary (OOV) words.

##### Abstract (translated by Google)
语言阅读对于人类来说是一项非常艰巨的任务。在本文中，我们提出了一种基于卷积神经网络（CNN）的端到端模型，用于从发言人的无声视频帧中生成可理解的声学语音信号。所提出的CNN基于其相邻帧为每个帧生成声音特征。然后从学习的语音特征合成波形以产生可理解的语音。我们表明，通过利用CNN的自动特征学习功能，我们可以在GRID数据集上获得最先进的词汇可​​理解性，并显示出学习词汇外（OOV）单词的有希望的结果。

##### URL
[https://arxiv.org/abs/1701.00495](https://arxiv.org/abs/1701.00495)

##### PDF
[https://arxiv.org/pdf/1701.00495](https://arxiv.org/pdf/1701.00495)

