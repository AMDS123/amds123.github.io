---
layout: post
title: "Principal Filter Analysis for Guided Network Compression"
date: 2018-07-20 23:36:11
categories: arXiv_CV
tags: arXiv_CV GAN Relation
author: Xavier Suau, Luca Zappella, Vinay Palakkode, Nicholas Apostoloff
mathjax: true
---

* content
{:toc}

##### Abstract
Principal Filter Analysis (PFA), is an elegant, easy to implement, yet effective methodology for neural network compression. PFA exploits the intrinsic correlation between filter responses within network layers to recommend a smaller network footprint. We propose two compression algorithms: the first allows a user to specify the proportion of the original spectral energy that should be preserved in each layer after compression, while the second is a parameter-free approach that automatically selects the compression used at each layer. Both algorithms are evaluated against several architectures and datasets, and we show considerable compression rates without compromising accuracy, e.g., for VGG-16 on CIFAR-10 and CIFAR-100 PFA achieves a compression rate of 8x and 3x with an accuracy gain of 0.4% points and 1.4% points, respectively. In our tests we also demonstrate that networks compressed with PFA achieve an accuracy that is very close to the empirical upper bound for a given compression ratio.

##### Abstract (translated by Google)
主滤波器分析（PFA）是一种优雅，易于实现且有效的神经网络压缩方法。 PFA利用网络层内过滤器响应之间的内在关联来推荐更小的网络占用空间。我们提出了两种压缩算法：第一种允许用户指定压缩后每层应保留的原始光谱能量的比例，而第二种是无参数的方法，自动选择每层使用的压缩。两种算法都针对多种架构和数据集进行评估，并且我们在不影响准确性的情况下显示出相当大的压缩率，例如，对于CIFAR-10上的VGG-16和CIFAR-100 PFA，压缩率达到8x和3x，准确度增益为0.4％分数和1.4％分别。在我们的测试中，我们还证明了使用PFA压缩的网络实现了非常接近给定压缩比的经验上限的精度。

##### URL
[http://arxiv.org/abs/1807.10585](http://arxiv.org/abs/1807.10585)

##### PDF
[http://arxiv.org/pdf/1807.10585](http://arxiv.org/pdf/1807.10585)

