---
layout: post
title: "Towards a Simple Approach to Multi-step Model-based Reinforcement Learning"
date: 2018-10-31 21:31:59
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Prediction
author: Kavosh Asadi, Evan Cater, Dipendra Misra, Michael L. Littman
mathjax: true
---

* content
{:toc}

##### Abstract
When environmental interaction is expensive, model-based reinforcement learning offers a solution by planning ahead and avoiding costly mistakes. Model-based agents typically learn a single-step transition model. In this paper, we propose a multi-step model that predicts the outcome of an action sequence with variable length. We show that this model is easy to learn, and that the model can make policy-conditional predictions. We report preliminary results that show a clear advantage for the multi-step model compared to its one-step counterpart.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.00128](http://arxiv.org/abs/1811.00128)

##### PDF
[http://arxiv.org/pdf/1811.00128](http://arxiv.org/pdf/1811.00128)

