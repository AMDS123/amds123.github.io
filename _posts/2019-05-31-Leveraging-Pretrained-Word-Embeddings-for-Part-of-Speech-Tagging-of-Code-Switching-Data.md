---
layout: post
title: "Leveraging Pretrained Word Embeddings for Part-of-Speech Tagging of Code Switching Data"
date: 2019-05-31 00:08:27
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Fahad AlGhamdi, Mona Diab
mathjax: true
---

* content
{:toc}

##### Abstract
Linguistic Code Switching (CS) is a phenomenon that occurs when multilingual speakers alternate between two or more languages/dialects within a single conversation. Processing CS data is especially challenging in intra-sentential data given state-of-the-art monolingual NLP technologies since such technologies are geared toward the processing of one language at a time. In this paper, we address the problem of Part-of-Speech tagging (POS) in the context of linguistic code switching (CS). We explore leveraging multiple neural network architectures to measure the impact of different pre-trained embeddings methods on POS tagging CS data. We investigate the landscape in four CS language pairs, Spanish-English, Hindi-English, Modern Standard Arabic- Egyptian Arabic dialect (MSA-EGY), and Modern Standard Arabic- Levantine Arabic dialect (MSA-LEV). Our results show that multilingual embedding (e.g., MSA-EGY and MSA-LEV) helps closely related languages (EGY/LEV) but adds noise to the languages that are distant (SPA/HIN). Finally, we show that our proposed models outperform state-of-the-art CS taggers for MSA-EGY language pair.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.13359](http://arxiv.org/abs/1905.13359)

##### PDF
[http://arxiv.org/pdf/1905.13359](http://arxiv.org/pdf/1905.13359)

