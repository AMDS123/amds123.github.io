---
layout: post
title: "Attention-Based End-to-End Speech Recognition on Voice Search"
date: 2017-10-29 03:29:40
categories: arXiv_CL
tags: arXiv_CL Attention Speech_Recognition CNN Language_Model Recognition
author: Changhao Shan, Junbo Zhang, Yujun Wang, Lei Xie
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, there has been an increasing interest in end-to-end speech recognition that directly transcribes speech to text without any predefined alignments. In this paper, we explore the use of attention-based encoder-decoder model for Mandarin speech recognition on voice search. We propose a smoothing method for attention mechanism and compare with content attention and convolutional attention. Moreover, frame skipping is employed for fast training and convergence. On the XiaoMi TV voice search dataset, we achieve a character error rate (CER) of 3.58% and a sentence error rate (SER) of 7.43% without using any lexicon or language model. While together with a trigram language model, we reach 2.81% CER and 5.77% SER.

##### Abstract (translated by Google)
最近，对端对端语音识别的兴趣日益增长，它直接将语音转换成文本而没有任何预定义的对齐。在本文中，我们探讨了基于注意的编码器 - 解码器模型在语音搜索中对普通话语音识别的使用。我们提出了一种关注机制的平滑方法，并将其与内容注意和卷积关注进行比较。而且，跳帧被用于快速训练和收敛。在小米电视语音搜索数据集中，不使用任何词典或语言模型，字符错误率（CER）为3.58％，错误率（SER）为7.43％。加上三元语言模型，我们达到了2.81％的CER和5.77％的SER。

##### URL
[https://arxiv.org/abs/1707.07167](https://arxiv.org/abs/1707.07167)

##### PDF
[https://arxiv.org/pdf/1707.07167](https://arxiv.org/pdf/1707.07167)

