---
layout: post
title: "Long-Term Video Generation of Multiple FuturesUsing Human Poses"
date: 2019-04-16 08:50:44
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN Prediction
author: Naoya Fushishita, Antonio Tejero-de-Pablos, Yusuke Mukuta, Tatsuya Harada
mathjax: true
---

* content
{:toc}

##### Abstract
Predicting the near-future from an input video is a useful task for applications such as autonomous driving and robotics. While most previous works predict a single future, multiple futures with different behaviors can possibly occur. Moreover, if the predicted future is too short, it may not be fully usable by a human or other system. In this paper, we propose a novel method for future video prediction capable of generating multiple long-term futures. This makes the predictions more suitable for real applications. First, from an input human video, we generate sequences of future human poses as the image coordinates of their body-joints by adversarial learning. We generate multiple futures by inputting to the generator combinations of a latent code (to reflect various behaviors) and an attraction point (to reflect various trajectories). In addition, we generate long-term future human poses using a novel approach based on unidimensional convolutional neural networks. Last, we generate an output video based on the generated poses for visualization. We evaluate the generated future poses and videos using three criteria (i.e., realism, diversity and accuracy), and show that our proposed method outperforms other state-of-the-art works.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.07538](http://arxiv.org/abs/1904.07538)

##### PDF
[http://arxiv.org/pdf/1904.07538](http://arxiv.org/pdf/1904.07538)

