---
layout: post
title: "Shallow reading with Deep Learning: Predicting popularity of online content using only its title"
date: 2017-07-21 09:02:55
categories: arXiv_CL
tags: arXiv_CL Knowledge Attention Embedding RNN Deep_Learning Prediction
author: Wociech Stokowiec, Tomasz Trzcinski, Krzysztof Wolk, Krzysztof Marasek, Przemyslaw Rokita
mathjax: true
---

* content
{:toc}

##### Abstract
With the ever decreasing attention span of contemporary Internet users, the title of online content (such as a news article or video) can be a major factor in determining its popularity. To take advantage of this phenomenon, we propose a new method based on a bidirectional Long Short-Term Memory (LSTM) neural network designed to predict the popularity of online content using only its title. We evaluate the proposed architecture on two distinct datasets of news articles and news videos distributed in social media that contain over 40,000 samples in total. On those datasets, our approach improves the performance over traditional shallow approaches by a margin of 15%. Additionally, we show that using pre-trained word vectors in the embedding layer improves the results of LSTM models, especially when the training set is small. To our knowledge, this is the first attempt of applying popularity prediction using only textual information from the title.

##### Abstract (translated by Google)
随着现代互联网用户的关注度不断下降，在线内容（如新闻文章或视频）的标题可能是决定其受欢迎程度的主要因素。为了利用这一现象，我们提出了一种基于双向长时间短期记忆（LSTM）神经网络的新方法，该方法设计为仅使用其标题来预测在线内容的普及。我们在新闻文章和新闻视频的两个不同的数据集上评估拟议的架构，这些数据集分布在社交媒体上，总共包含4万多个样本。在这些数据集上，我们的方法使传统浅层方法的性能提高了15％。此外，我们表明，在嵌入层中使用预先训练的单词向量改善了LSTM模型的结果，特别是当训练集小时。就我们所知，这是仅使用标题中的文本信息来应用流行预测的第一次尝试。

##### URL
[https://arxiv.org/abs/1707.06806](https://arxiv.org/abs/1707.06806)

##### PDF
[https://arxiv.org/pdf/1707.06806](https://arxiv.org/pdf/1707.06806)

