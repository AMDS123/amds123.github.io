---
layout: post
title: "Multimodal Affective Analysis Using Hierarchical Attention Strategy with Word-Level Alignment"
date: 2018-05-22 15:25:29
categories: arXiv_CL
tags: arXiv_CL Sentiment Attention
author: Yue Gu, Kangning Yang, Shiyu Fu, Shuhong Chen, Xinyu Li, Ivan Marsic
mathjax: true
---

* content
{:toc}

##### Abstract
Multimodal affective computing, learning to recognize and interpret human affects and subjective information from multiple data sources, is still challenging because: (i) it is hard to extract informative features to represent human affects from heterogeneous inputs; (ii) current fusion strategies only fuse different modalities at abstract level, ignoring time-dependent interactions between modalities. Addressing such issues, we introduce a hierarchical multimodal architecture with attention and word-level fusion to classify utter-ance-level sentiment and emotion from text and audio data. Our introduced model outperforms the state-of-the-art approaches on published datasets and we demonstrated that our model is able to visualize and interpret the synchronized attention over modalities.

##### Abstract (translated by Google)
多模式情感计算，学习识别和解释来自多个数据源的人类影响和主观信息，仍然具有挑战性，因为：（i）很难从异构输入中提取信息特征来表示人类影响; （ii）当前的融合策略仅在抽象层面融合不同的模态，忽略模态之间的时间相关的相互作用。为了解决这些问题，我们引入了一种分级多模式架构，将注意力和词汇级别融合，从文本和音频数据中分类出完整的情感和情感。我们推出的模型比已发表的数据集上的最新方法优越，并且我们证明了我们的模型能够可视化和解释对模态的同步关注。

##### URL
[https://arxiv.org/abs/1805.08660](https://arxiv.org/abs/1805.08660)

##### PDF
[https://arxiv.org/pdf/1805.08660](https://arxiv.org/pdf/1805.08660)

