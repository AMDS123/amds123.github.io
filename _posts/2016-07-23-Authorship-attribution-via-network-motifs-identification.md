---
layout: post
title: "Authorship attribution via network motifs identification"
date: 2016-07-23 19:07:53
categories: arXiv_CL
tags: arXiv_CL Summarization Classification
author: Vanessa Queiroz Marinho, Graeme Hirst, Diego Raphael Amancio
mathjax: true
---

* content
{:toc}

##### Abstract
Concepts and methods of complex networks can be used to analyse texts at their different complexity levels. Examples of natural language processing (NLP) tasks studied via topological analysis of networks are keyword identification, automatic extractive summarization and authorship attribution. Even though a myriad of network measurements have been applied to study the authorship attribution problem, the use of motifs for text analysis has been restricted to a few works. The goal of this paper is to apply the concept of motifs, recurrent interconnection patterns, in the authorship attribution task. The absolute frequencies of all thirteen directed motifs with three nodes were extracted from the co-occurrence networks and used as classification features. The effectiveness of these features was verified with four machine learning methods. The results show that motifs are able to distinguish the writing style of different authors. In our best scenario, 57.5% of the books were correctly classified. The chance baseline for this problem is 12.5%. In addition, we have found that function words play an important role in these recurrent patterns. Taken together, our findings suggest that motifs should be further explored in other related linguistic tasks.

##### Abstract (translated by Google)
复杂网络的概念和方法可用于分析不同复杂程度的文本。通过网络拓扑分析研究的自然语言处理（NLP）任务的例子是关键字识别，自动提取汇总和作者归属。尽管已经应用了大量的网络测量来研究作者归属问题，但是用于文本分析的图案的使用仅限于几个作品。本文的目标是在作者归属任务中运用主题概念，经常性互连模式。从共现网络中提取所有13个具有3个节点的定向图案的绝对频率，并将其用作分类特征。这四个机器学习方法验证了这些特征的有效性。结果表明，图案能够区分不同作者的写作风格。在我们最好的情况下，57.5％的书被正确分类。这个问题的机会基线是12.5％。另外，我们发现函数词在这些循环模式中起着重要的作用。综合起来，我们的研究结果表明，主题应进一步探讨其他相关的语言任务。

##### URL
[https://arxiv.org/abs/1607.06961](https://arxiv.org/abs/1607.06961)

##### PDF
[https://arxiv.org/pdf/1607.06961](https://arxiv.org/pdf/1607.06961)

