---
layout: post
title: "Deep-Reinforcement-Learning for Gliding and Perching Bodies"
date: 2018-07-07 08:49:50
categories: arXiv_RO
tags: arXiv_RO Knowledge Reinforcement_Learning
author: Guido Novati, Lakshminarayanan Mahadevan, Petros Koumoutsakos
mathjax: true
---

* content
{:toc}

##### Abstract
Controlled gliding is one of the most energetically efficient modes of transportation for natural and human powered fliers. Here we demonstrate that gliding and landing strategies with different optimality criteria can be identified through deep reinforcement learning without explicit knowledge of the underlying physics. We combine a two dimensional model of a controlled elliptical body with deep reinforcement learning (D-RL) to achieve gliding with either minimum energy expenditure, or fastest time of arrival, at a predetermined location. In both cases the gliding trajectories are smooth, although energy/time optimal strategies are distinguished by small/high frequency actuations. We examine the effects of the ellipse's shape and weight on the optimal policies for controlled gliding. Surprisingly, we find that the model-free reinforcement learning leads to more robust gliding than model-based optimal control strategies with a modest additional computational cost. We also demonstrate that the gliders with D-RL can generalize their strategies to reach the target location from previously unseen starting positions. The model-free character and robustness of D-RL suggests a promising framework for developing mechanical devices capable of exploiting complex flow environments.

##### Abstract (translated by Google)
受控制的滑翔是天然和人力动力飞行器最具能量效率的运输方式之一。在这里，我们证明了具有不同最优性标准的滑行和着陆策略可以通过深度强化学习来识别，而无需明确了解基础物理。我们将受控椭圆体的二维模型与深度强化学习（D-RL）相结合，以在预定位置实现最小能量消耗或最快到达时间的滑行。在两种情况下，滑行轨迹都是平滑的，尽管通过小/高频致动来区分能量/时间最优策略。我们研究了椭圆的形状和重量对受控滑翔的最优策略的影响。令人惊讶的是，我们发现无模型强化学习比基于模型的最优控制策略导致更强大的滑动，并且具有适度的额外计算成本。我们还证明了具有D-RL的滑翔机可以推广其策略以从先前看不见的起始位置到达目标位置。 D-RL的无模型特性和鲁棒性为开发能够利用复杂流动环境的机械设备提供了一个有前景的框架。

##### URL
[http://arxiv.org/abs/1807.03671](http://arxiv.org/abs/1807.03671)

##### PDF
[http://arxiv.org/pdf/1807.03671](http://arxiv.org/pdf/1807.03671)

