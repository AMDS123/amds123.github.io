---
layout: post
title: "Predicting the Driver's Focus of Attention: the DRVE Project"
date: 2017-11-17 15:17:59
categories: arXiv_CV
tags: arXiv_CV Attention Tracking
author: Andrea Palazzi, Davide Abati, Simone Calderara, Francesco Solera, Rita Cucchiara
mathjax: true
---

* content
{:toc}

##### Abstract
In this work we aim to predict the driver's focus of attention. The goal is to estimate what a person would pay attention to while driving, and which part of the scene around the vehicle is more critical for the task. To this end we propose a new computer vision model based on a multi-branch deep architecture that integrates three sources of information: raw video, motion and scene semantics. We also introduce DR(eye)VE, the largest dataset of driving scenes for which eye-tracking annotations are available. This dataset features more than 500,000 registered frames, matching ego-centric views (from glasses worn by drivers) and car-centric views (from roof-mounted camera), further enriched by other sensors measurements. Results highlight that several attention patterns are shared across drivers and can be reproduced to some extent. The indication of which elements in the scene are likely to capture the driver's attention may benefit several applications in the context of human-vehicle interaction and driver attention analysis.

##### Abstract (translated by Google)
在这项工作中，我们旨在预测驾驶员关注的焦点。目标是估计一个人在开车的时候会注意什么，车辆周围的哪个部分对于这个任务更重要。为此，我们提出了一种新的基于多分支深层架构的计算机视觉模型，该架构集成了三种信息源：原始视频，运动和场景语义。我们还介绍了DR（眼睛）VE，这是驾驶场景的最大数据集，可以使用眼动追踪注释。这个数据集具有超过500,000个注册框架，匹配以自我为中心的视角（来自驾驶员佩戴的眼镜）和以汽车为中心的视角（来自屋顶摄像头），并通过其他传感器测量进一步丰富。结果强调了几种注意模式在司机之间共享，可以在一定程度上复制。在人车交互和驾驶员注意力分析的背景下，场景中哪些元素可能捕捉驾驶员注意力的指示可以受益。

##### URL
[https://arxiv.org/abs/1705.03854](https://arxiv.org/abs/1705.03854)

##### PDF
[https://arxiv.org/pdf/1705.03854](https://arxiv.org/pdf/1705.03854)

