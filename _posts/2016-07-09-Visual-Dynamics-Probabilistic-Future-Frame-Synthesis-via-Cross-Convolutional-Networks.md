---
layout: post
title: "Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks"
date: 2016-07-09 08:41:40
categories: arXiv_CV
tags: arXiv_CV CNN
author: Tianfan Xue, Jiajun Wu, Katherine L. Bouman, William T. Freeman
mathjax: true
---

* content
{:toc}

##### Abstract
We study the problem of synthesizing a number of likely future frames from a single input image. In contrast to traditional methods, which have tackled this problem in a deterministic or non-parametric way, we propose a novel approach that models future frames in a probabilistic manner. Our probabilistic model makes it possible for us to sample and synthesize many possible future frames from a single input image. Future frame synthesis is challenging, as it involves low- and high-level image and motion understanding. We propose a novel network structure, namely a Cross Convolutional Network to aid in synthesizing future frames; this network structure encodes image and motion information as feature maps and convolutional kernels, respectively. In experiments, our model performs well on synthetic data, such as 2D shapes and animated game sprites, as well as on real-wold videos. We also show that our model can be applied to tasks such as visual analogy-making, and present an analysis of the learned network representations.

##### Abstract (translated by Google)
我们研究从单个输入图像综合一些可能的未来帧的问题。与以确定性或非参数化方式解决这个问题的传统方法相比，我们提出了一种以概率方式对未来帧进行建模的新方法。我们的概率模型使我们有可能从单个输入图像中采样和合成许多可能的未来帧。未来的帧合成是具有挑战性的，因为它涉及低级和高级的图像和运动的理解。我们提出了一个新的网络结构，即一个交叉卷积网络来帮助合成未来的帧;该网络结构分别将图像和运动信息编码为特征映射和卷积核。在实验中，我们的模型在合成数据（例如二维形状和动画游戏精灵）以及真实视频视频上表现良好。我们还表明，我们的模型可以应用于视觉类比制作等任务，并对学习到的网络表示进行分析。

##### URL
[https://arxiv.org/abs/1607.02586](https://arxiv.org/abs/1607.02586)

##### PDF
[https://arxiv.org/pdf/1607.02586](https://arxiv.org/pdf/1607.02586)

