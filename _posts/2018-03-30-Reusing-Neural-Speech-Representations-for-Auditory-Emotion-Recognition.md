---
layout: post
title: "Reusing Neural Speech Representations for Auditory Emotion Recognition"
date: 2018-03-30 15:18:20
categories: arXiv_CL
tags: arXiv_CL Transfer_Learning Classification Recognition
author: Egor Lakomkin, Cornelius Weber, Sven Magg, Stefan Wermter
mathjax: true
---

* content
{:toc}

##### Abstract
Acoustic emotion recognition aims to categorize the affective state of the speaker and is still a difficult task for machine learning models. The difficulties come from the scarcity of training data, general subjectivity in emotion perception resulting in low annotator agreement, and the uncertainty about which features are the most relevant and robust ones for classification. In this paper, we will tackle the latter problem. Inspired by the recent success of transfer learning methods we propose a set of architectures which utilize neural representations inferred by training on large speech databases for the acoustic emotion recognition task. Our experiments on the IEMOCAP dataset show ~10% relative improvements in the accuracy and F1-score over the baseline recurrent neural network which is trained end-to-end for emotion recognition.

##### Abstract (translated by Google)
声学情感识别旨在对讲话者的情感状态进行分类，并且对于机器学习模型仍然是一项艰巨的任务。困难来自训练数据的稀缺性，情绪感知的一般主观性导致了低的注释者协议，以及关于哪些特征是用于分类的最相关和强健的特征的不确定性。在本文中，我们将解决后一个问题。受近期转移学习方法的成功启发，我们提出了一套架构，其利用通过对大型语音数据库的训练推断出的神经表示来进行声学情感识别任务。我们在IEMOCAP数据集上进行的实验显示，相对于基线递归神经网络而言，精确度和F1分数相对提高了10％，这是经过端对端训练的情绪识别。

##### URL
[http://arxiv.org/abs/1803.11508](http://arxiv.org/abs/1803.11508)

##### PDF
[http://arxiv.org/pdf/1803.11508](http://arxiv.org/pdf/1803.11508)

