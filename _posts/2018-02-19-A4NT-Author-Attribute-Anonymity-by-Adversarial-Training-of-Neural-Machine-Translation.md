---
layout: post
title: "$A^{4}NT$: Author Attribute Anonymity by Adversarial Training of Neural Machine Translation"
date: 2018-02-19 10:37:27
categories: arXiv_CL
tags: arXiv_CL Adversarial GAN Language_Model
author: Rakshith Shetty, Bernt Schiele, Mario Fritz
mathjax: true
---

* content
{:toc}

##### Abstract
Text-based analysis methods allow to reveal privacy relevant author attributes such as gender, age and identify of the text's author. Such methods can compromise the privacy of an anonymous author even when the author tries to remove privacy sensitive content. In this paper, we propose an automatic method, called Adversarial Author Attribute Anonymity Neural Translation ($A^4NT$), to combat such text-based adversaries. We combine sequence-to-sequence language models used in machine translation and generative adversarial networks to obfuscate author attributes. Unlike machine translation techniques which need paired data, our method can be trained on unpaired corpora of text containing different authors. Importantly, we propose and evaluate techniques to impose constraints on our $A^4NT$ to preserve the semantics of the input text. $A^4NT$ learns to make minimal changes to the input text to successfully fool author attribute classifiers, while aiming to maintain the meaning of the input. We show through experiments on two different datasets and three settings that our proposed method is effective in fooling the author attribute classifiers and thereby improving the anonymity of authors.

##### Abstract (translated by Google)
基于文本的分析方法可以揭示隐私相关作者的属性，如性别，年龄和文本作者的身份。即使作者试图删除隐私敏感内容，此类方法也可能会危害匿名作者的隐私。在本文中，我们提出了一种自动方法，称为敌对作者属性匿名神经翻译（$ A ^ 4NT $），以对付这种基于文本的对手。我们将机器翻译中使用的序列到序列语言模型和生成对抗网络结合起来以混淆作者属性。与需要配对数据的机器翻译技术不同，我们的方法可以在包含不同作者的不成对的文本语料库上进行训练。重要的是，我们提出并评估技术来强制约束我们的$ A ^ 4NT $以保留输入文本的语义。 $ A ^ 4NT $学习对输入文本进行最小限度的更改，以成功欺骗作者属性分类器，同时保持输入的含义。我们通过两个不同的数据集和三个设置的实验显示，我们提出的方法可以有效地愚弄作者属性分类器，从而提高作者的匿名性。

##### URL
[http://arxiv.org/abs/1711.01921](http://arxiv.org/abs/1711.01921)

##### PDF
[http://arxiv.org/pdf/1711.01921](http://arxiv.org/pdf/1711.01921)

