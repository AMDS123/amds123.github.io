---
layout: post
title: "Real-world Multi-object, Multi-grasp Detection"
date: 2018-07-20 21:02:09
categories: arXiv_RO
tags: arXiv_RO Classification Deep_Learning Detection
author: Fu-Jen Chu, Ruinian Xu, Patricio A. Vela
mathjax: true
---

* content
{:toc}

##### Abstract
A deep learning architecture is proposed to predict graspable locations for robotic manipulation. It considers situations where no, one, or multiple object(s) are seen. By defining the learning problem to be classification with null hypothesis competition instead of regression, the deep neural network with RGB-D image input predicts multiple grasp candidates for a single object or multiple objects, in a single shot. The method outperforms state-of-the-art approaches on the Cornell dataset with 96.0% and 96.1% accuracy on image-wise and object- wise splits, respectively. Evaluation on a multi-object dataset illustrates the generalization capability of the architecture. Grasping experiments achieve 96.0% grasp localization and 88.0% grasping success rates on a test set of household objects. The real-time process takes less than .25 s from image to plan.

##### Abstract (translated by Google)
提出了深度学习架构来预测机器人操纵的可抓握位置。它考虑了看不到，一个或多个对象的情况。通过将学习问题定义为使用零假设竞争而不是回归的分类，具有RGB-D图像输入的深度神经网络在单次拍摄中预测单个对象或多个对象的多个抓握候选。该方法优于Cornell数据集的最新方法，分别在图像和对象分割上具有96.0％和96.1％的准确度。对多对象数据集的评估说明了该体系结构的泛化能力。抓取实验在一组家用物品上实现了96.0％的掌握定位和88.0％的抓握成功率。从图像到计划，实时过程需要不到0.25秒。

##### URL
[http://arxiv.org/abs/1802.00520](http://arxiv.org/abs/1802.00520)

##### PDF
[http://arxiv.org/pdf/1802.00520](http://arxiv.org/pdf/1802.00520)

