---
layout: post
title: "Captioning Images with Diverse Objects"
date: 2017-07-20 18:06:27
categories: arXiv_CV
tags: arXiv_CV Knowledge Caption Embedding Recognition
author: Subhashini Venugopalan, Lisa Anne Hendricks, Marcus Rohrbach, Raymond Mooney, Trevor Darrell, Kate Saenko
mathjax: true
---

* content
{:toc}

##### Abstract
Recent captioning models are limited in their ability to scale and describe concepts unseen in paired image-text corpora. We propose the Novel Object Captioner (NOC), a deep visual semantic captioning model that can describe a large number of object categories not present in existing image-caption datasets. Our model takes advantage of external sources -- labeled images from object recognition datasets, and semantic knowledge extracted from unannotated text. We propose minimizing a joint objective which can learn from these diverse data sources and leverage distributional semantic embeddings, enabling the model to generalize and describe novel objects outside of image-caption datasets. We demonstrate that our model exploits semantic information to generate captions for hundreds of object categories in the ImageNet object recognition dataset that are not observed in MSCOCO image-caption training data, as well as many categories that are observed very rarely. Both automatic evaluations and human judgements show that our model considerably outperforms prior work in being able to describe many more categories of objects.

##### Abstract (translated by Google)
最近的字幕模型在对配对的图像文本语料库中看不见的概念进行缩放和描述的能力方面受到限制。我们提出了新颖的对象字幕（NOC），一个深层的视觉语义字幕模型，可以描述大量的不存在于现有的图像 - 字幕数据集的对象类别。我们的模型利用外部来源 - 来自对象识别数据集的标记图像，以及从未注释文本中提取的语义知识。我们提出最小化一个联合目标，可以从这些不同的数据源学习和利用分布式语义嵌入，使模型推广和描述图像 - 字幕数据集之外的新的对象。我们证明，我们的模型利用语义信息来为ImageNet对象识别数据集中的数百个对象类别生成字幕，这些字幕在MSCOCO图像字幕训练数据中未被观察到，以及很少被观察到的许多类别。自动评估和人类判断都表明，我们的模型在描述更多类别的对象方面大大优于先前的工作。

##### URL
[https://arxiv.org/abs/1606.07770](https://arxiv.org/abs/1606.07770)

##### PDF
[https://arxiv.org/pdf/1606.07770](https://arxiv.org/pdf/1606.07770)

