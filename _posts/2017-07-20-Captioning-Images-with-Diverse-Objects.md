---
layout: post
title: "Captioning Images with Diverse Objects"
date: 2017-07-20 18:06:27
categories: arXiv_CV
tags: arXiv_CV Image_Caption Knowledge Caption Embedding Recognition
author: Subhashini Venugopalan, Lisa Anne Hendricks, Marcus Rohrbach, Raymond Mooney, Trevor Darrell, Kate Saenko
mathjax: true
---

* content
{:toc}

##### Abstract
Recent captioning models are limited in their ability to scale and describe concepts unseen in paired image-text corpora. We propose the Novel Object Captioner (NOC), a deep visual semantic captioning model that can describe a large number of object categories not present in existing image-caption datasets. Our model takes advantage of external sources -- labeled images from object recognition datasets, and semantic knowledge extracted from unannotated text. We propose minimizing a joint objective which can learn from these diverse data sources and leverage distributional semantic embeddings, enabling the model to generalize and describe novel objects outside of image-caption datasets. We demonstrate that our model exploits semantic information to generate captions for hundreds of object categories in the ImageNet object recognition dataset that are not observed in MSCOCO image-caption training data, as well as many categories that are observed very rarely. Both automatic evaluations and human judgements show that our model considerably outperforms prior work in being able to describe many more categories of objects.

##### Abstract (translated by Google)
最近的字幕模型在缩放和描述配对图像 - 文本语料库中未见的概念方面受到限制。我们提出了新的对象捕获器（NOC），这是一种深度可视语义字幕模型，可以描述现有图像标题数据集中不存在的大量对象类别。我们的模型利用外部资源 - 来自对象识别数据集的标记图像，以及从未注释文本中提取的语义知识。我们建议最小化一个联合目标，该目标可以从这些不同的数据源中学习并利用分布式语义嵌入，使模型能够概括和描述图像标题数据集之外的新对象。我们证明了我们的模型利用语义信息为ImageNet对象识别数据集中的数百个对象类别生成了在MSCOCO图像标题训练数据中未观察到的标题，以及很少观察到的许多类别。自动评估和人工判断都表明，我们的模型在描述更多类别的对象方面远远优于以前的工作。

##### URL
[https://arxiv.org/abs/1606.07770](https://arxiv.org/abs/1606.07770)

##### PDF
[https://arxiv.org/pdf/1606.07770](https://arxiv.org/pdf/1606.07770)

