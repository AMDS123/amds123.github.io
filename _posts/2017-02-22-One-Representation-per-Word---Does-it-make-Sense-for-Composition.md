---
layout: post
title: "One Representation per Word - Does it make Sense for Composition?"
date: 2017-02-22 07:41:08
categories: arXiv_SD
tags: arXiv_SD
author: Thomas Kober, Julie Weeds, John Wilkie, Jeremy Reffin, David Weir
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we investigate whether an a priori disambiguation of word senses is strictly necessary or whether the meaning of a word in context can be disambiguated through composition alone. We evaluate the performance of off-the-shelf single-vector and multi-sense vector models on a benchmark phrase similarity task and a novel task for word-sense discrimination. We find that single-sense vector models perform as well or better than multi-sense vector models despite arguably less clean elementary representations. Our findings furthermore show that simple composition functions such as pointwise addition are able to recover sense specific information from a single-sense vector model remarkably well.

##### Abstract (translated by Google)
在本文中，我们调查是否严格需要先验消歧的单词感或是否单词的含义可以通过组成单独消歧。我们评估现成的单向量和多向量向量模型在基准短语相似性任务上的表现以及用于词义歧视的新任务。我们发现单向矢量模型的表现与多义向量模型一样好或者更好，尽管可以说是不太清晰的基本表示。我们的发现进一步表明，简单的组合功能，如逐点加法，能够从单义向量模型中很好地恢复感知特定的信息。

##### URL
[https://arxiv.org/abs/1702.06696](https://arxiv.org/abs/1702.06696)

##### PDF
[https://arxiv.org/pdf/1702.06696](https://arxiv.org/pdf/1702.06696)

