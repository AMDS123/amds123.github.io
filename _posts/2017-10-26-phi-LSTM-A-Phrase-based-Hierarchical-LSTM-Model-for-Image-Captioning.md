---
layout: post
title: "phi-LSTM: A Phrase-based Hierarchical LSTM Model for Image Captioning"
date: 2017-10-26 15:16:57
categories: arXiv_CL
tags: arXiv_CL Image_Caption Caption CNN RNN Relation
author: Ying Hua Tan, Chee Seng Chan
mathjax: true
---

* content
{:toc}

##### Abstract
A picture is worth a thousand words. Not until recently, however, we noticed some success stories in understanding of visual scenes: a model that is able to detect/name objects, describe their attributes, and recognize their relationships/interactions. In this paper, we propose a phrase-based hierarchical Long Short-Term Memory (phi-LSTM) model to generate image description. The proposed model encodes sentence as a sequence of combination of phrases and words, instead of a sequence of words alone as in those conventional solutions. The two levels of this model are dedicated to i) learn to generate image relevant noun phrases, and ii) produce appropriate image description from the phrases and other words in the corpus. Adopting a convolutional neural network to learn image features and the LSTM to learn the word sequence in a sentence, the proposed model has shown better or competitive results in comparison to the state-of-the-art models on Flickr8k and Flickr30k datasets.

##### Abstract (translated by Google)
一张图片胜过千言万语。然而，直到最近，我们才注意到了一些关于视觉场景理解的成功案例：一种能够检测/命名对象，描述其属性并识别其关系/交互的模型。在本文中，我们提出了一种基于短语的分层长短期记忆（phi-LSTM）模型来生成图像描述。所提出的模型将句子编码为短语和单词组合的序列，而不是如在那些常规解决方案中单独的单词序列。这个模型的两个级别致力于：i）学习生成图像相关的名词短语，以及ii）从语料库中的短语和其他词中产生适当的图像描述。采用卷积神经网络学习图像特征和LSTM来学习句子中的单词序列，与Flickr8k和Flickr30k数据集上的最新模型相比，所提出的模型显示出更好或更具竞争力的结果。

##### URL
[https://arxiv.org/abs/1608.05813](https://arxiv.org/abs/1608.05813)

##### PDF
[https://arxiv.org/pdf/1608.05813](https://arxiv.org/pdf/1608.05813)

