---
layout: post
title: "On Dropout and Nuclear Norm Regularization"
date: 2019-05-28 15:31:51
categories: arXiv_AI
tags: arXiv_AI Regularization
author: Poorya Mianjy, Raman Arora
mathjax: true
---

* content
{:toc}

##### Abstract
We give a formal and complete characterization of the explicit regularizer induced by dropout in deep linear networks with squared loss. We show that (a) the explicit regularizer is composed of an $\ell_2$-path regularizer and other terms that are also re-scaling invariant, (b) the convex envelope of the induced regularizer is the squared nuclear norm of the network map, and (c) for a sufficiently large dropout rate, we characterize the global optima of the dropout objective. We validate our theoretical findings with empirical results.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.11887](http://arxiv.org/abs/1905.11887)

##### PDF
[http://arxiv.org/pdf/1905.11887](http://arxiv.org/pdf/1905.11887)

