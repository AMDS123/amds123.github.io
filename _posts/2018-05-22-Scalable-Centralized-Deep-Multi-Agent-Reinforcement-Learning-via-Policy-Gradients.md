---
layout: post
title: "Scalable Centralized Deep Multi-Agent Reinforcement Learning via Policy Gradients"
date: 2018-05-22 00:31:03
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization
author: Arbaaz Khan, Clark Zhang, Daniel D. Lee, Vijay Kumar, Alejandro Ribeiro
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we explore using deep reinforcement learning for problems with multiple agents. Most existing methods for deep multi-agent reinforcement learning consider only a small number of agents. When the number of agents increases, the dimensionality of the input and control spaces increase as well, and these methods do not scale well. To address this, we propose casting the multi-agent reinforcement learning problem as a distributed optimization problem. Our algorithm assumes that for multi-agent settings, policies of individual agents in a given population live close to each other in parameter space and can be approximated by a single policy. With this simple assumption, we show our algorithm to be extremely effective for reinforcement learning in multi-agent settings. We demonstrate its effectiveness against existing comparable approaches on co-operative and competitive tasks.

##### Abstract (translated by Google)
在本文中，我们将探索使用深度强化学习来解决多个代理的问题。大多数现有的深度多智能体强化学习方法只考虑少数代理。当代理人数量增加时，输入和控制空间的维度也会增加，而这些方法不能很好地扩展。为了解决这个问题，我们提出将多代理强化学习问题作为分布式优化问题。我们的算法假设对于多智能体设置，给定人群中各个智能体的策略在参数空间中彼此靠近，并且可以通过单个策略来近似。通过这个简单的假设，我们展示了我们的算法对于多代理设置中的强化学习非常有效。我们在合作和竞争性任务中与现有的可比较方法展示其有效性。

##### URL
[http://arxiv.org/abs/1805.08776](http://arxiv.org/abs/1805.08776)

##### PDF
[http://arxiv.org/pdf/1805.08776](http://arxiv.org/pdf/1805.08776)

