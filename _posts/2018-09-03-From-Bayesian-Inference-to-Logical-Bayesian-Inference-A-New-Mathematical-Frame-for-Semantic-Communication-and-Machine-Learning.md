---
layout: post
title: "From Bayesian Inference to Logical Bayesian Inference: A New Mathematical Frame for Semantic Communication and Machine Learning"
date: 2018-09-03 11:39:11
categories: arXiv_AI
tags: arXiv_AI Inference Classification Prediction
author: Chenguang Lu
mathjax: true
---

* content
{:toc}

##### Abstract
Bayesian Inference (BI) uses the Bayes' posterior whereas Logical Bayesian Inference (LBI) uses the truth function or membership function as the inference tool. LBI was proposed because BI was not compatible with the classical Bayes' prediction and didn't use logical probability and hence couldn't express semantic meaning. In LBI, statistical probability and logical probability are strictly distinguished, used at the same time, and linked by the third kind of Bayes' Theorem. The Shannon channel consists of a set of transition probability functions whereas the semantic channel consists of a set of truth functions. When a sample is large enough, we can directly derive the semantic channel from Shannon's channel. Otherwise, we can use parameters to construct truth functions and use the Maximum Semantic Information (MSI) criterion to optimize the truth functions. The MSI criterion is equivalent to the Maximum Likelihood (ML) criterion, and compatible with the Regularized Least Square (RLS) criterion. By matching the two channels one with another, we can obtain the Channels' Matching (CM) algorithm. This algorithm can improve multi-label classifications, maximum likelihood estimations (including unseen instance classifications), and mixture models. In comparison with BI, LBI 1) uses the prior P(X) of X instead of that of Y or {\theta} and fits cases where the source P(X) changes, 2) can be used to solve the denotations of labels, and 3) is more compatible with the classical Bayes' prediction and likelihood method. LBI also provides a confirmation measure between -1 and 1 for induction.

##### Abstract (translated by Google)
贝叶斯推理（BI）使用贝叶斯后验，而逻辑贝叶斯推理（LBI）使用真值函数或隶属函数作为推理工具。提出LBI是因为BI与经典的贝叶斯预测不兼容，并且没有使用逻辑概率，因此无法表达语义。在LBI中，统计概率和逻辑概率被严格区分，同时使用，并由第三种贝叶斯定理联系起来。香农通道由一组转移概率函数组成，而语义通道由一组真值函数组成。当样本足够大时，我们可以直接从香农的频道中导出语义信道。否则，我们可以使用参数来构造真值函数，并使用最大语义信息（MSI）标准来优化真值函数。 MSI标准等同于最大似然（ML）标准，并且与规则化最小二乘（RLS）标准兼容。通过将两个通道相互匹配，我们可以获得通道匹配（CM）算法。该算法可以改进多标签分类，最大似然估计（包括看不见的实例分类）和混合模型。与BI相比，LBI 1）使用X的先前P（X）而不是Y或{\ theta}，并且适用于源P（X）改变的情况，2）可用于解决标签的表示，和3）更符合经典的贝叶斯预测和似然法。 LBI还提供-1和1之间的确认测量，用于诱导。

##### URL
[http://arxiv.org/abs/1809.01577](http://arxiv.org/abs/1809.01577)

##### PDF
[http://arxiv.org/pdf/1809.01577](http://arxiv.org/pdf/1809.01577)

