---
layout: post
title: "Image2GIF: Generating Cinemagraphs using Recurrent Deep Q-Networks"
date: 2018-01-27 05:48:20
categories: arXiv_CV
tags: arXiv_CV Quantitative
author: Yipin Zhou, Yale Song, Tamara L. Berg
mathjax: true
---

* content
{:toc}

##### Abstract
Given a still photograph, one can imagine how dynamic objects might move against a static background. This idea has been actualized in the form of cinemagraphs, where the motion of particular objects within a still image is repeated, giving the viewer a sense of animation. In this paper, we learn computational models that can generate cinemagraph sequences automatically given a single image. To generate cinemagraphs, we explore combining generative models with a recurrent neural network and deep Q-networks to enhance the power of sequence generation. To enable and evaluate these models we make use of two datasets, one synthetically generated and the other containing real video generated cinemagraphs. Both qualitative and quantitative evaluations demonstrate the effectiveness of our models on the synthetic and real datasets.

##### Abstract (translated by Google)
给定一个静止的照片，可以想象动态对象如何在静态背景下移动。这个想法已经以电影图形的形式实现了，静止图像内的特定对象的运动被重复，给观看者一个动画的感觉。在本文中，我们学习计算模型，可以自动生成一个单一的图像cinemagraph序列。为了生成电影图形，我们探索将生成模型与递归神经网络和深度Q网络相结合来增强序列生成的能力。为了启用和评估这些模型，我们使用了两个数据集，一个是合成生成的，另一个是包含真实视频生成的电影图。定性和定量评估都证明了我们的模型在合成和真实数据集上的有效性。

##### URL
[http://arxiv.org/abs/1801.09042](http://arxiv.org/abs/1801.09042)

##### PDF
[http://arxiv.org/pdf/1801.09042](http://arxiv.org/pdf/1801.09042)

