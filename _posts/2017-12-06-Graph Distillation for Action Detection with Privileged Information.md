---
layout: post
title: 'Graph Distillation for Action Detection with Privileged Information'
date: 2017-12-06 01:34:45
categories: arXiv_CV
tags: arXiv_CV Detection
author: Zelun Luo, Lu Jiang, Jun-Ting Hsieh, Juan Carlos Niebles, Li Fei-Fei
---

* content
{:toc}

##### Abstract
In this work, we propose a technique that tackles the video understanding problem under a realistic, demanding condition in which we have limited labeled data and partially observed training modalities. Common methods such as transfer learning do not take advantage of the rich information from extra modalities potentially available in the source domain dataset. On the other hand, previous work on cross-modality learning only focuses on a single domain or task. In this work, we propose a graph-based distillation method that incorporates rich privileged information from a large multi-modal dataset in the source domain, and shows an improved performance in the target domain where data is scarce. Leveraging both a large-scale dataset and its extra modalities, our method learns a better model for temporal action detection and action classification without needing to have access to these modalities during test time. We evaluate our approach on action classification and temporal action detection tasks, and show that our models achieve the state-of-the-art performance on the PKU-MMD and NTU RGB+D datasets.

##### Abstract (translated by Google)
在这项工作中，我们提出了一个解决视频理解问题的技术，在一个现实的，苛刻的条件下，我们有有限的标记数据和部分观察训练模态。传统学习等常用方法不利用源域数据集中潜在可用模式的丰富信息。另一方面，以前关于跨模态学习的研究只关注单个领域或任务。在这项工作中，我们提出了一种基于图形的精馏方法，它将来自源域中的大型多模式数据集的丰富特权信息合并在一起，并且在数据稀缺的目标域中显示出改进的性能。利用大规模数据集及其额外的模式，我们的方法学习一个更好的时间动作检测和行动分类模型，而不需要在测试时间访问这些模式。我们评估我们的行动分类和时间动作检测任务的方法，并显示我们的模型在PKU-MMD和NTU RGB + D数据集上实现了最先进的性能。

##### URL
[https://arxiv.org/abs/1712.00108](https://arxiv.org/abs/1712.00108)

