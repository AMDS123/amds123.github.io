---
layout: post
title: "Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification"
date: 2016-11-28 17:48:04
categories: arXiv_CV
tags: arXiv_CV CNN Classification
author: Justin Salamon, Juan Pablo Bello
mathjax: true
---

* content
{:toc}

##### Abstract
The ability of deep convolutional neural networks (CNN) to learn discriminative spectro-temporal patterns makes them well suited to environmental sound classification. However, the relative scarcity of labeled data has impeded the exploitation of this family of high-capacity models. This study has two primary contributions: first, we propose a deep convolutional neural network architecture for environmental sound classification. Second, we propose the use of audio data augmentation for overcoming the problem of data scarcity and explore the influence of different augmentations on the performance of the proposed CNN architecture. Combined with data augmentation, the proposed model produces state-of-the-art results for environmental sound classification. We show that the improved performance stems from the combination of a deep, high-capacity model and an augmented training set: this combination outperforms both the proposed CNN without augmentation and a "shallow" dictionary learning model with augmentation. Finally, we examine the influence of each augmentation on the model's classification accuracy for each class, and observe that the accuracy for each class is influenced differently by each augmentation, suggesting that the performance of the model could be improved further by applying class-conditional data augmentation.

##### Abstract (translated by Google)
深卷积神经网络（CNN）能够学习辨别的时空模式，使得它们非常适合于环境声音的分类。然而，标签数据的相对稀缺阻碍了这一系列高容量模型的开发。这项研究有两个主要贡献：首先，我们提出了一个深度卷积神经网络架构的环境声音分类。其次，我们提出使用音频数据增强来克服数据稀缺问题，并探讨不同增强对CNN体系结构性能的影响。结合数据增强，所提出的模型产生了用于环境声音分类的最先进的结果。我们表明，改进的性能源于深层，高容量模型和增强训练集合的组合：该组合优于提出的CNN而没有增强和具有增强的“浅”字典学习模型。最后，我们考察了每个增量对每个类的模型分类精度的影响，并且观察到每个类的准确性受到每个增量的不同影响，表明通过应用类条件数据可以进一步提高模型的性能增强。

##### URL
[https://arxiv.org/abs/1608.04363](https://arxiv.org/abs/1608.04363)

##### PDF
[https://arxiv.org/pdf/1608.04363](https://arxiv.org/pdf/1608.04363)

