---
layout: post
title: "Cascaded CNN-resBiLSTM-CTC: An End-to-End Acoustic Model For Speech Recognition"
date: 2018-10-30 11:13:35
categories: arXiv_CL
tags: arXiv_CL Attention Speech_Recognition RNN Deep_Learning Language_Model Recognition
author: Xinpei Zhou, Jiwei Li, Xi Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
Automatic speech recognition (ASR) tasks are resolved by end-to-end deep learning models, which benefits us by less preparation of raw data, and easier transformation between languages. We propose a novel end-to-end deep learning model architecture namely cascaded CNN-resBiLSTM-CTC. In the proposed model, we add residual blocks in BiLSTM layers to extract sophisticated phoneme and semantic information together, and apply cascaded structure to pay more attention mining information of hard negative samples. By applying both simple Fast Fourier Transform (FFT) technique and n-gram language model (LM) rescoring method, we manage to achieve word error rate (WER) of 3.41% on LibriSpeech test clean corpora. Furthermore, we propose a new batch-varied method to speed up the training process in length-varied tasks, which result in 25% less training time.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.12001](http://arxiv.org/abs/1810.12001)

##### PDF
[http://arxiv.org/pdf/1810.12001](http://arxiv.org/pdf/1810.12001)

