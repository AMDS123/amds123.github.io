---
layout: post
title: "A Structured Self-attentive Sentence Embedding"
date: 2017-03-09 04:42:30
categories: arXiv_SD
tags: arXiv_SD Regularization Sentiment Attention Sentiment_Classification Embedding Classification
author: Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, Yoshua Bengio
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.

##### Abstract (translated by Google)
本文提出了一种通过引入自我注意提取可解释句子嵌入的新模型。我们不使用向量，而是使用二维矩阵来表示嵌入，矩阵的每一行都出现在句子的不同部分。我们还提出了模型的自我注意机制和特殊的正则化术语。作为一个副作用，嵌入带有一个简单的方法来显示句子的哪些特定部分被编码到嵌入中。我们评估我们的模型的3个不同的任务：作者简介，情感分类，和文本蕴涵。结果表明，与其他句子嵌入方法相比，我们的模型在3个任务中都有显着的性能提升。

##### URL
[https://arxiv.org/abs/1703.03130](https://arxiv.org/abs/1703.03130)

##### PDF
[https://arxiv.org/pdf/1703.03130](https://arxiv.org/pdf/1703.03130)

