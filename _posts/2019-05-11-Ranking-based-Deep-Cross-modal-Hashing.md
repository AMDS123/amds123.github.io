---
layout: post
title: "Ranking-based Deep Cross-modal Hashing"
date: 2019-05-11 05:13:06
categories: arXiv_AI
tags: arXiv_AI
author: Xuanwu Liu, Guoxian Yu, Carlotta Domeniconi, Jun Wang, Yazhou Ren, Maozu Guo
mathjax: true
---

* content
{:toc}

##### Abstract
Cross-modal hashing has been receiving increasing interests for its low storage cost and fast query speed in multi-modal data retrievals. However, most existing hashing methods are based on hand-crafted or raw level features of objects, which may not be optimally compatible with the coding process. Besides, these hashing methods are mainly designed to handle simple pairwise similarity. The complex multilevel ranking semantic structure of instances associated with multiple labels has not been well explored yet. In this paper, we propose a ranking-based deep cross-modal hashing approach (RDCMH). RDCMH firstly uses the feature and label information of data to derive a semi-supervised semantic ranking list. Next, to expand the semantic representation power of hand-crafted features, RDCMH integrates the semantic ranking information into deep cross-modal hashing and jointly optimizes the compatible parameters of deep feature representations and of hashing functions. Experiments on real multi-modal datasets show that RDCMH outperforms other competitive baselines and achieves the state-of-the-art performance in cross-modal retrieval applications.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.04450](http://arxiv.org/abs/1905.04450)

##### PDF
[http://arxiv.org/pdf/1905.04450](http://arxiv.org/pdf/1905.04450)

