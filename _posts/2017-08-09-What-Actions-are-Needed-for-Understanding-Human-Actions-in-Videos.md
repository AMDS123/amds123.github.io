---
layout: post
title: "What Actions are Needed for Understanding Human Actions in Videos?"
date: 2017-08-09 02:25:56
categories: arXiv_CV
tags: arXiv_CV
author: Gunnar A. Sigurdsson, Olga Russakovsky, Abhinav Gupta
mathjax: true
---

* content
{:toc}

##### Abstract
What is the right way to reason about human activities? What directions forward are most promising? In this work, we analyze the current state of human activity understanding in videos. The goal of this paper is to examine datasets, evaluation metrics, algorithms, and potential future directions. We look at the qualitative attributes that define activities such as pose variability, brevity, and density. The experiments consider multiple state-of-the-art algorithms and multiple datasets. The results demonstrate that while there is inherent ambiguity in the temporal extent of activities, current datasets still permit effective benchmarking. We discover that fine-grained understanding of objects and pose when combined with temporal reasoning is likely to yield substantial improvements in algorithmic accuracy. We present the many kinds of information that will be needed to achieve substantial gains in activity understanding: objects, verbs, intent, and sequential reasoning. The software and additional information will be made available to provide other researchers detailed diagnostics to understand their own algorithms.

##### Abstract (translated by Google)
什么是正确的方式来推理人类活动？前进的方向是什么最有希望的？在这项工作中，我们分析视频中人类活动理解的现状。本文的目标是检查数据集，评估指标，算法和潜在的未来方向。我们看一下定义活动的定性属性，如姿态变化，简洁性和密度。实验考虑多个最先进的算法和多个数据集。结果表明，虽然活动的时间范围存在固有的模糊性，但目前的数据集仍然允许有效的基准。我们发现，当与时间推理相结合时，对对象和姿态的细粒度理解很可能在算法精度上产生重大的改进。我们提出了在活动理解方面取得实质性成果所需的各种信息：对象，动词，意图和顺序推理。软件和附加信息将提供给其他研究人员的详细诊断，以了解他们自己的算法。

##### URL
[https://arxiv.org/abs/1708.02696](https://arxiv.org/abs/1708.02696)

##### PDF
[https://arxiv.org/pdf/1708.02696](https://arxiv.org/pdf/1708.02696)

