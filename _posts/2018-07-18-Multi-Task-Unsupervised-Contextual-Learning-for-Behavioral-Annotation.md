---
layout: post
title: "Multi-Task Unsupervised Contextual Learning for Behavioral Annotation"
date: 2018-07-18 06:39:07
categories: arXiv_CL
tags: arXiv_CL Knowledge Embedding Deep_Learning
author: Shao-Yen Tseng, Panayiotis Georgiou
mathjax: true
---

* content
{:toc}

##### Abstract
Unsupervised learning has been an attractive method for easily deriving meaningful data representations from vast amounts of unlabeled data. These representations or, in the context of deep learning, embeddings, often yield superior results in many tasks, whether used directly or as features in subsequent training stages. However, the quality of the embeddings is highly dependent on the assumed knowledge in the unlabeled data and how the system extracts information without supervision. Domain portability is also very limited in unsupervised learning, often requiring re-training on other large-scale corpora to achieve robustness. In this work we present a paradigm for unsupervised contextual learning for behavioral interactions which addresses unsupervised domain adaption. We introduce a multitask ob- jective into unsupervised learning and show that embeddings generated through this process increases performance of behavior related tasks.

##### Abstract (translated by Google)
无监督学习一直是从大量未标记数据中轻松获得有意义的数据表示的有吸引力的方法。这些表示或在深度学习嵌入的背景下，通常在许多任务中产生优异的结果，无论是直接使用还是作为后续训练阶段的特征。然而，嵌入的质量高度依赖于未标记数据中的假定知识以及系统如何在没有监督的情况下提取信息。在无监督学习中，域可移植性也非常有限，通常需要对其他大型语料库进行重新训练以实现稳健性。在这项工作中，我们提出了一种范式，用于行为交互的无监督语境学习，解决无监督的领域适应问题。我们在无监督学习中引入了一个多任务目标，并表明通过此过程生成的嵌入可以提高行为相关任务的性能。

##### URL
[https://arxiv.org/abs/1807.06792](https://arxiv.org/abs/1807.06792)

##### PDF
[https://arxiv.org/pdf/1807.06792](https://arxiv.org/pdf/1807.06792)

