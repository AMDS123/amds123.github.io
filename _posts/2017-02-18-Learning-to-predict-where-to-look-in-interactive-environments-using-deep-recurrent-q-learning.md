---
layout: post
title: "Learning to predict where to look in interactive environments using deep recurrent q-learning"
date: 2017-02-18 21:23:14
categories: arXiv_CV
tags: arXiv_CV Salient Attention Reinforcement_Learning
author: Sajad Mousavi, Michael Schukat, Enda Howley, Ali Borji, Nasser Mozayani
mathjax: true
---

* content
{:toc}

##### Abstract
Bottom-Up (BU) saliency models do not perform well in complex interactive environments where humans are actively engaged in tasks (e.g., sandwich making and playing the video games). In this paper, we leverage Reinforcement Learning (RL) to highlight task-relevant locations of input frames. We propose a soft attention mechanism combined with the Deep Q-Network (DQN) model to teach an RL agent how to play a game and where to look by focusing on the most pertinent parts of its visual input. Our evaluations on several Atari 2600 games show that the soft attention based model could predict fixation locations significantly better than bottom-up models such as Itti-Kochs saliency and Graph-Based Visual Saliency (GBVS) models.

##### Abstract (translated by Google)
自下而上（BU）显着性模型在人类积极参与任务的复杂交互式环境（例如制作三明治和玩视频游戏）中表现不佳。在本文中，我们利用强化学习（RL）强调输入框架的任务相关位置。我们提出了一种与深度Q网络（DQN）模型相结合的软性关注机制，通过关注视觉输入的最相关部分来教授RL代理如何玩游戏以及在哪里寻找。我们对几个Atari 2600游戏的评估表明，基于软注意的模型可以预测固定位置明显优于自底向上模型，如Itti-Kochs显着性和基于图形的视觉显着性（GBVS）模型。

##### URL
[https://arxiv.org/abs/1612.05753](https://arxiv.org/abs/1612.05753)

##### PDF
[https://arxiv.org/pdf/1612.05753](https://arxiv.org/pdf/1612.05753)

