---
layout: post
title: "CURL: Co-trained Unsupervised Representation Learning for Image Classification"
date: 2015-09-11 12:21:20
categories: arXiv_CV
tags: arXiv_CV CNN Image_Classification Represenation_Learning Classification Recognition
author: Simone Bianco, Gianluigi Ciocca, Claudio Cusano
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we propose a strategy for semi-supervised image classification that leverages unsupervised representation learning and co-training. The strategy, that is called CURL from Co-trained Unsupervised Representation Learning, iteratively builds two classifiers on two different views of the data. The two views correspond to different representations learned from both labeled and unlabeled data and differ in the fusion scheme used to combine the image features. To assess the performance of our proposal, we conducted several experiments on widely used data sets for scene and object recognition. We considered three scenarios (inductive, transductive and self-taught learning) that differ in the strategy followed to exploit the unlabeled data. As image features we considered a combination of GIST, PHOG, and LBP as well as features extracted from a Convolutional Neural Network. Moreover, two embodiments of CURL are investigated: one using Ensemble Projection as unsupervised representation learning coupled with Logistic Regression, and one based on LapSVM. The results show that CURL clearly outperforms other supervised and semi-supervised learning methods in the state of the art.

##### Abstract (translated by Google)
在本文中，我们提出了一个半监督的图像分类策略，利用无监督表示学习和协同训练。该策略被称为协同训练无监督表示学习（CURL），它在两个不同的数据视图上迭代建立两个分类器。这两个视图对应于从标记和未标记数据中学习到的不同表示，并且在用于组合图像特征的融合方案上有所不同。为了评估我们提议的性能，我们对广泛使用的场景和物体识别数据集进行了多次实验。我们考虑了三个不同的方案（归纳，转导和自学成才），这些方案在利用未标记数据的策略上是不同的。作为图像特征，我们考虑了GIST，PHOG和LBP的组合以及从卷积神经网络提取的特征。此外，研究了CURL的两个实施例：一个使用Ensemble Projection作为无监督表示学习与Logistic回归相结合，另一个基于LapSVM。结果显示，CURL显然优于现有技术中的其他监督和半监督学习方法。

##### URL
[https://arxiv.org/abs/1505.08098](https://arxiv.org/abs/1505.08098)

##### PDF
[https://arxiv.org/pdf/1505.08098](https://arxiv.org/pdf/1505.08098)

