---
layout: post
title: "Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis"
date: 2017-01-27 17:09:07
categories: arXiv_SD
tags: arXiv_SD Survey Detection
author: Björn Ross, Michael Rist, Guillermo Carbonell, Benjamin Cabrera, Nils Kurowsky, Michael Wojatzki
mathjax: true
---

* content
{:toc}

##### Abstract
Some users of social media are spreading racist, sexist, and otherwise hateful content. For the purpose of training a hate speech detection system, the reliability of the annotations is crucial, but there is no universally agreed-upon definition. We collected potentially hateful messages and asked two groups of internet users to determine whether they were hate speech or not, whether they should be banned or not and to rate their degree of offensiveness. One of the groups was shown a definition prior to completing the survey. We aimed to assess whether hate speech can be annotated reliably, and the extent to which existing definitions are in accordance with subjective ratings. Our results indicate that showing users a definition caused them to partially align their own opinion with the definition but did not improve reliability, which was very low overall. We conclude that the presence of hate speech should perhaps not be considered a binary yes-or-no decision, and raters need more detailed instructions for the annotation.

##### Abstract (translated by Google)
社交媒体的一些用户正在传播种族主义，性别歧视和其他可恶的内容。为了训练一个仇恨言论检测系统，注释的可靠性是至关重要的，但是没有普遍认同的定义。我们收集到潜在的可恶信息，并要求两组网民判断是否是仇恨言论，是否应该被禁止，并评估他们的进攻程度。在完成调查之前，其中一个小组显示了一个定义。我们的目的是评估仇恨言论是否可以可靠地加以注释，以及现有定义与主观评级相一致的程度。我们的研究结果表明，向用户展示一个定义使得他们将自己的观点与定义部分地结合起来，但并没有提高可靠性，总体来说这是非常低的。我们得出这样的结论：仇恨言论的存在或许不应该被认为是一个二元决定，评估者需要更详细的注释说明。

##### URL
[https://arxiv.org/abs/1701.08118](https://arxiv.org/abs/1701.08118)

##### PDF
[https://arxiv.org/pdf/1701.08118](https://arxiv.org/pdf/1701.08118)

