---
layout: post
title: "Controlling Output Length in Neural Encoder-Decoders"
date: 2016-09-30 00:01:27
categories: arXiv_CL
tags: arXiv_CL Summarization
author: Yuta Kikuchi, Graham Neubig, Ryohei Sasano, Hiroya Takamura, Manabu Okumura
mathjax: true
---

* content
{:toc}

##### Abstract
Neural encoder-decoder models have shown great success in many sequence generation tasks. However, previous work has not investigated situations in which we would like to control the length of encoder-decoder outputs. This capability is crucial for applications such as text summarization, in which we have to generate concise summaries with a desired length. In this paper, we propose methods for controlling the output sequence length for neural encoder-decoder models: two decoding-based methods and two learning-based methods. Results show that our learning-based methods have the capability to control length without degrading summary quality in a summarization task.

##### Abstract (translated by Google)
神经编码器 - 解码器模型已经在许多序列生成任务中取得了巨大的成功。然而，以前的工作并没有调查我们想要控制编解码器输出长度的情况。此功能对于文本摘要等应用程序至关重要，因为我们必须生成具有所需长度的简明摘要。在本文中，我们提出了用于控制神经编码器 - 解码器模型的输出序列长度的方法：两种基于解码的方法和两种基于学习的方法。结果显示，我们的基于学习的方法有能力在总结任务中控制长度而不降低总结质量。

##### URL
[https://arxiv.org/abs/1609.09552](https://arxiv.org/abs/1609.09552)

##### PDF
[https://arxiv.org/pdf/1609.09552](https://arxiv.org/pdf/1609.09552)

