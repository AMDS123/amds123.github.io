---
layout: post
title: "Multimodal Dialogs : A large-scale dataset for studying multimodal domain-aware conversations"
date: 2017-05-09 07:50:08
categories: arXiv_SD
tags: arXiv_SD Deep_Learning
author: Amrita Saha, Mitesh Khapra, Karthik Sankaranarayanan
mathjax: true
---

* content
{:toc}

##### Abstract
While multimodal conversation agents are gaining importance in several domains such as retail, travel etc., deep learning research in this area has been limited primarily due to the lack of availability of large-scale, open chatlogs. To overcome this bottleneck, in this paper we introduce the task of multimodal, domain-aware conversations, and propose the MMD benchmark dataset. This dataset was gathered by working in close coordination with large number of domain experts in the retail domain and consists of over 150K conversation sessions between shoppers and sales agents, with over 6.5Million utterances. With this dataset, we propose 5 new sub-tasks for multimodal conversations along with their evaluation methodology. We also propose two novel multimodal neural models in the encode-attend-decode paradigm and demonstrate their performance on two of the sub-tasks, namely text response generation and best image response selection. These experiments serve to establish baseline performance and open new research directions for each of these sub-tasks.

##### Abstract (translated by Google)
虽然多式联运代理商在零售，旅游等多个领域日益重要，但在这方面的深度学习研究一直受到限制，主要是由于缺乏大规模的开放式聊天记录。为了克服这个瓶颈，本文介绍了多模式，领域意识对话的任务，并提出了MMD基准数据集。这个数据集是通过与零售领域的大量领域专家密切合作而收集的，由购物者和销售代理人之间的超过150,000个会话组成，超过650万个话语。通过这个数据集，我们提出了5个多模式对话的新子任务及其评估方法。我们还提出了两种新的多模态神经模型在编码参加解码范例，并展示了他们在两个子任务，即文本响应生成和最佳图像响应选择的表现。这些实验有助于确定基线性能，并为这些子任务中的每一个开放新的研究方向。

##### URL
[https://arxiv.org/abs/1704.00200](https://arxiv.org/abs/1704.00200)

##### PDF
[https://arxiv.org/pdf/1704.00200](https://arxiv.org/pdf/1704.00200)

