---
layout: post
title: "Sequence-based Multimodal Apprenticeship Learning For Robot Perception and Decision Making"
date: 2017-02-24 06:37:06
categories: arXiv_CV
tags: arXiv_CV Attention
author: Fei Han, Xue Yang, Yu Zhang, Hao Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Apprenticeship learning has recently attracted a wide attention due to its capability of allowing robots to learn physical tasks directly from demonstrations provided by human experts. Most previous techniques assumed that the state space is known a priori or employed simple state representations that usually suffer from perceptual aliasing. Different from previous research, we propose a novel approach named Sequence-based Multimodal Apprenticeship Learning (SMAL), which is capable to simultaneously fusing temporal information and multimodal data, and to integrate robot perception with decision making. To evaluate the SMAL approach, experiments are performed using both simulations and real-world robots in the challenging search and rescue scenarios. The empirical study has validated that our SMAL approach can effectively learn plans for robots to make decisions using sequence of multimodal observations. Experimental results have also showed that SMAL outperforms the baseline methods using individual images.

##### Abstract (translated by Google)
学徒学习最近引起了广泛的关注，因为它允许机器人直接从人类专家提供的示范中学习物理任务。大多数先前的技术假定状态空间是已知的或者采用通常遭受感知混叠的简单状态表示。与以往的研究不同，本文提出了一种基于序列的多模式学徒学习（SMAL）方法，能够同时融合时间信息和多模态数据，并将机器人的感知与决策相结合。为了评估SMAL方法，在具有挑战性的搜索和救援方案中，使用模拟和真实世界的机器人进行实验。实证研究验证了我们的SMAL方法能够有效地学习机器人使用多模态观测序列做出决策的计划。实验结果也显示，SMAL优于使用单个图像的基线方法。

##### URL
[https://arxiv.org/abs/1702.07475](https://arxiv.org/abs/1702.07475)

##### PDF
[https://arxiv.org/pdf/1702.07475](https://arxiv.org/pdf/1702.07475)

