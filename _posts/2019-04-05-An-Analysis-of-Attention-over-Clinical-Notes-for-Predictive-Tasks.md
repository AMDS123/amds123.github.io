---
layout: post
title: "An Analysis of Attention over Clinical Notes for Predictive Tasks"
date: 2019-04-05 19:22:47
categories: arXiv_AI
tags: arXiv_AI Attention Prediction
author: Sarthak Jain, Ramin Mohammadi, Byron C. Wallace
mathjax: true
---

* content
{:toc}

##### Abstract
The shift to electronic medical records (EMRs) has engendered research into machine learning and natural language technologies to analyze patient records, and to predict from these clinical outcomes of interest. Two observations motivate our aims here. First, unstructured notes contained within EMR often contain key information, and hence should be exploited by models. Second, while strong predictive performance is important, interpretability of models is perhaps equally so for applications in this domain. Together, these points suggest that neural models for EMR may benefit from incorporation of attention over notes, which one may hope will both yield performance gains and afford transparency in predictions. In this work we perform experiments to explore this question using two EMR corpora and four different predictive tasks, that: (i) inclusion of attention mechanisms is critical for neural encoder modules that operate over notes fields in order to yield competitive performance, but, (ii) unfortunately, while these boost predictive performance, it is decidedly less clear whether they provide meaningful support for predictions.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.03244](http://arxiv.org/abs/1904.03244)

##### PDF
[http://arxiv.org/pdf/1904.03244](http://arxiv.org/pdf/1904.03244)

