---
layout: post
title: "Deep learning is a good steganalysis tool when embedding key is reused for different images, even if there is a cover source-mismatch"
date: 2018-01-12 07:49:46
categories: arXiv_CV
tags: arXiv_CV Image_Caption GAN Embedding CNN Classification Deep_Learning
author: Lionel Pibre, Pasquet J&#xe9;r&#xf4;me, Dino Ienco, Marc Chaumont
mathjax: true
---

* content
{:toc}

##### Abstract
Since the BOSS competition, in 2010, most steganalysis approaches use a learning methodology involving two steps: feature extraction, such as the Rich Models (RM), for the image representation, and use of the Ensemble Classifier (EC) for the learning step. In 2015, Qian et al. have shown that the use of a deep learning approach that jointly learns and computes the features, is very promising for the steganalysis. In this paper, we follow-up the study of Qian et al., and show that, due to intrinsic joint minimization, the results obtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural Network (FNN), if well parameterized, surpass the conventional use of a RM with an EC. First, numerous experiments were conducted in order to find the best " shape " of the CNN. Second, experiments were carried out in the clairvoyant scenario in order to compare the CNN and FNN to an RM with an EC. The results show more than 16% reduction in the classification error with our CNN or FNN. Third, experiments were also performed in a cover-source mismatch setting. The results show that the CNN and FNN are naturally robust to the mismatch problem. In Addition to the experiments, we provide discussions on the internal mechanisms of a CNN, and weave links with some previously stated ideas, in order to understand the impressive results we obtained.

##### Abstract (translated by Google)
自从2010年的BOSS竞赛以来，大多数隐写分析方法都采用了两个步骤的学习方法：用于图像表示的特征提取（例如Rich Models（RM））和用于学习步骤的集成分类器（EC）的使用。在2015年，钱等人。已经表明，使用深度学习方法，共同学习和计算的特点，是非常有希望的隐写分析。在本文中，我们跟进了Qian等人的研究，并且表明，由于内在联合最小化，从卷积神经网络（CNN）或全连接神经网络（FNN）获得的结果，如果参数化，超过了与欧共体的常规使用RM。首先，为了找到CNN的最佳“形状”，进行了大量实验。其次，为了将CNN和FNN与一个EC与RM进行比较，在透视情景下进行了实验。结果显示，CNN或FNN的分类误差减少了16％以上。第三，实验也在覆盖源不匹配设置中进行。结果表明CNN和FNN对于不匹配问题自然是有效的。除了实验之外，我们还讨论了有线电视新闻网的内部机制，并与之前提出的一些观点联系起来，以了解我们取得的令人印象深刻的成果。

##### URL
[http://arxiv.org/abs/1511.04855](http://arxiv.org/abs/1511.04855)

##### PDF
[http://arxiv.org/pdf/1511.04855](http://arxiv.org/pdf/1511.04855)

