---
layout: post
title: "Graph based manifold regularized deep neural networks for automatic speech recognition"
date: 2016-06-19 23:40:51
categories: arXiv_CL
tags: arXiv_CL Regularization Speech_Recognition Relation Recognition
author: Vikrant Singh Tomar, Richard C. Rose
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks (DNNs) have been successfully applied to a wide variety of acoustic modeling tasks in recent years. These include the applications of DNNs either in a discriminative feature extraction or in a hybrid acoustic modeling scenario. Despite the rapid progress in this area, a number of challenges remain in training DNNs. This paper presents an effective way of training DNNs using a manifold learning based regularization framework. In this framework, the parameters of the network are optimized to preserve underlying manifold based relationships between speech feature vectors while minimizing a measure of loss between network outputs and targets. This is achieved by incorporating manifold based locality constraints in the objective criterion of DNNs. Empirical evidence is provided to demonstrate that training a network with manifold constraints preserves structural compactness in the hidden layers of the network. Manifold regularization is applied to train bottleneck DNNs for feature extraction in hidden Markov model (HMM) based speech recognition. The experiments in this work are conducted on the Aurora-2 spoken digits and the Aurora-4 read news large vocabulary continuous speech recognition tasks. The performance is measured in terms of word error rate (WER) on these tasks. It is shown that the manifold regularized DNNs result in up to 37% reduction in WER relative to standard DNNs.

##### Abstract (translated by Google)
深度神经网络（DNN）近年来已成功地应用于各种声学建模任务。这些包括DNN在判别特征提取或混合声学建模场景中的应用。尽管在这一领域取得了快速进展，但在培训DNN方面仍然存在一些挑战。本文提出了一种使用基于流形学习的正则化框架来训练DNN的有效方法。在这个框架中，网络的参数被优化以保留语音特征向量之间的基于流形的关系，同时最小化网络输出和目标之间的损失量度。这是通过将基于流形的局部约束纳入DNN的客观标准来实现的。经验证据表明，训练具有多种约束的网络保留了网络隐藏层的结构紧凑性。基于HMM（HMM）的语音识别方法采用流形正则化方法训练瓶颈DNN进行特征提取。在这项工作中的实验是在极光2口语数字和极光4读新闻大词汇连续语音识别任务进行。性能是根据这些任务的字错误率（WER）来衡量的。结果表明，相对于标准的DNNs，歧管正则化的DNNs导致WER降低多达37％。

##### URL
[https://arxiv.org/abs/1606.05925](https://arxiv.org/abs/1606.05925)

##### PDF
[https://arxiv.org/pdf/1606.05925](https://arxiv.org/pdf/1606.05925)

