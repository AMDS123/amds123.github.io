---
layout: post
title: "Data Sets: Word Embeddings Learned from Tweets and General Data"
date: 2017-08-14 02:34:17
categories: arXiv_CL
tags: arXiv_CL Sentiment Embedding Classification
author: Quanzhi Li, Sameena Shah, Xiaomo Liu, Armineh Nourbakhsh
mathjax: true
---

* content
{:toc}

##### Abstract
A word embedding is a low-dimensional, dense and real- valued vector representation of a word. Word embeddings have been used in many NLP tasks. They are usually gener- ated from a large text corpus. The embedding of a word cap- tures both its syntactic and semantic aspects. Tweets are short, noisy and have unique lexical and semantic features that are different from other types of text. Therefore, it is necessary to have word embeddings learned specifically from tweets. In this paper, we present ten word embedding data sets. In addition to the data sets learned from just tweet data, we also built embedding sets from the general data and the combination of tweets with the general data. The general data consist of news articles, Wikipedia data and other web data. These ten embedding models were learned from about 400 million tweets and 7 billion words from the general text. In this paper, we also present two experiments demonstrating how to use the data sets in some NLP tasks, such as tweet sentiment analysis and tweet topic classification tasks.

##### Abstract (translated by Google)
单词嵌入是单词的低维，密集和实值矢量表示。词嵌入已被用于许多NLP任务。他们通常是从一个大的文本语料库中产生的。嵌入一​​个单词可以捕捉它的句法和语义方面。推文短小，嘈杂，具有独特的词汇和语义特征，与其他类型的文本不同。因此，有必要从推文中具体学习词嵌入。在本文中，我们提出了十个字嵌入数据集。除了从tweet数据中学习的数据集以外，我们还从通用数据和推特与普通数据的组合中构建了嵌入集。一般数据包括新闻文章，维基百科数据和其他网络数据。这十种嵌入模式是从一​​般文本中的大约4亿个推文和70亿个字中学习的。在本文中，我们还展示了两个实验，演示如何在一些NLP任务中使用数据集，例如tweet情绪分析和tweet主题分类任务。

##### URL
[https://arxiv.org/abs/1708.03994](https://arxiv.org/abs/1708.03994)

##### PDF
[https://arxiv.org/pdf/1708.03994](https://arxiv.org/pdf/1708.03994)

