---
layout: post
title: "Can DNNs Learn to Lipread Full Sentences?"
date: 2018-05-29 19:54:19
categories: arXiv_CV
tags: arXiv_CV Attention CNN Classification Language_Model
author: George Sterpu, Christian Saam, Naomi Harte
mathjax: true
---

* content
{:toc}

##### Abstract
Finding visual features and suitable models for lipreading tasks that are more complex than a well-constrained vocabulary has proven challenging. This paper explores state-of-the-art Deep Neural Network architectures for lipreading based on a Sequence to Sequence Recurrent Neural Network. We report results for both hand-crafted and 2D/3D Convolutional Neural Network visual front-ends, online monotonic attention, and a joint Connectionist Temporal Classification-Sequence-to-Sequence loss. The system is evaluated on the publicly available TCD-TIMIT dataset, with 59 speakers and a vocabulary of over 6000 words. Results show a major improvement on a Hidden Markov Model framework. A fuller analysis of performance across visemes demonstrates that the network is not only learning the language model, but actually learning to lipread.

##### Abstract (translated by Google)
事实证明，寻找视觉特征和合适的唇形识读任务模型要比限制良好的词汇表复杂得多。本文探讨了基于顺序循环递归神经网络的尖端深度神经网络体系结构。我们报告了手工制作的和二维/三维卷积神经网络视觉前端的结果，在线单调注意以及联合时间分类 - 序列 - 序列联合损失。该系统在公共可用的TCD-TIMIT数据集上进行评估，共有59位演讲者和超过6000个单词的词汇。结果显示了对隐马尔可夫模型框架的重大改进。对各种视角的表现进行更全面的分析表明，网络不仅仅是学习语言模型，而且实际上是在学习唇书。

##### URL
[https://arxiv.org/abs/1805.11685](https://arxiv.org/abs/1805.11685)

##### PDF
[https://arxiv.org/pdf/1805.11685](https://arxiv.org/pdf/1805.11685)

