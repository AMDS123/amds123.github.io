---
layout: post
title: "Improving Search through A3C Reinforcement Learning based Conversational Agent"
date: 2018-08-19 08:00:34
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Milan Aggarwal, Aarushi Arora, Shagun Sodhani, Balaji Krishnamurthy
mathjax: true
---

* content
{:toc}

##### Abstract
We develop a reinforcement learning based search assistant which can assist users through a set of actions and sequence of interactions to enable them realize their intent. Our approach caters to subjective search where the user is seeking digital assets such as images which is fundamentally different from the tasks which have objective and limited search modalities. Labeled conversational data is generally not available in such search tasks and training the agent through human interactions can be time consuming. We propose a stochastic virtual user which impersonates a real user and can be used to sample user behavior efficiently to train the agent which accelerates the bootstrapping of the agent. We develop A3C algorithm based context preserving architecture which enables the agent to provide contextual assistance to the user. We compare the A3C agent with Q-learning and evaluate its performance on average rewards and state values it obtains with the virtual user in validation episodes. Our experiments show that the agent learns to achieve higher rewards and better states.

##### Abstract (translated by Google)
我们开发了一种基于强化学习的搜索助手，可以帮助用户完成一系列动作和一系列交互，从而实现他们的意图。我们的方法迎合主观搜索，其中用户正在寻找数字资产，例如图像，其与具有客观和有限搜索模态的任务根本不同。标记的会话数据通常在此类搜索任务中不可用，并且通过人工交互对代理进行培训可能非常耗时。我们提出了一个模拟真实用户的随机虚拟用户，可以用来有效地对用户行为进行采样，以训练代理，从而加速代理的引导。我们开发基于A3C算法的上下文保留架构，使代理能够为用户提供上下文帮助。我们将A3C代理与Q-learning进行比较，并评估其在验证事件中与虚拟用户获得的平均奖励和状态值的性能。我们的实验表明，代理人学会获得更高的回报和更好的状态。

##### URL
[http://arxiv.org/abs/1709.05638](http://arxiv.org/abs/1709.05638)

##### PDF
[http://arxiv.org/pdf/1709.05638](http://arxiv.org/pdf/1709.05638)

