---
layout: post
title: "How far are we from solving the 2D & 3D Face Alignment problem?"
date: 2017-09-07 16:21:37
categories: arXiv_CV
tags: arXiv_CV Face
author: Adrian Bulat, Georgios Tzimiropoulos
mathjax: true
---

* content
{:toc}

##### Abstract
This paper investigates how far a very deep neural network is from attaining close to saturating performance on existing 2D and 3D face alignment datasets. To this end, we make the following 5 contributions: (a) we construct, for the first time, a very strong baseline by combining a state-of-the-art architecture for landmark localization with a state-of-the-art residual block, train it on a very large yet synthetically expanded 2D facial landmark dataset and finally evaluate it on all other 2D facial landmark datasets. (b) We create a guided by 2D landmarks network which converts 2D landmark annotations to 3D and unifies all existing datasets, leading to the creation of LS3D-W, the largest and most challenging 3D facial landmark dataset to date ~230,000 images. (c) Following that, we train a neural network for 3D face alignment and evaluate it on the newly introduced LS3D-W. (d) We further look into the effect of all "traditional" factors affecting face alignment performance like large pose, initialization and resolution, and introduce a "new" one, namely the size of the network. (e) We show that both 2D and 3D face alignment networks achieve performance of remarkable accuracy which is probably close to saturating the datasets used. Training and testing code as well as the dataset can be downloaded from this https URL

##### Abstract (translated by Google)
本文研究了一个非常深的神经网络在已有的二维和三维人脸对齐数据集上达到饱和的程度。为此，我们做出以下五点贡献：（a）我们首次构建了一个非常强大的基线，将最先进的地标定位架构与最先进的残差块，在一个非常大的综合扩展的2D面部标记数据集上进行训练，最后在所有其他的2D面部标记数据集上进行评估。 （b）我们创建了2D地标网络，将2D标志性标注转换为3D，并将所有现有数据集合在一起，从而创建LS3D-W，这是迄今为止最大，最具挑战性的3D面部标记数据集，约230,000个图像。 （c）之后，我们训练神经网络进行三维人脸对齐，并在新推出的LS3D-W上进行评估。 （d）我们进一步研究所有“传统”因素影响大姿态，初始化和分辨率等人脸对准性能的效果，并引入一个“新”的因素，即网络的大小。 （e）我们表明，二维和三维人脸对齐网络实现卓越的准确性，这可能接近饱和所使用的数据集。可以从此https URL下载培训和测试代码以及​​数据集

##### URL
[https://arxiv.org/abs/1703.07332](https://arxiv.org/abs/1703.07332)

##### PDF
[https://arxiv.org/pdf/1703.07332](https://arxiv.org/pdf/1703.07332)

