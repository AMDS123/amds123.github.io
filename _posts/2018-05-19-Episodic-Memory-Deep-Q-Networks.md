---
layout: post
title: "Episodic Memory Deep Q-Networks"
date: 2018-05-19 14:33:00
categories: arXiv_AI
tags: arXiv_AI Attention Reinforcement_Learning
author: Zichuan Lin, Tianqi Zhao, Guangwen Yang, Lintao Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Reinforcement learning (RL) algorithms have made huge progress in recent years by leveraging the power of deep neural networks (DNN). Despite the success, deep RL algorithms are known to be sample inefficient, often requiring many rounds of interaction with the environments to obtain satisfactory performance. Recently, episodic memory based RL has attracted attention due to its ability to latch on good actions quickly. In this paper, we present a simple yet effective biologically inspired RL algorithm called Episodic Memory Deep Q-Networks (EMDQN), which leverages episodic memory to supervise an agent during training. Experiments show that our proposed method can lead to better sample efficiency and is more likely to find good policies. It only requires 1/5 of the interactions of DQN to achieve many state-of-the-art performances on Atari games, significantly outperforming regular DQN and other episodic memory based RL algorithms.

##### Abstract (translated by Google)
通过利用深度神经网络（DNN）的强大功能，强化学习（RL）算法近年来取得了巨大进步。尽管取得了成功，但已知深度RL算法样本效率低下，通常需要与环境进行多次交互以获得令人满意的性能。最近，基于情景记忆的RL由于能够快速锁定好行为而受到关注。在本文中，我们提出了一种简单而有效的生物启发式RL算法，称为情景记忆深度Q网络（EMDQN），它利用情景记忆在训练期间监督代理。实验表明，我们提出的方法可以导致更好的采样效率，更有可能找到好的策略。它只需要DQN相互作用的1/5即可实现Atari游戏中许多最先进的性能，明显优于常规DQN和其他基于情景记忆的RL算法。

##### URL
[https://arxiv.org/abs/1805.07603](https://arxiv.org/abs/1805.07603)

##### PDF
[https://arxiv.org/pdf/1805.07603](https://arxiv.org/pdf/1805.07603)

