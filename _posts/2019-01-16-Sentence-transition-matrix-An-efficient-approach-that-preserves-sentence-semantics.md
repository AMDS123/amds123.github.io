---
layout: post
title: "Sentence transition matrix: An efficient approach that preserves sentence semantics"
date: 2019-01-16 10:40:18
categories: arXiv_CL
tags: arXiv_CL Summarization Embedding Classification
author: Myeongjun Jang, Pilsung Kang
mathjax: true
---

* content
{:toc}

##### Abstract
Sentence embedding is a significant research topic in the field of natural language processing (NLP). Generating sentence embedding vectors reflecting the intrinsic meaning of a sentence is a key factor to achieve an enhanced performance in various NLP tasks such as sentence classification and document summarization. Therefore, various sentence embedding models based on supervised and unsupervised learning have been proposed after the advent of researches regarding the distributed representation of words. They were evaluated through semantic textual similarity (STS) tasks, which measure the degree of semantic preservation of a sentence and neural network-based supervised embedding models generally yielded state-of-the-art performance. However, these models have a limitation in that they have multiple parameters to update, thereby requiring a tremendous amount of labeled training data. In this study, we propose an efficient approach that learns a transition matrix that refines a sentence embedding vector to reflect the latent semantic meaning of a sentence. The proposed method has two practical advantages; (1) it can be applied to any sentence embedding method, and (2) it can achieve robust performance in STS tasks irrespective of the number of training examples.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1901.05219](http://arxiv.org/abs/1901.05219)

##### PDF
[http://arxiv.org/pdf/1901.05219](http://arxiv.org/pdf/1901.05219)

