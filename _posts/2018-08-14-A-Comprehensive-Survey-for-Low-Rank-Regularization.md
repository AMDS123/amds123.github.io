---
layout: post
title: "A Comprehensive Survey for Low Rank Regularization"
date: 2018-08-14 04:38:58
categories: arXiv_CV
tags: arXiv_CV Regularization Review Survey Optimization
author: Zhanxuan Hu, Feiping Nie, Lai Tian, Xuelong Li
mathjax: true
---

* content
{:toc}

##### Abstract
Low rank regularization, in essence, involves introducing a low rank or approximately low rank assumption for matrix we aim to learn, which has achieved great success in many fields including machine learning, data mining and computer version. Over the last decade, much progress has been made in theories and practical applications. Nevertheless, the intersection between them is very slight. In order to construct a bridge between practical applications and theoretical research, in this paper we provide a comprehensive survey for low rank regularization. We first review several traditional machine learning models using low rank regularization, and then show their (or their variants) applications in solving practical issues, such as non-rigid structure from motion and image denoising. Subsequently, we summarize the regularizers and optimization methods that achieve great success in traditional machine learning tasks but are rarely seen in solving practical issues. Finally, we provide a discussion and comparison for some representative regularizers including convex and non-convex relaxations. Extensive experimental results demonstrate that non-convex regularizers can provide a large advantage over the nuclear norm, the regularizer widely used in solving practical issues.

##### Abstract (translated by Google)
低秩正则化本质上涉及为我们要学习的矩阵引入低秩或近似低秩的假设，其在包括机器学习，数据挖掘和计算机版本在内的许多领域中取得了巨大成功。在过去十年中，理论和实际应用取得了很大进展。然而，它们之间的交叉点很小。为了构建实际应用与理论研究之间的桥梁，本文对低阶正则化进行了全面的研究。我们首先回顾几种使用低秩正则化的传统机器学习模型，然后展示它们（或它们的变体）在解决实际问题中的应用，例如来自运动的非刚性结构和图像去噪。随后，我们总结了在传统机器学习任务中取得巨大成功但在解决实际问题时很少见到的正则化器和优化方法。最后，我们提供了一些代表性正则化器的讨论和比较，包括凸和非凸松弛。广泛的实验结果表明，非凸正则化器可以提供超过核范数的大优势，正则化器广泛用于解决实际问题。

##### URL
[http://arxiv.org/abs/1808.04521](http://arxiv.org/abs/1808.04521)

##### PDF
[http://arxiv.org/pdf/1808.04521](http://arxiv.org/pdf/1808.04521)

