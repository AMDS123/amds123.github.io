---
layout: post
title: "Polar Transformer Networks"
date: 2017-10-27 21:47:37
categories: arXiv_CV
tags: arXiv_CV CNN
author: Carlos Esteves, Christine Allen-Blanchette, Xiaowei Zhou, Kostas Daniilidis
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional neural networks (CNNs) are inherently equivariant to translation. Efforts to embed other forms of equivariance have concentrated solely on rotation. We expand the notion of equivariance in CNNs through the Polar Transformer Network (PTN). PTN combines ideas from the Spatial Transformer Network (STN) and canonical coordinate representations. The result is a network invariant to translation and equivariant to both rotation and scale. PTN is trained end-to-end and composed of three distinct stages: a polar origin predictor, the newly introduced polar transformer module and a classifier. PTN achieves state-of-the-art on rotated MNIST and the newly introduced SIM2MNIST dataset, an MNIST variation obtained by adding clutter and perturbing digits with translation, rotation and scaling. The ideas of PTN are extensible to 3D which we demonstrate through the Cylindrical Transformer Network

##### Abstract (translated by Google)
卷积神经网络（CNN）本质上等同于翻译。嵌入其他形式的等式的努力完全集中于轮换。我们通过极地变压器网络（PTN）扩展了有线电视网络中等效性的概念。 PTN结合了空间变换网络（STN）的思想和典型坐标表示。其结果是一个网络不变的翻译和旋转和规模同等。 PTN是端对端训练，由三个不同的阶段组成：一个极地起源预报器，新引进的极地变压器模块和一个分类器。 PTN在旋转的MNIST和新引入的SIM2MNIST数据集上实现了最新技术，MNIST变体是通过将平移，旋转和缩放加上杂波和扰动数字而获得的。 PTN的思想可以扩展到3D，我们通过圆柱形变压器网络展示

##### URL
[https://arxiv.org/abs/1709.01889](https://arxiv.org/abs/1709.01889)

##### PDF
[https://arxiv.org/pdf/1709.01889](https://arxiv.org/pdf/1709.01889)

