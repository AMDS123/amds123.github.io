---
layout: post
title: "Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks"
date: 2017-01-10 18:30:11
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition CNN RNN Classification Relation Recognition
author: Ying Zhang, Mohammad Pezeshki, Philemon Brakel, Saizheng Zhang, Cesar Laurent Yoshua Bengio, Aaron Courville
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional Neural Networks (CNNs) are effective models for reducing spectral variations and modeling spectral correlations in acoustic features for automatic speech recognition (ASR). Hybrid speech recognition systems incorporating CNNs with Hidden Markov Models/Gaussian Mixture Models (HMMs/GMMs) have achieved the state-of-the-art in various benchmarks. Meanwhile, Connectionist Temporal Classification (CTC) with Recurrent Neural Networks (RNNs), which is proposed for labeling unsegmented sequences, makes it feasible to train an end-to-end speech recognition system instead of hybrid settings. However, RNNs are computationally expensive and sometimes difficult to train. In this paper, inspired by the advantages of both CNNs and the CTC approach, we propose an end-to-end speech framework for sequence labeling, by combining hierarchical CNNs with CTC directly without recurrent connections. By evaluating the approach on the TIMIT phoneme recognition task, we show that the proposed model is not only computationally efficient, but also competitive with the existing baseline systems. Moreover, we argue that CNNs have the capability to model temporal correlations with appropriate context information.

##### Abstract (translated by Google)
卷积神经网络（CNN）是减少频谱变化和模拟自动语音识别（ASR）的声学特征中的频谱相关性的有效模型。将CNN与隐马尔可夫模型/高斯混合模型（HMM / GMM）相结合的混合语音识别系统已经实现了各种基准的最新技术。同时，提出用于标记未分段序列的连接主义时间分类（CTC）和递归神经网络（RNN），使得训练端到端语音识别系统而不是混合设置成为可能。但是，RNN的计算成本很高，有时难以训练。本文从CNN和CTC方法的优点出发，提出了一种序贯标签的端到端语音框架，将分层的CNN与CTC直接相结合，无需重复连接。通过评估TIMIT音素识别任务的方法，我们表明，提出的模型不仅计算效率高，而且还与现有的基准系统竞争。而且，我们认为CNN有能力用合适的上下文信息来建模时间相关性。

##### URL
[https://arxiv.org/abs/1701.02720](https://arxiv.org/abs/1701.02720)

##### PDF
[https://arxiv.org/pdf/1701.02720](https://arxiv.org/pdf/1701.02720)

