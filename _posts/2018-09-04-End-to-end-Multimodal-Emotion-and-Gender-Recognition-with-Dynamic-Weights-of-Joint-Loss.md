---
layout: post
title: "End-to-end Multimodal Emotion and Gender Recognition with Dynamic Weights of Joint Loss"
date: 2018-09-04 00:52:25
categories: arXiv_CV
tags: arXiv_CV Knowledge Classification Prediction Recognition
author: Myungsu Chae, Tae-Ho Kim, Young Hoon Shin, Jun-Woo Kim, Soo-Young Lee
mathjax: true
---

* content
{:toc}

##### Abstract
Multi-task learning (MTL) is one of the method for improving generalizability of multiple tasks. In order to perform multiple classification tasks with one neural network model, the losses of each task should be combined. Previous studies have mostly focused on prediction of multiple tasks using joint loss with static weights for training model. Choosing weights between tasks have not taken any considerations while it is set by uniformly or empirically. In this study, we propose a method to make joint loss using dynamic weights to improve total performance not an individual performance of tasks, and apply this method to end-to-end multimodal emotion and gender recognition model using audio and video data. This approach provides proper weights for each loss of the tasks when training ends. In our experiment, a performance of emotion and gender recognition with proposed method shows lower joint loss which is computed as negative log-likelihood than the one with static weights of joint loss. Also, our proposed model shows better generalizability than compared models. In our best knowledge, this research shows the strength of dynamic weights of joint loss for maximizing total performance at first in emotion and gender recognition task.

##### Abstract (translated by Google)
多任务学习（MTL）是提高多任务可普遍性的方法之一。为了使用一个神经网络模型执行多个分类任务，应该组合每个任务的损失。以前的研究主要集中在使用关节损失和训练模型的静态权重预测多个任务。在通过统一或经验设置任务之间选择权重时没有考虑任何因素。在这项研究中，我们提出了一种使用动态权重进行关节损失的方法，以提高总体绩效而不是单个任务执行，并将此方法应用于使用音频和视频数据的端到端多模态情感和性别识别模型。这种方法为训练结束时每次失去的任务提供适当的权重。在我们的实验中，用所提出的方法表现出情绪和性别识别表现出较低的关节损失，其计算为负对数似然，而不是具有关节损失静态权重的关节损失。此外，我们提出的模型显示出比相比模型更好的普遍性。根据我们的最佳知识，这项研究显示了关节损失的动态权重的强度，以在情绪和性别识别任务中最大化总体表现。

##### URL
[http://arxiv.org/abs/1809.00758](http://arxiv.org/abs/1809.00758)

##### PDF
[http://arxiv.org/pdf/1809.00758](http://arxiv.org/pdf/1809.00758)

