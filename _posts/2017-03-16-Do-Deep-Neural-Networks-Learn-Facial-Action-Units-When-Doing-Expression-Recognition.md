---
layout: post
title: "Do Deep Neural Networks Learn Facial Action Units When Doing Expression Recognition?"
date: 2017-03-16 03:07:21
categories: arXiv_CV
tags: arXiv_CV Knowledge Face CNN Prediction Recognition
author: Pooya Khorrami, Tom Le Paine, Thomas S. Huang
mathjax: true
---

* content
{:toc}

##### Abstract
Despite being the appearance-based classifier of choice in recent years, relatively few works have examined how much convolutional neural networks (CNNs) can improve performance on accepted expression recognition benchmarks and, more importantly, examine what it is they actually learn. In this work, not only do we show that CNNs can achieve strong performance, but we also introduce an approach to decipher which portions of the face influence the CNN's predictions. First, we train a zero-bias CNN on facial expression data and achieve, to our knowledge, state-of-the-art performance on two expression recognition benchmarks: the extended Cohn-Kanade (CK+) dataset and the Toronto Face Dataset (TFD). We then qualitatively analyze the network by visualizing the spatial patterns that maximally excite different neurons in the convolutional layers and show how they resemble Facial Action Units (FAUs). Finally, we use the FAU labels provided in the CK+ dataset to verify that the FAUs observed in our filter visualizations indeed align with the subject's facial movements.

##### Abstract (translated by Google)
尽管近年来被选为基于外表的分类器，但相对较少的作品已经研究了多少卷积神经网络（CNNs）可以提高公认的表达式识别基准的性能，更重要的是，研究它们实际学到的是什么。在这项工作中，我们不仅证明了CNN可以取得强大的表现，而且还介绍了一种方法来破译脸部的哪些部分影响CNN的预测。首先，我们对面部表情数据进行零偏置CNN训练，就我们所知，在两个表达式识别基准上实现了最新的性能：扩展的Cohn-Kanade（CK +）数据集和多伦多人脸数据集（TFD ）。然后，我们通过可视化最大程度地激发卷积层中不同神经元的空间模式来定性分析网络，并显示它们如何类似于面部动作单元（FAU）。最后，我们使用CK +数据集中提供的FAU标签来验证在我们的过滤器可视化中观察到的FAU确实与对象的面部运动对齐。

##### URL
[https://arxiv.org/abs/1510.02969](https://arxiv.org/abs/1510.02969)

##### PDF
[https://arxiv.org/pdf/1510.02969](https://arxiv.org/pdf/1510.02969)

