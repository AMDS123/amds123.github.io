---
layout: post
title: "Learning Discrete Bayesian Networks from Continuous Data"
date: 2018-09-18 02:44:57
categories: arXiv_AI
tags: arXiv_AI Relation
author: Yi-Chun Chen, Tim Allan Wheeler, Mykel John Kochenderfer
mathjax: true
---

* content
{:toc}

##### Abstract
Learning Bayesian networks from raw data can help provide insights into the relationships between variables. While real data often contains a mixture of discrete and continuous-valued variables, many Bayesian network structure learning algorithms assume all random variables are discrete. Thus, continuous variables are often discretized when learning a Bayesian network. However, the choice of discretization policy has significant impact on the accuracy, speed, and interpretability of the resulting models. This paper introduces a principled Bayesian discretization method for continuous variables in Bayesian networks with quadratic complexity instead of the cubic complexity of other standard techniques. Empirical demonstrations show that the proposed method is superior to the established minimum description length algorithm. In addition, this paper shows how to incorporate existing methods into the structure learning process to discretize all continuous variables and simultaneously learn Bayesian network structures.

##### Abstract (translated by Google)
从原始数据中学习贝叶斯网络有助于深入了解变量之间的关系。虽然实际数据通常包含离散和连续值变量的混合，但许多贝叶斯网络结构学习算法假设所有随机变量都是离散的。因此，在学习贝叶斯网络时，连续变量通常是离散的。但是，离散化政策的选择会对结果模型的准确性，速度和可解释性产生重大影响。本文介绍了贝叶斯网络中连续变量的原理贝叶斯离散化方法，该方法具有二次复杂度，而不是其他标准技术的立方复杂度。经验证明表明，该方法优于已建立的最小描述长度算法。此外，本文还展示了如何将现有方法融入结构学习过程中，以便对所有连续变量进行离散化，同时学习贝叶斯网络结构。

##### URL
[http://arxiv.org/abs/1512.02406](http://arxiv.org/abs/1512.02406)

##### PDF
[http://arxiv.org/pdf/1512.02406](http://arxiv.org/pdf/1512.02406)

