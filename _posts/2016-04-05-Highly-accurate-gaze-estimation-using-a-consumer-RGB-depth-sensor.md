---
layout: post
title: "Highly accurate gaze estimation using a consumer RGB-depth sensor"
date: 2016-04-05 20:50:40
categories: arXiv_CV
tags: arXiv_CV Face Pose_Estimation
author: Reza Shoja Ghiass, Ognjen Arandjelovic
mathjax: true
---

* content
{:toc}

##### Abstract
Determining the direction in which a person is looking is an important problem in a wide range of HCI applications. In this paper we describe a highly accurate algorithm that performs gaze estimation using an affordable and widely available device such as Kinect. The method we propose starts by performing accurate head pose estimation achieved by fitting a person specific morphable model of the face to depth data. The ordinarily competing requirements of high accuracy and high speed are met concurrently by formulating the fitting objective function as a combination of terms which excel either in accurate or fast fitting, and then by adaptively adjusting their relative contributions throughout fitting. Following pose estimation, pose normalization is done by re-rendering the fitted model as a frontal face. Finally gaze estimates are obtained through regression from the appearance of the eyes in synthetic, normalized images. Using EYEDIAP, the standard public dataset for the evaluation of gaze estimation algorithms from RGB-D data, we demonstrate that our method greatly outperforms the state of the art.

##### Abstract (translated by Google)
确定一个人正在寻找的方向是一个重要的问题在广泛的人机交互应用。在本文中，我们描述了一个高度精确的算法，使用Kinect等价格合理且广泛使用的设备来执行注视估计。我们提出的方法开始于通过将人脸特定形变模型拟合到深度数据来实现精确的头部姿态估计。通过将拟合目标函数作为精确或快速拟合优于条件的组合，然后通过自适应地调整它们在整个拟合中的相对贡献，来同时满足高精度和高速度的通常竞争要求。在姿态估计之后，姿态归一化通过将拟合模型重新渲染为正面来完成。最后，凝视估计是通过从合成的，归一化图像中的眼睛的外观回归获得的。使用EYEDIAP（标准公共数据集）来评估来自RGB-D数据的注视估算算法，我们证明了我们的方法大大优于现有技术。

##### URL
[https://arxiv.org/abs/1604.01420](https://arxiv.org/abs/1604.01420)

##### PDF
[https://arxiv.org/pdf/1604.01420](https://arxiv.org/pdf/1604.01420)

