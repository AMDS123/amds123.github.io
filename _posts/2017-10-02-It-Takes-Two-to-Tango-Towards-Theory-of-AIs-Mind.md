---
layout: post
title: "It Takes Two to Tango: Towards Theory of AI's Mind"
date: 2017-10-02 17:55:50
categories: arXiv_CV
tags: arXiv_CV Knowledge QA Attention Prediction VQA
author: Arjun Chandrasekaran, Deshraj Yadav, Prithvijit Chattopadhyay, Viraj Prabhu, Devi Parikh
mathjax: true
---

* content
{:toc}

##### Abstract
Theory of Mind is the ability to attribute mental states (beliefs, intents, knowledge, perspectives, etc.) to others and recognize that these mental states may differ from one's own. Theory of Mind is critical to effective communication and to teams demonstrating higher collective performance. To effectively leverage the progress in Artificial Intelligence (AI) to make our lives more productive, it is important for humans and AI to work well together in a team. Traditionally, there has been much emphasis on research to make AI more accurate, and (to a lesser extent) on having it better understand human intentions, tendencies, beliefs, and contexts. The latter involves making AI more human-like and having it develop a theory of our minds. In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks. We instantiate these ideas within the domain of Visual Question Answering (VQA). We find that using just a few examples (50), lay people can be trained to better predict responses and oncoming failures of a complex VQA model. We further evaluate the role existing explanation (or interpretability) modalities play in helping humans build ToAIM. Explainable AI has received considerable scientific and popular attention in recent times. Surprisingly, we find that having access to the model's internal states - its confidence in its top-k predictions, explicit or implicit attention maps which highlight regions in the image (and words in the question) the model is looking at (and listening to) while answering a question about an image - do not help people better predict its behavior.

##### Abstract (translated by Google)
心理理论是将心理状态（信仰，意图，知识，观点等）归因于他人并且认识到这些心理状态可能与自己不同的能力。心理理论对于有效沟通和表现出更高集体表现的团队至关重要。为了有效地利用人工智能（AI）的进步来提高我们的生活效率，人类和AI在团队中一起工作非常重要。传统上，人们一直非常重视研究，以使AI更准确，并且（在较小程度上）使其更好地理解人类的意图，倾向，信仰和背景。后者涉及使AI更像人类，并让它发展我们的思想理论。在这项工作中，我们认为人类AI团队要有效，人类还必须发展人工智能理论（ToAIM） - 了解其优势，劣势，信念和怪癖。我们在Visual Question Answering（VQA）领域中实例化这些想法。我们发现只使用几个例子（50），可以训练非专业人员更好地预测复杂VQA模型的响应和即将发生的故障。我们进一步评估现有解释（或可解释性）模式在帮助人类构建ToAIM方面所起的作用。可解释的人工智能近来受到了相当多的科学和普遍的关注。令人惊讶的是，我们发现可以访问模型的内部状态 - 它对top-k预测的信心，显式或隐式注意力图，突出显示图像中的区域（以及问题中的单词）模型正在查看（和收听）在回答关于图像的问题时 - 不要帮助人们更好地预测其行为。

##### URL
[https://arxiv.org/abs/1704.00717](https://arxiv.org/abs/1704.00717)

##### PDF
[https://arxiv.org/pdf/1704.00717](https://arxiv.org/pdf/1704.00717)

