---
layout: post
title: "It Takes Two to Tango: Towards Theory of AI's Mind"
date: 2017-10-02 17:55:50
categories: arXiv_CV
tags: arXiv_CV VQA
author: Arjun Chandrasekaran, Deshraj Yadav, Prithvijit Chattopadhyay, Viraj Prabhu, Devi Parikh
mathjax: true
---

* content
{:toc}

##### Abstract
Theory of Mind is the ability to attribute mental states (beliefs, intents, knowledge, perspectives, etc.) to others and recognize that these mental states may differ from one's own. Theory of Mind is critical to effective communication and to teams demonstrating higher collective performance. To effectively leverage the progress in Artificial Intelligence (AI) to make our lives more productive, it is important for humans and AI to work well together in a team. Traditionally, there has been much emphasis on research to make AI more accurate, and (to a lesser extent) on having it better understand human intentions, tendencies, beliefs, and contexts. The latter involves making AI more human-like and having it develop a theory of our minds. In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs, and quirks. We instantiate these ideas within the domain of Visual Question Answering (VQA). We find that using just a few examples (50), lay people can be trained to better predict responses and oncoming failures of a complex VQA model. We further evaluate the role existing explanation (or interpretability) modalities play in helping humans build ToAIM. Explainable AI has received considerable scientific and popular attention in recent times. Surprisingly, we find that having access to the model's internal states - its confidence in its top-k predictions, explicit or implicit attention maps which highlight regions in the image (and words in the question) the model is looking at (and listening to) while answering a question about an image - do not help people better predict its behavior.

##### Abstract (translated by Google)
心理理论是将心理状态（信念，意图，知识，观点等）归于他人的能力，并认识到这些心理状态可能与自己的不同。心理理论对有效沟通和团队表现更高的团队至关重要。为了有效地利用人工智能（AI）的进步，使我们的生活更富有成效，对于人类和人工智能来说，团队合作是非常重要的。传统上，人们一直非常重视研究，使人工智能更加准确，并且（在较小程度上）更好地理解人的意图，倾向，信仰和背景。后者涉及使AI更加人性化，让它发展出我们的头脑理论。在这项工作中，我们认为人类AI团队是有效的，人类也必须发展AI的理论（ToAIM） - 了解它的长处，弱点，信念和怪癖。我们在Visual Question Answering（VQA）的范畴内实例化这些想法。我们发现，只用几个例子（50），就可以训练外行人员更好地预测复杂的VQA模型的响应和迎面而来的失败。我们进一步评估现有解释（或可解释性）模式在帮助人类建立ToAIM方面的作用。可解释的AI近来受到了相当多的科学和普遍的关注。令人惊讶的是，我们发现可以访问模型的内部状态 - 它对前k个预测的信心，显示或隐含的注意图，突出显示图像中的区域（和问题中的单词）模型正在查看（并听取）同时回答关于图像的问题 - 不能帮助人们更好地预测其行为。

##### URL
[https://arxiv.org/abs/1704.00717](https://arxiv.org/abs/1704.00717)

##### PDF
[https://arxiv.org/pdf/1704.00717](https://arxiv.org/pdf/1704.00717)

