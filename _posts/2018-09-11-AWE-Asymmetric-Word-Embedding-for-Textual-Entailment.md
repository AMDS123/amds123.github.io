---
layout: post
title: "AWE: Asymmetric Word Embedding for Textual Entailment"
date: 2018-09-11 17:30:12
categories: arXiv_CL
tags: arXiv_CL Embedding Deep_Learning Relation
author: Tengfei Ma, Chiamin Wu, Cao Xiao, Jimeng Sun
mathjax: true
---

* content
{:toc}

##### Abstract
Textual entailment is a fundamental task in natural language processing. It refers to the directional relation between text fragments such that the "premise" can infer "hypothesis". In recent years deep learning methods have achieved great success in this task. Many of them have considered the inter-sentence word-word interactions between the premise-hypothesis pairs, however, few of them considered the "asymmetry" of these interactions. Different from paraphrase identification or sentence similarity evaluation, textual entailment is essentially determining a directional (asymmetric) relation between the premise and the hypothesis. In this paper, we propose a simple but effective way to enhance existing textual entailment algorithms by using asymmetric word embeddings. Experimental results on SciTail and SNLI datasets show that the learned asymmetric word embeddings could significantly improve the word-word interaction based textual entailment models. It is noteworthy that the proposed AWE-DeIsTe model can get 2.1% accuracy improvement over prior state-of-the-art on SciTail.

##### Abstract (translated by Google)
文本蕴涵是自然语言处理的基本任务。它指的是文本片段之间的方向关系，使得“前提”可以推断出“假设”。近年来，深度学习方法在这项任务中取得了巨大成功。他们中的许多人已经考虑了前提 - 假设对之间的句子间词 - 词相互作用，然而，他们中很少有人认为这些相互作用的“不对称性”。与复述识别或句子相似性评估不同，文本蕴涵基本上是确定前提和假设之间的方向（不对称）关系。在本文中，我们提出了一种简单但有效的方法，通过使用非对称字嵌入来增强现有的文本蕴涵算法。 SciTail和SNLI数据集的实验结果表明，学习的非对称词嵌入可以显着改善基于文字蕴涵模型的单词 - 词交互。值得注意的是，与SciTail先前的最新技术相比，所提出的AWE-DeIsTe模型可以获得2.1％的准确度提升。

##### URL
[http://arxiv.org/abs/1809.04047](http://arxiv.org/abs/1809.04047)

##### PDF
[http://arxiv.org/pdf/1809.04047](http://arxiv.org/pdf/1809.04047)

