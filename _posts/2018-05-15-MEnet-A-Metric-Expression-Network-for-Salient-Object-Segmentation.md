---
layout: post
title: "MEnet: A Metric Expression Network for Salient Object Segmentation"
date: 2018-05-15 08:32:42
categories: arXiv_CV
tags: arXiv_CV Salient Segmentation
author: Shulian Cai, Jiabin Huang, Delu Zeng, Xinghao Ding, John Paisley
mathjax: true
---

* content
{:toc}

##### Abstract
Recent CNN-based saliency models have achieved great performance on public datasets, however, most of them are sensitive to distortion (e.g., noise, compression). In this paper, an end-to-end generic salient object segmentation model called Metric Expression Network (MEnet) is proposed to overcome this drawback. Within this architecture, we construct a new topological metric space, with the implicit metric being determined by the deep network. In this way, we succeed in grouping all the pixels within the observed image semantically within this latent space into two regions: a salient region and a non-salient region. With this method, all feature extractions are carried out at the pixel level, which makes the output boundaries of salient object fine-grained. Experimental results show that the proposed metric can generate robust salient maps that allow for object segmentation. By testing the method on several public benchmarks, we show that the performance of MEnet has achieved good results. Furthermore, the proposed method outperforms previous CNN-based methods on distorted images.

##### Abstract (translated by Google)
最近的基于CNN的显着性模型在公共数据集上取得了很好的性能，然而，它们中的大多数对失真（例如噪声，压缩）敏感。在本文中，提出了一种称为Metric Expression Network（MEnet）的端到端通用显着对象分割模型来克服这个缺点。在这种体系结构中，我们构造了一个新的拓扑度量空间，其中隐式度量由深度网络决定。通过这种方式，我们成功地将观察图像内的所有像素在该潜在空间内语义分组为两个区域：显着区域和非显着区域。使用这种方法，所有特征提取都在像素级执行，这使得显着对象的输出边界变得细致。实验结果表明，所提出的度量可以生成允许进行对象分割的鲁棒显着映射。通过在几个公共基准测试方法，我们表明，MEnet的性能取得了良好的效果。此外，所提出的方法胜过以前基于CNN的方法对失真图像。

##### URL
[http://arxiv.org/abs/1805.05638](http://arxiv.org/abs/1805.05638)

##### PDF
[http://arxiv.org/pdf/1805.05638](http://arxiv.org/pdf/1805.05638)

