---
layout: post
title: "Interpretable Set Functions"
date: 2018-05-31 18:53:15
categories: arXiv_AI
tags: arXiv_AI Sparse
author: Andrew Cotter, Maya Gupta, Heinrich Jiang, James Muller, Taman Narayan, Serena Wang, Tao Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
We propose learning flexible but interpretable functions that aggregate a variable-length set of permutation-invariant feature vectors to predict a label. We use a deep lattice network model so we can architect the model structure to enhance interpretability, and add monotonicity constraints between inputs-and-outputs. We then use the proposed set function to automate the engineering of dense, interpretable features from sparse categorical features, which we call semantic feature engine. Experiments on real-world data show the achieved accuracy is similar to deep sets or deep neural networks, and is easier to debug and understand.

##### Abstract (translated by Google)
我们提出了学习灵活但可解释的函数，这些函数聚合一组变长不变特征向量来预测标签。我们使用深度网格模型，因此我们可以构建模型结构以提高可解释性，并在输入和输出之间添加单调性约束。然后，我们使用所提出的集合函数来从稀疏分类特征（我们称之为语义特征引擎）自动化密集，可解释特征的工程。对实际数据的实验表明，实现的精度类似于深度集或深度神经网络，并且更易于调试和理解。

##### URL
[http://arxiv.org/abs/1806.00050](http://arxiv.org/abs/1806.00050)

##### PDF
[http://arxiv.org/pdf/1806.00050](http://arxiv.org/pdf/1806.00050)

