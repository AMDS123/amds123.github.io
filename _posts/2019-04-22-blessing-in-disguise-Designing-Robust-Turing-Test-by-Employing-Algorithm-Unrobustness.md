---
layout: post
title: "blessing in disguise: Designing Robust Turing Test by Employing Algorithm Unrobustness"
date: 2019-04-22 11:41:30
categories: arXiv_CV
tags: arXiv_CV Adversarial Deep_Learning Quantitative Recognition
author: Jiaming Zhang, Jitao Sang, Kaiyuan Xu, Shangxi Wu, Yongli Hu, Yanfeng Sun, Jian Yu
mathjax: true
---

* content
{:toc}

##### Abstract
Turing test was originally proposed to examine whether machine's behavior is indistinguishable from a human. The most popular and practical Turing test is CAPTCHA, which is to discriminate algorithm from human by offering recognition-alike questions. The recent development of deep learning has significantly advanced the capability of algorithm in solving CAPTCHA questions, forcing CAPTCHA designers to increase question complexity. Instead of designing questions difficult for both algorithm and human, this study attempts to employ the limitations of algorithm to design robust CAPTCHA questions easily solvable to human. Specifically, our data analysis observes that human and algorithm demonstrates different vulnerability to visual distortions: adversarial perturbation is significantly annoying to algorithm yet friendly to human. We are motivated to employ adversarially perturbed images for robust CAPTCHA design in the context of character-based questions. Three modules of multi-target attack, ensemble adversarial training, and image preprocessing differentiable approximation are proposed to address the characteristics of character-based CAPTCHA cracking. Qualitative and quantitative experimental results demonstrate the effectiveness of the proposed solution. We hope this study can lead to the discussions around adversarial attack/defense in CAPTCHA design and also inspire the future attempts in employing algorithm limitation for practical usage.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.09804](http://arxiv.org/abs/1904.09804)

##### PDF
[http://arxiv.org/pdf/1904.09804](http://arxiv.org/pdf/1904.09804)

