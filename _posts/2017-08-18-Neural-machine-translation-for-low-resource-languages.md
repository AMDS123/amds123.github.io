---
layout: post
title: "Neural machine translation for low-resource languages"
date: 2017-08-18 18:16:23
categories: arXiv_CL
tags: arXiv_CL NMT
author: Robert Östling, Jörg Tiedemann
mathjax: true
---

* content
{:toc}

##### Abstract
Neural machine translation (NMT) approaches have improved the state of the art in many machine translation settings over the last couple of years, but they require large amounts of training data to produce sensible output. We demonstrate that NMT can be used for low-resource languages as well, by introducing more local dependencies and using word alignments to learn sentence reordering during translation. In addition to our novel model, we also present an empirical evaluation of low-resource phrase-based statistical machine translation (SMT) and NMT to investigate the lower limits of the respective technologies. We find that while SMT remains the best option for low-resource settings, our method can produce acceptable translations with only 70000 tokens of training data, a level where the baseline NMT system fails completely.

##### Abstract (translated by Google)
在过去几年中，神经机器翻译（NMT）方法已经改进了许多机器翻译设置的技术水平，但是它们需要大量的训练数据来产生合理的输出。我们证明NMT也可以用于低资源语言，通过引入更多的本地依赖和使用单词对齐来学习在翻译过程中的句子重新排序。除了我们的新模型，我们还提出了一个低资源的基于短语的统计机器翻译（SMT）和NMT的实证评估来调查各自技术的下限。我们发现虽然SMT仍然是低资源设置的最佳选择，但是我们的方法只能产生70000令牌的训练数据，这是基线NMT系统完全失败的水平。

##### URL
[https://arxiv.org/abs/1708.05729](https://arxiv.org/abs/1708.05729)

##### PDF
[https://arxiv.org/pdf/1708.05729](https://arxiv.org/pdf/1708.05729)

