---
layout: post
title: "Logographic Subword Model for Neural Machine Translation"
date: 2018-09-07 17:34:34
categories: arXiv_CL
tags: arXiv_CL Inference RNN
author: Yihao Fang, Rong Zheng, Xiaodan Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
A novel logographic subword model is proposed to reinterpret logograms as abstract subwords for neural machine translation. Our approach drastically reduces the size of an artificial neural network, while maintaining comparable BLEU scores as those attained with the baseline RNN and CNN seq2seq models. The smaller model size also leads to shorter training and inference time. Experiments demonstrate that in the tasks of English-Chinese/Chinese-English translation, the reduction of those aspects can be from $11\%$ to as high as $77\%$. Compared to previous subword models, abstract subwords can be applied to various logographic languages. Considering most of the logographic languages are ancient and very low resource languages, these advantages are very desirable for archaeological computational linguistic applications such as a resource-limited offline hand-held Demotic-English translator.

##### Abstract (translated by Google)
提出了一种新颖的逻辑子字模型，将逻辑图重新解释为神经机器翻译的抽象子词。我们的方法大大减少了人工神经网络的规模，同时保持了与基线RNN和CNN seq2seq模型获得的BLEU分数相当的BLEU分数。较小的模型尺寸也会缩短培训和推理时间。实验表明，在英汉/英汉翻译的任务中，这些方面的减少可以从$ 11 \％$到$ 77 \％$。与先前的子词模型相比，抽象子词可以应用于各种语言语言。考虑到大多数语言语言是古老的和非常低资源的语言，这些优点对于考古计算语言应用是非常期望的，例如资源有限的离线手持式Demotic-English翻译器。

##### URL
[https://arxiv.org/abs/1809.02592](https://arxiv.org/abs/1809.02592)

##### PDF
[https://arxiv.org/pdf/1809.02592](https://arxiv.org/pdf/1809.02592)

