---
layout: post
title: "Mapping Instructions and Visual Observations to Actions with Reinforcement Learning"
date: 2017-07-22 15:10:11
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning
author: Dipendra Misra, John Langford, Yoav Artzi
mathjax: true
---

* content
{:toc}

##### Abstract
We propose to directly map raw visual observations and text input to actions for instruction execution. While existing approaches assume access to structured environment representations or use a pipeline of separately trained models, we learn a single model to jointly reason about linguistic and visual input. We use reinforcement learning in a contextual bandit setting to train a neural network agent. To guide the agent's exploration, we use reward shaping with different forms of supervision. Our approach does not require intermediate representations, planning procedures, or training different models. We evaluate in a simulated environment, and show significant improvements over supervised learning and common reinforcement learning variants.

##### Abstract (translated by Google)
我们建议直接将原始视觉观察和文本输入映射到指令执行的动作。虽然现有的方法假定可以访问结构化的环境表示或使用单独训练模型的流水线，但是我们学习了一个单一的模型来共同推理语言和视觉输入。我们使用强化学习的背景下的匪徒设置来训练一个神经网络代理。为了引导代理人的探索，我们使用不同形式的监督进行奖励塑造。我们的方法不需要中间表示，计划程序或训练不同的模型。我们在模拟环境中进行评估，并且与监督学习和常规强化学习变体相比显示出显着的改进。

##### URL
[https://arxiv.org/abs/1704.08795](https://arxiv.org/abs/1704.08795)

##### PDF
[https://arxiv.org/pdf/1704.08795](https://arxiv.org/pdf/1704.08795)

