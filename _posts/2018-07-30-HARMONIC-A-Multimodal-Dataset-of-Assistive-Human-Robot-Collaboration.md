---
layout: post
title: "HARMONIC: A Multimodal Dataset of Assistive Human-Robot Collaboration"
date: 2018-07-30 02:55:18
categories: arXiv_RO
tags: arXiv_RO Prediction
author: Benjamin A. Newman, Reuben M. Aronson, Siddartha S. Srinivasa, Kris Kitani, Henny Admoni
mathjax: true
---

* content
{:toc}

##### Abstract
We present HARMONIC, a large multi-modal dataset of human interactions in a shared autonomy setting. The dataset provides human, robot, and environment data streams from twenty-four people engaged in an assistive eating task with a 6 degree-of-freedom (DOF) robot arm. From each participant, we recorded video of both eyes, egocentric video from a head-mounted camera, joystick commands, electromyography from the participant's forearm used to operate the joystick, third person stereo video, and the joint positions of the 6 DOF robot arm. Also included are several data streams that come as a direct result of these recordings, namely eye gaze fixations in the egocentric camera frame and body position skeletons. This dataset could be of interest to researchers studying intention prediction, human mental state modeling, and shared autonomy. Data streams are provided in a variety of formats such as video and human-readable csv or yaml files.

##### Abstract (translated by Google)
我们在共享自治设置中呈现HARMONIC，一个人类交互的大型多模态数据集。该数据集提供了来自24名参与辅助进食任务的人员，机器人和环境数据流以及6自由度（DOF）机器人手臂。从每个参与者，我们记录了双眼的视频，来自头戴式摄像机的自我中心视频，操纵杆命令，用于操作操纵杆的参与者前臂的肌电图，第三人立体视频以及6自由度机器人手臂的关节位置。还包括作为这些记录的直接结果的若干数据流，即以自我为中心的相机框架和身体位置骨架中的眼睛注视固定。研究意图预测，人类心理状态建模和共享自治的研究人员可能会对此数据集感兴趣。数据流以各种格式提供，例如视频和人类可读的csv或yaml文件。

##### URL
[http://arxiv.org/abs/1807.11154](http://arxiv.org/abs/1807.11154)

##### PDF
[http://arxiv.org/pdf/1807.11154](http://arxiv.org/pdf/1807.11154)

