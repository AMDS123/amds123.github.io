---
layout: post
title: "Stacked Semantic-Guided Attention Model for Fine-Grained Zero-Shot Learning"
date: 2018-05-21 15:12:19
categories: arXiv_CV
tags: arXiv_CV Attention Classification Prediction Relation
author: Yunlong Yu, Zhong Ji, Yanwei Fu, Jichang Guo, Yanwei Pang, Zhongfei Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Zero-Shot Learning (ZSL) is achieved via aligning the semantic relationships between the global image feature vector and the corresponding class semantic descriptions. However, using the global features to represent fine-grained images may lead to sub-optimal results since they neglect the discriminative differences of local regions. Besides, different regions contain distinct discriminative information. The important regions should contribute more to the prediction. To this end, we propose a novel stacked semantics-guided attention (S2GA) model to obtain semantic relevant features by using individual class semantic features to progressively guide the visual features to generate an attention map for weighting the importance of different local regions. Feeding both the integrated visual features and the class semantic features into a multi-class classification architecture, the proposed framework can be trained end-to-end. Extensive experimental results on CUB and NABird datasets show that the proposed approach has a consistent improvement on both fine-grained zero-shot classification and retrieval tasks.

##### Abstract (translated by Google)
通过对齐全局图像特征向量和相应的类语义描述之间的语义关系，实现零点学习（ZSL）。然而，使用全局特征来表示细粒度图像可能会导致次优结果，因为它们忽略了局部区域的区别性差异。此外，不同区域包含明显的区别性信息。重要地区应该对预测做出更多贡献。为此，我们提出了一种新颖的堆叠语义引导注意（S2GA）模型，通过使用个别类的语义特征，逐步引导的视觉特征以生成注意图用于加权不同局部区域的重要性，以得到语义相关特征。将综合视觉特征和类语义特征提供给多类分类体系结构，所提议的框架可以被端对端训练。在CUB和NABird数据集上的广泛的实验结果表明，所提出的方法在细粒度零炮分类和检索任务上具有一致的改进。

##### URL
[https://arxiv.org/abs/1805.08113](https://arxiv.org/abs/1805.08113)

##### PDF
[https://arxiv.org/pdf/1805.08113](https://arxiv.org/pdf/1805.08113)

