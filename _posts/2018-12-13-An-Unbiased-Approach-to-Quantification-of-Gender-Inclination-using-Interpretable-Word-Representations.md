---
layout: post
title: "An Unbiased Approach to Quantification of Gender Inclination using Interpretable Word Representations"
date: 2018-12-13 21:00:05
categories: arXiv_CL
tags: arXiv_CL Embedding Language_Model
author: Navid Rekabsaz, Allan Hanbury
mathjax: true
---

* content
{:toc}

##### Abstract
Recent advances in word embedding provide significant benefit to various information processing tasks. Yet these dense representations and their estimation of word-to-word relatedness remain difficult to interpret and hard to analyze. As an alternative, explicit word representations i.e. vectors with clearly-defined dimensions, which can be words, windows of words, or documents are easily interpretable, and recent methods show competitive performance to the dense vectors. In this work, we propose a method to transfer word2vec SkipGram embedding model to its explicit representation model. The method provides interpretable explicit vectors while keeping the effectiveness of the original model, tested by evaluating the model on several word association collections. Based on the proposed explicit representation, we propose a novel method to quantify the degree of the existence of gender bias in the English language (used in Wikipedia) with regard to a set of occupations. By measuring the bias towards explicit Female and Male factors, the work demonstrates a general tendency of the majority of the occupations to male and a strong bias in a few specific occupations (e.g. nurse) to female.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.10424](http://arxiv.org/abs/1812.10424)

##### PDF
[http://arxiv.org/pdf/1812.10424](http://arxiv.org/pdf/1812.10424)

