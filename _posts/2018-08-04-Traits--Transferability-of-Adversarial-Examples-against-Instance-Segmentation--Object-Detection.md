---
layout: post
title: "Traits & Transferability of Adversarial Examples against Instance Segmentation & Object Detection"
date: 2018-08-04 08:57:58
categories: arXiv_CV
tags: arXiv_CV Adversarial Object_Detection Segmentation Image_Classification Classification Detection
author: Raghav Gurbaxani, Shivank Mishra
mathjax: true
---

* content
{:toc}

##### Abstract
Despite the recent advancements in deploying neural networks for image classification, it has been found that adversarial examples are able to fool these models leading them to misclassify the images. Since these models are now being widely deployed, we provide an insight on the threat of these adversarial examples by evaluating their characteristics and transferability to more complex models that utilize Image Classification as a subtask. We demonstrate the ineffectiveness of adversarial examples when applied to Instance Segmentation & Object Detection models. We show that this ineffectiveness arises from the inability of adversarial examples to withstand transformations such as scaling or a change in lighting conditions. Moreover, we show that there exists a small threshold below which the adversarial property is retained while applying these input transformations. Additionally, these attacks demonstrate weak cross-network transferability across neural network architectures, e.g. VGG16 and ResNet50, however, the attack may fool both the networks if passed sequentially through networks during its formation. The lack of scalability and transferability challenges the question of how adversarial images would be effective in the real world.

##### Abstract (translated by Google)
尽管最近在部署用于图像分类的神经网络方面取得了进展，但已经发现，对抗性示例能够欺骗这些模型，导致它们对图像进行错误分类。由于这些模型现在已被广泛部署，我们通过评估这些模型的特征和可转移性来提供对这些对抗性示例的威胁的洞察力，这些模型利用图像分类作为子任务。我们在应用于实例分割和对象检测模型时证明了对抗性示例的无效性。我们表明，这种无效性源于对抗性例子无法承受缩放或光照条件变化等变形。此外，我们表明存在一个小阈值，低于该阈值，在应用这些输入转换时保留对抗性。另外，这些攻击表明跨越神经网络架构的弱跨网络可转移性，例如，然而，如果VGG16和ResNet50在网络形成过程中顺序通过网络，则攻击可能会欺骗两个网络。缺乏可扩展性和可转移性挑战了对抗性图像在现实世界中如何有效的问题。

##### URL
[https://arxiv.org/abs/1808.01452](https://arxiv.org/abs/1808.01452)

##### PDF
[https://arxiv.org/pdf/1808.01452](https://arxiv.org/pdf/1808.01452)

