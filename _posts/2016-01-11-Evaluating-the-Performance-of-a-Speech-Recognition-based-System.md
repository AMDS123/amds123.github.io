---
layout: post
title: "Evaluating the Performance of a Speech Recognition based System"
date: 2016-01-11 18:01:56
categories: arXiv_SD
tags: arXiv_SD Face Speech_Recognition Recognition
author: Vinod Kumar Pandey, Sunil Kumar Kopparapu
mathjax: true
---

* content
{:toc}

##### Abstract
Speech based solutions have taken center stage with growth in the services industry where there is a need to cater to a very large number of people from all strata of the society. While natural language speech interfaces are the talk in the research community, yet in practice, menu based speech solutions thrive. Typically in a menu based speech solution the user is required to respond by speaking from a closed set of words when prompted by the system. A sequence of human speech response to the IVR prompts results in the completion of a transaction. A transaction is deemed successful if the speech solution can correctly recognize all the spoken utterances of the user whenever prompted by the system. The usual mechanism to evaluate the performance of a speech solution is to do an extensive test of the system by putting it to actual people use and then evaluating the performance by analyzing the logs for successful transactions. This kind of evaluation could lead to dissatisfied test users especially if the performance of the system were to result in a poor transaction completion rate. To negate this the Wizard of Oz approach is adopted during evaluation of a speech system. Overall this kind of evaluations is an expensive proposition both in terms of time and cost. In this paper, we propose a method to evaluate the performance of a speech solution without actually putting it to people use. We first describe the methodology and then show experimentally that this can be used to identify the performance bottlenecks of the speech solution even before the system is actually used thus saving evaluation time and expenses.

##### Abstract (translated by Google)
基于言语的解决方案已经成为服务业发展的中心舞台，需要迎合来自社会各阶层的众多人士。虽然自然语言的语音界面是研究界的话题，但在实践中，基于菜单的语音解决方案蓬勃发展。典型地，在基于菜单的语音解决方案中，当系统提示时，用户需要通过从一组封闭的单词进行发言来进行响应。对IVR提示的一系列人类语音响应提示交易完成。如果语音解决方案能够在系统提示时正确识别用户的所有说出的话语，则交易被认为是成功的。评估语音解决方案性能的常用机制是通过将系统投入实际使用，然后通过分析成功事务的日志来评估性能来对系统进行广泛的测试。这种评估可能会导致不满意的测试用户，特别是如果系统的性能导致交易完成率较差。为了否定这一点，在对语音系统进行评估时采用了绿野仙踪的方法。总体而言，这种评估在时间和成本方面都是昂贵的。在本文中，我们提出了一种评估语音解决方案的性能的方法，而不用实际地将其用于人们的使用。我们首先描述方法，然后通过实验表明，即使在系统实际使用之前，这也可以用来识别语音解决方案的性能瓶颈，从而节省评估时间和费用。

##### URL
[https://arxiv.org/abs/1601.02543](https://arxiv.org/abs/1601.02543)

##### PDF
[https://arxiv.org/pdf/1601.02543](https://arxiv.org/pdf/1601.02543)

