---
layout: post
title: "Thin-Slicing Network: A Deep Structured Model for Pose Estimation in Videos"
date: 2017-03-31 13:59:31
categories: arXiv_CV
tags: arXiv_CV Knowledge Pose_Estimation Relation
author: Jie Song, Limin Wang, Luc Van Gool, Otmar Hilliges
mathjax: true
---

* content
{:toc}

##### Abstract
Deep ConvNets have been shown to be effective for the task of human pose estimation from single images. However, several challenging issues arise in the video-based case such as self-occlusion, motion blur, and uncommon poses with few or no examples in training data sets. Temporal information can provide additional cues about the location of body joints and help to alleviate these issues. In this paper, we propose a deep structured model to estimate a sequence of human poses in unconstrained videos. This model can be efficiently trained in an end-to-end manner and is capable of representing appearance of body joints and their spatio-temporal relationships simultaneously. Domain knowledge about the human body is explicitly incorporated into the network providing effective priors to regularize the skeletal structure and to enforce temporal consistency. The proposed end-to-end architecture is evaluated on two widely used benchmarks (Penn Action dataset and JHMDB dataset) for video-based pose estimation. Our approach significantly outperforms the existing state-of-the-art methods.

##### Abstract (translated by Google)
已经显示深度通信对于单个图像的人体姿态估计的任务是有效的。然而，在基于视频的情况下出现了几个具有挑战性的问题，如自闭塞，运动模糊和不常见的姿势，在训练数据集中几乎没有例子。时间信息可以提供关于身体关节位置的额外提示，并有助于缓解这些问题。在本文中，我们提出了一个深度结构化的模型来估计无约束视频中的人体姿势序列。该模型能够以端对端的方式高效地训练，并且能够同时表示身体关节的外观及其时空关系。关于人体的领域知识被明确地纳入网络，提供有效的先验来规范骨骼结构并强化时间一致性。所提出的端到端体系结构是在两个广泛使用的基准（Penn Action数据集和JHMDB数据集）上评估的，用于基于视频的姿态估计。我们的方法明显优于现有的最先进的方法。

##### URL
[https://arxiv.org/abs/1703.10898](https://arxiv.org/abs/1703.10898)

##### PDF
[https://arxiv.org/pdf/1703.10898](https://arxiv.org/pdf/1703.10898)

