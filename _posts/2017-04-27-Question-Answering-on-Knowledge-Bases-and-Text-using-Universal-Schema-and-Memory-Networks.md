---
layout: post
title: "Question Answering on Knowledge Bases and Text using Universal Schema and Memory Networks"
date: 2017-04-27 00:03:02
categories: arXiv_CV
tags: arXiv_CV Knowledge Memory_Networks
author: Rajarshi Das, Manzil Zaheer, Siva Reddy, Andrew McCallum
mathjax: true
---

* content
{:toc}

##### Abstract
Existing question answering methods infer answers either from a knowledge base or from raw text. While knowledge base (KB) methods are good at answering compositional questions, their performance is often affected by the incompleteness of the KB. Au contraire, web text contains millions of facts that are absent in the KB, however in an unstructured form. {\it Universal schema} can support reasoning on the union of both structured KBs and unstructured text by aligning them in a common embedded space. In this paper we extend universal schema to natural language question answering, employing \emph{memory networks} to attend to the large body of facts in the combination of text and KB. Our models can be trained in an end-to-end fashion on question-answer pairs. Evaluation results on \spades fill-in-the-blank question answering dataset show that exploiting universal schema for question answering is better than using either a KB or text alone. This model also outperforms the current state-of-the-art by 8.5 $F_1$ points.\footnote{Code and data available in \url{this https URL}}

##### Abstract (translated by Google)
现有的问题回答方法可以从知识库或原始文本中推断出答案。虽然知识库（Knowledge Base，KB）方法擅长回答组合问题，但其性能往往受知识库不完整性的影响。在互联网上，网络文本包含了数百万KB中缺少的事实，但是却是一种非结构化的形式。 {\ it Universal schema}可以通过将它们对齐到一个公共的嵌入式空间来支持结构化的KB和非结构化文本的联合推理。在本文中，我们将通用模式扩展到自然语言问题回答，采用\ emph {内存网络}来处理文本和KB组合中的大量事实。我们的模型可以在问题 - 答案对中以端到端的方式进行培训。在\黑桃填空问题答疑数据集的评估结果表明，使用通用模式进行问题回答要比单独使用KB或文本要好。这个模型也比目前的最新技术水平高出8.5 $ F_1 $分。\ footnote {代码和数据可在\ url {this https URL}}

##### URL
[https://arxiv.org/abs/1704.08384](https://arxiv.org/abs/1704.08384)

##### PDF
[https://arxiv.org/pdf/1704.08384](https://arxiv.org/pdf/1704.08384)

