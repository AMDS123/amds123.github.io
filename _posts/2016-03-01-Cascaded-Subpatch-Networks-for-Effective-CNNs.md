---
layout: post
title: "Cascaded Subpatch Networks for Effective CNNs"
date: 2016-03-01 03:44:49
categories: arXiv_CV
tags: arXiv_CV Knowledge CNN
author: Xiaoheng Jiang, Yanwei Pang, Manli Sun, Xuelong Li
mathjax: true
---

* content
{:toc}

##### Abstract
Conventional Convolutional Neural Networks (CNNs) use either a linear or non-linear filter to extract features from an image patch (region) of spatial size $ H\times W $ (Typically, $ H $ is small and is equal to $ W$, e.g., $ H $ is 5 or 7). Generally, the size of the filter is equal to the size $ H\times W $ of the input patch. We argue that the representation ability of equal-size strategy is not strong enough. To overcome the drawback, we propose to use subpatch filter whose spatial size $ h\times w $ is smaller than $ H\times W $. The proposed subpatch filter consists of two subsequent filters. The first one is a linear filter of spatial size $ h\times w $ and is aimed at extracting features from spatial domain. The second one is of spatial size $ 1\times 1 $ and is used for strengthening the connection between different input feature channels and for reducing the number of parameters. The subpatch filter convolves with the input patch and the resulting network is called a subpatch network. Taking the output of one subpatch network as input, we further repeat constructing subpatch networks until the output contains only one neuron in spatial domain. These subpatch networks form a new network called Cascaded Subpatch Network (CSNet). The feature layer generated by CSNet is called csconv layer. For the whole input image, we construct a deep neural network by stacking a sequence of csconv layers. Experimental results on four benchmark datasets demonstrate the effectiveness and compactness of the proposed CSNet. For example, our CSNet reaches a test error of $ 5.68\% $ on the CIFAR10 dataset without model averaging. To the best of our knowledge, this is the best result ever obtained on the CIFAR10 dataset.

##### Abstract (translated by Google)
传统的卷积神经网络（CNN）使用线性或非线性滤波器从空间大小为$ H \ times W $的图像块（区域）中提取特征（通常，$ H $很小，等于$ W $例如$ H $是5或7）。通常，过滤器的大小等于输入补丁的大小$ H \ times W $。我们认为同等规模战略的表征能力还不够强。为了克服这个缺点，我们建议使用空间大小$ h \ times w $小于$ H \ times W $的次级过滤器。建议的子插件过滤器由两个后续的过滤器组成。第一个是空间大小为$ h \ times w $的线性滤波器，旨在从空间域提取特征。第二个是空间大小$ 1 \ times 1 $，用于加强不同输入特征通道之间的连接并减少参数的数量。子派生过滤器与输入修补程序卷积，生成的网络称为子派生网络。以一个子网络的输出为输入，进一步重复构建子网络，直到输出只包含一个空间域的神经元。这些子节点网络形成一个称为级联子网络（CSNet）的新网络。 CSNet生成的要素图层称为csconv图层。对于整个输入图像，我们通过堆叠一系列csconv层来构建一个深度神经网络。在四个基准数据集上的实验结果证明了所提出的CSNet的有效性和紧凑性。例如，我们的CSNet在CIFAR10数据集上的测试错误为$ 5.68 \％$，没有进行模型平均。据我们所知，这是在CIFAR10数据集上获得的最好结果。

##### URL
[https://arxiv.org/abs/1603.00128](https://arxiv.org/abs/1603.00128)

##### PDF
[https://arxiv.org/pdf/1603.00128](https://arxiv.org/pdf/1603.00128)

