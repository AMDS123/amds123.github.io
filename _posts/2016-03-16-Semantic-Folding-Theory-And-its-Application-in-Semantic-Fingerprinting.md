---
layout: post
title: "Semantic Folding Theory And its Application in Semantic Fingerprinting"
date: 2016-03-16 22:04:51
categories: arXiv_CL
tags: arXiv_CL Sparse GAN
author: Francisco De Sousa Webber
mathjax: true
---

* content
{:toc}

##### Abstract
Human language is recognized as a very complex domain since decades. No computer system has been able to reach human levels of performance so far. The only known computational system capable of proper language processing is the human brain. While we gather more and more data about the brain, its fundamental computational processes still remain obscure. The lack of a sound computational brain theory also prevents the fundamental understanding of Natural Language Processing. As always when science lacks a theoretical foundation, statistical modeling is applied to accommodate as many sampled real-world data as possible. An unsolved fundamental issue is the actual representation of language (data) within the brain, denoted as the Representational Problem. Starting with Jeff Hawkins' Hierarchical Temporal Memory (HTM) theory, a consistent computational theory of the human cortex, we have developed a corresponding theory of language data representation: The Semantic Folding Theory. The process of encoding words, by using a topographic semantic space as distributional reference frame into a sparse binary representational vector is called Semantic Folding and is the central topic of this document. Semantic Folding describes a method of converting language from its symbolic representation (text) into an explicit, semantically grounded representation that can be generically processed by Hawkins' HTM networks. As it turned out, this change in representation, by itself, can solve many complex NLP problems by applying Boolean operators and a generic similarity function like the Euclidian Distance. Many practical problems of statistical NLP systems, like the high cost of computation, the fundamental incongruity of precision and recall , the complex tuning procedures etc., can be elegantly overcome by applying Semantic Folding.

##### Abstract (translated by Google)
人类语言几十年来被认为是一个非常复杂的领域。迄今为止，没有任何一个计算机系统能够达到人类的性能水平。唯一能够正确处理语言的计算系统是人脑。当我们收集越来越多关于大脑的数据时，其基本的计算过程仍然是模糊的。缺乏完善的计算脑理论也阻碍了对自然语言处理的基本理解。与往常一样，当科学缺乏理论基础时，统计模型被应用于尽可能多的样本实际数据。一个未解决的根本问题是大脑中语言（数据）的实际表示，表示为表示性问题。从杰夫·霍金斯的分层时间记忆（HTM）理论开始，人类皮层一致的计算理论，我们已经开发了相应的语言数据表示理论：语义折叠理论。通过将地形语义空间作为分布参考框架用于稀疏二进制表示向量，编码单词的过程称为语义折叠，是本文的核心主题。语义折叠（Semantic Folding）描述了一种将语言从其符号表示（文本）转换为明确的语义接地表示的方法，该表示可以由Hawkins的HTM网络进行一般处理。事实证明，表示的这种变化本身可以通过应用布尔运算符和像欧几里德距离这样的通用相似函数来解决许多复杂的NLP问题。统计NLP系统的许多实际问题，如计算成本高，精度和召回的根本不协调，复杂的调整程序等，都可以通过应用语义折叠来克服。

##### URL
[https://arxiv.org/abs/1511.08855](https://arxiv.org/abs/1511.08855)

##### PDF
[https://arxiv.org/pdf/1511.08855](https://arxiv.org/pdf/1511.08855)

