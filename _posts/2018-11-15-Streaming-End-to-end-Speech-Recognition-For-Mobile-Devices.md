---
layout: post
title: "Streaming End-to-end Speech Recognition For Mobile Devices"
date: 2018-11-15 23:09:44
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition Recognition
author: Yanzhang He, Tara N. Sainath, Rohit Prabhavalkar, Ian McGraw, Raziel Alvarez, Ding Zhao, David Rybach, Anjuli Kannan, Yonghui Wu, Ruoming Pang, Qiao Liang, Deepti Bhatia, Yuan Shangguan, Bo Li, Golan Pundak, Khe Chai Sim, Tom Bagby, Shuo-yiin Chang, Kanishka Rao, Alexander Gruenstein
mathjax: true
---

* content
{:toc}

##### Abstract
End-to-end (E2E) models, which directly predict output character sequences given input speech, are good candidates for on-device speech recognition. E2E models, however, present numerous challenges: In order to be truly useful, such models must decode speech utterances in a streaming fashion, in real time; they must be robust to the long tail of use cases; they must be able to leverage user-specific context (e.g., contact lists); and above all, they must be extremely accurate. In this work, we describe our efforts at building an E2E speech recognizer using a recurrent neural network transducer. In experimental evaluations, we find that the proposed approach can outperform a conventional CTC-based model in terms of both latency and accuracy in a number of evaluation categories.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.06621](http://arxiv.org/abs/1811.06621)

##### PDF
[http://arxiv.org/pdf/1811.06621](http://arxiv.org/pdf/1811.06621)

