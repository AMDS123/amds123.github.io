---
layout: post
title: "Learning to Transfer Learn"
date: 2019-08-29 18:16:24
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Transfer_Learning Optimization
author: Linchao Zhu, Sercan O. Arik, Yi Yang, Tomas Pfister
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel framework, learning to transfer learn (L2TL), to improve transfer learning on a target dataset by judicious extraction of information from a source dataset. Our framework considers joint optimization of strongly-shared weights between models of source and target tasks, and employs adaptive weights for scaling of constituent loss terms. The adaptation of the weights is done using a reinforcement learning (RL)-based policy model, which is guided based on a performance metric on the target validation set. We demonstrate state-of-the-art performance of L2TL given fixed models, consistently outperforming fine-tuning baselines on various datasets. In addition, in the regimes of small-scale target datasets and significant label mismatch between source and target datasets, L2TL outperforms previous methods by a large margin.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.11406](http://arxiv.org/abs/1908.11406)

##### PDF
[http://arxiv.org/pdf/1908.11406](http://arxiv.org/pdf/1908.11406)

