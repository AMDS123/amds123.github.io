---
layout: post
title: "DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural Architectures"
date: 2018-07-25 07:56:33
categories: arXiv_CV
tags: arXiv_CV NAS Image_Classification Inference Classification Language_Model
author: Jin-Dong Dong, An-Chieh Cheng, Da-Cheng Juan, Wei Wei, Min Sun
mathjax: true
---

* content
{:toc}

##### Abstract
Recent breakthroughs in Neural Architectural Search (NAS) have achieved state-of-the-art performances in applications such as image classification and language modeling. However, these techniques typically ignore device-related objectives such as inference time, memory usage, and power consumption. Optimizing neural architecture for device-related objectives is immensely crucial for deploying deep networks on portable devices with limited computing resources. We propose DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural Architectures, optimizing for both device-related (e.g., inference time and memory usage) and device-agnostic (e.g., accuracy and model size) objectives. DPP-Net employs a compact search space inspired by current state-of-the-art mobile CNNs, and further improves search efficiency by adopting progressive search (Liu et al. 2017). Experimental results on CIFAR-10 are poised to demonstrate the effectiveness of Pareto-optimal networks found by DPP-Net, for three different devices: (1) a workstation with Titan X GPU, (2) NVIDIA Jetson TX1 embedded system, and (3) mobile phone with ARM Cortex-A53. Compared to CondenseNet and NASNet (Mobile), DPP-Net achieves better performances: higher accuracy and shorter inference time on various devices. Additional experimental results show that models found by DPP-Net also achieve considerably-good performance on ImageNet as well.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1806.08198](https://arxiv.org/abs/1806.08198)

##### PDF
[https://arxiv.org/pdf/1806.08198](https://arxiv.org/pdf/1806.08198)

