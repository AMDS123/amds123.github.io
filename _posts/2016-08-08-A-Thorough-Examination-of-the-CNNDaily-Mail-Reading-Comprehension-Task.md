---
layout: post
title: "A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task"
date: 2016-08-08 21:21:19
categories: arXiv_CL
tags: arXiv_CL
author: Danqi Chen, Jason Bolton, Christopher D. Manning
mathjax: true
---

* content
{:toc}

##### Abstract
Enabling a computer to understand a document so that it can answer comprehension questions is a central, yet unsolved goal of NLP. A key factor impeding its solution by machine learned systems is the limited availability of human-annotated data. Hermann et al. (2015) seek to solve this problem by creating over a million training examples by pairing CNN and Daily Mail news articles with their summarized bullet points, and show that a neural network can then be trained to give good performance on this task. In this paper, we conduct a thorough examination of this new reading comprehension task. Our primary aim is to understand what depth of language understanding is required to do well on this task. We approach this from one side by doing a careful hand-analysis of a small subset of the problems and from the other by showing that simple, carefully designed systems can obtain accuracies of 73.6% and 76.6% on these two datasets, exceeding current state-of-the-art results by 7-10% and approaching what we believe is the ceiling for performance on this task.

##### Abstract (translated by Google)
使计算机能够理解文档以便能够回答理解问题是NLP的一个中心但尚未解决的目标。机器学习系统阻碍其解决方案的一个关键因素是人类注释数据的有限可用性。赫尔曼等人。 （2015年）通过将CNN和每日邮报新闻文章与他们总结的要点进行配对，创造了超过一百万的培训范例来解决这个问题，并表明可以训练一个神经网络，以便在这个任务上取得良好的表现。本文对这一新的阅读理解任务进行了全面的考察。我们的主要目标是了解需要深入的语言理解来完成这项任务。我们通过对一小部分问题进行仔细的手工分析，从另一方面来看待这个问题，通过简单的精心设计的系统可以获得这两个数据集的73.6％和76.6％的准确性，最先进的成果达到7-10％，接近我们认为是这项任务的最高成绩。

##### URL
[https://arxiv.org/abs/1606.02858](https://arxiv.org/abs/1606.02858)

##### PDF
[https://arxiv.org/pdf/1606.02858](https://arxiv.org/pdf/1606.02858)

