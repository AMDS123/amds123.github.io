---
layout: post
title: 'Neural Machine Translation with Reconstruction'
date: 2017-12-06 09:30:05
categories: arXiv_CL
tags: arXiv_CL NMT
author: Zhaopeng Tu, Yang Liu, Lifeng Shang, Xiaohua Liu, Hang Li
---

* content
{:toc}

##### Abstract
Although end-to-end Neural Machine Translation (NMT) has achieved remarkable progress in the past two years, it suffers from a major drawback: translations generated by NMT systems often lack of adequacy. It has been widely observed that NMT tends to repeatedly translate some source words while mistakenly ignoring other words. To alleviate this problem, we propose a novel encoder-decoder-reconstructor framework for NMT. The reconstructor, incorporated into the NMT model, manages to reconstruct the input source sentence from the hidden layer of the output target sentence, to ensure that the information in the source side is transformed to the target side as much as possible. Experiments show that the proposed framework significantly improves the adequacy of NMT output and achieves superior translation result over state-of-the-art NMT and statistical MT systems.

##### Abstract (translated by Google)
虽然端到端的神经机器翻译（NMT）在过去两年取得了显着的进展，但是它有一个主要的缺点：由NMT系统产生的翻译通常缺乏足够的能力。人们普遍认为NMT倾向于反复翻译某些源词，而忽略其他词语。为了缓解这个问题，我们提出了一种新型的NMT编解码器 - 重构器框架。并入NMT模型的重构器设法从输出目标语句的隐藏层重构输入源语句，以确保源端信息尽可能地转换到目标端。实验表明，所提出的框架显着提高了NMT输出的适应性，并且在最先进的NMT和统计MT系统上实现了优越的翻译结果。

##### URL
[https://arxiv.org/abs/1611.01874](https://arxiv.org/abs/1611.01874)

