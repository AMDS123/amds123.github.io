---
layout: post
title: "Visual and Textual Sentiment Analysis Using Deep Fusion Convolutional Neural Networks"
date: 2017-11-21 14:19:48
categories: arXiv_CV
tags: arXiv_CV Sentiment Attention CNN Relation Recommendation
author: Xingyue Chen, Yunhong Wang, Qingjie Liu
mathjax: true
---

* content
{:toc}

##### Abstract
Sentiment analysis is attracting more and more attentions and has become a very hot research topic due to its potential applications in personalized recommendation, opinion mining, etc. Most of the existing methods are based on either textual or visual data and can not achieve satisfactory results, as it is very hard to extract sufficient information from only one single modality data. Inspired by the observation that there exists strong semantic correlation between visual and textual data in social medias, we propose an end-to-end deep fusion convolutional neural network to jointly learn textual and visual sentiment representations from training examples. The two modality information are fused together in a pooling layer and fed into fully-connected layers to predict the sentiment polarity. We evaluate the proposed approach on two widely used data sets. Results show that our method achieves promising result compared with the state-of-the-art methods which clearly demonstrate its competency.

##### Abstract (translated by Google)
情感分析越来越引起人们的关注，由于其在个性化推荐，意见挖掘等方面的潜在应用，已经成为一个非常热门的研究课题。现有的方法大都是基于文本或视觉数据，无法取得满意的结果，因为从唯一的一个模态数据中提取足够的信息是非常困难的。受到社会媒体视觉和文本数据存在强烈语义关联的启发，本文提出了一个端到端的深度融合卷积神经网络，从训练样本中共同学习文本和视觉情感表征。两个模态信息在汇聚层中融合在一起，并馈送到完全连接的层以预测情绪极性。我们评估提出的方法在两个广泛使用的数据集。结果表明，我们的方法与明确证明其胜任能力的最先进方法相比，取得了令人满意的结果。

##### URL
[https://arxiv.org/abs/1711.07798](https://arxiv.org/abs/1711.07798)

##### PDF
[https://arxiv.org/pdf/1711.07798](https://arxiv.org/pdf/1711.07798)

