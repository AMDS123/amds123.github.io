---
layout: post
title: "Language Graph Distillation for Low-Resource Machine Translation"
date: 2019-08-17 08:01:05
categories: arXiv_CL
tags: arXiv_CL Knowledge
author: Tianyu He, Jiale Chen, Xu Tan, Tao Qin
mathjax: true
---

* content
{:toc}

##### Abstract
Neural machine translation on low-resource language is challenging due to the lack of bilingual sentence pairs. Previous works usually solve the low-resource translation problem with knowledge transfer in a multilingual setting. In this paper, we propose the concept of Language Graph and further design a novel graph distillation algorithm that boosts the accuracy of low-resource translations in the graph with forward and backward knowledge distillation. Preliminary experiments on the TED talks multilingual dataset demonstrate the effectiveness of our proposed method. Specifically, we improve the low-resource translation pair by more than 3.13 points in terms of BLEU score.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.06258](http://arxiv.org/abs/1908.06258)

##### PDF
[http://arxiv.org/pdf/1908.06258](http://arxiv.org/pdf/1908.06258)

