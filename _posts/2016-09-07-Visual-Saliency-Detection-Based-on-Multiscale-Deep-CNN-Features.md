---
layout: post
title: "Visual Saliency Detection Based on Multiscale Deep CNN Features"
date: 2016-09-07 17:13:16
categories: arXiv_CV
tags: arXiv_CV Salient CNN Detection Recognition
author: Guanbin Li, Yizhou Yu
mathjax: true
---

* content
{:toc}

##### Abstract
Visual saliency is a fundamental problem in both cognitive and computational sciences, including computer vision. In this paper, we discover that a high-quality visual saliency model can be learned from multiscale features extracted using deep convolutional neural networks (CNNs), which have had many successes in visual recognition tasks. For learning such saliency models, we introduce a neural network architecture, which has fully connected layers on top of CNNs responsible for feature extraction at three different scales. The penultimate layer of our neural network has been confirmed to be a discriminative high-level feature vector for saliency detection, which we call deep contrast feature. To generate a more robust feature, we integrate handcrafted low-level features with our deep contrast feature. To promote further research and evaluation of visual saliency models, we also construct a new large database of 4447 challenging images and their pixelwise saliency annotations. Experimental results demonstrate that our proposed method is capable of achieving state-of-the-art performance on all public benchmarks, improving the F- measure by 6.12% and 10.0% respectively on the DUT-OMRON dataset and our new dataset (HKU-IS), and lowering the mean absolute error by 9% and 35.3% respectively on these two datasets.

##### Abstract (translated by Google)
视觉显着性是包括计算机视觉在内的认知科学和计算科学的基本问题。在本文中，我们发现使用深度卷积神经网络（CNNs）提取的多尺度特征可以学习到高质量的视觉显着性模型，在视觉识别任务中取得了许多成功。为了学习这样的显着性模型，我们引入了一个神经网络结构，它在CNN之上完全连接了层，负责三个不同尺度的特征提取。我们的神经网络倒数第二层已被证实是显着性检测的判别性高级特征向量，我们称之为深度对比特征。为了生成更强大的功能，我们将手工制作的低级功能与我们的深度对比功能相结合。为了促进视觉显着性模型的进一步研究和评估，我们还构建了一个新的4447个具有挑战性的图像及其像素显着性注释的大型数据库。实验结果表明，我们提出的方法能够实现所有公共基准的最新性能，在DUT-OMRON数据集和我们的新数据集（HKU-IS）上分别提高了6.12％和10.0％ ），并将这两个数据集的平均绝对误差分别降低9％和35.3％。

##### URL
[https://arxiv.org/abs/1609.02077](https://arxiv.org/abs/1609.02077)

##### PDF
[https://arxiv.org/pdf/1609.02077](https://arxiv.org/pdf/1609.02077)

