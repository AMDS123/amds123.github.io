---
layout: post
title: "Does It Make Sense? And Why? A Pilot Study for Sense Making and Explanation"
date: 2019-06-02 08:03:21
categories: arXiv_AI
tags: arXiv_AI Knowledge Attention Language_Model
author: Cunxiang Wang, Shuailong Liang, Yue Zhang, Xiaonan Li, Tian Gao
mathjax: true
---

* content
{:toc}

##### Abstract
Introducing common sense to natural language understanding systems has received increasing research attention. It remains a fundamental question on how to evaluate whether a system has a sense making capability. Existing benchmarks measures commonsense knowledge indirectly and without explanation. In this paper, we release a benchmark to directly test whether a system can differentiate natural language statements that make sense from those that do not make sense. In addition, a system is asked to identify the most crucial reason why a statement does not make sense. We evaluate models trained over large-scale language modeling tasks as well as human performance, showing that there are different challenges for system sense making.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.00363](http://arxiv.org/abs/1906.00363)

##### PDF
[http://arxiv.org/pdf/1906.00363](http://arxiv.org/pdf/1906.00363)

