---
layout: post
title: "Deep Visual Foresight for Planning Robot Motion"
date: 2017-03-13 00:18:49
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning Prediction
author: Chelsea Finn, Sergey Levine
mathjax: true
---

* content
{:toc}

##### Abstract
A key challenge in scaling up robot learning to many skills and environments is removing the need for human supervision, so that robots can collect their own data and improve their own performance without being limited by the cost of requesting human feedback. Model-based reinforcement learning holds the promise of enabling an agent to learn to predict the effects of its actions, which could provide flexible predictive models for a wide range of tasks and environments, without detailed human supervision. We develop a method for combining deep action-conditioned video prediction models with model-predictive control that uses entirely unlabeled training data. Our approach does not require a calibrated camera, an instrumented training set-up, nor precise sensing and actuation. Our results show that our method enables a real robot to perform nonprehensile manipulation -- pushing objects -- and can handle novel objects not seen during training.

##### Abstract (translated by Google)
将机器人学习扩展到许多技能和环境中的一个关键挑战就是不再需要人工监控，这样机器人就可以收集自己的数据并提高自己的表现，而不受人们反馈请求的成本的限制。基于模型的强化学习具有使代理人能够学习预测其行为的影响的希望，这可以为广泛的任务和环境提供灵活的预测模型，而无需详细的人员监督。我们开发了一种方法，将深度行为条件视频预测模型与使用完全未标记的训练数据的模型预测控制相结合。我们的方法不需要校准摄像机，仪器化的训练设置，也不需要精确的感测和驱动。我们的结果表明，我们的方法使真正的机器人执行非易懂的操作 - 推物体，并可以处理在训练期间看不到的新物体。

##### URL
[https://arxiv.org/abs/1610.00696](https://arxiv.org/abs/1610.00696)

##### PDF
[https://arxiv.org/pdf/1610.00696](https://arxiv.org/pdf/1610.00696)

