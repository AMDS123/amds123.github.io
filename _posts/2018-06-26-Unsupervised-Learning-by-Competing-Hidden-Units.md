---
layout: post
title: "Unsupervised Learning by Competing Hidden Units"
date: 2018-06-26 19:32:58
categories: arXiv_CV
tags: arXiv_CV Object_Detection Detection
author: Dmitry Krotov, John Hopfield
mathjax: true
---

* content
{:toc}

##### Abstract
It is widely believed that the backpropagation algorithm is essential for learning good feature detectors in early layers of artificial neural networks, so that these detectors are useful for the task performed by the higher layers of that neural network. At the same time, the traditional form of backpropagation is biologically implausible. In the present paper we propose an unusual learning rule, which has a degree of biological plausibility, and which is motivated by Hebb's idea that change of the synapse strength should be local - i.e. should depend only on the activities of the pre and post synaptic neurons. We design a learning algorithm that utilizes global inhibition in the hidden layer, and is capable of learning early feature detectors in a completely unsupervised way. These learned lower layer feature detectors can be used to train higher layer weights in a usual supervised way so that the performance of the full network is comparable to the performance of standard feedforward networks trained end-to-end with a backpropagation algorithm.

##### Abstract (translated by Google)
人们普遍认为反向传播算法对于在早期的人工神经网络层学习优质特征检测器是必不可少的，因此这些检测器对于由该神经网络的较高层执行的任务是有用的。同时，传统的反向传播形式在生物学上是不可信的。在本文中，我们提出了一种不寻常的学习规则，它具有一定程度的生物合理性，并且受Hebb的想法的启发，即突触强度的变化应该是局部的 - 即应该仅取决于突触前和突触后神经元的活动。我们设计了一种学习算法，利用隐藏层中的全局抑制，并且能够以完全无监督的方式学习早期特征检测器。这些学习到的低层特征检测器可以用于以通常的监督方式训练更高层的权重，从而使整个网络的性能与通过反向传播算法端对端训练的标准前馈网络的性能相当。

##### URL
[http://arxiv.org/abs/1806.10181](http://arxiv.org/abs/1806.10181)

##### PDF
[http://arxiv.org/pdf/1806.10181](http://arxiv.org/pdf/1806.10181)

