---
layout: post
title: "Guided Alignment Training for Topic-Aware Neural Machine Translation"
date: 2016-07-06 14:13:12
categories: arXiv_CL
tags: arXiv_CL Attention NMT
author: Wenhu Chen, Evgeny Matusov, Shahram Khadivi, Jan-Thorsten Peter
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose an effective way for biasing the attention mechanism of a sequence-to-sequence neural machine translation (NMT) model towards the well-studied statistical word alignment models. We show that our novel guided alignment training approach improves translation quality on real-life e-commerce texts consisting of product titles and descriptions, overcoming the problems posed by many unknown words and a large type/token ratio. We also show that meta-data associated with input texts such as topic or category information can significantly improve translation quality when used as an additional signal to the decoder part of the network. With both novel features, the BLEU score of the NMT system on a product title set improves from 18.6 to 21.3%. Even larger MT quality gains are obtained through domain adaptation of a general domain NMT system to e-commerce data. The developed NMT system also performs well on the IWSLT speech translation task, where an ensemble of four variant systems outperforms the phrase-based baseline by 2.1% BLEU absolute.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1607.01628](https://arxiv.org/abs/1607.01628)

##### PDF
[https://arxiv.org/pdf/1607.01628](https://arxiv.org/pdf/1607.01628)

