---
layout: post
title: "Guided Alignment Training for Topic-Aware Neural Machine Translation"
date: 2016-07-06 14:13:12
categories: arXiv_CL
tags: arXiv_CL NMT
author: Wenhu Chen, Evgeny Matusov, Shahram Khadivi, Jan-Thorsten Peter
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose an effective way for biasing the attention mechanism of a sequence-to-sequence neural machine translation (NMT) model towards the well-studied statistical word alignment models. We show that our novel guided alignment training approach improves translation quality on real-life e-commerce texts consisting of product titles and descriptions, overcoming the problems posed by many unknown words and a large type/token ratio. We also show that meta-data associated with input texts such as topic or category information can significantly improve translation quality when used as an additional signal to the decoder part of the network. With both novel features, the BLEU score of the NMT system on a product title set improves from 18.6 to 21.3%. Even larger MT quality gains are obtained through domain adaptation of a general domain NMT system to e-commerce data. The developed NMT system also performs well on the IWSLT speech translation task, where an ensemble of four variant systems outperforms the phrase-based baseline by 2.1% BLEU absolute.

##### Abstract (translated by Google)
在本文中，我们提出了一种有效的方法来将序列 - 序列神经机器翻译（NMT）模型的注意力机制偏向于深入研究的统计字对齐模型。我们发现，我们的小说引导式对齐培训方法提高了由产品标题和描述组成的真实电子商务文本的翻译质量，克服了许多未知单词和大型/标记比率带来的问题。我们还表明，与输入文本（如主题或类别信息）相关联的元数据在用作网络解码器部分的附加信号时可以显着提高翻译质量。有了这两个新功能，NMT系统在产品标题集上的BLEU得分从18.6提高到21.3％。通过通用域NMT系统对电子商务数据的域调整，可以获得更大的MT质量增益。开发的NMT系统在IWSLT语音翻译任务中表现良好，其中四个变体系统的总体优于基于短语的基线2.1％BLEU绝对值。

##### URL
[https://arxiv.org/abs/1607.01628](https://arxiv.org/abs/1607.01628)

##### PDF
[https://arxiv.org/pdf/1607.01628](https://arxiv.org/pdf/1607.01628)

