---
layout: post
title: "FAN: Focused Attention Networks"
date: 2019-05-27 20:41:53
categories: arXiv_CV
tags: arXiv_CV Object_Detection Attention Embedding Classification Detection Relation
author: Chu Wang, Babak Samari, Vladimir Kim, Siddhartha Chaudhuri, Kaleem Siddiqi
mathjax: true
---

* content
{:toc}

##### Abstract
Attention networks show promise for both vision and language tasks, by emphasizing relationships between constituent elements through appropriate weighting functions. Such elements could be regions in an image output by a region proposal network, or words in a sentence, represented by word embedding. Thus far, however, the learning of attention weights has been driven solely by the minimization of task specific loss functions. We here introduce a method of learning attention weights to better emphasize informative pair-wise relations between entities. The key idea is to use a novel center-mass cross entropy loss, which can be applied in conjunction with the task specific ones. We then introduce a focused attention backbone to learn these attention weights for general tasks. We demonstrate that the focused attention module leads to a new state-of-the-art for the recovery of relations in a relationship proposal task. Our experiments show that it also boosts performance for diverse vision and language tasks, including object detection, scene categorization and document classification.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1905.11498](https://arxiv.org/abs/1905.11498)

##### PDF
[https://arxiv.org/pdf/1905.11498](https://arxiv.org/pdf/1905.11498)

