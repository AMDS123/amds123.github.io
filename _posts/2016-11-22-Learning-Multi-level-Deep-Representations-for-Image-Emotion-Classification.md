---
layout: post
title: "Learning Multi-level Deep Representations for Image Emotion Classification"
date: 2016-11-22 05:12:19
categories: arXiv_CV
tags: arXiv_CV Image_Caption Classification
author: Tianrong Rao, Min Xu, Dong Xu
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a new deep network that learns multi-level deep representations for image emotion classification (MldrNet). Image emotion can be recognized through image semantics, image aesthetics and low-level visual features from both global and local views. Existing image emotion classification works using hand-crafted features or deep features mainly focus on either low-level visual features or semantic-level image representations without taking all factors into consideration. Our proposed MldrNet unifies deep representations of three levels, i.e. image semantics, image aesthetics and low-level visual features through multiple instance learning (MIL) in order to effectively cope with noisy labeled data, such as images collected from the Internet. Extensive experiments on both Internet images and abstract paintings demonstrate the proposed method outperforms the state-of-the-art methods using deep features or hand-crafted features. The proposed approach also outperforms the state-of-the-art methods with at least 6% performance improvement in terms of overall classification accuracy.

##### Abstract (translated by Google)
在本文中，我们提出了一个新的深度网络，学习图像情感分类（MldrNet）的多级深度表示。图像情感可以通过图像语义，图像美学和来自全球和本地视图的低级视觉特征来识别。现有的使用手工特征或深度特征的图像情感分类工作主要集中在低级视觉特征或语义级别图像表征，而没有考虑所有因素。我们提出的MldrNet通过多实例学习（MIL）统一了三个层次的深层表示，即图像语义，图像美学和低层视觉特征，以便有效地处理从互联网收集的图像等有噪声的标记数据。在互联网图像和抽象绘画上进行的大量实验表明，所提出的方法优于使用深度特征或手工特征的最先进的方法。所提出的方法也优于最先进的方法，总体分类准确度方面性能提高至少6％。

##### URL
[https://arxiv.org/abs/1611.07145](https://arxiv.org/abs/1611.07145)

##### PDF
[https://arxiv.org/pdf/1611.07145](https://arxiv.org/pdf/1611.07145)

