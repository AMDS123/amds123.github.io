---
layout: post
title: "End-to-end Learning for 3D Facial Animation from Raw Waveforms of Speech"
date: 2017-12-07 21:13:47
categories: arXiv_CV
tags: arXiv_CV Face Inference Deep_Learning
author: Hai X. Pham, Yuting Wang, Vladimir Pavlovic
mathjax: true
---

* content
{:toc}

##### Abstract
We present a deep learning framework for real-time speech-driven 3D facial animation from just raw waveforms. Our deep neural network directly maps an input sequence of speech audio to a series of micro facial action unit activations and head rotations to drive a 3D blendshape face model. In particular, our deep model is able to learn the latent representations of time-varying contextual information and affective states within the speech. Hence, our model not only activates appropriate facial action units at inference to depict different utterance generating actions, in the form of lip movements, but also, without any assumption, automatically estimates emotional intensity of the speaker and reproduces her ever-changing affective states by adjusting strength of facial unit activations. For example, in a happy speech, the mouth opens wider than normal, while other facial units are relaxed; or in a surprised state, both eyebrows raise higher. Experiments on a diverse audiovisual corpus of different actors across a wide range of emotional states show interesting and promising results of our approach. Being speaker-independent, our generalized model is readily applicable to various tasks in human-machine interaction and animation.

##### Abstract (translated by Google)
我们提供了一个从原始波形实时语音驱动3D面部动画的深度学习框架。我们的深层神经网络将输入的语音音频序列直接映射到一系列微面部动作单元激活和头部旋转，以驱动3D混合面部模型。特别是，我们的深层模型能够学习语音中时变情境信息和情感状态的潜在表征。因此，我们的模型不仅在推理中激活适当的面部动作单元，以嘴唇运动的形式描绘不同的话语产生动作，而且在没有任何假设的情况下，自动估计说话者的情绪强度并且通过以下方式再现其不断变化的情感状态调整面部活动的力量。例如，在一个快乐的演讲中，嘴巴张大得比平常宽，而其他的脸部单位则放松;或者处于惊讶的状态，双眉提高。在各种情绪状态下不同演员的不同视听语料上的实验显示了我们方法的有趣和有希望的结果。独立于说话者，我们的广义模型很容易适用于人机交互和动画的各种任务。

##### URL
[http://arxiv.org/abs/1710.00920](http://arxiv.org/abs/1710.00920)

##### PDF
[http://arxiv.org/pdf/1710.00920](http://arxiv.org/pdf/1710.00920)

