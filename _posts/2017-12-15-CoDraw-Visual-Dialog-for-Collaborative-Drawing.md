---
layout: post
title: "CoDraw: Visual Dialog for Collaborative Drawing"
date: 2017-12-15 06:38:15
categories: arXiv_CV
tags: arXiv_CV Attention Quantitative
author: Jin-Hwa Kim, Devi Parikh, Dhruv Batra, Byoung-Tak Zhang, Yuandong Tian
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we propose a goal-driven collaborative task that contains vision, language, and action in a virtual environment as its core components. Specifically, we develop a collaborative `Image Drawing' game between two agents, called CoDraw. Our game is grounded in a virtual world that contains movable clip art objects. Two players, Teller and Drawer, are involved. The Teller sees an abstract scene containing multiple clip arts in a semantically meaningful configuration, while the Drawer tries to reconstruct the scene on an empty canvas using available clip arts. The two players communicate via two-way communication using natural language. We collect the CoDraw dataset of ~10K dialogs consisting of 138K messages exchanged between a Teller and a Drawer from Amazon Mechanical Turk (AMT). We analyze our dataset and present three models to model the players' behaviors, including an attention model to describe and draw multiple clip arts at each round. The attention models are quantitatively compared to the other models to show how the conventional approaches work for this new task. We also present qualitative visualizations.

##### Abstract (translated by Google)
在这项工作中，我们提出了一个目标驱动的协作任务，其中包含虚拟环境中的视觉，语言和行动作为其核心组件。具体而言，我们在两个代理之间开发了一个名为CoDraw的协作“图像绘制”游戏。我们的游戏基于包含可移动剪贴画对象的虚拟世界。涉及两名玩家，特勒和抽屉。出纳员看到一个抽象的场景，其中包含多个具有语义上有意义配置的剪贴画，而抽屉则尝试使用可用的剪贴画在空画布上重建场景。两个玩家通过使用自然语言的双向交流进行交流。我们收集了从亚马逊土耳其机器人（AMT）的柜员机和抽屉之间交换的138K个消息组成的〜1​​0K对话的CoDraw数据集。我们分析我们的数据集，并提出三个模型来模拟玩家的行为，包括一个注意模型来描述和绘制多个剪贴画在每一轮。注意模型与其他模型进行了定量比较，以显示传统方法如何适用于这项新任务。我们也提供定性的可视化。

##### URL
[http://arxiv.org/abs/1712.05558](http://arxiv.org/abs/1712.05558)

##### PDF
[http://arxiv.org/pdf/1712.05558](http://arxiv.org/pdf/1712.05558)

