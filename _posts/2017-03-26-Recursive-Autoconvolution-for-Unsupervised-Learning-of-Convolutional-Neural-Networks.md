---
layout: post
title: "Recursive Autoconvolution for Unsupervised Learning of Convolutional Neural Networks"
date: 2017-03-26 18:31:05
categories: arXiv_CV
tags: arXiv_CV CNN Image_Classification Classification Recognition
author: Boris Knyazev, Erhardt Barth, Thomas Martinetz
mathjax: true
---

* content
{:toc}

##### Abstract
In visual recognition tasks, such as image classification, unsupervised learning exploits cheap unlabeled data and can help to solve these tasks more efficiently. We show that the recursive autoconvolution operator, adopted from physics, boosts existing unsupervised methods by learning more discriminative filters. We take well established convolutional neural networks and train their filters layer-wise. In addition, based on previous works we design a network which extracts more than 600k features per sample, but with the total number of trainable parameters greatly reduced by introducing shared filters in higher layers. We evaluate our networks on the MNIST, CIFAR-10, CIFAR-100 and STL-10 image classification benchmarks and report several state of the art results among other unsupervised methods.

##### Abstract (translated by Google)
在视觉识别任务中，如图像分类，无监督学习利用廉价的未标记数据，并可以帮助更有效地解决这些任务。我们展示了从物理学中采用的递归自动运算算子，通过学习更多的判别式滤波器来提高现有的无监督方法。我们采用完善的卷积神经网络，并逐层训练滤波器。另外，根据以往的工作，我们设计了一个网络，每个样本可以提取超过600k的特征，但是通过在更高层中引入共享过滤器，大大减少了可训练参数的总数。我们在MNIST，CIFAR-10，CIFAR-100和STL-10图像分类基准上评估我们的网络，并报告其他无监督方法的最新成果。

##### URL
[https://arxiv.org/abs/1606.00611](https://arxiv.org/abs/1606.00611)

##### PDF
[https://arxiv.org/pdf/1606.00611](https://arxiv.org/pdf/1606.00611)

