---
layout: post
title: "Describe and Attend to Track: Learning Natural Language guided Structural Representation and Visual Attention for Object Tracking"
date: 2018-11-25 14:00:05
categories: arXiv_CV
tags: arXiv_CV Attention Tracking Object_Tracking Detection Relation
author: Xiao Wang, Chenglong Li, Rui Yang, Tianzhu Zhang, Jin Tang, Bin Luo
mathjax: true
---

* content
{:toc}

##### Abstract
The tracking-by-detection framework requires a set of positive and negative training samples to learn robust tracking models for precise localization of target objects. However, existing tracking models mostly treat different samples independently while ignores the relationship information among them. In this paper, we propose a novel structure-aware deep neural network to overcome such limitations. In particular, we construct a graph to represent the pairwise relationships among training samples, and additionally take the natural language as the supervised information to learn both feature representations and classifiers robustly. To refine the states of the target and re-track the target when it is back to view from heavy occlusion and out of view, we elaborately design a novel subnetwork to learn the target-driven visual attentions from the guidance of both visual and natural language cues. Extensive experiments on five tracking benchmark datasets validated the effectiveness of our proposed method.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1811.10014](https://arxiv.org/abs/1811.10014)

##### PDF
[https://arxiv.org/pdf/1811.10014](https://arxiv.org/pdf/1811.10014)

