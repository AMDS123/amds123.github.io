---
layout: post
title: "Learning a Deep Model for Human Action Recognition from Novel Viewpoints"
date: 2016-02-02 08:42:44
categories: arXiv_CV
tags: arXiv_CV Knowledge Action_Recognition Recognition
author: Hossein Rahmani, Ajmal Mian, Mubarak Shah
mathjax: true
---

* content
{:toc}

##### Abstract
Recognizing human actions from unknown and unseen (novel) views is a challenging problem. We propose a Robust Non-Linear Knowledge Transfer Model (R-NKTM) for human action recognition from novel views. The proposed R-NKTM is a deep fully-connected neural network that transfers knowledge of human actions from any unknown view to a shared high-level virtual view by finding a non-linear virtual path that connects the views. The R-NKTM is learned from dense trajectories of synthetic 3D human models fitted to real motion capture data and generalizes to real videos of human actions. The strength of our technique is that we learn a single R-NKTM for all actions and all viewpoints for knowledge transfer of any real human action video without the need for re-training or fine-tuning the model. Thus, R-NKTM can efficiently scale to incorporate new action classes. R-NKTM is learned with dummy labels and does not require knowledge of the camera viewpoint at any stage. Experiments on three benchmark cross-view human action datasets show that our method outperforms existing state-of-the-art.

##### Abstract (translated by Google)
认识到来自未知和不可见（新颖）观点的人类行为是一个具有挑战性的问题。我们提出了一个鲁棒的非线性知识转移模型（R-NKTM），用于从新视角进行人类行为识别。所提出的R-NKTM是一种深度全连接的神经网络，通过寻找连接视图的非线性虚拟路径，将人类行为的知识从任何未知视图转移到共享的高级虚拟视图。 R-NKTM从合成3D人体模型的密集轨迹中学习，适合真实的运动捕捉数据，并将其推广到人类行为的真实视频。我们的技术的优势在于，我们可以学习单一的R-NKTM技术，无需重新训练或微调模型，即可实现任何真实的人类动作视频的知识传输。因此，R-NKTM可以有效地扩展到新的行动类别。 R-NKTM使用虚拟标签学习，不需要任何阶段的相机视点知识。在三个基准交叉人类行动数据集的实验表明，我们的方法胜过现有的最新技术。

##### URL
[https://arxiv.org/abs/1602.00828](https://arxiv.org/abs/1602.00828)

##### PDF
[https://arxiv.org/pdf/1602.00828](https://arxiv.org/pdf/1602.00828)

