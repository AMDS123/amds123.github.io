---
layout: post
title: "SEWA DB: A Rich Database for Audio-Visual Emotion and Sentiment Research in the Wild"
date: 2019-01-09 17:28:57
categories: arXiv_AI
tags: arXiv_AI Sentiment Detection
author: Jean Kossaifi, Robert Walecki, Yannis Panagakis, Jie Shen, Maximilian Schmitt, Fabien Ringeval, Jing Han, Vedhas Pandit, Bjorn Schuller, Kam Star, Elnar Hajiyev, Maja Pantic
mathjax: true
---

* content
{:toc}

##### Abstract
Natural human-computer interaction and audio-visual human behaviour sensing systems, which would achieve robust performance in-the-wild are more needed than ever as digital devices are becoming indispensable part of our life more and more. Accurately annotated real-world data are the crux in devising such systems. However, existing databases usually consider controlled settings, low demographic variability, and a single task. In this paper, we introduce the SEWA database of more than 2000 minutes of audio-visual data of 398 people coming from six cultures, 50% female, and uniformly spanning the age range of 18 to 65 years old. Subjects were recorded in two different contexts: while watching adverts and while discussing adverts in a video chat. The database includes rich annotations of the recordings in terms of facial landmarks, facial action units (FAU), various vocalisations, mirroring, and continuously valued valence, arousal, liking, agreement, and prototypic examples of (dis)liking. This database aims to be an extremely valuable resource for researchers in affective computing and automatic human sensing and is expected to push forward the research in human behaviour analysis, including cultural studies. Along with the database, we provide extensive baseline experiments for automatic FAU detection and automatic valence, arousal and (dis)liking intensity estimation.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1901.02839](http://arxiv.org/abs/1901.02839)

##### PDF
[http://arxiv.org/pdf/1901.02839](http://arxiv.org/pdf/1901.02839)

