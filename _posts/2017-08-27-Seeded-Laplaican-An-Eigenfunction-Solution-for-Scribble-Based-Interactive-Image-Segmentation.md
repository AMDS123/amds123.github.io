---
layout: post
title: "Seeded Laplaican: An Eigenfunction Solution for Scribble Based Interactive Image Segmentation"
date: 2017-08-27 20:12:37
categories: arXiv_CV
tags: arXiv_CV Segmentation Quantitative
author: Ahmed Taha, Marwan Torki
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we cast the scribble-based interactive image segmentation as a semi-supervised learning problem. Our novel approach alleviates the need to solve an expensive generalized eigenvector problem by approximating the eigenvectors using efficiently computed eigenfunctions. The smoothness operator defined on feature densities at the limit n tends to infinity recovers the exact eigenvectors of the graph Laplacian, where n is the number of nodes in the graph. To further reduce the computational complexity without scarifying our accuracy, we select pivots pixels from user annotations. In our experiments, we evaluate our approach using both human scribble and "robot user" annotations to guide the foreground/background segmentation. We developed a new unbiased collection of five annotated images datasets to standardize the evaluation procedure for any scribble-based segmentation method. We experimented with several variations, including different feature vectors, pivot count and the number of eigenvectors. Experiments are carried out on datasets that contain a wide variety of natural images. We achieve better qualitative and quantitative results compared to state-of-the-art interactive segmentation algorithms.

##### Abstract (translated by Google)
在本文中，我们将基于涂抹的交互式图像分割作为一个半监督学习问题。我们的新颖方法通过使用有效计算的本征函数逼近特征向量来减轻解决昂贵的广义特征向量问题的需要。定义在极限n处的特征密度的平滑算子倾向于无穷恢复图拉普拉斯算子的精确特征向量，其中n是图中节点的数目。为了进一步降低计算复杂性而不会影响我们的准确性，我们从用户注释中选择枢轴点。在我们的实验中，我们使用人工涂鸦和“机器人用户”注释来评估我们的方法，以指导前景/背景分割。我们开发了一个新的无偏见的五个注释图像数据集，以标准化任何基于涂鸦的分割方法的评估程序。我们尝试了几个变体，包括不同的特征向量，轴数和特征向量的数量。在包含各种自然图像的数据集上进行实验。与最先进的交互式分割算法相比，我们获得了更好的定性和定量结果。

##### URL
[https://arxiv.org/abs/1702.00882](https://arxiv.org/abs/1702.00882)

##### PDF
[https://arxiv.org/pdf/1702.00882](https://arxiv.org/pdf/1702.00882)

