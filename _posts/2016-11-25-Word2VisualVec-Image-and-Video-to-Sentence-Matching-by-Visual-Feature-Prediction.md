---
layout: post
title: "Word2VisualVec: Image and Video to Sentence Matching by Visual Feature Prediction"
date: 2016-11-25 06:06:31
categories: arXiv_CV
tags: arXiv_CV Prediction
author: Jianfeng Dong, Xirong Li, Cees G. M. Snoek
mathjax: true
---

* content
{:toc}

##### Abstract
This paper strives to find the sentence best describing the content of an image or video. Different from existing works, which rely on a joint subspace for image / video to sentence matching, we propose to do so in a visual space only. We contribute Word2VisualVec, a deep neural network architecture that learns to predict a deep visual encoding of textual input based on sentence vectorization and a multi-layer perceptron. We thoroughly analyze its architectural design, by varying the sentence vectorization strategy, network depth and the deep feature to predict for image to sentence matching. We also generalize Word2VisualVec for matching a video to a sentence, by extending the predictive abilities to 3-D ConvNet features as well as a visual-audio representation. Experiments on four challenging image and video benchmarks detail Word2VisualVec's properties, capabilities for image and video to sentence matching, and on all datasets its state-of-the-art results.

##### Abstract (translated by Google)
本文试图找到最能描述图像或视频内容的句子。与现有的依靠联合子空间进行图像/视频判断匹配的现有作品不同，我们建议只在视觉空间中进行。我们贡献Word2VisualVec，深度神经网络体系结构，学习预测基于句子矢量和多层感知器的文本输入的深度视觉编码。我们通过改变句子的矢量化策略，网络深度和深度特征来预测图像到句子的匹配，深入分析其体系结构设计。我们还将Word2VisualVec概括为将视频与句子进行匹配，将预测能力扩展到三维ConvNet特征以及视觉 - 音频表示。对四个具有挑战性的图像和视频基准的实验详细介绍了Word2VisualVec的属性，图像和视频的句子匹配功能以及所有数据集上的最新结果。

##### URL
[https://arxiv.org/abs/1604.06838](https://arxiv.org/abs/1604.06838)

##### PDF
[https://arxiv.org/pdf/1604.06838](https://arxiv.org/pdf/1604.06838)

