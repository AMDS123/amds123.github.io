---
layout: post
title: "Exposition and Interpretation of the Topology of Neural Networks"
date: 2018-11-27 16:21:07
categories: arXiv_CV
tags: arXiv_CV CNN
author: Rickard Br&#xfc;el Gabrielsson, Gunnar Carlsson
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional neural networks (CNN's) are powerful and widely used tools. However, their interpretability is far from ideal. One such shortcoming is the difficulty of deducing a network's ability to generalize to unseen data. In this paper we use topological data analysis to investigate what various CNN's learn and demonstrate how such information can be interpreted and utilized. We show that the weights of convolutional layers at depths from 1 through 13 learn simple global structures. We also demonstrate the change of the simple structures over the course of training. In particular, we define and analyze the spaces of spatial filters of convolutional layers and show the recurrence, among all networks, depths, and during training, of a simple circle consisting of rotating edges, as well as a less recurring unanticipated complex circle that combines lines, edges, and non-linear patterns. We also demonstrate that topological structure correlates with a network's ability to generalize to unseen data and that topological information can be used to improve a network's performance. We train over a thousand CNN's on MNIST, CIFAR-10, and SVHN, as well as use VGG-networks pretrained on ImageNet.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.03234](http://arxiv.org/abs/1810.03234)

##### PDF
[http://arxiv.org/pdf/1810.03234](http://arxiv.org/pdf/1810.03234)

