---
layout: post
title: "Continuous Multimodal Emotion Recognition Approach for AVEC 2017"
date: 2017-10-24 12:08:09
categories: arXiv_CV
tags: arXiv_CV GAN CNN Relation Recognition
author: Narotam Singh (1), Nittin Singh (1), Abhinav Dhall (1) ((1) Indian Institute of Technology Ropar)
mathjax: true
---

* content
{:toc}

##### Abstract
This paper reports the analysis of audio and visual features in predicting the continuous emotion dimensions under the seventh Audio/Visual Emotion Challenge (AVEC 2017), which was done as part of a B.Tech. 2nd year internship project. For visual features we used the HOG (Histogram of Gradients) features, Fisher encodings of SIFT (Scale-Invariant Feature Transform) features based on Gaussian mixture model (GMM) and some pretrained Convolutional Neural Network layers as features; all these extracted for each video clip. For audio features we used the Bag-of-audio-words (BoAW) representation of the LLDs (low-level descriptors) generated by openXBOW provided by the organisers of the event. Then we trained fully connected neural network regression model on the dataset for all these different modalities. We applied multimodal fusion on the output models to get the Concordance correlation coefficient on Development set as well as Test set.

##### Abstract (translated by Google)
本文报道了在第七届音像视觉情感挑战赛（AVEC2017）下对音乐和视觉特征进行的预测连续情感维度的分析。第二年实习项目。对于视觉特征，我们使用HOG（梯度直方图）特征，基于高斯混合模型（GMM）的SIFT（尺度不变特征变换）特征的Fisher编码和一些预训练的卷积神经网络层作为特征;所有这些提取为每个视频剪辑。对于音频特性，我们使用由事件组织者提供的openXBOW生成的LLD（低级描述符）的音频文字（BoW）表示。然后，我们在所有这些不同模式的数据集上训练完全连接的神经网络回归模型。我们在输出模型上应用多模态融合，得到了开发集和测试集的一致性相关系数。

##### URL
[https://arxiv.org/abs/1709.05861](https://arxiv.org/abs/1709.05861)

##### PDF
[https://arxiv.org/pdf/1709.05861](https://arxiv.org/pdf/1709.05861)

