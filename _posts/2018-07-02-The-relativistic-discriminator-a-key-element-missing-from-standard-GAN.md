---
layout: post
title: "The relativistic discriminator: a key element missing from standard GAN"
date: 2018-07-02 15:11:23
categories: arXiv_CV
tags: arXiv_CV Adversarial Knowledge GAN
author: Alexia Jolicoeur-Martineau
mathjax: true
---

* content
{:toc}

##### Abstract
In standard generative adversarial network (SGAN), the discriminator estimates the probability that the input data is real. The generator is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. We show that this property can be induced by using a relativistic discriminator which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.

##### Abstract (translated by Google)
在标准生成对抗网络（SGAN）中，鉴别器估计输入数据是真实的概率。训练发生器以增加假数据是真实的概率。我们认为它还应该同时降低实际数据是真实的概率，因为1）这将解释先验知识，即小批量中的一半数据是假的，2）这将通过分歧最小化观察到，3 ）在最佳设置中，SGAN等同于积分概率度量（IPM）GAN。我们证明了这个性质可以通过使用相对论鉴别器来诱导，该鉴别器估计给定真实数据比随机抽样假数据更真实的概率。我们还提出了一种变体，其中鉴别器平均估计给定的实际数据比假数据更真实的概率。我们概括了两种非标准GAN损失函数的方法，我们将它们分别称为相对论GAN（RGAN）和相对论平均GAN（RaGAN）。我们展示了基于IPM的GAN是使用身份功能的RGAN的子集。根据经验，我们观察到1）RGAN和RaGAN比非相对论对应物更稳定并产生更高质量的数据样本.2）具有梯度惩罚的标准RaGAN产生比WGAN-GP更好质量的数据，同时仅需要单个鉴别器更新每个发生器更新（将达到最先进技术所需的时间减少400％），以及3）RaGAN能够从非常小的样本（N = 2011）生成合理的高分辨率图像（256x256），同时GAN和LSGAN不能;这些图像的质量明显优于WGAN-GP和SGAN生成的光谱归一化图像。

##### URL
[https://arxiv.org/abs/1807.00734](https://arxiv.org/abs/1807.00734)

##### PDF
[https://arxiv.org/pdf/1807.00734](https://arxiv.org/pdf/1807.00734)

