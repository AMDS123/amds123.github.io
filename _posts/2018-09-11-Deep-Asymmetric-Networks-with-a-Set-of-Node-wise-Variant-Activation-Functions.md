---
layout: post
title: "Deep Asymmetric Networks with a Set of Node-wise Variant Activation Functions"
date: 2018-09-11 08:09:25
categories: arXiv_CV
tags: arXiv_CV
author: Jinhyeok Jang, Hyunjoong Cho, Jaehong Kim, Jaeyeon Lee, Seungjoon Yang
mathjax: true
---

* content
{:toc}

##### Abstract
This work presents deep asymmetric networks with a set of node-wise variant activation functions. The nodes' sensitivities are affected by activation function selections such that the nodes with smaller indices become increasingly more sensitive. As a result, features learned by the nodes are sorted by the node indices in the order of their importance. Asymmetric networks not only learn input features but also the importance of those features. Nodes of lesser importance in asymmetric networks can be pruned to reduce the complexity of the networks, and the pruned networks can be retrained without incurring performance losses. We validate the feature-sorting property using both shallow and deep asymmetric networks as well as deep asymmetric networks transferred from famous networks.

##### Abstract (translated by Google)
这项工作呈现了具有一组节点方式变体激活函数的深度非对称网络。节点的灵敏度受激活函数选择的影响，使得具有较小索引的节点变得越来越敏感。结果，节点学习的特征按节点索引的重要性顺序排序。非对称网络不仅学习输入功能，还学习这些功能的重要性。可以修剪非对称网络中较不重要的节点以降低网络的复杂性，并且可以重新训练修剪的网络而不会导致性能损失。我们使用浅层和深层非对称网络以及从着名网络传输的深度非对称网络来验证特征排序属性。

##### URL
[http://arxiv.org/abs/1809.03721](http://arxiv.org/abs/1809.03721)

##### PDF
[http://arxiv.org/pdf/1809.03721](http://arxiv.org/pdf/1809.03721)

