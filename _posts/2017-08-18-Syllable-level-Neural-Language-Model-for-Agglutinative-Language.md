---
layout: post
title: "Syllable-level Neural Language Model for Agglutinative Language"
date: 2017-08-18 06:02:16
categories: arXiv_CL
tags: arXiv_CL Embedding Language_Model Prediction
author: Seunghak Yu, Nilesh Kulkarni, Haejun Lee, Jihie Kim
mathjax: true
---

* content
{:toc}

##### Abstract
Language models for agglutinative languages have always been hindered in past due to myriad of agglutinations possible to any given word through various affixes. We propose a method to diminish the problem of out-of-vocabulary words by introducing an embedding derived from syllables and morphemes which leverages the agglutinative property. Our model outperforms character-level embedding in perplexity by 16.87 with 9.50M parameters. Proposed method achieves state of the art performance over existing input prediction methods in terms of Key Stroke Saving and has been commercialized.

##### Abstract (translated by Google)
由于通过各种词缀对任何给定词语可能产生的无数凝集，过去一直阻碍粘着语言的语言模式。我们提出了一种方法，通过引入从音节和语素中获得的利用凝集性质的嵌入来减少词汇外的问题。我们的模型在9.50M参数的情况下比16.87更好地表现了字符级的困惑嵌入。所提出的方法在现有的输入预测方法上实现了现有技术的性能，并且已经商业化。

##### URL
[https://arxiv.org/abs/1708.05515](https://arxiv.org/abs/1708.05515)

##### PDF
[https://arxiv.org/pdf/1708.05515](https://arxiv.org/pdf/1708.05515)

