---
layout: post
title: "Fine-grained Video Classification and Captioning"
date: 2018-04-24 20:06:55
categories: arXiv_CV
tags: arXiv_CV Video_Caption Caption Video_Classification Classification Relation
author: Farzaneh Mahdisoltani, Guillaume Berger, Waseem Gharbieh, David Fleet, Roland Memisevic
mathjax: true
---

* content
{:toc}

##### Abstract
We describe a DNN for fine-grained action classification and video captioning. It gives state-of-the-art performance on the challenging Something-Something dataset, with over 220, 000 videos and 174 fine-grained actions. Classification and captioning on this dataset are challenging because of the subtle differences between actions, the use of thousands of different objects, and the diversity of captions penned by crowd actors. The model architecture shares features for classification and captioning, and is trained end-to-end. It performs much better than the existing classification benchmark for Something-Something, with impressive fine-grained results, and it yields a strong baseline on the new Something-Something captioning task. Our results reveal that there is a strong correlation between the degree of detail in the task and the ability of the learned features to transfer to other tasks.

##### Abstract (translated by Google)
我们描述了用于细粒度动作分类和视频字幕的DNN。它在具有挑战性的Something-Something数据集上提供了最先进的性能，拥有超过220,000个视频和174个细粒度的动作。由于行动之间的微妙差异，数千个不同对象的使用以及人群演员所写的字幕的多样性，对该数据集的分类和字幕是具有挑战性的。模型体系结构共享用于分类和字幕的功能，并且是端到端训练的。它比Something-Something的现有分类基准测试表现更好，具有令人印象深刻的细粒度结果，并且它在新的Something-Something字幕任务上产生了强大的基线。我们的结果表明，任务的细节程度与学习特征转移到其他任务的能力之间存在很强的相关性。

##### URL
[https://arxiv.org/abs/1804.09235](https://arxiv.org/abs/1804.09235)

##### PDF
[https://arxiv.org/pdf/1804.09235](https://arxiv.org/pdf/1804.09235)

