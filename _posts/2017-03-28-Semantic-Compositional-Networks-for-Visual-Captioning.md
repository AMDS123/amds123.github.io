---
layout: post
title: "Semantic Compositional Networks for Visual Captioning"
date: 2017-03-28 18:33:51
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption RNN Quantitative
author: Zhe Gan, Chuang Gan, Xiaodong He, Yunchen Pu, Kenneth Tran, Jianfeng Gao, Lawrence Carin, Li Deng
mathjax: true
---

* content
{:toc}

##### Abstract
A Semantic Compositional Network (SCN) is developed for image captioning, in which semantic concepts (i.e., tags) are detected from the image, and the probability of each tag is used to compose the parameters in a long short-term memory (LSTM) network. The SCN extends each weight matrix of the LSTM to an ensemble of tag-dependent weight matrices. The degree to which each member of the ensemble is used to generate an image caption is tied to the image-dependent probability of the corresponding tag. In addition to captioning images, we also extend the SCN to generate captions for video clips. We qualitatively analyze semantic composition in SCNs, and quantitatively evaluate the algorithm on three benchmark datasets: COCO, Flickr30k, and Youtube2Text. Experimental results show that the proposed method significantly outperforms prior state-of-the-art approaches, across multiple evaluation metrics.

##### Abstract (translated by Google)
为图像字幕开发语义合成网络（SCN），其中从图像中检测语义概念（即标签），并且使用每个标签的概率来组成长短期记忆（LSTM）中的参数。网络。 SCN将LSTM的每个权重矩阵扩展到依赖于标签的权重矩阵的集合。使用整体的每个成员生成图像标题的程度与相应标签的图像相关概率相关联。除了字幕图像，我们还扩展了SCN以生成视频剪辑的标题。我们定性分析SCN中的语义组成，并在三个基准数据集上定量评估算法：COCO，Flickr30k和Youtube2Text。实验结果表明，所提出的方法在多个评估指标上明显优于先前的最新方法。

##### URL
[https://arxiv.org/abs/1611.08002](https://arxiv.org/abs/1611.08002)

##### PDF
[https://arxiv.org/pdf/1611.08002](https://arxiv.org/pdf/1611.08002)

