---
layout: post
title: "End-to-End Subtitle Detection and Recognition for Videos in East Asian Languages via CNN Ensemble with Near-Human-Level Performance"
date: 2016-11-18 17:09:14
categories: arXiv_CV
tags: arXiv_CV CNN Language_Model Detection Recognition
author: Yan Xu, Siyuan Shan, Ziming Qiu, Zhipeng Jia, Zhengyang Shen, Yipei Wang, Mengfei Shi, Eric I-Chao Chang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose an innovative end-to-end subtitle detection and recognition system for videos in East Asian languages. Our end-to-end system consists of multiple stages. Subtitles are firstly detected by a novel image operator based on the sequence information of consecutive video frames. Then, an ensemble of Convolutional Neural Networks (CNNs) trained on synthetic data is adopted for detecting and recognizing East Asian characters. Finally, a dynamic programming approach leveraging language models is applied to constitute results of the entire body of text lines. The proposed system achieves average end-to-end accuracies of 98.2% and 98.3% on 40 videos in Simplified Chinese and 40 videos in Traditional Chinese respectively, which is a significant outperformance of other existing methods. The near-perfect accuracy of our system dramatically narrows the gap between human cognitive ability and state-of-the-art algorithms used for such a task.

##### Abstract (translated by Google)
在本文中，我们提出了一个创新的端到端的东亚语言视频字幕检测和识别系统。我们的端到端系统由多个阶段组成。字幕首先由基于连续视频帧的序列信息的新颖图像算子检测。然后，采用合成数据训练的卷积神经网络（CNN）集合来检测和识别东亚字符。最后，利用语言模型的动态规划方法来构成整个文本行的结果。所提出的系统对于简体中文的40个视频和繁体中文的40个视频分别达到98.2％和98.3％的平均端对端准确度，这是其他现有方法的显着性能。我们系统的近乎完美的准确性极大地缩小了人类认知能力和用于此类任务的最先进算法之间的差距。

##### URL
[https://arxiv.org/abs/1611.06159](https://arxiv.org/abs/1611.06159)

##### PDF
[https://arxiv.org/pdf/1611.06159](https://arxiv.org/pdf/1611.06159)

