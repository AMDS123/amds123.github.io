---
layout: post
title: "Maintaining cooperation in complex social dilemmas using deep reinforcement learning"
date: 2018-03-02 14:39:55
categories: arXiv_AI
tags: arXiv_AI Face Reinforcement_Learning
author: Adam Lerer, Alexander Peysakhovich
mathjax: true
---

* content
{:toc}

##### Abstract
Social dilemmas are situations where individuals face a temptation to increase their payoffs at a cost to total welfare. Building artificially intelligent agents that achieve good outcomes in these situations is important because many real world interactions include a tension between selfish interests and the welfare of others. We show how to modify modern reinforcement learning methods to construct agents that act in ways that are simple to understand, nice (begin by cooperating), provokable (try to avoid being exploited), and forgiving (try to return to mutual cooperation). We show both theoretically and experimentally that such agents can maintain cooperation in Markov social dilemmas. Our construction does not require training methods beyond a modification of self-play, thus if an environment is such that good strategies can be constructed in the zero-sum case (eg. Atari) then we can construct agents that solve social dilemmas in this environment.

##### Abstract (translated by Google)
社会困境是个人面临诱惑，以牺牲总福利来增加他们的收益的情况。在这些情况下建立能够取得良好结果的人为智能代理非常重要，因为许多现实世界的相互作用包括自私利益与他人利益之间的紧张关系。我们展示了如何修改现代强化学习方法来构建以简单易懂，好（开始合作），可挑衅（尽量避免被开发）和宽容（试图回到相互合作）的方式行事的代理人。我们在理论上和实验上都表明，这些代理人可以在马尔可夫社会困境中保持合作。我们的构建不需要改变自我发挥的训练方法，因此如果一个环境能够在零和情况下构建好战略（例如Atari），那么我们就可以构建能够解决这种环境中的社会困境的代理。

##### URL
[http://arxiv.org/abs/1707.01068](http://arxiv.org/abs/1707.01068)

##### PDF
[http://arxiv.org/pdf/1707.01068](http://arxiv.org/pdf/1707.01068)

