---
layout: post
title: "Visual Speech Enhancement"
date: 2018-06-13 07:25:47
categories: arXiv_CV
tags: arXiv_CV
author: Aviv Gabbay, Asaph Shamir, Shmuel Peleg
mathjax: true
---

* content
{:toc}

##### Abstract
When video is shot in noisy environment, the voice of a speaker seen in the video can be enhanced using the visible mouth movements, reducing background noise. While most existing methods use audio-only inputs, improved performance is obtained with our visual speech enhancement, based on an audio-visual neural network. We include in the training data videos to which we added the voice of the target speaker as background noise. Since the audio input is not sufficient to separate the voice of a speaker from his own voice, the trained model better exploits the visual input and generalizes well to different noise types. The proposed model outperforms prior audio visual methods on two public lipreading datasets. It is also the first to be demonstrated on a dataset not designed for lipreading, such as the weekly addresses of Barack Obama.

##### Abstract (translated by Google)
当视频在嘈杂的环境中拍摄时，可以使用可见的嘴部动作来增强视频中发言者的声音，从而减少背景噪音。虽然大多数现有方法使用纯音频输入，但基于视听神经网络的视觉语音增强功能可以提高性能。我们在训练数据视频中添加了目标讲话者的语音作为背景噪声。由于音频输入不足以将讲话者的声音与他自己的声音分开，所以训练好的模型更好地利用了视觉输入并且很好地适用于不同的噪声类型。所提出的模型在两个公开的唇读数据集上优于先前的视听方法。它也是第一个在不是为唇涂设计的数据集上进行演示的，例如巴拉克奥巴马的每周地址。

##### URL
[http://arxiv.org/abs/1711.08789](http://arxiv.org/abs/1711.08789)

##### PDF
[http://arxiv.org/pdf/1711.08789](http://arxiv.org/pdf/1711.08789)

