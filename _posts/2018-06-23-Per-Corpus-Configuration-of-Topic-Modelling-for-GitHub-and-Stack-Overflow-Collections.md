---
layout: post
title: "Per-Corpus Configuration of Topic Modelling for GitHub and Stack Overflow Collections"
date: 2018-06-23 11:30:52
categories: arXiv_CL
tags: arXiv_CL
author: Christoph Treude, Markus Wagner
mathjax: true
---

* content
{:toc}

##### Abstract
To make sense of large amounts of textual data, topic modelling is frequently used as a text-mining tool for the discovery of hidden semantic structures in text bodies. Latent Dirichlet allocation (LDA) is a commonly used topic model that aims to explain the structure of a corpus by grouping texts. LDA requires multiple parameters to work well, and there are only rough and sometimes conflicting guidelines available on how these parameters should be set. In this paper, we contribute (i) a broad study of parameters to arrive at good local optima, (ii) an a-posteriori characterisation of text corpora related to eight programming languages from GitHub and Stack Overflow, and (iii) an analysis of corpus feature importance via per-corpus LDA configuration.

##### Abstract (translated by Google)
为了理解大量的文本数据，主题建模经常用作文本挖掘工具，用于发现文本主体中隐藏的语义结构。潜在狄利克雷分配（LDA）是一种常用的主题模型，旨在通过对文本进行分组来解释语料库的结构。 LDA需要多个参数才能正常工作，并且在设置这些参数方面只有粗略的，有时是相互冲突的准则。在本文中，我们提供（i）参数的广泛研究以获得良好的局部最优性，（ii）与来自GitHub和Stack Overflow的八种编程语言有关的文本语料库的后验描述，以及（iii）语料库功能的重要性通过每个语料库LDA配置。

##### URL
[http://arxiv.org/abs/1804.04749](http://arxiv.org/abs/1804.04749)

##### PDF
[http://arxiv.org/pdf/1804.04749](http://arxiv.org/pdf/1804.04749)

