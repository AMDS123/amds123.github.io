---
layout: post
title: "Weakly Supervised Representation Learning for Unsynchronized Audio-Visual Events"
date: 2018-07-09 16:34:42
categories: arXiv_CV
tags: arXiv_CV Weakly_Supervised Represenation_Learning
author: Sanjeel Parekh, Slim Essid, Alexey Ozerov, Ngoc Q. K. Duong, Patrick P&#xe9;rez, Ga&#xeb;l Richard
mathjax: true
---

* content
{:toc}

##### Abstract
Audio-visual representation learning is an important task from the perspective of designing machines with the ability to understand complex events. To this end, we propose a novel multimodal framework that instantiates multiple instance learning. We show that the learnt representations are useful for classifying events and localizing their characteristic audio-visual elements. The system is trained using only video-level event labels without any timing information. An important feature of our method is its capacity to learn from unsynchronized audio-visual events. We achieve state-of-the-art results on a large-scale dataset of weakly-labeled audio event videos. Visualizations of localized visual regions and audio segments substantiate our system's efficacy, especially when dealing with noisy situations where modality-specific cues appear asynchronously.

##### Abstract (translated by Google)
从设计具有理解复杂事件能力的机器的角度来看，视听表示学习是一项重要任务。为此，我们提出了一种新的多模式框架，它实例化多实例学习。我们展示了学习的表示对于分类事件和本地化其特有的视听元素是有用的。仅使用视频级事件标签来训练系统，而没有任何定时信息。我们方法的一个重要特征是它能够学习非同步的视听事件。我们在弱标签音频事件视频的大型数据集上实现了最先进的结果。局部视觉区域和音频片段的可视化证实了我们系统的功效，特别是在处理模态特定提示异步出现的嘈杂情况时。

##### URL
[http://arxiv.org/abs/1804.07345](http://arxiv.org/abs/1804.07345)

##### PDF
[http://arxiv.org/pdf/1804.07345](http://arxiv.org/pdf/1804.07345)

