---
layout: post
title: "Who did What: A Large-Scale Person-Centered Cloze Dataset"
date: 2016-08-19 00:13:10
categories: arXiv_CL
tags: arXiv_CL
author: Takeshi Onishi, Hai Wang, Mohit Bansal, Kevin Gimpel, David McAllester
mathjax: true
---

* content
{:toc}

##### Abstract
We have constructed a new "Who-did-What" dataset of over 200,000 fill-in-the-gap (cloze) multiple choice reading comprehension problems constructed from the LDC English Gigaword newswire corpus. The WDW dataset has a variety of novel features. First, in contrast with the CNN and Daily Mail datasets (Hermann et al., 2015) we avoid using article summaries for question formation. Instead, each problem is formed from two independent articles --- an article given as the passage to be read and a separate article on the same events used to form the question. Second, we avoid anonymization --- each choice is a person named entity. Third, the problems have been filtered to remove a fraction that are easily solved by simple baselines, while remaining 84% solvable by humans. We report performance benchmarks of standard systems and propose the WDW dataset as a challenge task for the community.

##### Abstract (translated by Google)
我们已经构建了由LDC英语Gigaword新闻专线语料库构建的超过20万个填空（完形填空）阅读理解问题的“Who-did-What”数据集。 WDW数据集具有各种新颖的特征。首先，与CNN和Daily Mail数据集（Hermann等，2015）相比，我们避免使用文章摘要来形成问题。相反，每一个问题都是由两个独立的文章构成的---一篇文章是作为阅读的段落给出的，另一篇文章是关于用于形成问题的相同的事件。其次，我们避免匿名 - 每个选择都是一个名为实体的人。第三，这些问题已被过滤去除了一些容易被简单基线解决的部分，而剩下的84％可以被人类解决。我们报告标准系统的性能基准，并提出WDW数据集作为社区的挑战任务。

##### URL
[https://arxiv.org/abs/1608.05457](https://arxiv.org/abs/1608.05457)

##### PDF
[https://arxiv.org/pdf/1608.05457](https://arxiv.org/pdf/1608.05457)

