---
layout: post
title: "ReshapeGAN: Object Reshaping by Providing A Single Reference Image"
date: 2019-05-16 03:54:12
categories: arXiv_CV
tags: arXiv_CV Adversarial Knowledge GAN
author: Ziqiang Zheng, Yang Wu, Zhibin Yu, Yang Yang, Haiyong Zheng, Takeo Kanade
mathjax: true
---

* content
{:toc}

##### Abstract
The aim of this work is learning to reshape the object in an input image to an arbitrary new shape, by just simply providing a single reference image with an object instance in the desired shape. We propose a new Generative Adversarial Network (GAN) architecture for such an object reshaping problem, named ReshapeGAN. The network can be tailored for handling all kinds of problem settings, including both within-domain (or single-dataset) reshaping and cross-domain (typically across mutiple datasets) reshaping, with paired or unpaired training data. The appearance of the input object is preserved in all cases, and thus it is still identifiable after reshaping, which has never been achieved as far as we are aware. We present the tailored models of the proposed ReshapeGAN for all the problem settings, and have them tested on 8 kinds of reshaping tasks with 13 different datasets, demonstrating the ability of ReshapeGAN on generating convincing and superior results for object reshaping. To the best of our knowledge, we are the first to be able to make one GAN framework work on all such object reshaping tasks, especially the cross-domain tasks on handling multiple diverse datasets. We present here both ablation studies on our proposed ReshapeGAN models and comparisons with the state-of-the-art models when they are made comparable, using all kinds of applicable metrics that we are aware of.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.06514](http://arxiv.org/abs/1905.06514)

##### PDF
[http://arxiv.org/pdf/1905.06514](http://arxiv.org/pdf/1905.06514)

