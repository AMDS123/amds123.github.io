---
layout: post
title: "Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning"
date: 2019-02-04 18:45:46
categories: arXiv_AI
tags: arXiv_AI Sparse Reinforcement_Learning
author: Arthur Juliani, Ahmed Khalifa, Vincent-Pierre Berges, Jonathan Harper, Hunter Henry, Adam Crespi, Julian Togelius, Danny Lange
mathjax: true
---

* content
{:toc}

##### Abstract
The rapid pace of research in Deep Reinforcement Learning has been driven by the presence of fast and challenging simulation environments. These environments often take the form of games; with tasks ranging from simple board games, to classic home console games, to modern strategy games. We propose a new benchmark called Obstacle Tower: a high visual fidelity, 3D, 3rd person, procedurally generated game environment. An agent in the Obstacle Tower must learn to solve both low-level control and high-level planning problems in tandem while learning from pixels and a sparse reward signal. Unlike other similar benchmarks such as the ALE, evaluation of agent performance in Obstacle Tower is based on an agent's ability to perform well on unseen instances of the environment. In this paper we outline the environment and provide a set of initial baseline results produced by current state-of-the-art Deep RL methods as well as human players. In all cases these algorithms fail to produce agents capable of performing anywhere near human level on a set of evaluations designed to test both memorization and generalization ability. As such, we believe that the Obstacle Tower has the potential to serve as a helpful Deep RL benchmark now and into the future.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.01378](http://arxiv.org/abs/1902.01378)

##### PDF
[http://arxiv.org/pdf/1902.01378](http://arxiv.org/pdf/1902.01378)

