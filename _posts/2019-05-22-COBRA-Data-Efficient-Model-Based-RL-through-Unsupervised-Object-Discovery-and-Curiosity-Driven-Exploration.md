---
layout: post
title: "COBRA: Data-Efficient Model-Based RL through Unsupervised Object Discovery and Curiosity-Driven Exploration"
date: 2019-05-22 17:59:32
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Nicholas Watters, Loic Matthey, Matko Bosnjak, Christopher P. Burgess, Alexander Lerchner
mathjax: true
---

* content
{:toc}

##### Abstract
Data efficiency and robustness to task-irrelevant perturbations are long-standing challenges for deep reinforcement learning algorithms. Here we introduce a modular approach to addressing these challenges in a continuous control environment, without using hand-crafted or supervised information. Our Curious Object-Based seaRch Agent (COBRA) uses task-free intrinsically motivated exploration and unsupervised learning to build object-based models of its environment and action space. Subsequently, it can learn a variety of tasks through model-based search in very few steps and excel on structured hold-out tests of policy robustness.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.09275](http://arxiv.org/abs/1905.09275)

##### PDF
[http://arxiv.org/pdf/1905.09275](http://arxiv.org/pdf/1905.09275)

