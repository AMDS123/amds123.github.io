---
layout: post
title: "Canonical Tensor Decomposition for Knowledge Base Completion"
date: 2018-06-19 14:57:18
categories: arXiv_AI
tags: arXiv_AI Knowledge
author: Timoth&#xe9;e Lacroix, Nicolas Usunier, Guillaume Obozinski
mathjax: true
---

* content
{:toc}

##### Abstract
The problem of Knowledge Base Completion can be framed as a 3rd-order binary tensor completion problem. In this light, the Canonical Tensor Decomposition (CP) (Hitchcock, 1927) seems like a natural solution; however, current implementations of CP on standard Knowledge Base Completion benchmarks are lagging behind their competitors. In this work, we attempt to understand the limits of CP for knowledge base completion. First, we motivate and test a novel regularizer, based on tensor nuclear $p$-norms. Then, we present a reformulation of the problem that makes it invariant to arbitrary choices in the inclusion of predicates or their reciprocals in the dataset. These two methods combined allow us to beat the current state of the art on several datasets with a CP decomposition, and obtain even better results using the more advanced ComplEx model.

##### Abstract (translated by Google)
知识库完成的问题可以被定义为一个三阶二元张量完成问题。有鉴于此，标准张量分解（CP）（Hitchcock，1927）似乎是一个自然的解决方案;然而，目前在标准知识库完成基准测试中执行的CP落后于其竞争对手。在这项工作中，我们尝试了解CP完成知识库的限制。首先，我们根据张量核$ p $ -norms来激励和测试一个新的正规化器。然后，我们提出这个问题的重新表述，使得它在数据集中包含谓词或其倒数的任意选择时不变。综合这两种方法，我们可以在CP分解的几个数据集上击败当前的艺术状态，并使用更高级的ComplEx模型获得更好的结果。

##### URL
[http://arxiv.org/abs/1806.07297](http://arxiv.org/abs/1806.07297)

##### PDF
[http://arxiv.org/pdf/1806.07297](http://arxiv.org/pdf/1806.07297)

