---
layout: post
title: "Active Object Perceiver: Recognition-guided Policy Learning for Object Searching on Mobile Robots"
date: 2018-07-30 05:09:27
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Prediction Recognition
author: Xin Ye, Zhe Lin, Haoxiang Li, Shibin Zheng, Yezhou Yang
mathjax: true
---

* content
{:toc}

##### Abstract
We study the problem of learning a navigation policy for a robot to actively search for an object of interest in an indoor environment solely from its visual inputs. While scene-driven visual navigation has been widely studied, prior efforts on learning navigation policies for robots to find objects are limited. The problem is often more challenging than target scene finding as the target objects can be very small in the view and can be in an arbitrary pose. We approach the problem from an active perceiver perspective, and propose a novel framework that integrates a deep neural network based object recognition module and a deep reinforcement learning based action prediction mechanism. To validate our method, we conduct experiments on both a simulation dataset (AI2-THOR) and a real-world environment with a physical robot. We further propose a new decaying reward function to learn the control policy specific to the object searching task. Experimental results validate the efficacy of our method, which outperforms competing methods in both average trajectory length and success rate.

##### Abstract (translated by Google)
我们研究了为机器人学习导航策略的问题，该机器人仅通过其视觉输入主动在室内环境中搜索感兴趣的对象。虽然已经广泛研究了场景驱动的视觉导航，但是学习用于机器人查找对象的导航策略的先前努力是有限的。该问题通常比目标场景发现更具挑战性，因为目标对象在视图中可以非常小并且可以是任意姿势。我们从积极的感知角度处理问题，并提出一种新的框架，该框架集成了基于深度神经网络的对象识别模块和基于深度强化学习的动作预测机制。为了验证我们的方法，我们在模拟数据集（AI2-THOR）和物理机器人的真实环境中进行实验。我们进一步提出了一种新的衰减奖励函数来学习特定于对象搜索任务的控制策略。实验结果验证了该方法的有效性，在平均轨迹长度和成功率方面均优于竞争方法。

##### URL
[http://arxiv.org/abs/1807.11174](http://arxiv.org/abs/1807.11174)

##### PDF
[http://arxiv.org/pdf/1807.11174](http://arxiv.org/pdf/1807.11174)

