---
layout: post
title: "Co-interest Person Detection from Multiple Wearable Camera Videos"
date: 2015-09-05 01:48:00
categories: arXiv_CV
tags: arXiv_CV Segmentation Attention Detection
author: Yuewei Lin, Kareem Ezzeldeen, Youjie Zhou, Xiaochuan Fan, Hongkai Yu, Hui Qian, Song Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Wearable cameras, such as Google Glass and Go Pro, enable video data collection over larger areas and from different views. In this paper, we tackle a new problem of locating the co-interest person (CIP), i.e., the one who draws attention from most camera wearers, from temporally synchronized videos taken by multiple wearable cameras. Our basic idea is to exploit the motion patterns of people and use them to correlate the persons across different videos, instead of performing appearance-based matching as in traditional video co-segmentation/localization. This way, we can identify CIP even if a group of people with similar appearance are present in the view. More specifically, we detect a set of persons on each frame as the candidates of the CIP and then build a Conditional Random Field (CRF) model to select the one with consistent motion patterns in different videos and high spacial-temporal consistency in each video. We collect three sets of wearable-camera videos for testing the proposed algorithm. All the involved people have similar appearances in the collected videos and the experiments demonstrate the effectiveness of the proposed algorithm.

##### Abstract (translated by Google)
诸如Google Glass和Go Pro之类的可穿戴摄像头可以在更大范围和不同视图中收集视频数据。在本文中，我们解决了从多个可穿戴相机拍摄的时间同步视频中定位共同兴趣人（CIP）的新问题，即从大多数相机佩戴者引起注意的人。我们的基本思想是利用人物的运动模式，并利用它们将不同视频中的人物关联起来，而不是像传统的视频共分割/定位那样进行基于外观的匹配。这样一来，即使有一群外貌相似的人出现在视图中，我们也可以识别CIP。更具体地说，我们检测每个帧上的一组人作为CIP的候选者，然后建立一个条件随机场（CRF）模型来选择在不同视频中具有一致运动模式并且在每个视频中具有高时空一致性的模型。我们收集三套可穿戴相机视频，用于测试所提出的算法。所有参与者在收集的视频中都具有相似的外观，并且实验证明了所提出的算法的有效性。

##### URL
[https://arxiv.org/abs/1509.01654](https://arxiv.org/abs/1509.01654)

##### PDF
[https://arxiv.org/pdf/1509.01654](https://arxiv.org/pdf/1509.01654)

