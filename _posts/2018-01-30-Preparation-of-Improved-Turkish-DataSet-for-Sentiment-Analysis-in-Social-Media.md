---
layout: post
title: "Preparation of Improved Turkish DataSet for Sentiment Analysis in Social Media"
date: 2018-01-30 13:18:51
categories: arXiv_CL
tags: arXiv_CL Sentiment Review Prediction Detection
author: Semiha Makinist, &#x130;brahim R&#x131;za Halla&#xe7;, Bet&#xfc;l Ay Karaku&#x15f;, Galip Ayd&#x131;n
mathjax: true
---

* content
{:toc}

##### Abstract
A public dataset, with a variety of properties suitable for sentiment analysis [1], event prediction, trend detection and other text mining applications, is needed in order to be able to successfully perform analysis studies. The vast majority of data on social media is text-based and it is not possible to directly apply machine learning processes into these raw data, since several different processes are required to prepare the data before the implementation of the algorithms. For example, different misspellings of same word enlarge the word vector space unnecessarily, thereby it leads to reduce the success of the algorithm and increase the computational power requirement. This paper presents an improved Turkish dataset with an effective spelling correction algorithm based on Hadoop [2]. The collected data is recorded on the Hadoop Distributed File System and the text based data is processed by MapReduce programming model. This method is suitable for the storage and processing of large sized text based social media data. In this study, movie reviews have been automatically recorded with Apache ManifoldCF (MCF) [3] and data clusters have been created. Various methods compared such as Levenshtein and Fuzzy String Matching have been proposed to create a public dataset from collected data. Experimental results show that the proposed algorithm, which can be used as an open source dataset in sentiment analysis studies, have been performed successfully to the detection and correction of spelling errors.

##### Abstract (translated by Google)
为了能够成功进行分析研究，需要一个公共数据集，具有适合于情感分析[1]，事件预测，趋势检测和其他文本挖掘应用的各种属性。社交媒体上的绝大多数数据是基于文本的，并且不可能将机器学习过程直接应用到这些原始数据中，因为在算法实施之前需要几个不同的过程来准备数据。例如，同一个词的不同拼写错误会使词向量空间不必要地扩大，从而导致算法的成功性降低，增加了计算能力的要求。本文提出了一个基于Hadoop的有效拼写纠正算法的改进土耳其数据集[2]。收集到的数据记录在Hadoop分布式文件系统上，基于文本的数据由MapReduce编程模型处理。这种方法适用于基于大型文本的社交媒体数据的存储和处理。在这项研究中，电影评论已经被Apache ManifoldCF（MCF）[3]自动录制，并且已经创建了数据集群。已经提出了诸如Levenshtein和模糊字符串匹配的各种方法来从收集的数据创建公共数据集。实验结果表明，该算法在情感分析研究中可以作为开源数据集，成功地用于拼写错误的检测和纠正。

##### URL
[http://arxiv.org/abs/1801.09975](http://arxiv.org/abs/1801.09975)

##### PDF
[http://arxiv.org/pdf/1801.09975](http://arxiv.org/pdf/1801.09975)

