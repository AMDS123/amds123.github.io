---
layout: post
title: "LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking"
date: 2019-05-07 22:02:00
categories: arXiv_CV
tags: arXiv_CV Knowledge Pose_Estimation Tracking Object_Tracking
author: Guanghan Ning, Heng Huang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a novel effective light-weight framework, called LightTrack, for online human pose tracking. The proposed framework is designed to be generic for top-down pose tracking and is faster than existing online and offline methods. Single-person Pose Tracking (SPT) and Visual Object Tracking (VOT) are incorporated into one unified functioning entity, easily implemented by a replaceable single-person pose estimation module. Our framework unifies single-person pose tracking with multi-person identity association and sheds first light upon bridging keypoint tracking with object tracking. We also propose a Siamese Graph Convolution Network (SGCN) for human pose matching as a Re-ID module in our pose tracking system. In contrary to other Re-ID modules, we use a graphical representation of human joints for matching. The skeleton-based representation effectively captures human pose similarity and is computationally inexpensive. It is robust to sudden camera shift that introduces human drifting. To the best of our knowledge, this is the first paper to propose an online human pose tracking framework in a top-down fashion. The proposed framework is general enough to fit other pose estimators and candidate matching mechanisms. Our method outperforms other online methods while maintaining a much higher frame rate, and is very competitive with our offline state-of-the-art. We make the code publicly available at: https://github.com/Guanghan/lighttrack.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.02822](http://arxiv.org/abs/1905.02822)

##### PDF
[http://arxiv.org/pdf/1905.02822](http://arxiv.org/pdf/1905.02822)

