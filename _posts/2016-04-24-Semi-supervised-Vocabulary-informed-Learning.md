---
layout: post
title: "Semi-supervised Vocabulary-informed Learning"
date: 2016-04-24 23:36:36
categories: arXiv_CV
tags: arXiv_CV Embedding Recognition
author: Yanwei Fu, Leonid Sigal
mathjax: true
---

* content
{:toc}

##### Abstract
Despite significant progress in object categorization, in recent years, a number of important challenges remain, mainly, ability to learn from limited labeled data and ability to recognize object classes within large, potentially open, set of labels. Zero-shot learning is one way of addressing these challenges, but it has only been shown to work with limited sized class vocabularies and typically requires separation between supervised and unsupervised classes, allowing former to inform the latter but not vice versa. We propose the notion of semi-supervised vocabulary-informed learning to alleviate the above mentioned challenges and address problems of supervised, zero-shot and open set recognition using a unified framework. Specifically, we propose a maximum margin framework for semantic manifold-based recognition that incorporates distance constraints from (both supervised and unsupervised) vocabulary atoms, ensuring that labeled samples are projected closest to their correct prototypes, in the embedding space, than to others. We show that resulting model shows improvements in supervised, zero-shot, and large open set recognition, with up to 310K class vocabulary on AwA and ImageNet datasets.

##### Abstract (translated by Google)
尽管目标分类取得了重大进展，但近年来仍然存在一些重要的挑战，主要是有限的标记数据的学习能力以及识别潜在开放的大型标签中的对象类别的能力。零点学习是解决这些挑战的方法之一，但它只能用于有限大小的类别词汇表，并且通常需要在有监督的班级和无监督班级之间进行分离，允许前者告知后者，反之亦然。我们提出了半监督词汇知情学习的概念，以缓解上述挑战，并利用统一框架解决监督，零点和开放集合识别问题。具体来说，我们提出了一个基于语义流形的识别的最大边界框架，该框架结合了词汇原子（有监督和无监督）的距离约束，确保标记的样本在嵌入空间中被投影到最接近其正确原型的位置。我们展示了最终的模型显示在监督，零炮弹和大型开放集识别方面的改进，在AwA和ImageNet数据集上有高达310K级的词汇表。

##### URL
[https://arxiv.org/abs/1604.07093](https://arxiv.org/abs/1604.07093)

##### PDF
[https://arxiv.org/pdf/1604.07093](https://arxiv.org/pdf/1604.07093)

