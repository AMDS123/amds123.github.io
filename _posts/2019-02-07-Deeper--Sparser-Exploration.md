---
layout: post
title: "Deeper & Sparser Exploration"
date: 2019-02-07 14:52:37
categories: arXiv_AI
tags: arXiv_AI Sparse Reinforcement_Learning
author: Divya Grover, Christos Dimitrakakis
mathjax: true
---

* content
{:toc}

##### Abstract
We address the problem of efficient exploration by proposing a new meta algorithm in the context of model-based online planning for Bayesian Reinforcement Learning (BRL). We beat the state-of-the-art, while staying computationally faster, in some cases by two orders of magnitude. This is the first Optimism free BRL algorithm to beat all previous state-of-the-art in tabular RL. The main novelty is the use of a candidate policy generator, to generate long-term options in the belief tree, which allows us to create much sparser and deeper trees. We present results on many standard environments and empirically prove its performance.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.02661](http://arxiv.org/abs/1902.02661)

##### PDF
[http://arxiv.org/pdf/1902.02661](http://arxiv.org/pdf/1902.02661)

