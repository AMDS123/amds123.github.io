---
layout: post
title: "Generating Diverse and Accurate Visual Captions by Comparative Adversarial Learning"
date: 2018-04-11 08:05:47
categories: arXiv_CV
tags: arXiv_CV Image_Caption Adversarial Caption
author: Dianqi Li, Qiuyuan Huang, Xiaodong He, Lei Zhang, Ming-Ting Sun
mathjax: true
---

* content
{:toc}

##### Abstract
We study how to generate captions that are not only accurate in describing an image but also discriminative across different images. The problem is both fundamental and interesting, as most machine-generated captions, despite phenomenal research progresses in the past several years, are expressed in a very monotonic and featureless format. While such captions are normally accurate, they often lack important characteristics in human languages - distinctiveness for each caption and diversity for different images. To address this problem, we propose a novel conditional generative adversarial network for generating diverse captions across images. Instead of estimating the quality of a caption solely on one image, the proposed comparative adversarial learning framework better assesses the quality of captions by comparing a set of captions within the image-caption joint space. By contrasting with human-written captions and image-mismatched captions, the caption generator effectively exploits the inherent characteristics of human languages, and generates more discriminative captions. We show that our proposed network is capable of producing accurate and diverse captions across images.

##### Abstract (translated by Google)
我们研究如何生成不仅在描述图像时准确而且在不同图像之间具有辨别力的字幕。这个问题既重要又有趣，因为尽管在过去几年中取得了惊人的研究进展，但大多数机器生成的标题都是以非常单调且无特色的形式表达的。虽然这些字幕通常是准确的，但它们通常缺乏人类语言的重要特征 - 每个字幕的独特性和不同图像的多样性。为了解决这个问题，我们提出了一种新的条件生成对抗网络，用于生成跨图像的不同字幕。建议的比较对抗性学习框架不是仅仅在一张图像上估计字幕的质量，而是通过比较图像标题联合空间内的一组字幕来更好地评估字幕的质量。通过与人工书写字幕和图像不匹配的字幕形成对比，字幕生成器有效地利用了人类语言的固有特征，并产生了更多的歧视性字幕。我们表明，我们提出的网络能够在图像上生成准确和多样的字幕。

##### URL
[https://arxiv.org/abs/1804.00861](https://arxiv.org/abs/1804.00861)

##### PDF
[https://arxiv.org/pdf/1804.00861](https://arxiv.org/pdf/1804.00861)

