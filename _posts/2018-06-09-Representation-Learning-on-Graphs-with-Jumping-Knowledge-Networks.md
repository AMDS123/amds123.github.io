---
layout: post
title: "Representation Learning on Graphs with Jumping Knowledge Networks"
date: 2018-06-09 19:49:57
categories: arXiv_AI
tags: arXiv_AI Knowledge Attention CNN Represenation_Learning Deep_Learning
author: Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, Stefanie Jegelka
mathjax: true
---

* content
{:toc}

##### Abstract
Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure. We analyze some important properties of these models, and propose a strategy to overcome those. In particular, the range of "neighboring" nodes that a node's representation draws from strongly depends on the graph structure, analogous to the spread of a random walk. To adapt to local neighborhood properties and tasks, we explore an architecture -- jumping knowledge (JK) networks -- that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation. In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance. Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models' performance.

##### Abstract (translated by Google)
近期用于图表表达学习的深度学习方法遵循邻域聚集过程。我们分析这些模型的一些重要特性，并提出一个克服这些模型的策略。特别是，一个节点的表示从中汲取的“邻近”节点的范围很大程度上取决于图结构，类似于随机游走的扩展。为了适应当地邻居的特性和任务，我们探索了一个架构跳跃式知识（JK）网络 - 灵活地利用每个节点的不同邻域范围，以实现更好的结构意识表示。在许多关于社交，生物信息学和引文网络的实验中，我们证明了我们的模型达到了最先进的性能。此外，将JK框架与Graph Convolutional Networks，GraphSAGE和Graph Attention Networks等模型相结合，可以持续改善这些模型的性能。

##### URL
[http://arxiv.org/abs/1806.03536](http://arxiv.org/abs/1806.03536)

##### PDF
[http://arxiv.org/pdf/1806.03536](http://arxiv.org/pdf/1806.03536)

