---
layout: post
title: "Restricting Greed in Training of Generative Adversarial Network"
date: 2018-09-06 12:37:56
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Deep_Learning
author: Haoxuan You, Zhicheng Jiao, Haojun Xu, Jie Li, Ying Wang, Xinbo Gao
mathjax: true
---

* content
{:toc}

##### Abstract
Generative adversarial network (GAN) has gotten wide re-search interest in the field of deep learning. Variations of GAN have achieved competitive results on specific tasks. However, the stability of training and diversity of generated instances are still worth studying further. Training of GAN can be thought of as a greedy procedure, in which the generative net tries to make the locally optimal choice (minimizing loss function of discriminator) in each iteration. Unfortunately, this often makes generated data resemble only a few modes of real data and rotate between modes. To alleviate these problems, we propose a novel training strategy to restrict greed in training of GAN. With help of our method, the generated samples can cover more instance modes with more stable training process. Evaluating our method on several representative datasets, we demonstrate superiority of improved training strategy on typical GAN models with different distance metrics.

##### Abstract (translated by Google)
生成对抗网络（GAN）在深度学习领域获得了广泛的研究兴趣。 GAN的变化在特定任务上取得了竞争性成果。但是，培训的稳定性和生成实例的多样性仍值得进一步研究。 GAN的训练可以被认为是一种贪婪的过程，其中生成网试图在每次迭代中做出局部最优选择（最小化鉴别器的损失函数）。不幸的是，这通常使生成的数据仅类似于几种模式的实际数据并在模式之间旋转。为了缓解这些问题，我们提出了一种新的训练策略，以限制GAN训练中的贪婪。借助我们的方法，生成的样本可以覆盖更多实例模式，培训过程更加稳定。在几个有代表性的数据集上评估我们的方法，我们证明了改进的训练策略在具有不同距离度量的典型GAN模型上的优越性。

##### URL
[http://arxiv.org/abs/1711.10152](http://arxiv.org/abs/1711.10152)

##### PDF
[http://arxiv.org/pdf/1711.10152](http://arxiv.org/pdf/1711.10152)

