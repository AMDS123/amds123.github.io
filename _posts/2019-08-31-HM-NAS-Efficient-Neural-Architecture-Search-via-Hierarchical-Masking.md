---
layout: post
title: "HM-NAS: Efficient Neural Architecture Search via Hierarchical Masking"
date: 2019-08-31 04:02:16
categories: arXiv_CV
tags: arXiv_CV Attention
author: Shen Yan, Biyi Fang, Faen Zhang, Yu Zheng, Xiao Zeng, Hui Xu, Mi Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
The use of automatic methods, often referred to as Neural Architecture Search (NAS), in designing neural network architectures has recently drawn considerable attention. In this work, we present an efficient NAS approach, named HM- NAS, that generalizes existing weight sharing based NAS approaches. Existing weight sharing based NAS approaches still adopt hand-designed heuristics to generate architecture candidates. As a consequence, the space of architecture candidates is constrained in a subset of all possible architectures, making the architecture search results sub-optimal. HM-NAS addresses this limitation via two innovations. First, HM-NAS incorporates a multi-level architecture encoding scheme to enable searching for more flexible network architectures. Second, it discards the hand-designed heuristics and incorporates a hierarchical masking scheme that automatically learns and determines the optimal architecture. Compared to state-of-the-art weight sharing based approaches, HM-NAS is able to achieve better architecture search performance and competitive model evaluation accuracy. Without the constraint imposed by the hand-designed heuristics, our searched networks contain more flexible and meaningful architectures that existing weight sharing based NAS approaches are not able to discover

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1909.00122](http://arxiv.org/abs/1909.00122)

##### PDF
[http://arxiv.org/pdf/1909.00122](http://arxiv.org/pdf/1909.00122)

