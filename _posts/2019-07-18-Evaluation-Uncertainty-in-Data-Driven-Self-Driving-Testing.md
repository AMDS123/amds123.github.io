---
layout: post
title: "Evaluation Uncertainty in Data-Driven Self-Driving Testing"
date: 2019-07-18 02:08:25
categories: arXiv_RO
tags: arXiv_RO
author: Zhiyuan Huang, Mansur Arief, Henry Lam, Ding Zhao
mathjax: true
---

* content
{:toc}

##### Abstract
Safety evaluation of self-driving technologies has been extensively studied. One recent approach uses Monte Carlo based evaluation to estimate the occurrence probabilities of safety-critical events as safety measures. These Monte Carlo samples are generated from stochastic input models constructed based on real-world data. In this paper, we propose an approach to assess the impact on the probability estimates from the evaluation procedures due to the estimation error caused by data variability. Our proposed method merges the classical bootstrap method for estimating input uncertainty with a likelihood ratio based scheme to reuse experiment outputs. This approach is economical and efficient in terms of implementation costs in assessing input uncertainty for the evaluation of self-driving technology. We use an example in autonomous vehicle (AV) safety evaluation to demonstrate the proposed approach as a diagnostic tool for the quality of the fitted input model.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.09306](http://arxiv.org/abs/1904.09306)

##### PDF
[http://arxiv.org/pdf/1904.09306](http://arxiv.org/pdf/1904.09306)

