---
layout: post
title: "Solving the Rubik's Cube Without Human Knowledge"
date: 2018-05-18 23:07:31
categories: arXiv_AI
tags: arXiv_AI Sparse Knowledge Reinforcement_Learning Optimization
author: Stephen McAleer, Forest Agostinelli, Alexander Shmakov, Pierre Baldi
mathjax: true
---

* content
{:toc}

##### Abstract
A generally intelligent agent must be able to teach itself how to solve problems in complex domains with minimal human supervision. Recently, deep reinforcement learning algorithms combined with self-play have achieved superhuman proficiency in Go, Chess, and Shogi without human data or domain knowledge. In these environments, a reward is always received at the end of the game, however, for many combinatorial optimization environments, rewards are sparse and episodes are not guaranteed to terminate. We introduce Autodidactic Iteration: a novel reinforcement learning algorithm that is able to teach itself how to solve the Rubik's Cube with no human assistance. Our algorithm is able to solve 100% of randomly scrambled cubes while achieving a median solve length of 30 moves -- less than or equal to solvers that employ human domain knowledge.

##### Abstract (translated by Google)
一般而言，智能代理必须能够自我教导如何以最少的人力监督解决复杂领域的问题。最近，深度强化学习算法与自我玩耍相结合，在没有人类数据或领域知识的Go，Chess和Shogi中取得了超人的成就。在这些环境中，总是在游戏结束时收到奖励，但是，对于许多组合优化环境来说，奖励是稀疏的，情节不保证终止。我们介绍Autodidactic Iteration：一种新颖的强化学习算法，可以自行教导如何在没有人工协助的情况下解决魔方问题。我们的算法能够解决100％的随机加扰立方体，同时实现30步移动的中值解长度 - 小于或等于使用人类领域知识的解算器。

##### URL
[https://arxiv.org/abs/1805.07470](https://arxiv.org/abs/1805.07470)

##### PDF
[https://arxiv.org/pdf/1805.07470](https://arxiv.org/pdf/1805.07470)

