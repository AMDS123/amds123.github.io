---
layout: post
title: "Efficient Graph-based Word Sense Induction by Distributional Inclusion Vector Embeddings"
date: 2018-05-29 19:38:04
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Haw-Shiuan Chang, Amol Agrawal, Ananya Ganesh, Anirudha Desai, Vinayak Mathur, Alfred Hough, Andrew McCallum
mathjax: true
---

* content
{:toc}

##### Abstract
Word sense induction (WSI), which addresses polysemy by unsupervised discovery of multiple word senses, resolves ambiguities for downstream NLP tasks and also makes word representations more interpretable. This paper proposes an accurate and efficient graph-based method for WSI that builds a global non-negative vector embedding basis (which are interpretable like topics) and clusters the basis indexes in the ego network of each polysemous word. By adopting distributional inclusion vector embeddings as our basis formation model, we avoid the expensive step of nearest neighbor search that plagues other graph-based methods without sacrificing the quality of sense clusters. Experiments on three datasets show that our proposed method produces similar or better sense clusters and embeddings compared with previous state-of-the-art methods while being significantly more efficient.

##### Abstract (translated by Google)
通过无监督地发现多个词义来解决多义性的词义感应（WSI）解决了下游NLP任务的歧义，并且还使得词义更易于解释。本文提出了一种准确和高效的基于图的WSI方法，该方法建立了一个全局非负向量嵌入基（可以像主题一样解释），并将每个多义词的自我网络中的基础索引聚类在一起。通过采用分布式包含矢量嵌入作为我们的基础形成模型，我们避免了昂贵的最近邻搜索步骤，它困扰了其他基于图的方法而不牺牲感知集群的质量。对三个数据集的实验表明，与先前的先进方法相比，我们提出的方法产生类似或更好的感知簇和嵌入，同时效率更高。

##### URL
[http://arxiv.org/abs/1804.03257](http://arxiv.org/abs/1804.03257)

##### PDF
[http://arxiv.org/pdf/1804.03257](http://arxiv.org/pdf/1804.03257)

