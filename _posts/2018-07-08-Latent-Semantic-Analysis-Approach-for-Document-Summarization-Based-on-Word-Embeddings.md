---
layout: post
title: "Latent Semantic Analysis Approach for Document Summarization Based on Word Embeddings"
date: 2018-07-08 03:39:37
categories: arXiv_CL
tags: arXiv_CL Attention Summarization Embedding
author: Kamal Al-Sabahi, Zhang Zuping, Yang Kang
mathjax: true
---

* content
{:toc}

##### Abstract
Since the amount of information on the internet is growing rapidly, it is not easy for a user to find relevant information for his/her query. To tackle this issue, much attention has been paid to Automatic Document Summarization. The key point in any successful document summarizer is a good document representation. The traditional approaches based on word overlapping mostly fail to produce that kind of representation. Word embedding, distributed representation of words, has shown an excellent performance that allows words to match on semantic level. Naively concatenating word embeddings makes the common word dominant which in turn diminish the representation quality. In this paper, we employ word embeddings to improve the weighting schemes for calculating the input matrix of Latent Semantic Analysis method. Two embedding-based weighting schemes are proposed and then combined to calculate the values of this matrix. The new weighting schemes are modified versions of the augment weight and the entropy frequency. The new schemes combine the strength of the traditional weighting schemes and word embedding. The proposed approach is experimentally evaluated on three well-known English datasets, DUC 2002, DUC 2004 and Multilingual 2015 Single-document Summarization for English. The proposed model performs comprehensively better compared to the state-of-the-art methods, by at least 1% ROUGE points, leading to a conclusion that it provides a better document representation and a better document summary as a result.

##### Abstract (translated by Google)
由于互联网上的信息量正在快速增长，因此用户不容易找到他/她的查询的相关信息。为了解决这个问题，自动文档摘要已经引起了很多关注。任何成功的文档摘要生成器的关键点都是良好的文档表示。基于单词重叠的传统方法大多不能产生这种表示。单词嵌入，单词的分布式表示，已经表现出优秀的性能，允许单词在语义级别上匹配。天真地连接词嵌入使得常用词占优势，这反过来降低了表示质量。在本文中，我们采用字嵌入来改进计算潜在语义分析方法输入矩阵的加权方案。提出了两种基于嵌入的加权方案，然后将其组合以计算该矩阵的值。新的加权方案是增强权重和熵频率的修改版本。新方案结合了传统加权方案和文字嵌入的优势。所提出的方法通过实验评估三个着名的英语数据集，DUC 2002，DUC 2004和多语言2015单文档英文汇总。通过至少1％的ROUGE点，与最先进的方法相比，所提出的模型表现得更好，从而得出结论，它提供了更好的文档表示和更好的文档摘要。

##### URL
[http://arxiv.org/abs/1807.02748](http://arxiv.org/abs/1807.02748)

##### PDF
[http://arxiv.org/pdf/1807.02748](http://arxiv.org/pdf/1807.02748)

