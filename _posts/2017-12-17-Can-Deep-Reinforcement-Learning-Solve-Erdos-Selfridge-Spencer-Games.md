---
layout: post
title: "Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?"
date: 2017-12-17 00:51:17
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Maithra Raghu, Alex Irpan, Jacob Andreas, Robert Kleinberg, Quoc V. Le, Jon Kleinberg
mathjax: true
---

* content
{:toc}

##### Abstract
Deep reinforcement learning has achieved many recent successes, but our understanding of its strengths and limitations is hampered by the lack of rich environments in which we can fully characterize optimal behavior, and correspondingly diagnose individual actions against such a characterization. Here we consider a family of combinatorial games, arising from work of Erdos, Selfridge, and Spencer, and we propose their use as environments for evaluating and comparing different approaches to reinforcement learning. These games have a number of appealing features: they are challenging for current learning approaches, but they form (i) a low-dimensional, simply parametrized environment where (ii) there is a linear closed form solution for optimal behavior from any state, and (iii) the difficulty of the game can be tuned by changing environment parameters in an interpretable way. We use these Erdos-Selfridge-Spencer games not only to compare different algorithms, but also to compare approaches based on supervised and reinforcement learning, to analyze the power of multi-agent approaches in improving performance, and to evaluate generalization to environments outside the training set.

##### Abstract (translated by Google)
深入强化学习取得了许多最近的成功，但是我们对其优势和局限性的理解受到缺乏丰富的环境的影响，在这些环境中我们可以充分表征最佳行为，并相应地诊断针对这种表征的个体行为。在这里，我们考虑一个由Erdos，Selfridge和Spencer的作品产生的组合游戏家庭，我们提出他们作为环境来评估和比较不同的强化学习方法。这些游戏具有许多吸引人的特征：它们对当前的学习方法具有挑战性，但它们形成（i）低维，简单的参数化环境，其中（ii）存在用于来自任何状态的最优行为的线性封闭形式解， （iii）可以通过以可解释的方式改变环境参数来调整游戏的难度。我们使用这些Erdos-Selfridge-Spencer游戏不仅比较了不同的算法，而且还比较了基于监督和强化学习的方法，分析了多智能体方法提高性能的能力，并评估了对训练之外环境的泛化组。

##### URL
[http://arxiv.org/abs/1711.02301](http://arxiv.org/abs/1711.02301)

##### PDF
[http://arxiv.org/pdf/1711.02301](http://arxiv.org/pdf/1711.02301)

