---
layout: post
title: "Deep Double Sparsity Encoder: Learning to Sparsify Not Only Features But Also Parameters"
date: 2016-10-02 03:01:51
categories: arXiv_CV
tags: arXiv_CV
author: Zhangyang Wang, Thomas S. Huang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper emphasizes the significance to jointly exploit the problem structure and the parameter structure, in the context of deep modeling. As a specific and interesting example, we describe the deep double sparsity encoder (DDSE), which is inspired by the double sparsity model for dictionary learning. DDSE simultaneously sparsities the output features and the learned model parameters, under one unified framework. In addition to its intuitive model interpretation, DDSE also possesses compact model size and low complexity. Extensive simulations compare DDSE with several carefully-designed baselines, and verify the consistently superior performance of DDSE. We further apply DDSE to the novel application domain of brain encoding, with promising preliminary results achieved.

##### Abstract (translated by Google)
本文强调在深度建模的背景下共同开发问题结构和参数结构的意义。作为一个具体而有趣的例子，我们描述了深度双稀疏编码器（DDSE），它受双重稀疏模型的启发。 DDSE在统一的框架下同时稀疏输出特征和学习模型参数。除了直观的模型解释外，DDSE还具有紧凑的模型尺寸和低复杂度。大量的仿真比较了DDSE和几个精心设计的基线，并验证了DDSE一贯优越的性能。我们进一步将DDSE应用于脑部编码的新颖应用领域，取得了有希望的初步成果。

##### URL
[https://arxiv.org/abs/1608.06374](https://arxiv.org/abs/1608.06374)

##### PDF
[https://arxiv.org/pdf/1608.06374](https://arxiv.org/pdf/1608.06374)

