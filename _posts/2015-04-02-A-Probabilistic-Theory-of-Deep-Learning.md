---
layout: post
title: "A Probabilistic Theory of Deep Learning"
date: 2015-04-02 18:38:38
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition CNN Inference Deep_Learning Recognition
author: Ankit B. Patel, Tan Nguyen, Richard G. Baraniuk
mathjax: true
---

* content
{:toc}

##### Abstract
A grand challenge in machine learning is the development of computational algorithms that match or outperform humans in perceptual inference tasks that are complicated by nuisance variation. For instance, visual object recognition involves the unknown object position, orientation, and scale in object recognition while speech recognition involves the unknown voice pronunciation, pitch, and speed. Recently, a new breed of deep learning algorithms have emerged for high-nuisance inference tasks that routinely yield pattern recognition systems with near- or super-human capabilities. But a fundamental question remains: Why do they work? Intuitions abound, but a coherent framework for understanding, analyzing, and synthesizing deep learning architectures has remained elusive. We answer this question by developing a new probabilistic framework for deep learning based on the Deep Rendering Model: a generative probabilistic model that explicitly captures latent nuisance variation. By relaxing the generative model to a discriminative one, we can recover two of the current leading deep learning systems, deep convolutional neural networks and random decision forests, providing insights into their successes and shortcomings, as well as a principled route to their improvement.

##### Abstract (translated by Google)
在机器学习方面的一个巨大挑战是计算算法的发展，这些计算算法在由于滋扰变化而变得复杂的知觉推理任务中匹配或优于人类。例如，视觉对象识别涉及对象识别中的未知对象位置，方向和尺度，而语音识别涉及未知的声音发音，音调和速度。最近出现了一种新的深度学习算法，用于高滋扰推理任务，这些任务通常产生具有接近或超人类能力的模式识别系统。但是一个根本性的问题仍然是：为什么他们工作？直觉比比皆是，但理解，分析和综合深度学习架构的一致框架仍然难以捉摸。我们通过开发一个基于Deep Rendering模型的深度学习的概率框架来回答这个问题：一个明确地捕捉潜在滋扰变异的生成概率模型。通过将生成模型放松到一个有区别的模型，我们可以恢复当前领先的深度学习系统，深度卷积神经网络和随机决策森林中的两个，从而为他们的成功和不足提供见解，并为他们的改进提供一条原则性的途径。

##### URL
[https://arxiv.org/abs/1504.00641](https://arxiv.org/abs/1504.00641)

##### PDF
[https://arxiv.org/pdf/1504.00641](https://arxiv.org/pdf/1504.00641)

