---
layout: post
title: "Sparse Activity and Sparse Connectivity in Supervised Learning"
date: 2016-03-28 12:06:49
categories: arXiv_CV
tags: arXiv_CV Sparse Classification
author: Markus Thom, Günther Palm
mathjax: true
---

* content
{:toc}

##### Abstract
Sparseness is a useful regularizer for learning in a wide range of applications, in particular in neural networks. This paper proposes a model targeted at classification tasks, where sparse activity and sparse connectivity are used to enhance classification capabilities. The tool for achieving this is a sparseness-enforcing projection operator which finds the closest vector with a pre-defined sparseness for any given vector. In the theoretical part of this paper, a comprehensive theory for such a projection is developed. In conclusion, it is shown that the projection is differentiable almost everywhere and can thus be implemented as a smooth neuronal transfer function. The entire model can hence be tuned end-to-end using gradient-based methods. Experiments on the MNIST database of handwritten digits show that classification performance can be boosted by sparse activity or sparse connectivity. With a combination of both, performance can be significantly better compared to classical non-sparse approaches.

##### Abstract (translated by Google)
稀疏是在广泛的应用中学习的有用的正规化器，特别是在神经网络中。本文提出了一个针对分类任务的模型，其中使用稀疏活动和稀疏连通性来提高分类能力。实现这一点的工具是一个稀疏执行投影算子，它为任何给定的矢量找到具有预定义稀疏度的最接近的矢量。在本文的理论部分，一个全面的理论这样的投影开发。总之，表明投影几乎在任何地方都是可微的，因此可以实现为平滑的神经元传递函数。因此整个模型可以使用基于梯度的方法进行端到端的调整。在手写数字MNIST数据库上的实验表明，分类性能可以通过稀疏活动或稀疏连接提高。结合两者，与传统的非稀疏方法相比，性能可以显着提高。

##### URL
[https://arxiv.org/abs/1603.08367](https://arxiv.org/abs/1603.08367)

##### PDF
[https://arxiv.org/pdf/1603.08367](https://arxiv.org/pdf/1603.08367)

