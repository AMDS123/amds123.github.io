---
layout: post
title: "Investigating Biases in Textual Entailment Datasets"
date: 2019-06-23 19:38:53
categories: arXiv_CL
tags: arXiv_CL QA Classification Relation VQA
author: Shawn Tan, Yikang Shen, Chin-wei Huang, Aaron Courville
mathjax: true
---

* content
{:toc}

##### Abstract
The ability to understand logical relationships between sentences is an important task in language understanding. To aid in progress for this task, researchers have collected datasets for machine learning and evaluation of current systems. However, like in the crowdsourced Visual Question Answering (VQA) task, some biases in the data inevitably occur. In our experiments, we find that performing classification on just the hypotheses on the SNLI dataset yields an accuracy of 64%. We analyze the bias extent in the SNLI and the MultiNLI dataset, discuss its implication, and propose a simple method to reduce the biases in the datasets.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.09635](http://arxiv.org/abs/1906.09635)

##### PDF
[http://arxiv.org/pdf/1906.09635](http://arxiv.org/pdf/1906.09635)

