---
layout: post
title: "Multi-Task Cross-Lingual Sequence Tagging from Scratch"
date: 2016-08-09 15:07:39
categories: arXiv_SD
tags: arXiv_SD
author: Zhilin Yang, Ruslan Salakhutdinov, William Cohen
mathjax: true
---

* content
{:toc}

##### Abstract
We present a deep hierarchical recurrent neural network for sequence tagging. Given a sequence of words, our model employs deep gated recurrent units on both character and word levels to encode morphology and context information, and applies a conditional random field layer to predict the tags. Our model is task independent, language independent, and feature engineering free. We further extend our model to multi-task and cross-lingual joint training by sharing the architecture and parameters. Our model achieves state-of-the-art results in multiple languages on several benchmark tasks including POS tagging, chunking, and NER. We also demonstrate that multi-task and cross-lingual joint training can improve the performance in various cases.

##### Abstract (translated by Google)
我们提出了一个深层次递归神经网络序列标签。给定一个单词序列，我们的模型在字符和词水平都采用深门控循环单元来编码形态和上下文信息，并应用条件随机场层来预测标签。我们的模型是任务独立的，语言独立的，并且免费提供特征工程通过共享体系结构和参数，我们进一步将模型扩展到多任务和跨语言的联合训练。我们的模型在多种基准任务（包括POS标记，分块和NER）上实现了多种语言的最新结果。我们还表明，多任务和跨语言联合训练可以提高各种情况下的表现。

##### URL
[https://arxiv.org/abs/1603.06270](https://arxiv.org/abs/1603.06270)

##### PDF
[https://arxiv.org/pdf/1603.06270](https://arxiv.org/pdf/1603.06270)

