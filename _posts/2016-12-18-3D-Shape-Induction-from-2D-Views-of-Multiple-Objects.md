---
layout: post
title: "3D Shape Induction from 2D Views of Multiple Objects"
date: 2016-12-18 08:44:00
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Matheus Gadelha, Subhransu Maji, Rui Wang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we investigate the problem of inducing a distribution over three-dimensional structures given two-dimensional views of multiple objects taken from unknown viewpoints. Our approach called "projective generative adversarial networks" (PrGANs) trains a deep generative model of 3D shapes whose projections match the distributions of the input 2D views. The addition of a projection module allows us to infer the underlying 3D shape distribution without using any 3D, viewpoint information, or annotation during the learning phase. We show that our approach produces 3D shapes of comparable quality to GANs trained on 3D data for a number of shape categories including chairs, airplanes, and cars. Experiments also show that the disentangled representation of 2D shapes into geometry and viewpoint leads to a good generative model of 2D shapes. The key advantage is that our model allows us to predict 3D, viewpoint, and generate novel views from an input image in a completely unsupervised manner.

##### Abstract (translated by Google)
在本文中，我们研究了在给定来自未知视点的多个对象的二维视图的情况下引起三维结构上的分布的问题。我们称之为“投影生成对抗网络”（PrGANs）的方法训练了一种3D形状的深层生成模型，其投影与输入2D视图的分布相匹配。投影模块的添加使我们能够在学习阶段不使用任何3D视点信息或注释来推断潜在的3D形状分布。我们展示了我们的方法产生了与3D数据训练的GAN类似的质量可比的3D形状，用于许多形状类别，包括椅子，飞机和汽车。实验还表明，将二维形状解构成几何和视点的解题导致了二维形状的良好生成模型。关键优势在于，我们的模型使我们能够以完全无监督的方式预测3D，视点，并从输入图像中生成新的视图。

##### URL
[https://arxiv.org/abs/1612.05872](https://arxiv.org/abs/1612.05872)

##### PDF
[https://arxiv.org/pdf/1612.05872](https://arxiv.org/pdf/1612.05872)

