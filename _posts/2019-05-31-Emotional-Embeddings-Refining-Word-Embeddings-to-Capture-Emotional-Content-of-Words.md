---
layout: post
title: "Emotional Embeddings: Refining Word Embeddings to Capture Emotional Content of Words"
date: 2019-05-31 22:46:03
categories: arXiv_CL
tags: arXiv_CL Embedding Language_Model Detection
author: Armin Seyeditabari, Narges Tabari, Shafie Gholizadeh, Wlodek Zadrozny
mathjax: true
---

* content
{:toc}

##### Abstract
Word embeddings are one of the most useful tools in any modern natural language processing expert's toolkit. They contain various types of information about each word which makes them the best way to represent the terms in any NLP task. But there are some types of information that cannot be learned by these models. Emotional information of words are one of those. In this paper, we present an approach to incorporate emotional information of words into these models. We accomplish this by adding a secondary training stage which uses an emotional lexicon and a psychological model of basic emotions. We show that fitting an emotional model into pre-trained word vectors can increase the performance of these models in emotional similarity metrics. Retrained models perform better than their original counterparts from 13% improvement for Word2Vec model, to 29% for GloVe vectors. This is the first such model presented in the literature, and although preliminary, these emotion sensitive models can open the way to increase performance in variety of emotion detection techniques.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.00112](http://arxiv.org/abs/1906.00112)

##### PDF
[http://arxiv.org/pdf/1906.00112](http://arxiv.org/pdf/1906.00112)

