---
layout: post
title: "A Unified Deep Learning Architecture for Abuse Detection"
date: 2018-02-01 16:48:39
categories: arXiv_CL
tags: arXiv_CL Face Deep_Learning Detection
author: Antigoni-Maria Founta, Despoina Chatzakou, Nicolas Kourtellis, Jeremy Blackburn, Athena Vakali, Ilias Leontiadis
mathjax: true
---

* content
{:toc}

##### Abstract
Hate speech, offensive language, sexism, racism and other types of abusive behavior have become a common phenomenon in many online social media platforms. In recent years, such diverse abusive behaviors have been manifesting with increased frequency and levels of intensity. This is due to the openness and willingness of popular media platforms, such as Twitter and Facebook, to host content of sensitive or controversial topics. However, these platforms have not adequately addressed the problem of online abusive behavior, and their responsiveness to the effective detection and blocking of such inappropriate behavior remains limited. 
 In the present paper, we study this complex problem by following a more holistic approach, which considers the various aspects of abusive behavior. To make the approach tangible, we focus on Twitter data and analyze user and textual properties from different angles of abusive posting behavior. We propose a deep learning architecture, which utilizes a wide variety of available metadata, and combines it with automatically-extracted hidden patterns within the text of the tweets, to detect multiple abusive behavioral norms which are highly inter-related. We apply this unified architecture in a seamless, transparent fashion to detect different types of abusive behavior (hate speech, sexism vs. racism, bullying, sarcasm, etc.) without the need for any tuning of the model architecture for each task. We test the proposed approach with multiple datasets addressing different and multiple abusive behaviors on Twitter. Our results demonstrate that it largely outperforms the state-of-art methods (between 21 and 45\% improvement in AUC, depending on the dataset).

##### Abstract (translated by Google)
仇恨言论，冒犯性语言，性别歧视，种族主义等各种滥用行为已成为许多网络社交媒体平台的普遍现象。近年来，这种多样化的虐待行为已经显现出来，并且频率和程度越来越高。这是由于流行的媒体平台（如Twitter和Facebook）的开放性和意愿，以容纳敏感或有争议话题的内容。然而，这些平台并没有充分解决在线滥用行为的问题，而且对这种不当行为的有效发现和阻断的响应仍然有限。
 在本文中，我们通过更全面的方法来研究这个复杂的问题，它考虑了滥用行为的各个方面。为了使这种方法更加有形，我们专注于Twitter数据，并从不同角度对滥用发布行为进行用户和文本属性分析。我们提出了一个深度学习架构，它利用了各种可用的元数据，并将其与自动提取的隐藏模式结合起来，以检测多个互相关联的滥用行为准则。我们以无缝，透明的方式运用这个统一架构来检测不同类型的虐待行为（仇恨言论，性别歧视，种族歧视，欺凌，讽刺等），而不需要为每个任务调整模型架构。我们使用多个数据集对Twitter上的不同和多个滥用行为进行测试。我们的研究结果表明，它在很大程度上优于最先进的方法（根据数据集的不同，AUC的改善在21％和45％之间）。

##### URL
[http://arxiv.org/abs/1802.00385](http://arxiv.org/abs/1802.00385)

##### PDF
[http://arxiv.org/pdf/1802.00385](http://arxiv.org/pdf/1802.00385)

