---
layout: post
title: "Aequitas: A Bias and Fairness Audit Toolkit"
date: 2019-04-29 16:28:23
categories: arXiv_AI
tags: arXiv_AI Relation
author: Pedro Saleiro, Benedict Kuester, Loren Hinkson, Jesse London, Abby Stevens, Ari Anisfeld, Kit T. Rodolfa, Rayid Ghani
mathjax: true
---

* content
{:toc}

##### Abstract
Recent work has raised concerns on the risk of unintended bias in AI systems being used nowadays that can affect individuals unfairly based on race, gender or religion, among other possible characteristics. While a lot of bias metrics and fairness definitions have been proposed in recent years, there is no consensus on which metric/definition should be used and there are very few available resources to operationalize them. Therefore, despite recent awareness, auditing for bias and fairness when developing and deploying AI systems is not yet a standard practice. We present Aequitas, an open source bias and fairness audit toolkit that is an intuitive and easy to use addition to the machine learning workflow, enabling users to seamlessly test models for several bias and fairness metrics in relation to multiple population sub-groups. Aequitas facilitates informed and equitable decisions around developing and deploying algorithmic decision making systems for both data scientists, machine learning researchers and policymakers.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.05577](http://arxiv.org/abs/1811.05577)

##### PDF
[http://arxiv.org/pdf/1811.05577](http://arxiv.org/pdf/1811.05577)

