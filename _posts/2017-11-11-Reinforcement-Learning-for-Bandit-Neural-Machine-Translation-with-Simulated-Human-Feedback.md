---
layout: post
title: "Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback"
date: 2017-11-11 05:01:23
categories: arXiv_CL
tags: arXiv_CL Attention Reinforcement_Learning
author: Khanh Nguyen, Hal Daumé III, Jordan Boyd-Graber
mathjax: true
---

* content
{:toc}

##### Abstract
Machine translation is a natural candidate problem for reinforcement learning from human feedback: users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training focuses on expensive human-generated reference translations. We describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback. Our algorithm combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This algorithm (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors.

##### Abstract (translated by Google)
机器翻译是从人类反馈强化学习的一个自然的候选问题：用户提供候选翻译的快速，肮脏的评级，以指导系统改善。然而，目前的神经机器翻译培训重点是昂贵的人工参考翻译。我们描述了一个强化学习算法，改善了神经机器翻译系统模拟人的反馈。我们的算法结合了基于注意力的神经编码器 - 解码器架构（Luong et al。，2015）的优势actor-critic算法（Mnih et al。，2016）。 （a）针对动作空间大和奖励延迟的问题进行了很好的设计，（b）有效地优化了传统的语料库级机器翻译指标，（c）对模型化后的偏斜，高方差，实际的人类行为。

##### URL
[https://arxiv.org/abs/1707.07402](https://arxiv.org/abs/1707.07402)

##### PDF
[https://arxiv.org/pdf/1707.07402](https://arxiv.org/pdf/1707.07402)

