---
layout: post
title: "ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs"
date: 2018-06-25 13:31:07
categories: arXiv_CL
tags: arXiv_CL Attention CNN
author: Wenpeng Yin, Hinrich Sch&#xfc;tze, Bing Xiang, Bowen Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
How to model a pair of sentences is a critical issue in many NLP tasks such as answer selection (AS), paraphrase identification (PI) and textual entailment (TE). Most prior work (i) deals with one individual task by fine-tuning a specific system; (ii) models each sentence's representation separately, rarely considering the impact of the other sentence; or (iii) relies fully on manually designed, task-specific linguistic features. This work presents a general Attention Based Convolutional Neural Network (ABCNN) for modeling a pair of sentences. We make three contributions. (i) ABCNN can be applied to a wide variety of tasks that require modeling of sentence pairs. (ii) We propose three attention schemes that integrate mutual influence between sentences into CNN; thus, the representation of each sentence takes into consideration its counterpart. These interdependent sentence pair representations are more powerful than isolated sentence representations. (iii) ABCNN achieves state-of-the-art performance on AS, PI and TE tasks.

##### Abstract (translated by Google)
如何建模一对句子是许多NLP任务中的关键问题，如答案选择（AS），释义识别（PI）和文本包含（TE）。大多数先前的工作（i）通过微调特定系统来处理一项个人任务; （ii）分别模拟每个句子的表述，很少考虑另一句话的影响;或（iii）完全依赖手动设计的特定于任务的语言功能。这项工作提出了一个基于注意的卷积神经网络（ABCNN）来建模一对句子。我们做了三个贡献。 （i）ABCNN可以应用于需要对句子对建模的各种任务。 （ii）我们提出三种注意方案，将句子之间的相互影响整合到CNN中;因此，每个句子的表述都考虑到其对应物。这些相互依存的句对表示比单独的句子表示更有效。 （iii）ABCNN在AS，PI和TE任务上实现了最先进的性能。

##### URL
[http://arxiv.org/abs/1512.05193](http://arxiv.org/abs/1512.05193)

##### PDF
[http://arxiv.org/pdf/1512.05193](http://arxiv.org/pdf/1512.05193)

