---
layout: post
title: "Attention-Based LSTM for Psychological Stress Detection from Spoken Language Using Distant Supervision"
date: 2018-05-31 03:27:53
categories: arXiv_CL
tags: arXiv_CL Attention RNN Detection
author: Genta Indra Winata, Onno Pepijn Kampman, Pascale Fung
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a Long Short-Term Memory (LSTM) with attention mechanism to classify psychological stress from self-conducted interview transcriptions. We apply distant supervision by automatically labeling tweets based on their hashtag content, which complements and expands the size of our corpus. This additional data is used to initialize the model parameters, and which it is fine-tuned using the interview data. This improves the model's robustness, especially by expanding the vocabulary size. The bidirectional LSTM model with attention is found to be the best model in terms of accuracy (74.1%) and f-score (74.3%). Furthermore, we show that distant supervision fine-tuning enhances the model's performance by 1.6% accuracy and 2.1% f-score. The attention mechanism helps the model to select informative words.

##### Abstract (translated by Google)
我们提出了一种具有注意机制的长时间短记忆（LSTM），用于从自我采访转录中分类心理压力。我们会根据自己的主题标签内容自动标注推文，从而实施远程监督，这样可以补充并扩展我们的语料库的大小。这些附加数据用于初始化模型参数，以及使用面试数据对其进行微调。这提高了模型的鲁棒性，尤其是通过扩大词汇量。注意力的双向LSTM模型在准确性（74.1％）和f评分（74.3％）方面被认为是最好的模型。此外，我们显示远程监督微调将模型的表现提高了1.6％的准确性和2.1％的f分数。注意机制有助于模型选择信息性词语。

##### URL
[http://arxiv.org/abs/1805.12307](http://arxiv.org/abs/1805.12307)

##### PDF
[http://arxiv.org/pdf/1805.12307](http://arxiv.org/pdf/1805.12307)

