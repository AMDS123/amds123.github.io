---
layout: post
title: "Aspect Level Sentiment Classification with Deep Memory Network"
date: 2016-09-24 06:04:15
categories: arXiv_CV
tags: arXiv_CV Sentiment Attention Sentiment_Classification RNN Classification
author: Duyu Tang, Bing Qin, Ting Liu
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a deep memory network for aspect level sentiment classification. Unlike feature-based SVM and sequential neural models such as LSTM, this approach explicitly captures the importance of each context word when inferring the sentiment polarity of an aspect. Such importance degree and text representation are calculated with multiple computational layers, each of which is a neural attention model over an external memory. Experiments on laptop and restaurant datasets demonstrate that our approach performs comparable to state-of-art feature based SVM system, and substantially better than LSTM and attention-based LSTM architectures. On both datasets we show that multiple computational layers could improve the performance. Moreover, our approach is also fast. The deep memory network with 9 layers is 15 times faster than LSTM with a CPU implementation.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1605.08900](https://arxiv.org/abs/1605.08900)

##### PDF
[https://arxiv.org/pdf/1605.08900](https://arxiv.org/pdf/1605.08900)

