---
layout: post
title: "Aspect Level Sentiment Classification with Deep Memory Network"
date: 2016-09-24 06:04:15
categories: arXiv_CV
tags: arXiv_CV Sentiment Attention Sentiment_Classification RNN Classification
author: Duyu Tang, Bing Qin, Ting Liu
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a deep memory network for aspect level sentiment classification. Unlike feature-based SVM and sequential neural models such as LSTM, this approach explicitly captures the importance of each context word when inferring the sentiment polarity of an aspect. Such importance degree and text representation are calculated with multiple computational layers, each of which is a neural attention model over an external memory. Experiments on laptop and restaurant datasets demonstrate that our approach performs comparable to state-of-art feature based SVM system, and substantially better than LSTM and attention-based LSTM architectures. On both datasets we show that multiple computational layers could improve the performance. Moreover, our approach is also fast. The deep memory network with 9 layers is 15 times faster than LSTM with a CPU implementation.

##### Abstract (translated by Google)
我们引入一个深度内存网络来进行方面层面的情感分类。与基于特征的SVM和顺序神经模型（如LSTM）不同，这种方法在推断某个方面的情感极性时明确地捕获了每个上下文单词的重要性。这种重要程度和文本表示是用多个计算层来计算的，每个计算层都是外部存储器上的神经关注模型。笔记本电脑和餐厅数据集上的实验表明，我们的方法可以与基于先进特征的SVM系统进行比较，并且比LSTM和基于注意力的LSTM架构更好。在这两个数据集上，我们显示多个计算层可以提高性能。而且，我们的方法也很快。具有9层的深存储网络比CPU实现的LSTM快15倍。

##### URL
[https://arxiv.org/abs/1605.08900](https://arxiv.org/abs/1605.08900)

##### PDF
[https://arxiv.org/pdf/1605.08900](https://arxiv.org/pdf/1605.08900)

