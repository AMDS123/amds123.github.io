---
layout: post
title: "Generalization and Equilibrium in Generative Adversarial Nets"
date: 2017-08-01 19:51:56
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, Yi Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
We show that training of generative adversarial network (GAN) may not have good generalization properties; e.g., training may appear successful but the trained distribution may be far from target distribution in standard metrics. However, generalization does occur for a weaker metric called neural net distance. It is also shown that an approximate pure equilibrium exists in the discriminator/generator game for a special class of generators with natural training objectives when generator capacity and training set sizes are moderate. This existence of equilibrium inspires MIX+GAN protocol, which can be combined with any existing GAN training, and empirically shown to improve some of them.

##### Abstract (translated by Google)
我们证明生成对抗网络（GAN）的训练可能不具有良好的泛化特性;例如，训练可能看起来成功，但是训练的分布可能远离标准度量中的目标分布。然而，泛化确实发生在称为神经网络距离的较弱指标上。同时还表明，在发电机容量和训练集大小适中的情况下，对于具有自然训练目标的特殊类别发电机，鉴别器/发电机博弈中存在近似纯平衡。这种均衡的存在激发了MIX + GAN协议，它可以与任何现有的GAN训练相结合，并通过实证来改进其中的一些。

##### URL
[https://arxiv.org/abs/1703.00573](https://arxiv.org/abs/1703.00573)

##### PDF
[https://arxiv.org/pdf/1703.00573](https://arxiv.org/pdf/1703.00573)

