---
layout: post
title: "Show, Translate and Tell"
date: 2019-03-14 21:50:09
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption Embedding
author: Dheeraj Peri, Shagan Sah, Raymond Ptucha
mathjax: true
---

* content
{:toc}

##### Abstract
Humans have an incredible ability to process and understand information from multiple sources such as images, video, text, and speech. Recent success of deep neural networks has enabled us to develop algorithms which give machines the ability to understand and interpret this information. There is a need to both broaden their applicability and develop methods which correlate visual information along with semantic content. We propose a unified model which jointly trains on images and captions, and learns to generate new captions given either an image or a caption query. We evaluate our model on three different tasks namely cross-modal retrieval, image captioning, and sentence paraphrasing. Our model gains insight into cross-modal vector embeddings, generalizes well on multiple tasks and is competitive to state of the art methods on retrieval.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.06275](http://arxiv.org/abs/1903.06275)

##### PDF
[http://arxiv.org/pdf/1903.06275](http://arxiv.org/pdf/1903.06275)

