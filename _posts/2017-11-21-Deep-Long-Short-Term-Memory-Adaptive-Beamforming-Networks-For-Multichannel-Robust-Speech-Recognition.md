---
layout: post
title: "Deep Long Short-Term Memory Adaptive Beamforming Networks For Multichannel Robust Speech Recognition"
date: 2017-11-21 20:03:03
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition RNN Deep_Learning Recognition
author: Zhong Meng, Shinji Watanabe, John R. Hershey, Hakan Erdogan
mathjax: true
---

* content
{:toc}

##### Abstract
Far-field speech recognition in noisy and reverberant conditions remains a challenging problem despite recent deep learning breakthroughs. This problem is commonly addressed by acquiring a speech signal from multiple microphones and performing beamforming over them. In this paper, we propose to use a recurrent neural network with long short-term memory (LSTM) architecture to adaptively estimate real-time beamforming filter coefficients to cope with non-stationary environmental noise and dynamic nature of source and microphones positions which results in a set of timevarying room impulse responses. The LSTM adaptive beamformer is jointly trained with a deep LSTM acoustic model to predict senone labels. Further, we use hidden units in the deep LSTM acoustic model to assist in predicting the beamforming filter coefficients. The proposed system achieves 7.97% absolute gain over baseline systems with no beamforming on CHiME-3 real evaluation set.

##### Abstract (translated by Google)
嘈杂和混响条件下的远场语音识别仍然是一个具有挑战性的问题，尽管最近有深刻的学习突破。这个问题通常通过从多个麦克风获取语音信号并在其上执行波束形成来解决。在本文中，我们建议使用具有长时间短期记忆（LSTM）结构的递归神经网络来自适应地估计实时波束形成滤波器系数以应对非静止的环境噪声以及源和麦克风位置的动态性质，一组时间变化的房间冲动响应。 LSTM自适应波束形成器通过深度LSTM声学模型进行联合训练，以预测语音标签。此外，我们在深LSTM声学模型中使用隐藏单元来辅助预测波束形成滤波器系数。所提出的系统在CHiME-3真实评估集上没有波束成形的基线系统上获得了7.97％的绝对增益。

##### URL
[https://arxiv.org/abs/1711.08016](https://arxiv.org/abs/1711.08016)

##### PDF
[https://arxiv.org/pdf/1711.08016](https://arxiv.org/pdf/1711.08016)

