---
layout: post
title: "Two-Stream 3D Convolutional Neural Network for Skeleton-Based Action Recognition"
date: 2017-06-07 11:23:40
categories: arXiv_CV
tags: arXiv_CV Knowledge Action_Recognition CNN RNN Relation Recognition
author: Hong Liu, Juanhui Tu, Mengyuan Liu
mathjax: true
---

* content
{:toc}

##### Abstract
It remains a challenge to efficiently extract spatialtemporal information from skeleton sequences for 3D human action recognition. Although most recent action recognition methods are based on Recurrent Neural Networks which present outstanding performance, one of the shortcomings of these methods is the tendency to overemphasize the temporal information. Since 3D convolutional neural network(3D CNN) is a powerful tool to simultaneously learn features from both spatial and temporal dimensions through capturing the correlations between three dimensional signals, this paper proposes a novel two-stream model using 3D CNN. To our best knowledge, this is the first application of 3D CNN in skeleton-based action recognition. Our method consists of three stages. First, skeleton joints are mapped into a 3D coordinate space and then encoding the spatial and temporal information, respectively. Second, 3D CNN models are seperately adopted to extract deep features from two streams. Third, to enhance the ability of deep features to capture global relationships, we extend every stream into multitemporal version. Extensive experiments on the SmartHome dataset and the large-scale NTU RGB-D dataset demonstrate that our method outperforms most of RNN-based methods, which verify the complementary property between spatial and temporal information and the robustness to noise.

##### Abstract (translated by Google)
从三维人体动作识别的骨架序列中有效地提取空间时间信息仍然是一个挑战。尽管最近的动作识别方法是基于递归神经网络，其表现出色，但这些方法的缺点之一是过分强调时间信息的倾向。由于三维卷积神经网络（3D CNN）是一种通过捕捉三维信号之间的相关性同时学习空间和时间维度特征的强大工具，本文提出了一种使用3D CNN的新型双流模型。据我们所知，这是3D CNN在骨骼动作识别中的首次应用。我们的方法由三个阶段组成。首先，将骨架关节映射到三维坐标空间，然后分别对空间和时间信息进行编码。其次，分别采用3D CNN模型从两个流提取深度特征。第三，为了增强捕捉全局关系的深层特征的能力，我们将每个流扩展到多时间版本。在SmartHome数据集和大规模NTU RGB-D数据集上的大量实验表明，我们的方法胜过了大多数基于RNN的方法，这些方法验证了时空信息的互补性和噪声的鲁棒性。

##### URL
[https://arxiv.org/abs/1705.08106](https://arxiv.org/abs/1705.08106)

##### PDF
[https://arxiv.org/pdf/1705.08106](https://arxiv.org/pdf/1705.08106)

