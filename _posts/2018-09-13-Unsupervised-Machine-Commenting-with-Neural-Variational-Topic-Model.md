---
layout: post
title: "Unsupervised Machine Commenting with Neural Variational Topic Model"
date: 2018-09-13 13:48:42
categories: arXiv_CL
tags: arXiv_CL
author: Shuming Ma, Lei Cui, Furu Wei, Xu Sun
mathjax: true
---

* content
{:toc}

##### Abstract
Article comments can provide supplementary opinions and facts for readers, thereby increase the attraction and engagement of articles. Therefore, automatically commenting is helpful in improving the activeness of the community, such as online forums and news websites. Previous work shows that training an automatic commenting system requires large parallel corpora. Although part of articles are naturally paired with the comments on some websites, most articles and comments are unpaired on the Internet. To fully exploit the unpaired data, we completely remove the need for parallel data and propose a novel unsupervised approach to train an automatic article commenting model, relying on nothing but unpaired articles and comments. Our model is based on a retrieval-based commenting framework, which uses news to retrieve comments based on the similarity of their topics. The topic representation is obtained from a neural variational topic model, which is trained in an unsupervised manner. We evaluate our model on a news comment dataset. Experiments show that our proposed topic-based approach significantly outperforms previous lexicon-based models. The model also profits from paired corpora and achieves state-of-the-art performance under semi-supervised scenarios.

##### Abstract (translated by Google)
文章评论可以为读者提供补充意见和事实，从而增加文章的吸引力和参与度。因此，自动评论有助于提高社区的活跃度，例如在线论坛和新闻网站。以前的工作表明，培训自动评论系统需要大型并行语料库。虽然部分文章自然与某些网站上的评论配对，但大多数文章和评论在互联网上都是不配对的。为了充分利用不成对数据，我们完全消除了对并行数据的需求，并提出了一种新的无监督方法来训练自动文章评论模型，仅依赖于不成对的文章和评论。我们的模型基于基于检索的评论框架，该框架使用新闻根据主题的相似性检索评论。主题表示是从神经变分主题模型获得的，该模型以无人监督的方式训练。我们在新闻评论数据集上评估我们的模型。实验表明，我们提出的基于主题的方法明显优于以前的基于词典的模型。该模型还从配对的语料库中获利，并在半监督情景下实现了最先进的性能。

##### URL
[http://arxiv.org/abs/1809.04960](http://arxiv.org/abs/1809.04960)

##### PDF
[http://arxiv.org/pdf/1809.04960](http://arxiv.org/pdf/1809.04960)

