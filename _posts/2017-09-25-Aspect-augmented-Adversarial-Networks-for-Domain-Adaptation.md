---
layout: post
title: "Aspect-augmented Adversarial Networks for Domain Adaptation"
date: 2017-09-25 03:36:05
categories: arXiv_SD
tags: arXiv_SD Review Adversarial Transfer_Learning Classification
author: Yuan Zhang, Regina Barzilay, Tommi Jaakkola
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a neural method for transfer learning between two (source and target) classification tasks or aspects over the same domain. Rather than training on target labels, we use a few keywords pertaining to source and target aspects indicating sentence relevance instead of document class labels. Documents are encoded by learning to embed and softly select relevant sentences in an aspect-dependent manner. A shared classifier is trained on the source encoded documents and labels, and applied to target encoded documents. We ensure transfer through aspect-adversarial training so that encoded documents are, as sets, aspect-invariant. Experimental results demonstrate that our approach outperforms different baselines and model variants on two datasets, yielding an improvement of 27% on a pathology dataset and 5% on a review dataset.

##### Abstract (translated by Google)
我们介绍了两个（源和目标）分类任务之间的转移学习的神经方法或方面在相同的领域。我们不使用目标标签进行培训，而是使用与源和目标方面有关的几个关键字来指示句子相关性，而不是文档类标签。通过学习嵌入和轻松选择相关句子，文档被编码。在源编码的文档和标签上训练共享分类器，并将其应用于目标编码的文档。我们通过纵横对抗训练来确保传输，以便编码文档作为集合不变。实验结果表明，我们的方法优于两个数据集上的不同基线和模型变体，在病理数据集上得到27％的改善，在评论数据集上得到5％的改善。

##### URL
[https://arxiv.org/abs/1701.00188](https://arxiv.org/abs/1701.00188)

##### PDF
[https://arxiv.org/pdf/1701.00188](https://arxiv.org/pdf/1701.00188)

