---
layout: post
title: "Design Automation for Binarized Neural Networks: A Quantum Leap Opportunity?"
date: 2017-11-21 09:54:37
categories: arXiv_CV
tags: arXiv_CV Deep_Learning
author: Manuele Rusci, Lukas Cavigelli, Luca Benini
mathjax: true
---

* content
{:toc}

##### Abstract
Design automation in general, and in particular logic synthesis, can play a key role in enabling the design of application-specific Binarized Neural Networks (BNN). This paper presents the hardware design and synthesis of a purely combinational BNN for ultra-low power near-sensor processing. We leverage the major opportunities raised by BNN models, which consist mostly of logical bit-wise operations and integer counting and comparisons, for pushing ultra-low power deep learning circuits close to the sensor and coupling it with binarized mixed-signal image sensor data. We analyze area, power and energy metrics of BNNs synthesized as combinational networks. Our synthesis results in GlobalFoundries 22nm SOI technology shows a silicon area of 2.61mm2 for implementing a combinational BNN with 32x32 binary input sensor receptive field and weight parameters fixed at design time. This is 2.2x smaller than a synthesized network with re-configurable parameters. With respect to other comparable techniques for deep learning near-sensor processing, our approach features a 10x higher energy efficiency.

##### Abstract (translated by Google)
总的来说，设计自动化，特别是逻辑综合，可以在设计专用的二值化神经网络（BNN）方面发挥关键作用。本文介绍了一种用于超低功率近传感器处理的纯组合BNN的硬件设计和综合。我们利用BNN模型提出的主要机会，这些模型主要由逻辑按位运算和整数计数和比较组成，用于将超低功耗深度学习电路靠近传感器并与二进制混合信号图像传感器数据耦合。我们分析了作为组合网络合成的BNNs的面积，功率和能量度量。我们在GlobalFoundries 22nm SOI技术的综合结果显示，用于实现一个32x32二进制输入传感器接收场和重量参数在设计时固定的组合BNN的硅片面积为2.61平方毫米。这比具有可重新配置参数的综合网络小2.2倍。关于深度学习近似传感器处理的其他类似技术，我们的方法具有10倍的高能效。

##### URL
[http://arxiv.org/abs/1712.01743](http://arxiv.org/abs/1712.01743)

