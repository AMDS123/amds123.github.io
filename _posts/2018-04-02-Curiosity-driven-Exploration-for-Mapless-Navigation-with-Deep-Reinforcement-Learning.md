---
layout: post
title: "Curiosity-driven Exploration for Mapless Navigation with Deep Reinforcement Learning"
date: 2018-04-02 11:40:00
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Oleksii Zhelo, Jingwei Zhang, Lei Tai, Ming Liu, Wolfram Burgard
mathjax: true
---

* content
{:toc}

##### Abstract
This paper investigates exploration strategies of Deep Reinforcement Learning (DRL) methods to learn navigation policies for mobile robots. In particular, we augment the normal external reward for training DRL algorithms with intrinsic reward signals measured by curiosity. We test our approach in a mapless navigation setting, where the autonomous agent is required to navigate without the occupancy map of the environment, to targets whose relative locations can be easily acquired through low-cost solutions (e.g., visible light localization, Wi-Fi signal localization). We validate that the intrinsic motivation is crucial for improving DRL performance in tasks with challenging exploration requirements. Our experimental results show that our proposed method is able to more effectively learn navigation policies, and has better generalization capabilities in previously unseen environments. A video of our experimental results can be found at https://goo.gl/pWbpcF.

##### Abstract (translated by Google)
本文研究了Deep Reinforcement Learning（DRL）方法学习移动机器人导航策略的策略。特别是，我们通过好奇心衡量的固有奖励信号来增加训练DRL算法的正常外部奖励。我们在无人驾驶导航设置中测试我们的方法，自主驾驶员需要在没有环境占用图的情况下导航到相对位置可以通过低成本解决方案轻松获取的目标（例如可见光本地化，Wi-Fi信号定位）。我们验证内在动机对于提高具有挑战性探索需求的任务中的DRL性能至关重要。我们的实验结果表明，我们提出的方法能够更有效地学习导航策略，并且在先前看不见的环境中具有更好的泛化能力。我们的实验结果的视频可以在https://goo.gl/pWbpcF找到。

##### URL
[http://arxiv.org/abs/1804.00456](http://arxiv.org/abs/1804.00456)

##### PDF
[http://arxiv.org/pdf/1804.00456](http://arxiv.org/pdf/1804.00456)

