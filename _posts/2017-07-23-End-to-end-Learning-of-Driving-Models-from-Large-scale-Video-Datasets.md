---
layout: post
title: "End-to-end Learning of Driving Models from Large-scale Video Datasets"
date: 2017-07-23 10:10:56
categories: arXiv_CV
tags: arXiv_CV Segmentation RNN
author: Huazhe Xu, Yang Gao, Fisher Yu, Trevor Darrell
mathjax: true
---

* content
{:toc}

##### Abstract
Robust perception-action models should be learned from training data with diverse visual appearances and realistic behaviors, yet current approaches to deep visuomotor policy learning have been generally limited to in-situ models learned from a single vehicle or a simulation environment. We advocate learning a generic vehicle motion model from large scale crowd-sourced video data, and develop an end-to-end trainable architecture for learning to predict a distribution over future vehicle egomotion from instantaneous monocular camera observations and previous vehicle state. Our model incorporates a novel FCN-LSTM architecture, which can be learned from large-scale crowd-sourced vehicle action data, and leverages available scene segmentation side tasks to improve performance under a privileged learning paradigm.

##### Abstract (translated by Google)
应该从具有不同视觉外观和逼真行为的训练数据中学习鲁棒的感知行为模型，但是目前的深度视觉策略学习方法一般局限于从单一车辆或模拟环境中学习的现场模型。我们主张从大规模的人群来源的视频数据中学习一个通用的车辆运动模型，并开发一个端到端的可训练架构，用于学习从瞬时单目摄像机观测和以前的车辆状态预测未来车辆运动的分布。我们的模型融合了一种新颖的FCN-LSTM架构，可以从大规模的人群来源的车辆动作数据中学习，并且利用可用的场景分割侧面任务在特权学习范例下提高性能。

##### URL
[https://arxiv.org/abs/1612.01079](https://arxiv.org/abs/1612.01079)

##### PDF
[https://arxiv.org/pdf/1612.01079](https://arxiv.org/pdf/1612.01079)

