---
layout: post
title: "A Semantic QA-Based Approach for Text Summarization Evaluation"
date: 2017-04-21 15:32:01
categories: arXiv_CL
tags: arXiv_CL Knowledge QA Summarization
author: Ping Chen, Fei Wu, Tong Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Many Natural Language Processing and Computational Linguistics applications involves the generation of new texts based on some existing texts, such as summarization, text simplification and machine translation. However, there has been a serious problem haunting these applications for decades, that is, how to automatically and accurately assess quality of these applications. In this paper, we will present some preliminary results on one especially useful and challenging problem in NLP system evaluation: how to pinpoint content differences of two text passages (especially for large pas-sages such as articles and books). Our idea is intuitive and very different from existing approaches. We treat one text passage as a small knowledge base, and ask it a large number of questions to exhaustively identify all content points in it. By comparing the correctly answered questions from two text passages, we will be able to compare their content precisely. The experiment using 2007 DUC summarization corpus clearly shows promising results.

##### Abstract (translated by Google)
许多自然语言处理和计算语言学应用涉及基于一些现有文本（例如摘要，文本简化和机器翻译）生成新文本。然而，几十年来，这些应用一直是一个严重的问题，即如何自动，准确地评估这些应用的质量。在本文中，我们将对NLP系统评估中一个特别有用和具有挑战性的问题展示一些初步结果：如何精确定位两个文本段落的内容差异（特别是对于大型文章和书籍等）。我们的想法是直观的，与现有方法有很大的不同。我们把一个文本段落作为一个小的知识库，并且提出了大量的问题来详尽地识别其中的所有内容点。通过比较两个文本段落中正确回答的问题，我们将能够精确地比较它们的内容。使用2007年DUC摘要语料库的实验清楚地显示出有希望的结果。

##### URL
[https://arxiv.org/abs/1704.06259](https://arxiv.org/abs/1704.06259)

##### PDF
[https://arxiv.org/pdf/1704.06259](https://arxiv.org/pdf/1704.06259)

