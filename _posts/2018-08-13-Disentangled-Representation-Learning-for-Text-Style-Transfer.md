---
layout: post
title: "Disentangled Representation Learning for Text Style Transfer"
date: 2018-08-13 17:26:49
categories: arXiv_CL
tags: arXiv_CL Adversarial Style_Transfer Represenation_Learning Classification Language_Model Prediction Quantitative
author: Vineet John, Lili Mou, Hareesh Bahuleyan, Olga Vechtomova
mathjax: true
---

* content
{:toc}

##### Abstract
This paper tackles the problem of disentangling the latent variables of style and content in language models. We propose a simple, yet effective approach, which incorporates auxiliary objectives: a multi-task classification objective, and dual adversarial objectives for label prediction and bag-of-words prediction, respectively. We show, both qualitatively and quantitatively, that the style and content are indeed disentangled in the latent space, using this approach. This disentangled latent representation learning method is applied to attribute (e.g. style) transfer on non-parallel corpora. We achieve similar content preservation scores compared to previous state-of-the-art approaches, and significantly better style-transfer strength scores. Our code is made publicly available for replicability and extension purposes.

##### Abstract (translated by Google)
本文解决了语言模型中解决风格和内容潜在变量的问题。我们提出了一种简单而有效的方法，其中包括辅助目标：多任务分类目标，以及分别用于标签预测和词袋预测的双重对抗目标。我们在质量和数量上都表明，使用这种方法，风格和内容确实在潜在的空间中解开。这种解缠结的潜在表示学习方法应用于非平行语料库上的属性（例如，风格）转移。与先前的最先进方法相比，我们实现了类似的内容保存分数，并且具有明显更好的样式转移强度分数。我们的代码可公开用于可复制和扩展目的。

##### URL
[http://arxiv.org/abs/1808.04339](http://arxiv.org/abs/1808.04339)

##### PDF
[http://arxiv.org/pdf/1808.04339](http://arxiv.org/pdf/1808.04339)

