---
layout: post
title: "Toward Scalable Verification for Safety-Critical Deep Networks"
date: 2018-01-18 06:27:57
categories: arXiv_AI
tags: arXiv_AI Deep_Learning
author: Lindsey Kuper, Guy Katz, Justin Gottschlich, Kyle Julian, Clark Barrett, Mykel Kochenderfer
mathjax: true
---

* content
{:toc}

##### Abstract
The increasing use of deep neural networks for safety-critical applications, such as autonomous driving and flight control, raises concerns about their safety and reliability. Formal verification can address these concerns by guaranteeing that a deep learning system operates as intended, but the state-of-the-art is limited to small systems. In this work-in-progress report we give an overview of our work on mitigating this difficulty, by pursuing two complementary directions: devising scalable verification techniques, and identifying design choices that result in deep learning systems that are more amenable to verification.

##### Abstract (translated by Google)
深度神经网络在自动驾驶和飞行控制等安全关键应用中的使用日益增多，这引起了人们对其安全性和可靠性的担忧。形式验证可以通过保证深度学习系统按预期运行来解决这些问题，但最新的技术限于小型系统。在这份正在进行的工作报告中，我们通过两个互补的方向概述了我们在减轻这个困难方面所做的工作：设计可扩展的验证技术，并确定设计选择，从而产生更适合验证的深度学习系统。

##### URL
[http://arxiv.org/abs/1801.05950](http://arxiv.org/abs/1801.05950)

##### PDF
[http://arxiv.org/pdf/1801.05950](http://arxiv.org/pdf/1801.05950)

