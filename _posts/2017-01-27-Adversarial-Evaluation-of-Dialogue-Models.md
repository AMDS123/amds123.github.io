---
layout: post
title: "Adversarial Evaluation of Dialogue Models"
date: 2017-01-27 21:28:57
categories: arXiv_SD
tags: arXiv_SD Adversarial RNN
author: Anjuli Kannan, Oriol Vinyals
mathjax: true
---

* content
{:toc}

##### Abstract
The recent application of RNN encoder-decoder models has resulted in substantial progress in fully data-driven dialogue systems, but evaluation remains a challenge. An adversarial loss could be a way to directly evaluate the extent to which generated dialogue responses sound like they came from a human. This could reduce the need for human evaluation, while more directly evaluating on a generative task. In this work, we investigate this idea by training an RNN to discriminate a dialogue model's samples from human-generated samples. Although we find some evidence this setup could be viable, we also note that many issues remain in its practical application. We discuss both aspects and conclude that future work is warranted.

##### Abstract (translated by Google)
RNN编码器 - 解码器模型的最近应用已经在完全数据驱动的对话系统中取得了实质性的进展，但是评估仍然是一个挑战。对抗性的损失可能是一种直接评估对话响应听起来像是来自人类的程度的方式。这可以减少对人类评估的需求，同时更直接地对生成任务进行评估。在这项工作中，我们通过训练一个RNN来区分对话模型的样本和人类生成的样本来研究这个想法。虽然我们发现这种设置是可行的，但我们也注意到许多问题仍然在实际应用中。我们讨论这两个方面，并得出结论认为今后的工作是有必要的。

##### URL
[https://arxiv.org/abs/1701.08198](https://arxiv.org/abs/1701.08198)

##### PDF
[https://arxiv.org/pdf/1701.08198](https://arxiv.org/pdf/1701.08198)

