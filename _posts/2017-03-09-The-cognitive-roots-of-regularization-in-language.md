---
layout: post
title: "The cognitive roots of regularization in language"
date: 2017-03-09 19:50:00
categories: arXiv_SD
tags: arXiv_SD Regularization
author: Vanessa Ferdinand, Simon Kirby, Kenny Smith
mathjax: true
---

* content
{:toc}

##### Abstract
Regularization occurs when the output a learner produces is less variable than the linguistic data they observed. In an artificial language learning experiment, we show that there exist at least two independent sources of regularization bias in cognition: a domain-general source based on cognitive load and a domain-specific source triggered by linguistic stimuli. Both of these factors modulate how frequency information is encoded and produced, but only the production-side modulations result in regularization (i.e. cause learners to eliminate variation from the observed input). We formalize the definition of regularization as the reduction of entropy and find that entropy measures are better at identifying regularization behavior than frequency-based analyses. We also use a model of cultural transmission to extrapolate from our experimental data in order to predict the amount of regularization which would develop in each experimental condition if the artificial language was transmitted over several generations of learners. Here we find an interaction between cognitive load and linguistic domain, suggesting that the effect of cognitive constraints can become more complex when put into the context of cultural evolution: although learning biases certainly carry information about the course of language evolution, we should not expect a one-to-one correspondence between the micro-level processes that regularize linguistic datasets and the macro-level evolution of linguistic regularity.

##### Abstract (translated by Google)
正规化发生在学习者产出的输出比他们观察到的语言学数据变化更小时。在一个人工语言学习实验中，我们发现在认知中至少存在两个独立的正则化偏见来源：一个基于认知负荷的领域一般来源和一个由语言刺激触发的领域特定来源。这两个因素都调节频率信息的编码和生成方式，但只有生产端的调制导致正则化（即导致学习者消除观察输入的变化）。我们将正规化的定义形式化为熵的减少，并且发现熵测量在识别正则化行为方面比基于频率的分析更好。我们还使用文化传播模型来从我们的实验数据中推断出来，以便预测如果人工语言是在几代人的学习者中传输的话，那么在每个实验条件下将会产生正规化的量。在这里，我们发现了认知负荷和语言领域之间的相互作用，表明认知约束的影响在进入文化进化的背景下可能会变得更加复杂：尽管学习偏差确实带有关于语言进化过程的信息，但是我们不应该期待规范语言数据集的微观层面过程与语言规律的宏观层次演进之间存在一一对应关系。

##### URL
[https://arxiv.org/abs/1703.03442](https://arxiv.org/abs/1703.03442)

##### PDF
[https://arxiv.org/pdf/1703.03442](https://arxiv.org/pdf/1703.03442)

