---
layout: post
title: "Video Person Re-identification by Temporal Residual Learning"
date: 2018-02-22 07:13:53
categories: arXiv_CV
tags: arXiv_CV Re-identification Knowledge Person_Re-identification RNN
author: Ju Dai, Pingping Zhang, Huchuan Lu, Hongyu Wang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a novel feature learning framework for video person re-identification (re-ID). The proposed framework largely aims to exploit the adequate temporal information of video sequences and tackle the poor spatial alignment of moving pedestrians. More specifically, for exploiting the temporal information, we design a temporal residual learning (TRL) module to simultaneously extract the generic and specific features of consecutive frames. The TRL module is equipped with two bi-directional LSTM (BiLSTM), which are respectively responsible to describe a moving person in different aspects, providing complementary information for better feature representations. To deal with the poor spatial alignment in video re-ID datasets, we propose a spatial-temporal transformer network (ST^2N) module. Transformation parameters in the ST^2N module are learned by leveraging the high-level semantic information of the current frame as well as the temporal context knowledge from other frames. The proposed ST^2N module with less learnable parameters allows effective person alignments under significant appearance changes. Extensive experimental results on the large-scale MARS, PRID2011, ILIDS-VID and SDU-VID datasets demonstrate that the proposed method achieves consistently superior performance and outperforms most of the very recent state-of-the-art methods.

##### Abstract (translated by Google)
在本文中，我们提出了一种新的视频人物识别（re-ID）特征学习框架。所提出的框架很大程度上旨在利用视频序列的足够时间信息并解决移动行人的空间不良行为。更具体地说，为了利用时间信息，我们设计了时间残差学习（TRL）模块，以同时提取连续帧的一般和特定特征。 TRL模块配备两个双向LSTM（BiLSTM），它们分别负责描述不同方面的移动人员，为更好的特征表示提供补充信息。为了解决视频再识别数据集中空间对齐问题，我们提出了一个时空变换网络（ST ^ 2N）模块。通过利用当前帧的高级语义信息以及来自其他帧的时间背景知识来学习ST ^ 2N模块中的变换参数。所提出的ST ^ 2N模块具有较少的可学习参数，允许在显着外观变化下进行有效的人员对准。在大规模MARS，PRID2011，ILIDS-VID和SDU-VID数据集上的广泛的实验结果表明，所提出的方法实现了始终如一的卓越性能，并且胜过了大多数最近的最先进的方法。

##### URL
[http://arxiv.org/abs/1802.07918](http://arxiv.org/abs/1802.07918)

##### PDF
[http://arxiv.org/pdf/1802.07918](http://arxiv.org/pdf/1802.07918)

