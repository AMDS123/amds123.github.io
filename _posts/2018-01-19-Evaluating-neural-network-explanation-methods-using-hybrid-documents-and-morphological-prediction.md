---
layout: post
title: "Evaluating neural network explanation methods using hybrid documents and morphological prediction"
date: 2018-01-19 14:41:45
categories: arXiv_CL
tags: arXiv_CL CNN RNN Prediction Memory_Networks
author: Nina Poerner, Hinrich Sch&#xfc;tze, Benjamin Roth
mathjax: true
---

* content
{:toc}

##### Abstract
We propose two novel paradigms for evaluating neural network explanations in NLP. The first paradigm works on hybrid documents, the second exploits morphosyntactic agreements. Neither paradigm requires manual annotations; instead, a relevance ground truth is generated automatically. In our experiments, successful explanations for Long Short Term Memory networks (LSTMs) were produced by a decomposition of memory cells (Murdoch &amp; Szlam, 2017), while for convolutional neural networks, a gradient-based method by (Denil et al., 2014) works well. We also introduce LIMSSE, a substring-based extension of LIME (Ribeiro et al., 2016) that produces the most successful explanations in the hybrid document experiment.

##### Abstract (translated by Google)
我们提出了两种新颖的用于评估NLP神经网络解释的范例。第一个范式适用于混合文档，第二个范例是形态句法协议。这两种模式都不需要手动注释;相反，相关的地面真相是自动生成的。在我们的实验中，通过存储器单元的分解（Murdoch＆amp; Szlam，2017）产生对长时间短记忆网络（LSTM）的成功解释，而对于卷积神经网络，基于梯度的方法（Denil等， 2014）运作良好。我们还介绍了LIMSS，LIME的一个基于子串的扩展（Ribeiro et al。，2016），它在混合文档实验中产生了最成功的解释。

##### URL
[http://arxiv.org/abs/1801.06422](http://arxiv.org/abs/1801.06422)

##### PDF
[http://arxiv.org/pdf/1801.06422](http://arxiv.org/pdf/1801.06422)

