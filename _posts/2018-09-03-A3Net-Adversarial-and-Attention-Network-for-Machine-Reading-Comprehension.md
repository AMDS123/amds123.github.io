---
layout: post
title: "A3Net: Adversarial-and-Attention Network for Machine Reading Comprehension"
date: 2018-09-03 18:03:46
categories: arXiv_CL
tags: arXiv_CL Regularization Adversarial QA Attention Embedding
author: Jiuniu Wang, Xingyu Fu, Guangluan Xu, Yirong Wu, Ziyan Chen, Yang Wei, Li Jin
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we introduce Adversarial-and-attention Network (A3Net) for Machine Reading Comprehension. This model extends existing approaches from two perspectives. First, adversarial training is applied to several target variables within the model, rather than only to the inputs or embeddings. We control the norm of adversarial perturbations according to the norm of original target variables, so that we can jointly add perturbations to several target variables during training. As an effective regularization method, adversarial training improves robustness and generalization of our model. Second, we propose a multi-layer attention network utilizing three kinds of high-efficiency attention mechanisms. Multi-layer attention conducts interaction between question and passage within each layer, which contributes to reasonable representation and understanding of the model. Combining these two contributions, we enhance the diversity of dataset and the information extracting ability of the model at the same time. Meanwhile, we construct A3Net for the WebQA dataset. Results show that our model outperforms the state-of-the-art models (improving Fuzzy Score from 73.50% to 77.0%).

##### Abstract (translated by Google)
在本文中，我们介绍了用于机器阅读理解的对抗和关注网络（A3Net）。该模型从两个角度扩展了现有方法。首先，对抗训练应用于模型中的几个目标变量，而不仅仅应用于输入或嵌入。我们根据原始目标变量的范数来控制对抗扰动的范数，这样我们就可以在训练期间共同对几个目标变量进行扰动。作为一种有效的正则化方法，对抗训练提高了我们模型的鲁棒性和泛化能力。其次，我们提出了一种利用三种高效注意机制的多层注意网络。多层注意力在每层内进行问题和通道之间的相互作用，这有助于合理地表示和理解模型。结合这两个贡献，我们同时增强了数据集的多样性和模型的信息提取能力。同时，我们为WebQA数据集构建了A3Net。结果表明，我们的模型优于最先进的模型（将模糊分数从73.50％提高到77.0％）。

##### URL
[http://arxiv.org/abs/1809.00676](http://arxiv.org/abs/1809.00676)

##### PDF
[http://arxiv.org/pdf/1809.00676](http://arxiv.org/pdf/1809.00676)

