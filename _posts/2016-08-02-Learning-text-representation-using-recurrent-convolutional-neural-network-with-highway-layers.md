---
layout: post
title: "Learning text representation using recurrent convolutional neural network with highway layers"
date: 2016-08-02 16:17:05
categories: arXiv_CL
tags: arXiv_CL Sentiment Embedding CNN RNN
author: Ying Wen, Weinan Zhang, Rui Luo, Jun Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, the rapid development of word embedding and neural networks has brought new inspiration to various NLP and IR tasks. In this paper, we describe a staged hybrid model combining Recurrent Convolutional Neural Networks (RCNN) with highway layers. The highway network module is incorporated in the middle takes the output of the bi-directional Recurrent Neural Network (Bi-RNN) module in the first stage and provides the Convolutional Neural Network (CNN) module in the last stage with the input. The experiment shows that our model outperforms common neural network models (CNN, RNN, Bi-RNN) on a sentiment analysis task. Besides, the analysis of how sequence length influences the RCNN with highway layers shows that our model could learn good representation for the long text.

##### Abstract (translated by Google)
最近，词嵌入和神经网络的快速发展给各种NLP和IR任务带来了新的启发。在本文中，我们描述了一个分阶段的混合模型结合递归卷积神经网络（RCNN）与公路层。中间包含的高速公路网络模块将第一阶段的双向递归神经网络（Bi-RNN）模块的输出作为输入，最后提供卷积神经网络（CNN）模块。实验表明，我们的模型在一个情感分析任务上优于常见的神经网络模型（CNN，RNN，Bi-RNN）。此外，分析序列长度如何影响RCNN与公路层，表明我们的模型可以学习长文本的良好表示。

##### URL
[https://arxiv.org/abs/1606.06905](https://arxiv.org/abs/1606.06905)

##### PDF
[https://arxiv.org/pdf/1606.06905](https://arxiv.org/pdf/1606.06905)

