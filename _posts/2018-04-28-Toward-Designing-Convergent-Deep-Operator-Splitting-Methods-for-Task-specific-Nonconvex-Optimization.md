---
layout: post
title: "Toward Designing Convergent Deep Operator Splitting Methods for Task-specific Nonconvex Optimization"
date: 2018-04-28 12:59:50
categories: arXiv_CV
tags: arXiv_CV Optimization
author: Risheng Liu, Shichao Cheng, Yi He, Xin Fan, Zhongxuan Luo
mathjax: true
---

* content
{:toc}

##### Abstract
Operator splitting methods have been successfully used in computational sciences, statistics, learning and vision areas to reduce complex problems into a series of simpler subproblems. However, prevalent splitting schemes are mostly established only based on the mathematical properties of some general optimization models. So it is a laborious process and often requires many iterations of ideation and validation to obtain practical and task-specific optimal solutions, especially for nonconvex problems in real-world scenarios. To break through the above limits, we introduce a new algorithmic framework, called Learnable Bregman Splitting (LBS), to perform deep-architecture-based operator splitting for nonconvex optimization based on specific task model. Thanks to the data-dependent (i.e., learnable) nature, our LBS can not only speed up the convergence, but also avoid unwanted trivial solutions for real-world tasks. Though with inexact deep iterations, we can still establish the global convergence and estimate the asymptotic convergence rate of LBS only by enforcing some fairly loose assumptions. Extensive experiments on different applications (e.g., image completion and deblurring) verify our theoretical results and show the superiority of LBS against existing methods.

##### Abstract (translated by Google)
算子分裂方法已成功用于计算科学，统计学，学习和视觉领域，将复杂问题简化为一系列较简单的子问题。然而，流行的分裂方案大多仅基于一些通用优化模型的数学特性来建立。所以这是一个费力的过程，通常需要许多迭代的构思和验证才能获得实际的和特定任务的最优解决方案，特别是对于现实世界中的非凸性问题。为突破上述限制，我们引入了一种称为可学习Bregman分裂（LBS）的新算法框架，以基于特定任务模型执行基于深度架构的算子分裂，以实现非凸优化。由于数据相关（即可学习）的特性，我们的LBS不仅可以加快收敛速度​​，还可以避免不必要的现实世界任务的琐碎解决方案。尽管采用不精确的深度迭代，但我们仍然可以通过强制执行一些相当宽松的假设来建立全局收敛和估计LBS的渐近收敛速度。针对不同应用（例如图像完成和去模糊）的大量实验验证了我们的理论结果，并显示了LBS与现有方法的优越性。

##### URL
[https://arxiv.org/abs/1804.10798](https://arxiv.org/abs/1804.10798)

##### PDF
[https://arxiv.org/pdf/1804.10798](https://arxiv.org/pdf/1804.10798)

