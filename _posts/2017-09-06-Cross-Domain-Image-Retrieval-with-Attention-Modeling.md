---
layout: post
title: "Cross-Domain Image Retrieval with Attention Modeling"
date: 2017-09-06 11:49:46
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Attention CNN
author: Xin Ji, Wei Wang, Meihui Zhang, Yang Yang
mathjax: true
---

* content
{:toc}

##### Abstract
With the proliferation of e-commerce websites and the ubiquitousness of smart phones, cross-domain image retrieval using images taken by smart phones as queries to search products on e-commerce websites is emerging as a popular application. One challenge of this task is to locate the attention of both the query and database images. In particular, database images, e.g. of fashion products, on e-commerce websites are typically displayed with other accessories, and the images taken by users contain noisy background and large variations in orientation and lighting. Consequently, their attention is difficult to locate. In this paper, we exploit the rich tag information available on the e-commerce websites to locate the attention of database images. For query images, we use each candidate image in the database as the context to locate the query attention. Novel deep convolutional neural network architectures, namely TagYNet and CtxYNet, are proposed to learn the attention weights and then extract effective representations of the images. Experimental results on public datasets confirm that our approaches have significant improvement over the existing methods in terms of the retrieval accuracy and efficiency.

##### Abstract (translated by Google)
随着电子商务网站的普及和智能手机的普及，利用智能手机拍摄的图像作为查询电子商务网站上的产品的跨域图像检索正在成为一种流行的应用。这个任务的一个挑战是定位查询和数据库图像的注意力。特别是，数据库图像，例如在电子商务网站上的时尚产品通常与其他配件一起显示，用户拍摄的图像包含嘈杂的背景和方向和照明的大的变化。因此，他们的注意力很难找到。在本文中，我们利用电子商务网站上的丰富标签信息来定位数据库图像的注意力。对于查询图像，我们使用数据库中的每个候选图像作为上下文来定位查询注意力。提出了新的深度卷积神经网络体系结构，即TagYNet和CtxYNet，用于学习注意力的权重，然后提取图像的有效表示。在公共数据集上的实验结果证实，我们的方法在检索准确性和效率方面比现有方法有显着的改进。

##### URL
[https://arxiv.org/abs/1709.01784](https://arxiv.org/abs/1709.01784)

##### PDF
[https://arxiv.org/pdf/1709.01784](https://arxiv.org/pdf/1709.01784)

