---
layout: post
title: "Cross-modal Embeddings for Video and Audio Retrieval"
date: 2018-01-07 15:43:22
categories: arXiv_CV
tags: arXiv_CV Embedding
author: Didac Sur&#xed;s, Amanda Duarte, Amaia Salvador, Jordi Torres, Xavier Gir&#xf3;-i-Nieto
mathjax: true
---

* content
{:toc}

##### Abstract
The increasing amount of online videos brings several opportunities for training self-supervised neural networks. The creation of large scale datasets of videos such as the YouTube-8M allows us to deal with this large amount of data in manageable way. In this work, we find new ways of exploiting this dataset by taking advantage of the multi-modal information it provides. By means of a neural network, we are able to create links between audio and visual documents, by projecting them into a common region of the feature space, obtaining joint audio-visual embeddings. These links are used to retrieve audio samples that fit well to a given silent video, and also to retrieve images that match a given a query audio. The results in terms of Recall@K obtained over a subset of YouTube-8M videos show the potential of this unsupervised approach for cross-modal feature learning. We train embeddings for both scales and assess their quality in a retrieval problem, formulated as using the feature extracted from one modality to retrieve the most similar videos based on the features computed in the other modality.

##### Abstract (translated by Google)
在线视频数量的增加带来了一些训练自我监督的神经网络的机会。创建YouTube-8M等大型视频数据集使我们能够以可管理的方式处理大量的数据。在这项工作中，我们通过利用它提供的多模态信息，找到利用这个数据集的新方法。借助于神经网络，我们能够在音频和视觉文件之间建立链接，将它们投影到特征空间的公共区域，获得联合的视听嵌入。这些链接用于检索符合给定静音视频的音频样本，还用于检索匹配给定查询音频的图像。在YouTube-8M视频子集上获得的Recall @ K结果显示了这种无监督方法在跨模式特征学习中的潜力。我们训练两个尺度的嵌入，并在检索问题中评估它们的质量，制定为使用从一种模式提取的特征来基于在另一种模式中计算的特征检索最相似的视频。

##### URL
[http://arxiv.org/abs/1801.02200](http://arxiv.org/abs/1801.02200)

##### PDF
[http://arxiv.org/pdf/1801.02200](http://arxiv.org/pdf/1801.02200)

