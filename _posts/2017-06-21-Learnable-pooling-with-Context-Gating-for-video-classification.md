---
layout: post
title: "Learnable pooling with Context Gating for video classification"
date: 2017-06-21 13:49:14
categories: arXiv_CV
tags: arXiv_CV Video_Caption Video_Classification RNN Classification
author: Antoine Miech, Ivan Laptev, Josef Sivic
mathjax: true
---

* content
{:toc}

##### Abstract
Common video representations often deploy an average or maximum pooling of pre-extracted frame features over time. Such an approach provides a simple means to encode feature distributions, but is likely to be suboptimal. As an alternative, we here explore combinations of learnable pooling techniques such as Soft Bag-of-words, Fisher Vectors, NetVLAD, GRU and LSTM to aggregate video features over time. We also introduce a learnable non-linear network unit, named Context Gating, aiming at modeling interdependencies between features. We evaluate the method on the multi-modal Youtube-8M Large-Scale Video Understanding dataset using pre-extracted visual and audio features. We demonstrate improvements provided by the Context Gating as well as by the combination of learnable pooling methods. We finally show how this leads to the best performance, out of more than 600 teams, in the Kaggle Youtube-8M Large-Scale Video Understanding challenge.

##### Abstract (translated by Google)
常见的视频表示通常随着时间的推移而部署预先提取的帧特征的平均或最大的汇集。这种方法提供了一种简单的方法来编码特征分布，但可能不是最理想的。作为一种替代方法，我们在这里探索可学习池技术的组合，如软包袋，Fisher矢量，NetVLAD，GRU和LSTM，以聚合随着时间的推移视频功能。我们还引入了一个名为Context Gating的可学习的非线性网络单元，旨在模拟特征之间的相互依赖关系。我们使用预先提取的视觉和音频特征评估多模式Youtube-8M大规模视频理解数据集中的方法。我们展示了由Context Gating提供的改进以及可学习池化方法的组合。在Kaggle Youtube-8M大规模视频理解挑战中，我们终于展示了如何通过600多个团队获得最佳表现。

##### URL
[https://arxiv.org/abs/1706.06905](https://arxiv.org/abs/1706.06905)

##### PDF
[https://arxiv.org/pdf/1706.06905](https://arxiv.org/pdf/1706.06905)

