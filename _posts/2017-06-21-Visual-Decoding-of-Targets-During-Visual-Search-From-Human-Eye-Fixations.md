---
layout: post
title: "Visual Decoding of Targets During Visual Search From Human Eye Fixations"
date: 2017-06-21 11:19:10
categories: arXiv_CV
tags: arXiv_CV CNN Prediction
author: Hosnieh Sattar, Mario Fritz, Andreas Bulling
mathjax: true
---

* content
{:toc}

##### Abstract
What does human gaze reveal about a users' intents and to which extend can these intents be inferred or even visualized? Gaze was proposed as an implicit source of information to predict the target of visual search and, more recently, to predict the object class and attributes of the search target. In this work, we go one step further and investigate the feasibility of combining recent advances in encoding human gaze information using deep convolutional neural networks with the power of generative image models to visually decode, i.e. create a visual representation of, the search target. Such visual decoding is challenging for two reasons: 1) the search target only resides in the user's mind as a subjective visual pattern, and can most often not even be described verbally by the person, and 2) it is, as of yet, unclear if gaze fixations contain sufficient information for this task at all. We show, for the first time, that visual representations of search targets can indeed be decoded only from human gaze fixations. We propose to first encode fixations into a semantic representation and then decode this representation into an image. We evaluate our method on a recent gaze dataset of 14 participants searching for clothing in image collages and validate the model's predictions using two human studies. Our results show that 62% (Chance level = 10%) of the time users were able to select the categories of the decoded image right. In our second studies we show the importance of a local gaze encoding for decoding visual search targets of user

##### Abstract (translated by Google)
人类的目光透露着用户的意图以及这些意图在哪些方面可以被推断出来，甚至可以被视觉化？ Gaze被认为是一种隐含的信息来源，用于预测视觉搜索的目标，最近则预测搜索目标的对象类别和属性。在这项工作中，我们更进一步，研究将使用深度卷积神经网络编码人类注视信息的最新进展与生成图像模型的能力相结合以可视化地解码，即创建搜索目标的视觉表示的可行性。这种视觉解码是具有挑战性的，原因有两个：1）搜索目标仅作为主观视觉模式驻留在用户的头脑中，并且甚至通常甚至不能由该人员口头描述，以及2）至今还不清楚如果凝视注视包含足够的信息为这个任务根本。我们首次显示，搜索目标的视觉表示确实只能从人类凝视注意的方面解码。我们建议首先将注视编码成语义表示，然后将这个表示解码成图像。我们评估我们的方法在最近的14名参与者在图像拼贴中搜索服装的凝视数据集，并使用两项人体研究来验证模型的预测。我们的结果显示，用户能够正确选择解码图像的类别的62％（机会水平= 10％）。在我们的第二个研究中，我们展示了用于解码用户的视觉搜索目标的本地凝视编码的重要性

##### URL
[https://arxiv.org/abs/1706.05993](https://arxiv.org/abs/1706.05993)

##### PDF
[https://arxiv.org/pdf/1706.05993](https://arxiv.org/pdf/1706.05993)

