---
layout: post
title: "Reachable Set Computation and Safety Verification for Neural Networks with ReLU Activations"
date: 2017-12-21 08:57:06
categories: arXiv_AI
tags: arXiv_AI
author: Weiming Xiang, Hoang-Dung Tran, Taylor T. Johnson
mathjax: true
---

* content
{:toc}

##### Abstract
Neural networks have been widely used to solve complex real-world problems. Due to the complicate, nonlinear, non-convex nature of neural networks, formal safety guarantees for the output behaviors of neural networks will be crucial for their applications in safety-critical systems.In this paper, the output reachable set computation and safety verification problems for a class of neural networks consisting of Rectified Linear Unit (ReLU) activation functions are addressed. A layer-by-layer approach is developed to compute output reachable set. The computation is formulated in the form of a set of manipulations for a union of polyhedra, which can be efficiently applied with the aid of polyhedron computation tools. Based on the output reachable set computation results, the safety verification for a ReLU neural network can be performed by checking the intersections of unsafe regions and output reachable set described by a union of polyhedra. A numerical example of a randomly generated ReLU neural network is provided to show the effectiveness of the approach developed in this paper.

##### Abstract (translated by Google)
神经网络已被广泛用于解决复杂的现实世界问题。由于神经网络的复杂性，非线性，非凸性，神经网络输出行为的形式安全保证对其在安全关键系统中的应用至关重要。本文研究了输出可达集计算与安全验证问题针对一类由整流线性单元（ReLU）激活函数组成的神经网络进行了研究。开发了逐层方法来计算输出可达集。计算是以一组多面体的联合操作的形式来表达的，可以借助多面体计算工具来有效地应用。基于输出可达集合的计算结果，可以通过检查多面体联合描述的不安全区域与输出可达集合的交集来执行对ReLU神经网络的安全验证。随机生成的ReLU神经网络的数值实例表明了本文开发的方法的有效性。

##### URL
[https://arxiv.org/abs/1712.08163](https://arxiv.org/abs/1712.08163)

##### PDF
[https://arxiv.org/pdf/1712.08163](https://arxiv.org/pdf/1712.08163)

