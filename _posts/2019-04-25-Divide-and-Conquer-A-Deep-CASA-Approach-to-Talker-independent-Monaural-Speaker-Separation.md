---
layout: post
title: "Divide and Conquer: A Deep CASA Approach to Talker-independent Monaural Speaker Separation"
date: 2019-04-25 03:57:11
categories: arXiv_SD
tags: arXiv_SD Tracking Deep_Learning
author: Yuzhou Liu, DeLiang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
We address talker-independent monaural speaker separation from the perspectives of deep learning and computational auditory scene analysis (CASA). Specifically, we decompose the multi-speaker separation task into the stages of simultaneous grouping and sequential grouping. Simultaneous grouping is first performed in each time frame by separating the spectra of different speakers with a permutation-invariantly trained neural network. In the second stage, the frame-level separated spectra are sequentially grouped to different speakers by a clustering network. The proposed deep CASA approach optimizes frame-level separation and speaker tracking in turn, and produces excellent results for both objectives. Experimental results on the benchmark WSJ0-2mix database show that the new approach achieves the state-of-the-art results with a modest model size.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.11148](http://arxiv.org/abs/1904.11148)

##### PDF
[http://arxiv.org/pdf/1904.11148](http://arxiv.org/pdf/1904.11148)

