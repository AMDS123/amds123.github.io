---
layout: post
title: "Counting Grid Aggregation for Event Retrieval and Recognition"
date: 2016-10-11 12:11:47
categories: arXiv_CV
tags: arXiv_CV Classification Recognition
author: Zhanning Gao, Gang Hua, Dongqing Zhang, Jianru Xue, Nanning Zheng
mathjax: true
---

* content
{:toc}

##### Abstract
Event retrieval and recognition in a large corpus of videos necessitates a holistic fixed-size visual representation at the video clip level that is comprehensive, compact, and yet discriminative. It shall comprehensively aggregate information across relevant video frames, while suppress redundant information, leading to a compact representation that can effectively differentiate among different visual events. In search for such a representation, we propose to build a spatially consistent counting grid model to aggregate together deep features extracted from different video frames. The spatial consistency of the counting grid model is achieved by introducing a prior model estimated from a large corpus of video data. The counting grid model produces an intermediate tensor representation for each video, which automatically identifies and removes the feature redundancy across the different frames. The tensor representation is subsequently reduced to a fixed-size vector representation by averaging over the counting grid. When compared to existing methods on both event retrieval and event classification benchmarks, we achieve significantly better accuracy with much more compact representation.

##### Abstract (translated by Google)
在大量视频中的事件检索和识别需要在视频片段级别上具有全面的，固定尺寸的视觉表示，其是全面的，紧凑的并且具有区别性的。应全面统计相关视频帧中的信息，同时抑制冗余信息，导致紧凑的表示，可以有效区分不同的视觉事件。为了寻找这样一个表示，我们建议建立一个空间一致的计数网格模型来聚合从不同视频帧中提取的深度特征。计数网格模型的空间一致性是通过引入从大量视频数据集估计的先验模型来实现的。计数网格模型为每个视频生成一个中间张量表示，自动识别和删除跨不同帧的特征冗余。张量表示随后通过对计数网格进行平均而被减小为固定大小的矢量表示。与事件检索和事件分类基准的现有方法相比，我们通过更加紧凑的表示方法实现了更高的准确性。

##### URL
[https://arxiv.org/abs/1604.01109](https://arxiv.org/abs/1604.01109)

##### PDF
[https://arxiv.org/e-print/1604.01109](https://arxiv.org/e-print/1604.01109)

