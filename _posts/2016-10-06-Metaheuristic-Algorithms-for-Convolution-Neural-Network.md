---
layout: post
title: "Metaheuristic Algorithms for Convolution Neural Network"
date: 2016-10-06 16:11:06
categories: arXiv_CV
tags: arXiv_CV CNN Optimization Deep_Learning
author: L. M. Rasdi Rere, Mohamad Ivan Fanany, Aniati Murni Arymurthy
mathjax: true
---

* content
{:toc}

##### Abstract
A typical modern optimization technique is usually either heuristic or metaheuristic. This technique has managed to solve some optimization problems in the research area of science, engineering, and industry. However, implementation strategy of metaheuristic for accuracy improvement on convolution neural networks (CNN), a famous deep learning method, is still rarely investigated. Deep learning relates to a type of machine learning technique, where its aim is to move closer to the goal of artificial intelligence of creating a machine that could successfully perform any intellectual tasks that can be carried out by a human. In this paper, we propose the implementation strategy of three popular metaheuristic approaches, that is, simulated annealing, differential evolution, and harmony search, to optimize CNN. The performances of these metaheuristic methods in optimizing CNN on classifying MNIST and CIFAR dataset were evaluated and compared. Furthermore, the proposed methods are also compared with the original CNN. Although the proposed methods show an increase in the computation time, their accuracy has also been improved (up to 7.14 percent).

##### Abstract (translated by Google)
典型的现代优化技术通常是启发式或元启发式的。该技术已经成功解决了科学，工程和工业领域的一些优化问题。然而，着名的深度学习方法 - 卷积神经网络（CNN）的精度改进的启发式实现策略仍然很少被研究。深度学习涉及到一种机器学习技术，其目的是向人工智能的目标靠拢，以创造一台能够成功执行任何人类智力任务的机器。本文提出了三种流行的启发式算法的实现策略，即模拟退火算法，差分进化算法和和谐搜索算法来优化CNN。对这些元启发式方法在优化CNN方法对MNIST和CIFAR数据集进行分类时的性能进行了评估和比较。此外，所提出的方法也与原来的CNN进行了比较。尽管所提出的方法显示出计算时间的增加，但其准确度也已经提高（达到7.14％）。

##### URL
[https://arxiv.org/abs/1610.01925](https://arxiv.org/abs/1610.01925)

##### PDF
[https://arxiv.org/pdf/1610.01925](https://arxiv.org/pdf/1610.01925)

