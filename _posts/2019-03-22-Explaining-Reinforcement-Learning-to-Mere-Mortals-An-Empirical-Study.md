---
layout: post
title: "Explaining Reinforcement Learning to Mere Mortals: An Empirical Study"
date: 2019-03-22 20:56:55
categories: arXiv_AI
tags: arXiv_AI Salient Attention Reinforcement_Learning Prediction
author: Andrew Anderson, Jonathan Dodge, Amrita Sadarangani, Zoe Juozapaitis, Evan Newman, Jed Irvine, Souti Chattopadhyay, Alan Fern, Margaret Burnett
mathjax: true
---

* content
{:toc}

##### Abstract
We present a user study to investigate the impact of explanations on non-experts' understanding of reinforcement learning (RL) agents. We investigate both a common RL visualization, saliency maps (the focus of attention), and a more recent explanation type, reward-decomposition bars (predictions of future types of rewards). We designed a 124 participant, four-treatment experiment to compare participants' mental models of an RL agent in a simple Real-Time Strategy (RTS) game. Our results show that the combination of both saliency and reward bars were needed to achieve a statistically significant improvement in mental model score over the control. In addition, our qualitative analysis of the data reveals a number of effects for further study.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.09708](http://arxiv.org/abs/1903.09708)

##### PDF
[http://arxiv.org/pdf/1903.09708](http://arxiv.org/pdf/1903.09708)

