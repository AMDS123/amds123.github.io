---
layout: post
title: "Deep Residual Learning for Weakly-Supervised Relation Extraction"
date: 2017-07-27 13:56:36
categories: arXiv_CL
tags: arXiv_CL Relation_Extraction CNN Classification Relation
author: Yi Yao Huang, William Yang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Deep residual learning (ResNet) is a new method for training very deep neural networks using identity map-ping for shortcut connections. ResNet has won the ImageNet ILSVRC 2015 classification task, and achieved state-of-the-art performances in many computer vision tasks. However, the effect of residual learning on noisy natural language processing tasks is still not well understood. In this paper, we design a novel convolutional neural network (CNN) with residual learning, and investigate its impacts on the task of distantly supervised noisy relation extraction. In contradictory to popular beliefs that ResNet only works well for very deep networks, we found that even with 9 layers of CNNs, using identity mapping could significantly improve the performance for distantly-supervised relation extraction.

##### Abstract (translated by Google)
深度残差学习（ResNet）是一种新的方法，用于使用身份映射来进行非常深的神经网络的快捷连接。 ResNet赢得了ImageNet ILSVRC 2015分类任务，并在许多计算机视觉任务中取得了最先进的性能。但是，残差学习对自然语言处理任务的影响还不是很清楚。本文设计了一种残差学习的新型卷积神经网络（CNN），并研究了其对远程监督噪声关系抽取任务的影响。 ResNet与ResNet仅适用于非常深的网络的流行观点相矛盾，我们发现即使有9层CNNs，使用身份映射也能显着提高远程监督关系抽取的性能。

##### URL
[https://arxiv.org/abs/1707.08866](https://arxiv.org/abs/1707.08866)

##### PDF
[https://arxiv.org/pdf/1707.08866](https://arxiv.org/pdf/1707.08866)

