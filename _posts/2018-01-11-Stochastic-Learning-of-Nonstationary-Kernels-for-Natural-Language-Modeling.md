---
layout: post
title: "Stochastic Learning of Nonstationary Kernels for Natural Language Modeling"
date: 2018-01-11 18:24:02
categories: arXiv_CL
tags: arXiv_CL Inference Language_Model Relation
author: Sahil Garg, Greg Ver Steeg, Aram Galstyan
mathjax: true
---

* content
{:toc}

##### Abstract
Natural language processing often involves computations with semantic or syntactic graphs to facilitate sophisticated reasoning based on structural relationships. While convolution kernels provide a powerful tool for comparing graph structure based on node (word) level relationships, they are difficult to customize and can be computationally expensive. We propose a generalization of convolution kernels, with a nonstationary model, for better expressibility of natural languages in supervised settings. For a scalable learning of the parameters introduced with our model, we propose a novel algorithm that leverages stochastic sampling on k-nearest neighbor graphs, along with approximations based on locality-sensitive hashing. We demonstrate the advantages of our approach on a challenging real-world (structured inference) problem of automatically extracting biological models from the text of scientific papers.

##### Abstract (translated by Google)
自然语言处理通常涉及用语义或句法图进行计算，以促进基于结构关系的复杂推理。虽然卷积内核提供了一个强大的工具来比较基于节点（词）级别关系的图结构，但它们很难定制，并且可能在计算上是昂贵的。我们提出了一个卷积核的概括，用一个非平稳模型来更好地表达自然语言的监督设置。为了对我们的模型中引入的参数进行可扩展的学习，我们提出了一种新的算法，该算法利用k近邻图上的随机采样以及基于局部敏感散列的近似。我们展示了我们的方法在从科学论文的文本中自动提取生物模型的具有挑战性的现实世界（结构化推论）问题上的优势。

##### URL
[http://arxiv.org/abs/1801.03911](http://arxiv.org/abs/1801.03911)

##### PDF
[http://arxiv.org/pdf/1801.03911](http://arxiv.org/pdf/1801.03911)

