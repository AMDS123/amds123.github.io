---
layout: post
title: "THUMT: An Open Source Toolkit for Neural Machine Translation"
date: 2017-06-20 13:29:16
categories: arXiv_CL
tags: arXiv_CL NMT
author: Jiacheng Zhang, Yanzhuo Ding, Shiqi Shen, Yong Cheng, Maosong Sun, Huanbo Luan, Yang Liu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper introduces THUMT, an open-source toolkit for neural machine translation (NMT) developed by the Natural Language Processing Group at Tsinghua University. THUMT implements the standard attention-based encoder-decoder framework on top of Theano and supports three training criteria: maximum likelihood estimation, minimum risk training, and semi-supervised training. It features a visualization tool for displaying the relevance between hidden states in neural networks and contextual words, which helps to analyze the internal workings of NMT. Experiments on Chinese-English datasets show that THUMT using minimum risk training significantly outperforms GroundHog, a state-of-the-art toolkit for NMT.

##### Abstract (translated by Google)
本文介绍了清华大学自然语言处理集团开发的神经机器翻译（NMT）开源工具包THUMT。 THUMT在Theano之上实现了标准的基于注意力的编码器 - 解码器框架，支持三种训练标准：最大似然估计，最小风险训练和半监督训练。它具有一个可视化工具，用于显示神经网络中的隐藏状态和上下文单词之间的相关性，这有助于分析NMT的内部工作。汉英数据集的实验表明，使用最小风险训练的THUMT明显优于GroundHog，这是NMT的最新工具包。

##### URL
[https://arxiv.org/abs/1706.06415](https://arxiv.org/abs/1706.06415)

##### PDF
[https://arxiv.org/pdf/1706.06415](https://arxiv.org/pdf/1706.06415)

