---
layout: post
title: "Interpolated Adversarial Training: Achieving Robust Neural Networks without Sacrificing Accuracy"
date: 2019-06-16 22:01:51
categories: arXiv_AI
tags: arXiv_AI Adversarial Deep_Learning
author: Alex Lamb, Vikas Verma, Juho Kannala, Yoshua Bengio
mathjax: true
---

* content
{:toc}

##### Abstract
Adversarial robustness has become a central goal in deep learning, both in theory and practice. However, successful methods to improve adversarial robustness (such as adversarial training) greatly hurt generalization performance on the clean data. This could have a major impact on how adversarial robustness affects real world systems (i.e. many may opt to forego robustness if it can improve performance on the clean data). We propose Interpolated Adversarial Training, which employs recently proposed interpolation based training methods in the framework of adversarial training. On CIFAR-10, adversarial training increases clean test error from 5.8% to 16.7%, whereas with our Interpolated adversarial training we retain adversarial robustness while achieving a clean test error of only 6.5%. With our technique, the relative error increase for the robust model is reduced from 187.9% to just 12.1%

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.06784](http://arxiv.org/abs/1906.06784)

##### PDF
[http://arxiv.org/pdf/1906.06784](http://arxiv.org/pdf/1906.06784)

