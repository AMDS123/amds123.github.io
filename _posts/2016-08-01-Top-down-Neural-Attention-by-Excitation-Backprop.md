---
layout: post
title: "Top-down Neural Attention by Excitation Backprop"
date: 2016-08-01 17:49:57
categories: arXiv_CV
tags: arXiv_CV Attention Weakly_Supervised CNN
author: Jianming Zhang, Zhe Lin, Jonathan Brandt, Xiaohui Shen, Stan Sclaroff
mathjax: true
---

* content
{:toc}

##### Abstract
We aim to model the top-down attention of a Convolutional Neural Network (CNN) classifier for generating task-specific attention maps. Inspired by a top-down human visual attention model, we propose a new backpropagation scheme, called Excitation Backprop, to pass along top-down signals downwards in the network hierarchy via a probabilistic Winner-Take-All process. Furthermore, we introduce the concept of contrastive attention to make the top-down attention maps more discriminative. In experiments, we demonstrate the accuracy and generalizability of our method in weakly supervised localization tasks on the MS COCO, PASCAL VOC07 and ImageNet datasets. The usefulness of our method is further validated in the text-to-region association task. On the Flickr30k Entities dataset, we achieve promising performance in phrase localization by leveraging the top-down attention of a CNN model that has been trained on weakly labeled web images.

##### Abstract (translated by Google)
我们的目标是建模一个卷积神经网络（CNN）分类器的自上而下的注意力，用于生成任务特定的注意力图。受到自上而下的人类视觉注意模型的启发，我们提出了一种新的反向传播方案，称为激励反向传播（Excitation Backprop），通过一个概率Winner-Take-All过程在网络层次中向下传递自上而下的信号。此外，我们引入了对比注意的概念，使自上而下的注意力映射更具有歧视性。在实验中，我们证明了我们的方法在MS COCO，PASCAL VOC07和ImageNet数据集上的弱监督定位任务的准确性和一般性。我们的方法的有用性在文本到区域的关联任务中进一步验证。在Flickr30k实体数据集中，我们通过利用已经在弱标记的网页图像上训练的CNN模型的自顶向下的注意力，在短语定位中实现了有希望的性能。

##### URL
[https://arxiv.org/abs/1608.00507](https://arxiv.org/abs/1608.00507)

##### PDF
[https://arxiv.org/pdf/1608.00507](https://arxiv.org/pdf/1608.00507)

