---
layout: post
title: "Single-Channel Speech Separation with Auxiliary Speaker Embeddings"
date: 2019-06-24 14:35:29
categories: arXiv_SD
tags: arXiv_SD Embedding
author: Shuo Liu, Gil Keren, Bj&#xf6;rn Schuller
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel source separation model to decompose asingle-channel speech signal into two speech segments belonging to two different speakers. The proposed model is a neural network based on residual blocks, and uses learnt speaker embeddings created from additional clean context recordings of the two speakers as input to assist in attributing the different time-frequency bins to the two speakers. In experiments, we show that the proposed model yields good performance in the source separation task, and outperforms the state-of-the-art baselines. Specifically, separating speech from the challenging VoxCeleb dataset, the proposed model yields 4.79dB signal-to-distortion ratio, 8.44dB signal-to-artifacts ratio and 7.11dB signal-to-interference ratio.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.09997](http://arxiv.org/abs/1906.09997)

##### PDF
[http://arxiv.org/pdf/1906.09997](http://arxiv.org/pdf/1906.09997)

