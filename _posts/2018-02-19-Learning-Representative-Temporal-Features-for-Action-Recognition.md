---
layout: post
title: "Learning Representative Temporal Features for Action Recognition"
date: 2018-02-19 17:36:24
categories: arXiv_CV
tags: arXiv_CV Tracking Action_Recognition CNN Video_Classification Classification Recognition
author: Ali Javidani, Ahmad Mahmoudi-Aznaveh
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we present a novel video classification methodology that aims to recognize different categories of third-person videos efficiently. The idea is to tracking motion in videos and extracting both short-term and long-term features from motion time series by training a multi-channel one dimensional Convolutional Neural Network (1D-CNN). The positive point about our method is that we only try to learn representative temporal features along the temporal dimension. Spatial features are extracted using pre-trained networks that have already been trained on large scale image recognition datasets. Learning features toward only one dimension reduces the number of calculations significantly and makes our method applicable to even smaller datasets. Furthermore we show that not only our method could reach state-of-the-art results on two public datasets UCF11 and jHMDB, but also we could obtain a strong feature vector representation which in compare with other methods it is much efficient.

##### Abstract (translated by Google)
在本文中，我们提出了一种新颖的视频分类方法，旨在有效识别不同类别的第三方视频。其思想是通过训练多通道一维卷积神经网络（1D-CNN）来跟踪视频中的运动并从运动时间序列中提取短期和长期特征。我们的方法的优点是我们只尝试学习沿时间维度的代表性时间特征。使用预先训练过的网络提取空间特征，这些网络已经在大规模图像识别数据集上进行了训练。只向一个维度学习特征会显着减少计算次数，并使我们的方法适用于更小的数据集。此外，我们表明，不仅我们的方法可以在两个公共数据集UCF11和jHMDB上达到最新的结果，而且我们还可以获得强大的特征向量表示，与其他方法相比，它非常有效。

##### URL
[http://arxiv.org/abs/1802.06724](http://arxiv.org/abs/1802.06724)

##### PDF
[http://arxiv.org/pdf/1802.06724](http://arxiv.org/pdf/1802.06724)

