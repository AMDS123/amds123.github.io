---
layout: post
title: "RPRG: Toward Real-time Robotic Perception, Reasoning and Grasping with One Multi-task Convolutional Neural Network"
date: 2018-09-19 09:08:02
categories: arXiv_RO
tags: arXiv_RO CNN Detection Relation
author: Hanbo Zhang, Xuguang Lan, Lipeng Wan, Chenjie Yang, Xinwen Zhou, Nanning Zheng
mathjax: true
---

* content
{:toc}

##### Abstract
Autonomous robotic grasp plays an important role in intelligent robotics. However, it is challenging due to: (1) robotic grasp is a comprehensive task involving perception, planning and control; (2) autonomous robotic grasp in complex scenarios requires reasoning ability. In this paper, we propose a multi-task convolutional neural network for Robotic Perception, Reasoning and Grasping (RPRG), which can help robot find the target, make the plan for grasping and finally grasp the target step by step in object stacking scenes. We integrate vision-based robotic grasp detection and visual manipulation relationship reasoning in one single deep network and build the autonomous robotic grasp system. The proposed network has state-of-the-art performance in both tasks. Experiments demonstrate that with our model, Baxter robot can autonomously grasp the target with a success rate of 94.2%, 77.1% and 62.5% in object cluttered scenes, familiar stacking scenes and complex stacking scenes respectively at a speed of 6.5 FPS for each detection.

##### Abstract (translated by Google)
自主机器人掌握在智能机器人中起着重要作用。然而，由于以下原因，它具有挑战性：（1）机器人掌握是一项涉及感知，计划和控制的综合任务; （2）复杂场景下的自主机器人掌握需要推理能力。在本文中，我们提出了一个机器人感知，推理和掌握（RPRG）的多任务卷积神经网络，它可以帮助机器人找到目标，制定抓取计划，最后在对象堆叠场景中逐步掌握目标。我们将基于视觉的机器人抓握检测和视觉操纵关系推理集成在一个单一的深度网络中，并构建自动机器人抓取系统。所提出的网络在两个任务中都具有最先进的性能。实验证明，利用我们的模型，百特机器人可以在物体杂乱的场景，熟悉的堆叠场景和复杂的堆叠场景中分别以每个检测6.5 FPS的速度自动地抓住目标，成功率分别为94.2％，77.1％和62.5％。

##### URL
[http://arxiv.org/abs/1809.07081](http://arxiv.org/abs/1809.07081)

##### PDF
[http://arxiv.org/pdf/1809.07081](http://arxiv.org/pdf/1809.07081)

