---
layout: post
title: "The 2015 Sheffield System for Transcription of Multi-Genre Broadcast Media"
date: 2015-12-21 14:31:31
categories: arXiv_CL
tags: arXiv_CL Segmentation Speech_Recognition Language_Model Recognition
author: Oscar Saz, Mortaza Doulaty, Salil Deena, Rosanna Milner, Raymond W.M. Ng, Madina Hasan, Yulan Liu, Thomas Hain
mathjax: true
---

* content
{:toc}

##### Abstract
We describe the University of Sheffield system for participation in the 2015 Multi-Genre Broadcast (MGB) challenge task of transcribing multi-genre broadcast shows. Transcription was one of four tasks proposed in the MGB challenge, with the aim of advancing the state of the art of automatic speech recognition, speaker diarisation and automatic alignment of subtitles for broadcast media. Four topics are investigated in this work: Data selection techniques for training with unreliable data, automatic speech segmentation of broadcast media shows, acoustic modelling and adaptation in highly variable environments, and language modelling of multi-genre shows. The final system operates in multiple passes, using an initial unadapted decoding stage to refine segmentation, followed by three adapted passes: a hybrid DNN pass with input features normalised by speaker-based cepstral normalisation, another hybrid stage with input features normalised by speaker feature-MLLR transformations, and finally a bottleneck-based tandem stage with noise and speaker factorisation. The combination of these three system outputs provides a final error rate of 27.5% on the official development set, consisting of 47 multi-genre shows.

##### Abstract (translated by Google)
我们描述谢菲尔德大学系统参与2015年多类型广播（MGB）挑战任务转录多种类型的广播节目。转录是MGB挑战中提出的四项任务之一，旨在推进自动语音识别技术的发展水平，扬声器分离和广播媒体字幕的自动对齐。本文研究了四个主题：用不可靠数据进行训练的数据选择技术，广播媒体自动语音分段显示，高度可变环境中的声学建模和自适应以及多流派演示的语言建模。最终的系统运行在多个阶段，使用初始的非适应性解码阶段来细化分段，然后是三个适应阶段：具有通过基于说话者的倒谱归一化归一化的输入特征的混合DNN通道，具有通过说话者特征归一化的输入特征的另一个混合阶段， MLLR转换，最后是一个基于瓶颈的串联阶段，带有噪声和扬声器因子分解。这三个系统输出的组合提供了27.5％的官方开发套件的最终错误率，包括47个多种类型的节目。

##### URL
[https://arxiv.org/abs/1512.06643](https://arxiv.org/abs/1512.06643)

##### PDF
[https://arxiv.org/pdf/1512.06643](https://arxiv.org/pdf/1512.06643)

