---
layout: post
title: "Learning to Recognize Actions from Limited Training Examples Using a Recurrent Spiking Neural Model"
date: 2017-10-19 21:07:02
categories: arXiv_CV
tags: arXiv_CV Action_Recognition Relation Recognition
author: Priyadarshini Panda, Narayan Srinivasa
mathjax: true
---

* content
{:toc}

##### Abstract
A fundamental challenge in machine learning today is to build a model that can learn from few examples. Here, we describe a reservoir based spiking neural model for learning to recognize actions with a limited number of labeled videos. First, we propose a novel encoding, inspired by how microsaccades influence visual perception, to extract spike information from raw video data while preserving the temporal correlation across different frames. Using this encoding, we show that the reservoir generalizes its rich dynamical activity toward signature action/movements enabling it to learn from few training examples. We evaluate our approach on the UCF-101 dataset. Our experiments demonstrate that our proposed reservoir achieves 81.3%/87% Top-1/Top-5 accuracy, respectively, on the 101-class data while requiring just 8 video examples per class for training. Our results establish a new benchmark for action recognition from limited video examples for spiking neural models while yielding competetive accuracy with respect to state-of-the-art non-spiking neural models.

##### Abstract (translated by Google)
今天机器学习的一个基本挑战是建立一个可以从少数例子中学习的模型。在这里，我们描述了一个基于水库的尖峰神经模型，用于学习识别有限数量的标记视频的行为。首先，我们提出了一种新颖的编码方式，受到微观视觉如何影响视觉感知的启发，从原始视频数据中提取尖峰信息，同时保留不同帧之间的时间相关性。使用这种编码，我们表明，水库概括其丰富的动态活动对签名行动/运动，使其能够从少数的训练案例学习。我们在UCF-101数据集上评估我们的方法。我们的实验表明，我们提出的储层在101级数据上分别达到了81.3％/ 87％的前1 /前5的准确性，而每类训练只需要8个视频实例。我们的研究结果为有限的视频实例建立了新的动作识别基准，用于峰值神经模型，同时产生与最先进的非尖峰神经模型相比的竞争精度。

##### URL
[https://arxiv.org/abs/1710.07354](https://arxiv.org/abs/1710.07354)

##### PDF
[https://arxiv.org/pdf/1710.07354](https://arxiv.org/pdf/1710.07354)

