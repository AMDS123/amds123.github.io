---
layout: post
title: "Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection"
date: 2017-10-19 23:04:39
categories: arXiv_CL
tags: arXiv_CL
author: Youxuan Jiang, Jonathan K. Kummerfeld, Walter S. Lasecki
mathjax: true
---

* content
{:toc}

##### Abstract
Linguistically diverse datasets are critical for training and evaluating robust machine learning systems, but data collection is a costly process that often requires experts. Crowdsourcing the process of paraphrase generation is an effective means of expanding natural language datasets, but there has been limited analysis of the trade-offs that arise when designing tasks. In this paper, we present the first systematic study of the key factors in crowdsourcing paraphrase collection. We consider variations in instructions, incentives, data domains, and workflows. We manually analyzed paraphrases for correctness, grammaticality, and linguistic diversity. Our observations provide new insight into the trade-offs between accuracy and diversity in crowd responses that arise as a result of task design, providing guidance for future paraphrase generation procedures.

##### Abstract (translated by Google)
语言不同的数据集对训练和评估强大的机器学习系统至关重要，但数据收集是一个昂贵的过程，往往需要专家。将复述生成过程众包是扩展自然语言数据集的有效手段，但对设计任务时出现的权衡分析有限。在本文中，我们首先系统地研究了众包复述收集的关键因素。我们考虑指令，激励，数据域和工作流程的变化。我们手动分析了释义的正确性，语法性和语言多样性。我们的观察结果提供了新的洞察力，以作为任务设计结果引起的人群反应的准确性和多样性之间的权衡，为将来的释义生成过程提供指导。

##### URL
[https://arxiv.org/abs/1704.05753](https://arxiv.org/abs/1704.05753)

##### PDF
[https://arxiv.org/pdf/1704.05753](https://arxiv.org/pdf/1704.05753)

