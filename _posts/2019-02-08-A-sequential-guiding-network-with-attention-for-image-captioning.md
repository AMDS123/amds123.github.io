---
layout: post
title: "A sequential guiding network with attention for image captioning"
date: 2019-02-08 22:35:58
categories: arXiv_CV
tags: arXiv_CV Image_Caption Attention Caption CNN RNN Deep_Learning
author: Daouda Sow, Zengchang Qin, Mouhamed Niasse, Tao Wan
mathjax: true
---

* content
{:toc}

##### Abstract
The recent advances of deep learning in both computer vision (CV) and natural language processing (NLP) provide us a new way of understanding semantics, by which we can deal with more challenging tasks such as automatic description generation from natural images. In this challenge, the encoder-decoder framework has achieved promising performance when a convolutional neural network (CNN) is used as image encoder and a recurrent neural network (RNN) as decoder. In this paper, we introduce a sequential guiding network that guides the decoder during word generation. The new model is an extension of the encoder-decoder framework with attention that has an additional guiding long short-term memory (LSTM) and can be trained in an end-to-end manner by using image/descriptions pairs. We validate our approach by conducting extensive experiments on a benchmark dataset, i.e., MS COCO Captions. The proposed model achieves significant improvement comparing to the other state-of-the-art deep learning models.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1811.00228](https://arxiv.org/abs/1811.00228)

##### PDF
[https://arxiv.org/pdf/1811.00228](https://arxiv.org/pdf/1811.00228)

