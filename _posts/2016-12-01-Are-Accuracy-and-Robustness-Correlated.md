---
layout: post
title: "Are Accuracy and Robustness Correlated?"
date: 2016-12-01 00:54:14
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN Classification Recognition
author: Andras Rozsa, Manuel Günther, Terrance E. Boult
mathjax: true
---

* content
{:toc}

##### Abstract
Machine learning models are vulnerable to adversarial examples formed by applying small carefully chosen perturbations to inputs that cause unexpected classification errors. In this paper, we perform experiments on various adversarial example generation approaches with multiple deep convolutional neural networks including Residual Networks, the best performing models on ImageNet Large-Scale Visual Recognition Challenge 2015. We compare the adversarial example generation techniques with respect to the quality of the produced images, and measure the robustness of the tested machine learning models to adversarial examples. Finally, we conduct large-scale experiments on cross-model adversarial portability. We find that adversarial examples are mostly transferable across similar network topologies, and we demonstrate that better machine learning models are less vulnerable to adversarial examples.

##### Abstract (translated by Google)
机器学习模型容易受到敌对的例子，通过对输入引入意想不到的分类错误的小的仔细选择的扰动形成。在本文中，我们对多种深度卷积神经网络的各种对抗性实例生成方法进行了实验，其中包括剩余网络，这是2015年ImageNet大规模视觉识别挑战赛中表现最好的模型。我们比较了对抗示例生成技术生成的图像，并测试机器学习模型的对抗性的例子的鲁棒性。最后，我们进行跨模式对抗性可移植性的大规模实验。我们发现敌对的例子大都可以通过类似的网络拓扑转移，我们证明更好的机器学习模型不太容易受到敌对的例子。

##### URL
[https://arxiv.org/abs/1610.04563](https://arxiv.org/abs/1610.04563)

##### PDF
[https://arxiv.org/pdf/1610.04563](https://arxiv.org/pdf/1610.04563)

