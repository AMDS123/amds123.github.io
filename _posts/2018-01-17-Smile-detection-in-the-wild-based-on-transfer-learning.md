---
layout: post
title: "Smile detection in the wild based on transfer learning"
date: 2018-01-17 19:58:26
categories: arXiv_CV
tags: arXiv_CV Face CNN Transfer_Learning Detection Recognition Face_Recognition
author: Xin Guo, Luisa F. Polanía, Kenneth E. Barner
mathjax: true
---

* content
{:toc}

##### Abstract
Smile detection from unconstrained facial images is a specialized and challenging problem. As one of the most informative expressions, smiles convey basic underlying emotions, such as happiness and satisfaction, which lead to multiple applications, e.g., human behavior analysis and interactive controlling. Compared to the size of databases for face recognition, far less labeled data is available for training smile detection systems. To leverage the large amount of labeled data from face recognition datasets and to alleviate overfitting on smile detection, an efficient transfer learning-based smile detection approach is proposed in this paper. Unlike previous works which use either hand-engineered features or train deep convolutional networks from scratch, a well-trained deep face recognition model is explored and fine-tuned for smile detection in the wild. Three different models are built as a result of fine-tuning the face recognition model with different inputs, including aligned, unaligned and grayscale images generated from the GENKI-4K dataset. Experiments show that the proposed approach achieves improved state-of-the-art performance. Robustness of the model to noise and blur artifacts is also evaluated in this paper.

##### Abstract (translated by Google)
从无约束的面部图像的微笑检测是一个专门和具有挑战性的问题。作为信息最丰富的表达之一，微笑表达了基本的基本情绪，如快乐和满足感，导致多种应用，例如人类行为分析和交互控制。与用于人脸识别的数据库的大小相比，用于训练微笑检测系统的标签数据少得多。为了充分利用人脸识别数据集中的大量标注数据，减轻笑脸检测的过度拟合，本文提出了一种高效的基于转移学习的笑脸检测方法。与以往使用手工设计特征或从头开始训练深度卷积网络的作品不同，我们探索和训练了一个训练有素的深层人脸识别模型，并对野外微笑检测进行了微调。根据GENKI-4K数据集生成的对齐，未对齐和灰度图像，对不同输入的人脸识别模型进行微调，从而建立了三种不同的模型。实验表明，所提出的方法实现了改进的最新性能。本文还评估了模型对噪声和模糊伪影的鲁棒性。

##### URL
[https://arxiv.org/abs/1802.02185](https://arxiv.org/abs/1802.02185)

##### PDF
[https://arxiv.org/pdf/1802.02185](https://arxiv.org/pdf/1802.02185)

