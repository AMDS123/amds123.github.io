---
layout: post
title: "Learning Cross-Modal Deep Embeddings for Multi-Object Image Retrieval using Text and Sketch"
date: 2018-04-28 15:23:25
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval Attention Embedding
author: Sounak Dey, Anjan Dutta, Suman K. Ghosh, Ernest Valveny, Josep Lladós, Umapada Pal
mathjax: true
---

* content
{:toc}

##### Abstract
In this work we introduce a cross modal image retrieval system that allows both text and sketch as input modalities for the query. A cross-modal deep network architecture is formulated to jointly model the sketch and text input modalities as well as the the image output modality, learning a common embedding between text and images and between sketches and images. In addition, an attention model is used to selectively focus the attention on the different objects of the image, allowing for retrieval with multiple objects in the query. Experiments show that the proposed method performs the best in both single and multiple object image retrieval in standard datasets.

##### Abstract (translated by Google)
在这项工作中，我们介绍一个跨模态图像检索系统，它允许文本和草图作为查询的输入形式。一个跨模态的深层网络架构被设计为联合建模草图和文本输入模式以及图像输出模态，学习文本和图像以及草图和图像之间的常见嵌入。另外，注意模型用于有选择地将注意力集中在图像的不同对象上，允许在查询中使用多个对象进行检索。实验表明，所提出的方法在标准数据集中的单个和多个对象图像检索中表现最好。

##### URL
[https://arxiv.org/abs/1804.10819](https://arxiv.org/abs/1804.10819)

##### PDF
[https://arxiv.org/pdf/1804.10819](https://arxiv.org/pdf/1804.10819)

