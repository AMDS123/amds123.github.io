---
layout: post
title: "Reinforced Continual Learning"
date: 2018-05-31 08:11:12
categories: arXiv_CV
tags: arXiv_CV Knowledge Reinforcement_Learning Classification
author: Ju Xu, Zhanxing Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
Most artificial intelligence models have limiting ability to solve new tasks faster, without forgetting previously acquired knowledge. The recently emerging paradigm of continual learning aims to solve this issue, in which the model learns various tasks in a sequential fashion. In this work, a novel approach for continual learning is proposed, which searches for the best neural architecture for each coming task via sophisticatedly designed reinforcement learning strategies. We name it as Reinforced Continual Learning. Our method not only has good performance on preventing catastrophic forgetting but also fits new tasks well. The experiments on sequential classification tasks for variants of MNIST and CIFAR-100 datasets demonstrate that the proposed approach outperforms existing continual learning alternatives for deep networks.

##### Abstract (translated by Google)
大多数人工智能模型具有更快解决新任务的限制能力，而不会忘记以前获得的知识。最近出现的持续学习范式旨在解决这个问题，其中模型以顺序方式学习各种任务。在这项工作中，提出了一种新颖的连续学习方法，通过精心设计的强化学习策略为每个未来任务寻找最佳的神经架构。我们将其命名为强化持续学习。我们的方法不仅在防止灾难性遗忘方面表现出色，而且也很好地适应了新的任务。针对MNIST和CIFAR-100数据集变体的顺序分类任务的实验表明，所提出的方法优于现有的深度网络连续学习方案。

##### URL
[http://arxiv.org/abs/1805.12369](http://arxiv.org/abs/1805.12369)

##### PDF
[http://arxiv.org/pdf/1805.12369](http://arxiv.org/pdf/1805.12369)

