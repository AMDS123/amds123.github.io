---
layout: post
title: "Improving the Improved Training of Wasserstein GANs: A Consistency Term and Its Dual Effect"
date: 2018-03-05 08:00:39
categories: arXiv_CV
tags: arXiv_CV Adversarial Knowledge GAN
author: Xiang Wei, Boqing Gong, Zixia Liu, Wei Lu, Liqiang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Despite being impactful on a variety of problems and applications, the generative adversarial nets (GANs) are remarkably difficult to train. This issue is formally analyzed by \cite{arjovsky2017towards}, who also propose an alternative direction to avoid the caveats in the minmax two-player training of GANs. The corresponding algorithm, called Wasserstein GAN (WGAN), hinges on the 1-Lipschitz continuity of the discriminator. In this paper, we propose a novel approach to enforcing the Lipschitz continuity in the training procedure of WGANs. Our approach seamlessly connects WGAN with one of the recent semi-supervised learning methods. As a result, it gives rise to not only better photo-realistic samples than the previous methods but also state-of-the-art semi-supervised learning results. In particular, our approach gives rise to the inception score of more than 5.0 with only 1,000 CIFAR-10 images and is the first that exceeds the accuracy of 90% on the CIFAR-10 dataset using only 4,000 labeled images, to the best of our knowledge.

##### Abstract (translated by Google)
尽管对各种问题和应用产生了影响，但生成对抗网络（GAN）难以训练。这个问题由\ cite {arjovsky2017towards}进行正式分析，他们也提出了一种避免GAN的minmax双球员训练中的注意事项的替代方法。称为Wasserstein GAN（WGAN）的相应算法取决于鉴别器的1-Lipschitz连续性。在本文中，我们提出了一种在WGAN的训练过程中实施Lipschitz连续性的新方法。我们的方法将WGAN与最近的半监督学习方法之一无缝连接。结果，它不仅产生了比以前的方法更好的照片拟真样本，而且还产生了最先进的半监督学习结果。特别是，我们的方法提供超过5.0的初始分数，仅有1,000张CIFAR-10图像，并且仅使用4,000张标记图像，第一张图像超过了CIFAR-10数据集90％的准确率，知识。

##### URL
[http://arxiv.org/abs/1803.01541](http://arxiv.org/abs/1803.01541)

##### PDF
[http://arxiv.org/pdf/1803.01541](http://arxiv.org/pdf/1803.01541)

