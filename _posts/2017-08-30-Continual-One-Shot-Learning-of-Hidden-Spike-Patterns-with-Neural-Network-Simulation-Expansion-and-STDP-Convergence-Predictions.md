---
layout: post
title: "Continual One-Shot Learning of Hidden Spike-Patterns with Neural Network Simulation Expansion and STDP Convergence Predictions"
date: 2017-08-30 01:07:18
categories: arXiv_CV
tags: arXiv_CV Prediction Detection
author: Toby Lightheart, Steven Grainger, Tien-Fu Lu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a constructive algorithm that achieves successful one-shot learning of hidden spike-patterns in a competitive detection task. It has previously been shown (Masquelier et al., 2008) that spike-timing-dependent plasticity (STDP) and lateral inhibition can result in neurons competitively tuned to repeating spike-patterns concealed in high rates of overall presynaptic activity. One-shot construction of neurons with synapse weights calculated as estimates of converged STDP outcomes results in immediate selective detection of hidden spike-patterns. The capability of continual learning is demonstrated through the successful one-shot detection of new sets of spike-patterns introduced after long intervals in the simulation time. Simulation expansion (Lightheart et al., 2013) has been proposed as an approach to the development of constructive algorithms that are compatible with simulations of biological neural networks. A simulation of a biological neural network may have orders of magnitude fewer neurons and connections than the related biological neural systems; therefore, simulated neural networks can be assumed to be a subset of a larger neural system. The constructive algorithm is developed using simulation expansion concepts to perform an operation equivalent to the exchange of neurons between the simulation and the larger hypothetical neural system. The dynamic selection of neurons to simulate within a larger neural system (hypothetical or stored in memory) may be a starting point for a wide range of developments and applications in machine learning and the simulation of biology.

##### Abstract (translated by Google)
本文提出了一种构造性的算法，在竞争性检测任务中实现隐藏尖峰模式的成功一次学习。先前已经表明（Masquelier等人，2008），穗定时依赖性可塑性（STDP）和侧向抑制可以导致神经元竞争性地调整以重复突起模式，隐藏在总体突触前活性的高速率中。将突触权重的一次构建的神经元计算为收敛的STDP结果的估计，从而立即选择性地检测隐藏的尖峰模式。连续学习的能力通过在仿真时间内长时间间隔引入新的尖峰模式的成功一次探测来证明。已经提出了仿真扩展（Lightheart等人，2013）作为开发与生物神经网络模拟兼容的构造性算法的方法。生物神经网络的模拟可能比相关的生物神经系统少数量级的神经元和连接;因此，可以假设模拟神经网络是较大神经系统的一个子集。构造算法是利用仿真扩展概念来开发的，以执行相当于仿真与较大的假设神经系统之间的神经元交换的操作。在较大的神经系统（假设的或存储在存储器内）中模拟神经元的动态选择可能是机器学习和生物学模拟的广泛发展和应用的起点。

##### URL
[https://arxiv.org/abs/1708.09072](https://arxiv.org/abs/1708.09072)

##### PDF
[https://arxiv.org/pdf/1708.09072](https://arxiv.org/pdf/1708.09072)

