---
layout: post
title: "No More Discrimination: Cross City Adaptation of Road Scene Segmenters"
date: 2017-04-27 11:14:21
categories: arXiv_CV
tags: arXiv_CV Adversarial Segmentation Semantic_Segmentation
author: Yi-Hsin Chen, Wei-Yu Chen, Yu-Ting Chen, Bo-Cheng Tsai, Yu-Chiang Frank Wang, Min Sun
mathjax: true
---

* content
{:toc}

##### Abstract
Despite the recent success of deep-learning based semantic segmentation, deploying a pre-trained road scene segmenter to a city whose images are not presented in the training set would not achieve satisfactory performance due to dataset biases. Instead of collecting a large number of annotated images of each city of interest to train or refine the segmenter, we propose an unsupervised learning approach to adapt road scene segmenters across different cities. By utilizing Google Street View and its time-machine feature, we can collect unannotated images for each road scene at different times, so that the associated static-object priors can be extracted accordingly. By advancing a joint global and class-specific domain adversarial learning framework, adaptation of pre-trained segmenters to that city can be achieved without the need of any user annotation or interaction. We show that our method improves the performance of semantic segmentation in multiple cities across continents, while it performs favorably against state-of-the-art approaches requiring annotated training data.

##### Abstract (translated by Google)
尽管最近成功的基于深度学习的语义分割，但是将预先训练的道路场景分割器部署到其图像未在训练集中呈现的城市由于数据集偏差而不能获得令人满意的性能。我们提出了一种无监督学习方法来适应不同城市的道路场景分割器，而不是收集每个感兴趣城市的大量注释图像来训练或细化分割器。通过利用Google Street View及其时间机器功能，我们可以在不同的时间为每个道路场景收集未注释的图像，从而相应地提取相关联的静态对象优先级。通过推进联合的全球和特定类别的领域对抗性学习框架，可以实现预先训练的分段器适应该城市，而不需要任何用户注释或交互。我们表明，我们的方法提高了跨大洲的多个城市的语义分割的性能，同时它对需要注释的训练数据的最新方法进行有利的表现。

##### URL
[https://arxiv.org/abs/1704.08509](https://arxiv.org/abs/1704.08509)

##### PDF
[https://arxiv.org/pdf/1704.08509](https://arxiv.org/pdf/1704.08509)

