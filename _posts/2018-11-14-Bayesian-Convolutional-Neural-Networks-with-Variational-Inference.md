---
layout: post
title: "Bayesian Convolutional Neural Networks with Variational Inference"
date: 2018-11-14 13:48:37
categories: arXiv_CV
tags: arXiv_CV Regularization CNN Inference RNN
author: Kumar Shridhar, Felix Laumann, Adrian Llopart Maurin, Martin Olsen, Marcus Liwicki
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce Bayesian convolutional neural networks with variational inference, a variant of convolutional neural networks (CNNs), in which the intractable posterior probability distributions over weights are inferred by Bayes by Backprop. We demonstrate how this reliable variational inference method can serve as a fundamental construct for various network architectures. On multiple datasets in supervised learning settings (MNIST, CIFAR-10, CIFAR-100), our proposed variational inference method achieves performances equivalent to frequentist inference in identical architectures, while the two desiderata, a measure for uncertainty and regularization are incorporated naturally. We examine in detail how this measure for uncertainty, namely the predictive variance, can be decomposed into aleatoric and epistemic uncertainties. In the past, Bayes by Back prop has been successfully implemented in feedforward and recurrent neural networks, but not in convolutional ones. This work represents the extension of the group of Bayesian neural networks with variational inference which encompasses now all three aforementioned types of network architectures.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1806.05978](http://arxiv.org/abs/1806.05978)

##### PDF
[http://arxiv.org/pdf/1806.05978](http://arxiv.org/pdf/1806.05978)

