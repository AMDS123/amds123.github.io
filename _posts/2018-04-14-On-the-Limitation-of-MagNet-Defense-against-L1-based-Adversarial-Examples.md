---
layout: post
title: "On the Limitation of MagNet Defense against $L_1$-based Adversarial Examples"
date: 2018-04-14 05:44:51
categories: arXiv_CV
tags: arXiv_CV Adversarial Object_Detection Deep_Learning Detection
author: Pei-Hsuan Lu, Pin-Yu Chen, Kang-Cheng Chen, Chia-Mu Yu
mathjax: true
---

* content
{:toc}

##### Abstract
In recent years, defending adversarial perturbations to natural examples in order to build robust machine learning models trained by deep neural networks (DNNs) has become an emerging research field in the conjunction of deep learning and security. In particular, MagNet consisting of an adversary detector and a data reformer is by far one of the strongest defenses in the black-box oblivious attack setting, where the attacker aims to craft transferable adversarial examples from an undefended DNN model to bypass an unknown defense module deployed on the same DNN model. Under this setting, MagNet can successfully defend a variety of attacks in DNNs, including the high-confidence adversarial examples generated by the Carlini and Wagner's attack based on the $L_2$ distortion metric. However, in this paper, under the same attack setting we show that adversarial examples crafted based on the $L_1$ distortion metric can easily bypass MagNet and mislead the target DNN image classifiers on MNIST and CIFAR-10. We also provide explanations on why the considered approach can yield adversarial examples with superior attack performance and conduct extensive experiments on variants of MagNet to verify its lack of robustness to $L_1$ distortion based attacks. Notably, our results substantially weaken the assumption of effective threat models on MagNet that require knowing the deployed defense technique when attacking DNNs (i.e., the gray-box attack setting).

##### Abstract (translated by Google)
近年来，为了构建由深度神经网络（DNNs）训练的鲁棒机器学习模型，捍卫对自然例子的敌对扰动已经成为深度学习和安全性相结合的新兴研究领域。尤其是，由对手探测器和数据重组器构成的MagNet是迄今为止黑箱不经意攻击设置中最强有力的防御措施之一，攻击者的目标是从未设防的DNN模型制作可转让的敌对示例，绕过未知的防御模块部署在相同的DNN模型上。在此设置下，MagNet可以成功防御DNN中的各种攻击，包括基于$ L_2 $失真度量的Carlini和Wagner攻击生成的高信度对抗示例。然而，在本文中，在相同的攻击设置下，我们展示基于$ L_1 $失真度量制作的敌对示例可轻松绕过MagNet并误导MNIST和CIFAR-10上的目标DNN图像分类器。我们还解释了为什么所考虑的方法能够产生出色的攻击性能的对抗性例子，并对MagNet变体进行了大量实验，以验证其对基于$ L_1 $失真的攻击的鲁棒性的缺乏。值得注意的是，我们的结果大大削弱了MagNet上的有效威胁模型的假设，这需要在攻击DNN时知道部署的防御技术（即灰箱攻击设置）。

##### URL
[https://arxiv.org/abs/1805.00310](https://arxiv.org/abs/1805.00310)

##### PDF
[https://arxiv.org/pdf/1805.00310](https://arxiv.org/pdf/1805.00310)

