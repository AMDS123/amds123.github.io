---
layout: post
title: "ASSERT: Anti-Spoofing with Squeeze-Excitation and Residual neTworks"
date: 2019-04-01 21:47:00
categories: arXiv_CL
tags: arXiv_CL Attention Optimization
author: Cheng-I Lai, Nanxin Chen, Jes&#xfa;s Villalba, Najim Dehak
mathjax: true
---

* content
{:toc}

##### Abstract
We present JHU's system submission to the ASVspoof 2019 Challenge: Anti-Spoofing with Squeeze-Excitation and Residual neTworks (ASSERT). Anti-spoofing has gathered more and more attention since the inauguration of the ASVspoof Challenges, and ASVspoof 2019 dedicates to address attacks from all three major types: text-to-speech, voice conversion, and replay. Built upon previous research work on Deep Neural Network (DNN), ASSERT is a pipeline for DNN-based approach to anti-spoofing. ASSERT has four components: feature engineering, DNN models, network optimization and system combination, where the DNN models are variants of squeeze-excitation and residual networks. We conducted an ablation study of the effectiveness of each component on the ASVspoof 2019 corpus, and experimental results showed that ASSERT obtained more than 93% and 17% relative improvements over the baseline systems in the two sub-challenges in ASVspooof 2019, ranking ASSERT one of the top performing systems. Code and pretrained models will be made publicly available.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.01120](http://arxiv.org/abs/1904.01120)

##### PDF
[http://arxiv.org/pdf/1904.01120](http://arxiv.org/pdf/1904.01120)

