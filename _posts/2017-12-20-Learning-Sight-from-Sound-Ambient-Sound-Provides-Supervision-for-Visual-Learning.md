---
layout: post
title: "Learning Sight from Sound: Ambient Sound Provides Supervision for Visual Learning"
date: 2017-12-20 00:10:40
categories: arXiv_CV
tags: arXiv_CV CNN Recognition
author: Andrew Owens, Jiajun Wu, Josh H. McDermott, William T. Freeman, Antonio Torralba
mathjax: true
---

* content
{:toc}

##### Abstract
The sound of crashing waves, the roar of fast-moving cars -- sound conveys important information about the objects in our surroundings. In this work, we show that ambient sounds can be used as a supervisory signal for learning visual models. To demonstrate this, we train a convolutional neural network to predict a statistical summary of the sound associated with a video frame. We show that, through this process, the network learns a representation that conveys information about objects and scenes. We evaluate this representation on several recognition tasks, finding that its performance is comparable to that of other state-of-the-art unsupervised learning methods. Finally, we show through visualizations that the network learns units that are selective to objects that are often associated with characteristic sounds. This paper extends an earlier conference paper, Owens et al. 2016, with additional experiments and discussion.

##### Abstract (translated by Google)
轰鸣的声音，快速移动的汽车的轰鸣声，传达了我们周围物体的重要信息。在这项工作中，我们展示了环境声音可以用作学习视觉模型的监督信号。为了证明这一点，我们训练卷积神经网络来预测与视频帧相关的声音的统计总结。我们表明，通过这个过程，网络学习表达传达关于对象和场景的信息。我们评估这种表示在几个识别任务，发现其性能是相当于其他国家的最先进的无监督的学习方法。最后，我们通过可视化表明，网络学习对通常与特征声音相关的对象有选择性的单元。本文延伸了早先的一篇论文Owens et al。 2016年，进行更多的实验和讨论。

##### URL
[https://arxiv.org/abs/1712.07271](https://arxiv.org/abs/1712.07271)

##### PDF
[https://arxiv.org/pdf/1712.07271](https://arxiv.org/pdf/1712.07271)

