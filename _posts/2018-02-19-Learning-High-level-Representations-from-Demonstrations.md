---
layout: post
title: "Learning High-level Representations from Demonstrations"
date: 2018-02-19 12:11:16
categories: arXiv_AI
tags: arXiv_AI Sparse
author: Garrett Andersen, Peter Vrancx, Haitham Bou-Ammar
mathjax: true
---

* content
{:toc}

##### Abstract
Hierarchical learning (HL) is key to solving complex sequential decision problems with long horizons and sparse rewards. It allows learning agents to break-up large problems into smaller, more manageable subtasks. A common approach to HL, is to provide the agent with a number of high-level skills that solve small parts of the overall problem. A major open question, however, is how to identify a suitable set of reusable skills. We propose a principled approach that uses human demonstrations to infer a set of subgoals based on changes in the demonstration dynamics. Using these subgoals, we decompose the learning problem into an abstract high-level representation and a set of low-level subtasks. The abstract description captures the overall problem structure, while subtasks capture desired skills. We demonstrate that we can jointly optimize over both levels of learning. We show that the resulting method significantly outperforms previous baselines on two challenging problems: the Atari 2600 game Montezuma's Revenge, and a simulated robotics problem moving the ant robot through a maze.

##### Abstract (translated by Google)
分层学习（HL）是解决具有长视野和稀疏奖励的复杂顺序决策问题的关键。它允许学习代理将大问题分解为更小，更易管理的子任务。 HL的一个常见方法是向代理人提供一些解决整个问题的小部分的高级技能。然而，一个重要的未解决问题是如何确定一套合适的可重用技能。我们提出了一个原则性的方法，它使用人类的示范来推断一系列基于演示动态变化的子目标。使用这些子目标，我们将学习问题分解为抽象的高级表示和一组低级子任务。抽象描述捕捉整体问题结构，而子任务捕获所需的技能。我们证明，我们可以共同优化两个层次的学习。我们证明，由此产生的方法在两个具有挑战性的问题上明显优于以前的基线：Atari 2600游戏蒙特祖玛的复仇以及模拟机器人学问题，使蚂蚁机器人在迷宫中移动。

##### URL
[http://arxiv.org/abs/1802.06604](http://arxiv.org/abs/1802.06604)

##### PDF
[http://arxiv.org/pdf/1802.06604](http://arxiv.org/pdf/1802.06604)

