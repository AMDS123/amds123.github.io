---
layout: post
title: "Learning to Design Games: Strategic Environments in Reinforcement Learning"
date: 2018-05-23 08:56:12
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Haifeng Zhang, Jun Wang, Zhiming Zhou, Weinan Zhang, Ying Wen, Yong Yu, Wenxin Li
mathjax: true
---

* content
{:toc}

##### Abstract
In typical reinforcement learning (RL), the environment is assumed given and the goal of the learning is to identify an optimal policy for the agent taking actions through its interactions with the environment. In this paper, we extend this setting by considering the environment is not given, but controllable and learnable through its interaction with the agent at the same time. This extension is motivated by environment design scenarios in the real-world, including game design, shopping space design and traffic signal design. Theoretically, we find a dual Markov decision process (MDP) w.r.t. the environment to that w.r.t. the agent, and derive a policy gradient solution to optimizing the parametrized environment. Furthermore, discontinuous environments are addressed by a proposed general generative framework. Our experiments on a Maze game design task show the effectiveness of the proposed algorithms in generating diverse and challenging Mazes against various agent settings.

##### Abstract (translated by Google)
在典型的强化学习（RL）中，假定环境是给定的，并且学习的目标是为代理人通过其与环境的相互作用采取行动来确定最优策略。在本文中，我们通过考虑环境没有给出，而是通过与代理人同时交互来控制和学习来扩展这种设置。这个扩展是由现实世界中的环境设计场景驱动的，包括游戏设计，购物空间设计和交通信号设计。理论上，我们找到一个双重马尔可夫决策过程（MDP）w.r.t.那个w.r.t的环境该代理，并推导出政策梯度解决方案来优化参数化环境。此外，不连续的环境通过提出的一般生成框架来解决。我们在迷宫游戏设计任务上的实验显示了提出的算法在针对各种代理设置生成各种具有挑战性的Maze中的有效性。

##### URL
[http://arxiv.org/abs/1707.01310](http://arxiv.org/abs/1707.01310)

##### PDF
[http://arxiv.org/pdf/1707.01310](http://arxiv.org/pdf/1707.01310)

