---
layout: post
title: "The LAMBADA dataset: Word prediction requiring a broad discourse context"
date: 2016-06-20 09:37:17
categories: arXiv_CL
tags: arXiv_CL Language_Model Prediction
author: Denis Paperno (1), Germán Kruszewski (1), Angeliki Lazaridou (1), Quan Ngoc Pham (1), Raffaella Bernardi (1), Sandro Pezzelle (1), Marco Baroni (1), Gemma Boleda (1), Raquel Fernández (2) ((1) CIMeC - Center for Mind/Brain Sciences, University of Trento, (2) Institute for Logic, Language & Computation, University of Amsterdam)
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce LAMBADA, a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word. To succeed on LAMBADA, computational models cannot simply rely on local context, but must be able to keep track of information in the broader discourse. We show that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-of-the-art language models reaches accuracy above 1% on this novel benchmark. We thus propose LAMBADA as a challenging test set, meant to encourage the development of new models capable of genuine understanding of broad context in natural language text.

##### Abstract (translated by Google)
我们引入了LAMBADA这一数据集，通过一个单词预测任务来评估计算模型对文本理解的能力。拉姆巴达（LAMBADA）是一个叙述性的段落，它们分享了这样一个特征，即如果人们能够看到整个段落的话，他们能够猜出他们的最后一个词，但是如果他们只看到目标词之前的最后一个句子的话。为了在LAMBADA上取得成功，计算模型不能简单地依赖于当地情况，而必须能够在广泛的话语中追踪信息。我们展示LAMBADA是一个广泛的语言现象的范例，并且在这个新颖的基准测试中，没有任何一个最先进的语言模型达到1％以上的精度。因此，我们提出LAMBADA是一个具有挑战性的测试集，旨在鼓励开发能够真正理解自然语言文本的广泛背景的新模型。

##### URL
[https://arxiv.org/abs/1606.06031](https://arxiv.org/abs/1606.06031)

##### PDF
[https://arxiv.org/pdf/1606.06031](https://arxiv.org/pdf/1606.06031)

