---
layout: post
title: "Multi-Agent Manipulation via Locomotion using Hierarchical Sim2Real"
date: 2019-08-13 15:12:02
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Ofir Nachum, Michael Ahn, Hugo Ponte, Shixiang Gu, Vikash Kumar
mathjax: true
---

* content
{:toc}

##### Abstract
Manipulation and locomotion are closely related problems that are often studied in isolation. In this work, we study the problem of coordinating multiple mobile agents to exhibit manipulation behaviors using a reinforcement learning (RL) approach. Our method hinges on the use of hierarchical sim2real -- a simulated environment is used to learn low-level goal-reaching skills, which are then used as the action space for a high-level RL controller, also trained in simulation. The full hierarchical policy is then transferred to the real world in a zero-shot fashion. The application of domain randomization during training enables the learned behaviors to generalize to real-world settings, while the use of hierarchy provides a modular paradigm for learning and transferring increasingly complex behaviors. We evaluate our method on a number of real-world tasks, including coordinated object manipulation in a multi-agent setting. See videos at https://sites.google.com/view/manipulation-via-locomotion

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.05224](http://arxiv.org/abs/1908.05224)

##### PDF
[http://arxiv.org/pdf/1908.05224](http://arxiv.org/pdf/1908.05224)

