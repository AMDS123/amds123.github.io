---
layout: post
title: "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data"
date: 2018-07-08 21:22:11
categories: arXiv_CL
tags: arXiv_CL Embedding Transfer_Learning Inference
author: Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault, Antoine Bordes
mathjax: true
---

* content
{:toc}

##### Abstract
Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available.

##### Abstract (translated by Google)
许多现代NLP系统依赖于先前在大型语料库上以无人监督的方式训练的单词嵌入作为基本特征。然而，为更大的文本块（例如句子）获得嵌入的努力并未如此成功。学习无监督的句子表示的几次尝试都没有达到令人满意的性能，无法被广泛采用。在本文中，我们展示了使用斯坦福自然语言推理数据集的监督数据训练的通用句子表示如何能够在广泛的传递任务中始终优于SkipThought向量等无监督方法。就像计算机视觉如何使用ImageNet获取特征然后可以转移到其他任务一样，我们的工作往往表明自然语言推理对于转移学习与其他NLP任务的适用性。我们的编码器是公开的。

##### URL
[http://arxiv.org/abs/1705.02364](http://arxiv.org/abs/1705.02364)

##### PDF
[http://arxiv.org/pdf/1705.02364](http://arxiv.org/pdf/1705.02364)

