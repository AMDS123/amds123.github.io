---
layout: post
title: "Extraction and Classification of Diving Clips from Continuous Video Footage"
date: 2017-05-25 00:08:40
categories: arXiv_CV
tags: arXiv_CV Knowledge Tracking Classification
author: Aiden Nibali, Zhen He, Stuart Morgan, Daniel Greenwood
mathjax: true
---

* content
{:toc}

##### Abstract
Due to recent advances in technology, the recording and analysis of video data has become an increasingly common component of athlete training programmes. Today it is incredibly easy and affordable to set up a fixed camera and record athletes in a wide range of sports, such as diving, gymnastics, golf, tennis, etc. However, the manual analysis of the obtained footage is a time-consuming task which involves isolating actions of interest and categorizing them using domain-specific knowledge. In order to automate this kind of task, three challenging sub-problems are often encountered: 1) temporally cropping events/actions of interest from continuous video; 2) tracking the object of interest; and 3) classifying the events/actions of interest. Most previous work has focused on solving just one of the above sub-problems in isolation. In contrast, this paper provides a complete solution to the overall action monitoring task in the context of a challenging real-world exemplar. Specifically, we address the problem of diving classification. This is a challenging problem since the person (diver) of interest typically occupies fewer than 1% of the pixels in each frame. The model is required to learn the temporal boundaries of a dive, even though other divers and bystanders may be in view. Finally, the model must be sensitive to subtle changes in body pose over a large number of frames to determine the classification code. We provide effective solutions to each of the sub-problems which combine to provide a highly functional solution to the task as a whole. The techniques proposed can be easily generalized to video footage recorded from other sports.

##### Abstract (translated by Google)
由于近来技术的进步，视频数据的记录和分析已经成为运动员训练计划日益普遍的组成部分。如今，在潜水，体操，高尔夫，网球等各种运动中设置固定照相机和记录运动员是非常容易且可负担得起的。然而，对所获得的镜头的手动分析是耗时的任务其中涉及隔离感兴趣的行为并使用特定于领域的知识对其进行分类。为了使这种任务自动化，经常遇到三个具有挑战性的子问题：1）从连续的视频暂时地裁剪感兴趣的事件/动作; 2）跟踪感兴趣的对象;和3）分类感兴趣的事件/动作。以前的大部分工作都集中在单独解决上述子问题中的一个问题上。相比之下，本文提供了一个完整的解决方案，在一个具有挑战性的现实世界范例的全面行动监测任务。具体来说，我们解决了潜水分类的问题。这是一个具有挑战性的问题，因为感兴趣的人（潜水员）通常占据每帧中像素的少于1％。需要模型来学习潜水的时间边界，尽管其他潜水员和旁观者可能在视野中。最后，模型必须对大量帧中身体姿态的细微变化敏感，以确定分类代码。我们为每个子问题提供有效的解决方案，从而为整个任务提供高度功能性的解决方案。所提出的技术可以容易地推广到从其他运动记录的视频片段。

##### URL
[https://arxiv.org/abs/1705.09003](https://arxiv.org/abs/1705.09003)

##### PDF
[https://arxiv.org/pdf/1705.09003](https://arxiv.org/pdf/1705.09003)

