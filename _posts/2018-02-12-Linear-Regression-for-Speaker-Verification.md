---
layout: post
title: "Linear Regression for Speaker Verification"
date: 2018-02-12 15:23:35
categories: arXiv_SD
tags: arXiv_SD Recognition
author: Xiao-Lei Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a linear regression based back-end for speaker verification. Linear regression is a simple linear model that minimizes the mean squared estimation error between the target and its estimate with a closed form solution, where the target is defined as the ground-truth indicator vectors of utterances. We use the linear regression model to learn speaker models from a front-end, and verify the similarity of two speaker models by a cosine similarity scoring classifier. To evaluate the effectiveness of the linear regression model, we construct three speaker verification systems that use the Gaussian mixture model and identity-vector (GMM/i-vector) front-end, deep neural network and i-vector (DNN/i-vector) front-end, and deep vector (d-vector) front-end as their front-ends, respectively. Our empirical comparison results on the NIST speaker recognition evaluation data sets show that the proposed method outperforms within-class covariance normalization, linear discriminant analysis, and probabilistic linear discriminant analysis, given any of the three front-ends.

##### Abstract (translated by Google)
本文提出了一种基于线性回归的说话人验证后端。线性回归是一种简单的线性模型，它用目标被定义为话语的地面真值指示向量的闭式解决方案来最小化目标及其估计之间的均方估计误差。我们使用线性回归模型从前端学习说话人模型，并通过余弦相似性评分分类器验证两个说话人模型的相似性。为了评估线性回归模型的有效性，我们构造了三个使用高斯混合模型和身份向量（GMM / i向量）前端，深度神经网络和i向量（DNN / i向量）的说话人验证系统）前端，以及深度矢量（d矢量）前端作为它们的前端。我们在NIST说话人识别评估数据集上的实证比较结果表明，在三个前端任何一个的情况下，所提出的方法优于类内协方差归一化，线性判别分析和概率线性判别分析。

##### URL
[http://arxiv.org/abs/1802.04113](http://arxiv.org/abs/1802.04113)

##### PDF
[http://arxiv.org/pdf/1802.04113](http://arxiv.org/pdf/1802.04113)

