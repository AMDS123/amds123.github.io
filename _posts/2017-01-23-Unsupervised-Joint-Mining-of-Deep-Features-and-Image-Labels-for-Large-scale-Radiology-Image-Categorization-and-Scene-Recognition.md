---
layout: post
title: "Unsupervised Joint Mining of Deep Features and Image Labels for Large-scale Radiology Image Categorization and Scene Recognition"
date: 2017-01-23 19:34:22
categories: arXiv_CV
tags: arXiv_CV Image_Caption CNN Optimization Classification Quantitative Recognition
author: Xiaosong Wang, Le Lu, Hoo-chang Shin, Lauren Kim, Mohammadhadi Bagheri, Isabella Nogues, Jianhua Yao, Ronald M. Summers
mathjax: true
---

* content
{:toc}

##### Abstract
The recent rapid and tremendous success of deep convolutional neural networks (CNN) on many challenging computer vision tasks largely derives from the accessibility of the well-annotated ImageNet and PASCAL VOC datasets. Nevertheless, unsupervised image categorization (i.e., without the ground-truth labeling) is much less investigated, yet critically important and difficult when annotations are extremely hard to obtain in the conventional way of "Google Search" and crowd sourcing. We address this problem by presenting a looped deep pseudo-task optimization (LDPO) framework for joint mining of deep CNN features and image labels. Our method is conceptually simple and rests upon the hypothesized "convergence" of better labels leading to better trained CNN models which in turn feed more discriminative image representations to facilitate more meaningful clusters/labels. Our proposed method is validated in tackling two important applications: 1) Large-scale medical image annotation has always been a prohibitively expensive and easily-biased task even for well-trained radiologists. Significantly better image categorization results are achieved via our proposed approach compared to the previous state-of-the-art method. 2) Unsupervised scene recognition on representative and publicly available datasets with our proposed technique is examined. The LDPO achieves excellent quantitative scene classification results. On the MIT indoor scene dataset, it attains a clustering accuracy of 75.3%, compared to the state-of-the-art supervised classification accuracy of 81.0% (when both are based on the VGG-VD model).

##### Abstract (translated by Google)
深度卷积神经网络（CNN）最近在许多具有挑战性的计算机视觉任务上取得了巨大的成功，主要来自于注释良好的ImageNet和PASCAL VOC数据集的可访问性。然而，无监督的图像分类（即没有地面真实性标签）的调查要少得多，但是当以“Google搜索”和众包搜索的传统方式很难获得注释时，这种分类非常重要和困难。我们通过提出一个深层CNN特征和图像标签联合挖掘的深层伪任务优化（LDPO）框架来解决这个问题。我们的方法在概念上是简单的，依靠更好的标签的假设“收敛”，导致更好的训练CNN模型，反过来喂养更多的歧视性图像表示，以促进更有意义的群集/标签。我们提出的方法在解决两个重要的应用中得到验证：1）即使对于训练有素的放射科医生，大规模的医学图像注释一直是一个非常昂贵和容易偏差的任务。与先前的先进方法相比，通过我们提出的方法实现了显着更好的图像分类结果。 2）使用我们提出的技术对代表性和公开可用的数据集进行无监督的场景识别。 LDPO实现了优秀的定量场景分类结果。在麻省理工学院的室内场景数据集中，相比最先进的81.0％的监督分类准确度（两者均基于VGG-VD模型），聚类精度达到75.3％。

##### URL
[https://arxiv.org/abs/1701.06599](https://arxiv.org/abs/1701.06599)

##### PDF
[https://arxiv.org/pdf/1701.06599](https://arxiv.org/pdf/1701.06599)

