---
layout: post
title: "Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information"
date: 2016-06-03 06:40:14
categories: arXiv_CL
tags: arXiv_CL Knowledge QA Attention
author: Yuanzhe Zhang, Kang Liu, Shizhu He, Guoliang Ji, Zhanyi Liu, Hua Wu, Jun Zhao
mathjax: true
---

* content
{:toc}

##### Abstract
With the rapid growth of knowledge bases (KBs) on the web, how to take full advantage of them becomes increasingly important. Knowledge base-based question answering (KB-QA) is one of the most promising approaches to access the substantial knowledge. Meantime, as the neural network-based (NN-based) methods develop, NN-based KB-QA has already achieved impressive results. However, previous work did not put emphasis on question representation, and the question is converted into a fixed vector regardless of its candidate answers. This simple representation strategy is unable to express the proper information of the question. Hence, we present a neural attention-based model to represent the questions dynamically according to the different focuses of various candidate answer aspects. In addition, we leverage the global knowledge inside the underlying KB, aiming at integrating the rich KB information into the representation of the answers. And it also alleviates the out of vocabulary (OOV) problem, which helps the attention model to represent the question more precisely. The experimental results on WEBQUESTIONS demonstrate the effectiveness of the proposed approach.

##### Abstract (translated by Google)
随着知识库（KB）在网络上的快速增长，如何充分利用它们变得越来越重要。基于知识库的问答（KB-QA）是获取实质性知识的最有前途的方法之一。同时，随着神经网络（NN）方法的发展，基于NN的KB-QA方法已经取得了令人瞩目的成果。然而，以前的工作并没有把重点放在问题表示上，而是把问题转换成一个固定的矢量，而不管它的候选答案。这种简单的表示策略无法表达问题的正确信息。因此，我们提出了一个基于神经关注的模型来根据不同的候选答案方面的不同焦点动态地表示问题。另外，我们利用底层知识库中的全球知识，旨在将丰富的知识库信息整合到答案的表示中。同时也减轻了词汇量（OOV）的问题，从而帮助注意模型更准确地表达问题。 WEBQUESTIONS上的实验结果证明了所提出方法的有效性。

##### URL
[https://arxiv.org/abs/1606.00979](https://arxiv.org/abs/1606.00979)

##### PDF
[https://arxiv.org/pdf/1606.00979](https://arxiv.org/pdf/1606.00979)

