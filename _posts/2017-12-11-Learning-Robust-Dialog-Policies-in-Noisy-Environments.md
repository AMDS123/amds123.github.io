---
layout: post
title: "Learning Robust Dialog Policies in Noisy Environments"
date: 2017-12-11 21:22:01
categories: arXiv_CL
tags: arXiv_CL Face Speech_Recognition Reinforcement_Learning Recognition
author: Maryam Fazel-Zarandi, Shang-Wen Li, Jin Cao, Jared Casale, Peter Henderson, David Whitney, Alborz Geramifard
mathjax: true
---

* content
{:toc}

##### Abstract
Modern virtual personal assistants provide a convenient interface for completing daily tasks via voice commands. An important consideration for these assistants is the ability to recover from automatic speech recognition (ASR) and natural language understanding (NLU) errors. In this paper, we focus on learning robust dialog policies to recover from these errors. To this end, we develop a user simulator which interacts with the assistant through voice commands in realistic scenarios with noisy audio, and use it to learn dialog policies through deep reinforcement learning. We show that dialogs generated by our simulator are indistinguishable from human generated dialogs, as determined by human evaluators. Furthermore, preliminary experimental results show that the learned policies in noisy environments achieve the same execution success rate with fewer dialog turns compared to fixed rule-based policies.

##### Abstract (translated by Google)
现代虚拟个人助理提供了一个方便的界面，通过语音命令完成日常任务。这些助手的重要考虑因素是从自动语音识别（ASR）和自然语言理解（NLU）错误中恢复的能力。在本文中，我们重点学习强大的对话策略以从这些错误中恢复。为此，我们开发了一个用户模拟器，通过语音命令，在带有噪音的实际场景中与助手进行交互，并通过深度强化学习来学习对话策略。我们显示由我们的模拟器生成的对话框与人类生成的对话框无法区分，正如人类评估者所确定的那样。此外，初步的实验结果表明，与固定的基于规则的策略相比，在嘈杂环境中学习到的策略实现了相同的执行成功率，对话轮次更少。

##### URL
[http://arxiv.org/abs/1712.04034](http://arxiv.org/abs/1712.04034)

##### PDF
[http://arxiv.org/pdf/1712.04034](http://arxiv.org/pdf/1712.04034)

