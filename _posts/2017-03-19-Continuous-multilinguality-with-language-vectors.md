---
layout: post
title: "Continuous multilinguality with language vectors"
date: 2017-03-19 18:52:15
categories: arXiv_CL
tags: arXiv_CL Inference Language_Model Prediction Relation
author: Robert Östling, Jörg Tiedemann
mathjax: true
---

* content
{:toc}

##### Abstract
Most existing models for multilingual natural language processing (NLP) treat language as a discrete category, and make predictions for either one language or the other. In contrast, we propose using continuous vector representations of language. We show that these can be learned efficiently with a character-based neural language model, and used to improve inference about language varieties not seen during training. In experiments with 1303 Bible translations into 990 different languages, we empirically explore the capacity of multilingual language models, and also show that the language vectors capture genetic relationships between languages.

##### Abstract (translated by Google)
大多数现有的多语言自然语言处理（NLP）模型将语言视为一个独立的类别，并对任何一种语言进行预测。相反，我们建议使用语言的连续向量表示。我们表明，这些可以有效地学习与基于字符的神经语言模型，并用于改善对训练期间未见的语言品种的推论。在1303个圣经翻译成990种不同语言的实验中，我们经验地探索了多语言语言模型的能力，并且还显示语言向量捕捉语言之间的遗传关系。

##### URL
[https://arxiv.org/abs/1612.07486](https://arxiv.org/abs/1612.07486)

##### PDF
[https://arxiv.org/pdf/1612.07486](https://arxiv.org/pdf/1612.07486)

