---
layout: post
title: "ODE Analysis of Stochastic Gradient Methods with Optimism and Anchoring for Minimax Problems and GANs"
date: 2019-05-26 23:05:13
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Gradient_Descent
author: Ernest K. Ryu, Kun Yuan, Wotao Yin
mathjax: true
---

* content
{:toc}

##### Abstract
Despite remarkable empirical success, the training dynamics of generative adversarial networks (GAN), which involves solving a minimax game using stochastic gradients, is still poorly understood. In this work, we analyze last-iterate convergence of simultaneous gradient descent (simGD) and its variants under the assumption of convex-concavity, guided by a continuous-time analysis with differential equations. First, we show that simGD, as is, converges with stochastic sub-gradients under strict convexity in the primal variable. Second, we generalize optimistic simGD to accommodate an optimism rate separate from the learning rate and show its convergence with full gradients. Finally, we present anchored simGD, a new method, and show convergence with stochastic subgradients.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1905.10899](https://arxiv.org/abs/1905.10899)

##### PDF
[https://arxiv.org/pdf/1905.10899](https://arxiv.org/pdf/1905.10899)

