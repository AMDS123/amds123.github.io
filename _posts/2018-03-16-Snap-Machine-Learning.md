---
layout: post
title: "Snap Machine Learning"
date: 2018-03-16 17:37:12
categories: arXiv_AI
tags: arXiv_AI Prediction
author: Celestine Dünner, Thomas Parnell, Dimitrios Sarigiannis, Nikolas Ioannou, Haralampos Pozidis
mathjax: true
---

* content
{:toc}

##### Abstract
We describe an efficient, scalable machine learning library that enables very fast training of generalized linear models. We demonstrate that our library can remove the training time as a bottleneck for machine learning workloads, opening the door to a range of new applications. For instance, it allows more agile development, faster and more fine-grained exploration of the hyper-parameter space, enables scaling to massive datasets and makes frequent re-training of models possible in order to adapt to events as they occur. Our library, named Snap Machine Learning (Snap ML), combines recent advances in machine learning systems and algorithms in a nested manner to reflect the hierarchical architecture of modern distributed systems. This allows us to effectively leverage available network, memory and heterogeneous compute resources. On a terabyte-scale publicly available dataset for click-through-rate prediction in computational advertising, we demonstrate the training of a logistic regression classifier in 1.53 minutes, a 46x improvement over the fastest reported performance.

##### Abstract (translated by Google)
我们描述了一个高效的，可扩展的机器学习库，可以对广义线性模型进行快速培训。我们证明，我们的图书馆可以将培训时间作为机器学习工作负载的瓶颈，为一系列新应用打开大门。例如，它可以实现更敏捷的开发，更快速和更细粒度地探索超参数空间，支持对海量数据集进行扩展，并对模型进行频繁的重新训练，以适应发生的事件。我们的图书馆被命名为Snap Machine Learning（Snap ML），它将嵌入式机器学习系统和算法的最新进展结合起来，以反映现代分布式系统的分层架构。这使我们能够有效利用可用的网络，内存和异构计算资源。在用于计算广告中的点击率预测的TB级公开可用数据集中，我们演示了在1.53分钟内对逻辑回归分类器进行的训练，比最快报告的性能提高了46倍。

##### URL
[https://arxiv.org/abs/1803.06333](https://arxiv.org/abs/1803.06333)

##### PDF
[https://arxiv.org/pdf/1803.06333](https://arxiv.org/pdf/1803.06333)

