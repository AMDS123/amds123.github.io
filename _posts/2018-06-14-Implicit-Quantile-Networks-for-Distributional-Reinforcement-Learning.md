---
layout: post
title: "Implicit Quantile Networks for Distributional Reinforcement Learning"
date: 2018-06-14 14:28:37
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Will Dabney, Georg Ostrovski, David Silver, R&#xe9;mi Munos
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we build on recent advances in distributional reinforcement learning to give a generally applicable, flexible, and state-of-the-art distributional variant of DQN. We achieve this by using quantile regression to approximate the full quantile function for the state-action return distribution. By reparameterizing a distribution over the sample space, this yields an implicitly defined return distribution and gives rise to a large class of risk-sensitive policies. We demonstrate improved performance on the 57 Atari 2600 games in the ALE, and use our algorithm's implicitly defined distributions to study the effects of risk-sensitive policies in Atari games.

##### Abstract (translated by Google)
在这项工作中，我们建立在分布式强化学习方面的最新进展，为DQN提供一个普遍适用的，灵活的和最先进的分布式变体。我们通过使用分位数回归来逼近状态行为回报分布的完整分位数函数来实现这一目标。通过对样本空间上的分布进行重新参数化，这产生了隐式定义的回报分布，并产生了一大类风险敏感型政策。我们演示了ALE中57个Atari 2600游戏的性能提升，并使用我们算法的隐式定义分布来研究Atari游戏中风险敏感策略的影响。

##### URL
[http://arxiv.org/abs/1806.06923](http://arxiv.org/abs/1806.06923)

##### PDF
[http://arxiv.org/pdf/1806.06923](http://arxiv.org/pdf/1806.06923)

