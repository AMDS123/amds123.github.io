---
layout: post
title: "Learning camera viewpoint using CNN to improve 3D body pose estimation"
date: 2016-09-18 17:56:15
categories: arXiv_CV
tags: arXiv_CV Image_Caption Segmentation Pose_Estimation CNN Relation
author: Mona Fathollahi Ghezelghieh, Rangachar Kasturi, Sudeep Sarkar
mathjax: true
---

* content
{:toc}

##### Abstract
The objective of this work is to estimate 3D human pose from a single RGB image. Extracting image representations which incorporate both spatial relation of body parts and their relative depth plays an essential role in accurate3D pose reconstruction. In this paper, for the first time, we show that camera viewpoint in combination to 2D joint lo-cations significantly improves 3D pose accuracy without the explicit use of perspective geometry mathematical models.To this end, we train a deep Convolutional Neural Net-work (CNN) to learn categorical camera viewpoint. To make the network robust against clothing and body shape of the subject in the image, we utilized 3D computer rendering to synthesize additional training images. We test our framework on the largest 3D pose estimation bench-mark, Human3.6m, and achieve up to 20% error reduction compared to the state-of-the-art approaches that do not use body part segmentation.

##### Abstract (translated by Google)
这项工作的目标是从一个单一的RGB图像估计三维人体姿态。结合身体部位的空间关系及其相对深度的图像表示方法，在精确三维姿态重建中起着至关重要的作用。在本文中，我们首次展示了将相机视点与2D关节点相结合，显着提高了三维姿态精度，而不需要明确使用透视几何数学模型。为此，我们训练了深度卷积神经网络（CNN）学习分类摄像机的观点。为了使网络对图像中的主体的衣服和身体形状稳健，我们利用3D计算机渲染来合成额外的训练图像。我们在最大的三维姿态估计基准测试框架Human3.6m上测试了我们的框架，与不使用身体局部分割的最新方法相比，误差降低了20％。

##### URL
[https://arxiv.org/abs/1609.05522](https://arxiv.org/abs/1609.05522)

##### PDF
[https://arxiv.org/pdf/1609.05522](https://arxiv.org/pdf/1609.05522)

