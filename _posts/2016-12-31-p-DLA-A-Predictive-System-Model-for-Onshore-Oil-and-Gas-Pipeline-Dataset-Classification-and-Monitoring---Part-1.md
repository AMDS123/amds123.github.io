---
layout: post
title: "p-DLA: A Predictive System Model for Onshore Oil and Gas Pipeline Dataset Classification and Monitoring - Part 1"
date: 2016-12-31 00:40:17
categories: arXiv_CV
tags: arXiv_CV Sparse Knowledge RNN Classification Prediction Recognition
author: E.N. Osegi
mathjax: true
---

* content
{:toc}

##### Abstract
With the rise in militant activity and rogue behaviour in oil and gas regions around the world, oil pipeline disturbances is on the increase leading to huge losses to multinational operators and the countries where such facilities exist. However, this situation can be averted if adequate predictive monitoring schemes are put in place. We propose in the first part of this paper, an artificial intelligence predictive monitoring system capable of predictive classification and pattern recognition of pipeline datasets. The predictive system is based on a highly sparse predictive Deviant Learning Algorithm (p-DLA) designed to synthesize a sequence of memory predictive clusters for eventual monitoring, control and decision making. The DLA (p-DLA) is compared with a popular machine learning algorithm, the Long Short-Term Memory (LSTM) which is based on a temporal version of the standard feed-forward back-propagation trained artificial neural networks (ANNs). The results of simulations study show impressive results and validates the sparse memory predictive approach which favours the sub-synthesis of a highly compressed and low dimensional knowledge discovery and information prediction scheme. It also shows that the proposed new approach is competitive with a well-known and proven AI approach such as the LSTM.

##### Abstract (translated by Google)
随着世界各地石油天然气地区武装活动和流氓行为的上升，石油管道的动荡不断增加，给跨国运营商和这些国家带来巨大损失。但是，如果有足够的预测监测计划，这种情况可以避免。我们在本文的第一部分提出了一种能够对管线数据集进行预测分类和模式识别的人工智能预测监测系统。预测系统基于高度稀疏的预测性偏差学习算法（p-DLA），该算法设计用于综合用于最终监控，控制和决策的一系列预测内存簇。将DLA（p-DLA）与流行的机器学习算法 - 基于标准前馈后向传播训练的人工神经网络（ANN）的时间版本的长期短期存储器（LSTM）进行比较。模拟研究的结果显示了令人印象深刻的结果，并验证了稀疏记忆预测方法有利于高度压缩和低维知识发现和信息预测方案的子合成。这也表明，提出的新方法是有竞争力的一个众所周知的和验证的人工智能方法，如LSTM。

##### URL
[https://arxiv.org/abs/1701.00040](https://arxiv.org/abs/1701.00040)

##### PDF
[https://arxiv.org/pdf/1701.00040](https://arxiv.org/pdf/1701.00040)

