---
layout: post
title: "TANKER: Distributed Architecture for Named Entity Recognition and Disambiguation"
date: 2017-10-25 09:34:18
categories: arXiv_CL
tags: arXiv_CL Face Summarization Recognition
author: Sandro A. Coelho, Diego Moussallem, Gustavo C. Publio, Diego Esteves
mathjax: true
---

* content
{:toc}

##### Abstract
Named Entity Recognition and Disambiguation (NERD) systems have recently been widely researched to deal with the significant growth of the Web. NERD systems are crucial for several Natural Language Processing (NLP) tasks such as summarization, understanding, and machine translation. However, there is no standard interface specification, i.e. these systems may vary significantly either for exporting their outputs or for processing the inputs. Thus, when a given company desires to implement more than one NERD system, the process is quite exhaustive and prone to failure. In addition, industrial solutions demand critical requirements, e.g., large-scale processing, completeness, versatility, and licenses. Commonly, these requirements impose a limitation, making good NERD models to be ignored by companies. This paper presents TANKER, a distributed architecture which aims to overcome scalability, reliability and failure tolerance limitations related to industrial needs by combining NERD systems. To this end, TANKER relies on a micro-services oriented architecture, which enables agile development and delivery of complex enterprise applications. In addition, TANKER provides a standardized API which makes possible to combine several NERD systems at once.

##### Abstract (translated by Google)
命名实体识别和消除（NERD）系统最近已经被广泛研究，以应对网络的显着增长。 NERD系统对于几个自然语言处理（NLP）任务（例如摘要，理解和机器翻译）是至关重要的。但是，没有标准的接口规范，即这些系统可能会出现显着变化，无论是输出输出还是处理输入。因此，当一个给定的公司希望实施多个NERD系统时，这个过程是非常详尽的，并且容易失败。另外，工业解决方案需要关键的要求，例如大规模处理，完整性，多功能性和许可证。通常情况下，这些要求会加以限制，使得NERD模型被公司所忽视。本文提出了一种分布式架构TANKER，其目的是通过结合NERD系统来克服与工业需求相关的可扩展性，可靠性和容错限制。为此，TANKER依靠面向微服务的架构，从而实现敏捷开发和交付复杂的企业应用程序。另外，TANKER提供了一个标准化的API，可以同时组合多个NERD系统。

##### URL
[https://arxiv.org/abs/1708.09230](https://arxiv.org/abs/1708.09230)

##### PDF
[https://arxiv.org/html/1708.09230](https://arxiv.org/html/1708.09230)

