---
layout: post
title: "Exploiting Spatial Correlation in Convolutional Neural Networks for Activation Value Prediction"
date: 2018-07-21 14:56:30
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition CNN Prediction Relation Recognition
author: Gil Shomron, Uri Weiser
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional neural networks (CNNs) compute their output using weighted-sums of adjacent input elements. This method enables CNNs to achieve state-of-the-art results in a wide range of applications such as computer vision and speech recognition. However, it also comes with the cost of high computational intensity. 
 In this paper we propose to exploit the spatial correlation inherent in CNNs, and use it for value prediction. We show that spatial correlation may be exploited to predict activation values, thus reducing the needed computations in the network. We demonstrate this method with a heuristic that predicts which activations are zero-valued according to nearby activation values, in a scheme we call cross-neuron prediction. Our prediction heuristic reduces the number of multiply-accumulate operations by an average of 40.8%, 36.2%, and 20.8%, with degradation in top-5 accuracy of 2.9%, 5.1%, and 7.6%, for AlexNet, VGG-16, and ResNet-18, respectively.

##### Abstract (translated by Google)
卷积神经网络（CNN）使用相邻输入元素的加权和来计算它们的输出。该方法使CNN能够在诸如计算机视觉和语音识别的广泛应用中实现最先进的结果。然而，它还伴随着高计算强度的成本。
 在本文中，我们建议利用CNN中固有的空间相关性，并将其用于价值预测。我们表明可以利用空间相关性来预测激活值，从而减少网络中所需的计算。我们用一种启发式方法演示了这种方法，该方法根据附近的激活值预测哪些激活是零值，在我们称之为跨神经元预测的方案中。我们的预测启发式算法将乘法累加运算的数量平均减少了40.8％，36.2％和20.8％，AlexNet，VGG-16的前5个精度降低了2.9％，5.1％和7.6％，和ResNet-18，分别。

##### URL
[http://arxiv.org/abs/1807.10598](http://arxiv.org/abs/1807.10598)

##### PDF
[http://arxiv.org/pdf/1807.10598](http://arxiv.org/pdf/1807.10598)

