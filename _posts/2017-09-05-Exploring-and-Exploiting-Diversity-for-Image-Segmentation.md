---
layout: post
title: "Exploring and Exploiting Diversity for Image Segmentation"
date: 2017-09-05 23:30:11
categories: arXiv_CV
tags: arXiv_CV Segmentation Semantic_Segmentation Optimization Inference Recognition
author: Payman Yadollahpour
mathjax: true
---

* content
{:toc}

##### Abstract
Semantic image segmentation is an important computer vision task that is difficult because it consists of both recognition and segmentation. The task is often cast as a structured output problem on an exponentially large output-space, which is typically modeled by a discrete probabilistic model. The best segmentation is found by inferring the Maximum a-Posteriori (MAP) solution over the output distribution defined by the model. Due to limitations in optimization, the model cannot be arbitrarily complex. This leads to a trade-off: devise a more accurate model that incorporates rich high-order interactions between image elements at the cost of inaccurate and possibly intractable optimization OR leverage a tractable model which produces less accurate MAP solutions but may contain high quality solutions as other modes of its output distribution. This thesis investigates the latter and presents a two stage approach to semantic segmentation. In the first stage a tractable segmentation model outputs a set of high probability segmentations from the underlying distribution that are not just minor perturbations of each other. Critically the output of this stage is a diverse set of plausible solutions and not just a single one. In the second stage, a discriminatively trained re-ranking model selects the best segmentation from this set. The re-ranking stage can use much more complex features than what could be tractably used in the segmentation model, allowing a better exploration of the solution space than simply returning the MAP solution. The formulation is agnostic to the underlying segmentation model (e.g. CRF, CNN, etc.) and optimization algorithm, which makes it applicable to a wide range of models and inference methods. Evaluation of the approach on a number of semantic image segmentation benchmark datasets highlight its superiority over inferring the MAP solution.

##### Abstract (translated by Google)
语义图像分割是一个重要的计算机视觉任务，因为它由识别和分割组成，因此很难实现。这个任务常常被作为一个结构化的输出问题投射在一个指数级的大输出空间上，这个输出空间通常是用一个离散的概率模型来建模的。通过推导模型定义的输出分布上的最大后验（MAP）解决方案，找到最佳的分割。由于优化的限制，模型不能任意复杂。这导致了一个权衡：设计一个更精确的模型，其中包含丰富的高阶图像元素之间的相互作用，代价是不准确和可能难以控制的优化，或者利用一个易于处理的模型来生成不太精确的MAP解决方案，但可能包含高质量的解决方案其他输出模式。本文对后者进行了研究，提出了一个两阶段的语义分割方法。在第一阶段，一个易于理解的分割模型从基本分布中输出一组高度概率的分割，这些分割不仅是彼此的微小的扰动。至关重要的是，这个阶段的成果是多种可行的解决方案，而不仅仅是单一的解决方案。在第二阶段，一个有区别地训练的重新排序模型从这个集合中选择最佳的分割。重新排序阶段可以使用比在分割模型中易于使用的更复杂的特征，从而比简单地返回MAP解决方案更好地探索解空间。该公式对底层的分割模型（例如CRF，CNN等）和优化算法是不可知的，这使得它适用于广泛的模型和推理方法。对一些语义图像分割基准数据集的方法进行评估突出了其优于推导MAP解决方案的优势。

##### URL
[https://arxiv.org/abs/1709.01625](https://arxiv.org/abs/1709.01625)

##### PDF
[https://arxiv.org/pdf/1709.01625](https://arxiv.org/pdf/1709.01625)

