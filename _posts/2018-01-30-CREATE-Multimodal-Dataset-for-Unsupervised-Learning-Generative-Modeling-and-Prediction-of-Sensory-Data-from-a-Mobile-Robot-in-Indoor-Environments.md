---
layout: post
title: "CREATE: Multimodal Dataset for Unsupervised Learning, Generative Modeling and Prediction of Sensory Data from a Mobile Robot in Indoor Environments"
date: 2018-01-30 20:40:48
categories: arXiv_RO
tags: arXiv_RO Prediction Detection Relation
author: Simon Brodeur, Simon Carrier, Jean Rouat
mathjax: true
---

* content
{:toc}

##### Abstract
The CREATE database is composed of 14 hours of multimodal recordings from a mobile robotic platform based on the iRobot Create. The various sensors cover vision, audition, motors and proprioception. The dataset has been designed in the context of a mobile robot that can learn multimodal representations of its environment, thanks to its ability to navigate the environment. This ability can also be used to learn the dependencies and relationships between the different modalities of the robot (e.g. vision, audition), as they reflect both the external environment and the internal state of the robot. The provided multimodal dataset is expected to have multiple usages, such as multimodal unsupervised object learning, multimodal prediction and egomotion/causality detection.

##### Abstract (translated by Google)
CREATE数据库由来自基于iRobot Create的移动机器人平台的14小时多模录音组成。各种传感器涵盖视觉，试听，电机和本体感受。该数据集是在移动机器人环境下设计的，可以学习环境的多模式表示，这要归功于其环境导航能力。这种能力也可以用来学习机器人不同形式（例如视觉，听觉）之间的依赖关系和关系，因为它们反映机器人的外部环境和内部状态。所提供的多模态数据集有多种用法，如多模式无监督对象学习，多模式预测和自我/因果关系检测。

##### URL
[http://arxiv.org/abs/1801.10214](http://arxiv.org/abs/1801.10214)

##### PDF
[http://arxiv.org/pdf/1801.10214](http://arxiv.org/pdf/1801.10214)

