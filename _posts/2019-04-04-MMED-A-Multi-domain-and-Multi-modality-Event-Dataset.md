---
layout: post
title: "MMED: A Multi-domain and Multi-modality Event Dataset"
date: 2019-04-04 05:27:10
categories: arXiv_CV
tags: arXiv_CV Knowledge GAN VQA
author: Zhenguo Yan, Zehang Lin, Min Cheng, Qing Li, Wenyin Liu
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we construct and release a multi-domain and multi-modality event dataset (MMED), containing 25,165 textual news articles collected from hundreds of news media sites (e.g., Yahoo News, Google News, CNN News.) and 76,516 image posts shared on Flickr social media, which are annotated according to 412 real-world events. The dataset is collected to explore the problem of organizing heterogeneous data contributed by professionals and amateurs in different data domains, and the problem of transferring event knowledge obtained from one data domain to heterogeneous data domain, thus summarizing the data with different contributors. We hope that the release of the MMED dataset can stimulate innovate research on related challenging problems, such as event discovery, cross-modal (event) retrieval, and visual question answering, etc.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.02354](http://arxiv.org/abs/1904.02354)

##### PDF
[http://arxiv.org/pdf/1904.02354](http://arxiv.org/pdf/1904.02354)

