---
layout: post
title: "Network Dissection: Quantifying Interpretability of Deep Visual Representations"
date: 2017-04-19 16:10:38
categories: arXiv_CV
tags: arXiv_CV CNN
author: David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, Antonio Torralba
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a general framework called Network Dissection for quantifying the interpretability of latent representations of CNNs by evaluating the alignment between individual hidden units and a set of semantic concepts. Given any CNN model, the proposed method draws on a broad data set of visual concepts to score the semantics of hidden units at each intermediate convolutional layer. The units with semantics are given labels across a range of objects, parts, scenes, textures, materials, and colors. We use the proposed method to test the hypothesis that interpretability of units is equivalent to random linear combinations of units, then we apply our method to compare the latent representations of various networks when trained to solve different supervised and self-supervised training tasks. We further analyze the effect of training iterations, compare networks trained with different initializations, examine the impact of network depth and width, and measure the effect of dropout and batch normalization on the interpretability of deep visual representations. We demonstrate that the proposed method can shed light on characteristics of CNN models and training methods that go beyond measurements of their discriminative power.

##### Abstract (translated by Google)
我们提出了一个称为网络解剖的通用框架，通过评估单个隐藏单元和一组语义概念之间的对应关系，来量化CNN潜在表示的可解释性。给定任何CNN模型，所提出的方法利用广泛的视觉概念数据集来评分每个中间卷积层隐藏单元的语义。具有语义的单元在对象，部件，场景，纹理，材料和颜色范围内被赋予标签。我们使用所提出的方法来检验单位的可解释性等价于单位的随机线性组合的假设，然后我们运用我们的方法来比较不同网络的潜在表征在训练时解决不同的监督和自我监督的训练任务。我们进一步分析训练迭代的效果，比较不同初始化训练的网络，检查网络深度和宽度的影响，并测量失落和批量归一化对深度视觉表示可解释性的影响。我们证明了所提出的方法可以揭示CNN模型和训练方法超出其判别能力测量的特征。

##### URL
[https://arxiv.org/abs/1704.05796](https://arxiv.org/abs/1704.05796)

##### PDF
[https://arxiv.org/pdf/1704.05796](https://arxiv.org/pdf/1704.05796)

