---
layout: post
title: "Lip2AudSpec: Speech reconstruction from silent lip movements video"
date: 2017-10-26 16:39:05
categories: arXiv_CV
tags: arXiv_CV RNN Relation Recognition
author: Hassan Akbari, Himani Arora, Liangliang Cao, Nima Mesgarani
mathjax: true
---

* content
{:toc}

##### Abstract
In this study, we propose a deep neural network for reconstructing intelligible speech from silent lip movement videos. We use auditory spectrogram as spectral representation of speech and its corresponding sound generation method resulting in a more natural sounding reconstructed speech. Our proposed network consists of an autoencoder to extract bottleneck features from the auditory spectrogram which is then used as target to our main lip reading network comprising of CNN, LSTM and fully connected layers. Our experiments show that the autoencoder is able to reconstruct the original auditory spectrogram with a 98% correlation and also improves the quality of reconstructed speech from the main lip reading network. Our model, trained jointly on different speakers is able to extract individual speaker characteristics and gives promising results of reconstructing intelligible speech with superior word recognition accuracy.

##### Abstract (translated by Google)
在这项研究中，我们提出了一个深层神经网络来重建从无声的嘴唇运动视频的清晰的语音。我们使用听觉频谱图作为语音的频谱表示及其相应的声音生成方法，导致更加自然的声音重建的语音。我们提出的网络由一个自动编码器组成，从听觉频谱图中提取瓶颈特征，然后作为我们主要的由CNN，LSTM和全连接层构成的唇读网络的目标。我们的实验表明，自动编码器能够以98％的相关性重建原始听觉频谱图，并且还提高了来自主唇读取网络的重构语音的质量。我们的模型，联合训练不同的发言者能够提取个人发言者的特点，并提供有希望的结果重建清晰易懂的语音与优越的文字识别的准确性。

##### URL
[https://arxiv.org/abs/1710.09798](https://arxiv.org/abs/1710.09798)

##### PDF
[https://arxiv.org/pdf/1710.09798](https://arxiv.org/pdf/1710.09798)

