---
layout: post
title: "Approximate FPGA-based LSTMs under Computation Time Constraints"
date: 2018-01-07 13:46:03
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption RNN Quantitative
author: Michalis Rizakis, Stylianos I. Venieris, Alexandros Kouris, Christos-Savvas Bouganis
mathjax: true
---

* content
{:toc}

##### Abstract
Recurrent Neural Networks and in particular Long Short-Term Memory (LSTM) networks have demonstrated state-of-the-art accuracy in several emerging Artificial Intelligence tasks. However, the models are becoming increasingly demanding in terms of computational and memory load. Emerging latency-sensitive applications including mobile robots and autonomous vehicles often operate under stringent computation time constraints. In this paper, we address the challenge of deploying computationally demanding LSTMs at a constrained time budget by introducing an approximate computing scheme that combines iterative low-rank compression and pruning, along with a novel FPGA-based LSTM architecture. Combined in an end-to-end framework, the approximation method's parameters are optimised and the architecture is configured to address the problem of high-performance LSTM execution in time-constrained applications. Quantitative evaluation on a real-life image captioning application indicates that the proposed methods required up to 6.5x less time to achieve the same application-level accuracy compared to a baseline method, while achieving an average of 25x higher accuracy under the same computation time constraints.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1801.02190](https://arxiv.org/abs/1801.02190)

##### PDF
[https://arxiv.org/pdf/1801.02190](https://arxiv.org/pdf/1801.02190)

