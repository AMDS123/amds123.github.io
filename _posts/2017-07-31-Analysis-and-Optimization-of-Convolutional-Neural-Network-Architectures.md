---
layout: post
title: "Analysis and Optimization of Convolutional Neural Network Architectures"
date: 2017-07-31 05:35:12
categories: arXiv_CV
tags: arXiv_CV CNN Optimization Classification Recognition
author: Martin Thoma
mathjax: true
---

* content
{:toc}

##### Abstract
Convolutional Neural Networks (CNNs) dominate various computer vision tasks since Alex Krizhevsky showed that they can be trained effectively and reduced the top-5 error from 26.2 % to 15.3 % on the ImageNet large scale visual recognition challenge. Many aspects of CNNs are examined in various publications, but literature about the analysis and construction of neural network architectures is rare. This work is one step to close this gap. A comprehensive overview over existing techniques for CNN analysis and topology construction is provided. A novel way to visualize classification errors with confusion matrices was developed. Based on this method, hierarchical classifiers are described and evaluated. Additionally, some results are confirmed and quantified for CIFAR-100. For example, the positive impact of smaller batch sizes, averaging ensembles, data augmentation and test-time transformations on the accuracy. Other results, such as the positive impact of learned color transformation on the test accuracy could not be confirmed. A model which has only one million learned parameters for an input size of 32x32x3 and 100 classes and which beats the state of the art on the benchmark dataset Asirra, GTSRB, HASYv2 and STL-10 was developed.

##### Abstract (translated by Google)
卷积神经网络（CNNs）在各种计算机视觉任务中占主导地位，因为Alex Krizhevsky表明，在ImageNet大规模视觉识别挑战中，他们可以有效地训练并将前5个误差从26.2％降低到15.3％。 CNN的许多方面都在各种出版物中进行了检查，但关于神经网络结构分析和构建的文献却很少。这项工作是缩小这一差距的一步。提供了有关CNN分析和拓扑结构的现有技术的综合概述。开发了一种用混淆矩阵可视化分类错误的新方法。基于这种方法，分层分类器被描述和评估。另外，CIFAR-100的一些结果被确认和量化。例如，小批量，平均集合，数据增加和测试时间转换对正确性的积极影响。其他结果，如学习颜色转换对测试精度的积极影响，无法得到证实。开发了一种模型，其输入大小为32x32x3和100个类别，并且在基准数据集Asirra，GTSRB，HASYv2和STL-10上的技术发展水平上仅有一百万学习参数。

##### URL
[https://arxiv.org/abs/1707.09725](https://arxiv.org/abs/1707.09725)

##### PDF
[https://arxiv.org/pdf/1707.09725](https://arxiv.org/pdf/1707.09725)

