---
layout: post
title: "Comparing Attention-based Convolutional and Recurrent Neural Networks: Success and Limitations in Machine Reading Comprehension"
date: 2018-08-27 09:04:22
categories: arXiv_CL
tags: arXiv_CL Adversarial QA Attention CNN Inference RNN
author: Matthias Blohm, Glorianna Jagfeld, Ekta Sood, Xiang Yu, Ngoc Thang Vu
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a machine reading comprehension model based on the compare-aggregate framework with two-staged attention that achieves state-of-the-art results on the MovieQA question answering dataset. To investigate the limitations of our model as well as the behavioral difference between convolutional and recurrent neural networks, we generate adversarial examples to confuse the model and compare to human performance. Furthermore, we assess the generalizability of our model by analyzing its differences to human inference,

##### Abstract (translated by Google)
我们提出了一种机器阅读理解模型，该模型基于比较 - 聚合框架和两阶段关注，在MovieQA问答数据集上实现了最先进的结果。为了研究我们的模型的局限性以及卷积和递归神经网络之间的行为差​​异，我们生成了对抗性的例子来混淆模型并与人类表现进行比较。此外，我们通过分析模型与人类推理的差异来评估模型的普遍性，

##### URL
[http://arxiv.org/abs/1808.08744](http://arxiv.org/abs/1808.08744)

##### PDF
[http://arxiv.org/pdf/1808.08744](http://arxiv.org/pdf/1808.08744)

