---
layout: post
title: "End-to-End Comparative Attention Networks for Person Re-identification"
date: 2017-04-28 16:02:15
categories: arXiv_CV
tags: arXiv_CV Re-identification Attention Person_Re-identification Deep_Learning
author: Hao Liu, Jiashi Feng, Meibin Qi, Jianguo Jiang, Shuicheng Yan
mathjax: true
---

* content
{:toc}

##### Abstract
Person re-identification across disjoint camera views has been widely applied in video surveillance yet it is still a challenging problem. One of the major challenges lies in the lack of spatial and temporal cues, which makes it difficult to deal with large variations of lighting conditions, viewing angles, body poses and occlusions. Recently, several deep learning based person re-identification approaches have been proposed and achieved remarkable performance. However, most of those approaches extract discriminative features from the whole frame at one glimpse without differentiating various parts of the persons to identify. It is essentially important to examine multiple highly discriminative local regions of the person images in details through multiple glimpses for dealing with the large appearance variance. In this paper, we propose a new soft attention based model, i.e., the end to-end Comparative Attention Network (CAN), specifically tailored for the task of person re-identification. The end-to-end CAN learns to selectively focus on parts of pairs of person images after taking a few glimpses of them and adaptively comparing their appearance. The CAN model is able to learn which parts of images are relevant for discerning persons and automatically integrates information from different parts to determine whether a pair of images belongs to the same person. In other words, our proposed CAN model simulates the human perception process to verify whether two images are from the same person. Extensive experiments on three benchmark person re-identification datasets, including CUHK01, CHUHK03 and Market-1501, clearly demonstrate that our proposed end-to-end CAN for person re-identification outperforms well established baselines significantly and offer new state-of-the-art performance.

##### Abstract (translated by Google)
人们在不相交的摄像机视图中重新识别已被广泛应用于视频监控，但仍然是一个具有挑战性的问题。其中一个主要的挑战在于缺乏空间和时间的线索，这使得很难处理光照条件，视角，身体姿势和遮挡的大的变化。近来，已经提出了几种深度学习的人重新识别方法，取得了显着的成绩。然而，这些方法大部分都是从整个框架中提取出有区别的特征，而没有区分人的各个部分来识别。通过多次处理大的出现方差来详细检查人物图像的多个高判别性局部区域是非常重要的。在本文中，我们提出了一种新的基于软注意的模型，即端到端比较注意网络（CAN），专门为人员重新识别而设计。端到端的CAN学习，在对其进行一些瞥见并自适应地比较它们的外观之后，选择性地将焦点对准人对图像的一部分。 CAN模型能够了解图像的哪些部分与识别人员相关，并自动地集成来自不同部分的信息以确定一对图像是否属于同一个人。换句话说，我们提出的CAN模型模拟人类的感知过程来验证两个图像是否来自同一个人。在包括CUHK01，CHUHK03和Market-1501在内的三个基准测试人员重新识别数据集上进行的大量实验清楚地表明，我们提出的用于人员重新识别的端到端CAN显着优于已确定的基线，艺术表演。

##### URL
[https://arxiv.org/abs/1606.04404](https://arxiv.org/abs/1606.04404)

##### PDF
[https://arxiv.org/pdf/1606.04404](https://arxiv.org/pdf/1606.04404)

