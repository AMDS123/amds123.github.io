---
layout: post
title: "ASP:A Fast Adversarial Attack Example Generation Framework based on Adversarial Saliency Prediction"
date: 2018-02-15 21:07:05
categories: arXiv_CV
tags: arXiv_CV Salient Adversarial Image_Classification Classification Prediction
author: Fuxun Yu, Qide Dong, Xiang Chen
mathjax: true
---

* content
{:toc}

##### Abstract
With the excellent accuracy and feasibility, the Neural Networks have been widely applied into the novel intelligent applications and systems. However, with the appearance of the Adversarial Attack, the NN based system performance becomes extremely vulnerable:the image classification results can be arbitrarily misled by the adversarial examples, which are crafted images with human unperceivable pixel-level perturbation. As this raised a significant system security issue, we implemented a series of investigations on the adversarial attack in this work: We first identify an image's pixel vulnerability to the adversarial attack based on the adversarial saliency analysis. By comparing the analyzed saliency map and the adversarial perturbation distribution, we proposed a new evaluation scheme to comprehensively assess the adversarial attack precision and efficiency. Then, with a novel adversarial saliency prediction method, a fast adversarial example generation framework, namely "ASP", is proposed with significant attack efficiency improvement and dramatic computation cost reduction. Compared to the previous methods, experiments show that ASP has at most 12 times speed-up for adversarial example generation, 2 times lower perturbation rate, and high attack success rate of 87% on both MNIST and Cifar10. ASP can be also well utilized to support the data-hungry NN adversarial training. By reducing the attack success rate as much as 90%, ASP can quickly and effectively enhance the defense capability of NN based system to the adversarial attacks.

##### Abstract (translated by Google)
神经网络具有出色的准确性和可行性，已被广泛应用于新型智能应用和系统中。然而，随着对抗攻击的出现，基于神经网络的系统性能变得非常脆弱：图像分类结果可能会被对手的例子任意误导，这些例子是人为无法察觉的像素级扰动的精心制作的图像。由于这引发了一个重大的系统安全问题，我们对这项工作进行了一系列关于敌对攻击的调查：我们首先根据对抗性显着性分析识别图像的像素对攻击对象的易感性。通过比较分析的显着图和对抗性摄动分布，我们提出了一种新的评估方案来综合评估敌对攻击的精度和效率。然后，提出了一种新的对抗性显着性预测方法，提出了一种快速的对抗性示例生成框架，即“ASP”，其具有显着的攻击效率提升和显着的计算成本降低。与以前的方法相比，实验表明，对于MNIST和Cifar10来说，ASP对抗例子生成速度最高可达12倍，扰动率低2倍，攻击成功率高达87％。 ASP也可以很好地用于支持数据饥饿的NN对抗训练。通过将攻击成功率降低90％以上，ASP可以快速有效地提高神经网络系统对敌对攻击的防御能力。

##### URL
[https://arxiv.org/abs/1802.05763](https://arxiv.org/abs/1802.05763)

##### PDF
[https://arxiv.org/pdf/1802.05763](https://arxiv.org/pdf/1802.05763)

