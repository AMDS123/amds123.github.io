---
layout: post
title: "Bridging the Gap: Attending to Discontinuity in Identification of Multiword Expressions"
date: 2019-02-27 18:01:53
categories: arXiv_AI
tags: arXiv_AI Attention CNN Deep_Learning Relation
author: Omid Rohanian, Shiva Taslimipoor, Samaneh Kouchaki, Le An Ha, Ruslan Mitkov
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a new method to tag Multiword Expressions (MWEs) using a linguistically interpretable language-independent deep learning architecture. We specifically target discontinuity, an under-explored aspect that poses a significant challenge to computational treatment of MWEs. Two neural architectures are explored: Graph Convolutional Network (GCN) and multi-head self-attention. GCN leverages dependency parse information, and self-attention attends to long-range relations. We finally propose a combined model that integrates complementary information from both through a gating mechanism. The experiments on a standard multilingual dataset for verbal MWEs show that our model outperforms the baselines not only in the case of discontinuous MWEs but also in overall F-score.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.10667](http://arxiv.org/abs/1902.10667)

##### PDF
[http://arxiv.org/pdf/1902.10667](http://arxiv.org/pdf/1902.10667)

