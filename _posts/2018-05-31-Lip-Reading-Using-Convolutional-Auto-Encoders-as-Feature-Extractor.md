---
layout: post
title: "Lip Reading Using Convolutional Auto Encoders as Feature Extractor"
date: 2018-05-31 08:20:12
categories: arXiv_CV
tags: arXiv_CV CNN Classification Relation Recognition
author: Dharin Parekh, Ankitesh Gupta, Shharrnam Chhatpar, Anmol Yash Kumar, Manasi Kulkarni
mathjax: true
---

* content
{:toc}

##### Abstract
Visual recognition of speech using the lip movement is called Lip-reading. Recent developments in this nascent field uses different neural networks as feature extractors which serve as input to a model which can map the temporal relationship and classify. Though end to end sentence level Lip-reading is the current trend, we proposed a new model which employs word level classification and breaks the set benchmarks for standard datasets. In our model we use convolutional autoencoders as feature extractors which are then fed to a Long short-term memory model. We tested our proposed model on BBC's LRW dataset, MIRACL-VC1 and GRID dataset. Achieving a classification accuracy of 98% on MIRACL-VC1 as compared to 93.4% of the set benchmark (Rekik et al., 2014). On BBC's LRW the proposed model performed better than the baseline model of convolutional neural networks and Long short-term memory model (Garg et al., 2016). Showing the features learned by the models we clearly indicate how the proposed model works better than the baseline model. The same model can also be extended for end to end sentence level classification.

##### Abstract (translated by Google)
使用嘴唇运动的视觉识别称为唇读。这个新兴领域的最新发展使用不同的神经网络作为特征提取器，其作为可以映射时间关系和分类的模型的输入。虽然端到端的句子水平唇阅读是目前的趋势，我们提出了一个新的模型，采用词级分类和打破标准数据集的设置基准。在我们的模型中，我们使用卷积自动编码器作为特征提取器，然后将其馈送到长期短期记忆模型。我们在BBC的LRW数据集，MIRACL-VC1和GRID数据集上测试了我们提出的模型。 MIRACL-VC1的分类准确率为98％，而设定的基准为93.4％（Rekik等，2014）。在BBC的LRW中，所提出的模型比卷积神经网络和Long短期记忆模型的基线模型表现得更好（Garg et al。，2016）。通过显示模型学到的特征，我们清楚地表明了建议的模型如何比基线模型更好地工作。同样的模型也可以扩展到端到端的句子级别分类。

##### URL
[http://arxiv.org/abs/1805.12371](http://arxiv.org/abs/1805.12371)

##### PDF
[http://arxiv.org/pdf/1805.12371](http://arxiv.org/pdf/1805.12371)

