---
layout: post
title: "Neural MultiVoice Models for Expressing Novel Personalities in Dialog"
date: 2018-09-05 05:24:00
categories: arXiv_CL
tags: arXiv_CL Knowledge Prediction
author: Shereen Oraby, Lena Reed, Sharath TS, Shubhangi Tandon, Marilyn Walker
mathjax: true
---

* content
{:toc}

##### Abstract
Natural language generators for task-oriented dialog should be able to vary the style of the output utterance while still effectively realizing the system dialog actions and their associated semantics. While the use of neural generation for training the response generation component of conversational agents promises to simplify the process of producing high quality responses in new domains, to our knowledge, there has been very little investigation of neural generators for task-oriented dialog that can vary their response style, and we know of no experiments on models that can generate responses that are different in style from those seen during training, while still maintain- ing semantic fidelity to the input meaning representation. Here, we show that a model that is trained to achieve a single stylis- tic personality target can produce outputs that combine stylistic targets. We carefully evaluate the multivoice outputs for both semantic fidelity and for similarities to and differences from the linguistic features that characterize the original training style. We show that contrary to our predictions, the learned models do not always simply interpolate model parameters, but rather produce styles that are distinct, and novel from the personalities they were trained on.

##### Abstract (translated by Google)
面向任务的对话的自然语言生成器应该能够改变输出话语的风格，同时仍然有效地实现系统对话动作及其相关的语义。虽然使用神经生成训练会话代理的响应生成组件有望简化在新领域中产生高质量响应的过程，但据我们所知，对于面向任务的对话的神经生成器的研究很少，可能会有所不同他们的反应风格，我们知道在模型上没有实验可以产生与训练期间看到的风格不同的反应，同时仍然保持输入意义表示的语义保真度。在这里，我们展示了经过训练以实现单一风格个性目标的模型可以产生结合风格目标的输出。我们仔细评估多语言输出的语义保真度，以及与原始训练风格特征的语言特征的相似性和差异。我们表明，与我们的预测相反，学习模型并不总是简单地插入模型参数，而是产生独特的风格，并且从他们训练的个性中创造出新颖的风格。

##### URL
[http://arxiv.org/abs/1809.01331](http://arxiv.org/abs/1809.01331)

##### PDF
[http://arxiv.org/pdf/1809.01331](http://arxiv.org/pdf/1809.01331)

