---
layout: post
title: "On the Convergent Properties of Word Embedding Methods"
date: 2016-05-12 19:59:43
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Yingtao Tian, Vivek Kulkarni, Bryan Perozzi, Steven Skiena
mathjax: true
---

* content
{:toc}

##### Abstract
Do word embeddings converge to learn similar things over different initializations? How repeatable are experiments with word embeddings? Are all word embedding techniques equally reliable? In this paper we propose evaluating methods for learning word representations by their consistency across initializations. We propose a measure to quantify the similarity of the learned word representations under this setting (where they are subject to different random initializations). Our preliminary results illustrate that our metric not only measures a intrinsic property of word embedding methods but also correlates well with other evaluation metrics on downstream tasks. We believe our methods are is useful in characterizing robustness -- an important property to consider when developing new word embedding methods.

##### Abstract (translated by Google)
单词嵌入是否通过不同的初始化学习类似的东西？字嵌入实验有多可重复性？所有的字嵌入技术都可靠吗？在本文中，我们提出了评估方法学习词表征的一致性初始化。我们提出了一种措施来量化在这种情况下学习词汇表征的相似性（在哪里受到不同的随机初始化）。我们的初步结果表明，我们的度量不仅衡量字嵌入方法的内在属性，而且还与其他下游任务的评估度量相关联。我们相信我们的方法在表征鲁棒性方面是有用的 - 在开发新的词嵌入方法时需要考虑的重要属性。

##### URL
[https://arxiv.org/abs/1605.03956](https://arxiv.org/abs/1605.03956)

##### PDF
[https://arxiv.org/pdf/1605.03956](https://arxiv.org/pdf/1605.03956)

