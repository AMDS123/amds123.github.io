---
layout: post
title: "ActionFlowNet: Learning Motion Representation for Action Recognition"
date: 2018-02-16 22:15:25
categories: arXiv_CV
tags: arXiv_CV Action_Recognition CNN Recognition
author: Joe Yue-Hei Ng, Jonghyun Choi, Jan Neumann, Larry S. Davis
mathjax: true
---

* content
{:toc}

##### Abstract
Even with the recent advances in convolutional neural networks (CNN) in various visual recognition tasks, the state-of-the-art action recognition system still relies on hand crafted motion feature such as optical flow to achieve the best performance. We propose a multitask learning model ActionFlowNet to train a single stream network directly from raw pixels to jointly estimate optical flow while recognizing actions with convolutional neural networks, capturing both appearance and motion in a single model. We additionally provide insights to how the quality of the learned optical flow affects the action recognition. Our model significantly improves action recognition accuracy by a large margin 31% compared to state-of-the-art CNN-based action recognition models trained without external large scale data and additional optical flow input. Without pretraining on large external labeled datasets, our model, by well exploiting the motion information, achieves competitive recognition accuracy to the models trained with large labeled datasets such as ImageNet and Sport-1M.

##### Abstract (translated by Google)
即使在卷积神经网络（CNN）在各种视觉识别任务中的最新进展中，最先进的动作识别系统仍然依靠手工制作的运动特征（例如光流）来实现最佳性能。我们提出了一个多任务学习模型ActionFlowNet，以直接从原始像素训练单个流网络来联合估计光流，同时识别卷积神经网络的动作，在单个模型中捕获外观和运动。我们还提供了有关如何了解学习光流的质量如何影响动作识别的见解。与没有外部大规模数据和额外光流输入训练的最先进的基于CNN的动作识别模型相比，我们的模型显着提高了动作识别精度31％。如果不对大型外部标记数据集进行预训练，我们的模型通过充分利用运动信息，可以对使用大型标记数据集（如ImageNet和Sport-1M）训练的模型实现有竞争力的识别准确性。

##### URL
[http://arxiv.org/abs/1612.03052](http://arxiv.org/abs/1612.03052)

##### PDF
[http://arxiv.org/pdf/1612.03052](http://arxiv.org/pdf/1612.03052)

