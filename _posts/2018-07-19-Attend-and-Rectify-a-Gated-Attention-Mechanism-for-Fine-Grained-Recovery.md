---
layout: post
title: "Attend and Rectify: a Gated Attention Mechanism for Fine-Grained Recovery"
date: 2018-07-19 09:52:36
categories: arXiv_CV
tags: arXiv_CV Attention CNN Classification Recognition
author: Pau Rodríguez, Josep M. Gonfaus, Guillem Cucurull, F. Xavier Roca, Jordi Gonzàlez
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. It learns to attend to lower-level feature activations without requiring part annotations and uses these activations to update and rectify the output likelihood distribution. In contrast to other approaches, the proposed mechanism is modular, architecture-independent and efficient both in terms of parameters and computation required. Experiments show that networks augmented with our approach systematically improve their classification accuracy and become more robust to clutter. As a result, Wide Residual Networks augmented with our proposal surpasses the state of the art classification accuracies in CIFAR-10, the Adience gender recognition task, Stanford dogs, and UEC Food-100.

##### Abstract (translated by Google)
我们提出了一种新的注意机制来增强卷积神经网络以进行细粒度识别。它学会了参与较低级别的功能激活而无需部分注释，并使用这些激活来更新和纠正输出可能性分布。与其他方法相比，所提出的机制是模块化的，与架构无关的，并且在参数和所需的计算方面都是有效的。实验表明，通过我们的方法增强的网络系统地提高了它们的分类准确性，并且变得更加稳健。因此，广泛的剩余网络增强了我们的建议超过了CIFAR-10，Adience性别识别任务，斯坦福犬和UEC Food-100的最新分类准确度。

##### URL
[https://arxiv.org/abs/1807.07320](https://arxiv.org/abs/1807.07320)

##### PDF
[https://arxiv.org/pdf/1807.07320](https://arxiv.org/pdf/1807.07320)

