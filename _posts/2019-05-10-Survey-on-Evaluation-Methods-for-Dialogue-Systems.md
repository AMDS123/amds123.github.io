---
layout: post
title: "Survey on Evaluation Methods for Dialogue Systems"
date: 2019-05-10 11:14:12
categories: arXiv_AI
tags: arXiv_AI Survey
author: Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen, Sophie Rosset, Eneko Agirre, Mark Cieliebak
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we survey the methods and concepts developed for the evaluation of dialogue systems. Evaluation is a crucial part during the development process. Often, dialogue systems are evaluated by means of human evaluations and questionnaires. However, this tends to be very cost and time intensive. Thus, much work has been put into finding methods, which allow to reduce the involvement of human labour. In this survey, we present the main concepts and methods. For this, we differentiate between the various classes of dialogue systems (task-oriented dialogue systems, conversational dialogue systems, and question-answering dialogue systems). We cover each class by introducing the main technologies developed for the dialogue systems and then by presenting the evaluation methods regarding this class.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.04071](http://arxiv.org/abs/1905.04071)

##### PDF
[http://arxiv.org/pdf/1905.04071](http://arxiv.org/pdf/1905.04071)

