---
layout: post
title: "Video Frame Interpolation by Plug-and-Play Deep Locally Linear Embedding"
date: 2018-07-04 06:49:03
categories: arXiv_CV
tags: arXiv_CV Embedding CNN Deep_Learning
author: Anh-Duc Nguyen, Woojae Kim, Jongyoo Kim, Sanghoon Lee
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a generative framework which takes on the video frame interpolation problem. Our framework, which we call Deep Locally Linear Embedding (DeepLLE), is powered by a deep convolutional neural network (CNN) while it can be used instantly like conventional models. DeepLLE fits an auto-encoding CNN to a set of several consecutive frames and embeds a linearity constraint on the latent codes so that new frames can be generated by interpolating new latent codes. Different from the current deep learning paradigm which requires training on large datasets, DeepLLE works in a plug-and-play and unsupervised manner, and is able to generate an arbitrary number of frames. Thorough experiments demonstrate that without bells and whistles, our method is highly competitive among current state-of-the-art models.

##### Abstract (translated by Google)
我们提出了一个生成框架，它承担了视频帧插值问题。我们的框架，我们称之为深度局部线性嵌入（DeepLLE），由深度卷积神经网络（CNN）提供动力，同时它可以像传统模型一样立即使用。 DeepLLE将自动编码CNN拟合到一组连续的帧中，并在潜码上嵌入线性约束，以便通过插入新的潜码生成新帧。与当前需要对大型数据集进行训练的深度学习范例不同，DeepLLE以即插即用和无监督的方式工作，并且能够生成任意数量的帧。彻底的实验表明，在没有花里胡哨的情况下，我们的方法在当前最先进的模型中具有很强的竞争力。

##### URL
[http://arxiv.org/abs/1807.01462](http://arxiv.org/abs/1807.01462)

##### PDF
[http://arxiv.org/pdf/1807.01462](http://arxiv.org/pdf/1807.01462)

