---
layout: post
title: "End-to-End Joint Learning of Natural Language Understanding and Dialogue Manager"
date: 2017-01-04 08:39:09
categories: arXiv_CL
tags: arXiv_CL Prediction
author: Xuesong Yang, Yun-Nung Chen, Dilek Hakkani-Tur, Paul Crook, Xiujun Li, Jianfeng Gao, Li Deng
mathjax: true
---

* content
{:toc}

##### Abstract
Natural language understanding and dialogue policy learning are both essential in conversational systems that predict the next system actions in response to a current user utterance. Conventional approaches aggregate separate models of natural language understanding (NLU) and system action prediction (SAP) as a pipeline that is sensitive to noisy outputs of error-prone NLU. To address the issues, we propose an end-to-end deep recurrent neural network with limited contextual dialogue memory by jointly training NLU and SAP on DSTC4 multi-domain human-human dialogues. Experiments show that our proposed model significantly outperforms the state-of-the-art pipeline models for both NLU and SAP, which indicates that our joint model is capable of mitigating the affects of noisy NLU outputs, and NLU model can be refined by error flows backpropagating from the extra supervised signals of system actions.

##### Abstract (translated by Google)
自然语言理解和对话政策学习在会话系统中是必不可少的，这些会话系统可以根据当前的用户话语预测下一个系统行为。传统方法将自然语言理解（NLU）和系统行为预测（SAP）的单独模型聚合为对易出错的NLU的噪声输出敏感的流水线。为了解决这个问题，我们通过联合训练NLU和SAP在DSTC4多领域人 - 人对话中提出了一个有限的上下文对话记忆的端到端深度递归神经网络。实验表明，我们提出的模型明显优于NLU和SAP的现有流水线模型，这表明我们的联合模型能够减轻噪声NLU输出的影响，NLU模型可以通过误差流从额外监督的系统动作信号反向传播。

##### URL
[https://arxiv.org/abs/1612.00913](https://arxiv.org/abs/1612.00913)

##### PDF
[https://arxiv.org/pdf/1612.00913](https://arxiv.org/pdf/1612.00913)

