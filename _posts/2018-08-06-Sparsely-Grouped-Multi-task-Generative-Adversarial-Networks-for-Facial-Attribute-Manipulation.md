---
layout: post
title: "Sparsely Grouped Multi-task Generative Adversarial Networks for Facial Attribute Manipulation"
date: 2018-08-06 08:34:07
categories: arXiv_CV
tags: arXiv_CV Adversarial Sparse GAN Style_Transfer
author: Jichao Zhang, Yezhi Shu, Songhua Xu, Gongze Cao, Fan Zhong, Xueying Qin
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, Image-to-Image Translation (IIT) has achieved great progress in image style transfer and semantic context manipulation for images. However, existing approaches require exhaustively labelling training data, which is labor demanding, difficult to scale up, and hard to adapt to a new domain. To overcome such a key limitation, we propose Sparsely Grouped Generative Adversarial Networks (SG-GAN) as a novel approach that can translate images in sparsely grouped datasets where only a few train samples are labelled. Using a one-input multi-output architecture, SG-GAN is well-suited for tackling multi-task learning and sparsely grouped learning tasks. The new model is able to translate images among multiple groups using only a single trained model. To experimentally validate the advantages of the new model, we apply the proposed method to tackle a series of attribute manipulation tasks for facial images as a case study. Experimental results show that SG-GAN can achieve comparable results with state-of-the-art methods on adequately labelled datasets while attaining a superior image translation quality on sparsely grouped datasets.

##### Abstract (translated by Google)
最近，图像到图像翻译（IIT）在图像的图像样式转换和语义上下文操作方面取得了很大的进步。然而，现有方法需要详尽地标记训练数据，这是劳动力要求高，难以扩展，并且难以适应新领域。为了克服这种关键限制，我们提出稀疏分组生成对抗网络（SG-GAN）作为一种新方法，可以在稀疏分组的数据集中转换图像，其中只有少数列车样本被标记。 SG-GAN采用单输入多输出架构，非常适合处理多任务学习和稀疏分组学习任务。新模型只能使用一个训练模型在多个组之间转换图像。为了实验验证新模型的优点，我们应用所提出的方法来处理面部图像的一系列属性操作任务作为案例研究。实验结果表明，SG-GAN可以在充分标记的数据集上使用最先进的方法获得可比较的结果，同时在稀疏分组的数据集上获得优异的图像转换质量。

##### URL
[http://arxiv.org/abs/1805.07509](http://arxiv.org/abs/1805.07509)

##### PDF
[http://arxiv.org/pdf/1805.07509](http://arxiv.org/pdf/1805.07509)

