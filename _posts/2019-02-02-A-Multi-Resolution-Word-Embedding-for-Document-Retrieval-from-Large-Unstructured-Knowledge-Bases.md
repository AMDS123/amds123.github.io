---
layout: post
title: "A Multi-Resolution Word Embedding for Document Retrieval from Large Unstructured Knowledge Bases"
date: 2019-02-02 07:44:41
categories: arXiv_CL
tags: arXiv_CL Knowledge Embedding Language_Model
author: Tolgahan Cakaloglu, Xiaowei Xu
mathjax: true
---

* content
{:toc}

##### Abstract
Deep language models learning a hierarchical representation proved to be a powerful tool for natural language processing, text mining and information retrieval. However, representations that perform well for retrieval must capture semantic meaning at different levels of abstraction or context-scopes. In this paper, we propose a new method to generate multi-resolution word embedding representing documents at multiple resolutions in term of context-scopes. In order to investigate its performance, we use the Stanford Question Answering Dataset (SQuAD) and the Question Answering by Search And Reading (QUASAR) in an open-domain question-answering setting, where the first task is to find documents useful for answering a given question. To this end, we first compare the quality of various text-embedding methods for retrieval performance and give an extensive empirical comparison with the performance of various non-augmented base embeddings with and without multi-resolution representation. We argue that multi-resolution word embeddings are consistently superior to the original counterparts and deep residual neural models specifically trained for retrieval purposes can yield further significant gains when they are used for augmenting those embeddings.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.00663](http://arxiv.org/abs/1902.00663)

##### PDF
[http://arxiv.org/pdf/1902.00663](http://arxiv.org/pdf/1902.00663)

