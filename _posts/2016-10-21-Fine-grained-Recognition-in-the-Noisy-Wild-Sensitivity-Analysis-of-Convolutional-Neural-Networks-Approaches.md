---
layout: post
title: "Fine-grained Recognition in the Noisy Wild: Sensitivity Analysis of Convolutional Neural Networks Approaches"
date: 2016-10-21 12:14:50
categories: arXiv_CV
tags: arXiv_CV CNN Recognition
author: Erik Rodner, Marcel Simon, Robert B. Fisher, Joachim Denzler
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we study the sensitivity of CNN outputs with respect to image transformations and noise in the area of fine-grained recognition. In particular, we answer the following questions (1) how sensitive are CNNs with respect to image transformations encountered during wild image capture?; (2) how can we predict CNN sensitivity?; and (3) can we increase the robustness of CNNs with respect to image degradations? To answer the first question, we provide an extensive empirical sensitivity analysis of commonly used CNN architectures (AlexNet, VGG19, GoogleNet) across various types of image degradations. This allows for predicting CNN performance for new domains comprised by images of lower quality or captured from a different viewpoint. We also show how the sensitivity of CNN outputs can be predicted for single images. Furthermore, we demonstrate that input layer dropout or pre-filtering during test time only reduces CNN sensitivity for high levels of degradation. Experiments for fine-grained recognition tasks reveal that VGG19 is more robust to severe image degradations than AlexNet and GoogleNet. However, small intensity noise can lead to dramatic changes in CNN performance even for VGG19.

##### Abstract (translated by Google)
在本文中，我们研究了CNN输出对细粒度识别领域中图像变换和噪声的敏感性。具体来说，我们回答以下问题（1）CNN在野外图像捕获过程中遇到的图像转换有多敏感？ （2）我们如何预测有线电视新闻网的敏感度？ （3）我们能否增加CNN在图像退化方面的鲁棒性？为了回答第一个问题，我们对各种类型的图像劣化提供了常用的CNN架构（AlexNet，VGG19，GoogleNet）的广泛的经验敏感性分析。这允许预测对于由较低质量的图像或从不同视点捕获的新域的CNN性能。我们还展示了如何能够预测单个图像的CNN输出的灵敏度。此外，我们证明在测试期间输入层丢失或预滤波只会降低高级别退化的CNN灵敏度。对细粒度识别任务的实验表明，VGG19比AlexNet和GoogleNet对严重的图像劣化更有效。然而，即使对于VGG19，小的强度噪声也会导致CNN性能的剧烈变化。

##### URL
[https://arxiv.org/abs/1610.06756](https://arxiv.org/abs/1610.06756)

##### PDF
[https://arxiv.org/pdf/1610.06756](https://arxiv.org/pdf/1610.06756)

