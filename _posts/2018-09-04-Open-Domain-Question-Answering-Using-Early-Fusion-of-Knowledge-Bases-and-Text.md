---
layout: post
title: "Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text"
date: 2018-09-04 03:15:56
categories: arXiv_CL
tags: arXiv_CL Knowledge QA Represenation_Learning Relation
author: Haitian Sun, Bhuwan Dhingra, Manzil Zaheer, Kathryn Mazaitis, Ruslan Salakhutdinov, William W. Cohen
mathjax: true
---

* content
{:toc}

##### Abstract
Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entity-linked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting. Source code is available at https://github.com/OceanskySun/GraftNet .

##### Abstract (translated by Google)
开放域问答（QA）正在从复杂的流水线系统发展到端到端的深度神经网络。已经开发了专门的神经模型，用于单独从文本或知识库（KB）中提取答案。在本文中，我们将看一个更实用的设置，即关于KB和实体链接文本组合的QA，当具有大文本语料库的不完整KB时，这是适当的。基于图表示学习的最新进展，我们提出了一种新的模型GRAFT-Net，用于从包含文本和KB实体和关系的特定于问题的子图中提取答案。我们为此问题构建了一套基准测试任务，改变了问题的难度，培训数据量和KB完整性。我们表明，当使用KB或单独的文本进行测试时，GRAFT-Net与最先进的设备相比具有竞争力，并且在组合设置中大大优于现有方法。源代码可从https://github.com/OceanskySun/GraftNet获得。

##### URL
[http://arxiv.org/abs/1809.00782](http://arxiv.org/abs/1809.00782)

##### PDF
[http://arxiv.org/pdf/1809.00782](http://arxiv.org/pdf/1809.00782)

