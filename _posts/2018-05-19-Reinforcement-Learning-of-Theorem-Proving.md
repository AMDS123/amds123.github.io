---
layout: post
title: "Reinforcement Learning of Theorem Proving"
date: 2018-05-19 10:05:43
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning Inference
author: Cezary Kaliszyk, Josef Urban, Henryk Michalewski, Mirek Olšák
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a theorem proving algorithm that uses practically no domain heuristics for guiding its connection-style proof search. Instead, it runs many Monte-Carlo simulations guided by reinforcement learning from previous proof attempts. We produce several versions of the prover, parameterized by different learning and guiding algorithms. The strongest version of the system is trained on a large corpus of mathematical problems and evaluated on previously unseen problems. The trained system solves within the same number of inferences over 40% more problems than a baseline prover, which is an unusually high improvement in this hard AI domain. To our knowledge this is the first time reinforcement learning has been convincingly applied to solving general mathematical problems on a large scale.

##### Abstract (translated by Google)
我们引入一个定理证明算法，它几乎不使用域试探法来指导它的连接式证明搜索。相反，它运行了许多蒙特卡洛模拟，这些模拟是通过以前的证明尝试的强化学习来指导的。我们生成多种版本的证明器，通过不同的学习和指导算法进行参数化。该系统的最强版本接受了大量数学问题的训练，并评估了以前看不到的问题。训练有素的系统可以在相同数量的推理中解决超过基准证明者40％以上的问题，这是这个硬AI领域的异常高的改进。就我们所知，这是第一次强化学习被有力地应用于大规模解决一般数学问题。

##### URL
[https://arxiv.org/abs/1805.07563](https://arxiv.org/abs/1805.07563)

##### PDF
[https://arxiv.org/pdf/1805.07563](https://arxiv.org/pdf/1805.07563)

