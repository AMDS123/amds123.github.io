---
layout: post
title: "Historical Document Image Segmentation with LDA-Initialized Deep Neural Networks"
date: 2017-10-19 22:43:47
categories: arXiv_CV
tags: arXiv_CV Segmentation Transfer_Learning Classification
author: Michele Alberti, Mathias Seuret, Vinaychandran Pondenkandath, Rolf Ingold, Marcus Liwicki
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present a novel approach to perform deep neural networks layer-wise weight initialization using Linear Discriminant Analysis (LDA). Typically, the weights of a deep neural network are initialized with: random values, greedy layer-wise pre-training (usually as Deep Belief Network or as auto-encoder) or by re-using the layers from another network (transfer learning). Hence, many training epochs are needed before meaningful weights are learned, or a rather similar dataset is required for seeding a fine-tuning of transfer learning. In this paper, we describe how to turn an LDA into either a neural layer or a classification layer. We analyze the initialization technique on historical documents. First, we show that an LDA-based initialization is quick and leads to a very stable initialization. Furthermore, for the task of layout analysis at pixel level, we investigate the effectiveness of LDA-based initialization and show that it outperforms state-of-the-art random weight initialization methods.

##### Abstract (translated by Google)
在本文中，我们提出了一种使用线性判别分析（LDA）执行深层神经网络分层权重初始化的新方法。通常，深度神经网络的权重用随机值，贪婪分层预训练（通常作为Deep Belief Network或自动编码器）或通过重新使用来自其他网络的层（传输学习）来初始化。因此，在学习有意义的权重之前，需要很多训练时期，或者需要一个相当类似的数据集来进行传递学习的微调。在本文中，我们描述如何将LDA变成神经层或分类层。我们分析历史文档的初始化技术。首先，我们展示基于LDA的初始化很快，并导致非常稳定的初始化。此外，针对像素级布局分析的任务，我们研究基于LDA的初始化的有效性，并显示它优于最先进的随机权重初始化方法。

##### URL
[https://arxiv.org/abs/1710.07363](https://arxiv.org/abs/1710.07363)

##### PDF
[https://arxiv.org/pdf/1710.07363](https://arxiv.org/pdf/1710.07363)

