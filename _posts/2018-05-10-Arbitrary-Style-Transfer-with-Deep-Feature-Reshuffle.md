---
layout: post
title: "Arbitrary Style Transfer with Deep Feature Reshuffle"
date: 2018-05-10 17:58:11
categories: arXiv_CV
tags: arXiv_CV Style_Transfer Optimization
author: Shuyang Gu, Congliang Chen, Jing Liao, Lu Yuan
mathjax: true
---

* content
{:toc}

##### Abstract
This paper introduces a novel method by reshuffling deep features (i.e., permuting the spacial locations of a feature map) of the style image for arbitrary style transfer. We theoretically prove that our new style loss based on reshuffle connects both global and local style losses respectively used by most parametric and non-parametric neural style transfer methods. This simple idea can effectively address the challenging issues in existing style transfer methods. On one hand, it can avoid distortions in local style patterns, and allow semantic-level transfer, compared with neural parametric methods. On the other hand, it can preserve globally similar appearance to the style image, and avoid wash-out artifacts, compared with neural non-parametric methods. Based on the proposed loss, we also present a progressive feature-domain optimization approach. The experiments show that our method is widely applicable to various styles, and produces better quality than existing methods.

##### Abstract (translated by Google)
本文介绍了一种新的方法，通过调整样式图像的深部特征（即置换特征地图的空间位置）进行任意样式转换。我们从理论上证明，基于重新洗牌的我们的新风格损失将大多数参数化和非参数化神经风格转移方法分别使用的全局和局部风格损失连接起来。这个简单的想法可以有效解决现有样式转换方法中具有挑战性的问题一方面，与神经参数方法相比，它可以避免局部风格模式的扭曲，并且允许语义水平的转移。另一方面，与神经非参数方法相比，它可以保持与样式图像的全局相似的外观，并且避免洗出伪影。基于提出的损失，我们还提出了一种渐进式特征域优化方法。实验表明，我们的方法广泛适用于各种风格，并产生比现有方法更好的质量。

##### URL
[http://arxiv.org/abs/1805.04103](http://arxiv.org/abs/1805.04103)

##### PDF
[http://arxiv.org/pdf/1805.04103](http://arxiv.org/pdf/1805.04103)

