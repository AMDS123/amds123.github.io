---
layout: post
title: "Evolution-Preserving Dense Trajectory Descriptors"
date: 2017-02-14 00:54:52
categories: arXiv_CV
tags: arXiv_CV Action_Recognition Deep_Learning Recognition
author: Yang Wang, Vinh Tran, Minh Hoai
mathjax: true
---

* content
{:toc}

##### Abstract
Recently Trajectory-pooled Deep-learning Descriptors were shown to achieve state-of-the-art human action recognition results on a number of datasets. This paper improves their performance by applying rank pooling to each trajectory, encoding the temporal evolution of deep learning features computed along the trajectory. This leads to Evolution-Preserving Trajectory (EPT) descriptors, a novel type of video descriptor that significantly outperforms Trajectory-pooled Deep-learning Descriptors. EPT descriptors are defined based on dense trajectories, and they provide complimentary benefits to video descriptors that are not based on trajectories. In particular, we show that the combination of EPT descriptors and VideoDarwin leads to state-of-the-art performance on Hollywood2 and UCF101 datasets.

##### Abstract (translated by Google)
最近，轨迹汇集深度学习描述符被证明可以在许多数据集上获得最先进的人类行为识别结果。本文通过对每个轨迹应用排序池来提高他们的性能，对沿轨迹计算的深度学习特征的时间演化进行编码。这导致了演进保留轨迹（EPT）描述符，这是一种新型的视频描述符，明显优于轨迹集合的深度学习描述符。 EPT描述符是基于密集的轨迹来定义的，它们为不基于轨迹的视频描述符提供了额外的好处。特别是，我们展示了EPT描述符和VideoDarwin的结合导致Hollywood2和UCF101数据集上的最新性能。

##### URL
[https://arxiv.org/abs/1702.04037](https://arxiv.org/abs/1702.04037)

##### PDF
[https://arxiv.org/pdf/1702.04037](https://arxiv.org/pdf/1702.04037)

