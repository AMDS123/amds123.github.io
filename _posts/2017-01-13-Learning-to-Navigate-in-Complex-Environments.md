---
layout: post
title: "Learning to Navigate in Complex Environments"
date: 2017-01-13 11:15:22
categories: arXiv_CV
tags: arXiv_CV Reinforcement_Learning Classification Prediction
author: Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew J. Ballard, Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu, Dharshan Kumaran, Raia Hadsell
mathjax: true
---

* content
{:toc}

##### Abstract
Learning to navigate in complex environments with dynamic elements is an important milestone in developing AI agents. In this work we formulate the navigation question as a reinforcement learning problem and show that data efficiency and task performance can be dramatically improved by relying on additional auxiliary tasks leveraging multimodal sensory inputs. In particular we consider jointly learning the goal-driven reinforcement learning problem with auxiliary depth prediction and loop closure classification tasks. This approach can learn to navigate from raw sensory input in complicated 3D mazes, approaching human-level performance even under conditions where the goal location changes frequently. We provide detailed analysis of the agent behaviour, its ability to localise, and its network activity dynamics, showing that the agent implicitly learns key navigation abilities.

##### Abstract (translated by Google)
学习在具有动态元素的复杂环境中进行导航是开发AI代理的重要里程碑。在这项工作中，我们将导航问题作为一个强化学习问题，并且表明通过利用多模态感官输入的附加辅助任务可以显着提高数据效率和任务性能。具体而言，我们考虑联合学习目标驱动强化学习问题与辅助深度预测和闭环分类任务。这种方法可以学习从复杂的3D迷宫中的原始感官输入导航，即使在目标位置经常变化的情况下也能接近人类的表现。我们对代理行为，本地化能力和网络活动动态进行了详细分析，显示代理隐式学习关键导航能力。

##### URL
[https://arxiv.org/abs/1611.03673](https://arxiv.org/abs/1611.03673)

##### PDF
[https://arxiv.org/pdf/1611.03673](https://arxiv.org/pdf/1611.03673)

