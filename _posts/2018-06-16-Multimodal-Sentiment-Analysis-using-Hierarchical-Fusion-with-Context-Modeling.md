---
layout: post
title: "Multimodal Sentiment Analysis using Hierarchical Fusion with Context Modeling"
date: 2018-06-16 12:05:24
categories: arXiv_CV
tags: arXiv_CV Sentiment
author: N. Majumder, D. Hazarika, A. Gelbukh, E. Cambria, S. Poria
mathjax: true
---

* content
{:toc}

##### Abstract
Multimodal sentiment analysis is a very actively growing field of research. A promising area of opportunity in this field is to improve the multimodal fusion mechanism. We present a novel feature fusion strategy that proceeds in a hierarchical fashion, first fusing the modalities two in two and only then fusing all three modalities. On multimodal sentiment analysis of individual utterances, our strategy outperforms conventional concatenation of features by 1%, which amounts to 5% reduction in error rate. On utterance-level multimodal sentiment analysis of multi-utterance video clips, for which current state-of-the-art techniques incorporate contextual information from other utterances of the same clip, our hierarchical fusion gives up to 2.4% (almost 10% error rate reduction) over currently used concatenation. The implementation of our method is publicly available in the form of open-source code.

##### Abstract (translated by Google)
多模态情绪分析是一个非常积极的研究领域。这一领域的一个有前途的机会领域是改进多模式融合机制。我们提出了一种新颖的特征融合策略，以分层方式进行，首先将模式融合到两个模式中，然后融合所有三种模式。在对单个话语进行多模态情感分析时，我们的策略优于传统的1％特征串联，差错率降低5％。对于多语音视频剪辑的话语级多模态情景分析，对于当前最先进的技术采用来自同一剪辑的其他话语的上下文信息，我们的分层融合提供高达2.4％（差不多10％的差错率减少）超过当前使用的级联。我们的方法的实现以公开源代码的形式公开可用。

##### URL
[http://arxiv.org/abs/1806.06228](http://arxiv.org/abs/1806.06228)

##### PDF
[http://arxiv.org/pdf/1806.06228](http://arxiv.org/pdf/1806.06228)

