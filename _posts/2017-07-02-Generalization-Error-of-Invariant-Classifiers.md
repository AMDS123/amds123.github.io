---
layout: post
title: "Generalization Error of Invariant Classifiers"
date: 2017-07-02 18:58:21
categories: arXiv_CV
tags: arXiv_CV CNN Classification
author: Jure Sokolic, Raja Giryes, Guillermo Sapiro, Miguel R. D. Rodrigues
mathjax: true
---

* content
{:toc}

##### Abstract
This paper studies the generalization error of invariant classifiers. In particular, we consider the common scenario where the classification task is invariant to certain transformations of the input, and that the classifier is constructed (or learned) to be invariant to these transformations. Our approach relies on factoring the input space into a product of a base space and a set of transformations. We show that whereas the generalization error of a non-invariant classifier is proportional to the complexity of the input space, the generalization error of an invariant classifier is proportional to the complexity of the base space. We also derive a set of sufficient conditions on the geometry of the base space and the set of transformations that ensure that the complexity of the base space is much smaller than the complexity of the input space. Our analysis applies to general classifiers such as convolutional neural networks. We demonstrate the implications of the developed theory for such classifiers with experiments on the MNIST and CIFAR-10 datasets.

##### Abstract (translated by Google)
本文研究了不变分类器的泛化误差。特别是，我们考虑了分类任务对于输入的某些变换不变的常见情况，并且分类器被构建（或学习）为对这些变换不变。我们的方法依赖于将输入空间分解为基本空间和一组转换的乘积。我们证明了，虽然非不变分类器的泛化误差与输入空间的复杂度成正比，但不变分类器的泛化误差与基空间的复杂度成正比。我们还得到了一组充分的基本空间和转换集的几何条件，以确保基空间的复杂度远小于输入空间的复杂度。我们的分析适用于一般的分类器，如卷积神经网络。我们用MNIST和CIFAR-10数据集上的实验来证明这种分类器的发展理论的含义。

##### URL
[https://arxiv.org/abs/1610.04574](https://arxiv.org/abs/1610.04574)

##### PDF
[https://arxiv.org/pdf/1610.04574](https://arxiv.org/pdf/1610.04574)

