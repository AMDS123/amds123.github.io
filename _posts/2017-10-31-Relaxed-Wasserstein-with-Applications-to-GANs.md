---
layout: post
title: "Relaxed Wasserstein with Applications to GANs"
date: 2017-10-31 08:39:34
categories: arXiv_CV
tags: arXiv_CV GAN
author: Xin Guo, Johnny Hong, Tianyi Lin, Nan Yang
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel class of statistical divergences called \textit{Relaxed Wasserstein} (RW) divergence. RW divergence generalizes Wasserstein distance and is parametrized by strictly convex, differentiable functions. We establish for RW several key probabilistic properties, which are critical for the success of Wasserstein distances. In particular, we show that RW is dominated by Total Variation (TV) and Wasserstein-$L^2$ distance, and establish continuity, differentiability, and duality representation of RW divergence. Finally, we provide a non-asymptotic moment estimate and a concentration inequality for RW divergence. Our experiments on image generation problems show that RWGANs with Kullback-Leibler (KL) divergence provide competitive performance compared with many state-of-the-art approaches. Empirically, we show that RWGANs possess better convergence properties than WGANs, with competitive inception scores. In comparison to the existing literature in GANs, which are ad-hoc in the choices of cost functions, this new conceptual framework not only provides great flexibility in designing general cost functions, e.g., for applications to GANs, but also allows different cost functions implemented and compared under a unified mathematical framework.

##### Abstract (translated by Google)
我们提出了一种叫做\ textit {Relaxed Wasserstein}（RW）散度的新型统计散度。 RW散度推广Wasserstein距离，并通过严格凸，可微函数进行参数化。我们为RW建立了几个关键的概率性质，这对于Wasserstein距离的成功是至关重要的。具体来说，我们证明了RW是由全变分（TV）和Wasserstein  -  L ^ 2 $距离决定的，建立了RW散度的连续性，可微性和对偶表示。最后，我们给出RW散度的非渐近矩估计和集中不等式。我们对图像生成问题的实验表明，与许多最先进的方法相比，具有Kullback-Leibler（KL）分歧的RWGAN提供了有竞争力的性能。从经验上来看，RWGAN具有比WGAN更好的收敛特性，具有竞争初始分数。与GAN中的现有文献相比，这些文献在成本函数的选择上是特设的，这个新的概念框架不仅在设计一般成本函数方面提供了很大的灵活性，例如用于GAN的应用，而且允许实现不同的成本函数并在统一的数学框架下进行比较。

##### URL
[https://arxiv.org/abs/1705.07164](https://arxiv.org/abs/1705.07164)

##### PDF
[https://arxiv.org/pdf/1705.07164](https://arxiv.org/pdf/1705.07164)

