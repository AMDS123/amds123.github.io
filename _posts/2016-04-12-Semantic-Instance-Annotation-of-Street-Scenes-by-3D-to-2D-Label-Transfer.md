---
layout: post
title: "Semantic Instance Annotation of Street Scenes by 3D to 2D Label Transfer"
date: 2016-04-12 07:08:11
categories: arXiv_CV
tags: arXiv_CV Segmentation Semantic_Segmentation Recognition
author: Jun Xie, Martin Kiefel, Ming-Ting Sun, Andreas Geiger
mathjax: true
---

* content
{:toc}

##### Abstract
Semantic annotations are vital for training models for object recognition, semantic segmentation or scene understanding. Unfortunately, pixelwise annotation of images at very large scale is labor-intensive and only little labeled data is available, particularly at instance level and for street scenes. In this paper, we propose to tackle this problem by lifting the semantic instance labeling task from 2D into 3D. Given reconstructions from stereo or laser data, we annotate static 3D scene elements with rough bounding primitives and develop a model which transfers this information into the image domain. We leverage our method to obtain 2D labels for a novel suburban video dataset which we have collected, resulting in 400k semantic and instance image annotations. A comparison of our method to state-of-the-art label transfer baselines reveals that 3D information enables more efficient annotation while at the same time resulting in improved accuracy and time-coherent labels.

##### Abstract (translated by Google)
语义标注对于对象识别，语义分割或场景理解的训练模型是至关重要的。不幸的是，非常大规模的图像像素注释是劳动密集型的，只有很少的标注数据可用，特别是在实例层面和街道场景。在本文中，我们建议通过将语义实例标注任务从2D提升到3D来解决这个问题。给定从立体或激光数据重建，我们注释静态三维场景元素与粗糙的边界原语，并开发出一个模型，将这种信息转移到图像域。我们利用我们的方法获取我们收集的一个新颖的郊区视频数据集的二维标签，从而产生400k个语义和实例图像注释。我们的方法与最先进的标签转印基线的比较揭示了3D信息能够实现更有效的注释，同时导致改进的准确性和时间相关标签。

##### URL
[https://arxiv.org/abs/1511.03240](https://arxiv.org/abs/1511.03240)

##### PDF
[https://arxiv.org/pdf/1511.03240](https://arxiv.org/pdf/1511.03240)

