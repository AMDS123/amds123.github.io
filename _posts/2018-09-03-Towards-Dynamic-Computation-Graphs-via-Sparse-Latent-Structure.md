---
layout: post
title: "Towards Dynamic Computation Graphs via Sparse Latent Structure"
date: 2018-09-03 16:52:19
categories: arXiv_CL
tags: arXiv_CL Sparse Knowledge Inference
author: Vlad Niculae, Andr&#xe9; F. T. Martins, Claire Cardie
mathjax: true
---

* content
{:toc}

##### Abstract
Deep NLP models benefit from underlying structures in the data---e.g., parse trees---typically extracted using off-the-shelf parsers. Recent attempts to jointly learn the latent structure encounter a tradeoff: either make factorization assumptions that limit expressiveness, or sacrifice end-to-end differentiability. Using the recently proposed SparseMAP inference, which retrieves a sparse distribution over latent structures, we propose a novel approach for end-to-end learning of latent structure predictors jointly with a downstream predictor. To the best of our knowledge, our method is the first to enable unrestricted dynamic computation graph construction from the global latent structure, while maintaining differentiability.

##### Abstract (translated by Google)
深度NLP模型受益于数据中的底层结构 - 例如，解析树 - 通常使用现成的解析器提取。最近共同学习潜在结构的尝试遇到了一个权衡：要么使分解假设限制表达性，要么牺牲端到端的可分性。使用最近提出的SparseMAP推理，它检索潜在结构上的稀疏分布，我们提出了一种新方法，用于与潜在结构预测器的端到端学习以及下游预测器。据我们所知，我们的方法是第一个从全局潜在结构中实现无限制动态计算图构建，同时保持可微性的方法。

##### URL
[http://arxiv.org/abs/1809.00653](http://arxiv.org/abs/1809.00653)

##### PDF
[http://arxiv.org/pdf/1809.00653](http://arxiv.org/pdf/1809.00653)

