---
layout: post
title: "Look at Boundary: A Boundary-Aware Face Alignment Algorithm"
date: 2018-05-26 13:19:02
categories: arXiv_CV
tags: arXiv_CV Face Relation
author: Wayne Wu, Chen Qian, Shuo Yang, Quan Wang, Yici Cai, Qiang Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel boundary-aware face alignment algorithm by utilising boundary lines as the geometric structure of a human face to help facial landmark localisation. Unlike the conventional heatmap based method and regression based method, our approach derives face landmarks from boundary lines which remove the ambiguities in the landmark definition. Three questions are explored and answered by this work: 1. Why using boundary? 2. How to use boundary? 3. What is the relationship between boundary estimation and landmarks localisation? Our boundary- aware face alignment algorithm achieves 3.49% mean error on 300-W Fullset, which outperforms state-of-the-art methods by a large margin. Our method can also easily integrate information from other datasets. By utilising boundary information of 300-W dataset, our method achieves 3.92% mean error with 0.39% failure rate on COFW dataset, and 1.25% mean error on AFLW-Full dataset. Moreover, we propose a new dataset WFLW to unify training and testing across different factors, including poses, expressions, illuminations, makeups, occlusions, and blurriness. Dataset and model will be publicly available at https://wywu.github.io/projects/LAB/LAB.html

##### Abstract (translated by Google)
我们通过利用边界线作为人脸的几何结构来帮助面部地标定位，提出了一种新的边界感知人脸对准算法。与传统的基于热图的方法和基于回归的方法不同，我们的方法从边界线中导出面部标志，消除了界标定义中的模糊性。本工作探讨并回答了三个问题：1.为什么使用边界？ 2.如何使用边界？ 3.边界估计和地标本地化之间的关系是什么？我们的边界意识面对齐算法在300W Fullset上实现了3.49％的均值误差，这大大超过了当前最先进的方法。我们的方法也可以轻松地整合来自其他数据集的信息。通过利用300W数据集的边界信息，我们的方法实现了3.92％的平均误差，在COFW数据集上的失败率为0.39％，在AFLW-Full数据集上的平均误差为1.25％。此外，我们提出了一个新的数据集WFLW，以统一不同因素的训练和测试，包括姿势，表情，照明，化妆，遮挡和模糊。数据集和模型将在https://wywu.github.io/projects/LAB/LAB.html上公开提供

##### URL
[http://arxiv.org/abs/1805.10483](http://arxiv.org/abs/1805.10483)

##### PDF
[http://arxiv.org/pdf/1805.10483](http://arxiv.org/pdf/1805.10483)

