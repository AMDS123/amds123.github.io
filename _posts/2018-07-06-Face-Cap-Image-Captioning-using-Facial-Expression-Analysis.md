---
layout: post
title: "Face-Cap: Image Captioning using Facial Expression Analysis"
date: 2018-07-06 04:12:20
categories: arXiv_CV
tags: arXiv_CV Image_Caption Face Caption Relation
author: Omid Mohamad Nezami, Mark Dras, Peter Anderson, Len Hamey
mathjax: true
---

* content
{:toc}

##### Abstract
Image captioning is the process of generating a natural language description of an image. Most current image captioning models, however, do not take into account the emotional aspect of an image, which is very relevant to activities and interpersonal relationships represented therein. Towards developing a model that can produce human-like captions incorporating these, we use facial expression features extracted from images including human faces, with the aim of improving the descriptive ability of the model. In this work, we present two variants of our Face-Cap model, which embed facial expression features in different ways, to generate image captions. Using all standard evaluation metrics, our Face-Cap models outperform a state-of-the-art baseline model for generating image captions when applied to an image caption dataset extracted from the standard Flickr 30K dataset, consisting of around 11K images containing faces. An analysis of the captions finds that, perhaps surprisingly, the improvement in caption quality appears to come not from the addition of adjectives linked to emotional aspects of the images, but from more variety in the actions described in the captions.

##### Abstract (translated by Google)
图像字幕是生成图像的自然语言描述的过程。然而，大多数当前的图像字幕模型没有考虑图像的情绪方面，这与其中表示的活动和人际关系非常相关。为了开发一种可以生成包含这些类似人类字幕的模型，我们使用从包括人脸在内的图像中提取的面部表情特征，旨在提高模型的描述能力。在这项工作中，我们提出了两种Face-Cap模型，它以不同的方式嵌入面部表情特征，以生成图像标题。使用所有标准评估指标，我们的Face-Cap模型在应用于从标准Flickr 30K数据集中提取的图像标题数据集时，优于用于生成图像标题的最先进基线模型，该数据集包含大约11K个包含面部的图像。对字幕的分析发现，或许令人惊讶的是，字幕质量的提高似乎不是来自添加与图像的情感方面相关的形容词，而是来自字幕中描述的动作的更多变化。

##### URL
[http://arxiv.org/abs/1807.02250](http://arxiv.org/abs/1807.02250)

##### PDF
[http://arxiv.org/pdf/1807.02250](http://arxiv.org/pdf/1807.02250)

