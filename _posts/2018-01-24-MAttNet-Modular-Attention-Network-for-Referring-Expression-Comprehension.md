---
layout: post
title: "MAttNet: Modular Attention Network for Referring Expression Comprehension"
date: 2018-01-24 20:54:26
categories: arXiv_AI
tags: arXiv_AI Attention Relation
author: Licheng Yu, Zhe Lin, Xiaohui Shen, Jimei Yang, Xin Lu, Mohit Bansal, Tamara L.Berg
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we address referring expression comprehension: localizing an image region described by a natural language expression. While most recent work treats expressions as a single unit, we propose to decompose them into three modular components related to subject appearance, location, and relationship to other objects. This allows us to flexibly adapt to expressions containing different types of information in an end-to-end framework. In our model, which we call the Modular Attention Network (MAttNet), two types of attention are utilized: language-based attention that learns the module weights as well as the word/phrase attention that each module should focus on; and visual attention that allows the subject and relationship modules to focus on relevant image components. Module weights combine scores from all three modules dynamically to output an overall score. Experiments show that MAttNet outperforms previous state-of-art methods by a large margin on both bounding-box-level and pixel-level comprehension tasks.

##### Abstract (translated by Google)
在本文中，我们解决表达式的理解：定位由自然语言表达描述的图像区域。虽然最近的工作把表达看作是一个单一的单元，但是我们建议将它们分解成与主体外观，位置和与其他对象的关系的三个模块化组件。这使我们能够灵活地适应在端到端框架中包含不同类型信息的表达式。在我们称为模块化注意网络（MAttNet）的模型中，利用了两种类型的关注：学习模块权重的基于语言的注意力以及每个模块应该关注的词/词注意;以及视觉注意力，使主体和关系模块能够专注于相关的图像组件。模块权重动态合并来自所有三个模块的分数，以输出总分。实验表明，MAttNet在边界框级别和像素级别的理解任务上都大大优于以前的先进方法。

##### URL
[http://arxiv.org/abs/1801.08186](http://arxiv.org/abs/1801.08186)

##### PDF
[http://arxiv.org/pdf/1801.08186](http://arxiv.org/pdf/1801.08186)

