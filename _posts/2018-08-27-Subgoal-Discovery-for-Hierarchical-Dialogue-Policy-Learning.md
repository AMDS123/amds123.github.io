---
layout: post
title: "Subgoal Discovery for Hierarchical Dialogue Policy Learning"
date: 2018-08-27 22:20:26
categories: arXiv_AI
tags: arXiv_AI Sparse Reinforcement_Learning
author: Da Tang, Xiujun Li, Jianfeng Gao, Chong Wang, Lihong Li, Tony Jebara
mathjax: true
---

* content
{:toc}

##### Abstract
Developing agents to engage in complex goal-oriented dialogues is challenging partly because the main learning signals are very sparse in long conversations. In this paper, we propose a divide-and-conquer approach that discovers and exploits the hidden structure of the task to enable efficient policy learning. First, given successful example dialogues, we propose the Subgoal Discovery Network (SDN) to divide a complex goal-oriented task into a set of simpler subgoals in an unsupervised fashion. We then use these subgoals to learn a multi-level policy by hierarchical reinforcement learning. We demonstrate our method by building a dialogue agent for the composite task of travel planning. Experiments with simulated and real users show that our approach performs competitively against a state-of-the-art method that requires human-defined subgoals. Moreover, we show that the learned subgoals are often human comprehensible.

##### Abstract (translated by Google)
开发代理商参与复杂的面向目标的对话具有挑战性，部分原因在于长时间对话中的主要学习信号非常稀少。在本文中，我们提出了一种分而治之的方法，可以发现并利用任务的隐藏结构来实现有效的政策学习。首先，给出成功的示例对话，我们建议Subgoal Discovery Network（SDN）将一个复杂的面向目标的任务以无人监督的方式划分为一组更简单的子目标。然后，我们使用这些子目标通过分层强化学习来学习多层次策略。我们通过为旅行计划的复合任务构建对话代理来演示我们的方法。模拟和真实用户的实验表明，我们的方法与需要人类定义的子目标的最先进方法相比具有竞争力。此外，我们表明，学到的子目标通常是人类可理解的。

##### URL
[http://arxiv.org/abs/1804.07855](http://arxiv.org/abs/1804.07855)

##### PDF
[http://arxiv.org/pdf/1804.07855](http://arxiv.org/pdf/1804.07855)

