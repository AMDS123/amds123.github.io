---
layout: post
title: "Reinforcement Learning under Threats"
date: 2018-09-05 14:56:09
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: V&#xed;ctor Gallego, Roi Naveiro, David R&#xed;os Insua
mathjax: true
---

* content
{:toc}

##### Abstract
In several reinforcement learning (RL) scenarios, mainly in security settings, there may be adversaries trying to interfere with the reward generating process. In this paper, we introduce Threatened Markov Decision Processes (TMDPs), which provide a framework to support a decision maker against a potential adversary in RL. Furthermore, we propose a level-$k$ thinking scheme resulting in a new learning framework to deal with TMDPs. After introducing our framework and deriving theoretical results, relevant empirical evidence is given via extensive experiments, showing the benefits of accounting for adversaries while the agent learns.

##### Abstract (translated by Google)
在几个强化学习（RL）场景中，主要是在安全设置中，可能存在试图干扰奖励生成过程的对手。在本文中，我们介绍了威胁马尔可夫决策过程（TMDP），它提供了一个框架来支持决策者对抗RL中的潜在对手。此外，我们提出了一个级别$ k $的思维方案，从而形成了一个新的学习框架来处理TMDP。在介绍了我们的框架并得出理论结果之后，通过广泛的实验给出了相关的经验证据，显示了当代理人学习时会计对手的好处。

##### URL
[http://arxiv.org/abs/1809.01560](http://arxiv.org/abs/1809.01560)

##### PDF
[http://arxiv.org/pdf/1809.01560](http://arxiv.org/pdf/1809.01560)

