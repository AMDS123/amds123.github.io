---
layout: post
title: "Sentence-State LSTM for Text Representation"
date: 2018-05-07 12:36:54
categories: arXiv_CL
tags: arXiv_CL RNN Classification
author: Yue Zhang, Qi Liu, Linfeng Song
mathjax: true
---

* content
{:toc}

##### Abstract
Bi-directional LSTMs are a powerful tool for text representation. On the other hand, they have been shown to suffer various limitations due to their sequential nature. We investigate an alternative LSTM structure for encoding text, which consists of a parallel state for each word. Recurrent steps are used to perform local and global information exchange between words simultaneously, rather than incremental reading of a sequence of words. Results on various classification and sequence labelling benchmarks show that the proposed model has strong representation power, giving highly competitive performances compared to stacked BiLSTM models with similar parameter numbers.

##### Abstract (translated by Google)
双向LSTM是用于文本表示的强大工具。另一方面，由于它们的连续性，它们已经显示出受到各种限制。我们调查了一种替代的LSTM结构来编码文本，其中包含每个单词的并行状态。循环步骤用于同时在单词之间执行本地和全局信息交换，而不是逐字读取一系列单词。各种分类和序列标记基准的结果表明，所提出的模型具有较强的表示能力，与具有相似参数数量的堆叠BiLSTM模型相比，具有极高的竞争力。

##### URL
[http://arxiv.org/abs/1805.02474](http://arxiv.org/abs/1805.02474)

##### PDF
[http://arxiv.org/pdf/1805.02474](http://arxiv.org/pdf/1805.02474)

