---
layout: post
title: "Procedural Generation of Videos to Train Deep Action Recognition Networks"
date: 2017-07-19 10:34:36
categories: arXiv_CV
tags: arXiv_CV Action_Recognition Represenation_Learning Deep_Learning Recognition
author: César Roberto de Souza, Adrien Gaidon, Yohann Cabon, Antonio Manuel López Peña
mathjax: true
---

* content
{:toc}

##### Abstract
Deep learning for human action recognition in videos is making significant progress, but is slowed down by its dependency on expensive manual labeling of large video collections. In this work, we investigate the generation of synthetic training data for action recognition, as it has recently shown promising results for a variety of other computer vision tasks. We propose an interpretable parametric generative model of human action videos that relies on procedural generation and other computer graphics techniques of modern game engines. We generate a diverse, realistic, and physically plausible dataset of human action videos, called PHAV for "Procedural Human Action Videos". It contains a total of 39,982 videos, with more than 1,000 examples for each action of 35 categories. Our approach is not limited to existing motion capture sequences, and we procedurally define 14 synthetic actions. We introduce a deep multi-task representation learning architecture to mix synthetic and real videos, even if the action categories differ. Our experiments on the UCF101 and HMDB51 benchmarks suggest that combining our large set of synthetic videos with small real-world datasets can boost recognition performance, significantly outperforming fine-tuning state-of-the-art unsupervised generative models of videos.

##### Abstract (translated by Google)
视频中人类行为认知的深度学习正在取得重大进展，但由于依赖昂贵的大型视频集合手动标记而放慢了速度。在这项工作中，我们调查了行动识别的综合训练数据的生成，因为它最近已经显示了其他各种计算机视觉任务的有希望的结果。我们提出了一个可解释的参数生成模型的人类行动视频依赖于程序代和其他计算机图形技术的现代游戏引擎。我们生成了一个多样的，现实的，物理上可信的人类动作视频数据集，名为“程序人类行动视频”的PHAV。它总共包含39,982个视频，其中35个类别的每个动作都有1000多个示例。我们的方法不限于现有的动作捕捉序列，我们在程序上定义了14个合成动作。我们引入了深入的多任务表示学习体系结构，即使动作类别不同，也可以混合合成视频和真实视频。我们在UCF101和HMDB51基准测试中的实验表明，将我们大量的合成视频与小型真实世界的数据集相结合可以提高识别性能，显着优于微调视频最先进的无监督生成模型。

##### URL
[https://arxiv.org/abs/1612.00881](https://arxiv.org/abs/1612.00881)

##### PDF
[https://arxiv.org/pdf/1612.00881](https://arxiv.org/pdf/1612.00881)

