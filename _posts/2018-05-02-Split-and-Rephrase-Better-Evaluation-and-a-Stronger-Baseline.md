---
layout: post
title: "Split and Rephrase: Better Evaluation and a Stronger Baseline"
date: 2018-05-02 21:36:38
categories: arXiv_CL
tags: arXiv_CL
author: Roee Aharoni, Yoav Goldberg
mathjax: true
---

* content
{:toc}

##### Abstract
Splitting and rephrasing a complex sentence into several shorter sentences that convey the same meaning is a challenging problem in NLP. We show that while vanilla seq2seq models can reach high scores on the proposed benchmark (Narayan et al., 2017), they suffer from memorization of the training set which contains more than 89% of the unique simple sentences from the validation and test sets. To aid this, we present a new train-development-test data split and neural models augmented with a copy-mechanism, outperforming the best reported baseline by 8.68 BLEU and fostering further progress on the task.

##### Abstract (translated by Google)
把一个复杂的句子拆分成几个更短的句子，表达相同的含义，这在NLP中是一个具有挑战性的问题。我们证明，虽然vanilla seq2seq模型可以在建议的基准测试中达到高分（Narayan等，2017），但他们患有训练集的记忆，其中包含验证和测试集中超过89％的独特简单句子。为此，我们提出了新的训练 - 发展 - 测试数据分割和增加了复制机制的神经模型，比8.68 BLEU报告的最佳基线更好，并促进了任务的进一步进展。

##### URL
[http://arxiv.org/abs/1805.01035](http://arxiv.org/abs/1805.01035)

##### PDF
[http://arxiv.org/pdf/1805.01035](http://arxiv.org/pdf/1805.01035)

