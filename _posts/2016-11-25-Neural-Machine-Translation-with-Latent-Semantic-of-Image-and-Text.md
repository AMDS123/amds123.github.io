---
layout: post
title: "Neural Machine Translation with Latent Semantic of Image and Text"
date: 2016-11-25 14:10:39
categories: arXiv_CL
tags: arXiv_CL Attention
author: Joji Toyama, Masanori Misono, Masahiro Suzuki, Kotaro Nakayama, Yutaka Matsuo
mathjax: true
---

* content
{:toc}

##### Abstract
Although attention-based Neural Machine Translation have achieved great success, attention-mechanism cannot capture the entire meaning of the source sentence because the attention mechanism generates a target word depending heavily on the relevant parts of the source sentence. The report of earlier studies has introduced a latent variable to capture the entire meaning of sentence and achieved improvement on attention-based Neural Machine Translation. We follow this approach and we believe that the capturing meaning of sentence benefits from image information because human beings understand the meaning of language not only from textual information but also from perceptual information such as that gained from vision. As described herein, we propose a neural machine translation model that introduces a continuous latent variable containing an underlying semantic extracted from texts and images. Our model, which can be trained end-to-end, requires image information only when training. Experiments conducted with an English--German translation task show that our model outperforms over the baseline.

##### Abstract (translated by Google)
注意力机器翻译虽然取得了很大的成功，但由于注意机制在很大程度上依赖于源句的相关部分产生了目标词，注意机制无法捕捉到源句的全部含义。早期的研究报告引入了一个潜在的变量来捕捉句子的全部含义，并在注意型神经机器翻译方面取得了进步。我们遵循这种方法，我们认为，从图像信息中获取句子的含义是有好处的，因为人类不仅从文本信息中理解语言的含义，而且从视觉上获得的感知信息也理解语言的含义。如本文所述，我们提出一种神经机器翻译模型，其引入包含从文本和图像中提取的基础语义的连续潜变量。我们的模型，可以训练端到端，只需要训练时的图像信息。用英语 - 德语翻译任务进行的实验表明，我们的模型在基线上表现出色。

##### URL
[https://arxiv.org/abs/1611.08459](https://arxiv.org/abs/1611.08459)

##### PDF
[https://arxiv.org/pdf/1611.08459](https://arxiv.org/pdf/1611.08459)

