---
layout: post
title: "Evolutionary RL for Container Loading"
date: 2018-05-17 09:19:35
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization
author: S Saikia, R Verma, P Agarwal, G Shroff, L Vig, A Srinivasan
mathjax: true
---

* content
{:toc}

##### Abstract
Loading the containers on the ship from a yard, is an impor- tant part of port operations. Finding the optimal sequence for the loading of containers, is known to be computationally hard and is an example of combinatorial optimization, which leads to the application of simple heuristics in practice. In this paper, we propose an approach which uses a mix of Evolutionary Strategies and Reinforcement Learning (RL) tech- niques to find an approximation of the optimal solution. The RL based agent uses the Policy Gradient method, an evolutionary reward strategy and a Pool of good (not-optimal) solutions to find the approximation. We find that the RL agent learns near-optimal solutions that outperforms the heuristic solutions. We also observe that the RL agent assisted with a pool generalizes better for unseen problems than an RL agent without a pool. We present our results on synthetic data as well as on subsets of real-world problems taken from container terminal. The results validate that our approach does comparatively better than the heuristics solutions available, and adapts to unseen problems better.

##### Abstract (translated by Google)
从码头装载集装箱，是港口业务的重要组成部分。找到装载容器的最佳顺序，已知在计算上很难并且是组合优化的一个例子，这导致在实践中应用简单的启发式方法。在本文中，我们提出了一种使用演化策略和强化学习（RL）技术混合的方法来找到最优解的近似值。基于RL的代理使用策略梯度方法，演化奖励策略和优质（非最优）解决方案池来寻找近似值。我们发现RL代理学习了超越启发式解决方案的近似最优解决方案。我们还观察到，RL代理与一个池共同协助更好地发现看不见的问题，而不是没有共享池的RL代理。我们在合成数据以及从集装箱码头取得的现实世界问题的子集上展示我们的结果。结果证实，我们的方法确实比现有的启发式解决方案要好，并更好地适应了看不见的问题。

##### URL
[http://arxiv.org/abs/1805.06664](http://arxiv.org/abs/1805.06664)

##### PDF
[http://arxiv.org/pdf/1805.06664](http://arxiv.org/pdf/1805.06664)

