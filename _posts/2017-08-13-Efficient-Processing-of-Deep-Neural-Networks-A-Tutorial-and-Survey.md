---
layout: post
title: "Efficient Processing of Deep Neural Networks: A Tutorial and Survey"
date: 2017-08-13 14:47:12
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition Survey Recognition
author: Vivienne Sze, Yu-Hsin Chen, Tien-Ju Yang, Joel Emer
mathjax: true
---

* content
{:toc}

##### Abstract
Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances towards the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic co-designs, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the trade-offs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities.

##### Abstract (translated by Google)
深度神经网络（DNN）目前被广泛用于许多人工智能（AI）应用，包括计算机视觉，语音识别和机器人技术。虽然DNN在许多AI任务上提供了最先进的准确性，但其代价是计算复杂度高。因此，能够高效处理DNN以提高能效和吞吐量而不牺牲应用精度或增加硬件成本的技术对于在AI系统中广泛部署DNN是至关重要的。本文旨在提供一个全面的教程和调查关于实现高效处理DNN目标的最新进展。具体来说，它将提供DNN的概述，讨论支持DNN的各种硬件平台和体系结构，并单独通过硬件设计更改或通过联合硬件设计和DNN算法更改来突出显示降低DNN计算成本的关键趋势。它还将总结各种开发资源，使研究人员和从业人员能够快速入门，并突出重要的基准测量指标和设计考虑因素，以便评估快速增长的DNN硬件设计数量，可选地包括算法协同设计，被学术界和工业界提出来。读者将从本文中删除以下概念：了解DNN的关键设计注意事项;能够使用基准和比较度量来评估不同的DNN硬件实现;了解各种硬件架构和平台之间的权衡关系;能够评估各种DNN设计技术对于高效处理的效用;并了解最近的实施趋势和机会。

##### URL
[https://arxiv.org/abs/1703.09039](https://arxiv.org/abs/1703.09039)

##### PDF
[https://arxiv.org/pdf/1703.09039](https://arxiv.org/pdf/1703.09039)

