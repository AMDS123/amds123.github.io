---
layout: post
title: "Convolutional sparse coding for capturing high speed video content"
date: 2018-06-13 10:31:07
categories: arXiv_CV
tags: arXiv_CV Sparse CNN
author: Ana Serrano, Elena Garces, Diego Gutierrez, Belen Masia
mathjax: true
---

* content
{:toc}

##### Abstract
Video capture is limited by the trade-off between spatial and temporal resolution: when capturing videos of high temporal resolution, the spatial resolution decreases due to bandwidth limitations in the capture system. Achieving both high spatial and temporal resolution is only possible with highly specialized and very expensive hardware, and even then the same basic trade-off remains. The recent introduction of compressive sensing and sparse reconstruction techniques allows for the capture of single-shot high-speed video, by coding the temporal information in a single frame, and then reconstructing the full video sequence from this single coded image and a trained dictionary of image patches. In this paper, we first analyze this approach, and find insights that help improve the quality of the reconstructed videos. We then introduce a novel technique, based on convolutional sparse coding (CSC), and show how it outperforms the state-of-the-art, patch-based approach in terms of flexibility and efficiency, due to the convolutional nature of its filter banks. The key idea for CSC high-speed video acquisition is extending the basic formulation by imposing an additional constraint in the temporal dimension, which enforces sparsity of the first-order derivatives over time.

##### Abstract (translated by Google)
视频捕获受限于空间和时间分辨率之间的平衡：当捕获高时间分辨率的视频时，由于捕获系统中的带宽限制，空间分辨率下降。只有高度专业化且非常昂贵的硬件才能实现高空间分辨率和时间分辨率，即使如此，仍然存在相同的基本折衷。最近引入的压缩感知和稀疏重建技术允许通过在单个帧中编码时间信息来捕获单发高速视频，然后从该单个编码图像和经训练的字典中重建完整视频序列图像补丁。在本文中，我们首先分析这种方法，并找到有助于改进重建视频质量的见解。然后，我们介绍一种基于卷积稀疏编码（CSC）的新技术，并展示它如何在灵活性和效率方面超越最先进的基于补丁的方法，这是由于其滤波器组的卷积性质。 CSC高速视频采集的关键思想是通过在时间维上施加额外的约束来扩展基本公式，这实现了一阶导数随时间推移的稀疏性。

##### URL
[http://arxiv.org/abs/1806.04935](http://arxiv.org/abs/1806.04935)

##### PDF
[http://arxiv.org/pdf/1806.04935](http://arxiv.org/pdf/1806.04935)

