---
layout: post
title: "Character-based Neural Machine Translation"
date: 2016-06-30 10:28:36
categories: arXiv_SD
tags: arXiv_SD Attention Face Embedding CNN
author: Marta R. Costa-Jussà, José A. R. Fonollosa
mathjax: true
---

* content
{:toc}

##### Abstract
Neural Machine Translation (MT) has reached state-of-the-art results. However, one of the main challenges that neural MT still faces is dealing with very large vocabularies and morphologically rich languages. In this paper, we propose a neural MT system using character-based embeddings in combination with convolutional and highway layers to replace the standard lookup-based word representations. The resulting unlimited-vocabulary and affix-aware source word embeddings are tested in a state-of-the-art neural MT based on an attention-based bidirectional recurrent neural network. The proposed MT scheme provides improved results even when the source language is not morphologically rich. Improvements up to 3 BLEU points are obtained in the German-English WMT task.

##### Abstract (translated by Google)
神经机器翻译（MT）已经达到了最新的成果。然而，神经MT仍然面临的主要挑战之一是处理非常大的词汇和形态丰富的语言。在本文中，我们提出了一个神经MT系统，使用基于字符的嵌入与卷积和高速公路层结合来替代标准的基于查找的单词表示。基于注意力的双向递归神经网络，在最先进的神经MT中测试得到的无限词汇和词缀识别的源词嵌入。即使在源语言不丰富的情况下，所提出的MT方案也能提供改进的结果。在德国 - 英国的WMT任务中获得了3 BLEU点的改进。

##### URL
[https://arxiv.org/abs/1603.00810](https://arxiv.org/abs/1603.00810)

##### PDF
[https://arxiv.org/pdf/1603.00810](https://arxiv.org/pdf/1603.00810)

