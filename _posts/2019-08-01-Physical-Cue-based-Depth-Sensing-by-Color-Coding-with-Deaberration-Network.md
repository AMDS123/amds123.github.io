---
layout: post
title: "Physical Cue based Depth-Sensing by Color Coding with Deaberration Network"
date: 2019-08-01 11:08:10
categories: arXiv_CV
tags: arXiv_CV Attention Deep_Learning Quantitative
author: Nao Mishima, Tatsuo Kozakaya, Akihisa Moriya, Ryuzo Okada, Shinsaku Hiura
mathjax: true
---

* content
{:toc}

##### Abstract
Color-coded aperture (CCA) methods can physically measure the depth of a scene given by physical cues from a single-shot image of a monocular camera. However, they are vulnerable to actual lens aberrations in real scenes because they assume an ideal lens for simplifying algorithms. In this paper, we propose physical cue-based deep learning for CCA photography. To address actual lens aberrations, we developed a deep deaberration network (DDN) that is additionally equipped with a self-attention mechanism of position and color channels to efficiently learn the lens aberration. Furthermore, a new Bayes L1 loss function based on Bayesian deep learning enables to handle the uncertainty of depth estimation more accurately. Quantitative and qualitative comparisons demonstrate that our method is superior to conventional methods including real outdoor scenes. Furthermore, compared to a long-baseline stereo camera, the proposed method provides an error-free depth map at close range, as there is no blind spot between the left and right cameras.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.00329](http://arxiv.org/abs/1908.00329)

##### PDF
[http://arxiv.org/pdf/1908.00329](http://arxiv.org/pdf/1908.00329)

