---
layout: post
title: "A Two-Stream Variational Adversarial Network for Video Generation"
date: 2018-12-03 19:11:45
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Ximeng Sun, Huijuan Xu, Kate Saenko
mathjax: true
---

* content
{:toc}

##### Abstract
Video generation is an inherently challenging task, as it requires the model to generate realistic content and motion simultaneously. Existing methods generate both motion and content together using a single generator network, but this approach may fail on complex videos. In this paper, we propose a two-stream video generation model that separates content and motion generation into two parallel generators, called Two-Stream Variational Adversarial Network (TwoStreamVAN). Our model outputs a realistic video given an input action label by progressively generating and fusing motion and content features at multiple scales using adaptive motion kernels. In addition, to better evaluate video generation models, we design a new synthetic human action dataset to bridge the difficulty gap between over-complicated human action datasets and simple toy datasets. Our model significantly outperforms existing methods on the standard Weizmann Human Action and MUG Facial Expression datasets, as well as our new dataset.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.01037](http://arxiv.org/abs/1812.01037)

##### PDF
[http://arxiv.org/pdf/1812.01037](http://arxiv.org/pdf/1812.01037)

