---
layout: post
title: "Multimodal Observation and Interpretation of Subjects Engaged in Problem Solving"
date: 2017-10-12 12:59:42
categories: arXiv_CV
tags: arXiv_CV Attention Detection
author: Thomas Guntz (LIG), Raffaella Balzarini (LIG), Dominique Vaufreydaz (LIG, UGA), James L. Crowley (Grenoble INP, LIG)
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we present the first results of a pilot experiment in the capture and interpretation of multimodal signals of human experts engaged in solving challenging chess problems. Our goal is to investigate the extent to which observations of eye-gaze, posture, emotion and other physiological signals can be used to model the cognitive state of subjects, and to explore the integration of multiple sensor modalities to improve the reliability of detection of human displays of awareness and emotion. We observed chess players engaged in problems of increasing difficulty while recording their behavior. Such recordings can be used to estimate a participant's awareness of the current situation and to predict ability to respond effectively to challenging situations. Results show that a multimodal approach is more accurate than a unimodal one. By combining body posture, visual attention and emotion, the multimodal approach can reach up to 93% of accuracy when determining player's chess expertise while unimodal approach reaches 86%. Finally this experiment validates the use of our equipment as a general and reproducible tool for the study of participants engaged in screen-based interaction and/or problem solving.

##### Abstract (translated by Google)
在本文中，我们介绍了在解决具有挑战性的国际象棋问题的人类专家的多模式信号的捕获和解释的先导实验的第一个结果。我们的目标是研究观察视线，姿势，情绪和其他生理信号的程度可以用来模拟受试者的认知状态，并探索多种传感器模式的整合以提高人类检测的可靠性意识和情感的展示。我们观察棋手在记录他们的行为时遇到难度增加的问题。这样的记录可以用来估计参与者对当前情况的意识，并预测对有挑战性的情况作出有效反应的能力。结果表明，多模式方法比单峰模式更准确。通过结合身体姿势，视觉注意力和情绪，多模式方法在确定玩家的棋类专业知识时可以达到93％的准确度，而单峰方法达到86％。最后，这个实验验证了我们的设备的使用，作为参与基于屏幕的交互和/或解决问题的参与者的研究的一般和可重复的工具。

##### URL
[https://arxiv.org/abs/1710.04486](https://arxiv.org/abs/1710.04486)

##### PDF
[https://arxiv.org/pdf/1710.04486](https://arxiv.org/pdf/1710.04486)

