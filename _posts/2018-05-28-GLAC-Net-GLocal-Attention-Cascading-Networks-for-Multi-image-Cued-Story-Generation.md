---
layout: post
title: "GLAC Net: GLocal Attention Cascading Networks for Multi-image Cued Story Generation"
date: 2018-05-28 15:30:21
categories: arXiv_CV
tags: arXiv_CV Attention Deep_Learning
author: Taehyeong Kim, Min-Oh Heo, Seonil Son, Kyoung-Wha Park, Byoung-Tak Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
The task of multi-image cued story generation, such as visual storytelling dataset (VIST) challenge, is to compose multiple coherent sentences from a given sequence of images. The main difficulty is how to generate image-specific sentences within the context of overall images. Here we propose a deep learning network model, GLAC Net, that generates visual stories by combining global-local (glocal) attention and context cascading mechanisms. The model incorporates two levels of attention, i.e., overall encoding level and image feature level, to construct image-dependent sentences. While standard attention configuration needs a large number of parameters, the GLAC Net implements them in a very simple way via hard connections from the outputs of encoders or image features onto the sentence generators. The coherency of the generated story is further improved by conveying (cascading) the information of the previous sentence to the next sentence serially. We evaluate the performance of the GLAC Net on the visual storytelling dataset (VIST) and achieve very competitive results compared to the state-of-the-art techniques.

##### Abstract (translated by Google)
多图像预告故事生成的任务，如视觉故事叙述数据集（VIST）挑战，是从给定的图像序列组成多个连贯的句子。主要困难在于如何在整个图像的上下文中生成特定于图像的句子。在这里，我们提出了一个深度学习网络模型GLAC Net，它通过结合全球 - 本地（全球本地）注意力和上下文级联机制来生成视觉故事。该模型包含两个层次的关注，即整体编码级别和图像特征级别，以构建与图像相关的句子。虽然标准的注意配置需要大量的参数，但GLAC Net通过从编码器输出或图像特征到句子生成器的硬连接以非常简单的方式实现它们。通过将前一个句子的信息连续地传送（串接）到下一个句子，可以进一步提高生成故事的一致性。我们评估了GLAC网络在视觉叙事数据集（VIST）上的表现，并与最先进的技术相比，取得了非常有竞争力的结果。

##### URL
[http://arxiv.org/abs/1805.10973](http://arxiv.org/abs/1805.10973)

##### PDF
[http://arxiv.org/pdf/1805.10973](http://arxiv.org/pdf/1805.10973)

