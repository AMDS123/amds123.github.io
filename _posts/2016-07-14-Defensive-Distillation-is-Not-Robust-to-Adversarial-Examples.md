---
layout: post
title: "Defensive Distillation is Not Robust to Adversarial Examples"
date: 2016-07-14 20:44:27
categories: arXiv_CV
tags: arXiv_CV Adversarial Classification
author: Nicholas Carlini, David Wagner
mathjax: true
---

* content
{:toc}

##### Abstract
We show that defensive distillation is not secure: it is no more resistant to targeted misclassification attacks than unprotected neural networks.

##### Abstract (translated by Google)
我们表明，防御性蒸馏是不安全的：它比没有保护的神经网络对目标错误分类攻击没有抵抗力。

##### URL
[https://arxiv.org/abs/1607.04311](https://arxiv.org/abs/1607.04311)

##### PDF
[https://arxiv.org/pdf/1607.04311](https://arxiv.org/pdf/1607.04311)

