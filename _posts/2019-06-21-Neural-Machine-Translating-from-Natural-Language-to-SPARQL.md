---
layout: post
title: "Neural Machine Translating from Natural Language to SPARQL"
date: 2019-06-21 19:34:19
categories: arXiv_CL
tags: arXiv_CL Knowledge_Graph Knowledge NMT Deep_Learning
author: Xiaoyu Yin, Dagmar Gromann, Sebastian Rudolph
mathjax: true
---

* content
{:toc}

##### Abstract
SPARQL is a highly powerful query language for an ever-growing number of Linked Data resources and Knowledge Graphs. Using it requires a certain familiarity with the entities in the domain to be queried as well as expertise in the language's syntax and semantics, none of which average human web users can be assumed to possess. To overcome this limitation, automatically translating natural language questions to SPARQL queries has been a vibrant field of research. However, to this date, the vast success of deep learning methods has not yet been fully propagated to this research problem. This paper contributes to filling this gap by evaluating the utilization of eight different Neural Machine Translation (NMT) models for the task of translating from natural language to the structured query language SPARQL. While highlighting the importance of high-quantity and high-quality datasets, the results show a dominance of a CNN-based architecture with a BLEU score of up to 98 and accuracy of up to 94%.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.09302](http://arxiv.org/abs/1906.09302)

##### PDF
[http://arxiv.org/pdf/1906.09302](http://arxiv.org/pdf/1906.09302)

