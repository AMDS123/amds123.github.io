---
layout: post
title: "Integrating Text and Image: Determining Multimodal Document Intent in Instagram Posts"
date: 2019-04-19 04:28:17
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption Detection Relation
author: Julia Kruk, Jonah Lubin, Karan Sikka, Xiao Lin, Dan Jurafsky, Ajay Divakaran
mathjax: true
---

* content
{:toc}

##### Abstract
Computing author intent from multimodal data like Instagram posts requires modeling a complex relationship between text and image. For example a caption might reflect ironically on the image, so neither the caption nor the image is a mere transcript of the other. Instead they combine -- via what has been called meaning multiplication -- to create a new meaning that has a more complex relation to the literal meanings of text and image. Here we introduce a multimodal dataset of 1299 Instagram post labeled for three orthogonal taxonomies: the authorial intent behind the image-caption pair, the contextual relationship between the literal meanings of the image and caption, and the semiotic relationship between the signified meanings of the image and caption. We build a baseline deep multimodal classifier to validate the taxonomy, showing that employing both text and image improves intent detection by 8% compared to using only image modality, demonstrating the commonality of non-intersective meaning multiplication. Our dataset offers an important resource for the study of the rich meanings that results from pairing text and image.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1904.09073](http://arxiv.org/abs/1904.09073)

##### PDF
[http://arxiv.org/pdf/1904.09073](http://arxiv.org/pdf/1904.09073)

