---
layout: post
title: "Anticipating Visual Representations from Unlabeled Video"
date: 2016-11-30 03:49:34
categories: arXiv_CV
tags: arXiv_CV Knowledge Prediction Recognition
author: Carl Vondrick, Hamed Pirsiavash, Antonio Torralba
mathjax: true
---

* content
{:toc}

##### Abstract
Anticipating actions and objects before they start or appear is a difficult problem in computer vision with several real-world applications. This task is challenging partly because it requires leveraging extensive knowledge of the world that is difficult to write down. We believe that a promising resource for efficiently learning this knowledge is through readily available unlabeled video. We present a framework that capitalizes on temporal structure in unlabeled video to learn to anticipate human actions and objects. The key idea behind our approach is that we can train deep networks to predict the visual representation of images in the future. Visual representations are a promising prediction target because they encode images at a higher semantic level than pixels yet are automatic to compute. We then apply recognition algorithms on our predicted representation to anticipate objects and actions. We experimentally validate this idea on two datasets, anticipating actions one second in the future and objects five seconds in the future.

##### Abstract (translated by Google)
在开始或出现之前预测动作和事物是计算机视觉中的一个难题，有几个实际应用。这项任务的挑战在一定程度上是因为它需要利用难以记录的世界的广泛知识。我们相信，有效学习这些知识的有前途的资源是通过容易获得的无标签视频。我们提出一个框架，利用未标记的视频中的时间结构来学习预测人类的行为和对象。我们的方法背后的关键思想是，我们可以训练深层网络来预测未来图像的视觉表现。视觉表示是一个很有希望的预测目标，因为它们编码的图像比像素更高的语义层次，而且是自动计算的。然后我们对我们的预测表示应用识别算法来预测对象和行为。我们在两个数据集上通过实验验证这个想法，预测未来一秒钟的动作，以及将来五秒钟的动作。

##### URL
[https://arxiv.org/abs/1504.08023](https://arxiv.org/abs/1504.08023)

##### PDF
[https://arxiv.org/pdf/1504.08023](https://arxiv.org/pdf/1504.08023)

