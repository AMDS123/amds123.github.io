---
layout: post
title: "Visually Grounded, Situated Learning in Neural Models"
date: 2018-05-29 15:53:30
categories: arXiv_AI
tags: arXiv_AI Language_Model
author: Alexander G. Ororbia, Ankur Mali, Matthew A. Kelly, David Reitter
mathjax: true
---

* content
{:toc}

##### Abstract
The theory of situated cognition postulates that language is inseparable from its physical context--words, phrases, and sentences must be learned in the context of the objects or concepts to which they refer. Yet, statistical language models are trained on words alone. This makes it impossible for language models to connect to the real world--the world described in the sentences presented to the model. In this paper, we examine the generalization ability of neural language models trained with a visual context. A multimodal connectionist language architecture based on the Differential State Framework is proposed, which outperforms its equivalent trained on language alone, even when no visual context is available at test time. Superior performance for language models trained with a visual context is robust across different languages and models.

##### Abstract (translated by Google)
情境认知理论假设语言与其物理环境是不可分离的 - 词汇，短语和句子必须在它们所指对象或概念的背景下学习。然而，统计语言模型仅靠单词进行培训。这使得语言模型无法连接到现实世界 - 在提供给模型的句子中描述的世界。在本文中，我们考察用视觉上下文训练的神经语言模型的泛化能力。提出了一种基于差分状态框架的多模式连接主义语言体系结构，即使在测试时间没有可用的上下文可用，其性能也优于单独使用语言进行等效训练。对于使用视觉上下文进行训练的语言模型来说，出色的性能在不同的语言和模型中都很强大

##### URL
[http://arxiv.org/abs/1805.11546](http://arxiv.org/abs/1805.11546)

##### PDF
[http://arxiv.org/pdf/1805.11546](http://arxiv.org/pdf/1805.11546)

