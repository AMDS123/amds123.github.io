---
layout: post
title: "ShapeCaptioner: Generative Caption Network for 3D Shapes by Learning a Mapping from Parts Detected in Multiple Views to Sentences"
date: 2019-07-31 22:17:31
categories: arXiv_CV
tags: arXiv_CV Knowledge Segmentation Caption Detection
author: Zhizhong Han, Chao Chen, Yu-Shen Liu, Matthias Zwicker
mathjax: true
---

* content
{:toc}

##### Abstract
3D shape captioning is a challenging application in 3D shape understanding. Captions from recent multi-view based methods reveal that they cannot capture part-level characteristics of 3D shapes. This leads to a lack of detailed part-level description in captions, which human tend to focus on. To resolve this issue, we propose ShapeCaptioner, a generative caption network, to perform 3D shape captioning from semantic parts detected in multiple views. Our novelty lies in learning the knowledge of part detection in multiple views from 3D shape segmentations and transferring this knowledge to facilitate learning the mapping from 3D shapes to sentences. Specifically, ShapeCaptioner aggregates the parts detected in multiple colored views using our novel part class specific aggregation to represent a 3D shape, and then, employs a sequence to sequence model to generate the caption. Our outperforming results show that ShapeCaptioner can learn 3D shape features with more detailed part characteristics to facilitate better 3D shape captioning than previous work.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.00120](http://arxiv.org/abs/1908.00120)

##### PDF
[http://arxiv.org/pdf/1908.00120](http://arxiv.org/pdf/1908.00120)

