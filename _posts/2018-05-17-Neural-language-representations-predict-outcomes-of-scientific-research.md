---
layout: post
title: "Neural language representations predict outcomes of scientific research"
date: 2018-05-17 17:40:12
categories: arXiv_AI
tags: arXiv_AI Relation
author: James P. Bagrow, Daniel Berenberg, Joshua Bongard
mathjax: true
---

* content
{:toc}

##### Abstract
Many research fields codify their findings in standard formats, often by reporting correlations between quantities of interest. But the space of all testable correlates is far larger than scientific resources can currently address, so the ability to accurately predict correlations would be useful to plan research and allocate resources. Using a dataset of approximately 170,000 correlational findings extracted from leading social science journals, we show that a trained neural network can accurately predict the reported correlations using only the text descriptions of the correlates. Accurate predictive models such as these can guide scientists towards promising untested correlates, better quantify the information gained from new findings, and has implications for moving artificial intelligence systems from predicting structures to predicting relationships in the real world.

##### Abstract (translated by Google)
许多研究领域通常通过报告感兴趣量之间的相关性来将他们的发现编码为标准格式。但是所有可测试相关的空间都远大于目前可以解决的科学资源，因此准确预测相关性的能力对计划研究和分配资源很有用。使用从主要社会科学期刊中提取的大约170,000个相关性研究结果的数据集，我们显示训练的神经网络可以仅使用关联的文本描述准确预测报告的相关性。诸如此类的精确预测模型可以引导科学家走向有前途的未经测试的相关性，更好地量化从新发现获得的信息，并且对于将人工智能系统从预测结构移动到预测现实世界中的关系具有影响。

##### URL
[http://arxiv.org/abs/1805.06879](http://arxiv.org/abs/1805.06879)

##### PDF
[http://arxiv.org/pdf/1805.06879](http://arxiv.org/pdf/1805.06879)

