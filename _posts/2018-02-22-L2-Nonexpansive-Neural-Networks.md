---
layout: post
title: "L2-Nonexpansive Neural Networks"
date: 2018-02-22 04:01:18
categories: arXiv_AI
tags: arXiv_AI Adversarial Quantitative
author: Haifeng Qian, Mark N. Wegman
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a class of well-conditioned neural networks in which a unit amount of change in the inputs causes at most a unit amount of change in the outputs or any of the internal layers. We develop the known methodology of controlling Lipschitz constants to realize its full potential in maximizing robustness: our linear and convolution layers subsume those in the previous Parseval networks as a special case and allow greater degrees of freedom; aggregation, pooling, splitting and other operators are adapted in new ways, and a new loss function is proposed, all for the purpose of improving robustness. With MNIST and CIFAR-10 classifiers, we demonstrate a number of advantages. Without needing any adversarial training, the proposed classifiers exceed the state of the art in robustness against white-box L2-bounded adversarial attacks. Their outputs are quantitatively more meaningful than ordinary networks and indicate levels of confidence. They are also free of exploding gradients, among other desirable properties.

##### Abstract (translated by Google)
本文提出了一类有条件的神经网络，其中输入变化的单位量导致输出或任何内部层的单位变化量。我们开发了控制Lipschitz常量的已知方法，以实现其最大化鲁棒性的全部潜力：我们的线性和卷积层将先前的Parseval网络中的那些包含为特殊情况并允许更大的自由度;聚合，池化，分裂等运营商都以新的方式进行了改造，并提出了一种新的损失函数，这些都是为了提高鲁棒性。使用MNIST和CIFAR-10分类器，我们展现出许多优势。在不需要任何敌对训练的情况下，所提出的分类器在抗白盒L2有界对抗攻击的鲁棒性方面超越了现有技术水平。他们的产出在数量上比普通网络更有意义，并表明了信心水平。它们也没有爆炸梯度以及其他所需的特性。

##### URL
[http://arxiv.org/abs/1802.07896](http://arxiv.org/abs/1802.07896)

##### PDF
[http://arxiv.org/pdf/1802.07896](http://arxiv.org/pdf/1802.07896)

