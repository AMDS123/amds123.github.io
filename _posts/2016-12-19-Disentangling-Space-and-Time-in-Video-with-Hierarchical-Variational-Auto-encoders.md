---
layout: post
title: "Disentangling Space and Time in Video with Hierarchical Variational Auto-encoders"
date: 2016-12-19 17:17:26
categories: arXiv_CV
tags: arXiv_CV Transfer_Learning Inference
author: Will Grathwohl, Aaron Wilson
mathjax: true
---

* content
{:toc}

##### Abstract
There are many forms of feature information present in video data. Principle among them are object identity information which is largely static across multiple video frames, and object pose and style information which continuously transforms from frame to frame. Most existing models confound these two types of representation by mapping them to a shared feature space. In this paper we propose a probabilistic approach for learning separable representations of object identity and pose information using unsupervised video data. Our approach leverages a deep generative model with a factored prior distribution that encodes properties of temporal invariances in the hidden feature set. Learning is achieved via variational inference. We present results of learning identity and pose information on a dataset of moving characters as well as a dataset of rotating 3D objects. Our experimental results demonstrate our model's success in factoring its representation, and demonstrate that the model achieves improved performance in transfer learning tasks.

##### Abstract (translated by Google)
视频数据中存在许多形式的特征信息。其中原理是在多个视频帧中基本静止的对象身份信息，以及从帧到帧连续变换的对象姿态和样式信息。大多数现有模型通过将这两种表示映射到共享特征空间来混淆这两种表示。在本文中，我们提出了一种概率方法来学习使用无监督视频数据的对象身份和姿态信息的可分离表示。我们的方法利用一个深层的生成模型和一个事先分布，对隐藏特征集中的时间不变性进行编码。学习是通过变化推理来实现的。我们提出学习身份和姿态信息的结果在移动字符的数据集以及旋转3D对象的数据集。我们的实验结果证明了我们的模型在代表性方面的成功，并证明该模型在转移学习任务中实现了改进的性能。

##### URL
[https://arxiv.org/abs/1612.04440](https://arxiv.org/abs/1612.04440)

##### PDF
[https://arxiv.org/pdf/1612.04440](https://arxiv.org/pdf/1612.04440)

