---
layout: post
title: "Is it worth it? Budget-related evaluation metrics for model selection"
date: 2018-07-18 15:37:58
categories: arXiv_CL
tags: arXiv_CL
author: Filip Klubička, Giancarlo D. Salton, John D. Kelleher
mathjax: true
---

* content
{:toc}

##### Abstract
Creating a linguistic resource is often done by using a machine learning model that filters the content that goes through to a human annotator, before going into the final resource. However, budgets are often limited, and the amount of available data exceeds the amount of affordable annotation. In order to optimize the benefit from the invested human work, we argue that deciding on which model one should employ depends not only on generalized evaluation metrics such as F-score, but also on the gain metric. Because the model with the highest F-score may not necessarily have the best sequencing of predicted classes, this may lead to wasting funds on annotating false positives, yielding zero improvement of the linguistic resource. We exemplify our point with a case study, using real data from a task of building a verb-noun idiom dictionary. We show that, given the choice of three systems with varying F-scores, the system with the highest F-score does not yield the highest profits. In other words, in our case the cost-benefit trade off is more favorable for a system with a lower F-score.

##### Abstract (translated by Google)
创建语言资源通常通过使用机器学习模型来完成，该机器学习模型在进入最终资源之前过滤到人类注释器的内容。但是，预算通常是有限的，可用数据量超过了可承受的注释量。为了优化投入人力资源的效益，我们认为决定采用哪种模式不仅取决于广义评估指标（如F-score），还取决于收益指标。因为具有最高F分数的模型可能不一定具有预测类别的最佳排序，这可能导致浪费资金来注释误报，从而使语言资源零改善。我们用一个案例研究来说明我们的观点，使用来自构建动词 - 名词习语词典的任务的真实数据。我们证明，考虑到三种具有不同F分数的系统的选择，具有最高F分数的系统不会产生最高的利润。换句话说，在我们的案例中，成本 - 收益权衡对于具有较低F分数的系统更有利。

##### URL
[https://arxiv.org/abs/1807.06998](https://arxiv.org/abs/1807.06998)

##### PDF
[https://arxiv.org/pdf/1807.06998](https://arxiv.org/pdf/1807.06998)

