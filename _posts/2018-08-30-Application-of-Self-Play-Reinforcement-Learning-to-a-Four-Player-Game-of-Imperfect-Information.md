---
layout: post
title: "Application of Self-Play Reinforcement Learning to a Four-Player Game of Imperfect Information"
date: 2018-08-30 11:26:59
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization
author: Henry Charlesworth
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce a new virtual environment for simulating a card game known as "Big 2". This is a four-player game of imperfect information with a relatively complicated action space (being allowed to play 1,2,3,4 or 5 card combinations from an initial starting hand of 13 cards). As such it poses a challenge for many current reinforcement learning methods. We then use the recently proposed "Proximal Policy Optimization" algorithm to train a deep neural network to play the game, purely learning via self-play, and find that it is able to reach a level which outperforms amateur human players after only a relatively short amount of training time and without needing to search a tree of future game states.

##### Abstract (translated by Google)
我们引入了一个新的虚拟环境来模拟名为“Big 2”的纸牌游戏。这是一个不完美信息的四人游戏，具有相对复杂的动作空间（允许从13张牌的初始起手牌中玩1,2,3,4或5张牌组合）。因此，它对许多当前的强化学习方法提出了挑战。然后，我们使用最近提出的“近端策略优化”算法来训练深度神经网络来玩游戏，纯粹通过自我游戏进行学习，并发现它能够在仅相对较短的时间内达到优于业余人类玩家的水平训练时间量，无需搜索未来游戏状态的树。

##### URL
[http://arxiv.org/abs/1808.10442](http://arxiv.org/abs/1808.10442)

##### PDF
[http://arxiv.org/pdf/1808.10442](http://arxiv.org/pdf/1808.10442)

