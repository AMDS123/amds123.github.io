---
layout: post
title: "Federated Learning Of Out-Of-Vocabulary Words"
date: 2019-03-26 00:01:47
categories: arXiv_CL
tags: arXiv_CL Prediction
author: Mingqing Chen, Rajiv Mathews, Tom Ouyang, Fran&#xe7;oise Beaufays
mathjax: true
---

* content
{:toc}

##### Abstract
We demonstrate that a character-level recurrent neural network is able to learn out-of-vocabulary (OOV) words under federated learning settings, for the purpose of expanding the vocabulary of a virtual keyboard for smartphones without exporting sensitive text to servers. High-frequency words can be sampled from the trained generative model by drawing from the joint posterior directly. We study the feasibility of the approach in two settings: (1) using simulated federated learning on a publicly available non-IID per-user dataset from a popular social networking website, (2) using federated learning on data hosted on user mobile devices. The model achieves good recall and precision compared to ground-truth OOV words in setting (1). With (2) we demonstrate the practicality of this approach by showing that we can learn meaningful OOV words with good character-level prediction accuracy and cross entropy loss.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.10635](http://arxiv.org/abs/1903.10635)

##### PDF
[http://arxiv.org/pdf/1903.10635](http://arxiv.org/pdf/1903.10635)

