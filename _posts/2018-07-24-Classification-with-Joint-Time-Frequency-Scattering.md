---
layout: post
title: "Classification with Joint Time-Frequency Scattering"
date: 2018-07-24 01:01:35
categories: arXiv_SD
tags: arXiv_SD CNN Classification Relation
author: Joakim and&#xe9;n, Vincent Lostanlen, St&#xe9;phane Mallat
mathjax: true
---

* content
{:toc}

##### Abstract
In time series classification, signals are typically mapped into some intermediate representation which is used to construct models. We introduce the joint time-frequency scattering transform, a locally time-shift invariant representation which characterizes the multiscale energy distribution of a signal in time and frequency. It is computed through wavelet convolutions and modulus non-linearities and may therefore be implemented as a deep convolutional neural network whose filters are not learned but calculated from wavelets. We consider the progression from mel-spectrograms to time scattering and joint time-frequency scattering transforms, illustrating the relationship between increased discriminability and refinements of convolutional network architectures. The suitability of the joint time-frequency scattering transform for characterizing time series is demonstrated through applications to chirp signals and audio synthesis experiments. The proposed transform also obtains state-of-the-art results on several audio classification tasks, outperforming time scattering transforms and achieving accuracies comparable to those of fully learned networks.

##### Abstract (translated by Google)
在时间序列分类中，信号通常被映射到用于构建模型的一些中间表示。我们介绍了联合时频散射变换，一种局部时移不变表示，它表征了信号在时间和频率上的多尺度能量分布。它是通过小波卷积和模数非线性计算的，因此可以实现为深度卷积神经网络，其滤波器不是学习的，而是从小波计算的。我们考虑从梅谱图到时间散射和联合时频散射变换的进展，说明增加的可辨识性与卷积网络架构的改进之间的关系。通过应用于啁啾信号和音频合成实验，证明了联合时频散射变换用于表征时间序列的适用性。所提出的变换还获得了几个音频分类任务的最新结果，优于时间散射变换，并且实现了与完全学习的网络相当的精度。

##### URL
[http://arxiv.org/abs/1807.08869](http://arxiv.org/abs/1807.08869)

##### PDF
[http://arxiv.org/pdf/1807.08869](http://arxiv.org/pdf/1807.08869)

