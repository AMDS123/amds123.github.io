---
layout: post
title: "Natural Language Multitasking: Analyzing and Improving Syntactic Saliency of Hidden Representations"
date: 2018-01-18 14:10:37
categories: arXiv_AI
tags: arXiv_AI Salient
author: Gino Brunner, Yuyi Wang, Roger Wattenhofer, Michael Weigelt
mathjax: true
---

* content
{:toc}

##### Abstract
We train multi-task autoencoders on linguistic tasks and analyze the learned hidden sentence representations. The representations change significantly when translation and part-of-speech decoders are added. The more decoders a model employs, the better it clusters sentences according to their syntactic similarity, as the representation space becomes less entangled. We explore the structure of the representation space by interpolating between sentences, which yields interesting pseudo-English sentences, many of which have recognizable syntactic structure. Lastly, we point out an interesting property of our models: The difference-vector between two sentences can be added to change a third sentence with similar features in a meaningful way.

##### Abstract (translated by Google)
我们训练多任务autoencoders在语言任务和分析学习隐藏的句子表示。当翻译和词性解码器被添加时，表示变化显着。模型使用的解码器越多，根据句法相似性将句子聚类越好，因为表示空间变得较少纠缠。我们通过在句子之间插入来探索表示空间的结构，这产生了有趣的伪英语句子，其中许多句子具有可识别的句法结构。最后，我们指出了我们模型的一个有趣的性质：可以添加两个句子之间的差异向量来以有意义的方式改变具有相似特征的第三个句子。

##### URL
[http://arxiv.org/abs/1801.06024](http://arxiv.org/abs/1801.06024)

##### PDF
[http://arxiv.org/pdf/1801.06024](http://arxiv.org/pdf/1801.06024)

