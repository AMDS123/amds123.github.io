---
layout: post
title: "Multi-task Learning Of Deep Neural Networks For Audio Visual Automatic Speech Recognition"
date: 2017-01-10 08:47:56
categories: arXiv_SD
tags: arXiv_SD Speech_Recognition Recognition
author: Abhinav Thanda, Shankar M Venkatesan
mathjax: true
---

* content
{:toc}

##### Abstract
Multi-task learning (MTL) involves the simultaneous training of two or more related tasks over shared representations. In this work, we apply MTL to audio-visual automatic speech recognition(AV-ASR). Our primary task is to learn a mapping between audio-visual fused features and frame labels obtained from acoustic GMM/HMM model. This is combined with an auxiliary task which maps visual features to frame labels obtained from a separate visual GMM/HMM model. The MTL model is tested at various levels of babble noise and the results are compared with a base-line hybrid DNN-HMM AV-ASR model. Our results indicate that MTL is especially useful at higher level of noise. Compared to base-line, upto 7\% relative improvement in WER is reported at -3 SNR dB

##### Abstract (translated by Google)
多任务学习（MTL）涉及在共享表示上同时训练两个或多个相关任务。在这项工作中，我们将MTL应用于视听自动语音识别（AV-ASR）。我们的主要任务是学习从声学GMM / HMM模型获得的视听融合特征与帧标签之间的映射。这与将视觉特征映射到从单独的可视GMM / HMM模型获得的帧标签的辅助任务相结合。 MTL模型在不同的噪声水平下进行测试，并将结果与​​基线混合DNN-HMM AV-ASR模型进行比较。我们的研究结果表明MTL在更高的噪声水平下特别有用。与基线相比，WER的相对改善高达7％相对于-3 SNR dB

##### URL
[https://arxiv.org/abs/1701.02477](https://arxiv.org/abs/1701.02477)

##### PDF
[https://arxiv.org/pdf/1701.02477](https://arxiv.org/pdf/1701.02477)

