---
layout: post
title: "Modelling Sentence Pairs with Tree-structured Attentive Encoder"
date: 2016-10-10 08:52:36
categories: arXiv_CL
tags: arXiv_CL Attention RNN
author: Yao Zhou, Cong Liu, Yan Pan
mathjax: true
---

* content
{:toc}

##### Abstract
We describe an attentive encoder that combines tree-structured recursive neural networks and sequential recurrent neural networks for modelling sentence pairs. Since existing attentive models exert attention on the sequential structure, we propose a way to incorporate attention into the tree topology. Specially, given a pair of sentences, our attentive encoder uses the representation of one sentence, which generated via an RNN, to guide the structural encoding of the other sentence on the dependency parse tree. We evaluate the proposed attentive encoder on three tasks: semantic similarity, paraphrase identification and true-false question selection. Experimental results show that our encoder outperforms all baselines and achieves state-of-the-art results on two tasks.

##### Abstract (translated by Google)
我们描述了一个专注的编码器，它结合了树状结构的递归神经网络和顺序循环神经网络来建模句对。由于现有的注意模型注重顺序结构，我们提出了一种将注意力集成到树形拓扑中的方法。特别地，给定一对句子，我们的专注编码器使用通过RNN产生的一个句子的表示来指导依赖分析树上的另一个句子的结构编码。我们评估建议周到的编码器的三项任务：语义相似性，释义识别和真假问题选择。实验结果表明，我们的编码器胜过所有的基线，并在两项任务上取得了最先进的成果。

##### URL
[https://arxiv.org/abs/1610.02806](https://arxiv.org/abs/1610.02806)

##### PDF
[https://arxiv.org/pdf/1610.02806](https://arxiv.org/pdf/1610.02806)

