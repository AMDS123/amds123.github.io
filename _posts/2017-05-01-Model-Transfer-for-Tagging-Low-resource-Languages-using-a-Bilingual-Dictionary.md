---
layout: post
title: "Model Transfer for Tagging Low-resource Languages using a Bilingual Dictionary"
date: 2017-05-01 05:58:56
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Meng Fang, Trevor Cohn
mathjax: true
---

* content
{:toc}

##### Abstract
Cross-lingual model transfer is a compelling and popular method for predicting annotations in a low-resource language, whereby parallel corpora provide a bridge to a high-resource language and its associated annotated corpora. However, parallel data is not readily available for many languages, limiting the applicability of these approaches. We address these drawbacks in our framework which takes advantage of cross-lingual word embeddings trained solely on a high coverage bilingual dictionary. We propose a novel neural network model for joint training from both sources of data based on cross-lingual word embeddings, and show substantial empirical improvements over baseline techniques. We also propose several active learning heuristics, which result in improvements over competitive benchmark methods.

##### Abstract (translated by Google)
跨语言模型转换是一种以低资源语言预测注释的引人注目和流行的方法，即平行语料库为高资源语言及其相关注释语料库提供了桥梁。然而，并行数据并不适用于许多语言，限制了这些方法的适用性。我们在我们的框架中解决了这些缺点，它利用了仅在高覆盖率双语词典上训练的跨语言词嵌入。我们提出了一个新的基于跨语言词嵌入的数据来源的联合训练神经网络模型，并显示了相对于基线技术的实质性经验改进。我们还提出了几种主动学习启发式方法，这些方法比竞争性基准方法有所改进。

##### URL
[https://arxiv.org/abs/1705.00424](https://arxiv.org/abs/1705.00424)

##### PDF
[https://arxiv.org/pdf/1705.00424](https://arxiv.org/pdf/1705.00424)

