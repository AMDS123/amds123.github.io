---
layout: post
title: "Meta Networks for Neural Style Transfer"
date: 2017-09-13 02:18:39
categories: arXiv_CV
tags: arXiv_CV Style_Transfer Optimization Gradient_Descent
author: Falong Shen, Shuicheng Yan, Gang Zeng
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we propose a new method to get the specified network parameters through one time feed-forward propagation of the meta networks and explore the application to neural style transfer. Recent works on style transfer typically need to train image transformation networks for every new style, and the style is encoded in the network parameters by enormous iterations of stochastic gradient descent. To tackle these issues, we build a meta network which takes in the style image and produces a corresponding image transformations network directly. Compared with optimization-based methods for every style, our meta networks can handle an arbitrary new style within $19ms$ seconds on one modern GPU card. The fast image transformation network generated by our meta network is only 449KB, which is capable of real-time executing on a mobile device. We also investigate the manifold of the style transfer networks by operating the hidden features from meta networks. Experiments have well validated the effectiveness of our method. Code and trained models has been released this https URL

##### Abstract (translated by Google)
在本文中，我们提出了一种通过元网络的一次前馈传播来获得指定的网络参数的新方法，并探讨了在神经风格转移中的应用。最近的风格转换工作通常需要对每种新风格的图像转换网络进行训练，风格通过随机梯度下降的巨大迭代在网络参数中进行编码。为了解决这些问题，我们构建了一个接入风格图像的元网络，直接生成相应的图像转换网络。与每种风格的基于优化的方法相比，我们的元网络可以在一块现代GPU卡上以$ 19ms $秒的速度处理任意新的风格。我们的元网络生成的快速图像转换网络只有449KB，能够在移动设备上实时执行。我们还通过操作元网络中的隐藏功能来调查风格转移网络的多样性。实验很好地验证了我们方法的有效性。代码和训练有素的模型已经发布了这个https URL

##### URL
[https://arxiv.org/abs/1709.04111](https://arxiv.org/abs/1709.04111)

##### PDF
[https://arxiv.org/pdf/1709.04111](https://arxiv.org/pdf/1709.04111)

