---
layout: post
title: "Transductive Unbiased Embedding for Zero-Shot Learning"
date: 2018-03-30 02:43:15
categories: arXiv_CV
tags: arXiv_CV Embedding
author: Jie Song, Chengchao Shen, Yezhou Yang, Yang Liu, Mingli Song
mathjax: true
---

* content
{:toc}

##### Abstract
Most existing Zero-Shot Learning (ZSL) methods have the strong bias problem, in which instances of unseen (target) classes tend to be categorized as one of the seen (source) classes. So they yield poor performance after being deployed in the generalized ZSL settings. In this paper, we propose a straightforward yet effective method named Quasi-Fully Supervised Learning (QFSL) to alleviate the bias problem. Our method follows the way of transductive learning, which assumes that both the labeled source images and unlabeled target images are available for training. In the semantic embedding space, the labeled source images are mapped to several fixed points specified by the source categories, and the unlabeled target images are forced to be mapped to other points specified by the target categories. Experiments conducted on AwA2, CUB and SUN datasets demonstrate that our method outperforms existing state-of-the-art approaches by a huge margin of 9.3~24.5% following generalized ZSL settings, and by a large margin of 0.2~16.2% following conventional ZSL settings.

##### Abstract (translated by Google)
大多数现有的零点学习（Zero-Shot Learning，ZSL）方法都存在强烈的偏见问题，其中看不见（目标）类的实例往往被归类为所看到的（源）类之一。因此，在广义ZSL设置中部署后，它们的性能很差。在本文中，我们提出了一个简单而有效的方法，称为准完全监督学习（QFSL）来缓解偏见问题。我们的方法遵循推导式学习的方式，该方式假定标记的源图像和未标记的目标图像都可用于训练。在语义嵌入空间中，被标记的源图像被映射到由源类别指定的若干个固定点，并且未标记的目标图像被强制映射到由目标类别指定的其他点。在AwA2，CUB和SUN数据集上进行的实验表明，我们的方法在遵循广义ZSL设置的情况下比现有技术的方法优越9.3％至24.5％，并且遵循传统ZSL的0.2％至16.2％的大幅度设置。

##### URL
[https://arxiv.org/abs/1803.11320](https://arxiv.org/abs/1803.11320)

##### PDF
[https://arxiv.org/pdf/1803.11320](https://arxiv.org/pdf/1803.11320)

