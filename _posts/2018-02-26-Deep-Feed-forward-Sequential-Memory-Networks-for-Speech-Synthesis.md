---
layout: post
title: "Deep Feed-forward Sequential Memory Networks for Speech Synthesis"
date: 2018-02-26 08:21:26
categories: arXiv_CL
tags: arXiv_CL Speech_Recognition Inference RNN Memory_Networks Recognition
author: Mengxiao Bi, Heng Lu, Shiliang Zhang, Ming Lei, Zhijie Yan
mathjax: true
---

* content
{:toc}

##### Abstract
The Bidirectional LSTM (BLSTM) RNN based speech synthesis system is among the best parametric Text-to-Speech (TTS) systems in terms of the naturalness of generated speech, especially the naturalness in prosody. However, the model complexity and inference cost of BLSTM prevents its usage in many runtime applications. Meanwhile, Deep Feed-forward Sequential Memory Networks (DFSMN) has shown its consistent out-performance over BLSTM in both word error rate (WER) and the runtime computation cost in speech recognition tasks. Since speech synthesis also requires to model long-term dependencies compared to speech recognition, in this paper, we investigate the Deep-FSMN (DFSMN) in speech synthesis. Both objective and subjective experiments show that, compared with BLSTM TTS method, the DFSMN system can generate synthesized speech with comparable speech quality while drastically reduce model complexity and speech generation time.

##### Abstract (translated by Google)
基于双向LSTM（BLSTM）RNN的语音合成系统在生成语音的自然性，尤其是韵律的自然度方面是最好的参数化文本到语音（TTS）系统之一。但是，BLSTM的模型复杂性和推理成本阻止了它在许多运行时应用程序中的使用。与此同时，深度前馈顺序存储网络（DFSMN）在语音识别任务中的误码率（WER）和运行时计算成本方面表现出了与BLSTM相比的一致性能。由于语音合成还需要模拟与语音识别相比较的长期依赖性，本文中我们将研究语音合成中的Deep-FSMN（DFSMN）。客观和主观实验表明，与BLSTM TTS方法相比，DFSMN系统可以生成具有可比较语音质量的合成语音，同时大幅降低模型复杂度和语音生成时间。

##### URL
[http://arxiv.org/abs/1802.09194](http://arxiv.org/abs/1802.09194)

##### PDF
[http://arxiv.org/pdf/1802.09194](http://arxiv.org/pdf/1802.09194)

