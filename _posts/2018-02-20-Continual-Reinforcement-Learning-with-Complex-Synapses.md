---
layout: post
title: "Continual Reinforcement Learning with Complex Synapses"
date: 2018-02-20 18:36:57
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning
author: Christos Kaplanis, Murray Shanahan, Claudia Clopath
mathjax: true
---

* content
{:toc}

##### Abstract
Unlike humans, who are capable of continual learning over their lifetimes, artificial neural networks have long been known to suffer from a phenomenon known as catastrophic forgetting, whereby new learning can lead to abrupt erasure of previously acquired knowledge. Whereas in a neural network the parameters are typically modelled as scalar values, an individual synapse in the brain comprises a complex network of interacting biochemical components that evolve at different timescales. In this paper, we show that by equipping tabular and deep reinforcement learning agents with a synaptic model that incorporates this biological complexity (Benna &amp; Fusi, 2016), catastrophic forgetting can be mitigated at multiple timescales. In particular, we find that as well as enabling continual learning across sequential training of two simple tasks, it can also be used to overcome within-task forgetting by reducing the need for an experience replay database.

##### Abstract (translated by Google)
与人类能够在其一生中不断学习的人类不同，人们早就知道人造神经网络会遭受一种称为灾难性遗忘的现象，因此新的学习可能导致以前获得的知识的突然删除。而在神经网络中，通常将参数建模为标量值，大脑中的个体突触包括在不同时间尺度演变的相互作用的生化组分的复杂网络。在本文中，我们表明，通过将表格和深层强化学习因子与包含这种生物复杂性的突触模型相结合（Benna＆amp; Fusi，2016），可以在多个时间尺度上减轻灾难性遗忘。特别是，我们发现，通过对两个简单任务的顺序培训实现持续学习，还可以通过减少对体验重放数据库的需求来克服任务内遗忘问题。

##### URL
[http://arxiv.org/abs/1802.07239](http://arxiv.org/abs/1802.07239)

##### PDF
[http://arxiv.org/pdf/1802.07239](http://arxiv.org/pdf/1802.07239)

