---
layout: post
title: "Consensus Attention-based Neural Networks for Chinese Reading Comprehension"
date: 2016-07-17 05:49:42
categories: arXiv_CL
tags: arXiv_CL Attention
author: Yiming Cui, Ting Liu, Zhipeng Chen, Shijin Wang, Guoping Hu
mathjax: true
---

* content
{:toc}

##### Abstract
Reading comprehension has embraced a booming in recent NLP research. Several institutes have released the Cloze-style reading comprehension data, and these have greatly accelerated the research of machine comprehension. In this work, we firstly present Chinese reading comprehension datasets, which consist of People Daily news dataset and Children's Fairy Tale (CFT) dataset. Also, we propose a consensus attention-based neural network architecture to tackle the Cloze-style reading comprehension problem, which aims to induce a consensus attention over every words in the query. Experimental results show that the proposed neural network significantly outperforms the state-of-the-art baselines in several public datasets. Furthermore, we setup a baseline for Chinese reading comprehension task, and hopefully this would speed up the process for future research.

##### Abstract (translated by Google)
阅读理解在最近的NLP研究中蓬勃发展。有几个研究所发布了完形填空的阅读理解数据，这些都极大地加速了机器理解的研究。在这项工作中，我们首先呈现由“人民日报”新闻数据集和儿童童话（CFT）数据集组成的中文阅读理解数据集。此外，我们提出了一个共识注意的神经网络体系结构来处理填空式阅读理解问题，其目的是引起对查询中的每个单词的共识注意。实验结果表明，所提出的神经网络显着优于几个公共数据集中最先进的基线。此外，我们还为中文阅读理解任务建立了基线，希望能够加快未来研究的进程。

##### URL
[https://arxiv.org/abs/1607.02250](https://arxiv.org/abs/1607.02250)

##### PDF
[https://arxiv.org/pdf/1607.02250](https://arxiv.org/pdf/1607.02250)

