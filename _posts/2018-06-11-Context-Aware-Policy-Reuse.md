---
layout: post
title: "Context-Aware Policy Reuse"
date: 2018-06-11 03:37:43
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Transfer_Learning
author: Siyuan Li, Fangda Gu, Guangxiang Zhu, Chongjie Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Transfer learning can greatly speed up reinforcement learning for a new task by leveraging policies of relevant tasks. 
 Existing works of policy reuse either focus on only selecting a single best source policy for transfer without considering contexts, or cannot guarantee to learn an optimal policy for a target task. 
 To improve transfer efficiency and guarantee optimality, we develop a novel policy reuse method, called {\em Context-Aware Policy reuSe} (CAPS), that enables multi-policy transfer. Our method learns when and which source policy is best for reuse, as well as when to terminate its reuse. CAPS provides theoretical guarantees in convergence and optimality for both source policy selection and target task learning. Empirical results on a grid-based navigation domain and the Pygame Learning Environment demonstrate that CAPS significantly outperforms other state-of-the-art policy reuse methods.

##### Abstract (translated by Google)
转移学习可以通过利用相关任务的策略，极大地加速学习新任务。
 现有的政策重用工作或者只关注于选择单一的最佳源策略进行传输而不考虑上下文，或者不能保证为目标任务学习最优策略。
 为了提高传输效率和保证最优性，我们开发了一种称为{em上下文感知策略reuSe}（CAPS）的新型策略重用方法，该方法支持多策略传输。我们的方法学习何时以及哪个源策略最适合重用，以及何时终止其重用。 CAPS为源策略选择和目标任务学习提供了收敛性和最优性的理论保证。基于网格的导航域和Pygame学习环境的实证结果表明CAPS明显优于其他最先进的策略重用方法。

##### URL
[http://arxiv.org/abs/1806.03793](http://arxiv.org/abs/1806.03793)

##### PDF
[http://arxiv.org/pdf/1806.03793](http://arxiv.org/pdf/1806.03793)

