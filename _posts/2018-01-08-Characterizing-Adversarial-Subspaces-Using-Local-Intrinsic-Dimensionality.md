---
layout: post
title: "Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality"
date: 2018-01-08 18:54:40
categories: arXiv_CV
tags: arXiv_CV Adversarial Prediction Detection
author: Xingjun Ma, Bo Li, Yisen Wang, Sarah M. Erfani, Sudanthi Wijewickrema, Michael E. Houle, Grant Schoenebeck, Dawn Song, James Bailey
mathjax: true
---

* content
{:toc}

##### Abstract
Deep Neural Networks (DNNs) have recently been shown to be vulnerable against adversarial examples, which are carefully crafted instances that can mislead DNNs to make errors during prediction. To better understand such attacks, a characterization is needed of the properties of regions (the so-called `adversarial subspaces') in which adversarial examples lie. In particular, effective measures are required to discriminate adversarial examples from normal examples in such regions. We tackle this challenge by characterizing the dimensional properties of adversarial regions, via the use of Local Intrinsic Dimensionality (LID). LID assesses the space-filling capability of the region surrounding a reference example, based on the distance distribution of the example to its neighbors. We first provide explanations about how adversarial perturbation can affect the LID characteristic of adversarial regions, and then show empirically that LID characteristics can facilitate the detection of adversarial examples generated using the state-of-the-art attacks. We show that when applied for adversarial detection, an LID-based method can outperform several state-of-the-art detection measures by large margins for five attack strategies across three benchmark datasets. Our analysis of the LID characteristic for adversarial regions not only motivates new directions of effective adversarial defense, but also opens up more challenges for developing new attacks to better understand the vulnerabilities of DNNs.

##### Abstract (translated by Google)
深度神经网络（DNNs）最近被证明是脆弱的反对对手的例子，这是精心设计的实例，可以误导DNN在预测过程中犯错误。为了更好地理解这种攻击，需要描述对抗性例子所在地区（即所谓的“对抗子空间”）的特性。特别是需要采取有效的措施，将这些地区的对抗事例与正常事例区分开来。我们通过使用局部内在维度（LID）来表征对抗区域的尺寸属性，以解决这个挑战。 LID根据示例与其邻居的距离分布评估参考示例周围区域的空间填充能力。我们首先提供关于对抗性扰动如何影响对抗区域的LID特征的解释，然后凭经验显示LID特征可以促进检测使用最先进的攻击产生的对抗性示例。我们表明，在应用对抗性检测时，基于LID的方法可以超越三个基准数据集中的五个攻击策略的大量边界的几个最先进的检测措施。我们分析对抗区域的LID特征，不仅激发有效对抗防御的新方向，而且为开发新的攻击，更好地了解DNN的脆弱性开辟了更多的挑战。

##### URL
[http://arxiv.org/abs/1801.02613](http://arxiv.org/abs/1801.02613)

##### PDF
[http://arxiv.org/pdf/1801.02613](http://arxiv.org/pdf/1801.02613)

