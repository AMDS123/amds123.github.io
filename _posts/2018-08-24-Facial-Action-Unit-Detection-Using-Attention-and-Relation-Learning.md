---
layout: post
title: "Facial Action Unit Detection Using Attention and Relation Learning"
date: 2018-08-24 09:10:22
categories: arXiv_CV
tags: arXiv_CV Knowledge Attention Detection Relation
author: Zhiwen Shao, Zhilei Liu, Jianfei Cai, Yunsheng Wu, Lizhuang Ma
mathjax: true
---

* content
{:toc}

##### Abstract
Attention mechanism has recently attracted increasing attentions in the area of facial action unit (AU) detection. By finding the region of interest (ROI) of each AU with the attention mechanism, AU related local features can be captured. Most existing attention based AU detection works use prior knowledge to generate fixed attentions or refine the predefined attentions within a small range, which limits their capacity to model various AUs. In this paper, we propose a novel end-to-end weakly-supervised attention and relation learning framework for AU detection with only AU labels, which has not been explored before. In particular, multi-scale features shared by each AU are learned firstly, and then both channel-wise attentions and spatial attentions are learned to select and extract AU related local features. Moreover, pixel-level relations for AUs are further captured to refine spatial attentions so as to extract more relevant local features. Extensive experiments on BP4D and DISFA benchmarks demonstrate that our framework (i) outperforms the state-of-the-art methods for AU detection, and (ii) can find the ROI of each AU and capture the relations among AUs adaptively.

##### Abstract (translated by Google)
注意机制最近在面部动作单元（AU）检测领域受到越来越多的关注。通过利用关注机制找到每个AU的感兴趣区域（ROI），可以捕获AU相关的局部特征。大多数现有的基于关注的AU检测工作使用先验知识来生成固定关注或在小范围内细化预定义的关注，这限制了他们对各种AU建模的能力。在本文中，我们提出了一种新的端到端弱监督注意和关系学习框架，用于AU检测，只有AU标签，以前没有被探索过。具体地，首先学习每个AU共享的多尺度特征，然后学习通道注意和空间注意以选择和提取AU相关的局部特征。此外，进一步捕获AU的像素级关系以改善空间注意力，以便提取更多相关的局部特征。对BP4D和DISFA基准测试的广泛实验表明，我们的框架（i）优于最先进的AU检测方法，（ii）可以找到每个AU的ROI并自适应地捕获AU之间的关系。

##### URL
[http://arxiv.org/abs/1808.03457](http://arxiv.org/abs/1808.03457)

##### PDF
[http://arxiv.org/pdf/1808.03457](http://arxiv.org/pdf/1808.03457)

