---
layout: post
title: "The Forgettable-Watcher Model for Video Question Answering"
date: 2017-05-03 04:46:33
categories: arXiv_CL
tags: arXiv_CL QA Attention VQA
author: Hongyang Xue, Zhou Zhao, Deng Cai
mathjax: true
---

* content
{:toc}

##### Abstract
A number of visual question answering approaches have been proposed recently, aiming at understanding the visual scenes by answering the natural language questions. While the image question answering has drawn significant attention, video question answering is largely unexplored. Video-QA is different from Image-QA since the information and the events are scattered among multiple frames. In order to better utilize the temporal structure of the videos and the phrasal structures of the answers, we propose two mechanisms: the re-watching and the re-reading mechanisms and combine them into the forgettable-watcher model. Then we propose a TGIF-QA dataset for video question answering with the help of automatic question generation. Finally, we evaluate the models on our dataset. The experimental results show the effectiveness of our proposed models.

##### Abstract (translated by Google)
最近提出了许多视觉问答方法，旨在通过回答自然语言问题来理解视觉场景。在形象问题回答引起重视的同时，视频问答在很大程度上是未知的。 Video-QA与Image-QA不同，因为信息和事件分散在多个帧中。为了更好地利用视频的时间结构和答案的短语结构，我们提出了两种机制：重读和重读机制，并将它们组合成遗忘观察者模型。然后，我们提出了一个TGIF-QA数据集，用于视频问题的回答与自动生成问题的帮助。最后，我们在我们的数据集上评估模型。实验结果表明了我们提出的模型的有效性。

##### URL
[https://arxiv.org/abs/1705.01253](https://arxiv.org/abs/1705.01253)

##### PDF
[https://arxiv.org/pdf/1705.01253](https://arxiv.org/pdf/1705.01253)

