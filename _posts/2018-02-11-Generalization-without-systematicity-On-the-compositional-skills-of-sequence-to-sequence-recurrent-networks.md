---
layout: post
title: "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks"
date: 2018-02-11 21:55:39
categories: arXiv_AI
tags: arXiv_AI RNN
author: Brenden M. Lake, Marco Baroni
mathjax: true
---

* content
{:toc}

##### Abstract
Humans can understand and produce new utterances effortlessly, thanks to their compositional skills. Once a person learns the meaning of a new verb "dax," he or she can immediately understand the meaning of "dax twice" or "sing and dax." In this paper, we introduce the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences. We then test the zero-shot generalization capabilities of a variety of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence methods. We find that RNNs can make successful zero-shot generalizations when the differences between training and test commands are small, so that they can apply "mix-and-match" strategies to solve the task. However, when generalization requires systematic compositional skills (as in the "dax" example above), RNNs fail spectacularly. We conclude with a proof-of-concept experiment in neural machine translation, suggesting that lack of systematicity might be partially responsible for neural networks' notorious training data thirst.

##### Abstract (translated by Google)
由于他们的构图技巧，人类可以毫不费力地理解和产生新的话语。一旦一个人学习到新动词“dax”的含义，他或她可以立即理解“dax两次”或“唱歌和dax”的含义。在本文中，我们介绍SCAN域，它由一组简单的组合导航命令和相应的动作序列组成。然后我们用序列到序列的方法测试在SCAN上训练的各种循环神经网络（RNN）的零点归纳能力。我们发现，当训练和测试命令之间的差异很小时，RNN可以成功实现零炮概括，以便他们可以应用“混合搭配”策略来解决任务。然而，当泛化需要系统的组合技巧时（如上面的“dax”例子），RNNs失败了。我们用神经机器翻译中的概念验证实验得出结论，表明缺乏系统性可能部分地负责神经网络的臭名昭着的训练数据干渴。

##### URL
[http://arxiv.org/abs/1711.00350](http://arxiv.org/abs/1711.00350)

##### PDF
[http://arxiv.org/pdf/1711.00350](http://arxiv.org/pdf/1711.00350)

