---
layout: post
title: "Knowledge Distillation with Adversarial Samples Supporting Decision Boundary"
date: 2018-05-21 05:19:06
categories: arXiv_CV
tags: arXiv_CV Adversarial Knowledge
author: Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi
mathjax: true
---

* content
{:toc}

##### Abstract
Many recent works on knowledge distillation have provided ways to transfer the knowledge of a trained network for improving the learning process of a new one, but finding a good technique for knowledge distillation is still an open problem. In this paper, we provide a new perspective based on a decision boundary, which is one of the most important component of a classifier. The generalization performance of a classifier is closely related to the adequacy of its decision boundary, so a good classifier bears a good decision boundary. Therefore, transferring information closely related to the decision boundary can be a good attempt for knowledge distillation. To realize this goal, we utilize an adversarial attack to discover samples supporting a decision boundary. Based on this idea, to transfer more accurate information about the decision boundary, the proposed algorithm trains a student classifier based on the adversarial samples supporting the decision boundary. Experiments show that the proposed method indeed improves knowledge distillation and achieves the state-of-the-arts performance.

##### Abstract (translated by Google)
最近许多关于知识蒸馏的研究提供了转移培训网络的知识以改进新知识的学习过程的方法，但是找到一种用于知识蒸馏的好技术仍然是一个悬而未决的问题。在本文中，我们提供了一个基于决策边界的新观点，决策边界是分类器最重要的组成部分之一。分类器的泛化性能与其决策边界的充分性密切相关，因此好的分类器具有良好的决策边界。因此，传递与决策边界密切相关的信息可能是对知识蒸馏的一种很好的尝试。为了实现这个目标，我们利用敌对攻击来发现支持决策边界的样本。基于这个思想，为了传递更准确的决策边界信息，该算法根据支持决策边界的敌对样本训练学生分类器。实验表明，所提出的方法确实提高了知识蒸馏，并实现了艺术级的表现。

##### URL
[https://arxiv.org/abs/1805.05532](https://arxiv.org/abs/1805.05532)

##### PDF
[https://arxiv.org/pdf/1805.05532](https://arxiv.org/pdf/1805.05532)

