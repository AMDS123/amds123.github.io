---
layout: post
title: "von Mises-Fisher Mixture Model-based Deep learning: Application to Face Verification"
date: 2017-12-31 22:24:58
categories: arXiv_CV
tags: arXiv_CV Face Classification Deep_Learning Recognition
author: Md. Abul Hasnat, Julien Bohn&#xe9;, Jonathan Milgram, St&#xe9;phane Gentric, Liming Chen
mathjax: true
---

* content
{:toc}

##### Abstract
A number of pattern recognition tasks, \textit{e.g.}, face verification, can be boiled down to classification or clustering of unit length directional feature vectors whose distance can be simply computed by their angle. In this paper, we propose the von Mises-Fisher (vMF) mixture model as the theoretical foundation for an effective deep-learning of such directional features and derive a novel vMF Mixture Loss and its corresponding vMF deep features. The proposed vMF feature learning achieves the characteristics of discriminative learning, \textit{i.e.}, compacting the instances of the same class while increasing the distance of instances from different classes. Moreover, it subsumes a number of popular loss functions as well as an effective method in deep learning, namely normalization. We conduct extensive experiments on face verification using 4 different challenging face datasets, \textit{i.e.}, LFW, YouTube faces, CACD and IJB-A. Results show the effectiveness and excellent generalization ability of the proposed approach as it achieves state-of-the-art results on the LFW, YouTube faces and CACD datasets and competitive results on the IJB-A dataset.

##### Abstract (translated by Google)
面对验证的许多模式识别任务可以归结为单位长度方向特征向量的分类或聚类，其距离可以通过它们的角度来简单地计算。本文提出了von Mises-Fisher（vMF）混合模型作为这种方向特征的有效深度学习的理论基础，并推导出一种新颖的vMF混合损失及其相应的vMF深度特征。所提出的vMF特征学习实现了区分性学习的特征，即在相同类别的实例中压缩实例，同时增加来自不同类别的实例的距离。此外，它包含了一些流行的损失函数，也是深度学习的有效方法，即归一化。我们在脸部验证方面进行了广泛的实验，使用了4种不同的具有挑战性的脸部数据集\ textit {LFW}，YouTube脸孔，CACD和IJB-A。结果显示了所提出的方法的有效性和出色的泛化能力，因为它实现了LFW，YouTube面孔和CACD数据集上的最新结果以及IJB-A数据集上的竞争结果。

##### URL
[http://arxiv.org/abs/1706.04264](http://arxiv.org/abs/1706.04264)

##### PDF
[http://arxiv.org/pdf/1706.04264](http://arxiv.org/pdf/1706.04264)

