---
layout: post
title: "Long-Term Visual Object Tracking Benchmark"
date: 2019-01-01 10:21:44
categories: arXiv_CV
tags: arXiv_CV Tracking Object_Tracking Deep_Learning Quantitative
author: Abhinav Moudgil, Vineet Gandhi
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a new long video dataset (called Track Long and Prosper - TLP) and benchmark for single object tracking. The dataset consists of 50 HD videos from real world scenarios, encompassing a duration of over 400 minutes (676K frames), making it more than 20 folds larger in average duration per sequence and more than 8 folds larger in terms of total covered duration, as compared to existing generic datasets for visual tracking. The proposed dataset paves a way to suitably assess long term tracking performance and train better deep learning architectures (avoiding/reducing augmentation, which may not reflect real world behaviour). We benchmark the dataset on 17 state of the art trackers and rank them according to tracking accuracy and run time speeds. We further present thorough qualitative and quantitative evaluation highlighting the importance of long term aspect of tracking. Our most interesting observations are (a) existing short sequence benchmarks fail to bring out the inherent differences in tracking algorithms which widen up while tracking on long sequences and (b) the accuracy of trackers abruptly drops on challenging long sequences, suggesting the potential need of research efforts in the direction of long-term tracking.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1712.01358](http://arxiv.org/abs/1712.01358)

##### PDF
[http://arxiv.org/pdf/1712.01358](http://arxiv.org/pdf/1712.01358)

