---
layout: post
title: "Zero-Resource Neural Machine Translation with Multi-Agent Communication Game"
date: 2018-02-09 03:53:13
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption NMT
author: Yun Chen, Yang Liu, Victor O.K. Li
mathjax: true
---

* content
{:toc}

##### Abstract
While end-to-end neural machine translation (NMT) has achieved notable success in the past years in translating a handful of resource-rich language pairs, it still suffers from the data scarcity problem for low-resource language pairs and domains. To tackle this problem, we propose an interactive multimodal framework for zero-resource neural machine translation. Instead of being passively exposed to large amounts of parallel corpora, our learners (implemented as encoder-decoder architecture) engage in cooperative image description games, and thus develop their own image captioning or neural machine translation model from the need to communicate in order to succeed at the game. Experimental results on the IAPR-TC12 and Multi30K datasets show that the proposed learning mechanism significantly improves over the state-of-the-art methods.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1802.03116](https://arxiv.org/abs/1802.03116)

##### PDF
[https://arxiv.org/pdf/1802.03116](https://arxiv.org/pdf/1802.03116)

