---
layout: post
title: "Zero-Resource Neural Machine Translation with Multi-Agent Communication Game"
date: 2018-02-09 03:53:13
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption NMT
author: Yun Chen, Yang Liu, Victor O.K. Li
mathjax: true
---

* content
{:toc}

##### Abstract
While end-to-end neural machine translation (NMT) has achieved notable success in the past years in translating a handful of resource-rich language pairs, it still suffers from the data scarcity problem for low-resource language pairs and domains. To tackle this problem, we propose an interactive multimodal framework for zero-resource neural machine translation. Instead of being passively exposed to large amounts of parallel corpora, our learners (implemented as encoder-decoder architecture) engage in cooperative image description games, and thus develop their own image captioning or neural machine translation model from the need to communicate in order to succeed at the game. Experimental results on the IAPR-TC12 and Multi30K datasets show that the proposed learning mechanism significantly improves over the state-of-the-art methods.

##### Abstract (translated by Google)
虽然端到端神经机器翻译（NMT）在过去几年中在翻译少量资源丰富的语言对方面取得了显着的成功，但它仍然受到低资源语言对和域的数据稀缺问题的困扰。为了解决这个问题，我们提出了一种用于零资源神经机器翻译的交互式多模式框架。我们的学习者（实现为编码器 - 解码器架构）不是被动地暴露于大量并行语料库，而是参与合作图像描述游戏，从而根据需要进行通信以便成功开发自己的图像字幕或神经机器翻译模型在比赛中。 IAPR-TC12和Multi30K数据集的实验结果表明，与最先进的方法相比，所提出的学习机制显着改善。

##### URL
[https://arxiv.org/abs/1802.03116](https://arxiv.org/abs/1802.03116)

##### PDF
[https://arxiv.org/pdf/1802.03116](https://arxiv.org/pdf/1802.03116)

