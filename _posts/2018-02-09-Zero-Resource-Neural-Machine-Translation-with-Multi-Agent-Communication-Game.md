---
layout: post
title: "Zero-Resource Neural Machine Translation with Multi-Agent Communication Game"
date: 2018-02-09 03:53:13
categories: arXiv_CL
tags: arXiv_CL Image_Caption Caption NMT
author: Yun Chen, Yang Liu, Victor O.K. Li
mathjax: true
---

* content
{:toc}

##### Abstract
While end-to-end neural machine translation (NMT) has achieved notable success in the past years in translating a handful of resource-rich language pairs, it still suffers from the data scarcity problem for low-resource language pairs and domains. To tackle this problem, we propose an interactive multimodal framework for zero-resource neural machine translation. Instead of being passively exposed to large amounts of parallel corpora, our learners (implemented as encoder-decoder architecture) engage in cooperative image description games, and thus develop their own image captioning or neural machine translation model from the need to communicate in order to succeed at the game. Experimental results on the IAPR-TC12 and Multi30K datasets show that the proposed learning mechanism significantly improves over the state-of-the-art methods.

##### Abstract (translated by Google)
虽然端到端的神经机器翻译（NMT）在过去的几年在翻译少量的资源丰富的语言对方面取得了显着的成功，但是它仍然面临着低资源语言对和领域的数据稀缺问题。为了解决这个问题，我们提出了一种零资源神经机器翻译的交互式多模式框架。我们的学习者（被实现为编码器 - 解码器架构）不是被动地暴露给大量的平行语料库，而是参与合作的图像描述游戏，从而开发自己的图像字幕或神经机器翻译模型，在比赛中。在IAPR-TC12和Multi30K数据集上的实验结果表明，所提出的学习机制比现有技术方法显着提高。

##### URL
[http://arxiv.org/abs/1802.03116](http://arxiv.org/abs/1802.03116)

##### PDF
[http://arxiv.org/pdf/1802.03116](http://arxiv.org/pdf/1802.03116)

