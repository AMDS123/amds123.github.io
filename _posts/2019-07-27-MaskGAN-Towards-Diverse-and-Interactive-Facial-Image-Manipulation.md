---
layout: post
title: "MaskGAN: Towards Diverse and Interactive Facial Image Manipulation"
date: 2019-07-27 14:23:19
categories: arXiv_CV
tags: arXiv_CV GAN Face
author: Cheng-Han Lee, Ziwei Liu, Lingyun Wu, Ping Luo
mathjax: true
---

* content
{:toc}

##### Abstract
Facial image manipulation has achieved great progresses in recent years. However, previous methods either operate on a predefined set of face attributes or leave users little freedom to interactively manipulate images. To overcome these drawbacks, we propose a novel framework termed MaskGAN, enabling diverse and interactive face manipulation. Our key insight is that semantic masks serve as a suitable intermediate representation for flexible face manipulation with fidelity preservation. MaskGAN has two main components: 1) Dense Mapping Network, and 2) Editing Behavior Simulated Training. Specifically, Dense mapping network learns style mapping between a free-form user modified mask and a target image, enabling diverse generation results. Editing behavior simulated training models the user editing behavior on the source mask, making the overall framework more robust to various manipulated inputs. To facilitate extensive studies, we construct a large-scale high-resolution face dataset with fine-grained mask annotations named CelebAMask-HQ. MaskGAN is comprehensively evaluated on two challenging tasks: attribute transfer and style copy, demonstrating superior performance over other state-of-the-art methods. The code, models and dataset are available at \url{https://github.com/switchablenorms/CelebAMask-HQ}.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.11922](http://arxiv.org/abs/1907.11922)

##### PDF
[http://arxiv.org/pdf/1907.11922](http://arxiv.org/pdf/1907.11922)

