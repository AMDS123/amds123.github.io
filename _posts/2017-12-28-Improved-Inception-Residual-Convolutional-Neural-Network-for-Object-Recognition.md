---
layout: post
title: "Improved Inception-Residual Convolutional Neural Network for Object Recognition"
date: 2017-12-28 15:08:14
categories: arXiv_CV
tags: arXiv_CV CNN Classification Recognition
author: Md Zahangir Alom, Mahmudul Hasan, Chris Yakopcic, Tarek M. Taha, Vijayan K. Asari
mathjax: true
---

* content
{:toc}

##### Abstract
Machine learning and computer vision have driven many of the greatest advances in the modeling of Deep Convolutional Neural Networks (DCNNs). Nowadays, most of the research has been focused on improving recognition accuracy with better DCNN models and learning approaches. The recurrent convolutional approach is not applied very much, other than in a few DCNN architectures. On the other hand, Inception-v4 and Residual networks have promptly become popular among computer the vision community. In this paper, we introduce a new DCNN model called the Inception Recurrent Residual Convolutional Neural Network (IRRCNN), which utilizes the power of the Recurrent Convolutional Neural Network (RCNN), the Inception network, and the Residual network. This approach improves the recognition accuracy of the Inception-residual network with same number of network parameters. In addition, this proposed architecture generalizes the Inception network, the RCNN, and the Residual network with significantly improved training accuracy. We have empirically evaluated the performance of the IRRCNN model on different benchmarks including CIFAR-10, CIFAR-100, TinyImageNet-200, and CU3D-100. The experimental results show higher recognition accuracy against most of the popular DCNN models including the RCNN. We have also investigated the performance of the IRRCNN approach against the Equivalent Inception Network (EIN) and the Equivalent Inception Residual Network (EIRN) counterpart on the CIFAR-100 dataset. We report around 4.53%, 4.49% and 3.56% improvement in classification accuracy compared with the RCNN, EIN, and EIRN on the CIFAR-100 dataset respectively. Furthermore, the experiment has been conducted on the TinyImageNet-200 and CU3D-100 datasets where the IRRCNN provides better testing accuracy compared to the Inception Recurrent CNN (IRCNN), the EIN, and the EIRN.

##### Abstract (translated by Google)
机器学习和计算机视觉已经推动了深度卷积神经网络（DCNN）建模方面的许多最大的进步。目前，大部分的研究都集中在通过更好的DCNN模型和学习方法来提高识别精度上。经常性的卷积方法并不适用，除了在一些DCNN架构中。另一方面，Inception-v4和Residual网络也迅速在计算机界流行起来。在本文中，我们引入一种新的DCNN模型，称为初始回归残差卷积神经网络（IRRCNN），它利用了回归卷积神经网络（RCNN）的功能，初始网络和残差网络。这种方法提高了具有相同网络参数数量的初始残差网络的识别准确率。此外，本文提出的网络架构概括了初始网络，RCNN和残差网络，训练精度显着提高。我们根据经验对IRRCNN模型的性能进行了评估，包括CIFAR-10，CIFAR-100，TinyImageNet-200和CU3D-100。实验结果表明，对包括RCNN在内的大多数流行的DCNN模型，识别精度更高。我们还调查了IRRNN方法在CIFAR-100数据集上针对等效初始网络（EIN）和等效初始残差网络（EIRN）的性能。与CIFAR-100数据集上的RCNN，EIN和EIRN相比，分类精度分别提高了4.53％，4.49％和3.56％。此外，已经在TinyImageNet-200和CU3D-100数据集上进行了实验，与初始周期性CNN（IRCNN），EIN和EIRN相比，IRRCNN提供了更好的测试精度。

##### URL
[http://arxiv.org/abs/1712.09888](http://arxiv.org/abs/1712.09888)

##### PDF
[http://arxiv.org/pdf/1712.09888](http://arxiv.org/pdf/1712.09888)

