---
layout: post
title: "Mining Deep And-Or Object Structures via Cost-Sensitive Question-Answer-Based Active Annotations"
date: 2019-01-08 01:24:54
categories: arXiv_CV
tags: arXiv_CV QA
author: Quanshi Zhang, Ying Nian Wu, Hao Zhang, Song-Chun Zhu
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a cost-sensitive active Question-Answering (QA) framework for learning a nine-layer And-Or graph (AOG) from web images. The AOG explicitly represents object categories, poses/viewpoints, parts, and detailed structures within the parts in a compositional hierarchy. The QA framework is designed to minimize an overall risk, which trades off the loss and query costs. The loss is defined for nodes in all layers of the AOG, including the generative loss (measuring the likelihood of the images) and the discriminative loss (measuring the fitness to human answers). The cost comprises both the human labor of answering questions and the computational cost of model learning. The cost-sensitive QA framework iteratively selects different storylines of questions to update different nodes in the AOG. Experiments showed that our method required much less human supervision (e.g., labeling parts on 3--10 training objects for each category) and achieved better performance than baseline methods.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1708.03911](http://arxiv.org/abs/1708.03911)

##### PDF
[http://arxiv.org/pdf/1708.03911](http://arxiv.org/pdf/1708.03911)

