---
layout: post
title: "Theoretical Guarantees of Deep Embedding Losses Under Label Noise"
date: 2018-12-06 17:19:01
categories: arXiv_CV
tags: arXiv_CV Weakly_Supervised Embedding
author: Nam Le, Jean-Marc Odobez
mathjax: true
---

* content
{:toc}

##### Abstract
Collecting labeled data to train deep neural networks is costly and even impractical for many tasks. Thus, research effort has been focused in automatically curated datasets or unsupervised and weakly supervised learning. The common problem in these directions is learning with unreliable label information. In this paper, we address the tolerance of deep embedding learning losses against label noise, i.e. when the observed labels are different from the true labels. Specifically, we provide the sufficient conditions to achieve theoretical guarantees for the 2 common loss functions: marginal loss and triplet loss. From these theoretical results, we can estimate how sampling strategies and initialization can affect the level of resistance against label noise. The analysis also helps providing more effective guidelines in unsupervised and weakly supervised deep embedding learning.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.02676](http://arxiv.org/abs/1812.02676)

##### PDF
[http://arxiv.org/pdf/1812.02676](http://arxiv.org/pdf/1812.02676)

