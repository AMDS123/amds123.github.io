---
layout: post
title: "Discourse Embellishment Using a Deep Encoder-Decoder Network"
date: 2018-10-18 14:29:50
categories: arXiv_CL
tags: arXiv_CL RNN
author: Leonid Berov, Kai Standvoss
mathjax: true
---

* content
{:toc}

##### Abstract
We suggest a new NLG task in the context of the discourse generation pipeline of computational storytelling systems. This task, textual embellishment, is defined by taking a text as input and generating a semantically equivalent output with increased lexical and syntactic complexity. Ideally, this would allow the authors of computational storytellers to implement just lightweight NLG systems and use a domain-independent embellishment module to translate its output into more literary text. We present promising first results on this task using LSTM Encoder-Decoder networks trained on the WikiLarge dataset. Furthermore, we introduce "Compiled Computer Tales", a corpus of computationally generated stories, that can be used to test the capabilities of embellishment algorithms.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1810.08076](http://arxiv.org/abs/1810.08076)

##### PDF
[http://arxiv.org/pdf/1810.08076](http://arxiv.org/pdf/1810.08076)

