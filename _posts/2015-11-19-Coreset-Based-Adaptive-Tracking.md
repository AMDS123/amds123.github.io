---
layout: post
title: "Coreset-Based Adaptive Tracking"
date: 2015-11-19 12:59:20
categories: arXiv_CV
tags: arXiv_CV Tracking Object_Tracking Detection Relation
author: Abhimanyu Dubey, Nikhil Naik, Dan Raviv, Rahul Sukthankar, Ramesh Raskar
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a method for learning from streaming visual data using a compact, constant size representation of all the data that was seen until a given moment. Specifically, we construct a 'coreset' representation of streaming data using a parallelized algorithm, which is an approximation of a set with relation to the squared distances between this set and all other points in its ambient space. We learn an adaptive object appearance model from the coreset tree in constant time and logarithmic space and use it for object tracking by detection. Our method obtains excellent results for object tracking on three standard datasets over more than 100 videos. The ability to summarize data efficiently makes our method ideally suited for tracking in long videos in presence of space and time constraints. We demonstrate this ability by outperforming a variety of algorithms on the TLD dataset with 2685 frames on average. This coreset based learning approach can be applied for both real-time learning of small, varied data and fast learning of big data.

##### Abstract (translated by Google)
我们提出了一种从流式可视化数据学习的方法，使用一个紧凑，恒定的大小来表示直到特定时刻的所有数据。具体而言，我们使用并行化算法构建流式数据的“核心集”表示，该算法是关于该集合与其周围空间中的所有其他点之间的平方距离的集合的近似值。我们从核心树中的常量时间和对数空间学习一个自适应的对象外观模型，并将其用于通过检测进行对象跟踪。我们的方法在超过100个视频的三个标准数据集上的对象跟踪方面获得了极好的结果。有效地总结数据的能力使得我们的方法非常适合于在存在空间和时间限制的情况下跟踪长视频。我们通过平均拥有2685帧的顶级域名（TLD）数据集上的各种算法来表现出这种能力。这种基于核心的学习方法可以应用于实时学习小型，多样的数据和快速学习大数据。

##### URL
[https://arxiv.org/abs/1511.06147](https://arxiv.org/abs/1511.06147)

##### PDF
[https://arxiv.org/pdf/1511.06147](https://arxiv.org/pdf/1511.06147)

