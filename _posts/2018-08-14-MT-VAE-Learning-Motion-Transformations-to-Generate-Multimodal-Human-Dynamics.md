---
layout: post
title: "MT-VAE: Learning Motion Transformations to Generate Multimodal Human Dynamics"
date: 2018-08-14 06:21:03
categories: arXiv_AI
tags: arXiv_AI Embedding
author: Xinchen Yan, Akash Rastogi, Ruben Villegas, Kalyan Sunkavalli, Eli Shechtman, Sunil Hadap, Ersin Yumer, Honglak Lee
mathjax: true
---

* content
{:toc}

##### Abstract
Long-term human motion can be represented as a series of motion modes---motion sequences that capture short-term temporal dynamics---with transitions between them. We leverage this structure and present a novel Motion Transformation Variational Auto-Encoders (MT-VAE) for learning motion sequence generation. Our model jointly learns a feature embedding for motion modes (that the motion sequence can be reconstructed from) and a feature transformation that represents the transition of one motion mode to the next motion mode. Our model is able to generate multiple diverse and plausible motion sequences in the future from the same input. We apply our approach to both facial and full body motion, and demonstrate applications like analogy-based motion transfer and video synthesis.

##### Abstract (translated by Google)
长期人体运动可以表示为一系列运动模式 - 捕捉短期时间动态的运动序列 - 它们之间的过渡。我们利用这种结构，提出了一种新颖的运动变换变分自动编码器（MT-VAE），用于学习运动序列生成。我们的模型联合学习运动模式的特征嵌入（可以从中重建运动序列）和表示一个运动模式到下一个运动模式的转换的特征变换。我们的模型能够在未来从相同的输入生成多种多样且可信的运动序列。我们将我们的方法应用于面部和全身运动，并演示了基于类比的运动传递和视频合成等应用。

##### URL
[http://arxiv.org/abs/1808.04545](http://arxiv.org/abs/1808.04545)

##### PDF
[http://arxiv.org/pdf/1808.04545](http://arxiv.org/pdf/1808.04545)

