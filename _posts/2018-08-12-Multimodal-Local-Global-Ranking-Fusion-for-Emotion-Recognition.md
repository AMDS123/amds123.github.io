---
layout: post
title: "Multimodal Local-Global Ranking Fusion for Emotion Recognition"
date: 2018-08-12 09:44:01
categories: arXiv_AI
tags: arXiv_AI Prediction Recognition
author: Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency
mathjax: true
---

* content
{:toc}

##### Abstract
Emotion recognition is a core research area at the intersection of artificial intelligence and human communication analysis. It is a significant technical challenge since humans display their emotions through complex idiosyncratic combinations of the language, visual and acoustic modalities. In contrast to traditional multimodal fusion techniques, we approach emotion recognition from both direct person-independent and relative person-dependent perspectives. The direct person-independent perspective follows the conventional emotion recognition approach which directly infers absolute emotion labels from observed multimodal features. The relative person-dependent perspective approaches emotion recognition in a relative manner by comparing partial video segments to determine if there was an increase or decrease in emotional intensity. Our proposed model integrates these direct and relative prediction perspectives by dividing the emotion recognition task into three easier subtasks. The first subtask involves a multimodal local ranking of relative emotion intensities between two short segments of a video. The second subtask uses local rankings to infer global relative emotion ranks with a Bayesian ranking algorithm. The third subtask incorporates both direct predictions from observed multimodal behaviors and relative emotion ranks from local-global rankings for final emotion prediction. Our approach displays excellent performance on an audio-visual emotion recognition benchmark and improves over other algorithms for multimodal fusion.

##### Abstract (translated by Google)
情感识别是人工智能与人类交流分析交叉的核心研究领域。这是一项重大的技术挑战，因为人类通过语言，视觉和声学模式的复杂特殊组合来展示自己的情感。与传统的多模态融合技术相比，我们从直接的人独立和相对的人依赖视角来处理情感识别。直接的人独立视角遵循传统的情感识别方法，该方法直接从观察到的多模态特征中推断绝对情感标签。相对的人依赖性视角通过比较部分视频片段以确定是否存在情绪强度的增加或减少来以相对方式接近情绪识别。我们提出的模型通过将情绪识别任务划分为三个更容易的子任务来整合这些直接和相对预测视角。第一个子任务涉及视频的两个短片段之间的相对情绪强度的多模态本地排名。第二个子任务使用局部排名来用贝叶斯排序算法推断全局相对情绪等级。第三个子任务包括观察到的多模态行为的直接预测和来自最终情绪预测的局部 - 全局排名的相对情绪等级。我们的方法在视听情感识别基准测试中表现出优异的性能，并且优于其他多模式融合算法。

##### URL
[http://arxiv.org/abs/1809.04931](http://arxiv.org/abs/1809.04931)

##### PDF
[http://arxiv.org/pdf/1809.04931](http://arxiv.org/pdf/1809.04931)

