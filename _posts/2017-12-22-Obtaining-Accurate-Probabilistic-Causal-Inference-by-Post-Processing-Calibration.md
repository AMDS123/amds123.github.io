---
layout: post
title: "Obtaining Accurate Probabilistic Causal Inference by Post-Processing Calibration"
date: 2017-12-22 19:15:15
categories: arXiv_AI
tags: arXiv_AI Inference Prediction Relation
author: Fattaneh Jabbari, Mahdi Pakdaman Naeini, Gregory F. Cooper
mathjax: true
---

* content
{:toc}

##### Abstract
Discovery of an accurate causal Bayesian network structure from observational data can be useful in many areas of science. Often the discoveries are made under uncertainty, which can be expressed as probabilities. To guide the use of such discoveries, including directing further investigation, it is important that those probabilities be well-calibrated. In this paper, we introduce a novel framework to derive calibrated probabilities of causal relationships from observational data. The framework consists of three components: (1) an approximate method for generating initial probability estimates of the edge types for each pair of variables, (2) the availability of a relatively small number of the causal relationships in the network for which the truth status is known, which we call a calibration training set, and (3) a calibration method for using the approximate probability estimates and the calibration training set to generate calibrated probabilities for the many remaining pairs of variables. We also introduce a new calibration method based on a shallow neural network. Our experiments on simulated data support that the proposed approach improves the calibration of causal edge predictions. The results also support that the approach often improves the precision and recall of predictions.

##### Abstract (translated by Google)
从观测数据中发现准确的因果贝叶斯网络结构在许多科学领域可能是有用的。通常发现是在不确定的情况下做出的，可以用概率来表示。为了指导这些发现的使用，包括指导进一步的调查，重要的是要对这些概率进行精确的校准。在本文中，我们引入一个新的框架来从观测数据中导出校正的因果关系概率。该框架由三部分组成：（1）用于生成每对变量的边缘类型的初始概率估计的近似方法，（2）网络中相对少量的因果关系的可用性，其中真值状态是已知的，我们称之为校准训练集，以及（3）使用近似概率估计和校准训练集的校准方法来为许多其余的变量对生成校准概率。我们还介绍了一种基于浅层神经网络的新的校准方法。我们在模拟数据上的实验支持所提出的方法改进了因果边缘预测的校准。结果还支持该方法经常提高预测的精度和回忆。

##### URL
[http://arxiv.org/abs/1712.08626](http://arxiv.org/abs/1712.08626)

##### PDF
[http://arxiv.org/pdf/1712.08626](http://arxiv.org/pdf/1712.08626)

