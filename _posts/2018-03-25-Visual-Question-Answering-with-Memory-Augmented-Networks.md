---
layout: post
title: "Visual Question Answering with Memory-Augmented Networks"
date: 2018-03-25 09:46:14
categories: arXiv_CV
tags: arXiv_CV QA Attention VQA
author: Chao Ma, Chunhua Shen, Anthony Dick, Qi Wu, Peng Wang, Anton van den Hengel, Ian Reid
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we exploit a memory-augmented neural network to predict accurate answers to visual questions, even when those answers occur rarely in the training set. The memory network incorporates both internal and external memory blocks and selectively pays attention to each training exemplar. We show that memory-augmented neural networks are able to maintain a relatively long-term memory of scarce training exemplars, which is important for visual question answering due to the heavy-tailed distribution of answers in a general VQA setting. Experimental results on two large-scale benchmark datasets show the favorable performance of the proposed algorithm with a comparison to state of the art.

##### Abstract (translated by Google)
在本文中，我们利用记忆增强神经网络来预测视觉问题的准确答案，即使这些答案在训练集中很少发生。内存网络包含内部和外部内存块，并有选择地关注每个培训示例。我们表明，记忆增强神经网络能够保持稀缺训练样本的相对长期记忆，这对于视觉问题回答很重要，因为在一般的VQA设置中答案的重尾分布。两个大规模基准数据集的实验结果表明，与现有技术相比，该算法具有良好的性能。

##### URL
[https://arxiv.org/abs/1707.04968](https://arxiv.org/abs/1707.04968)

##### PDF
[https://arxiv.org/pdf/1707.04968](https://arxiv.org/pdf/1707.04968)

