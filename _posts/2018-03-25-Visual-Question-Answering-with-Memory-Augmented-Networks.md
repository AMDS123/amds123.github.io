---
layout: post
title: "Visual Question Answering with Memory-Augmented Networks"
date: 2018-03-25 09:46:14
categories: arXiv_CV
tags: arXiv_CV QA Attention VQA
author: Chao Ma, Chunhua Shen, Anthony Dick, Qi Wu, Peng Wang, Anton van den Hengel, Ian Reid
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we exploit a memory-augmented neural network to predict accurate answers to visual questions, even when those answers occur rarely in the training set. The memory network incorporates both internal and external memory blocks and selectively pays attention to each training exemplar. We show that memory-augmented neural networks are able to maintain a relatively long-term memory of scarce training exemplars, which is important for visual question answering due to the heavy-tailed distribution of answers in a general VQA setting. Experimental results on two large-scale benchmark datasets show the favorable performance of the proposed algorithm with a comparison to state of the art.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1707.04968](https://arxiv.org/abs/1707.04968)

##### PDF
[https://arxiv.org/pdf/1707.04968](https://arxiv.org/pdf/1707.04968)

