---
layout: post
title: "To Go or Not To Go? A Near Unsupervised Learning Approach For Robot Navigation"
date: 2017-09-16 00:39:19
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Detection
author: Noriaki Hirose, Amir Sadeghian, Patrick Goebel, Silvio Savarese
mathjax: true
---

* content
{:toc}

##### Abstract
It is important for robots to be able to decide whether they can go through a space or not, as they navigate through a dynamic environment. This capability can help them avoid injury or serious damage, e.g., as a result of running into people and obstacles, getting stuck, or falling off an edge. To this end, we propose an unsupervised and a near-unsupervised method based on Generative Adversarial Networks (GAN) to classify scenarios as traversable or not based on visual data. Our method is inspired by the recent success of data-driven approaches on computer vision problems and anomaly detection, and reduces the need for vast amounts of negative examples at training time. Collecting negative data indicating that a robot should not go through a space is typically hard and dangerous because of collisions, whereas collecting positive data can be automated and done safely based on the robot's own traveling experience. We verify the generality and effectiveness of the proposed approach on a test dataset collected in a previously unseen environment with a mobile robot. Furthermore, we show that our method can be used to build costmaps (we call as "GoNoGo" costmaps) for robot path planning using visual data only.

##### Abstract (translated by Google)
机器人能够决定他们是否能够通过一个空间是非常重要的，因为他们在一个动态的环境中进行导航。这种能力可以帮助他们避免伤害或严重的损害，例如，由于碰到人和障碍物，卡住或掉下来而造成的伤害。为此，本文提出了一种基于生成对抗网络（GAN）的无监督近似无监督方法，基于可视化数据将场景划分为可穿越或不可穿越。我们的方法受到最近在计算机视觉问题和异常检测方面数据驱动方法的成功启发，并减少了在培训时间对大量负面例子的需求。收集表明机器人不应该通过空间的负面数据通常是困难和危险的，因为碰撞，而收集正面的数据可以自动化，并根据机器人自己的旅行经验安全地完成。我们验证了所提出的方法在一个以前看不见的环境中采集的测试数据集的移动机器人的通用性和有效性。此外，我们显示我们的方法可以用于构建使用可视化数据的机器人路径规划的costmaps（我们称之为“GoNoGo”costmaps）。

##### URL
[https://arxiv.org/abs/1709.05439](https://arxiv.org/abs/1709.05439)

##### PDF
[https://arxiv.org/pdf/1709.05439](https://arxiv.org/pdf/1709.05439)

