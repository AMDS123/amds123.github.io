---
layout: post
title: "Vector Embedding of Wikipedia Concepts and Entities"
date: 2017-02-12 00:23:04
categories: arXiv_SD
tags: arXiv_SD Attention GAN Face Embedding Image_Classification Classification Deep_Learning
author: Ehsan Sherkat, Evangelos Milios
mathjax: true
---

* content
{:toc}

##### Abstract
Using deep learning for different machine learning tasks such as image classification and word embedding has recently gained many attentions. Its appealing performance reported across specific Natural Language Processing (NLP) tasks in comparison with other approaches is the reason for its popularity. Word embedding is the task of mapping words or phrases to a low dimensional numerical vector. In this paper, we use deep learning to embed Wikipedia Concepts and Entities. The English version of Wikipedia contains more than five million pages, which suggest its capability to cover many English Entities, Phrases, and Concepts. Each Wikipedia page is considered as a concept. Some concepts correspond to entities, such as a person's name, an organization or a place. Contrary to word embedding, Wikipedia Concepts Embedding is not ambiguous, so there are different vectors for concepts with similar surface form but different mentions. We proposed several approaches and evaluated their performance based on Concept Analogy and Concept Similarity tasks. The results show that proposed approaches have the performance comparable and in some cases even higher than the state-of-the-art methods.

##### Abstract (translated by Google)
针对不同的机器学习任务，如图像分类和文字嵌入，深度学习最近受到了很多关注。与其他方法相比，其在特定自然语言处理（NLP）任务中报告的吸引人的表现是其受欢迎的原因。字嵌入是将单词或短语映射到低维数值向量的任务。在本文中，我们使用深度学习来嵌入维基百科的概念和实体。维基百科的英文版包含超过五百万页，这表明其涵盖许多英文实体，短语和概念的能力。每个维基百科页面被认为是一个概念。一些概念与实体相对应，比如一个人的名字，一个组织或一个地方。与词嵌入相反，维基百科概念嵌入不是模糊的，所以对于具有相似表面形式但提及不同的概念，存在不同的向量。我们提出了几种方法，并基于概念类比和概念相似性任务对其性能进行评估。结果表明，所提出的方法具有可比的性能，并且在一些情况下甚至比现有技术的方法更高。

##### URL
[https://arxiv.org/abs/1702.03470](https://arxiv.org/abs/1702.03470)

##### PDF
[https://arxiv.org/pdf/1702.03470](https://arxiv.org/pdf/1702.03470)

