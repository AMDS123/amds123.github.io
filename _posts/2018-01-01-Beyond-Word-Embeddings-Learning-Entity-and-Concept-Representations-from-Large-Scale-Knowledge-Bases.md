---
layout: post
title: "Beyond Word Embeddings: Learning Entity and Concept Representations from Large Scale Knowledge Bases"
date: 2018-01-01 03:43:30
categories: arXiv_AI
tags: arXiv_AI Knowledge Embedding
author: Walid Shalaby, Wlodek Zadrozny, Hongxia Jin
mathjax: true
---

* content
{:toc}

##### Abstract
Text representation using neural word embeddings has proven efficacy in many NLP applications. Recently, a lot of research interest goes beyond word embeddings by adapting the traditional word embedding models to learn vectors of multiword expressions (concepts/entities). However, current methods are limited to textual knowledge bases only (e.g., Wikipedia). In this paper, we propose a novel approach for learning concept vectors from two large scale knowledge bases (Wikipedia, and Probase). We adapt the skip-gram model to seamlessly learn from the knowledge in Wikipedia text and Probase concept graph. We evaluate our concept embedding models intrinsically on two tasks: 1) analogical reasoning where we achieve a state-of-the-art performance of 91% on semantic analogies, 2) concept categorization where we achieve a state-of-the-art performance on two benchmark datasets achieving categorization accuracy of 100% on one and 98% on the other. Additionally, we present a case study to extrinsically evaluate our model on unsupervised argument type identification for neural semantic parsing. We demonstrate the competitive accuracy of our unsupervised method and its ability to better generalize to out of vocabulary entity mentions compared to the tedious and error prone methods which depend on gazetteers and regular expressions.

##### Abstract (translated by Google)
使用神经词嵌入的文本表示在许多NLP应用中已被证明是有效的。最近，通过使传统的词嵌入模型学习多词表达式（概念/实体）的向量，大量的研究兴趣超越了词嵌入。然而，目前的方法仅限于文本知识库（例如维基百科）。在本文中，我们提出了一种从两个大型知识库（Wikipedia和Probase）学习概念向量的新方法。我们调整跳跃模型，从维基百科文本和Probase概念图中的知识中无缝学习。我们评估我们的概念嵌入模型的本质上是两个任务：1）类比推理，我们达到了语义类比91％的最先进的表现，2）概念分类，我们实现了最先进的性能在两个基准数据集上实现100％的分类准确性，另一个为98％。此外，我们提出了一个案例研究外部评估我们的模型在无监督参数类型识别神经语义分析。我们证明了我们的无监督方法的竞争性准确性，以及相对于依赖于地名词典和正则表达式的繁琐易错的方法，它能更好地概括出词汇实体提及。

##### URL
[http://arxiv.org/abs/1801.00388](http://arxiv.org/abs/1801.00388)

##### PDF
[http://arxiv.org/pdf/1801.00388](http://arxiv.org/pdf/1801.00388)

