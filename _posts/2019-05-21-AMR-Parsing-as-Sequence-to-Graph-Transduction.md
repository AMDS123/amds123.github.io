---
layout: post
title: "AMR Parsing as Sequence-to-Graph Transduction"
date: 2019-05-21 15:41:18
categories: arXiv_CL
tags: arXiv_CL Attention
author: Sheng Zhang, Xutai Ma, Kevin Duh, Benjamin Van Durme
mathjax: true
---

* content
{:toc}

##### Abstract
We propose an attention-based model that treats AMR parsing as sequence-to-graph transduction. Unlike most AMR parsers that rely on pre-trained aligners, external semantic resources, or data augmentation, our proposed parser is aligner-free, and it can be effectively trained with limited amounts of labeled AMR data. Our experimental results outperform all previously reported SMATCH scores, on both AMR 2.0 (76.3% F1 on LDC2017T10) and AMR 1.0 (70.2% F1 on LDC2014T12).

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.08704](http://arxiv.org/abs/1905.08704)

##### PDF
[http://arxiv.org/pdf/1905.08704](http://arxiv.org/pdf/1905.08704)

