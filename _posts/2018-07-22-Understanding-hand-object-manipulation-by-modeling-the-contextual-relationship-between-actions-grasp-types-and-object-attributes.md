---
layout: post
title: "Understanding hand-object manipulation by modeling the contextual relationship between actions, grasp types and object attributes"
date: 2018-07-22 07:45:01
categories: arXiv_CV
tags: arXiv_CV Relation Recognition
author: Minjie Cai, Kris Kitani, Yoichi Sato
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a novel method for understanding daily hand-object manipulation by developing computer vision-based techniques. Specifically, we focus on recognizing hand grasp types, object attributes and manipulation actions within an unified framework by exploring their contextual relationships. Our hypothesis is that it is necessary to jointly model hands, objects and actions in order to accurately recognize multiple tasks that are correlated to each other in hand-object manipulation. In the proposed model, we explore various semantic relationships between actions, grasp types and object attributes, and show how the context can be used to boost the recognition of each component. We also explore the spatial relationship between the hand and object in order to detect the manipulated object from hand in cluttered environment. Experiment results on all three recognition tasks show that our proposed method outperforms traditional appearance-based methods which are not designed to take into account contextual relationships involved in hand-object manipulation. The visualization and generalizability study of the learned context further supports our hypothesis.

##### Abstract (translated by Google)
本文提出了一种通过开发基于计算机视觉的技术来理解日常手对象操纵的新方法。具体而言，我们通过探索其上下文关系，专注于在统一框架内识别手抓取类型，对象属性和操纵动作。我们的假设是，有必要联合模拟手，对象和动作，以便准确地识别在手 - 对象操纵中彼此相关的多个任务。在提出的模型中，我们探索了动作之间的各种语义关系，掌握了类型和对象属性，并展示了如何使用上下文来提升每个组件的识别。我们还探索了手与物体之间的空间关系，以便在杂乱的环境中从手中检测被操纵的物体。所有三个识别任务的实验结果表明，我们提出的方法优于传统的基于外观的方法，这些方法不是为了考虑手 - 对象操作中涉及的上下文关系而设计的。学习语境的可视化和普遍性研究进一步支持了我们的假设。

##### URL
[http://arxiv.org/abs/1807.08254](http://arxiv.org/abs/1807.08254)

##### PDF
[http://arxiv.org/pdf/1807.08254](http://arxiv.org/pdf/1807.08254)

