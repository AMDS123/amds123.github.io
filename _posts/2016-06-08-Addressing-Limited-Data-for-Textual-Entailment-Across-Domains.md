---
layout: post
title: "Addressing Limited Data for Textual Entailment Across Domains"
date: 2016-06-08 16:56:19
categories: arXiv_CL
tags: arXiv_CL
author: Chaitanya Shivade, Preethi Raghavan, Siddharth Patwardhan
mathjax: true
---

* content
{:toc}

##### Abstract
We seek to address the lack of labeled data (and high cost of annotation) for textual entailment in some domains. To that end, we first create (for experimental purposes) an entailment dataset for the clinical domain, and a highly competitive supervised entailment system, ENT, that is effective (out of the box) on two domains. We then explore self-training and active learning strategies to address the lack of labeled data. With self-training, we successfully exploit unlabeled data to improve over ENT by 15% F-score on the newswire domain, and 13% F-score on clinical data. On the other hand, our active learning experiments demonstrate that we can match (and even beat) ENT using only 6.6% of the training data in the clinical domain, and only 5.8% of the training data in the newswire domain.

##### Abstract (translated by Google)
我们试图解决某些领域缺乏标注数据（以及高昂的注释成本）的问题。为此，我们首先（为了实验目的）创建用于临床领域的包含数据集，以及在两个领域有效（开箱即用）的高度竞争的监督包含系统ENT。然后，我们探讨自我训练和积极的学习策略，以解决缺乏标签的数据。通过自我培训，我们成功地利用无标签数据在新闻专线领域提高15％的F-score，在临床数据上提高13％的F-score。另一方面，我们的主动学习实验表明，我们只能使用临床领域6.6％的训练数据来匹配（甚至击败）耳鼻喉科，而新闻专线领域只有5.8％的训练数据。

##### URL
[https://arxiv.org/abs/1606.02638](https://arxiv.org/abs/1606.02638)

##### PDF
[https://arxiv.org/pdf/1606.02638](https://arxiv.org/pdf/1606.02638)

