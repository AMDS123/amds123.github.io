---
layout: post
title: "Learning to Learn Semantic Parsers from Natural Language Supervision"
date: 2019-02-22 06:28:36
categories: arXiv_CL
tags: arXiv_CL
author: Igor Labutov, Bishan Yang, Tom Mitchell
mathjax: true
---

* content
{:toc}

##### Abstract
As humans, we often rely on language to learn language. For example, when corrected in a conversation, we may learn from that correction, over time improving our language fluency. Inspired by this observation, we propose a learning algorithm for training semantic parsers from supervision (feedback) expressed in natural language. Our algorithm learns a semantic parser from users' corrections such as "no, what I really meant was before his job, not after", by also simultaneously learning to parse this natural language feedback in order to leverage it as a form of supervision. Unlike supervision with gold-standard logical forms, our method does not require the user to be familiar with the underlying logical formalism, and unlike supervision from denotation, it does not require the user to know the correct answer to their query. This makes our learning algorithm naturally scalable in settings where existing conversational logs are available and can be leveraged as training data. We construct a novel dataset of natural language feedback in a conversational setting, and show that our method is effective at learning a semantic parser from such natural language supervision.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.08373](http://arxiv.org/abs/1902.08373)

##### PDF
[http://arxiv.org/pdf/1902.08373](http://arxiv.org/pdf/1902.08373)

