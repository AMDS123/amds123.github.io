---
layout: post
title: "Training Artificial Neural Networks by Generalized Likelihood Ratio Method: Exploring Brain-like Learning to Improve Adversarial Defensiveness"
date: 2019-01-31 09:14:16
categories: arXiv_AI
tags: arXiv_AI Adversarial Classification Deep_Learning
author: Li Xiao, Yijie Peng, Jeff Hong, Zewu Ke
mathjax: true
---

* content
{:toc}

##### Abstract
Recent work in deep learning has shown that the artificial neural networks are vulnerable to adversarial attacks, where a very small perturbation of the inputs can drastically alter the classification result. In this work, we propose a generalized likelihood ratio method capable of training the artificial neural networks with some biological brain-like mechanisms,.e.g., (a) learning by the loss value, (b) learning via neurons with discontinuous activation and loss functions. The traditional back propagation method cannot train the artificial neural networks with aforementioned brain-like learning mechanisms. Numerical results show that various artificial neural networks trained by the new method can significantly improve the defensiveness against the adversarial attacks. Code is available: \url{https://github.com/LX-doctorAI/GLR_ADV} .

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1902.00358](http://arxiv.org/abs/1902.00358)

##### PDF
[http://arxiv.org/pdf/1902.00358](http://arxiv.org/pdf/1902.00358)

