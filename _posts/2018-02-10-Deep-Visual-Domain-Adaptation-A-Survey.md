---
layout: post
title: "Deep Visual Domain Adaptation: A Survey"
date: 2018-02-10 14:35:27
categories: arXiv_CV
tags: arXiv_CV Review Object_Detection Segmentation Face Survey Embedding Image_Classification Semantic_Segmentation Classification Deep_Learning Detection Recognition Face_Recognition
author: Mei Wang, Weihong Deng
mathjax: true
---

* content
{:toc}

##### Abstract
Deep domain adaption has emerged as a new learning technique to address the lack of massive amounts of labeled data. Compared to conventional methods, which learn shared feature subspaces or reuse important source instances with shallow representations, deep domain adaption methods leverage deep networks to learn more transferable representations by embedding domain adaptation in the pipeline of deep learning. There have been comprehensive surveys for shallow domain adaption, but few timely reviews the emerging deep learning based methods. In this paper, we provide a comprehensive survey of deep domain adaptation methods for computer vision applications with four major contributions. First, we present a taxonomy of different deep domain adaption scenarios according to the properties of data that define how two domains are diverged. Second, we summarize deep domain adaption approaches into several categories based on training loss, and analyze and compare briefly the state-of-the-art methods under these categories. Third, we overview the computer vision applications that go beyond image classification, such as face recognition, semantic segmentation and object detection. Fourth, some potential deficiencies of current methods and several future directions are highlighted.

##### Abstract (translated by Google)
深度域适应已成为解决缺乏大量标记数据的新型学习技术。与传统方法学习共享特征子空间或重用浅层表示重用源实例相比，深层域自适应方法利用深度网络通过在深度学习的管道中嵌入域自适应学习更多可转移的表示。已经有关于浅层适应的全面调查，但很少及时回顾新兴的基于深度学习的方法。在本文中，我们提供了四个主要贡献的计算机视觉应用的深度域适应方法的综合调查。首先，根据定义两个域如何分离的数据属性，我们提出了不同深层域适应场景的分类。其次，我们基于训练损失将深度域自适应方法归纳为几类，并对这些类别下的最新方法进行简要分析和比较。第三，我们概述超越图像分类的计算机视觉应用，例如人脸识别，语义分割和对象检测。第四，强调了当前方法的一些潜在缺陷和几个未来方向。

##### URL
[http://arxiv.org/abs/1802.03601](http://arxiv.org/abs/1802.03601)

##### PDF
[http://arxiv.org/pdf/1802.03601](http://arxiv.org/pdf/1802.03601)

