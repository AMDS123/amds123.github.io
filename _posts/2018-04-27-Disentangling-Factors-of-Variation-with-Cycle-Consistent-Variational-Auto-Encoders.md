---
layout: post
title: "Disentangling Factors of Variation with Cycle-Consistent Variational Auto-Encoders"
date: 2018-04-27 12:37:35
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Ananya Harsh Jha, Saket Anand, Maneesh Singh, V. S. R. Veeravasarapu
mathjax: true
---

* content
{:toc}

##### Abstract
Generative models that learn disentangled representations for different factors of variation in an image can be very useful for targeted data augmentation. By sampling from the disentangled latent subspace of interest, we can efficiently generate new data necessary for a particular task. Learning disentangled representations is a challenging problem, especially when certain factors of variation are difficult to label. In this paper, we introduce a novel architecture that disentangles the latent space into two complementary subspaces by using only weak supervision in form of pairwise similarity labels. Inspired by the recent success of cycle-consistent adversarial architectures, we use cycle-consistency in a variational auto-encoder framework. Our non-adversarial approach is in contrast with the recent works that combine adversarial training with auto-encoders to disentangle representations. We show compelling results of disentangled latent subspaces on three datasets and compare with recent works that leverage adversarial training.

##### Abstract (translated by Google)
对于图像变化的不同因素学习解开表示的生成模型对于有针对性的数据增强可能非常有用。通过从感兴趣的解开的潜在子空间抽样，我们可以高效地生成特定任务所需的新数据。学习解开表示是一个具有挑战性的问题，特别是当某些变异因素难以标记时。在本文中，我们引入了一种新颖的体系结构，它通过仅使用两两相似标签形式的弱监督来将潜在空间解开为两个互补的子空间。受循环一致的对抗架构最近的成功启发，我们在变化的自动编码器框架中使用循环一致性。我们的非对抗方法与最近将对抗训练与自动编码器结合以解开表征的作品形成鲜明对比。我们展示了三个数据集上解开的潜在子空间的引人注目的结果，并与最近利用对抗训练的作品进行了比较。

##### URL
[https://arxiv.org/abs/1804.10469](https://arxiv.org/abs/1804.10469)

##### PDF
[https://arxiv.org/pdf/1804.10469](https://arxiv.org/pdf/1804.10469)

