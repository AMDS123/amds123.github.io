---
layout: post
title: "Path-Based Attention Neural Model for Fine-Grained Entity Typing"
date: 2018-01-09 02:56:13
categories: arXiv_CL
tags: arXiv_CL Attention
author: Denghui Zhang, Pengshan Cai, Yantao Jia, Manling Li, Yuanzhuo Wang, Xueqi Cheng
mathjax: true
---

* content
{:toc}

##### Abstract
Fine-grained entity typing aims to assign entity mentions in the free text with types arranged in a hierarchical structure. Traditional distant supervision based methods employ a structured data source as a weak supervision and do not need hand-labeled data, but they neglect the label noise in the automatically labeled training corpus. Although recent studies use many features to prune wrong data ahead of training, they suffer from error propagation and bring much complexity. In this paper, we propose an end-to-end typing model, called the path-based attention neural model (PAN), to learn a noise- robust performance by leveraging the hierarchical structure of types. Experiments demonstrate its effectiveness.

##### Abstract (translated by Google)
细粒度的实体输入旨在将自由文本中的实体提及与按层次结构排列的类型进行分配。传统的基于远程监控的方法采用结构化的数据源作为弱监督，不需要手工标注数据，而忽略了自动标注的训练语料库中的标签噪声。尽管最近的研究在训练之前使用许多特征来修剪错误的数据，但是它们受到错误传播的影响并且带来了很多复杂性在本文中，我们提出了一个端到端的打字模型，称为基于路径的注意神经模型（PAN），通过利用类型的层次结构来学习噪声鲁棒的性能。实验证明了它的有效性。

##### URL
[http://arxiv.org/abs/1710.10585](http://arxiv.org/abs/1710.10585)

##### PDF
[http://arxiv.org/pdf/1710.10585](http://arxiv.org/pdf/1710.10585)

