---
layout: post
title: "Linguistic Versus Latent Relations for Modeling Coherent Flow in Paragraphs"
date: 2019-08-30 15:30:11
categories: arXiv_AI
tags: arXiv_AI RNN Language_Model Prediction Relation
author: Dongyeop Kang, Hiroaki Hayashi, Alan W Black, Eduard Hovy
mathjax: true
---

* content
{:toc}

##### Abstract
Generating a long, coherent text such as a paragraph requires a high-level control of different levels of relations between sentences (e.g., tense, coreference). We call such a logical connection between sentences as a (paragraph) flow. In order to produce a coherent flow of text, we explore two forms of intersentential relations in a paragraph: one is a human-created linguistical relation that forms a structure (e.g., discourse tree) and the other is a relation from latent representation learned from the sentences themselves. Our two proposed models incorporate each form of relations into document-level language models: the former is a supervised model that jointly learns a language model as well as discourse relation prediction, and the latter is an unsupervised model that is hierarchically conditioned by a recurrent neural network (RNN) over the latent information. Our proposed models with both forms of relations outperform the baselines in partially conditioned paragraph generation task. Our codes and data are publicly available.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.11790](http://arxiv.org/abs/1908.11790)

##### PDF
[http://arxiv.org/pdf/1908.11790](http://arxiv.org/pdf/1908.11790)

