---
layout: post
title: "Feed Forward and Backward Run in Deep Convolution Neural Network"
date: 2017-11-09 07:32:30
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition CNN Classification Deep_Learning Recognition
author: Pushparaja Murugan
mathjax: true
---

* content
{:toc}

##### Abstract
Convolution Neural Networks (CNN), known as ConvNets are widely used in many visual imagery application, object classification, speech recognition. After the implementation and demonstration of the deep convolution neural network in Imagenet classification in 2012 by krizhevsky, the architecture of deep Convolution Neural Network is attracted many researchers. This has led to the major development in Deep learning frameworks such as Tensorflow, caffe, keras, theno. Though the implementation of deep learning is quite possible by employing deep learning frameworks, mathematical theory and concepts are harder to understand for new learners and practitioners. This article is intended to provide an overview of ConvNets architecture and to explain the mathematical theory behind it including activation function, loss function, feedforward and backward propagation. In this article, grey scale image is taken as input information image, ReLU and Sigmoid activation function are considered for developing the architecture and cross-entropy loss function are used for computing the difference between predicted value and actual value. The architecture is developed in such a way that it can contain one convolution layer, one pooling layer, and multiple dense layers

##### Abstract (translated by Google)
卷积神经网络（CNN），被称为ConvNets被广泛应用于许多视觉图像应用，对象分类，语音识别。深入卷积神经网络的结构在2012年由krizhevsky在Imagenet分类中实现和展示深度卷积神经网络之后，吸引了众多的研究者。这导致了Tensorflow，caffe，keras，soo等深度学习框架的重大发展。尽管深度学习的实施很有可能通过采用深度学习框架，但对于新的学习者和从业者来说，数学理论和概念难以理解。本文旨在概述ConvNets体系结构，并解释其背后的数学理论，包括激活函数，损失函数，前馈和后向传播。本文以灰度图像作为输入信息图像，考虑ReLU和Sigmoid激活函数的开发结构，利用交叉熵损失函数计算预测值与实际值的差值。该架构的开发方式可以包含一个卷积层，一个池层和多个密集层

##### URL
[https://arxiv.org/abs/1711.03278](https://arxiv.org/abs/1711.03278)

##### PDF
[https://arxiv.org/pdf/1711.03278](https://arxiv.org/pdf/1711.03278)

