---
layout: post
title: "Uncovering Temporal Context for Video Question and Answering"
date: 2015-11-15 07:57:41
categories: arXiv_CV
tags: arXiv_CV RNN
author: Linchao Zhu, Zhongwen Xu, Yi Yang, Alexander G. Hauptmann
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we introduce Video Question Answering in temporal domain to infer the past, describe the present and predict the future. We present an encoder-decoder approach using Recurrent Neural Networks to learn temporal structures of videos and introduce a dual-channel ranking loss to answer multiple-choice questions. We explore approaches for finer understanding of video content using question form of "fill-in-the-blank", and managed to collect 109,895 video clips with duration over 1,000 hours from TACoS, MPII-MD, MEDTest 14 datasets, while the corresponding 390,744 questions are generated from annotations. Extensive experiments demonstrate that our approach significantly outperforms the compared baselines.

##### Abstract (translated by Google)
在这项工作中，我们介绍视频问答在时间域推断过去，描述现在和预测未来。我们提出一种使用递归神经网络的编码器 - 解码器方法来学习视频的时间结构，并引入双通道排名损失来回答多项选择题。我们探索了使用问题形式“填空”来更好地理解视频内容的方法，并从TACoS，MPII-MD，MEDTest 14数据集中收集了109,895个持续时间超过1000小时的视频片段，而相应的390,744问题是从注释生成的。大量的实验表明，我们的方法明显优于比较的基线。

##### URL
[https://arxiv.org/abs/1511.04670](https://arxiv.org/abs/1511.04670)

##### PDF
[https://arxiv.org/pdf/1511.04670](https://arxiv.org/pdf/1511.04670)

