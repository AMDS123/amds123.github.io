---
layout: post
title: "Learning to Localize Sound Source in Visual Scenes"
date: 2018-03-10 18:19:02
categories: arXiv_CV
tags: arXiv_CV Attention
author: Arda Senocak, Tae-Hyun Oh, Junsik Kim, Ming-Hsuan Yang, In So Kweon
mathjax: true
---

* content
{:toc}

##### Abstract
Visual events are usually accompanied by sounds in our daily lives. We pose the question: Can the machine learn the correspondence between visual scene and the sound, and localize the sound source only by observing sound and visual scene pairs like human? In this paper, we propose a novel unsupervised algorithm to address the problem of localizing the sound source in visual scenes. A two-stream network structure which handles each modality, with attention mechanism is developed for sound source localization. Moreover, although our network is formulated within the unsupervised learning framework, it can be extended to a unified architecture with a simple modification for the supervised and semi-supervised learning settings as well. Meanwhile, a new sound source dataset is developed for performance evaluation. Our empirical evaluation shows that the unsupervised method eventually go through false conclusion in some cases. We show that even with a few supervision, false conclusion is able to be corrected and the source of sound in a visual scene can be localized effectively.

##### Abstract (translated by Google)
视觉事件通常伴随着我们日常生活中的声音。我们提出这样一个问题：机器能够学习视觉场景和声音之间的对应关系，并且只通过观察像人类一样的声音和视觉场景来定位声源吗？在本文中，我们提出了一种新的无监督算法来解决视觉场景中声源定位问题。处理每种形式的双流网络结构，并且为声源定位开发了注意机制。此外，尽管我们的网络是在无监督学习框架内制定的，但它也可以扩展到一个统一的体系结构，并对监督和半监督学习设置进行简单的修改。同时，为性能评估开发了一个新的声源数据集。我们的实证评估表明，在某些情况下，无监督方法最终会得到错误的结论。我们表明，即使有一些监督，错误的结论也能够得到纠正，并且可以有效地定位视觉场景中的声源。

##### URL
[https://arxiv.org/abs/1803.03849](https://arxiv.org/abs/1803.03849)

##### PDF
[https://arxiv.org/pdf/1803.03849](https://arxiv.org/pdf/1803.03849)

