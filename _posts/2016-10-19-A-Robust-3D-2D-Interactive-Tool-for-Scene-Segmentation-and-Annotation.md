---
layout: post
title: "A Robust 3D-2D Interactive Tool for Scene Segmentation and Annotation"
date: 2016-10-19 06:54:02
categories: arXiv_CV
tags: arXiv_CV Object_Detection Segmentation Detection Recognition
author: Duc Thanh Nguyen, Binh-Son Hua, Lap-Fai Yu, Sai-Kit Yeung
mathjax: true
---

* content
{:toc}

##### Abstract
Recent advances of 3D acquisition devices have enabled large-scale acquisition of 3D scene data. Such data, if completely and well annotated, can serve as useful ingredients for a wide spectrum of computer vision and graphics works such as data-driven modeling and scene understanding, object detection and recognition. However, annotating a vast amount of 3D scene data remains challenging due to the lack of an effective tool and/or the complexity of 3D scenes (e.g. clutter, varying illumination conditions). This paper aims to build a robust annotation tool that effectively and conveniently enables the segmentation and annotation of massive 3D data. Our tool works by coupling 2D and 3D information via an interactive framework, through which users can provide high-level semantic annotation for objects. We have experimented our tool and found that a typical indoor scene could be well segmented and annotated in less than 30 minutes by using the tool, as opposed to a few hours if done manually. Along with the tool, we created a dataset of over a hundred 3D scenes associated with complete annotations using our tool. The tool and dataset are available at www.scenenn.net.

##### Abstract (translated by Google)
3D采集设备的最新进展已经实现了3D场景数据的大规模采集。这些数据如果完整而详细地加以注释，可以作为计算机视觉和图形工作的有用组件，如数据驱动的建模和场景理解，物体检测和识别。然而，由于缺少有效的工具和/或3D场景的复杂性（例如杂波，变化的照明条件），注释大量的3D场景数据仍然具有挑战性。本文旨在构建一个强大的注释工具，可以有效，方便地实现海量三维数据的分割和注释。我们的工具通过一个交互框架耦合2D和3D信息，用户可以通过这个框架为对象提供高级语义注释。我们尝试了我们的工具，发现一个典型的室内场景可以在不到30分钟的时间内使用该工具进行良好的分段和注释，而手动完成则需要几个小时。与该工具一起，我们使用我们的工具创建了一个包含完整注释的超过一百个3D场景的数据集。工具和数据集可以在www.scenenn.net上找到。

##### URL
[https://arxiv.org/abs/1610.05883](https://arxiv.org/abs/1610.05883)

##### PDF
[https://arxiv.org/pdf/1610.05883](https://arxiv.org/pdf/1610.05883)

