---
layout: post
title: "Joint Training of Candidate Extraction and Answer Selection for Reading Comprehension"
date: 2018-05-16 06:14:31
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning Relation
author: Zhen Wang, Jiachen Liu, Xinyan Xiao, Yajuan Lyu, Tian Wu
mathjax: true
---

* content
{:toc}

##### Abstract
While sophisticated neural-based techniques have been developed in reading comprehension, most approaches model the answer in an independent manner, ignoring its relations with other answer candidates. This problem can be even worse in open-domain scenarios, where candidates from multiple passages should be combined to answer a single question. In this paper, we formulate reading comprehension as an extract-then-select two-stage procedure. We first extract answer candidates from passages, then select the final answer by combining information from all the candidates. Furthermore, we regard candidate extraction as a latent variable and train the two-stage process jointly with reinforcement learning. As a result, our approach has improved the state-of-the-art performance significantly on two challenging open-domain reading comprehension datasets. Further analysis demonstrates the effectiveness of our model components, especially the information fusion of all the candidates and the joint training of the extract-then-select procedure.

##### Abstract (translated by Google)
虽然在阅读理解中已经发展了复杂的基于神经的技术，但大多数方法都是以独立的方式对答案进行建模，忽略了与其他答案候选人的关系。在开放领域的情况下，这个问题可能会更糟，因为多个段落的候选人应该结合起来回答一个问题。在本文中，我们将阅读理解作为提取 - 然后选择两阶段过程。我们首先从段落中提取答案候选人，然后结合来自所有候选人的信息选择最终答案。此外，我们将候选抽取视为潜在变量，并与强化学习一起训练两阶段过程。因此，我们的方法在两个具有挑战性的开放领域阅读理解数据集上显着改善了最先进的性能。进一步的分析证明了我们的模型组件的有效性，特别是所有候选者的信息融合和提取 - 然后选择过程的联合训练。

##### URL
[http://arxiv.org/abs/1805.06145](http://arxiv.org/abs/1805.06145)

##### PDF
[http://arxiv.org/pdf/1805.06145](http://arxiv.org/pdf/1805.06145)

