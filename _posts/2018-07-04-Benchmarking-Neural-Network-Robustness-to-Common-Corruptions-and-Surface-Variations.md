---
layout: post
title: "Benchmarking Neural Network Robustness to Common Corruptions and Surface Variations"
date: 2018-07-04 17:57:11
categories: arXiv_AI
tags: arXiv_AI Adversarial Face
author: Dan Hendrycks, Thomas G. Dietterich
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Unlike recent robustness research, this benchmark evaluates performance on commonplace corruptions not worst-case adversarial corruptions. We find that there are negligible changes in relative corruption robustness from AlexNet to ResNet classifiers, and we discover ways to enhance corruption robustness. Then we propose a new dataset called Icons-50 which opens research on a new kind of robustness, surface variation robustness. With this dataset we evaluate the frailty of classifiers on new styles of known objects and unexpected instances of known classes. We also demonstrate two methods that improve surface variation robustness. Together our benchmarks may aid future work toward networks that learn fundamental class structure and also robustly generalize.

##### Abstract (translated by Google)
在本文中，我们为图像分类器的稳健性建立了严格的基准。我们的第一个基准ImageNet-C标准化和扩展了损坏稳健性主题，同时展示了哪些分类器在安全关键应用中更受欢迎。与最近的稳健性研究不同，该基准评估了普通腐败的表现，而非最坏情况的对抗性腐败。我们发现从AlexNet到ResNet分类器的相对损坏稳健性的变化可以忽略不计，我们发现了增强破坏稳健性的方法。然后我们提出了一个名为Icons-50的新数据集，它开启了对一种新的鲁棒性，表面变异鲁棒性的研究。使用此数据集，我们可以评估已知对象的新样式和已知类的意外实例的分类器的脆弱性。我们还展示了两种改善表面变异稳健性的方法。我们的基准测试可以共同帮助未来的工作向学习基本类结构的网络进行强有力的推广。

##### URL
[http://arxiv.org/abs/1807.01697](http://arxiv.org/abs/1807.01697)

##### PDF
[http://arxiv.org/pdf/1807.01697](http://arxiv.org/pdf/1807.01697)

