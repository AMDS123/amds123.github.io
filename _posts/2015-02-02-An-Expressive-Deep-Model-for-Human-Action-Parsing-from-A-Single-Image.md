---
layout: post
title: "An Expressive Deep Model for Human Action Parsing from A Single Image"
date: 2015-02-02 15:03:25
categories: arXiv_CV
tags: arXiv_CV Object_Detection Detection
author: Zhujin Liang, Xiaolong Wang, Rui Huang, Liang Lin
mathjax: true
---

* content
{:toc}

##### Abstract
This paper aims at one newly raising task in vision and multimedia research: recognizing human actions from still images. Its main challenges lie in the large variations in human poses and appearances, as well as the lack of temporal motion information. Addressing these problems, we propose to develop an expressive deep model to naturally integrate human layout and surrounding contexts for higher level action understanding from still images. In particular, a Deep Belief Net is trained to fuse information from different noisy sources such as body part detection and object detection. To bridge the semantic gap, we used manually labeled data to greatly improve the effectiveness and efficiency of the pre-training and fine-tuning stages of the DBN training. The resulting framework is shown to be robust to sometimes unreliable inputs (e.g., imprecise detections of human parts and objects), and outperforms the state-of-the-art approaches.

##### Abstract (translated by Google)
本文旨在提出一个新的视觉和多媒体研究任务：从静止图像中识别人类行为。它的主要挑战在于人类姿态和外表的巨大变化，以及缺乏时间运动信息。为了解决这些问题，我们建议开发一个表达深层的模型，自然地将人类布局和周围环境整合起来，从静止图像中获得更高层次的行动理解。特别是对深信仰网络进行训练，融合来自不同噪声源的信息，如身体部位检测和物体检测。为了弥合语义差距，我们使用人工标记的数据来大大提高DBN训练的预训练和微调阶段的有效性和效率。所得到的框架对于有时不可靠的输入（例如，不精确的人类部分和对象的检测）显示为稳健的，并且胜过最先进的方法。

##### URL
[https://arxiv.org/abs/1502.00501](https://arxiv.org/abs/1502.00501)

##### PDF
[https://arxiv.org/pdf/1502.00501](https://arxiv.org/pdf/1502.00501)

