---
layout: post
title: "One-Shot Fine-Grained Instance Retrieval"
date: 2017-07-04 03:51:32
categories: arXiv_CV
tags: arXiv_CV Image_Retrieval CNN
author: Hantao Yao, Shiliang Zhang, Yongdong Zhang, Jintao Li, Qi Tian
mathjax: true
---

* content
{:toc}

##### Abstract
Fine-Grained Visual Categorization (FGVC) has achieved significant progress recently. However, the number of fine-grained species could be huge and dynamically increasing in real scenarios, making it difficult to recognize unseen objects under the current FGVC framework. This raises an open issue to perform large-scale fine-grained identification without a complete training set. Aiming to conquer this issue, we propose a retrieval task named One-Shot Fine-Grained Instance Retrieval (OSFGIR). "One-Shot" denotes the ability of identifying unseen objects through a fine-grained retrieval task assisted with an incomplete auxiliary training set. This paper first presents the detailed description to OSFGIR task and our collected OSFGIR-378K dataset. Next, we propose the Convolutional and Normalization Networks (CN-Nets) learned on the auxiliary dataset to generate a concise and discriminative representation. Finally, we present a coarse-to-fine retrieval framework consisting of three components, i.e., coarse retrieval, fine-grained retrieval, and query expansion, respectively. The framework progressively retrieves images with similar semantics, and performs fine-grained identification. Experiments show our OSFGIR framework achieves significantly better accuracy and efficiency than existing FGVC and image retrieval methods, thus could be a better solution for large-scale fine-grained object identification.

##### Abstract (translated by Google)
细粒度视觉分类（FGVC）最近取得了重大进展。但是，在现实情况下，细粒物种的数量可能会非常庞大​​而且动态增加，这使得难以在现有的FGVC框架下识别出看不见的物体。这提出了一个开放的问题，没有一个完整的训练集进行大规模的细粒度识别。针对这一问题，提出了一种名为One-Shot Fine-Grained Instance Retrieval（OSFGIR）的检索任务。 “One-Shot”表示通过辅助不完全辅助训练集的细粒度检索任务来识别看不见的对象的能力。本文首先给出OSFGIR任务和我们收集的OSFGIR-378K数据集的详细描述。接下来，我们提出在辅助数据集上学习的卷积和规范化网络（CN-Nets），以产生简明和有区别的表示。最后，我们提出了一个由粗到细的检索和查询扩展三个部分组成的从粗到精的检索框架。该框架逐步检索具有相似语义的图像，并执行细粒度的识别。实验表明，我们的OSFGIR框架比现有的FGVC和图像检索方法具有更高的精度和效率，因此可以成为大规模细粒度物体识别的更好的解决方案。

##### URL
[https://arxiv.org/abs/1707.00811](https://arxiv.org/abs/1707.00811)

##### PDF
[https://arxiv.org/pdf/1707.00811](https://arxiv.org/pdf/1707.00811)

