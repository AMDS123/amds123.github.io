---
layout: post
title: "Guiding Reinforcement Learning Exploration Using Natural Language"
date: 2017-09-14 02:06:26
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning
author: Brent Harrison, Upol Ehsan, Mark O. Riedl
mathjax: true
---

* content
{:toc}

##### Abstract
In this work we present a technique to use natural language to help reinforcement learning generalize to unseen environments. This technique uses neural machine translation, specifically the use of encoder-decoder networks, to learn associations between natural language behavior descriptions and state-action information. We then use this learned model to guide agent exploration using a modified version of policy shaping to make it more effective at learning in unseen environments. We evaluate this technique using the popular arcade game, Frogger, under ideal and non-ideal conditions. This evaluation shows that our modified policy shaping algorithm improves over a Q-learning agent as well as a baseline version of policy shaping.

##### Abstract (translated by Google)
在这项工作中，我们提出了一种使用自然语言来帮助强化学习推广到看不见的环境的技术。这种技术使用神经机器翻译，特别是使用编码器 - 解码器网络来学习自然语言行为描述与状态动作信息之间的关联。然后，我们使用这个学习模型来指导代理人探索，使用修改版本的政策塑造，使其在看不见的环境中学习更有效。我们使用流行的街机游戏Frogger，在理想和非理想条件下评估这项技术。这个评估表明，我们修改后的策略整形算法比Q-learning代理以及策略整形的基线版本都有所改进。

##### URL
[https://arxiv.org/abs/1707.08616](https://arxiv.org/abs/1707.08616)

##### PDF
[https://arxiv.org/pdf/1707.08616](https://arxiv.org/pdf/1707.08616)

