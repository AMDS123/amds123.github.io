---
layout: post
title: "Multi-View Representation Learning: A Survey from Shallow Methods to Deep Methods"
date: 2017-09-01 05:52:06
categories: arXiv_CV
tags: arXiv_CV Review Sparse Survey Represenation_Learning RNN Relation
author: Yingming Li, Ming Yang, Zhongfei Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, multi-view representation learning has become a rapidly growing direction in machine learning and data mining areas. This paper introduces several principles for multi-view representation learning: correlation, consensus, and complementarity principles. Consequently, we first review the representative methods and theories of multi-view representation learning based on correlation principle, especially on canonical correlation analysis (CCA) and its several extensions. Then from the viewpoint of consensus and complementarity principles we investigate the advancement of multi-view representation learning that ranges from shallow methods including multi-modal topic learning, multi-view sparse coding, and multi-view latent space Markov networks, to deep methods including multi-modal restricted Boltzmann machines, multi-modal autoencoders, and multi-modal recurrent neural networks. Further, we also provide an important perspective from manifold alignment for multi-view representation learning. Overall, this survey aims to provide an insightful overview of theoretical basis and state-of-the-art developments in the field of multi-view representation learning and to help researchers find the most appropriate tools for particular applications.

##### Abstract (translated by Google)
最近，多视图表示学习已经成为机器学习和数据挖掘领域的一个迅速发展的方向。本文介绍了多视点表示学习的几个原则：相关性，共识性和互补性原则。因此，我们首先回顾了基于相关原理的多视图表示学习的代表方法和理论，特别是典型相关分析（CCA）及其几个扩展。然后从共识和互补原则的角度，我们研究了多视图表示学习的进展，从多模式主题学习，多视图稀疏编码，多视图潜在空间马尔可夫网络等浅层方法到深度方法包括多模式受限玻尔兹曼机器，多模态自编码器和多模式递归神经网络。此外，我们还提供了多视点表示学习的多重对齐的重要观点。总的来说，这次调查的目的是提供一个多视角表示学习领域的理论基础和最先进的发展的深刻概述，并帮助研究人员找到最适合特定应用的工具。

##### URL
[https://arxiv.org/abs/1610.01206](https://arxiv.org/abs/1610.01206)

##### PDF
[https://arxiv.org/pdf/1610.01206](https://arxiv.org/pdf/1610.01206)

