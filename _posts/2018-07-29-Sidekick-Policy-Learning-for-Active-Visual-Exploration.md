---
layout: post
title: "Sidekick Policy Learning for Active Visual Exploration"
date: 2018-07-29 06:32:42
categories: arXiv_CV
tags: arXiv_CV
author: Santhosh K. Ramakrishnan, Kristen Grauman
mathjax: true
---

* content
{:toc}

##### Abstract
We consider an active visual exploration scenario, where an agent must intelligently select its camera motions to efficiently reconstruct the full environment from only a limited set of narrow field-of-view glimpses. While the agent has full observability of the environment during training, it has only partial observability once deployed, being constrained by what portions it has seen and what camera motions are permissible. We introduce sidekick policy learning to capitalize on this imbalance of observability. The main idea is a preparatory learning phase that attempts simplified versions of the eventual exploration task, then guides the agent via reward shaping or initial policy supervision. To support interpretation of the resulting policies, we also develop a novel policy visualization technique. Results on active visual exploration tasks with 360 scenes and 3D objects show that sidekicks consistently improve performance and convergence rates over existing methods. Code, data and demos are available.

##### Abstract (translated by Google)
我们考虑一种主动的视觉探索场景，其中代理必须智能地选择其相机运动，以仅从有限的一组窄视场瞥见中有效地重建整个环境。虽然代理在训练期间具有完全的环境可观察性，但是一旦部署就具有部分可观察性，受到它所看到的部分以及允许的摄像机运动的约束。我们介绍了sidekick政策学习，以利用这种可观察性的不平衡。主要思想是预备学习阶段，尝试简化最终探索任务的版本，然后通过奖励塑造或初始政策监督来指导代理。为了支持对最终政策的解释，我们还开发了一种新颖的政策可视化技术。 360场景和3D对象的主动视觉探索任务的结果表明，与现有方法相比，sidekicks不断提高性能和收敛速度。可以使用代码，数据和演示。

##### URL
[http://arxiv.org/abs/1807.11010](http://arxiv.org/abs/1807.11010)

##### PDF
[http://arxiv.org/pdf/1807.11010](http://arxiv.org/pdf/1807.11010)

