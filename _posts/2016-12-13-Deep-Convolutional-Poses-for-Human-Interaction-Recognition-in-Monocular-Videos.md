---
layout: post
title: "Deep Convolutional Poses for Human Interaction Recognition in Monocular Videos"
date: 2016-12-13 00:22:58
categories: arXiv_CV
tags: arXiv_CV Pose_Estimation Action_Recognition CNN Recognition
author: Marcel Sheeny de Moraes, Sankha Mukherjee, Neil M Robertson
mathjax: true
---

* content
{:toc}

##### Abstract
Human interaction recognition is a challenging problem in computer vision and has been researched over the years due to its important applications. With the development of deep models for the human pose estimation problem, this work aims to verify the effectiveness of using the human pose in order to recognize the human interaction in monocular videos. This paper developed a method based on 5 steps: detect each person in the scene, track them, retrieve the human pose, extract features based on the pose and finally recognize the interaction using a classifier. The Two-Person interaction dataset was used for the development of this methodology. Using a whole sequence evaluation approach it achieved 87.56% of average accuracy of all interaction. Yun, et at achieved 91.10% using the same dataset, however their methodology used the depth sensor to recognize the interaction. The methodology developed in this paper shows that an RGB camera can be as effective as depth cameras to recognize the interaction between two persons using the recent development of deep models to estimate the human pose.

##### Abstract (translated by Google)
人类交互识别是计算机视觉中的一个挑战性问题，由于其重要的应用，多年来一直在进行研究。随着人体姿态估计问题深层模型的发展，本文旨在验证使用人体姿态的有效性，以便识别单眼视频中的人体交互。本文提出了一种基于5个步骤的方法：检测场景中的每个人，跟踪他们，检索人体姿势，基于姿态提取特征，并最终使用分类器识别交互。双人互动数据集被用于这种方法的发展。使用全序列评估方法，实现了所有交互的平均准确率的87.56％。 Yun等人使用相同的数据集达到了91.10％，但他们的方法使用深度传感器来识别相互作用。在本文中开发的方法表明，RGB摄像机可以像深度摄像机一样有效地识别两个人之间的相互作用，使用最近发展的深层模型来估计人的姿势。

##### URL
[https://arxiv.org/abs/1612.03982](https://arxiv.org/abs/1612.03982)

##### PDF
[https://arxiv.org/pdf/1612.03982](https://arxiv.org/pdf/1612.03982)

