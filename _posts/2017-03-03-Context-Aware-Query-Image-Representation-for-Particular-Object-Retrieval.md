---
layout: post
title: "Context Aware Query Image Representation for Particular Object Retrieval"
date: 2017-03-03 16:14:53
categories: arXiv_CV
tags: arXiv_CV Image_Caption Image_Retrieval Salient Attention CNN
author: Zakaria Laskar, Juho Kannala
mathjax: true
---

* content
{:toc}

##### Abstract
The current models of image representation based on Convolutional Neural Networks (CNN) have shown tremendous performance in image retrieval. Such models are inspired by the information flow along the visual pathway in the human visual cortex. We propose that in the field of particular object retrieval, the process of extracting CNN representations from query images with a given region of interest (ROI) can also be modelled by taking inspiration from human vision. Particularly, we show that by making the CNN pay attention on the ROI while extracting query image representation leads to significant improvement over the baseline methods on challenging Oxford5k and Paris6k datasets. Furthermore, we propose an extension to a recently introduced encoding method for CNN representations, regional maximum activations of convolutions (R-MAC). The proposed extension weights the regional representations using a novel saliency measure prior to aggregation. This leads to further improvement in retrieval accuracy.

##### Abstract (translated by Google)
目前基于卷积神经网络（CNN）的图像表示模型在图像检索中表现出了巨大的性能。这种模式受到人类视觉皮层视觉信息流的启发。我们提出，在特定对象检索领域，从具有给定兴趣区域（ROI）的查询图像中提取CNN表示的过程也可以通过从人类视觉获取灵感来建模。特别是，我们表明，通过使CNN关注投资回报率，同时提取查询图像表示导致显着改善比挑战Oxford5k和Paris6k数据集的基准方法。此外，我们提出了对最近引入的用于CNN表示的区域最大卷积激活（R-MAC）编码方法的扩展。所提出的扩展在聚合之前使用新的显着性度量来加权区域表示。这导致了检索精度的进一步提高。

##### URL
[https://arxiv.org/abs/1703.01226](https://arxiv.org/abs/1703.01226)

##### PDF
[https://arxiv.org/pdf/1703.01226](https://arxiv.org/pdf/1703.01226)

