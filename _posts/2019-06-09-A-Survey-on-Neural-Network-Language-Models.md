---
layout: post
title: "A Survey on Neural Network Language Models"
date: 2019-06-09 08:15:53
categories: arXiv_CL
tags: arXiv_CL Survey Language_Model
author: Kun Jing, Jungang Xu, Ben He
mathjax: true
---

* content
{:toc}

##### Abstract
As the core component of Natural Language Processing (NLP) system, Language Model (LM) can provide word representation and probability indication of word sequences. Neural Network Language Models (NNLMs) overcome the curse of dimensionality and improve the performance of traditional LMs. A survey on NNLMs is performed in this paper. The structure of classic NNLMs is described firstly, and then some major improvements are introduced and analyzed. We summarize and compare corpora and toolkits of NNLMs. Further, some research directions of NNLMs are discussed.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1906.03591](http://arxiv.org/abs/1906.03591)

##### PDF
[http://arxiv.org/pdf/1906.03591](http://arxiv.org/pdf/1906.03591)

