---
layout: post
title: "Dynamic Bernoulli Embeddings for Language Evolution"
date: 2017-03-23 13:00:14
categories: arXiv_SD
tags: arXiv_SD Embedding
author: Maja Rudolph, David Blei
mathjax: true
---

* content
{:toc}

##### Abstract
Word embeddings are a powerful approach for unsupervised analysis of language. Recently, Rudolph et al. (2016) developed exponential family embeddings, which cast word embeddings in a probabilistic framework. Here, we develop dynamic embeddings, building on exponential family embeddings to capture how the meanings of words change over time. We use dynamic embeddings to analyze three large collections of historical texts: the U.S. Senate speeches from 1858 to 2009, the history of computer science ACM abstracts from 1951 to 2014, and machine learning papers on the Arxiv from 2007 to 2015. We find dynamic embeddings provide better fits than classical embeddings and capture interesting patterns about how language changes.

##### Abstract (translated by Google)
词嵌入是对语言进行无监督分析的有效方法。最近，Rudolph等人（2016）开发了指数族嵌入，将概念框架中的词嵌入。在这里，我们开发动态嵌入，建立在指数族嵌入上，以捕捉单词的含义随着时间的变化。我们使用动态嵌入来分析三大历史文本集：1858年至2009年的美国参议院演讲，1951年至2014年的计算机科学ACM摘要史以及2007年至2015年的Arxiv机器学习论文。我们发现动态嵌入提供比经典嵌入更好的拟合，并捕捉关于语言如何变化的有趣模式。

##### URL
[https://arxiv.org/abs/1703.08052](https://arxiv.org/abs/1703.08052)

##### PDF
[https://arxiv.org/pdf/1703.08052](https://arxiv.org/pdf/1703.08052)

