---
layout: post
title: "Understanding Infographics through Textual and Visual Tag Prediction"
date: 2017-09-26 18:45:28
categories: arXiv_CV
tags: arXiv_CV Prediction
author: Zoya Bylinskii, Sami Alsheikh, Spandan Madan, Adria Recasens, Kimberli Zhong, Hanspeter Pfister, Fredo Durand, Aude Oliva
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce the problem of visual hashtag discovery for infographics: extracting visual elements from an infographic that are diagnostic of its topic. Given an infographic as input, our computational approach automatically outputs textual and visual elements predicted to be representative of the infographic content. Concretely, from a curated dataset of 29K large infographic images sampled across 26 categories and 391 tags, we present an automated two step approach. First, we extract the text from an infographic and use it to predict text tags indicative of the infographic content. And second, we use these predicted text tags as a supervisory signal to localize the most diagnostic visual elements from within the infographic i.e. visual hashtags. We report performances on a categorization and multi-label tag prediction problem and compare our proposed visual hashtags to human annotations.

##### Abstract (translated by Google)
我们介绍了信息图表的视觉主题标签发现问题：从信息图表中提取视觉元素来诊断其主题。以信息图为输入，我们的计算方法自动输出预测为信息图表内容的文本和视觉元素。具体来说，从26个类别的29K大型图表图像和391个标签采集的数据集中，我们提出了一个自动化的两步法。首先，我们从信息图中提取文本，并使用它来预测表示信息图内容的文本标签。其次，我们使用这些预测的文本标签作为监控信号来定位来自信息图中最具诊断性的视觉元素，即视觉主题标签。我们报告分类和多标签标签预测问题的表现，并比较我们提出的视觉主题标签和人类注释。

##### URL
[https://arxiv.org/abs/1709.09215](https://arxiv.org/abs/1709.09215)

##### PDF
[https://arxiv.org/pdf/1709.09215](https://arxiv.org/pdf/1709.09215)

