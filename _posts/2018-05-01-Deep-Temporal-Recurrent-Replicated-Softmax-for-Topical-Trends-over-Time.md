---
layout: post
title: "Deep Temporal-Recurrent-Replicated-Softmax for Topical Trends over Time"
date: 2018-05-01 09:17:46
categories: arXiv_AI
tags: arXiv_AI RNN
author: Pankaj Gupta, Subburam Rajaram, Hinrich Sch&#xfc;tze, Bernt Andrassy
mathjax: true
---

* content
{:toc}

##### Abstract
Dynamic topic modeling facilitates the identification of topical trends over time in temporal collections of unstructured documents. We introduce a novel unsupervised neural dynamic topic model named as Recurrent Neural Network-Replicated Softmax Model (RNNRSM), where the discovered topics at each time influence the topic discovery in the subsequent time steps. We account for the temporal ordering of documents by explicitly modeling a joint distribution of latent topical dependencies over time, using distributional estimators with temporal recurrent connections. Applying RNN-RSM to 19 years of articles on NLP research, we demonstrate that compared to state-of-the art topic models, RNNRSM shows better generalization, topic interpretation, evolution and trends. We also introduce a metric (named as SPAN) to quantify the capability of dynamic topic model to capture word evolution in topics over time.

##### Abstract (translated by Google)
动态主题建模有助于识别非结构化文档的时间集合中随时间变化的主题趋势。我们引入了一种新的无监督神经动态主题模型，称为递归神经网络 - 复制Softmax模型（RNNRSM），其中每次发现的主题影响后续时间步骤中的主题发现。我们通过使用具有时间重复连接的分布估计来明确地建模潜在的主题依赖关系随时间的联合分布来解释文档的时间排序。将RNN-RSM应用于19年关于NLP研究的文章，我们证明了与最先进的主题模型相比，RNNRSM显示出更好的概括，主题解释，演变和趋势。我们还引入了一个度量（命名为SPAN）来量化动态主题模型在主题中捕获单词演变的能力。

##### URL
[http://arxiv.org/abs/1711.05626](http://arxiv.org/abs/1711.05626)

##### PDF
[http://arxiv.org/pdf/1711.05626](http://arxiv.org/pdf/1711.05626)

