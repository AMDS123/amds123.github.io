---
layout: post
title: "You said that?"
date: 2017-07-18 14:58:55
categories: arXiv_CV
tags: arXiv_CV Face Embedding
author: Joon Son Chung, Amir Jamaludin, Andrew Zisserman
mathjax: true
---

* content
{:toc}

##### Abstract
We present a method for generating a video of a talking face. The method takes as inputs: (i) still images of the target face, and (ii) an audio speech segment; and outputs a video of the target face lip synched with the audio. The method runs in real time and is applicable to faces and audio not seen at training time. To achieve this we propose an encoder-decoder CNN model that uses a joint embedding of the face and audio to generate synthesised talking face video frames. The model is trained on tens of hours of unlabelled videos. We also show results of re-dubbing videos using speech from a different person.

##### Abstract (translated by Google)
我们提出一种生成谈话人脸视频的方法。该方法作为输入：（i）目标脸部的静止图像，和（ii）音频语音片段;并输出与音频同步的目标人脸的视频。该方法实时运行，适用于训练时未见的面孔和音频。为了实现这一点，我们提出了一种编码器 - 解码器CNN模型，其使用脸部和音频的联合嵌入来生成合成的交谈脸部视频帧。该模型是训练了几十个小时的未标记视频。我们还展示了使用另一个人的演讲重新录制视频的结果。

##### URL
[https://arxiv.org/abs/1705.02966](https://arxiv.org/abs/1705.02966)

##### PDF
[https://arxiv.org/pdf/1705.02966](https://arxiv.org/pdf/1705.02966)

