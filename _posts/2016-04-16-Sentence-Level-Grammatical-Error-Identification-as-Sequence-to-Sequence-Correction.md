---
layout: post
title: "Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction"
date: 2016-04-16 01:49:09
categories: arXiv_SD
tags: arXiv_SD Attention Prediction
author: Allen Schmaltz, Yoon Kim, Alexander M. Rush, Stuart M. Shieber
mathjax: true
---

* content
{:toc}

##### Abstract
We demonstrate that an attention-based encoder-decoder model can be used for sentence-level grammatical error identification for the Automated Evaluation of Scientific Writing (AESW) Shared Task 2016. The attention-based encoder-decoder models can be used for the generation of corrections, in addition to error identification, which is of interest for certain end-user applications. We show that a character-based encoder-decoder model is particularly effective, outperforming other results on the AESW Shared Task on its own, and showing gains over a word-based counterpart. Our final model--a combination of three character-based encoder-decoder models, one word-based encoder-decoder model, and a sentence-level CNN--is the highest performing system on the AESW 2016 binary prediction Shared Task.

##### Abstract (translated by Google)
我们证明，基于注意力的编码器 - 解码器模型可以用于科学写作自动评估（AESW）共享任务2016的句子级语法错误识别。基于注意力的编码器 - 解码器模型可以用于生成更正，除了错误识别，这是某些最终用户应用感兴趣的。我们展示了一个基于字符的编码器 - 解码器模型是特别有效的，它比AESW共享任务上的其他结果本身更胜一筹，并且显示出了基于单词的对手的收益。我们的最终模型是三个基于字符的编码器 - 解码器模型，一个基于字的编码器 - 解码器模型和一个句子级CNN的组合，是AESW 2016二进制预测共享任务中性能最高的系统。

##### URL
[https://arxiv.org/abs/1604.04677](https://arxiv.org/abs/1604.04677)

##### PDF
[https://arxiv.org/pdf/1604.04677](https://arxiv.org/pdf/1604.04677)

