---
layout: post
title: "Fast and Accurate Single Image Super-Resolution via Information Distillation Network"
date: 2018-03-26 07:56:54
categories: arXiv_CV
tags: arXiv_CV Super_Resolution Face CNN
author: Zheng Hui, Xiumei Wang, Xinbo Gao
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, deep convolutional neural networks (CNNs) have been demonstrated remarkable progress on single image super-resolution. However, as the depth and width of the networks increase, CNN-based super-resolution methods have been faced with the challenges of computational complexity and memory consumption in practice. In order to solve the above questions, we propose a deep but compact convolutional network to directly reconstruct the high resolution image from the original low resolution image. In general, the proposed model consists of three parts, which are feature extraction block, stacked information distillation blocks and reconstruction block respectively. By combining an enhancement unit with a compression unit into a distillation block, the local long and short-path features can be effectively extracted. Specifically, the proposed enhancement unit mixes together two different types of features and the compression unit distills more useful information for the sequential blocks. In addition, the proposed network has the advantage of fast execution due to the comparatively few numbers of filters per layer and the use of group convolution. Experimental results demonstrate that the proposed method is superior to the state-of-the-art methods, especially in terms of time performance.

##### Abstract (translated by Google)
最近，深度卷积神经网络（CNN）在单幅图像超分辨率方面取得了显着进展。然而，随着网络深度和宽度的增加，基于CNN的超分辨率方法在实践中面临着计算复杂度和内存消耗的挑战。为了解决上述问题，我们提出了一种深度但紧凑的卷积网络，以从原始低分辨率图像直接重建高分辨率图像。一般来说，该模型由三部分组成，分别是特征提取块，叠加信息蒸馏块和重构块。通过将增强单元与压缩单元组合到蒸馏块中，可以有效地提取局部长短路径特征。具体而言，所提出的增强单元将两种不同类型的特征混合在一起，并且压缩单元为顺序块提取更有用的信息。此外，由于每层滤波器的数量较少并且使用组卷积，所提出的网络具有快速执行的优点。实验结果表明，所提出的方法优于最先进的方法，尤其是在时间性能方面。

##### URL
[https://arxiv.org/abs/1803.09454](https://arxiv.org/abs/1803.09454)

##### PDF
[https://arxiv.org/pdf/1803.09454](https://arxiv.org/pdf/1803.09454)

