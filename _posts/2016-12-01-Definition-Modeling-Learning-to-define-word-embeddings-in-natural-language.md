---
layout: post
title: "Definition Modeling: Learning to define word embeddings in natural language"
date: 2016-12-01 19:42:37
categories: arXiv_CL
tags: arXiv_CL Embedding RNN Relation
author: Thanapon Noraset, Chen Liang, Larry Birnbaum, Doug Downey
mathjax: true
---

* content
{:toc}

##### Abstract
Distributed representations of words have been shown to capture lexical semantics, as demonstrated by their effectiveness in word similarity and analogical relation tasks. But, these tasks only evaluate lexical semantics indirectly. In this paper, we study whether it is possible to utilize distributed representations to generate dictionary definitions of words, as a more direct and transparent representation of the embeddings' semantics. We introduce definition modeling, the task of generating a definition for a given word and its embedding. We present several definition model architectures based on recurrent neural networks, and experiment with the models over multiple data sets. Our results show that a model that controls dependencies between the word being defined and the definition words performs significantly better, and that a character-level convolution layer designed to leverage morphology can complement word-level embeddings. Finally, an error analysis suggests that the errors made by a definition model may provide insight into the shortcomings of word embeddings.

##### Abstract (translated by Google)
已经显示词的分布式表示捕捉词汇语义，如其在词相似性和类比关系任务中的有效性所证明的。但是，这些任务只是间接评估词汇语义。在本文中，我们研究是否有可能利用分布式表示来生成字典的字典定义，作为嵌入语义的更直接和透明的表示。我们引入定义建模，为给定的单词生成定义及其嵌入的任务。我们提出了几种基于递归神经网络的定义模型体系结构，并对多个数据集上的模型进行了实验。我们的研究结果表明，控制被定义的单词和定义单词之间的依赖关系的模型表现得更好，并且设计为利用形态学的字符级卷积层可以补充字级嵌入。最后，错误分析表明，由定义模型所产生的错误可能会提供洞察字嵌入的缺点。

##### URL
[https://arxiv.org/abs/1612.00394](https://arxiv.org/abs/1612.00394)

##### PDF
[https://arxiv.org/pdf/1612.00394](https://arxiv.org/pdf/1612.00394)

