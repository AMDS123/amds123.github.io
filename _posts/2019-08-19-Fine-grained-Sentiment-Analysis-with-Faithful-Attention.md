---
layout: post
title: "Fine-grained Sentiment Analysis with Faithful Attention"
date: 2019-08-19 15:11:27
categories: arXiv_CL
tags: arXiv_CL Sentiment Relation_Extraction Attention Sentiment_Classification Classification Relation
author: Ruiqi Zhong, Steven Shao, Kathleen McKeown
mathjax: true
---

* content
{:toc}

##### Abstract
While the general task of textual sentiment classification has been widely studied, much less research looks specifically at sentiment between a specified source and target. To tackle this problem, we experimented with a state-of-the-art relation extraction model. Surprisingly, we found that despite reasonable performance, the model's attention was often systematically misaligned with the words that contribute to sentiment. Thus, we directly trained the model's attention with human rationales and improved our model performance by a robust 4~8 points on all tasks we defined on our data sets. We also present a rigorous analysis of the model's attention, both trained and untrained, using novel and intuitive metrics. Our results show that untrained attention does not provide faithful explanations; however, trained attention with concisely annotated human rationales not only increases performance, but also brings faithful explanations. Encouragingly, a small amount of annotated human rationales suffice to correct the attention in our task.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1908.06870](http://arxiv.org/abs/1908.06870)

##### PDF
[http://arxiv.org/pdf/1908.06870](http://arxiv.org/pdf/1908.06870)

