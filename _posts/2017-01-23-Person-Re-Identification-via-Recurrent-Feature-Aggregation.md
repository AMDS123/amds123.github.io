---
layout: post
title: "Person Re-Identification via Recurrent Feature Aggregation"
date: 2017-01-23 12:05:16
categories: arXiv_CV
tags: arXiv_CV Re-identification Person_Re-identification RNN
author: Yichao Yan, Bingbing Ni, Zhichao Song, Chao Ma, Yan Yan, Xiaokang Yang
mathjax: true
---

* content
{:toc}

##### Abstract
We address the person re-identification problem by effectively exploiting a globally discriminative feature representation from a sequence of tracked human regions/patches. This is in contrast to previous person re-id works, which rely on either single frame based person to person patch matching, or graph based sequence to sequence matching. We show that a progressive/sequential fusion framework based on long short term memory (LSTM) network aggregates the frame-wise human region representation at each time stamp and yields a sequence level human feature representation. Since LSTM nodes can remember and propagate previously accumulated good features and forget newly input inferior ones, even with simple hand-crafted features, the proposed recurrent feature aggregation network (RFA-Net) is effective in generating highly discriminative sequence level human representations. Extensive experimental results on two person re-identification benchmarks demonstrate that the proposed method performs favorably against state-of-the-art person re-identification methods.

##### Abstract (translated by Google)
我们通过有效地利用来自一系列被跟踪的人类区域/补丁的全局辨别特征表示来解决人重新识别问题。这与先前的人员重新编号作品形成对比，后者依赖于基于单个框架的人对人补丁匹配或基于图的序列来进行顺序匹配。我们表明，基于长期短期记忆（LSTM）网络的渐进/顺序融合框架聚合每个时间戳帧帧的人类区域表示，并产生序列级别的人类特征表示。由于LSTM节点可以记住和传播以前积累的好的特征，并且忘记了新输入的低级特征，所以即使具有简单的手工特征，所提出的递归特征聚合网络（RFA-Net）也能有效地产生高度区别的序列级人类表示。对两人重新识别基准的广泛的实验结果表明，所提出的方法对于最先进的人重新识别方法有利。

##### URL
[https://arxiv.org/abs/1701.06351](https://arxiv.org/abs/1701.06351)

##### PDF
[https://arxiv.org/pdf/1701.06351](https://arxiv.org/pdf/1701.06351)

