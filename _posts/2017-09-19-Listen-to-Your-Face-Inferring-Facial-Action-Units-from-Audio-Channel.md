---
layout: post
title: "Listen to Your Face: Inferring Facial Action Units from Audio Channel"
date: 2017-09-19 14:27:00
categories: arXiv_CV
tags: arXiv_CV Face Inference Relation Recognition
author: Zibo Meng, Shizhong Han, Yan Tong
mathjax: true
---

* content
{:toc}

##### Abstract
Extensive efforts have been devoted to recognizing facial action units (AUs). However, it is still challenging to recognize AUs from spontaneous facial displays especially when they are accompanied with speech. Different from all prior work that utilized visual observations for facial AU recognition, this paper presents a novel approach that recognizes speech-related AUs exclusively from audio signals based on the fact that facial activities are highly correlated with voice during speech. Specifically, dynamic and physiological relationships between AUs and phonemes are modeled through a continuous time Bayesian network (CTBN); then AU recognition is performed by probabilistic inference via the CTBN model. A pilot audiovisual AU-coded database has been constructed to evaluate the proposed audio-based AU recognition framework. The database consists of a "clean" subset with frontal and neutral faces and a challenging subset collected with large head movements and occlusions. Experimental results on this database show that the proposed CTBN model achieves promising recognition performance for 7 speech-related AUs and outperforms the state-of-the-art visual-based methods especially for those AUs that are activated at low intensities or "hardly visible" in the visual channel. Furthermore, the CTBN model yields more impressive recognition performance on the challenging subset, where the visual-based approaches suffer significantly.

##### Abstract (translated by Google)
已经致力于识别面部动作单元（AU）。然而，从自发的面部表情中识别AU仍然是一个挑战，特别是在伴随言语的情况下。与以往所有利用视觉观察进行面部AU识别的工作不同，本文提出了一种基于面部活动与语音中的声音高度相关的事实，从音频信号中完全识别与语音相关的AU的新方法。具体而言，通过连续时间贝叶斯网络（CTBN）建模AU和音素之间的动态和生理关系;然后通过CTBN模型通过概率推理进行AU识别。已经构建了一个试点视听AU编码数据库来评估提出的基于音频的AU识别框架。数据库由一个“干净”的子集组成，具有正面和中性面孔，以及一个具有挑战性的子集，头部有大的运动和遮挡。该数据库的实验结果表明，所提出的CTBN模型对于7个语音相关的AU实现了有希望的识别性能，并且优于最先进的基于视觉的方法，尤其是对于以低强度或“难以察觉”在视觉渠道。此外，CTBN模型在具有挑战性的子集上产生更多令人印象深刻的识别性能，其中基于视觉的方法显着受损。

##### URL
[https://arxiv.org/abs/1706.07536](https://arxiv.org/abs/1706.07536)

##### PDF
[https://arxiv.org/pdf/1706.07536](https://arxiv.org/pdf/1706.07536)

