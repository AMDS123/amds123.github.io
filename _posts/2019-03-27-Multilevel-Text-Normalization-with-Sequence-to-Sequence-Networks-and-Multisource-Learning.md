---
layout: post
title: "Multilevel Text Normalization with Sequence-to-Sequence Networks and Multisource Learning"
date: 2019-03-27 10:50:23
categories: arXiv_CL
tags: arXiv_CL Segmentation GAN Language_Model
author: Tatyana Ruzsics, Tanja Samard&#x17e;i&#x107;
mathjax: true
---

* content
{:toc}

##### Abstract
We define multilevel text normalization as sequence-to-sequence processing that transforms naturally noisy text into a sequence of normalized units of meaning (morphemes) in three steps: 1) writing normalization, 2) lemmatization, 3) canonical segmentation. These steps are traditionally considered separate NLP tasks, with diverse solutions, evaluation schemes and data sources. We exploit the fact that all these tasks involve sub-word sequence-to-sequence transformation to propose a systematic solution for all of them using neural encoder-decoder technology. The specific challenge that we tackle in this paper is integrating the traditional know-how on separate tasks into the neural sequence-to-sequence framework to improve the state of the art. We address this challenge by enriching the general framework with mechanisms that allow processing the information on multiple levels of text organization (characters, morphemes, words, sentences) in combination with structural information (multilevel language model, part-of-speech) and heterogeneous sources (text, dictionaries). We show that our solution consistently improves on the current methods in all three steps. In addition, we analyze the performance of our system to show the specific contribution of the integrating components to the overall improvement.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.11340](http://arxiv.org/abs/1903.11340)

##### PDF
[http://arxiv.org/pdf/1903.11340](http://arxiv.org/pdf/1903.11340)

