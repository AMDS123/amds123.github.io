---
layout: post
title: "Cued@wmt19:ewc&lms"
date: 2019-06-11 17:49:57
categories: arXiv_CL
tags: arXiv_CL Language_Model
author: Felix Stahlberg, Danielle Saunders, Adria de Gispert, Bill Byrne
mathjax: true
---

* content
{:toc}

##### Abstract
Two techniques provide the fabric of the Cambridge University Engineering Department's (CUED) entry to the WMT19 evaluation campaign: elastic weight consolidation (EWC) and different forms of language modelling (LMs). We report substantial gains by fine-tuning very strong baselines on former WMT test sets using a combination of checkpoint averaging and EWC. A sentence-level Transformer LM and a document-level LM based on a modified Transformer architecture yield further gains. As in previous years, we also extract $n$-gram probabilities from SMT lattices which can be seen as a source-conditioned $n$-gram LM.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1906.05447](https://arxiv.org/abs/1906.05447)

##### PDF
[https://arxiv.org/pdf/1906.05447](https://arxiv.org/pdf/1906.05447)

