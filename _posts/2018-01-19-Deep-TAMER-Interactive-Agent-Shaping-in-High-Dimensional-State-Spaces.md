---
layout: post
title: "Deep TAMER: Interactive Agent Shaping in High-Dimensional State Spaces"
date: 2018-01-19 20:36:13
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Deep_Learning
author: Garrett Warnell, Nicholas Waytowich, Vernon Lawhern, Peter Stone
mathjax: true
---

* content
{:toc}

##### Abstract
While recent advances in deep reinforcement learning have allowed autonomous learning agents to succeed at a variety of complex tasks, existing algorithms generally require a lot of training data. One way to increase the speed at which agents are able to learn to perform tasks is by leveraging the input of human trainers. Although such input can take many forms, real-time, scalar-valued feedback is especially useful in situations where it proves difficult or impossible for humans to provide expert demonstrations. Previous approaches have shown the usefulness of human input provided in this fashion (e.g., the TAMER framework), but they have thus far not considered high-dimensional state spaces or employed the use of deep learning. In this paper, we do both: we propose Deep TAMER, an extension of the TAMER framework that leverages the representational power of deep neural networks in order to learn complex tasks in just a short amount of time with a human trainer. We demonstrate Deep TAMER's success by using it and just 15 minutes of human-provided feedback to train an agent that performs better than humans on the Atari game of Bowling - a task that has proven difficult for even state-of-the-art reinforcement learning methods.

##### Abstract (translated by Google)
虽然最近在深度强化学习方面取得的进展使得自主学习机构能够在各种复杂的任务中取得成功，但是现有的算法通常需要大量的训练数据。提高代理人学习执行任务速度的一种方法是利用人员培训者的投入。虽然这样的输入可以采取多种形式，但实时标量定义的反馈在人类难以或不可能提供专家示范的情况下特别有用。先前的方法已经显示了以这种方式提供的人类输入（例如TAMER框架）的有用性，但是迄今为止他们尚未考虑高维状态空间或者采用深度学习。在本文中，我们做了两个：我们提出Deep TAMER，它是TAMER框架的扩展，它利用深度神经网络的代表性能力，以便在短时间内与人类教练学习复杂的任务。我们通过使用它来展示Deep TAMER的成功，仅用15分钟的人为反馈来训练在Atari保龄球游戏上表现比人类更好的代理 - 这项任务已经证明，即使是最先进的强化学习方法。

##### URL
[http://arxiv.org/abs/1709.10163](http://arxiv.org/abs/1709.10163)

##### PDF
[http://arxiv.org/pdf/1709.10163](http://arxiv.org/pdf/1709.10163)

