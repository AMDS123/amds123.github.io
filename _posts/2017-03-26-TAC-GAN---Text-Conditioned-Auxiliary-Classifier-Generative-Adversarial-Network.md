---
layout: post
title: "TAC-GAN - Text Conditioned Auxiliary Classifier Generative Adversarial Network"
date: 2017-03-26 11:29:21
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN
author: Ayushman Dash, John Cristian Borges Gamboa, Sheraz Ahmed, Marcus Liwicki, Muhammad Zeshan Afzal
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we present the Text Conditioned Auxiliary Classifier Generative Adversarial Network, (TAC-GAN) a text to image Generative Adversarial Network (GAN) for synthesizing images from their text descriptions. Former approaches have tried to condition the generative process on the textual data; but allying it to the usage of class information, known to diversify the generated samples and improve their structural coherence, has not been explored. We trained the presented TAC-GAN model on the Oxford-102 dataset of flowers, and evaluated the discriminability of the generated images with Inception-Score, as well as their diversity using the Multi-Scale Structural Similarity Index (MS-SSIM). Our approach outperforms the state-of-the-art models, i.e., its inception score is 3.45, corresponding to a relative increase of 7.8% compared to the recently introduced StackGan. A comparison of the mean MS-SSIM scores of the training and generated samples per class shows that our approach is able to generate highly diverse images with an average MS-SSIM of 0.14 over all generated classes.

##### Abstract (translated by Google)
在这项工作中，我们提出文本条件辅助分类器生成敌对网络（TAC-GAN）文本图像生成敌对网络（GAN）合成图像从他们的文字说明。前面的方法试图调整文本数据的生成过程;但是将它与使用已知的多样化生成的样品并改善它们的结构一致性的类信息联系在一起尚未被探索。我们在Oxford-102数据集上对TAC-GAN模型进行了训练，并使用多尺度结构相似性指数（MS-SSIM）评估了生成的图像与Inception-Score的差别以及它们的多样性。我们的方法胜过最先进的模型，即它的初始分数是3.45，相对于最近引入的StackGan，相对增加了7.8％。训练和每类生成样本的平均MS-SSIM得分的比较表明，我们的方法能够生成高度多样化的图像，在所有生成的类别上平均MS-SSIM为0.14。

##### URL
[https://arxiv.org/abs/1703.06412](https://arxiv.org/abs/1703.06412)

##### PDF
[https://arxiv.org/pdf/1703.06412](https://arxiv.org/pdf/1703.06412)

