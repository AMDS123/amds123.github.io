---
layout: post
title: "Automatic Ground Truths: Projected Image Annotations for Omnidirectional Vision"
date: 2017-09-12 05:38:42
categories: arXiv_CV
tags: arXiv_CV Object_Detection Tracking Detection Recognition
author: Victor Stamatescu, Peter Barsznica, Manjung Kim, Kin K. Liu, Mark McKenzie, Will Meakin, Gwilyn Saunders, Sebastien C. Wong, Russell S. A. Brinkworth
mathjax: true
---

* content
{:toc}

##### Abstract
We present a novel data set made up of omnidirectional video of multiple objects whose centroid positions are annotated automatically. Omnidirectional vision is an active field of research focused on the use of spherical imagery in video analysis and scene understanding, involving tasks such as object detection, tracking and recognition. Our goal is to provide a large and consistently annotated video data set that can be used to train and evaluate new algorithms for these tasks. Here we describe the experimental setup and software environment used to capture and map the 3D ground truth positions of multiple objects into the image. Furthermore, we estimate the expected systematic error on the mapped positions. In addition to final data products, we release publicly the software tools and raw data necessary to re-calibrate the camera and/or redo this mapping. The software also provides a simple framework for comparing the results of standard image annotation tools or visual tracking systems against our mapped ground truth annotations.

##### Abstract (translated by Google)
我们提出了一个新的数据集组成的全方位视频的多个对象的质心位置自动注释。全方位视觉是一个活跃的研究领域，专注于在视频分析和场景理解中使用球形图像，涉及诸如对象检测，跟踪和识别等任务。我们的目标是提供一个大的，一致的注释视频数据集，可以用来训练和评估这些任务的新算法。在这里，我们描述了用于捕捉和映射多个对象的3D地面真实位置到图像中的实验设置和软件环境。此外，我们估计映射位置上的预期系统误差。除了最终的数据产品之外，我们还公布了重新校准摄像机和/或重做这个映射所必需的软件工具和原始数据。该软件还提供了一个简单的框架，用于将标准图像注释工具或视觉跟踪系统的结果与我们映射的地面真实注释进行比较。

##### URL
[https://arxiv.org/abs/1709.03697](https://arxiv.org/abs/1709.03697)

##### PDF
[https://arxiv.org/pdf/1709.03697](https://arxiv.org/pdf/1709.03697)

