---
layout: post
title: "Convolutional-Recurrent Neural Networks for Speech Enhancement"
date: 2018-05-02 00:06:53
categories: arXiv_CL
tags: arXiv_CL Knowledge CNN RNN
author: Han Zhao, Shuayb Zarar, Ivan Tashev, Chin-Hui Lee
mathjax: true
---

* content
{:toc}

##### Abstract
We propose an end-to-end model based on convolutional and recurrent neural networks for speech enhancement. Our model is purely data-driven and does not make any assumptions about the type or the stationarity of the noise. In contrast to existing methods that use multilayer perceptrons (MLPs), we employ both convolutional and recurrent neural network architectures. Thus, our approach allows us to exploit local structures in both the frequency and temporal domains. By incorporating prior knowledge of speech signals into the design of model structures, we build a model that is more data-efficient and achieves better generalization on both seen and unseen noise. Based on experiments with synthetic data, we demonstrate that our model outperforms existing methods, improving PESQ by up to 0.6 on seen noise and 0.64 on unseen noise.

##### Abstract (translated by Google)
我们提出了一种基于卷积和递归神经网络的语音增强端到端模型。我们的模型纯粹是数据驱动的，不会对噪声的类型或平稳性做任何假设。与使用多层感知器（MLPs）的现有方法相反，我们采用卷积和递归神经网络架构。因此，我们的方法允许我们利用频域和时域的局部结构。通过将语音信号的先验知识整合到模型结构的设计中，我们构建了一个更具数据效率的模型，并且实现了对看得见和看不见的噪声的更好泛化。基于对合成数据的实验，我们证明我们的模型优于现有方法，PESQ在噪声上可以提高0.6，在看不见噪声时可提高0.64。

##### URL
[https://arxiv.org/abs/1805.00579](https://arxiv.org/abs/1805.00579)

##### PDF
[https://arxiv.org/pdf/1805.00579](https://arxiv.org/pdf/1805.00579)

