---
layout: post
title: "From Zero-shot Learning to Conventional Supervised Classification: Unseen Visual Data Synthesis"
date: 2017-05-04 10:28:37
categories: arXiv_CV
tags: arXiv_CV Classification Recognition
author: Yang Long, Li Liu, Ling Shao, Fumin Shen, Guiguang Ding, Jungong Han
mathjax: true
---

* content
{:toc}

##### Abstract
Robust object recognition systems usually rely on powerful feature extraction mechanisms from a large number of real images. However, in many realistic applications, collecting sufficient images for ever-growing new classes is unattainable. In this paper, we propose a new Zero-shot learning (ZSL) framework that can synthesise visual features for unseen classes without acquiring real images. Using the proposed Unseen Visual Data Synthesis (UVDS) algorithm, semantic attributes are effectively utilised as an intermediate clue to synthesise unseen visual features at the training stage. Hereafter, ZSL recognition is converted into the conventional supervised problem, i.e. the synthesised visual features can be straightforwardly fed to typical classifiers such as SVM. On four benchmark datasets, we demonstrate the benefit of using synthesised unseen data. Extensive experimental results suggest that our proposed approach significantly improve the state-of-the-art results.

##### Abstract (translated by Google)
鲁棒的对象识别系统通常依靠大量实际图像中强大的特征提取机制。但是，在许多实际应用中，为不断增长的新课程收集足够的图像是不可能的。在本文中，我们提出了一个新的零镜头学习（ZSL）框架，可以合成看不见的类的视觉特征，而不需要获取真实的图像。使用提出的Unseen Visual Data Synthesis（UVDS）算法，语义属性被有效地用作在训练阶段综合看不见的视觉特征的中间线索。此后，ZSL识别被转换成常规的监督问题，即合成的视觉特征可以被直接地馈送到典型的分类器例如SVM。在四个基准数据集上，我们展示了使用合成的不可见数据的好处。广泛的实验结果表明，我们提出的方法显着改善了最新的结果。

##### URL
[https://arxiv.org/abs/1705.01782](https://arxiv.org/abs/1705.01782)

##### PDF
[https://arxiv.org/pdf/1705.01782](https://arxiv.org/pdf/1705.01782)

