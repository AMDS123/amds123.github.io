---
layout: post
title: "Robust and Scalable Differentiable Neural Computer for Question Answering"
date: 2018-07-07 12:44:32
categories: arXiv_CL
tags: arXiv_CL Deep_Learning
author: J&#xf6;rg Franke, Jan Niehues, Alex Waibel
mathjax: true
---

* content
{:toc}

##### Abstract
Deep learning models are often not easily adaptable to new tasks and require task-specific adjustments. The differentiable neural computer (DNC), a memory-augmented neural network, is designed as a general problem solver which can be used in a wide range of tasks. But in reality, it is hard to apply this model to new tasks. We analyze the DNC and identify possible improvements within the application of question answering. This motivates a more robust and scalable DNC (rsDNC). The objective precondition is to keep the general character of this model intact while making its application more reliable and speeding up its required training time. The rsDNC is distinguished by a more robust training, a slim memory unit and a bidirectional architecture. We not only achieve new state-of-the-art performance on the bAbI task, but also minimize the performance variance between different initializations. Furthermore, we demonstrate the simplified applicability of the rsDNC to new tasks with passable results on the CNN RC task without adaptions.

##### Abstract (translated by Google)
深度学习模型通常不易适应新任务，需要特定于任务的调整。可微分神经计算机（DNC）是一种记忆增强神经网络，被设计为一般问题解决者，可用于各种任务。但实际上，很难将此模型应用于新任务。我们分析DNC并确定问答环境中可能的改进。这激发了更强大和可扩展的DNC（rsDNC）。客观的前提条件是保持该模型的一般特征，同时使其应用更加可靠，并加快其所需的培训时间。 rsDNC的特点是更强大的训练，纤薄的内存单元和双向架构。我们不仅在bAbI任务上实现了最新的最新性能，而且还最小化了不同初始化之间的性能差异。此外，我们演示了rsDNC对新任务的简化适用性，在没有自适应的情况下，CNN RC任务具有可通过的结果。

##### URL
[http://arxiv.org/abs/1807.02658](http://arxiv.org/abs/1807.02658)

##### PDF
[http://arxiv.org/pdf/1807.02658](http://arxiv.org/pdf/1807.02658)

