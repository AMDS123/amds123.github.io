---
layout: post
title: "Focusing on What is Relevant: Time-Series Learning and Understanding using Attention"
date: 2018-06-22 07:16:08
categories: arXiv_CV
tags: arXiv_CV Attention Classification Deep_Learning Detection
author: Phongtharin Vinayavekhin, Subhajit Chaudhury, Asim Munawar, Don Joven Agravante, Giovanni De Magistris, Daiki Kimura, Ryuki Tachibana
mathjax: true
---

* content
{:toc}

##### Abstract
This paper is a contribution towards interpretability of the deep learning models in different applications of time-series. We propose a temporal attention layer that is capable of selecting the relevant information to perform various tasks, including data completion, key-frame detection and classification. The method uses the whole input sequence to calculate an attention value for each time step. This results in more focused attention values and more plausible visualisation than previous methods. We apply the proposed method to three different tasks. Experimental results show that the proposed network produces comparable results to a state of the art. In addition, the network provides better interpretability of the decision, that is, it generates more significant attention weight to related frames compared to similar techniques attempted in the past.

##### Abstract (translated by Google)
本文是对深度学习模型在不同时间序列应用中可解释性的贡献。我们提出一个时间关注层，能够选择相关信息来执行各种任务，包括数据完成，关键帧检测和分类。该方法使用整个输入序列来计算每个时间步的关注值。这导致了比以前的方法更集中的关注值和更可信的可视化。我们将所提出的方法应用于三个不同的任务。实验结果表明，所提出的网络产生与现有技术水平相当的结果。此外，网络提供了更好的决策解释能力，也就是说，与过去尝试的类似技术相比，它对相关框架产生了更大的关注度。

##### URL
[http://arxiv.org/abs/1806.08523](http://arxiv.org/abs/1806.08523)

##### PDF
[http://arxiv.org/pdf/1806.08523](http://arxiv.org/pdf/1806.08523)

