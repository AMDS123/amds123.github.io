---
layout: post
title: "Continuous Learning in Single-Incremental-Task Scenarios"
date: 2018-06-22 09:22:42
categories: arXiv_AI
tags: arXiv_AI Regularization Knowledge
author: Davide Maltoni, Vincenzo Lomonaco
mathjax: true
---

* content
{:toc}

##### Abstract
It was recently shown that architectural, regularization and rehearsal strategies can be used to train deep models sequentially on a number of disjoint tasks without forgetting previously acquired knowledge. However, these strategies are still unsatisfactory if the tasks are not disjoint but constitute a single incremental task (e.g., class-incremental learning). In this paper we point out the differences between multi-task and single-incremental-task scenarios and show that well-known approaches such as LWF, EWC and SI are not ideal for incremental task scenarios. A new approach, denoted as AR1, combining architectural and regularization strategies is then specifically proposed. AR1 overhead (in term of memory and computation) is very small thus making it suitable for online learning. When tested on CORe50 and iCIFAR-100, AR1 outperformed existing regularization strategies by a good margin.

##### Abstract (translated by Google)
最近的研究表明，建筑，正规化和排练策略可以用来在许多不相交的任务上依次训练深层模型，而不会忘记以前获得的知识。然而，如果这些任务不是不相交而是一个单一的增量任务（例如，阶级增量学习），那么这些策略仍然不令人满意。在本文中，我们指出了多任务和单增量任务场景之间的差异，并指出诸如LWF，EWC和SI等众所周知的方法对于增量任务场景并不理想。然后专门提出一种新方法，称为AR1，将建筑和正则化战略相结合。 AR1开销（在内存和计算方面）非常小，因此适合在线学习。在CORe50和iCIFAR-100上进行测试时，AR1的表现优于现有正规化策略。

##### URL
[http://arxiv.org/abs/1806.08568](http://arxiv.org/abs/1806.08568)

##### PDF
[http://arxiv.org/pdf/1806.08568](http://arxiv.org/pdf/1806.08568)

