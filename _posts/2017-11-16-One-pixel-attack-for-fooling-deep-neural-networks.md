---
layout: post
title: "One pixel attack for fooling deep neural networks"
date: 2017-11-16 07:58:35
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Jiawei Su, Danilo Vasconcellos Vargas, Sakurai Kouichi
mathjax: true
---

* content
{:toc}

##### Abstract
Recent research has revealed that the output of Deep Neural Networks (DNN) can be easily altered by adding relatively small perturbations to the input vector. In this paper, we analyze an attack in an extremely limited scenario where only one pixel can be modified. For that we propose a novel method for generating one-pixel adversarial perturbations based on differential evolution. It requires less adversarial information and can fool more types of networks. The results show that 70.97% of the natural images can be perturbed to at least one target class by modifying just one pixel with 97.47% confidence on average. Thus, the proposed attack explores a different take on adversarial machine learning in an extreme limited scenario, showing that current DNNs are also vulnerable to such low dimension attacks.

##### Abstract (translated by Google)
最近的研究表明，深度神经网络（DNN）的输出可以通过向输入向量添加相对较小的扰动而容易地改变。在本文中，我们分析了一个非常有限的情况下只能修改一个像素的攻击。为此，我们提出了一种新的基于差分进化的单像素对抗扰动方法。它需要较少的敌对信息，可以欺骗更多类型的网络。结果表明，70.97％的自然图像可以被扰动到至少一个目标类通过修改一个像素平均97.47％的置信度。因此，所提出的攻击在极端有限的情况下探讨了不同的对抗机器学习，表明当前的DNN也容易受到这种低维攻击。

##### URL
[https://arxiv.org/abs/1710.08864](https://arxiv.org/abs/1710.08864)

##### PDF
[https://arxiv.org/pdf/1710.08864](https://arxiv.org/pdf/1710.08864)

