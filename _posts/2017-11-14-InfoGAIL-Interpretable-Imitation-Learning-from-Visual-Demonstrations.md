---
layout: post
title: "InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations"
date: 2017-11-14 21:51:21
categories: arXiv_CV
tags: arXiv_CV Adversarial
author: Yunzhu Li, Jiaming Song, Stefano Ermon
mathjax: true
---

* content
{:toc}

##### Abstract
The goal of imitation learning is to mimic expert behavior without access to an explicit reward signal. Expert demonstrations provided by humans, however, often show significant variability due to latent factors that are typically not explicitly modeled. In this paper, we propose a new algorithm that can infer the latent structure of expert demonstrations in an unsupervised way. Our method, built on top of Generative Adversarial Imitation Learning, can not only imitate complex behaviors, but also learn interpretable and meaningful representations of complex behavioral data, including visual demonstrations. In the driving domain, we show that a model learned from human demonstrations is able to both accurately reproduce a variety of behaviors and accurately anticipate human actions using raw visual inputs. Compared with various baselines, our method can better capture the latent structure underlying expert demonstrations, often recovering semantically meaningful factors of variation in the data.

##### Abstract (translated by Google)
模仿学习的目的是模仿专家行为而不能获得明确的奖励信号。然而，由人类提供的专家演示通常由于通常未被明确建模的潜在因素而显示出显着的可变性。在本文中，我们提出了一种新的算法，可以以无监督的方式推断专家演示的潜在结构。我们的方法建立在生成敌对模仿学习的基础之上，不仅可以模仿复杂的行为，还可以学习复杂的行为数据（包括视觉演示）的可解释和有意义的表示。在驾驶领域，我们展示了从人类示范中学习的模型能够准确地再现各种行为，并使用原始视觉输入准确地预测人类行为。与各种基线相比，我们的方法可以更好地捕捉潜在的专家示范潜在结构，往往恢复语义上有意义的数据变异因素。

##### URL
[https://arxiv.org/abs/1703.08840](https://arxiv.org/abs/1703.08840)

##### PDF
[https://arxiv.org/pdf/1703.08840](https://arxiv.org/pdf/1703.08840)

