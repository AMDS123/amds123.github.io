---
layout: post
title: "Non-myopic learning in repeated stochastic games"
date: 2018-01-19 13:54:51
categories: arXiv_AI
tags: arXiv_AI
author: Jacob W. Crandall
mathjax: true
---

* content
{:toc}

##### Abstract
In repeated stochastic games (RSGs), an agent must quickly adapt to the behavior of previously unknown associates, who may themselves be learning. This machine-learning problem is particularly challenging due, in part, to the presence of multiple (even infinite) equilibria and inherently large strategy spaces. In this paper, we introduce a method to reduce the strategy space of two-player general-sum RSGs to a handful of expert strategies. This process, called Mega, effectually reduces an RSG to a bandit problem. We show that the resulting strategy space preserves several important properties of the original RSG, thus enabling a learner to produce robust strategies within a reasonably small number of interactions. To better establish strengths and weaknesses of this approach, we empirically evaluate the resulting learning system against other algorithms in three different RSGs.

##### Abstract (translated by Google)
在重复的随机博弈（RSGs）中，代理人必须很快地适应先前未知的可能正在学习的同事的行为。这个机器学习问题特别具有挑战性，部分原因是存在多个（甚至是无限的）均衡和固有的大战略空间。在本文中，我们介绍一种将双人一般和RSG的策略空间减少到少数专家策略的方法。这个称为Mega的过程有效地将RSG减少为一个强盗问题。我们表明，由此产生的策略空间保留了原始RSG的几个重要属性，从而使学习者能够在相当少量的交互中产生稳健的策略。为了更好地建立这种方法的优点和缺点，我们在三个不同的RSG中，根据其他算法对实验结果进行了实证评估。

##### URL
[http://arxiv.org/abs/1409.8498](http://arxiv.org/abs/1409.8498)

##### PDF
[http://arxiv.org/pdf/1409.8498](http://arxiv.org/pdf/1409.8498)

