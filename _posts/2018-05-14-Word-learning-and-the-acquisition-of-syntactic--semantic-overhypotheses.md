---
layout: post
title: "Word learning and the acquisition of syntactic--semantic overhypotheses"
date: 2018-05-14 02:20:07
categories: arXiv_CL
tags: arXiv_CL Face Inference
author: Jon Gauthier, Roger Levy, Joshua B. Tenenbaum
mathjax: true
---

* content
{:toc}

##### Abstract
Children learning their first language face multiple problems of induction: how to learn the meanings of words, and how to build meaningful phrases from those words according to syntactic rules. We consider how children might solve these problems efficiently by solving them jointly, via a computational model that learns the syntax and semantics of multi-word utterances in a grounded reference game. We select a well-studied empirical case in which children are aware of patterns linking the syntactic and semantic properties of words --- that the properties picked out by base nouns tend to be related to shape, while prenominal adjectives tend to refer to other properties such as color. We show that children applying such inductive biases are accurately reflecting the statistics of child-directed speech, and that inducing similar biases in our computational model captures children's behavior in a classic adjective learning experiment. Our model incorporating such biases also demonstrates a clear data efficiency in learning, relative to a baseline model that learns without forming syntax-sensitive overhypotheses of word meaning. Thus solving a more complex joint inference problem may make the full problem of language acquisition easier, not harder.

##### Abstract (translated by Google)
学习第一语言的孩子会面临多种归纳问题：如何学习单词的含义，以及如何根据句法规则从这些单词中建立有意义的短语。我们考虑孩子们如何通过联合解决这些问题来有效地解决这些问题，通过计算模型来学习在地面参考游戏中的多词语的语法和语义。我们选择在其中的孩子都知道的连接词的句法和语义性模式的充分研究的实证案例---该特性通过基地挑选出来的名词往往是相关的形状，而prenominal形容词往往会参考其他性能如颜色。我们表明，应用这种归纳偏见的儿童准确地反映了儿童导向言语的统计数据，并且在我们的计算模型中引发类似的偏差可以捕捉儿童在经典形容词学习实验中的行为。与没有形成对语义敏感的词义含义的学习基线模型相比，包含这种偏倚的我们模型在学习上也表现出明显的数据效率。因此，解决更复杂的联合推理问题可能会使得语言获取的全部问题更容易，而不是更难。

##### URL
[https://arxiv.org/abs/1805.04988](https://arxiv.org/abs/1805.04988)

##### PDF
[https://arxiv.org/pdf/1805.04988](https://arxiv.org/pdf/1805.04988)

