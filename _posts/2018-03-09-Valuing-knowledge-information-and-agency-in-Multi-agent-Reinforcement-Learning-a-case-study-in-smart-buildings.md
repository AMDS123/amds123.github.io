---
layout: post
title: "Valuing knowledge, information and agency in Multi-agent Reinforcement Learning: a case study in smart buildings"
date: 2018-03-09 12:48:03
categories: arXiv_AI
tags: arXiv_AI Knowledge Reinforcement_Learning Optimization
author: Hussain Kazmi, Johan Suykens, Johan Driesen
mathjax: true
---

* content
{:toc}

##### Abstract
Increasing energy efficiency in buildings can reduce costs and emissions substantially. Historically, this has been treated as a local, or single-agent, optimization problem. However, many buildings utilize the same types of thermal equipment e.g. electric heaters and hot water vessels. During operation, occupants in these buildings interact with the equipment differently thereby driving them to diverse regions in the state-space. Reinforcement learning agents can learn from these interactions, recorded as sensor data, to optimize the overall energy efficiency. However, if these agents operate individually at a household level, they can not exploit the replicated structure in the problem. In this paper, we demonstrate that this problem can indeed benefit from multi-agent collaboration by making use of targeted exploration of the state-space allowing for better generalization. We also investigate trade-offs between integrating human knowledge and additional sensors. Results show that savings of over 40% are possible with collaborative multi-agent systems making use of either expert knowledge or additional sensors with no loss of occupant comfort. We find that such multi-agent systems comfortably outperform comparable single agent systems.

##### Abstract (translated by Google)
提高建筑物的能效可以大幅降低成本和排放量。从历史上看，这被视为本地或单一代理优化问题。然而，许多建筑物使用相同类型的热设备，例如，电加热器和热水容器。在操作过程中，这些建筑物中的居住者与设备发生不同的交互作用，从而将他们驱动到状态空间的不同区域。强化学习代理可以从这些交互中学习，记录为传感器数据，以优化整体能效。但是，如果这些代理商在家庭层面单独运作，他们就不能利用问题中复制的结构。在本文中，我们证明这个问题确实可以从多代理协作中受益，通过利用状态空间的有针对性的探索来实现更好的泛化。我们还研究整合人类知识和其他传感器之间的权衡。结果显示，使用专家知识或附加传感器的协作式多智能体系统可节省40％以上的成本，且不会降低乘客的舒适度。我们发现这样的多代理系统比同类的单代理系统更胜一筹。

##### URL
[http://arxiv.org/abs/1803.03491](http://arxiv.org/abs/1803.03491)

##### PDF
[http://arxiv.org/pdf/1803.03491](http://arxiv.org/pdf/1803.03491)

