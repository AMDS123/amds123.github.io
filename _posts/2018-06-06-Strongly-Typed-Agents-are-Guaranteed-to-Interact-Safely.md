---
layout: post
title: "Strongly-Typed Agents are Guaranteed to Interact Safely"
date: 2018-06-06 12:37:57
categories: arXiv_AI
tags: arXiv_AI Deep_Learning Gradient_Descent
author: David Balduzzi
mathjax: true
---

* content
{:toc}

##### Abstract
As artificial agents proliferate, it is becoming increasingly important to ensure that their interactions with one another are well-behaved. In this paper, we formalize a common-sense notion of when algorithms are well-behaved: an algorithm is safe if it does no harm. Motivated by recent progress in deep learning, we focus on the specific case where agents update their actions according to gradient descent. The paper shows that that gradient descent converges to a Nash equilibrium in safe games. The main contribution is to define strongly-typed agents and show they are guaranteed to interact safely, thereby providing sufficient conditions to guarantee safe interactions. A series of examples show that strong-typing generalizes certain key features of convexity, is closely related to blind source separation, and introduces a new perspective on classical multilinear games based on tensor decomposition.

##### Abstract (translated by Google)
随着人造药物的增殖，确保它们彼此之间的相互作用表现良好变得越来越重要。在本文中，我们形成了一个常识，即何时算法行为良好：如果算法没有坏处，算法是安全的。受近期深度学习进展的驱动，我们专注于特工根据梯度下降更新其行为的具体情况。该论文表明梯度下降收敛于安全博弈中的纳什均衡。主要贡献是定义强类型的代理并显示它们保证了安全交互，从而为保证安全交互提供了充分的条件。一系列实例表明，强类型概括了凸性的某些关键特征，与盲源分离密切相关，并且引入了基于张量分解的经典多线性博弈的新视角。

##### URL
[http://arxiv.org/abs/1702.07450](http://arxiv.org/abs/1702.07450)

##### PDF
[http://arxiv.org/pdf/1702.07450](http://arxiv.org/pdf/1702.07450)

