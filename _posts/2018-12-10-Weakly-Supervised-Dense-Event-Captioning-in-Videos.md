---
layout: post
title: "Weakly Supervised Dense Event Captioning in Videos"
date: 2018-12-10 14:58:24
categories: arXiv_CV
tags: arXiv_CV Weakly_Supervised Caption
author: Xuguang Duan, Wenbing Huang, Chuang Gan, Jingdong Wang, Wenwu Zhu, Junzhou Huang
mathjax: true
---

* content
{:toc}

##### Abstract
Dense event captioning aims to detect and describe all events of interest contained in a video. Despite the advanced development in this area, existing methods tackle this task by making use of dense temporal annotations, which is dramatically source-consuming. This paper formulates a new problem: weakly supervised dense event captioning, which does not require temporal segment annotations for model training. Our solution is based on the one-to-one correspondence assumption, each caption describes one temporal segment, and each temporal segment has one caption, which holds in current benchmark datasets and most real-world cases. We decompose the problem into a pair of dual problems: event captioning and sentence localization and present a cycle system to train our model. Extensive experimental results are provided to demonstrate the ability of our model on both dense event captioning and sentence localization in videos.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.03849](http://arxiv.org/abs/1812.03849)

##### PDF
[http://arxiv.org/pdf/1812.03849](http://arxiv.org/pdf/1812.03849)

