---
layout: post
title: "Contextual Memory Trees"
date: 2018-07-17 14:36:22
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption Inference Classification
author: Wen Sun, Alina Beygelzimer, Hal Daumé III, John Langford, Paul Mineiro
mathjax: true
---

* content
{:toc}

##### Abstract
We design and study a Contextual Memory Tree (CMT), a learning memory controller that inserts new memories into an experience store of unbounded size. It is designed to efficiently query for memories from that store, supporting logarithmic time insertion and retrieval operations. Hence CMT can be integrated into existing statistical learning algorithms as an augmented memory unit without substantially increasing training and inference computation. We demonstrate the efficacy of CMT by augmenting existing multi-class and multi-label classification algorithms with CMT and observe statistical improvement. We also test CMT learning on several image-captioning tasks to demonstrate that it performs computationally better than a simple nearest neighbors memory system while benefitting from reward learning.

##### Abstract (translated by Google)
我们设计并研究了一个上下文内存树（CMT），这是一种学习内存控制器，可以将新内存插入到无限大小的体验库中。它旨在有效地查询来自该商店的内存，支持对数时间插入和检索操作。因此，CMT可以作为增强的存储器单元集成到现有的统计学习算法中，而基本上不增加训练和推理计算。我们通过使用CMT扩充现有的多类和多标签分类算法并观察统计学改进来证明CMT的功效。我们还测试了几个图像字幕任务的CMT学习，以证明它在计算上比简单的最近邻居记忆系统更好，同时受益于奖励学习。

##### URL
[https://arxiv.org/abs/1807.06473](https://arxiv.org/abs/1807.06473)

##### PDF
[https://arxiv.org/pdf/1807.06473](https://arxiv.org/pdf/1807.06473)

