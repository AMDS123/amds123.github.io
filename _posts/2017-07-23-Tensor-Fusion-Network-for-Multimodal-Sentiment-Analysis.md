---
layout: post
title: "Tensor Fusion Network for Multimodal Sentiment Analysis"
date: 2017-07-23 05:54:20
categories: arXiv_CL
tags: arXiv_CL Sentiment
author: Amir Zadeh, Minghai Chen, Soujanya Poria, Erik Cambria, Louis-Philippe Morency
mathjax: true
---

* content
{:toc}

##### Abstract
Multimodal sentiment analysis is an increasingly popular research area, which extends the conventional language-based definition of sentiment analysis to a multimodal setup where other relevant modalities accompany language. In this paper, we pose the problem of multimodal sentiment analysis as modeling intra-modality and inter-modality dynamics. We introduce a novel model, termed Tensor Fusion Network, which learns both such dynamics end-to-end. The proposed approach is tailored for the volatile nature of spoken language in online videos as well as accompanying gestures and voice. In the experiments, our model outperforms state-of-the-art approaches for both multimodal and unimodal sentiment analysis.

##### Abstract (translated by Google)
多模态情绪分析是一个越来越受欢迎的研究领域，它将传统的基于语言的情绪分析定义扩展到其他相关模态伴随语言的多模式设置。在本文中，我们提出多模态情感分析作为模态内和模态间动态的建模问题。我们引入了一个新的模型，称为张量融合网络，它学习了这样的动态端到端。所提出的方法针对在线视频中的口头语言的易变性质以及伴随的手势和语音而量身定制。在实验中，我们的模型比多模式和单模态情绪分析的表现都优于最新的方法。

##### URL
[https://arxiv.org/abs/1707.07250](https://arxiv.org/abs/1707.07250)

##### PDF
[https://arxiv.org/pdf/1707.07250](https://arxiv.org/pdf/1707.07250)

