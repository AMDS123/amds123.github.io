---
layout: post
title: "Automating Predictive Modeling Process using Reinforcement Learning"
date: 2019-03-02 18:22:19
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization Classification
author: Udayan Khurana, Horst Samulowitz
mathjax: true
---

* content
{:toc}

##### Abstract
Building a good predictive model requires an array of activities such as data imputation, feature transformations, estimator selection, hyper-parameter search and ensemble construction. Given the large, complex and heterogenous space of options, off-the-shelf optimization methods are infeasible for realistic response times. In practice, much of the predictive modeling process is conducted by experienced data scientists, who selectively make use of available tools. Over time, they develop an understanding of the behavior of operators, and perform serial decision making under uncertainty, colloquially referred to as educated guesswork. With an unprecedented demand for application of supervised machine learning, there is a call for solutions that automatically search for a good combination of parameters across these tasks to minimize the modeling error. We introduce a novel system called APRL (Autonomous Predictive modeler via Reinforcement Learning), that uses past experience through reinforcement learning to optimize such sequential decision making from within a set of diverse actions under a time constraint on a previously unseen predictive learning problem. APRL actions are taken to optimize the performance of a final ensemble. This is in contrast to other systems, which maximize individual model accuracy first and create ensembles as a disconnected post-processing step. As a result, APRL is able to reduce up to 71\% of classification error on average over a wide variety of problems.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1903.00743](http://arxiv.org/abs/1903.00743)

##### PDF
[http://arxiv.org/pdf/1903.00743](http://arxiv.org/pdf/1903.00743)

