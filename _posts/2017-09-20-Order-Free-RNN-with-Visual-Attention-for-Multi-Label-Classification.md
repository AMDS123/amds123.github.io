---
layout: post
title: "Order-Free RNN with Visual Attention for Multi-Label Classification"
date: 2017-09-20 05:00:21
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption RNN
author: Shang-Fu Chen, Yi-Chen Chen, Chih-Kuan Yeh, Yu-Chiang Frank Wang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose the joint learning attention and recurrent neural network (RNN) models for multi-label classification. While approaches based on the use of either model exist (e.g., for the task of image captioning), training such existing network architectures typically require pre-defined label sequences. For multi-label classification, it would be desirable to have a robust inference process, so that the prediction error would not propagate and thus affect the performance. Our proposed model uniquely integrates attention and Long Short Term Memory (LSTM) models, which not only addresses the above problem but also allows one to identify visual objects of interests with varying sizes without the prior knowledge of particular label ordering. More importantly, label co-occurrence information can be jointly exploited by our LSTM model. Finally, by advancing the technique of beam search, prediction of multiple labels can be efficiently achieved by our proposed network model.

##### Abstract (translated by Google)
在本文中，我们提出了多标签分类的联合学习注意和递归神经网络（RNN）模型。尽管存在基于使用任一模型的方法（例如，用于图像字幕的任务），但是训练这种现有网络体系结构通常需要预定义的标签序列。对于多标签分类，需要有一个健壮的推理过程，所以预测误差不会传播，从而影响性能。我们提出的模型独特地集成了注意力和长时间短记忆（LSTM）模型，它们不仅解决了上述问题，而且还允许在没有特定标签排序的先验知识的情况下识别具有不同尺寸的视觉对象。更重要的是，标签共现信息可以被我们的LSTM模型共同利用。最后，通过推进波束搜索技术，通过我们提出的网络模型可以有效地实现多个标签的预测。

##### URL
[https://arxiv.org/abs/1707.05495](https://arxiv.org/abs/1707.05495)

