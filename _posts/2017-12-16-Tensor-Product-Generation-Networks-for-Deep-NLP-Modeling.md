---
layout: post
title: "Tensor Product Generation Networks for Deep NLP Modeling"
date: 2017-12-16 12:01:09
categories: arXiv_CV
tags: arXiv_CV Image_Caption Caption RNN Deep_Learning
author: Qiuyuan Huang, Paul Smolensky, Xiaodong He, Li Deng, Dapeng Wu
mathjax: true
---

* content
{:toc}

##### Abstract
We present a new approach to the design of deep networks for natural language processing (NLP), based on the general technique of Tensor Product Representations (TPRs) for encoding and processing symbol structures in distributed neural networks. A network architecture --- the Tensor Product Generation Network (TPGN) --- is proposed which is capable in principle of carrying out TPR computation, but which uses unconstrained deep learning to design its internal representations. Instantiated in a model for image-caption generation, TPGN outperforms LSTM baselines when evaluated on the COCO dataset. The TPR-capable structure enables interpretation of internal representations and operations, which prove to contain considerable grammatical content. Our caption-generation model can be interpreted as generating sequences of grammatical categories and retrieving words by their categories from a plan encoded as a distributed representation.

##### Abstract (translated by Google)
我们提出了一种新的自然语言处理深度网络设计方法（NLP），它基于用于编码和处理分布式神经网络中符号结构的Tensor Product Representations（TPR）的一般技术。提出了一种网络架构--- Tensor产生代网络（TPGN）---它原则上能够进行TPR计算，但它使用无约束深度学习来设计其内部表示。在用于生成图像标题的模型中实例化时，TPGN在COCO数据集上进行评估时优于LSTM基线。具有TPR功能的结构可以解释内部表示和操作，证明其含有相当多的语法内容。我们的字幕生成模型可以被解释为生成语法类别的序列，并从编码为分布式表示的计划中按类别检索单词。

##### URL
[https://arxiv.org/abs/1709.09118](https://arxiv.org/abs/1709.09118)

##### PDF
[https://arxiv.org/pdf/1709.09118](https://arxiv.org/pdf/1709.09118)

