---
layout: post
title: "Joint Representation Learning of Text and Knowledge for Knowledge Graph Completion"
date: 2016-11-13 12:32:20
categories: arXiv_CL
tags: arXiv_CL Knowledge_Graph Knowledge Embedding Represenation_Learning Classification Prediction Relation
author: Xu Han, Zhiyuan Liu, Maosong Sun
mathjax: true
---

* content
{:toc}

##### Abstract
Joint representation learning of text and knowledge within a unified semantic space enables us to perform knowledge graph completion more accurately. In this work, we propose a novel framework to embed words, entities and relations into the same continuous vector space. In this model, both entity and relation embeddings are learned by taking knowledge graph and plain text into consideration. In experiments, we evaluate the joint learning model on three tasks including entity prediction, relation prediction and relation classification from text. The experiment results show that our model can significantly and consistently improve the performance on the three tasks as compared with other baselines.

##### Abstract (translated by Google)
在一个统一的语义空间内进行文本和知识的联合表示学习使我们能够更准确地完成知识图的完成。在这项工作中，我们提出了一个新的框架，将词，实体和关系嵌入到同一个连续的向量空间中。在这个模型中，实体和关系嵌入都是通过考虑知识图和纯文本来学习的。在实验中，我们评估联合学习模型的三个任务，包括实体预测，关系预测和文本的关系分类。实验结果表明，与其他基线相比，我们的模型能够显着而持续地改善三个任务的性能。

##### URL
[https://arxiv.org/abs/1611.04125](https://arxiv.org/abs/1611.04125)

##### PDF
[https://arxiv.org/pdf/1611.04125](https://arxiv.org/pdf/1611.04125)

