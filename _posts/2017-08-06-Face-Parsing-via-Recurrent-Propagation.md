---
layout: post
title: "Face Parsing via Recurrent Propagation"
date: 2017-08-06 21:34:01
categories: arXiv_CV
tags: arXiv_CV Segmentation Face CNN Inference RNN Recognition
author: Sifei Liu, Jianping Shi, Ji Liang, Ming-Hsuan Yang
mathjax: true
---

* content
{:toc}

##### Abstract
Face parsing is an important problem in computer vision that finds numerous applications including recognition and editing. Recently, deep convolutional neural networks (CNNs) have been applied to image parsing and segmentation with the state-of-the-art performance. In this paper, we propose a face parsing algorithm that combines hierarchical representations learned by a CNN, and accurate label propagations achieved by a spatially variant recurrent neural network (RNN). The RNN-based propagation approach enables efficient inference over a global space with the guidance of semantic edges generated by a local convolutional model. Since the convolutional architecture can be shallow and the spatial RNN can have few parameters, the framework is much faster and more light-weighted than the state-of-the-art CNNs for the same task. We apply the proposed model to coarse-grained and fine-grained face parsing. For fine-grained face parsing, we develop a two-stage approach by first identifying the main regions and then segmenting the detail components, which achieves better performance in terms of accuracy and efficiency. With a single GPU, the proposed algorithm parses face images accurately at 300 frames per second, which facilitates real-time applications.

##### Abstract (translated by Google)
人脸解析是计算机视觉中的一个重要问题，可以找到许多应用程序，包括识别和编辑。最近，深度卷积神经网络（CNNs）已被应用于图像解析和分割与最先进的性能。在本文中，我们提出了一种结合CNN学习的分层表示的人脸解析算法，以及由空间变化的递归神经网络（RNN）实现的准确的标签传播。基于RNN的传播方法能够在局部卷积模型生成的语义边的引导下在全局空间上进行高效推理。由于卷积体系结构可以是浅的，而空间RNN可以具有很少的参数，所以相同任务的框架比现有CNNs更快，更轻。我们将所提出的模型应用于粗粒度和细粒度的人脸分析。对于细粒度的人脸解析，我们首先确定主要区域，然后细分细节组件，从而在准确性和效率方面取得更好的性能，从而开发出两阶段方法。所提出的算法通过一个GPU，以每秒300帧的速度精确解析人脸图像，便于实时应用。

##### URL
[https://arxiv.org/abs/1708.01936](https://arxiv.org/abs/1708.01936)

##### PDF
[https://arxiv.org/pdf/1708.01936](https://arxiv.org/pdf/1708.01936)

