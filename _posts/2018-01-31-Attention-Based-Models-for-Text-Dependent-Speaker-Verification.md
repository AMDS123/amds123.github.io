---
layout: post
title: "Attention-Based Models for Text-Dependent Speaker Verification"
date: 2018-01-31 20:58:17
categories: arXiv_CV
tags: arXiv_CV Image_Caption Attention Summarization Speech_Recognition Caption RNN Recognition
author: F A Rezaur Rahman Chowdhury, Quan Wang, Ignacio Lopez Moreno, Li Wan
mathjax: true
---

* content
{:toc}

##### Abstract
Attention-based models have recently shown great performance on a range of tasks, such as speech recognition, machine translation, and image captioning due to their ability to summarize relevant information that expands through the entire length of an input sequence. In this paper, we analyze the usage of attention mechanisms to the problem of sequence summarization in our end-to-end text-dependent speaker recognition system. We explore different topologies and their variants of the attention layer, and compare different pooling methods on the attention weights. Ultimately, we show that attention-based models can improves the Equal Error Rate (EER) of our speaker verification system by relatively 14% compared to our non-attention LSTM baseline model.

##### Abstract (translated by Google)
基于注意力的模型最近在一系列任务上表现出很好的表现，例如语音识别，机器翻译和图像字幕，因为它们能够汇总在输入序列的整个长度上扩展的相关信息。在本文中，我们分析了注意机制在我们的端到端文本相关说话人识别系统中对序列汇总问题的使用。我们探索了关注层的不同拓扑及其变体，并比较了注意力的不同汇集方法。最后，我们表明，与我们的非注意力LSTM基线模型相比，基于注意力的模型可以将我们的说话人验证系统的等错误率（EER）提高14％。

##### URL
[https://arxiv.org/abs/1710.10470](https://arxiv.org/abs/1710.10470)

##### PDF
[https://arxiv.org/pdf/1710.10470](https://arxiv.org/pdf/1710.10470)

