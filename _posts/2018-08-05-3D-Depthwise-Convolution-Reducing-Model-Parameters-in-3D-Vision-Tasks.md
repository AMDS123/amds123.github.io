---
layout: post
title: "3D Depthwise Convolution: Reducing Model Parameters in 3D Vision Tasks"
date: 2018-08-05 03:50:54
categories: arXiv_CV
tags: arXiv_CV Classification
author: Rongtian Ye, Fangyu Liu, Liqiang Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Standard 3D convolution operations require much larger amounts of memory and computation cost than 2D convolution operations. The fact has hindered the development of deep neural nets in many 3D vision tasks. In this paper, we investigate the possibility of applying depthwise separable convolutions in 3D scenario and introduce the use of 3D depthwise convolution. A 3D depthwise convolution splits a single standard 3D convolution into two separate steps, which would drastically reduce the number of parameters in 3D convolutions with more than one order of magnitude. We experiment with 3D depthwise convolution on popular CNN architectures and also compare it with a similar structure called pseudo-3D convolution. The results demonstrate that, with 3D depthwise convolutions, 3D vision tasks like classification and reconstruction can be carried out with more light-weighted neural networks while still delivering comparable performances.

##### Abstract (translated by Google)
与2D卷积运算相比，标准3D卷积运算需要更大量的存储器和计算成本。这一事实阻碍了许多3D视觉任务中深层神经网络的发展。在本文中，我们研究了在3D场景中应用深度可分离卷积的可能性，并介绍了3D深度卷积的使用。 3D深度卷积将单个标准3D卷积分成两个单独的步骤，这将大大减少3D卷积中的参数数量超过一个数量级。我们在流行的CNN架构上尝试3D深度卷积，并将其与称为伪3D卷积的类似结构进行比较。结果表明，利用3D深度卷积，可以使用更多的轻量级神经网络进行分类和重建等3D视觉任务，同时仍然提供相当的性能。

##### URL
[https://arxiv.org/abs/1808.01556](https://arxiv.org/abs/1808.01556)

##### PDF
[https://arxiv.org/pdf/1808.01556](https://arxiv.org/pdf/1808.01556)

