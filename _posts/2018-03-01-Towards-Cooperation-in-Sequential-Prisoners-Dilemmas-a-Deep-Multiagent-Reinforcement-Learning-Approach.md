---
layout: post
title: "Towards Cooperation in Sequential Prisoner's Dilemmas: a Deep Multiagent Reinforcement Learning Approach"
date: 2018-03-01 01:53:52
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Detection
author: Weixun Wang, Jianye Hao, Yixi Wang, Matthew Taylor
mathjax: true
---

* content
{:toc}

##### Abstract
The Iterated Prisoner's Dilemma has guided research on social dilemmas for decades. However, it distinguishes between only two atomic actions: cooperate and defect. In real-world prisoner's dilemmas, these choices are temporally extended and different strategies may correspond to sequences of actions, reflecting grades of cooperation. We introduce a Sequential Prisoner's Dilemma (SPD) game to better capture the aforementioned characteristics. In this work, we propose a deep multiagent reinforcement learning approach that investigates the evolution of mutual cooperation in SPD games. Our approach consists of two phases. The first phase is offline: it synthesizes policies with different cooperation degrees and then trains a cooperation degree detection network. The second phase is online: an agent adaptively selects its policy based on the detected degree of opponent cooperation. The effectiveness of our approach is demonstrated in two representative SPD 2D games: the Apple-Pear game and the Fruit Gathering game. Experimental results show that our strategy can avoid being exploited by exploitative opponents and achieve cooperation with cooperative opponents.

##### Abstract (translated by Google)
重复的囚徒困境已经引导了几十年来关于社会困境的研究。然而，它只区分两个原子动作：合作和缺陷。在现实世界的囚徒困境中，这些选择在时间上得到延伸，不同的战略可能对应于一系列行动，反映了合作的等级。我们引入了序列囚徒困境（SPD）游戏来更好地捕捉前述特征。在这项工作中，我们提出了深度多元强化学习方法，研究SPD游戏中相互合作的演变过程。我们的方法由两个阶段组成。第一阶段是离线：合成不同合作度的政策，然后培训合作度检测网络。第二阶段在线：代理根据检测到的对手合作程度自适应地选择其策略。我们的方法的有效性在两个有代表性的SPD 2D游戏中得到证明：Apple-Pear游戏和Fruit Gathering游戏。实验结果表明，我们的策略可以避免被剥削对手利用并实现与合作对手的合作。

##### URL
[http://arxiv.org/abs/1803.00162](http://arxiv.org/abs/1803.00162)

##### PDF
[http://arxiv.org/pdf/1803.00162](http://arxiv.org/pdf/1803.00162)

