---
layout: post
title: "Spatiotemporal KSVD Dictionary Learning for Online Multi-target Tracking"
date: 2018-07-05 18:36:24
categories: arXiv_CV
tags: arXiv_CV Sparse Face Tracking Optimization Classification Detection Recognition
author: Huynh Manh, Gita Alaghband
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we present a new spatial discriminative KSVD dictionary algorithm (STKSVD) for learning target appearance in online multi-target tracking. Different from other classification/recognition tasks (e.g. face, image recognition), learning target's appearance in online multi-target tracking is impacted by factors such as posture/articulation changes, partial occlusion by background scene or other targets, background changes (human detection bounding box covers human parts and part of the scene), etc. However, we observe that these variations occur gradually relative to spatial and temporal dynamics. We characterize the spatial and temporal information between target's samples through a new STKSVD appearance learning algorithm to better discriminate sparse code, linear classifier parameters and minimize reconstruction error in a single optimization system. Our appearance learning algorithm and tracking framework employ two different methods of calculating appearance similarity score in each stage of a two-stage association: a linear classifier in the first stage, and minimum residual errors in the second stage. The results tested using 2DMOT2015 dataset and its public Aggregated Channel features (ACF) human detection for all comparisons show that our method outperforms the existing related learning methods.

##### Abstract (translated by Google)
在本文中，我们提出了一种新的空间判别KSVD字典算法（STKSVD），用于在线多目标跟踪中学习目标外观。与其他分类/识别任务（例如，面部，图像识别）不同，在线多目标跟踪中学习目标的出现受到诸如姿势/清晰度变化，背景场景或其他目标的部分遮挡，背景变化（人类检测边界）等因素的影响。框中包括人体部分和场景的一部分）等。然而，我们观察到这些变化相对于空间和时间动态逐渐发生。我们通过新的STKSVD外观学习算法来表征目标样本之间的空间和时间信息，以更好地区分稀疏代码，线性分类器参数并最小化单个优化系统中的重建误差。我们的外观学习算法和跟踪框架采用两种不同的方法来计算两阶段关联的每个阶段中的外观相似性得分：第一阶段中的线性分类器和第二阶段中的最小残差错误。使用2DMOT2015数据集及其公共聚合通道特征（ACF）人体检测进行的所有比较测试结果表明，我们的方法优于现有的相关学习方法。

##### URL
[http://arxiv.org/abs/1807.02143](http://arxiv.org/abs/1807.02143)

##### PDF
[http://arxiv.org/pdf/1807.02143](http://arxiv.org/pdf/1807.02143)

