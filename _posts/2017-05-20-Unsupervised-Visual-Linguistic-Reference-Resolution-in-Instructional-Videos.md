---
layout: post
title: "Unsupervised Visual-Linguistic Reference Resolution in Instructional Videos"
date: 2017-05-20 22:33:54
categories: arXiv_CV
tags: arXiv_CV
author: De-An Huang, Joseph J. Lim, Li Fei-Fei, Juan Carlos Niebles
mathjax: true
---

* content
{:toc}

##### Abstract
We propose an unsupervised method for reference resolution in instructional videos, where the goal is to temporally link an entity (e.g., "dressing") to the action (e.g., "mix yogurt") that produced it. The key challenge is the inevitable visual-linguistic ambiguities arising from the changes in both visual appearance and referring expression of an entity in the video. This challenge is amplified by the fact that we aim to resolve references with no supervision. We address these challenges by learning a joint visual-linguistic model, where linguistic cues can help resolve visual ambiguities and vice versa. We verify our approach by learning our model unsupervisedly using more than two thousand unstructured cooking videos from YouTube, and show that our visual-linguistic model can substantially improve upon state-of-the-art linguistic only model on reference resolution in instructional videos.

##### Abstract (translated by Google)
我们在教学视频中提出了一种无监督的参考解决方法，其目标是将一个实体（例如“穿衣”）与产生它的动作（例如“混合酸奶”）暂时联系起来。关键的挑战是在视频中视觉外观和实体表达的变化引起的不可避免的视觉语言歧义。这个挑战被放大了，我们的目标是在没有监督的情况下解决引用问题。我们通过学习一个联合的视觉语言模型来解决这些挑战，语言学的线索可以帮助解决视觉模糊问题，反之亦然。我们通过无监督地使用来自YouTube的两千多个非结构化烹饪视频来学习我们的模型，并证明我们的视觉语言模型能够大大改善教学视频中参考分辨率的最新语言模型。

##### URL
[https://arxiv.org/abs/1703.02521](https://arxiv.org/abs/1703.02521)

##### PDF
[https://arxiv.org/pdf/1703.02521](https://arxiv.org/pdf/1703.02521)

