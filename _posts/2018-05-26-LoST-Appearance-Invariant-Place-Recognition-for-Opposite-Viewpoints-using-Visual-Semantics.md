---
layout: post
title: "LoST? Appearance-Invariant Place Recognition for Opposite Viewpoints using Visual Semantics"
date: 2018-05-26 10:34:17
categories: arXiv_CV
tags: arXiv_CV Salient Segmentation CNN Semantic_Segmentation Recognition
author: Sourav Garg, Niko Suenderhauf, Michael Milford
mathjax: true
---

* content
{:toc}

##### Abstract
Human visual scene understanding is so remarkable that we are able to recognize a revisited place when entering it from the opposite direction it was first visited, even in the presence of extreme variations in appearance. This capability is especially apparent during driving: a human driver can recognize where they are when travelling in the reverse direction along a route for the first time, without having to turn back and look. The difficulty of this problem exceeds any addressed in past appearance- and viewpoint-invariant visual place recognition (VPR) research, in part because large parts of the scene are not commonly observable from opposite directions. Consequently, as shown in this paper, the precision-recall performance of current state-of-the-art viewpoint- and appearance-invariant VPR techniques is orders of magnitude below what would be usable in a closed-loop system. Current engineered solutions predominantly rely on panoramic camera or LIDAR sensing setups; an eminently suitable engineering solution but one that is clearly very different to how humans navigate, which also has implications for how naturally humans could interact and communicate with the navigation system. In this paper we develop a suite of novel semantic- and appearance-based techniques to enable for the first time high performance place recognition in this challenging scenario. We first propose a novel Local Semantic Tensor (LoST) descriptor of images using the convolutional feature maps from a state-of-the-art dense semantic segmentation network. Then, to verify the spatial semantic arrangement of the top matching candidates, we develop a novel approach for mining semantically-salient keypoint correspondences.

##### Abstract (translated by Google)
人类视觉场景的理解非常显着，我们能够从与第一次访问相反的方向进入它时识别出重新访问的地点，即使在外观极度变化的情况下也是如此。这种能力在驾驶过程中尤其明显：驾驶员可以识别出沿着路线第一次沿相反方向行驶时的位置，而不必回头看。这个问题的难度超过了过去在外观和视点不变的视觉地点识别（VPR）研究中所解决的任何问题，部分原因是由于大部分场景不能从相反方向观察到。因此，如本文所示，当前最先进的视点和外观不变VPR技术的精确回忆性能比闭环系统中可用的要低几个数量级。目前的工程解决方案主要依靠全景相机或LIDAR感应设置;这是一个非常合适的工程解决方案，但与人类的导航方式明显不同，这也意味着人类可以与导航系统进行交互和通信。在本文中，我们开发了一套新颖的基于语义和外观的技术，以在这种具有挑战性的场景中首次实现高性能场所识别。我们首先使用来自最先进的密集语义分割网络的卷积特征映射来提出图像的新颖局部语义张量（LoST）描述符。然后，为了验证顶级匹配候选者的空间语义排列，我们开发了一种挖掘语义上突出的关键点对应关系的新方法。

##### URL
[http://arxiv.org/abs/1804.05526](http://arxiv.org/abs/1804.05526)

##### PDF
[http://arxiv.org/pdf/1804.05526](http://arxiv.org/pdf/1804.05526)

