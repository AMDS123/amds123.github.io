---
layout: post
title: "Policy Certificates: Towards Accountable Reinforcement Learning"
date: 2018-11-07 18:16:28
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Christoph Dann, Lihong Li, Wei Wei, Emma Brunskill
mathjax: true
---

* content
{:toc}

##### Abstract
The performance of a reinforcement learning algorithm can vary drastically during learning because of exploration. Existing algorithms provide little information about their current policy's quality before executing it, and thus have limited use in high-stakes applications like healthcare. In this paper, we address such a lack of accountability by proposing that algorithms output policy certificates, which upper bound the suboptimality in the next episode, allowing humans to intervene when the certified quality is not satisfactory. We further present a new learning framework (IPOC) for finite-sample analysis with policy certificates, and develop two IPOC algorithms that enjoy guarantees for the quality of both their policies and certificates.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.03056](http://arxiv.org/abs/1811.03056)

##### PDF
[http://arxiv.org/pdf/1811.03056](http://arxiv.org/pdf/1811.03056)

