---
layout: post
title: "Learning to Represent Mechanics via Long-term Extrapolation and Interpolation"
date: 2017-06-08 09:31:22
categories: arXiv_CV
tags: arXiv_CV
author: Sébastien Ehrhardt, Aron Monszpart, Andrea Vedaldi, Niloy Mitra
mathjax: true
---

* content
{:toc}

##### Abstract
While the basic laws of Newtonian mechanics are well understood, explaining a physical scenario still requires manually modeling the problem with suitable equations and associated parameters. In order to adopt such models for artificial intelligence, researchers have handcrafted the relevant states, and then used neural networks to learn the state transitions using simulation runs as training data. Unfortunately, such approaches can be unsuitable for modeling complex real-world scenarios, where manually authoring relevant state spaces tend to be challenging. In this work, we investigate if neural networks can implicitly learn physical states of real-world mechanical processes only based on visual data, and thus enable long-term physical extrapolation. We develop a recurrent neural network architecture for this task and also characterize resultant uncertainties in the form of evolving variance estimates. We evaluate our setup to extrapolate motion of a rolling ball on bowl of varying shape and orientation using only images as input, and report competitive results with approaches that assume access to internal physics models and parameters.

##### Abstract (translated by Google)
虽然牛顿力学的基本定律很好理解，但解释一个物理场景仍然需要用合适的方程和相关参数手动建模问题。为了将这些模型用于人工智能，研究人员已经手工制作了相关状态，然后使用神经网络将模拟运行作为训练数据来学习状态转换。不幸的是，这样的方法可能不适合建模复杂的现实世界的场景，手动编写相关的状态空间往往是具有挑战性的。在这项工作中，我们调查神经网络是否可以隐式地学习真实世界的机械过程的物理状态只基于视觉数据，从而使长期的物理外推。我们针对这一任务开发了一个递归的神经网络架构，并以变化的方差估计的形式表征了由此产生的不确定性。我们评估我们的设置，以仅使用图像作为输入，推断滚动球在不同形状和方向的碗上的运动，并且报告竞争性结果，假设可以访问内部物理模型和参数。

##### URL
[https://arxiv.org/abs/1706.02179](https://arxiv.org/abs/1706.02179)

##### PDF
[https://arxiv.org/pdf/1706.02179](https://arxiv.org/pdf/1706.02179)

