---
layout: post
title: "Unsupervised Spoken Term Detection with Spoken Queries by Multi-level Acoustic Patterns with Varying Model Granularity"
date: 2015-09-07 22:40:31
categories: arXiv_CL
tags: arXiv_CL Detection
author: Cheng-Tao Chung, Chun-an Chan, Lin-shan Lee
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents a new approach for unsupervised Spoken Term Detection with spoken queries using multiple sets of acoustic patterns automatically discovered from the target corpus. The different pattern HMM configurations(number of states per model, number of distinct models, number of Gaussians per state)form a three-dimensional model granularity space. Different sets of acoustic patterns automatically discovered on different points properly distributed over this three-dimensional space are complementary to one another, thus can jointly capture the characteristics of the spoken terms. By representing the spoken content and spoken query as sequences of acoustic patterns, a series of approaches for matching the pattern index sequences while considering the signal variations are developed. In this way, not only the on-line computation load can be reduced, but the signal distributions caused by different speakers and acoustic conditions can be reasonably taken care of. The results indicate that this approach significantly outperformed the unsupervised feature-based DTW baseline by 16.16\% in mean average precision on the TIMIT corpus.

##### Abstract (translated by Google)
本文提出了一种新的无声监听口语检测方法，使用从目标语料库自动发现的多组声音模式进行口头查询。不同模式的HMM配置（每个模型的状态数目，不同模型的数目，每个状态的高斯数目）形成三维模型粒度空间。在三维空间上正确分布的不同点上自动发现的不同声学模式是相互补充的，从而可以共同捕捉口语术语的特征。通过将口述内容和口头查询表示为声学模式的序列，开发了用于在考虑信号变化的同时匹配模式索引序列的一系列方法。这样不仅可以减少在线计算负荷，而且可以合理地考虑由不同扬声器和声学条件引起的信号分布。结果表明，该方法在TIMIT语料库上的均值平均精度显着优于无监督的基于特征的DTW基线16.16％。

##### URL
[https://arxiv.org/abs/1509.02213](https://arxiv.org/abs/1509.02213)

##### PDF
[https://arxiv.org/pdf/1509.02213](https://arxiv.org/pdf/1509.02213)

