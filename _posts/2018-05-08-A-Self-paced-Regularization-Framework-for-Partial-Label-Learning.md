---
layout: post
title: "A Self-paced Regularization Framework for Partial-Label Learning"
date: 2018-05-08 08:49:25
categories: arXiv_AI
tags: arXiv_AI Regularization
author: Gengyu Lyu, Songhe Feng, Congyang Lang
mathjax: true
---

* content
{:toc}

##### Abstract
Partial label learning (PLL) aims to solve the problem where each training instance is associated with a set of candidate labels, one of which is the correct label. Most PLL algorithms try to disambiguate the candidate label set, by either simply treating each candidate label equally or iteratively identifying the true label. Nonetheless, existing algorithms usually treat all labels and instances equally, and the complexities of both labels and instances are not taken into consideration during the learning stage. Inspired by the successful application of self-paced learning strategy in machine learning field, we integrate the self-paced regime into the partial label learning framework and propose a novel Self-Paced Partial-Label Learning (SP-PLL) algorithm, which could control the learning process to alleviate the problem by ranking the priorities of the training examples together with their candidate labels during each learning iteration. Extensive experiments and comparisons with other baseline methods demonstrate the effectiveness and robustness of the proposed method.

##### Abstract (translated by Google)
部分标签学习（PLL）旨在解决每个训练实例与一组候选标签相关联的问题，其中一个是正确的标签。大多数PLL算法试图通过简单地对待每个候选标签或迭代地标识真实标签来消除候选标签集的歧义。尽管如此，现有的算法通常对待所有的标签和实例，并且在学习阶段不考虑标签和实例的复杂性。受自主学习策略在机器学习领域的成功应用的启发，我们将自定进度机制融入部分标签学习框架，并提出了一种新型的自适应部分标签学习（Self-Paced Partial-Label Learning，SP-PLL）算法，通过在每次学习迭代期间将训练样例的优先级连同其候选标签进行排序来减轻问题的学习过程。广泛的实验和与其他基线方法的比较证明了所提出方法的有效性和鲁棒性。

##### URL
[http://arxiv.org/abs/1804.07759](http://arxiv.org/abs/1804.07759)

##### PDF
[http://arxiv.org/pdf/1804.07759](http://arxiv.org/pdf/1804.07759)

