---
layout: post
title: "Video Summarization with Long Short-term Memory"
date: 2016-07-29 07:05:34
categories: arXiv_CV
tags: arXiv_CV Summarization RNN Prediction
author: Ke Zhang, Wei-Lun Chao, Fei Sha, Kristen Grauman
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a novel supervised learning technique for summarizing videos by automatically selecting keyframes or key subshots. Casting the problem as a structured prediction problem on sequential data, our main idea is to use Long Short-Term Memory (LSTM), a special type of recurrent neural networks to model the variable-range dependencies entailed in the task of video summarization. Our learning models attain the state-of-the-art results on two benchmark video datasets. Detailed analysis justifies the design of the models. In particular, we show that it is crucial to take into consideration the sequential structures in videos and model them. Besides advances in modeling techniques, we introduce techniques to address the need of a large number of annotated data for training complex learning models. There, our main idea is to exploit the existence of auxiliary annotated video datasets, albeit heterogeneous in visual styles and contents. Specifically, we show domain adaptation techniques can improve summarization by reducing the discrepancies in statistical properties across those datasets.

##### Abstract (translated by Google)
我们提出了一种新颖的监督学习技术，通过自动选择关键帧或关键子帧来总结视频。将这个问题作为一个序列数据的结构化预测问题，我们的主要思想是使用长时间短期记忆（LSTM），一种特殊类型的递归神经网络来模拟视频摘要任务中所涉及的变量范围依赖性。我们的学习模型可以在两个基准视频数据集上获得最新的结果。详细的分析证明了模型的设计。特别是，我们表明考虑视频中的顺序结构并对其进行建模是至关重要的。除了建模技术的进步之外，我们还引入了一些技术来解决大量注释数据用于训练复杂学习模型的需求。在那里，我们的主要想法是利用辅助注释视频数据集的存在，尽管在视觉样式和内容中是不同的。具体来说，我们展示域适应技术可以通过减少这些数据集中统计属性的差异来改进汇总。

##### URL
[https://arxiv.org/abs/1605.08110](https://arxiv.org/abs/1605.08110)

##### PDF
[https://arxiv.org/pdf/1605.08110](https://arxiv.org/pdf/1605.08110)

