---
layout: post
title: "Playing Atari with Six Neurons"
date: 2018-06-04 20:09:43
categories: arXiv_AI
tags: arXiv_AI Sparse Reinforcement_Learning
author: Giuseppe Cuccu, Julian Togelius, Philippe Cudre-Mauroux
mathjax: true
---

* content
{:toc}

##### Abstract
Deep reinforcement learning on Atari games maps pixel directly to actions; internally, the deep neural network bears the responsibility of both extracting useful information and making decisions based on it. Aiming at devoting entire deep networks to decision making alone, we propose a new method for learning policies and compact state representations separately but simultaneously for policy approximation in reinforcement learning. State representations are generated by a novel algorithm based on Vector Quantization and Sparse Coding, trained online along with the network, and capable of growing its dictionary size over time. We also introduce new techniques allowing both the neural network and the evolution strategy to cope with varying dimensions. This enables networks of only 6 to 18 neurons to learn to play a selection of Atari games with performance comparable---and occasionally superior---to state-of-the-art techniques using evolution strategies on deep networks two orders of magnitude larger.

##### Abstract (translated by Google)
Atari游戏的深度强化学习将像素直接映射到动作;在内部，深层神经网络承担提取有用信息并基于此做出决策的责任。为了将整个深层网络用于决策制定，我们提出了一种新的策略学习方法和紧凑的状态表示方法，但是同时用于强化学习中的策略逼近。状态表示是由一种基于矢量量化和稀疏编码的新算法生成的，与网络一起在线训练，并且能够随着时间的推移增大它的字典大小。我们还引入了允许神经网络和进化策略应对不同维度的新技术。这使得只有6到18个神经元的网络能够学习如何使用性能可比较的偶尔优越的Atari游戏来选择最先进的技术，这些技术使用深度网络上的演化策略，比两个数量级更大。

##### URL
[http://arxiv.org/abs/1806.01363](http://arxiv.org/abs/1806.01363)

##### PDF
[http://arxiv.org/pdf/1806.01363](http://arxiv.org/pdf/1806.01363)

