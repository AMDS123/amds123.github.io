---
layout: post
title: "Multimodal Affect Recognition using Kinect"
date: 2016-07-09 20:01:33
categories: arXiv_CV
tags: arXiv_CV Attention Face Tracking Recognition
author: Amol Patwardhan, Gerald Knapp
mathjax: true
---

* content
{:toc}

##### Abstract
Affect (emotion) recognition has gained significant attention from researchers in the past decade. Emotion-aware computer systems and devices have many applications ranging from interactive robots, intelligent online tutor to emotion based navigation assistant. In this research data from multiple modalities such as face, head, hand, body and speech was utilized for affect recognition. The research used color and depth sensing device such as Kinect for facial feature extraction and tracking human body joints. Temporal features across multiple frames were used for affect recognition. Event driven decision level fusion was used to combine the results from each individual modality using majority voting to recognize the emotions. The study also implemented affect recognition by matching the features to the rule based emotion templates per modality. Experiments showed that multimodal affect recognition rates using combination of emotion templates and supervised learning were better compared to recognition rates based on supervised learning alone. Recognition rates obtained using temporal feature were higher compared to recognition rates obtained using position based features only.

##### Abstract (translated by Google)
感情（情绪）认知在过去十年中受到研究人员的高度重视。情感感知的计算机系统和设备具有从交互式机器人，智能在线导师到情感导航助理的许多应用。在这项研究中，来自多种形式的数据如脸部，头部，手部，身体和言语被用于情感识别。本研究采用Kinect等色彩深度感知装置进行人脸特征提取和人体关节追踪。跨多个帧的时间特征被用于影响识别。事件驱动的决策水平融合被用来结合使用多数投票的每个个体模式的结果来识别情绪。该研究还通过将特征与基于规则的情感模板匹配来实现情感识别。实验表明，与基于单独监督学习的识别率相比，使用情感模板和监督学习组合的多模式情感识别率更好。与使用基于位置的特征获得的识别率相比，使用时间特征获得的识别率更高。

##### URL
[https://arxiv.org/abs/1607.02652](https://arxiv.org/abs/1607.02652)

##### PDF
[https://arxiv.org/pdf/1607.02652](https://arxiv.org/pdf/1607.02652)

