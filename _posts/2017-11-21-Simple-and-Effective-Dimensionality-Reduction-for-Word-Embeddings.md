---
layout: post
title: "Simple and Effective Dimensionality Reduction for Word Embeddings"
date: 2017-11-21 14:06:32
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Vikas Raunak
mathjax: true
---

* content
{:toc}

##### Abstract
Word embeddings have become the basic building blocks for several natural language processing and information retrieval tasks. Pre-trained word embeddings are used in several downstream applications as well as for constructing representations for sentences, paragraphs and documents. Recently, there has been an emphasis on further improving the pre-trained word vectors through post-processing algorithms. One such area of improvement is the dimensionality reduction of the word embeddings. Reducing the size of word embeddings through dimensionality reduction can improve their utility in memory constrained devices, benefiting several real-world applications. In this work, we present a novel algorithm that effectively combines PCA based dimensionality reduction with a recently proposed post-processing algorithm, to construct word embeddings of lower dimensions. Empirical evaluations on 12 standard word similarity benchmarks show that our algorithm reduces the embedding dimensionality by 50%, while achieving similar or (more often) better performance than the higher dimension embeddings.

##### Abstract (translated by Google)
字嵌入已经成为几种自然语言处理和信息检索任务的基本构件。预先训练的单词嵌入用于几个下游应用程序以及用于构造句子，段落和文档的表示。最近，人们一直强调通过后处理算法来进一步改进预先训练的单词向量。一个这样的改进领域是嵌入字的降维。通过降维来减少字嵌入的大小可以提高它们在内存受限设备中的实用性，这有益于多个真实世界的应用。在这项工作中，我们提出了一种新的算法，有效地结合基于PCA的降维与最近提出的后处理算法，来构建低维的字嵌入。对12个标准词相似性基准的实证评估表明，我们的算法将嵌入维数降低了50％，同时实现了比高维嵌入更好的性能。

##### URL
[https://arxiv.org/abs/1708.03629](https://arxiv.org/abs/1708.03629)

##### PDF
[https://arxiv.org/pdf/1708.03629](https://arxiv.org/pdf/1708.03629)

