---
layout: post
title: "Recurrent Network-based Deterministic Policy Gradient for Solving Bipedal Walking Challenge on Rugged Terrains"
date: 2018-01-19 10:12:48
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning RNN
author: Doo Re Song, Chuanyu Yang, Christopher McGreavy, Zhibin Li
mathjax: true
---

* content
{:toc}

##### Abstract
This paper presents the learning algorithm based on the Recurrent Network-based Deterministic Policy Gradient. The Long-Short Term Memory is utilized to enable the Partially Observed Markov Decision Process framework. The novelty are improvements of LSTM networks: update of multi-step temporal difference, removal of backpropagation through time on actor, initialisation of hidden state using past trajectory scanning, and injection of external experiences learned by other agents. Our methods benefit the reinforcement learning agent on inferring the desirable action by referring the trajectories of both past observations and actions. The proposed algorithm was implemented to solve the Bipedal-Walker challenge in OpenAI virtual environment where only partial state information is available. The validation on the extremely rugged terrain demonstrates the effectiveness of the proposed algorithm by achieving a new record of highest rewards in the challenge. The autonomous behaviors generated by our agent are highly adaptive to a variety of obstacles as shown in the simulation results.

##### Abstract (translated by Google)
本文提出了基于循环网络的确定性策略梯度的学习算法。长短期记忆被用来启用部分观察马尔可夫决策过程框架。新颖性是LSTM网络的改进：多步时间差的更新，通过时间去除反向传播，使用过去的轨迹扫描初始化隐藏状态，注入其他代理学习的外部经验。我们的方法通过引用过去的观察和行动的轨迹来促进强化学习机构推断所期望的行动。提出的算法被实现来解决在只有部分状态信息可用的OpenAI虚拟环境中的Bipedal-Walker挑战。在非常崎岖的地形上的验证通过实现挑战中最高奖励的新记录来证明所提出的算法的有效性。我们的代理产生的自主行为是非常适应各种障碍，如模拟结果所示。

##### URL
[http://arxiv.org/abs/1710.02896](http://arxiv.org/abs/1710.02896)

##### PDF
[http://arxiv.org/pdf/1710.02896](http://arxiv.org/pdf/1710.02896)

