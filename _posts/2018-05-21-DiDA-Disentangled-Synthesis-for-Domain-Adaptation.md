---
layout: post
title: "DiDA: Disentangled Synthesis for Domain Adaptation"
date: 2018-05-21 12:43:17
categories: arXiv_CV
tags: arXiv_CV
author: Jinming Cao, Oren Katzir, Peng Jiang, Dani Lischinski, Danny Cohen-Or, Changhe Tu, Yangyan Li
mathjax: true
---

* content
{:toc}

##### Abstract
Unsupervised domain adaptation aims at learning a shared model for two related, but not identical, domains by leveraging supervision from a source domain to an unsupervised target domain. A number of effective domain adaptation approaches rely on the ability to extract discriminative, yet domain-invariant, latent factors which are common to both domains. Extracting latent commonality is also useful for disentanglement analysis, enabling separation between the common and the domain-specific features of both domains. In this paper, we present a method for boosting domain adaptation performance by leveraging disentanglement analysis. The key idea is that by learning to separately extract both the common and the domain-specific features, one can synthesize more target domain data with supervision, thereby boosting the domain adaptation performance. Better common feature extraction, in turn, helps further improve the disentanglement analysis and disentangled synthesis. We show that iterating between domain adaptation and disentanglement analysis can consistently improve each other on several unsupervised domain adaptation tasks, for various domain adaptation backbone models.

##### Abstract (translated by Google)
无监督域适应旨在通过利用从源域到无监督目标域的监督来学习两个相关但不完全相同的域的共享模型。一些有效的领域适应方法依赖于提取两个领域共有的区分性，但是领域不变性，潜在因素的能力。提取潜在共性对于解开分析也很有用，可以区分两个域的常见域和特定域特征。在本文中，我们提出了一种通过利用解缠分析来提高域适应性能的方法。关键的想法是，通过学习分别提取公共特征和特定领域特征，可以在监督下合成更多的目标领域数据，从而提高领域适应性能。反过来，更好的共同特征提取有助于进一步改善解缠分析和解开合成。我们表明，域适应和解缠分析之间的迭代可以持续地相互改进几个无监督域适应任务，适用于各种域适应骨干模型。

##### URL
[https://arxiv.org/abs/1805.08019](https://arxiv.org/abs/1805.08019)

##### PDF
[https://arxiv.org/pdf/1805.08019](https://arxiv.org/pdf/1805.08019)

