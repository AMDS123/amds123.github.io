---
layout: post
title: "On the difficulty of a distributional semantics of spoken language"
date: 2018-03-23 16:30:06
categories: arXiv_CL
tags: arXiv_CL Face
author: Grzegorz Chrupała, Lieke Gelderloos, Ákos Kádár, Afra Alishahi
mathjax: true
---

* content
{:toc}

##### Abstract
The bulk of research in the area of speech processing concerns itself with supervised approaches to transcribing spoken language into text. In the domain of unsupervised learning most work on speech has focused on discovering relatively low level constructs such as phoneme inventories or word-like units. This is in contrast to research on written language, where there is a large body of work on unsupervised induction of semantic representations of words and whole sentences and longer texts. In this study we examine the challenges of adapting these approaches from written to spoken language. We conjecture that unsupervised learning of spoken language semantics becomes possible if we abstract from the surface variability. We simulate this setting by using a dataset of utterances spoken by a realistic but uniform synthetic voice. We evaluate two simple unsupervised models which, to varying degrees of success, learn semantic representations of speech fragments. Finally we suggest possible routes toward transferring our methods to the domain of unrestricted natural speech.

##### Abstract (translated by Google)
语音处理领域的大部分研究都是以监督方式将口语转录成文本。在无监督学习领域，大多数言语工作都集中在发现音位相似或词类单位等较低层次的构念上。这与书面语言的研究形成了鲜明的对比，在书面语言方面，有大量的工作用于无监督地引导单词和整个句子以及更长文本的语义表征。在这项研究中，我们考察了将这些方法从书面语言转变为口头语言的挑战。我们猜想，如果我们从表面变异性中抽象出来，那么口语语义的无监督学习就成为可能。我们通过使用由真实但统一的合成语音讲出的话语数据集来模拟这种设置。我们评估了两个简单的无监督模型，这些模型对不同程度的成功学习语音片段的语义表示。最后，我们建议将我们的方法转移到无限制的自然语言领域的可能途径。

##### URL
[https://arxiv.org/abs/1803.08869](https://arxiv.org/abs/1803.08869)

##### PDF
[https://arxiv.org/pdf/1803.08869](https://arxiv.org/pdf/1803.08869)

