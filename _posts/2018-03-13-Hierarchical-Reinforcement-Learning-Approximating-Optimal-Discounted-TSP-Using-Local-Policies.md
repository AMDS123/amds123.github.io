---
layout: post
title: "Hierarchical Reinforcement Learning: Approximating Optimal Discounted TSP Using Local Policies"
date: 2018-03-13 08:13:11
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning
author: Tom Zahavy, Avinatan Hasidim, Haim Kaplan, Yishay Mansour
mathjax: true
---

* content
{:toc}

##### Abstract
In this work, we provide theoretical guarantees for reward decomposition in deterministic MDPs. Reward decomposition is a special case of Hierarchical Reinforcement Learning, that allows one to learn many policies in parallel and combine them into a composite solution. Our approach builds on mapping this problem into a Reward Discounted Traveling Salesman Problem, and then deriving approximate solutions for it. In particular, we focus on approximate solutions that are local, i.e., solutions that only observe information about the current state. Local policies are easy to implement and do not require substantial computational resources as they do not perform planning. While local deterministic policies, like Nearest Neighbor, are being used in practice for hierarchical reinforcement learning, we propose three stochastic policies that guarantee better performance than any deterministic policy.

##### Abstract (translated by Google)
在这项工作中，我们为确定性MDP中的奖励分解提供了理论保证。奖励分解是分层强化学习的一个特例，它允许人们并行学习许多策略并将它们组合成一个综合解决方案。我们的方法建立在将此问题映射到奖励折扣旅行推销员问题上，然后推导出近似解决方案。特别是，我们专注于本地的近似解决方案，即仅观察有关当前状态信息的解决方案。本地政策易于实施，不需要大量的计算资源，因为它们不执行规划。虽然本地确定性策略（如最近邻居）在实践中用于等级强化学习，但我们提出了三个随机策略，可以保证比任何确定性策略都有更好的性能。

##### URL
[http://arxiv.org/abs/1803.04674](http://arxiv.org/abs/1803.04674)

##### PDF
[http://arxiv.org/pdf/1803.04674](http://arxiv.org/pdf/1803.04674)

