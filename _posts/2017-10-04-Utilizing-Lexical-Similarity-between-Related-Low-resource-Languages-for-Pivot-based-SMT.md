---
layout: post
title: "Utilizing Lexical Similarity between Related, Low-resource Languages for Pivot-based SMT"
date: 2017-10-04 20:55:03
categories: arXiv_SD
tags: arXiv_SD
author: Anoop Kunchukuttan, Maulik Shah, Pradyot Prakash, Pushpak Bhattacharyya
mathjax: true
---

* content
{:toc}

##### Abstract
We investigate pivot-based translation between related languages in a low resource, phrase-based SMT setting. We show that a subword-level pivot-based SMT model using a related pivot language is substantially better than word and morpheme-level pivot models. It is also highly competitive with the best direct translation model, which is encouraging as no direct source-target training corpus is used. We also show that combining multiple related language pivot models can rival a direct translation model. Thus, the use of subwords as translation units coupled with multiple related pivot languages can compensate for the lack of a direct parallel corpus.

##### Abstract (translated by Google)
我们在低资源，基于短语的SMT设置中调查相关语言之间的基于枢轴的翻译。我们表明，使用相关枢轴语言的子字级基于枢轴的SMT模型比单词和语素级枢轴模型要好得多。它也与最好的直接翻译模型竞争激烈，这是令人鼓舞的，因为没有使用直接的源语言目标训练语料库。我们还表明，结合多个相关的语言枢轴模型可以与直接翻译模型相媲美。因此，使用子词作为与多个相关的枢轴语言相结合的翻译单元可以补偿缺少直接平行的语料库。

##### URL
[https://arxiv.org/abs/1702.07203](https://arxiv.org/abs/1702.07203)

##### PDF
[https://arxiv.org/pdf/1702.07203](https://arxiv.org/pdf/1702.07203)

