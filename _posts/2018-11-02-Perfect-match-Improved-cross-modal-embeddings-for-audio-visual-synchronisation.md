---
layout: post
title: "Perfect match: Improved cross-modal embeddings for audio-visual synchronisation"
date: 2018-11-02 07:41:21
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition Embedding Classification Recognition
author: Soo-Whan Chung, Joon Son Chung, Hong-Goo Kang
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a new strategy for learning powerful cross-modal embeddings for audio-to-video synchronization. Here, we set up the problem as one of cross-modal retrieval, where the objective is to find the most relevant audio segment given a short video clip. The method builds on the recent advances in learning representations from cross-modal self-supervision. 
 The main contributions of this paper are as follows: (1) we propose a new learning strategy where the embeddings are learnt via a multi-way matching problem, as opposed to a binary classification (matching or non-matching) problem as proposed by recent papers; (2) we demonstrate that performance of this method far exceeds the existing baselines on the synchronization task; (3) we use the learnt embeddings for visual speech recognition in self-supervision, and show that the performance matches the representations learnt end-to-end in a fully-supervised manner.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1809.08001](http://arxiv.org/abs/1809.08001)

##### PDF
[http://arxiv.org/pdf/1809.08001](http://arxiv.org/pdf/1809.08001)

