---
layout: post
title: "MemexQA: Visual Memex Question Answering"
date: 2017-08-04 00:17:48
categories: arXiv_CL
tags: arXiv_CL QA
author: Lu Jiang, Junwei Liang, Liangliang Cao, Yannis Kalantidis, Sachin Farfade, Alexander Hauptmann
mathjax: true
---

* content
{:toc}

##### Abstract
This paper proposes a new task, MemexQA: given a collection of photos or videos from a user, the goal is to automatically answer questions that help users recover their memory about events captured in the collection. Towards solving the task, we 1) present the MemexQA dataset, a large, realistic multimodal dataset consisting of real personal photos and crowd-sourced questions/answers, 2) propose MemexNet, a unified, end-to-end trainable network architecture for image, text and video question answering. Experimental results on the MemexQA dataset demonstrate that MemexNet outperforms strong baselines and yields the state-of-the-art on this novel and challenging task. The promising results on TextQA and VideoQA suggest MemexNet's efficacy and scalability across various QA tasks.

##### Abstract (translated by Google)
本文提出了一个新的任务MemexQA：给出用户的照片或视频集合，目标是自动回答问题，帮助用户恢复关于在集合中捕获的事件的记忆。为了解决这个任务，我们1）提出了MemexQA数据集，一个真实的个人照片和众包的问题/答案组成的大型，现实的多模式数据集，2）提出MemexNet，一个统一的，端到端的可训练网络架构，文字和视频问答。 MemexQA数据集上的实验结果表明，MemexNet的性能优于强大的基线，并产生了这一新颖且具有挑战性的任务。 TextQA和VideoQA的有希望的结果表明MemexNet在各种质量保证任务中的有效性和可扩展性。

##### URL
[https://arxiv.org/abs/1708.01336](https://arxiv.org/abs/1708.01336)

##### PDF
[https://arxiv.org/pdf/1708.01336](https://arxiv.org/pdf/1708.01336)

