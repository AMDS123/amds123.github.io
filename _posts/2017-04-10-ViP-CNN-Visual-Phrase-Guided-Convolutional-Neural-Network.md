---
layout: post
title: "ViP-CNN: Visual Phrase Guided Convolutional Neural Network"
date: 2017-04-10 16:45:53
categories: arXiv_CV
tags: arXiv_CV Image_Caption Object_Detection Attention Caption CNN Detection Relation Recognition
author: Yikang Li, Wanli Ouyang, Xiaogang Wang, Xiao'ou Tang
mathjax: true
---

* content
{:toc}

##### Abstract
As the intermediate level task connecting image captioning and object detection, visual relationship detection started to catch researchers' attention because of its descriptive power and clear structure. It detects the objects and captures their pair-wise interactions with a subject-predicate-object triplet, e.g. person-ride-horse. In this paper, each visual relationship is considered as a phrase with three components. We formulate the visual relationship detection as three inter-connected recognition problems and propose a Visual Phrase guided Convolutional Neural Network (ViP-CNN) to address them simultaneously. In ViP-CNN, we present a Phrase-guided Message Passing Structure (PMPS) to establish the connection among relationship components and help the model consider the three problems jointly. Corresponding non-maximum suppression method and model training strategy are also proposed. Experimental results show that our ViP-CNN outperforms the state-of-art method both in speed and accuracy. We further pretrain ViP-CNN on our cleansed Visual Genome Relationship dataset, which is found to perform better than the pretraining on the ImageNet for this task.

##### Abstract (translated by Google)
视觉关系检测作为连接图像字幕和目标检测的中间层次任务，由于其描述能力强，结构清晰，开始引起研究者的关注。它检测对象并捕获它们与主题 - 谓词 - 对象三元组的成对交互，例如，人骑马。在本文中，每个视觉关系被视为具有三个组成部分的短语。我们将视觉关系检测表示为三个相互关联的识别问题，并提出一个视觉短语引导卷积神经网络（ViP-CNN）来同时解决它们。在ViP-CNN中，我们提出了一个短语引导的消息传递结构（PMPS）来建立关系组件之间的连接，并帮助模型共同考虑这三个问题。还提出了相应的非最大抑制方法和模型训练策略。实验结果表明，我们的ViP-CNN在速度和准确性方面均优于最先进的方法。我们在我们清理过的Visual Genome Relationship数据集上进一步预先捕获了ViP-CNN，该数据集的性能优于ImageNet上的预训练。

##### URL
[https://arxiv.org/abs/1702.07191](https://arxiv.org/abs/1702.07191)

##### PDF
[https://arxiv.org/pdf/1702.07191](https://arxiv.org/pdf/1702.07191)

