---
layout: post
title: 'ViP-CNN: Visual Phrase Guided Convolutional Neural Network'
date: 2017-04-10 16:45:53
categories: arXiv_CV
tags: arXiv_CV Image_Caption Object_Detection Caption CNN Detection Recognition
author: Yikang Li, Wanli Ouyang, Xiaogang Wang, Xiao'ou Tang
---

* content
{:toc}

##### Abstract
As the intermediate level task connecting image captioning and object detection, visual relationship detection started to catch researchers' attention because of its descriptive power and clear structure. It detects the objects and captures their pair-wise interactions with a subject-predicate-object triplet, e.g. person-ride-horse. In this paper, each visual relationship is considered as a phrase with three components. We formulate the visual relationship detection as three inter-connected recognition problems and propose a Visual Phrase guided Convolutional Neural Network (ViP-CNN) to address them simultaneously. In ViP-CNN, we present a Phrase-guided Message Passing Structure (PMPS) to establish the connection among relationship components and help the model consider the three problems jointly. Corresponding non-maximum suppression method and model training strategy are also proposed. Experimental results show that our ViP-CNN outperforms the state-of-art method both in speed and accuracy. We further pretrain ViP-CNN on our cleansed Visual Genome Relationship dataset, which is found to perform better than the pretraining on the ImageNet for this task.

##### Abstract (translated by Google)
视觉关系检测作为图像字幕与对象检测的中间级任务，由于其描述能力强，结构清晰，开始引起研究者的关注。它检测对象并捕获它们与主语 - 谓词 - 对象三元组的成对交互，例如，人骑马。在本文中，每个视觉关系被认为是一个有三个组成部分的短语。我们将视觉关系检测作为三个相互关联的识别问题，提出了一个视觉引导的卷积神经网络（ViP-CNN）来同时解决它们。在ViP-CNN中，我们提出了一个短语引导消息传递结构（PMPS）来建立关系组件之间的联系，并帮助模型共同考虑这三个问题。提出了相应的非最大抑制方法和模型训练策略。实验结果表明，我们的ViP-CNN在速度和准确性上均优于现有技术。我们进一步在我们清理的Visual Genome Relationship数据集上预处理ViP-CNN，发现这个数据集比ImageNet上的预训练要好。

##### URL
[https://arxiv.org/abs/1702.07191](https://arxiv.org/abs/1702.07191)

