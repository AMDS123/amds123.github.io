---
layout: post
title: "SMT vs NMT: A Comparison over Hindi & Bengali Simple Sentences"
date: 2018-12-12 11:11:08
categories: arXiv_CL
tags: arXiv_CL Attention NMT
author: Sainik Kumar Mahata, Soumil Mandal, Dipankar Das, Sivaji Bandyopadhyay
mathjax: true
---

* content
{:toc}

##### Abstract
In the present article, we identified the qualitative differences between Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) outputs. We have tried to answer two important questions: 1. Does NMT perform equivalently well with respect to SMT and 2. Does it add extra flavor in improving the quality of MT output by employing simple sentences as training units. In order to obtain insights, we have developed three core models viz., SMT model based on Moses toolkit, followed by character and word level NMT models. All of the systems use English-Hindi and English-Bengali language pairs containing simple sentences as well as sentences of other complexity. In order to preserve the translations semantics with respect to the target words of a sentence, we have employed soft-attention into our word level NMT model. We have further evaluated all the systems with respect to the scenarios where they succeed and fail. Finally, the quality of translation has been validated using BLEU and TER metrics along with manual parameters like fluency, adequacy etc. We observed that NMT outperforms SMT in case of simple sentences whereas SMT outperforms in case of all types of sentence.

##### Abstract (translated by Google)


##### URL
[https://arxiv.org/abs/1812.04898](https://arxiv.org/abs/1812.04898)

##### PDF
[https://arxiv.org/pdf/1812.04898](https://arxiv.org/pdf/1812.04898)

