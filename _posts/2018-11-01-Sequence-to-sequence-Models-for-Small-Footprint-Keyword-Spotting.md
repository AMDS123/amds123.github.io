---
layout: post
title: "Sequence-to-sequence Models for Small-Footprint Keyword Spotting"
date: 2018-11-01 12:53:53
categories: arXiv_SD
tags: arXiv_SD Attention RNN
author: Haitong Zhang, Junbo Zhang, Yujun Wang
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we propose a sequence-to-sequence model for keyword spotting (KWS). Compared with other end-to-end architectures for KWS, our model simplifies the pipelines of production-quality KWS system and satisfies the requirement of high accuracy, low-latency, and small-footprint. We also evaluate the performances of different encoder architectures, which include LSTM and GRU. Experiments on the real-world wake-up data show that our approach outperforms the recently proposed attention-based end-to-end model. Specifically speaking, with 73K parameters, our sequence-to-sequence model achieves $\sim$3.05\% false rejection rate (FRR) at 0.1 false alarm (FA) per hour.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1811.00348](http://arxiv.org/abs/1811.00348)

##### PDF
[http://arxiv.org/pdf/1811.00348](http://arxiv.org/pdf/1811.00348)

