---
layout: post
title: "Simultaneously Color-Depth Super-Resolution with Conditional Generative Adversarial Network"
date: 2017-11-08 14:51:24
categories: arXiv_CV
tags: arXiv_CV Adversarial Super_Resolution GAN Style_Transfer Detection
author: Lijun Zhao, Huihui Bai, Jie Liang, Bing Zeng, Anhong Wang, Yao Zhao
mathjax: true
---

* content
{:toc}

##### Abstract
Recently, Generative Adversarial Network (GAN) has been found wide applications in style transfer, image-to-image translation and image super-resolution. In this paper, a color-depth conditional GAN is proposed to concurrently resolve the problems of depth super-resolution and color super-resolution in 3D videos. Firstly, given the low-resolution depth image and low-resolution color image, a generative network is proposed to leverage mutual information of color image and depth image to enhance each other in consideration of the geometry structural dependency of color-depth image in the same scene. Secondly, three loss functions, including data loss, total variation loss, and 8-connected gradient difference loss are introduced to train this generative network in order to keep generated images close to the real ones, in addition to the adversarial loss. Experimental results demonstrate that the proposed approach produces high-quality color image and depth image from low-quality image pair, and it is superior to several other leading methods. Besides, we use the same neural network framework to resolve the problem of image smoothing and edge detection at the same time.

##### Abstract (translated by Google)
最近，生成对抗网络（GAN）在风格转换，图像到图像转换和图像超分辨率方面被广泛应用。本文提出了一种颜色深度条件GAN，以同时解决3D视频中深度超分辨率和彩色超分辨率问题。首先，针对低分辨率深度图像和低分辨率彩色图像，提出了一种生成网络，利用同一颜色深度图像的几何结构依赖性，利用彩色图像与深度图像的相互信息进行相互增强现场。其次，引入数据丢失，总变差损失和8连通梯度差损失三种损失函数对该生成网络进行训练，以保持生成的图像接近真实的图像，除了对抗性的损失。实验结果表明，所提出的方法从低质量的图像对产生高质量的彩色图像和深度图像，并且优于其他几种领先的方法。此外，我们使用相同的神经网络框架来同时解决图像平滑和边缘检测问题。

##### URL
[https://arxiv.org/abs/1708.09105](https://arxiv.org/abs/1708.09105)

##### PDF
[https://arxiv.org/pdf/1708.09105](https://arxiv.org/pdf/1708.09105)

