---
layout: post
title: "Interactive Grounded Language Acquisition and Generalization in a 2D World"
date: 2018-08-13 23:29:31
categories: arXiv_AI
tags: arXiv_AI Prediction Detection Relation
author: Haonan Yu, Haichao Zhang, Wei Xu
mathjax: true
---

* content
{:toc}

##### Abstract
We build a virtual agent for learning language in a 2D maze-like world. The agent sees images of the surrounding environment, listens to a virtual teacher, and takes actions to receive rewards. It interactively learns the teacher's language from scratch based on two language use cases: sentence-directed navigation and question answering. It learns simultaneously the visual representations of the world, the language, and the action control. By disentangling language grounding from other computational routines and sharing a concept detection function between language grounding and prediction, the agent reliably interpolates and extrapolates to interpret sentences that contain new word combinations or new words missing from training sentences. The new words are transferred from the answers of language prediction. Such a language ability is trained and evaluated on a population of over 1.6 million distinct sentences consisting of 119 object words, 8 color words, 9 spatial-relation words, and 50 grammatical words. The proposed model significantly outperforms five comparison methods for interpreting zero-shot sentences. In addition, we demonstrate human-interpretable intermediate outputs of the model in the appendix.

##### Abstract (translated by Google)
我们在2D迷宫般的世界中构建了一个用于学习语言的虚拟代理。代理人看到周围环境的图像，听取虚拟教师的声音，并采取行动接收奖励。它基于两种语言用例交互式地从头开始学习教师的语言：句子导航和问答。它同时学习世界，语言和动作控制的视觉表现。通过将语言基础与其他计算例程解开并在语言基础和预测之间共享概念检测功能，代理可靠地插入和推断以解释包含新词组合或训练句中缺失的新词的句子。新单词从语言预测的答案转移。这种语言能力是在超过160万个不同句子的群体上训练和评估的，这些句子由119个对象词，8个颜色词，9个空间关系词和50个语法词组成。所提出的模型明显优于解释零射击句子的五种比较方法。此外，我们在附录中展示了该模型的人类可解释的中间产出。

##### URL
[http://arxiv.org/abs/1802.01433](http://arxiv.org/abs/1802.01433)

##### PDF
[http://arxiv.org/pdf/1802.01433](http://arxiv.org/pdf/1802.01433)

