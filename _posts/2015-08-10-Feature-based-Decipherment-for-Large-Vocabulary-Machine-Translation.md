---
layout: post
title: "Feature-based Decipherment for Large Vocabulary Machine Translation"
date: 2015-08-10 07:02:49
categories: arXiv_CL
tags: arXiv_CL Inference
author: Iftekhar Naim, Daniel Gildea
mathjax: true
---

* content
{:toc}

##### Abstract
Orthographic similarities across languages provide a strong signal for probabilistic decipherment, especially for closely related language pairs. The existing decipherment models, however, are not well-suited for exploiting these orthographic similarities. We propose a log-linear model with latent variables that incorporates orthographic similarity features. Maximum likelihood training is computationally expensive for the proposed log-linear model. To address this challenge, we perform approximate inference via MCMC sampling and contrastive divergence. Our results show that the proposed log-linear model with contrastive divergence scales to large vocabularies and outperforms the existing generative decipherment models by exploiting the orthographic features.

##### Abstract (translated by Google)
不同语言的正字法相似性为概率解密提供了强有力的信号，特别是对于密切相关的语言对。但是，现有的解密模型并不适合利用这些正字法的相似性。我们提出了一个对数线性模型与潜在变量合并的正交相似特征。对于所提出的对数线性模型，最大似然训练在计算上是昂贵的。为了解决这个难题，我们通过MCMC采样和对比散度进行近似推理。我们的研究结果表明，所提出的对数散度的对数线性模型可以扩展到大的词汇表，并且通过利用拼字特征优于现有的生成译码模型。

##### URL
[https://arxiv.org/abs/1508.02142](https://arxiv.org/abs/1508.02142)

##### PDF
[https://arxiv.org/pdf/1508.02142](https://arxiv.org/pdf/1508.02142)

