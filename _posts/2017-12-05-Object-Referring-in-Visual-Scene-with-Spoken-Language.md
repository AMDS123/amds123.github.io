---
layout: post
title: "Object Referring in Visual Scene with Spoken Language"
date: 2017-12-05 15:12:24
categories: arXiv_CV
tags: arXiv_CV
author: Arun Balajee Vasudevan, Dengxin Dai, Luc Van Gool
mathjax: true
---

* content
{:toc}

##### Abstract
Object referring has important applications, especially for human-machine interaction. While having received great attention, the task is mainly attacked with written language (text) as input rather than spoken language (speech), which is more natural. This paper investigates Object Referring with Spoken Language (ORSpoken) by presenting two datasets and one novel approach. Objects are annotated with their locations in images, text descriptions and speech descriptions. This makes the datasets ideal for multi-modality learning. The approach is developed by carefully taking down ORSpoken problem into three sub-problems and introducing task-specific vision-language interactions at the corresponding levels. Experiments show that our method outperforms competing methods consistently and significantly. The approach is also evaluated in the presence of audio noise, showing the efficacy of the proposed vision-language interaction methods in counteracting background noise.

##### Abstract (translated by Google)
对象引用具有重要的应用，特别是对于人机交互。在受到高度关注的同时，主要是以书面语言（文本）作为输入，而不是口头语言（言语）来攻击，这是比较自然的。本文通过提出两个数据集和一个新颖的方法来研究对象引用口语（ORPoken）。对象用图像，文字描述和语音描述中的位置进行注释。这使得数据集适合于多模式学习。该方法是通过仔细地将ORRoken问题分解成三个子问题并在相应的级别引入特定于任务的视觉语言交互来开发的。实验表明，我们的方法一贯而显着地优于竞争方法。该方法还评估存在的音频噪声，显示了建议的视觉语言交互方法在抵消背景噪音的功效。

##### URL
[http://arxiv.org/abs/1711.03800](http://arxiv.org/abs/1711.03800)

