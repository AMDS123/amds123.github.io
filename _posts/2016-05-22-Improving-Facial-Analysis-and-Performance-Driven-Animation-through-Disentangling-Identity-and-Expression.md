---
layout: post
title: "Improving Facial Analysis and Performance Driven Animation through Disentangling Identity and Expression"
date: 2016-05-22 23:01:37
categories: arXiv_CV
tags: arXiv_CV Tracking Prediction Recognition
author: David Rim, Sina Honari, Md Kamrul Hasan, Chris Pal
mathjax: true
---

* content
{:toc}

##### Abstract
We present techniques for improving performance driven facial animation, emotion recognition, and facial key-point or landmark prediction using learned identity invariant representations. Established approaches to these problems can work well if sufficient examples and labels for a particular identity are available and factors of variation are highly controlled. However, labeled examples of facial expressions, emotions and key-points for new individuals are difficult and costly to obtain. In this paper we improve the ability of techniques to generalize to new and unseen individuals by explicitly modeling previously seen variations related to identity and expression. We use a weakly-supervised approach in which identity labels are used to learn the different factors of variation linked to identity separately from factors related to expression. We show how probabilistic modeling of these sources of variation allows one to learn identity-invariant representations for expressions which can then be used to identity-normalize various procedures for facial expression analysis and animation control. We also show how to extend the widely used techniques of active appearance models and constrained local models through replacing the underlying point distribution models which are typically constructed using principal component analysis with identity-expression factorized representations. We present a wide variety of experiments in which we consistently improve performance on emotion recognition, markerless performance-driven facial animation and facial key-point tracking.

##### Abstract (translated by Google)
我们提出了使用学习的身份不变表示来改进性能驱动的面部动画，情感识别以及面部关键点或标志预测的技术。如果有足够的特定身份的例子和标签可供使用，并且变异因素受到高度控制，那么建立这些问题的方法可以奏效。然而，新面孔的面部表情，情绪和关键点的标记例子是困难且昂贵的。在本文中，我们通过明确建模与身份和表达相关的以前看到的变化来提高技术向新的和看不见的个体推广的能力。我们使用弱监督的方法，使用身份标签来学习与身份相关的变异的不同因素，与表达相关的因素分开。我们展示了这些变异来源的概率建模如何允许学习表达的身份不变表示，然后可以用于对脸部表情分析和动画控制的各种程序进行身份归一化。我们还展示了如何扩展主动外观模型和约束局部模型的广泛使用的技术，通过替换通常使用主成分分析构建的基础点分布模型与身份表达分解表示。我们提出了多种实验，我们不断提高情感识别，无标记性能驱动的面部动画和面部关键点跟踪的性能。

##### URL
[https://arxiv.org/abs/1512.08212](https://arxiv.org/abs/1512.08212)

##### PDF
[https://arxiv.org/pdf/1512.08212](https://arxiv.org/pdf/1512.08212)

