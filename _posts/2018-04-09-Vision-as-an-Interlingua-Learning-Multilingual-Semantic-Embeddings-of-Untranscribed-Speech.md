---
layout: post
title: "Vision as an Interlingua: Learning Multilingual Semantic Embeddings of Untranscribed Speech"
date: 2018-04-09 15:15:37
categories: arXiv_CV
tags: arXiv_CV Speech_Recognition Caption Embedding Recognition
author: David Harwath, Galen Chuang, James Glass
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we explore the learning of neural network embeddings for natural images and speech waveforms describing the content of those images. These embeddings are learned directly from the waveforms without the use of linguistic transcriptions or conventional speech recognition technology. While prior work has investigated this setting in the monolingual case using English speech data, this work represents the first effort to apply these techniques to languages beyond English. Using spoken captions collected in English and Hindi, we show that the same model architecture can be successfully applied to both languages. Further, we demonstrate that training a multilingual model simultaneously on both languages offers improved performance over the monolingual models. Finally, we show that these models are capable of performing semantic cross-lingual speech-to-speech retrieval.

##### Abstract (translated by Google)
在本文中，我们探讨了自然图像的神经网络嵌入和描述这些图像内容的语音波形的学习。这些嵌入可以直接从波形中学习，而不需要使用语言转录或传统的语音识别技术。虽然之前的研究使用英语语音数据对单语言情况下的这一设置进行了调查，但这项工作代表了首次将这些技术应用于英语以外的语言。使用以英文和印地文收集的口头字幕，我们表明相同的模型架构可以成功应用于这两种语言。此外，我们证明在两种语言中同时培训多语言模型可以提高单语模型的性能。最后，我们证明这些模型能够执行语义跨语言的语音到语音检索。

##### URL
[https://arxiv.org/abs/1804.03052](https://arxiv.org/abs/1804.03052)

##### PDF
[https://arxiv.org/pdf/1804.03052](https://arxiv.org/pdf/1804.03052)

