---
layout: post
title: "Learning Action Maps of Large Environments via First-Person Vision"
date: 2016-05-05 18:22:30
categories: arXiv_CV
tags: arXiv_CV Sparse Prediction Detection
author: Nicholas Rhinehart, Kris M. Kitani
mathjax: true
---

* content
{:toc}

##### Abstract
When people observe and interact with physical spaces, they are able to associate functionality to regions in the environment. Our goal is to automate dense functional understanding of large spaces by leveraging sparse activity demonstrations recorded from an ego-centric viewpoint. The method we describe enables functionality estimation in large scenes where people have behaved, as well as novel scenes where no behaviors are observed. Our method learns and predicts "Action Maps", which encode the ability for a user to perform activities at various locations. With the usage of an egocentric camera to observe human activities, our method scales with the size of the scene without the need for mounting multiple static surveillance cameras and is well-suited to the task of observing activities up-close. We demonstrate that by capturing appearance-based attributes of the environment and associating these attributes with activity demonstrations, our proposed mathematical framework allows for the prediction of Action Maps in new environments. Additionally, we offer a preliminary glance of the applicability of Action Maps by demonstrating a proof-of-concept application in which they are used in concert with activity detections to perform localization.

##### Abstract (translated by Google)
当人们观察和与物理空间交互时，他们能够将功能与环境中的区域相关联。我们的目标是通过利用以自我为中心观点记录的稀疏活动演示来自动化对大空间的密集功能理解。我们描述的方法可以在人们表现的大场景中进行功能估计，以及不会观察到任何行为的新颖场景。我们的方法学习和预测“行动地图”，它编码了用户在不同地点执行活动的能力。利用自我中心相机观察人体活动，我们的方法不需要安装多台静态监控摄像机，就可以随着场景的大小进行缩放，非常适合观察活动的近距离观察。我们通过捕获环境的外观属性并将这些属性与活动演示关联起来，我们提出的数学框架允许在新的环境中预测动作地图。此外，我们通过展示概念验证应用程序，初步了解“动作地图”的适用性，在此应用程序中将它们与活动检测结合使用以执行本地化。

##### URL
[https://arxiv.org/abs/1605.01679](https://arxiv.org/abs/1605.01679)

##### PDF
[https://arxiv.org/pdf/1605.01679](https://arxiv.org/pdf/1605.01679)

