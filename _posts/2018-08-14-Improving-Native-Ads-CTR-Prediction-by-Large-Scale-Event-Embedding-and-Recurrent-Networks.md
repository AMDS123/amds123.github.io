---
layout: post
title: "Improving Native Ads CTR Prediction by Large Scale Event Embedding and Recurrent Networks"
date: 2018-08-14 07:30:11
categories: arXiv_AI
tags: arXiv_AI Attention Embedding Prediction
author: Mehul Parsana, Krishna Poola, Yajun Wang, Zhiguang Wang
mathjax: true
---

* content
{:toc}

##### Abstract
Click through rate (CTR) prediction is very important for Native advertisement but also hard as there is no direct query intent. In this paper we propose a large-scale event embedding scheme to encode the each user browsing event by training a Siamese network with weak supervision on the users' consecutive events. The CTR prediction problem is modeled as a supervised recurrent neural network, which naturally model the user history as a sequence of events. Our proposed recurrent models utilizing pretrained event embedding vectors and an attention layer to model the user history. Our experiments demonstrate that our model significantly outperforms the baseline and some variants.

##### Abstract (translated by Google)
点击率（CTR）预测对于原生广告非常重要，但也很难，因为没有直接的查询意图。在本文中，我们提出了一种大规模事件嵌入方案，通过训练一个对用户连续事件监督不力的连体网络来编码每个用户浏览事件。 CTR预测问题被建模为监督的递归神经网络，其自然地将用户历史建模为事件序列。我们提出的循环模型利用预训练事件嵌入向量和注意层来模拟用户历史。我们的实验表明，我们的模型明显优于基线和一些变体。

##### URL
[http://arxiv.org/abs/1804.09133](http://arxiv.org/abs/1804.09133)

##### PDF
[http://arxiv.org/e-print/1804.09133](http://arxiv.org/e-print/1804.09133)

