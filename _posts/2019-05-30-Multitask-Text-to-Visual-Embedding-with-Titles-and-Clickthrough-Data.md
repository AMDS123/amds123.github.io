---
layout: post
title: "Multitask Text-to-Visual Embedding with Titles and Clickthrough Data"
date: 2019-05-30 22:33:15
categories: arXiv_CV
tags: arXiv_CV Embedding RNN
author: Pranav Aggarwal, Zhe Lin, Baldo Faieta, Saeid Motiian
mathjax: true
---

* content
{:toc}

##### Abstract
Text-visual (or called semantic-visual) embedding is a central problem in vision-language research. It typically involves mapping of an image and a text description to a common feature space through a CNN image encoder and a RNN language encoder. In this paper, we propose a new method for learning text-visual embedding using both image titles and click-through data from an image search engine. We also propose a new triplet loss function by modeling positive awareness of the embedding, and introduce a novel mini-batch-based hard negative sampling approach for better data efficiency in the learning process. Experimental results show that our proposed method outperforms existing methods, and is also effective for real-world text-to-visual retrieval.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.13339](http://arxiv.org/abs/1905.13339)

##### PDF
[http://arxiv.org/pdf/1905.13339](http://arxiv.org/pdf/1905.13339)

