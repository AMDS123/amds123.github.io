---
layout: post
title: "Neural Domain Adaptation for Biomedical Question Answering"
date: 2017-06-15 15:16:18
categories: arXiv_CL
tags: arXiv_CL QA Embedding Transfer_Learning Deep_Learning
author: Georg Wiese, Dirk Weissenborn, Mariana Neves
mathjax: true
---

* content
{:toc}

##### Abstract
Factoid question answering (QA) has recently benefited from the development of deep learning (DL) systems. Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles. However, these systems have not yet been applied to QA in more specific domains, such as biomedicine, because datasets are generally too small to train a DL system from scratch. For example, the BioASQ dataset for biomedical QA comprises less then 900 factoid (single answer) and list (multiple answers) QA instances. In this work, we adapt a neural QA system trained on a large open-domain dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) by employing various transfer learning techniques. Our network architecture is based on a state-of-the-art QA system, extended with biomedical word embeddings and a novel mechanism to answer list questions. In contrast to existing biomedical QA systems, our system does not rely on domain-specific ontologies, parsers or entity taggers, which are expensive to create. Despite this fact, our systems achieve state-of-the-art results on factoid questions and competitive results on list questions.

##### Abstract (translated by Google)
真题回答（QA）最近受益于深度学习（DL）系统的发展。在存在大量数据集的领域，神经网络模型优于传统方法，例如维基百科文章的SQUAD（大约100,000个问题）。然而，这些系统还没有被应用到QA等更具体的领域，如生物医学，因为数据集通常太小而不能从零开始训练DL系统。例如，用于生物医学QA的BioASQ数据集包含少于900个factoid（单一答案）和list（多个答案）QA实例。在这项工作中，我们通过采用各种转移学习技术，将训练在大型开放域数据集（SQUAD，源）上的神经QA系统适配到生物医学数据集（BioASQ，目标）。我们的网络架构基于最先进的质量保证体系，扩展了生物医学词汇嵌入和新颖的机制来回答列表问题。与现有的生物医学QA系统相比，我们的系统不依赖特定于领域的本体，解析器或实体标记器，这些创建过程非常昂贵。尽管如此，我们的系统还是能够在列表问题上获得真实性问题和竞争结果的最新结果。

##### URL
[https://arxiv.org/abs/1706.03610](https://arxiv.org/abs/1706.03610)

##### PDF
[https://arxiv.org/pdf/1706.03610](https://arxiv.org/pdf/1706.03610)

