---
layout: post
title: "The Corpus Replication Task"
date: 2018-06-20 20:37:28
categories: arXiv_CL
tags: arXiv_CL Embedding Language_Model Relation
author: Tobias Eichinger
mathjax: true
---

* content
{:toc}

##### Abstract
In the field of Natural Language Processing (NLP), we revisit the well-known word embedding algorithm word2vec. Word embeddings identify words by vectors such that the words' distributional similarity is captured. Unexpectedly, besides semantic similarity even relational similarity has been shown to be captured in word embeddings generated by word2vec, whence two questions arise. Firstly, which kind of relations are representable in continuous space and secondly, how are relations built. In order to tackle these questions we propose a bottom-up point of view. We call generating input text for which word2vec outputs target relations solving the Corpus Replication Task. Deeming generalizations of this approach to any set of relations possible, we expect solving of the Corpus Replication Task to provide partial answers to the questions.

##### Abstract (translated by Google)
在自然语言处理（NLP）领域，我们重新审视了着名的词嵌入算法word2vec。字嵌入通过向量来识别单词，以便捕获单词“分布相似性”。出乎意料的是，除了语义相似性之外，甚至关系相似性已经被显示为在word2vec生成的词嵌入中被捕获，因此出现了两个问题。首先，哪种关系可以在连续的空间中表现出来，其次，关系是如何建立的。为了解决这些问题，我们提出了一个自下而上的观点。我们称之为word2vec输出解决语料库复制任务的目标关系的输入文本。认为这种方法对任何一组关系都有可能的概括，我们期望解决语料库复制任务以提供问题的部分答案。

##### URL
[http://arxiv.org/abs/1806.07978](http://arxiv.org/abs/1806.07978)

##### PDF
[http://arxiv.org/pdf/1806.07978](http://arxiv.org/pdf/1806.07978)

