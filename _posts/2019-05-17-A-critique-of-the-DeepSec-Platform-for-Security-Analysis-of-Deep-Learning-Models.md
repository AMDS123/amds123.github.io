---
layout: post
title: "A critique of the DeepSec Platform for Security Analysis of Deep Learning Models"
date: 2019-05-17 04:26:52
categories: arXiv_AI
tags: arXiv_AI Adversarial Deep_Learning
author: Nicholas Carlini
mathjax: true
---

* content
{:toc}

##### Abstract
At IEEE S&amp;P 2019, the paper "DeepSec: A Uniform Platform for Security Analysis of Deep Learning Model" aims to to "systematically evaluate the existing adversarial attack and defense methods." While the paper's goals are laudable, it fails to achieve them and presents results that are fundamentally flawed and misleading. We explain the flaws in the DeepSec work, along with how its analysis fails to meaningfully evaluate the various attacks and defenses. Specifically, DeepSec (1) evaluates each defense obliviously, using attacks crafted against undefended models; (2) evaluates attacks and defenses using incorrect implementations that greatly under-estimate their effectiveness; (3) evaluates the robustness of each defense as an average, not based on the most effective attack against that defense; (4) performs several statistical analyses incorrectly and fails to report variance; and, (5) as a result of these errors draws invalid conclusions and makes sweeping generalizations.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1905.07112](http://arxiv.org/abs/1905.07112)

##### PDF
[http://arxiv.org/pdf/1905.07112](http://arxiv.org/pdf/1905.07112)

