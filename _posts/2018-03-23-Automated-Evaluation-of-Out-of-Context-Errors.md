---
layout: post
title: "Automated Evaluation of Out-of-Context Errors"
date: 2018-03-23 21:20:00
categories: arXiv_AI
tags: arXiv_AI Classification Language_Model Detection
author: Patrick Huber, Jan Niehues, Alex Waibel
mathjax: true
---

* content
{:toc}

##### Abstract
We present a new approach to evaluate computational models for the task of text understanding by the means of out-of-context error detection. Through the novel design of our automated modification process, existing large-scale data sources can be adopted for a vast number of text understanding tasks. The data is thereby altered on a semantic level, allowing models to be tested against a challenging set of modified text passages that require to comprise a broader narrative discourse. Our newly introduced task targets actual real-world problems of transcription and translation systems by inserting authentic out-of-context errors. The automated modification process is applied to the 2016 TEDTalk corpus. Entirely automating the process allows the adoption of complete datasets at low cost, facilitating supervised learning procedures and deeper networks to be trained and tested. To evaluate the quality of the modification algorithm a language model and a supervised binary classification model are trained and tested on the altered dataset. A human baseline evaluation is examined to compare the results with human performance. The outcome of the evaluation task indicates the difficulty to detect semantic errors for machine-learning algorithms and humans, showing that the errors cannot be identified when limited to a single sentence.

##### Abstract (translated by Google)
我们提出了一种新的方法来评估用于文本理解任务的计算模型，其方式是通过上下文错误检测。通过我们自动修改过程的新颖设计，现有的大型数据源可以用于大量的文本理解任务。数据因此在语义层面上被改变，允许模型针对需要包括更广泛的叙述性话语的具有挑战性的经修改的文本段落进行测试。我们新推出的任务通过插入真正的上下文错误来针对实际的转录和翻译系统的实际问题。自动修改过程适用于2016 TEDTalk语料库。完全实现流程自动化，可以以低成本采用完整的数据集，便于监督学习过程和深入的网络进行培训和测试。为了评估修改算法的质量，在改变的数据集上训练和测试语言模型和监督二进制分类模型。检查人类基线评估以将结果与人类表现进行比较。评估任务的结果表明难以检测机器学习算法和人类的语义错误，表明当限于单个句子时不能识别错误。

##### URL
[https://arxiv.org/abs/1803.08983](https://arxiv.org/abs/1803.08983)

##### PDF
[https://arxiv.org/pdf/1803.08983](https://arxiv.org/pdf/1803.08983)

