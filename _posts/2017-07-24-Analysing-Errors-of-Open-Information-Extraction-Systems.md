---
layout: post
title: "Analysing Errors of Open Information Extraction Systems"
date: 2017-07-24 11:49:00
categories: arXiv_CL
tags: arXiv_CL Relation
author: Rudolf Schneider, Tom Oberhauser, Tobias Klatt, Felix A. Gers, Alexander Löser
mathjax: true
---

* content
{:toc}

##### Abstract
We report results on benchmarking Open Information Extraction (OIE) systems using RelVis, a toolkit for benchmarking Open Information Extraction systems. Our comprehensive benchmark contains three data sets from the news domain and one data set from Wikipedia with overall 4522 labeled sentences and 11243 binary or n-ary OIE relations. In our analysis on these data sets we compared the performance of four popular OIE systems, ClausIE, OpenIE 4.2, Stanford OpenIE and PredPatt. In addition, we evaluated the impact of five common error classes on a subset of 749 n-ary tuples. From our deep analysis we unreveal important research directions for a next generation of OIE systems.

##### Abstract (translated by Google)
我们使用RelVis（基于开放式信息抽取系统的基准测试工具）对开放信息抽取（OIE）系统进行基准测试报告结果。我们的综合基准测试包含三个来自新闻领域的数据集和一个来自维基百科的数据集，总共4522个标记句子和11243个二元或n元OIE关系。在我们对这些数据集的分析中，我们比较了四种流行的OIE系统（ClausIE，OpenIE 4.2，Stanford OpenIE和PredPatt）的性能。另外，我们评估了五个常见错误类对749个n元组的子集的影响。从我们的深入分析，我们没有揭示下一代OIE系统的重要研究方向。

##### URL
[https://arxiv.org/abs/1707.07499](https://arxiv.org/abs/1707.07499)

##### PDF
[https://arxiv.org/pdf/1707.07499](https://arxiv.org/pdf/1707.07499)

