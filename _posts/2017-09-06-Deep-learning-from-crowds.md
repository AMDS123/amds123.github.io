---
layout: post
title: "Deep learning from crowds"
date: 2017-09-06 11:41:19
categories: arXiv_CV
tags: arXiv_CV Classification Deep_Learning
author: Filipe Rodrigues, Francisco Pereira
mathjax: true
---

* content
{:toc}

##### Abstract
Over the last few years, deep learning has revolutionized the field of machine learning by dramatically improving the state-of-the-art in various domains. However, as the size of supervised artificial neural networks grows, typically so does the need for larger labeled datasets. Recently, crowdsourcing has established itself as an efficient and cost-effective solution for labeling large sets of data in a scalable manner, but it often requires aggregating labels from multiple noisy contributors with different levels of expertise. In this paper, we address the problem of learning deep neural networks from crowds. We begin by describing an EM algorithm for jointly learning the parameters of the network and the confusion matrices of the different annotators for classification settings. Then, a novel general-purpose crowd layer is proposed, which allows us to train deep neural networks end-to-end, directly from the noisy labels of multiple annotators, using backpropagation. We empirically show that the proposed approach is able to internally capture the reliability and biases of different annotators and achieve new state-of-the-art results for various crowdsourced datasets across different settings, namely classification, regression and sequence labeling.

##### Abstract (translated by Google)
在过去的几年中，深度学习通过戏剧性地改进各个领域的最新技术，彻底改变了机器学习领域。然而，随着有监督人工神经网络的规模的增长，通常需要更大的标记数据集。最近，众包已经确立了自己作为一个高效率和成本效益的解决方案，以可扩展的方式标记大量数据，但它往往需要从不同级别的专业知识的多个嘈杂的贡献者聚合标签。在本文中，我们解决了从人群中学习深度神经网络的问题。我们首先描述用于联合学习网络参数的EM算法和用于分类设置的不同注释器的混淆矩阵。然后，提出了一个新的通用人群层，它允许我们使用反向传播直接从多个注释器的噪声标签端到端地训练深度神经网络。我们凭经验证明，所提出的方法能够在内部捕捉不同注释者的可靠性和偏差，并针对不同设置下的各种众包数据集（即分类，回归和序列标签）获得新的最新结果。

##### URL
[https://arxiv.org/abs/1709.01779](https://arxiv.org/abs/1709.01779)

##### PDF
[https://arxiv.org/pdf/1709.01779](https://arxiv.org/pdf/1709.01779)

