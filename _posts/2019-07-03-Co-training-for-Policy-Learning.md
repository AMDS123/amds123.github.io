---
layout: post
title: "Co-training for Policy Learning"
date: 2019-07-03 02:54:13
categories: arXiv_AI
tags: arXiv_AI Reinforcement_Learning Optimization Classification
author: Jialin Song, Ravi Lanka, Yisong Yue, Masahiro Ono
mathjax: true
---

* content
{:toc}

##### Abstract
We study the problem of learning sequential decision-making policies in settings with multiple state-action representations. Such settings naturally arise in many domains, such as planning (e.g., multiple integer programming formulations) and various combinatorial optimization problems (e.g., those with both integer programming and graph-based formulations). Inspired by the classical co-training framework for classification, we study the problem of co-training for policy learning. We present sufficient conditions under which learning from two views can improve upon learning from a single view alone. Motivated by these theoretical insights, we present a meta-algorithm for co-training for sequential decision making. Our framework is compatible with both reinforcement learning and imitation learning. We validate the effectiveness of our approach across a wide range of tasks, including discrete/continuous control and combinatorial optimization.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1907.04484](http://arxiv.org/abs/1907.04484)

##### PDF
[http://arxiv.org/pdf/1907.04484](http://arxiv.org/pdf/1907.04484)

