---
layout: post
title: "A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex Environments"
date: 2018-02-28 13:49:18
categories: arXiv_RO
tags: arXiv_RO Knowledge Deep_Learning
author: German I. Parisi, Pablo Barros, Di Fu, Sven Magg, Haiyan Wu, Xun Liu, Stefan Wermter
mathjax: true
---

* content
{:toc}

##### Abstract
Crossmodal conflict resolution is a crucial component of robot sensorimotor coupling through interaction with the environment for swift and robust behaviour also in noisy conditions. In this paper, we propose a neurorobotic experiment in which an iCub robot exhibits human-like responses in a complex crossmodal environment. To better understand how humans deal with multisensory conflicts, we conducted a behavioural study exposing 33 subjects to congruent and incongruent dynamic audio-visual cues. In contrast to previous studies using simplified stimuli, we designed a scenario with four animated avatars and observed that the magnitude and extension of the visual bias are related to the semantics embedded in the scene, i.e., visual cues that are congruent with environmental statistics (moving lips and vocalization) induce a stronger bias. We propose a deep learning model that processes stereophonic sound, facial features, and body motion to trigger a discrete response resembling the collected behavioural data. After training, we exposed the iCub to the same experimental conditions as the human subjects, showing that the robot can replicate similar responses in real time. Our interdisciplinary work provides important insights into how crossmodal conflict resolution can be modelled in robots and introduces future research directions for the efficient combination of sensory drive with internally generated knowledge and expectations.

##### Abstract (translated by Google)
跨模式冲突解决方案是机器人感应运动耦合的一个重要组成部分，它通过与环境的交互作用，在嘈杂的环境中实现快速和强大的行为。在本文中，我们提出了一个神经生物学实验，其中一个iCub机器人在一个复杂的交叉模式环境中展现出类人的反应。为了更好地理解人类如何处理多重感觉冲突，我们进行了一项行为研究，将33位受试者暴露于一致和不一致的动态视听线索。与以前使用简化刺激的研究相比，我们设计了一个包含四个动画角色的场景，并观察到视觉偏差的大小和范围与场景中嵌入的语义相关，即与环境统计数据一致的视觉线索（移动嘴唇和发声）引起更强烈的偏见。我们提出了一种深度学习模型，可以处理立体声，面部特征和身体运动，从而触发类似收集的行为数据的离散响应。训练结束后，我们将iCub暴露在与人类受试者相同的实验条件下，表明机器人可以实时复制类似的反应。我们的跨学科工作为如何在机器人中模拟交叉冲突解决方案提供了重要见解，并介绍了将感官驱动与内部生成的知识和期望有效结合的未来研究方向。

##### URL
[http://arxiv.org/abs/1802.10408](http://arxiv.org/abs/1802.10408)

##### PDF
[http://arxiv.org/pdf/1802.10408](http://arxiv.org/pdf/1802.10408)

