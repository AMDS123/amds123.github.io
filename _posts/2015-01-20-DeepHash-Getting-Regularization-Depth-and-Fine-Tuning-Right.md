---
layout: post
title: "DeepHash: Getting Regularization, Depth and Fine-Tuning Right"
date: 2015-01-20 04:36:12
categories: arXiv_CV
tags: arXiv_CV Regularization CNN
author: Jie Lin, Olivier Morere, Vijay Chandrasekhar, Antoine Veillard, Hanlin Goh
mathjax: true
---

* content
{:toc}

##### Abstract
This work focuses on representing very high-dimensional global image descriptors using very compact 64-1024 bit binary hashes for instance retrieval. We propose DeepHash: a hashing scheme based on deep networks. Key to making DeepHash work at extremely low bitrates are three important considerations -- regularization, depth and fine-tuning -- each requiring solutions specific to the hashing problem. In-depth evaluation shows that our scheme consistently outperforms state-of-the-art methods across all data sets for both Fisher Vectors and Deep Convolutional Neural Network features, by up to 20 percent over other schemes. The retrieval performance with 256-bit hashes is close to that of the uncompressed floating point features -- a remarkable 512 times compression.

##### Abstract (translated by Google)
这项工作的重点是使用非常紧凑的64-1024位二进制哈希来表示非常高维的全局图像描述符。我们建议DeepHash：一个基于深度网络的散列方案。让DeepHash以极低的比特率工作的关键是三个重要的考虑因素 - 正规化，深度和微调 - 每个都需要特定于哈希问题的解决方案。深入的评估表明，我们的方案始终比所有数据集中的Fisher矢量和深度卷积神经网络特征的最先进方法优于其他方案高达20％。 256位散列的检索性能接近于未压缩的浮点特征 - 显着的512倍压缩。

##### URL
[https://arxiv.org/abs/1501.04711](https://arxiv.org/abs/1501.04711)

##### PDF
[https://arxiv.org/pdf/1501.04711](https://arxiv.org/pdf/1501.04711)

