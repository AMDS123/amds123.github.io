---
layout: post
title: "Learning Flexible and Reusable Locomotion Primitives for a Microrobot"
date: 2018-03-01 03:48:06
categories: arXiv_AI
tags: arXiv_AI Knowledge Optimization
author: Brian Yang, Grant Wang, Roberto Calandra, Daniel Contreras, Sergey Levine, Kristofer Pister
mathjax: true
---

* content
{:toc}

##### Abstract
The design of gaits for robot locomotion can be a daunting process which requires significant expert knowledge and engineering. This process is even more challenging for robots that do not have an accurate physical model, such as compliant or micro-scale robots. Data-driven gait optimization provides an automated alternative to analytical gait design. In this paper, we propose a novel approach to efficiently learn a wide range of locomotion tasks with walking robots. This approach formalizes locomotion as a contextual policy search task to collect data, and subsequently uses that data to learn multi-objective locomotion primitives that can be used for planning. As a proof-of-concept we consider a simulated hexapod modeled after a recently developed microrobot, and we thoroughly evaluate the performance of this microrobot on different tasks and gaits. Our results validate the proposed controller and learning scheme on single and multi-objective locomotion tasks. Moreover, the experimental simulations show that without any prior knowledge about the robot used (e.g., dynamics model), our approach is capable of learning locomotion primitives within 250 trials and subsequently using them to successfully navigate through a maze.

##### Abstract (translated by Google)
机器人运动步态的设计可能是一个艰巨的过程，需要大量的专业知识和工程技术。对于没有准确物理模型的机器人，例如兼容或微型机器人，这一过程更具挑战性。数据驱动的步态优化提供了分析步态设计的自动化选择。在本文中，我们提出了一种新颖的方法来有效地学习与步行机器人广泛的运动任务。这种方法将运动形式化为收集数据的上下文策略搜索任务，并随后使用该数据来学习可用于规划的多目标运动基元。作为一个概念验证，我们考虑了一个模拟六足动物模仿最近开发的微型机器人，我们彻底评估这个微型机器人在不同任务和步态上的表现。我们的结果验证了提出的控制器和学习方案在单目标和多目标运动任务。此外，实验模拟表明，在没有任何关于所使用的机器人（例如，动力学模型）的任何先验知识的情况下，我们的方法能够在250次试验中学习运动基元，并随后使用它们成功地在迷宫中导航。

##### URL
[http://arxiv.org/abs/1803.00196](http://arxiv.org/abs/1803.00196)

##### PDF
[http://arxiv.org/pdf/1803.00196](http://arxiv.org/pdf/1803.00196)

