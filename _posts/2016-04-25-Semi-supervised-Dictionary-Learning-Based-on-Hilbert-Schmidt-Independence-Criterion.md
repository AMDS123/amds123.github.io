---
layout: post
title: "Semi-supervised Dictionary Learning Based on Hilbert-Schmidt Independence Criterion"
date: 2016-04-25 16:25:38
categories: arXiv_CV
tags: arXiv_CV Sparse Classification
author: Mehrdad J. Gangeh, Safaa M.A. Bedawi, Ali Ghodsi, Fakhri Karray
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, a novel semi-supervised dictionary learning and sparse representation (SS-DLSR) is proposed. The proposed method benefits from the supervisory information by learning the dictionary in a space where the dependency between the data and class labels is maximized. This maximization is performed using Hilbert-Schmidt independence criterion (HSIC). On the other hand, the global distribution of the underlying manifolds were learned from the unlabeled data by minimizing the distances between the unlabeled data and the corresponding nearest labeled data in the space of the dictionary learned. The proposed SS-DLSR algorithm has closed-form solutions for both the dictionary and sparse coefficients, and therefore does not have to learn the two iteratively and alternately as is common in the literature of the DLSR. This makes the solution for the proposed algorithm very fast. The experiments confirm the improvement in classification performance on benchmark datasets by including the information from both labeled and unlabeled data, particularly when there are many unlabeled data.

##### Abstract (translated by Google)
本文提出了一种新的半监督字典学习和稀疏表示（SS-DLSR）。所提出的方法受益于通过在数据和类别标签之间的依赖性被最大化的空间中学习字典的监督信息。这个最大化使用希尔伯特 - 施密特独立准则（HSIC）来执行。另一方面，通过最小化未标记数据与所学词典空间中相应的最近标记数据之间的距离，从未标记数据中学习基本流形的全局分布。所提出的SS-DLSR算法对于字典和稀疏系数都具有封闭形式的解，因此不必像DLSR文献中常见的那样迭代地和交替地学习。这使得所提出的算法的解决方案非常快速。这些实验证实了基准数据集的分类性能的提高，其中包括来自标记数据和未标记数据的信息，尤其是当有许多未标记数据时。

##### URL
[https://arxiv.org/abs/1604.07319](https://arxiv.org/abs/1604.07319)

##### PDF
[https://arxiv.org/pdf/1604.07319](https://arxiv.org/pdf/1604.07319)

