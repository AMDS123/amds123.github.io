---
layout: post
title: "Latent Intention Dialogue Models"
date: 2017-05-29 15:01:44
categories: arXiv_CL
tags: arXiv_CL Reinforcement_Learning Inference
author: Tsung-Hsien Wen, Yishu Miao, Phil Blunsom, Steve Young
mathjax: true
---

* content
{:toc}

##### Abstract
Developing a dialogue agent that is capable of making autonomous decisions and communicating by natural language is one of the long-term goals of machine learning research. Traditional approaches either rely on hand-crafting a small state-action set for applying reinforcement learning that is not scalable or constructing deterministic models for learning dialogue sentences that fail to capture natural conversational variability. In this paper, we propose a Latent Intention Dialogue Model (LIDM) that employs a discrete latent variable to learn underlying dialogue intentions in the framework of neural variational inference. In a goal-oriented dialogue scenario, these latent intentions can be interpreted as actions guiding the generation of machine responses, which can be further refined autonomously by reinforcement learning. The experimental evaluation of LIDM shows that the model out-performs published benchmarks for both corpus-based and human evaluation, demonstrating the effectiveness of discrete latent variable models for learning goal-oriented dialogues.

##### Abstract (translated by Google)
开发一个能够自主决策和自然语言沟通的对话代理是机器学习研究的长期目标之一。传统的方法要么依靠手工制定一个小的国家行动集来应用不可扩展的强化学习，要么构造确定性模型来学习不能捕捉自然对话变异性的对话句子。在本文中，我们提出了一个潜在意向对话模型（LIDM），它使用一个离散的潜变量在神经变分推理的框架下学习潜在的对话意图。在面向目标的对话场景中，这些潜在的意图可以被解释为指导机器响应产生的动作，这可以通过强化学习自主地进一步完善。 LIDM的实验评估表明，该模型表现出基于语料库和人类评估公布的基准，证明离散潜变量模型对学习目标导向对话的有效性。

##### URL
[https://arxiv.org/abs/1705.10229](https://arxiv.org/abs/1705.10229)

##### PDF
[https://arxiv.org/pdf/1705.10229](https://arxiv.org/pdf/1705.10229)

