---
layout: post
title: "Tagging like Humans: Diverse and Distinct Image Annotation"
date: 2018-03-31 03:22:50
categories: arXiv_CV
tags: arXiv_CV Adversarial GAN Quantitative
author: Baoyuan Wu, Weidong Chen, Peng Sun, Wei Liu, Bernard Ghanem, Siwei Lyu
mathjax: true
---

* content
{:toc}

##### Abstract
In this work we propose a new automatic image annotation model, dubbed {\bf diverse and distinct image annotation} (D2IA). The generative model D2IA is inspired by the ensemble of human annotations, which create semantically relevant, yet distinct and diverse tags. In D2IA, we generate a relevant and distinct tag subset, in which the tags are relevant to the image contents and semantically distinct to each other, using sequential sampling from a determinantal point process (DPP) model. Multiple such tag subsets that cover diverse semantic aspects or diverse semantic levels of the image contents are generated by randomly perturbing the DPP sampling process. We leverage a generative adversarial network (GAN) model to train D2IA. Extensive experiments including quantitative and qualitative comparisons, as well as human subject studies, on two benchmark datasets demonstrate that the proposed model can produce more diverse and distinct tags than the state-of-the-arts.

##### Abstract (translated by Google)
在这项工作中，我们提出了一种新的自动图像标注模型，称为{\ bf多样化和独特的图像标注}（D2IA）。生成模型D2IA受到人类注释集合的启发，这些集合创建了语义相关，但独特而多样的标签。在D2IA中，我们使用来自行列式点过程（DPP）模型的顺序抽样，生成相关且不同的标签子集，其中标签与图像内容相关并且在语义上彼此不同。通过随机扰动DPP采样过程来生成覆盖图像内容的不同语义方面或不同语义水平的多个这样的标签子集。我们利用生成对抗网络（GAN）模型来训练D2IA。包括定量和定性比较以及人体研究在内的两个基准数据集的广泛实验表明，所提出的模型可以产生比现有技术更多样化和不同的标签。

##### URL
[http://arxiv.org/abs/1804.00113](http://arxiv.org/abs/1804.00113)

##### PDF
[http://arxiv.org/pdf/1804.00113](http://arxiv.org/pdf/1804.00113)

