---
layout: post
title: "Deep Dual Pyramid Network for Barcode Segmentation using Barcode-30k Database"
date: 2018-07-31 15:59:11
categories: arXiv_CV
tags: arXiv_CV Segmentation Semantic_Segmentation Deep_Learning
author: Qijie Zhao, Feng Ni, Yang Song, Yongtao Wang, Zhi Tang
mathjax: true
---

* content
{:toc}

##### Abstract
Digital signs(such as barcode or QR code) are widely used in our daily life, and for many applications, we need to localize them on images. However, difficult cases such as targets with small scales, half-occlusion, shape deformation and large illumination changes cause challenges for conventional methods. In this paper, we address this problem by producing a large-scale dataset and adopting a deep learning based semantic segmentation approach. Specifically, a synthesizing method was proposed to generate well-annotated images containing barcode and QR code labels, which contributes to largely decrease the annotation time. Through the synthesis strategy, we introduce a dataset that contains 30000 images with Barcode and QR code - Barcode-30k. Moreover, we further propose a dual pyramid structure based segmentation network - BarcodeNet, which is mainly formed with two novel modules, Prior Pyramid Pooling Module(P3M) and Pyramid Refine Module(PRM). We validate the effectiveness of BarcodeNet on the proposed synthetic dataset, and it yields the result of mIoU accuracy 95.36\% on validation set. Additional segmentation results of real images have shown that accurate segmentation performance is achieved.

##### Abstract (translated by Google)
数字标牌（例如条形码或QR码）在我们的日常生活中被广泛使用，并且对于许多应用，我们需要将它们定位在图像上。然而，诸如具有小尺度，半遮挡，形状变形和大的照明变化的目标的困难情况对传统方法造成挑战。在本文中，我们通过生成大规模数据集并采用基于深度学习的语义分割方法来解决这个问题。具体地，提出了一种合成方法来生成包含条形码和QR码标签的注释良好的图像，这有助于大大减少注释时间。通过综合策略，我们引入了一个包含条形码和QR码的30000张图像的数据集 - 条形码-30k。此外，我们进一步提出了一种基于双金字塔结构的分割网络--BarcodeNet，它主要由两个新模块组成：先前金字塔池模块（P3M）和金字塔精化模块（PRM）。我们验证了BarcodeNet对所提出的合成数据集的有效性，并且它在验证集上产生了mIoU准确度95.36 \％的结果。实际图像的附加分割结果表明实现了准确的分割性能。

##### URL
[http://arxiv.org/abs/1807.11886](http://arxiv.org/abs/1807.11886)

##### PDF
[http://arxiv.org/pdf/1807.11886](http://arxiv.org/pdf/1807.11886)

