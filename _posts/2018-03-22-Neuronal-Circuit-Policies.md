---
layout: post
title: "Neuronal Circuit Policies"
date: 2018-03-22 19:23:32
categories: arXiv_AI
tags: arXiv_AI GAN Reinforcement_Learning
author: Mathias Lechner, Ramin M. Hasani, Radu Grosu
mathjax: true
---

* content
{:toc}

##### Abstract
We propose an effective way to create interpretable control agents, by re-purposing the function of a biological neural circuit model, to govern simulated and real world reinforcement learning (RL) test-beds. We model the tap-withdrawal (TW) neural circuit of the nematode, C. elegans, a circuit responsible for the worm's reflexive response to external mechanical touch stimulations, and learn its synaptic and neuronal parameters as a policy for controlling basic RL tasks. We also autonomously park a real rover robot on a pre-defined trajectory, by deploying such neuronal circuit policies learned in a simulated environment. For reconfiguration of the purpose of the TW neural circuit, we adopt a search-based RL algorithm. We show that our neuronal policies perform as good as deep neural network policies with the advantage of realizing interpretable dynamics at the cell level.

##### Abstract (translated by Google)
我们提出了一种有效的方法来创建可解释的控制代理，通过重新利用生物神经回路模型的功能来管理模拟和现实世界强化学习（RL）测试台。我们模拟了线虫（线虫）的抽头（TW）神经回路，线虫负责蠕虫对外部机械触觉刺激的反射响应，并且学习其突触和神经元参数作为控制基本RL任务的策略。我们还通过部署在模拟环境中学习到的神经电路策略，自动将真实漫游机器人停放在预定义的轨迹上。为了重新配置TW神经电路的目的，我们采用基于搜索的RL算法。我们表明，我们的神经元政策表现与深度神经网络策略一样好，具有在细胞水平实现可解释动态的优势。

##### URL
[https://arxiv.org/abs/1803.08554](https://arxiv.org/abs/1803.08554)

##### PDF
[https://arxiv.org/pdf/1803.08554](https://arxiv.org/pdf/1803.08554)

