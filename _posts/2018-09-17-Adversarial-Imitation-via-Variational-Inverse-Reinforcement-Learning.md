---
layout: post
title: "Adversarial Imitation via Variational Inverse Reinforcement Learning"
date: 2018-09-17 18:47:47
categories: arXiv_RO
tags: arXiv_RO Adversarial GAN Reinforcement_Learning Transfer_Learning
author: Ahmed H. Qureshi, Michael C. Yip
mathjax: true
---

* content
{:toc}

##### Abstract
We consider a problem of learning a reward and policy from expert examples under unknown dynamics in high-dimensional scenarios. Our proposed method builds on the framework of generative adversarial networks and exploits reward shaping to learn near-optimal rewards and policies. Potential-based reward shaping functions are known to guide the learning agent whereas in this paper we bring forward their benefits in learning near-optimal rewards. Our method simultaneously learns a potential-based reward shaping function through variational information maximization along with the reward and policy under the adversarial learning formulation. We evaluate our method on various high-dimensional complex control tasks. We also evaluate our learned rewards in transfer learning problems where training and testing environments are made to be different from each other in terms of dynamics or structure. Our experimentation shows that our proposed method not only learns near-optimal rewards and policies matching expert behavior, but also performs significantly better than state-of-the-art inverse reinforcement learning algorithms.

##### Abstract (translated by Google)
我们考虑了在高维场景中未知动态下的专家实例学习奖励和政策的问题。我们提出的方法建立在生成对抗网络的框架之上，并利用奖励塑造来学习近乎最佳的奖励和政策。众所周知，基于潜在的奖励塑造功能可以指导学习者，而在本文中，我们提出了学习近乎最佳奖励的好处。我们的方法通过变量信息最大化以及对抗性学习公式下的奖励和政策，同时学习基于潜在的奖励塑造功能。我们在各种高维复杂控制任务上评估我们的方法。我们还在转移学习问题中评估我们学到的奖励，其中训练和测试环境在动力学或结构方面彼此不同。我们的实验表明，我们提出的方法不仅可以学习近乎最优的奖励和政策匹配专家行为，而且比最先进的逆强化学习算法表现得更好。

##### URL
[http://arxiv.org/abs/1809.06404](http://arxiv.org/abs/1809.06404)

##### PDF
[http://arxiv.org/pdf/1809.06404](http://arxiv.org/pdf/1809.06404)

