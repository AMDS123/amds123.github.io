---
layout: post
title: "Am I Done? Predicting Action Progress in Videos"
date: 2017-11-15 19:11:15
categories: arXiv_CV
tags: arXiv_CV CNN RNN Prediction Detection
author: Federico Becattini, Tiberio Uricchio, Lorenzo Seidenari, Alberto Del Bimbo, Lamberto Ballan
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we introduce the problem of predicting action progress in videos. We argue that this is an extremely important task because, on the one hand, it can be valuable for a wide range of applications and, on the other hand, it facilitates better action detection results. To solve this problem we introduce a novel approach, named ProgressNet, capable of predicting when an action takes place in a video, where it is located within the frames, and how far it has progressed during its execution. Motivated by the recent success obtained from the interaction of Convolutional and Recurrent Neural Networks, our model is based on a combination of the Faster R-CNN framework, to make framewise predictions, and LSTM networks, to estimate action progress through time. After introducing two evaluation protocols for the task at hand, we demonstrate the capability of our model to effectively predict action progress on the UCF-101 and J-HMDB datasets. Additionally, we show that exploiting action progress it is also possible to improve spatio-temporal localization.

##### Abstract (translated by Google)
在本文中，我们介绍预测视频中行动进展的问题。我们认为这是一个非常重要的任务，因为它一方面对于广泛的应用可能是有价值的，另一方面也促进了更好的行为检测结果。为了解决这个问题，我们引入了一个名为ProgressNet的新方法，能够预测视频中的动作何时发生，帧中的位置以及执行过程中进展的程度。在最近由卷积和递归神经网络交互获得成功的推动下，我们的模型基于更快的R-CNN框架的组合，使框架预测和LSTM网络能够估计随时间推移的行动进展。在为手头的任务引入两个评估协议之后，我们证明了我们的模型有效预测UCF-101和J-HMDB数据集的行动进展的能力。另外，我们显示利用行为进展也有可能改善时空本地化。

##### URL
[https://arxiv.org/abs/1705.01781](https://arxiv.org/abs/1705.01781)

##### PDF
[https://arxiv.org/pdf/1705.01781](https://arxiv.org/pdf/1705.01781)

