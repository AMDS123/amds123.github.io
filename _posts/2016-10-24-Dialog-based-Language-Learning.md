---
layout: post
title: "Dialog-based Language Learning"
date: 2016-10-24 20:00:13
categories: arXiv_SD
tags: arXiv_SD
author: Jason Weston
mathjax: true
---

* content
{:toc}

##### Abstract
A long-term goal of machine learning research is to build an intelligent dialog agent. Most research in natural language understanding has focused on learning from fixed training sets of labeled data, with supervision either at the word level (tagging, parsing tasks) or sentence level (question answering, machine translation). This kind of supervision is not realistic of how humans learn, where language is both learned by, and used for, communication. In this work, we study dialog-based language learning, where supervision is given naturally and implicitly in the response of the dialog partner during the conversation. We study this setup in two domains: the bAbI dataset of (Weston et al., 2015) and large-scale question answering from (Dodge et al., 2015). We evaluate a set of baseline learning strategies on these tasks, and show that a novel model incorporating predictive lookahead is a promising approach for learning from a teacher's response. In particular, a surprising result is that it can learn to answer questions correctly without any reward-based supervision at all.

##### Abstract (translated by Google)
机器学习研究的长期目标是建立一个智能的对话代理。自然语言理解的大多数研究集中于从标记数据的固定训练集中学习，在单词级别（标记，解析任务）或句子级别（问题解答，机器翻译）进行监督。这种监督对于人类的学习方式是不现实的，语言既是通过交流学习的，也是通过交流的。在这项工作中，我们研究了基于对话的语言学习，在对话过程中对话伙伴的回应中自然地和隐含地给予了监督。我们在两个领域研究这个设置：（Weston et al。，2015）的bAbI数据集和（Dodge et al。，2015）的大规模问题回答。我们评估了一套关于这些任务的基线学习策略，并且表明一个结合预测性前瞻的新模型是从教师的反应中学习的一个有希望的方法。特别是，一个令人惊讶的结果是，它可以学习正确回答问题，而没有任何奖励监督。

##### URL
[https://arxiv.org/abs/1604.06045](https://arxiv.org/abs/1604.06045)

##### PDF
[https://arxiv.org/pdf/1604.06045](https://arxiv.org/pdf/1604.06045)

