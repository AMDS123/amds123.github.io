---
layout: post
title: "Dimensional emotion recognition using visual and textual cues"
date: 2018-05-03 16:42:20
categories: arXiv_AI
tags: arXiv_AI Knowledge Face Recognition
author: Pedro M. Ferreira, Diogo Pernes, Kelwin Fernandes, Ana Rebelo, Jaime S. Cardoso
mathjax: true
---

* content
{:toc}

##### Abstract
This paper addresses the problem of automatic emotion recognition in the scope of the One-Minute Gradual-Emotional Behavior challenge (OMG-Emotion challenge). The underlying objective of the challenge is the automatic estimation of emotion expressions in the two-dimensional emotion representation space (i.e., arousal and valence). The adopted methodology is a weighted ensemble of several models from both video and text modalities. For video-based recognition, two different types of visual cues (i.e., face and facial landmarks) were considered to feed a multi-input deep neural network. Regarding the text modality, a sequential model based on a simple recurrent architecture was implemented. In addition, we also introduce a model based on high-level features in order to embed domain knowledge in the learning process. Experimental results on the OMG-Emotion validation set demonstrate the effectiveness of the implemented ensemble model as it clearly outperforms the current baseline methods.

##### Abstract (translated by Google)
本文讨论了在一分钟渐进情绪行为挑战（OMG-Emotion挑战）范围内的自动情绪识别问题。挑战的根本目标是在二维情感表示空间（即，唤起和价）中的情绪表达的自动估计。采用的方法是来自视频和文本模式的几个模型的加权集合。对于基于视频的识别，两种不同类型的视觉提示（即人脸和面部标志）被视为提供多输入深度神经网络。关于文本模式，实现了基于简单循环体系结构的顺序模型。另外，为了将领域知识嵌入到学习过程中，我们还引入了基于高级特征的模型。 OMG-Emotion验证集的实验结果证明了实施的集成模型的有效性，因为它明显优于当前的基准方法。

##### URL
[http://arxiv.org/abs/1805.01416](http://arxiv.org/abs/1805.01416)

##### PDF
[http://arxiv.org/pdf/1805.01416](http://arxiv.org/pdf/1805.01416)

