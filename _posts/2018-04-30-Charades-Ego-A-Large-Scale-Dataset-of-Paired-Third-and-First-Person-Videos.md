---
layout: post
title: "Charades-Ego: A Large-Scale Dataset of Paired Third and First Person Videos"
date: 2018-04-30 16:57:00
categories: arXiv_CV
tags: arXiv_CV Video_Caption Caption Video_Classification Classification
author: Gunnar A. Sigurdsson, Abhinav Gupta, Cordelia Schmid, Ali Farhadi, Karteek Alahari
mathjax: true
---

* content
{:toc}

##### Abstract
In Actor and Observer we introduced a dataset linking the first and third-person video understanding domains, the Charades-Ego Dataset. In this paper we describe the egocentric aspect of the dataset and present annotations for Charades-Ego with 68,536 activity instances in 68.8 hours of first and third-person video, making it one of the largest and most diverse egocentric datasets available. Charades-Ego furthermore shares activity classes, scripts, and methodology with the Charades dataset, that consist of additional 82.3 hours of third-person video with 66,500 activity instances. Charades-Ego has temporal annotations and textual descriptions, making it suitable for egocentric video classification, localization, captioning, and new tasks utilizing the cross-modal nature of the data.

##### Abstract (translated by Google)
在Actor和Observer中，我们引入了一个链接第一人称和第三人称视频理解域的数据集，即Charades-Ego数据集。在本文中，我们描述了数据集的自我中心方面，并在68.8小时的第一和第三人称视频中为68,536个活动实例提供了Charades-Ego的注释，使其成为可用的最大和最多样化的自我中心数据集之一。 Charades-Ego还与Charades数据集共享活动类，脚本和方法，其中包括额外的82.3小时第三人称视频和66,500个活动实例。 Charades-Ego具有时间注释和文本描述，使其适用于以自我为中心的视频分类，本地化，字幕以及利用数据的跨模态特性的新任务。

##### URL
[https://arxiv.org/abs/1804.09626](https://arxiv.org/abs/1804.09626)

##### PDF
[https://arxiv.org/pdf/1804.09626](https://arxiv.org/pdf/1804.09626)

