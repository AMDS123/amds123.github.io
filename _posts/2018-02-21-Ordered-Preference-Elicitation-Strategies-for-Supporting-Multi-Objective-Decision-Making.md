---
layout: post
title: "Ordered Preference Elicitation Strategies for Supporting Multi-Objective Decision Making"
date: 2018-02-21 15:05:15
categories: arXiv_AI
tags: arXiv_AI Attention
author: Luisa M Zintgraf, Diederik M Roijers, Sjoerd Linders, Catholijn M Jonker, Ann Now&#xe9;
mathjax: true
---

* content
{:toc}

##### Abstract
In multi-objective decision planning and learning, much attention is paid to producing optimal solution sets that contain an optimal policy for every possible user preference profile. We argue that the step that follows, i.e, determining which policy to execute by maximising the user's intrinsic utility function over this (possibly infinite) set, is under-studied. This paper aims to fill this gap. We build on previous work on Gaussian processes and pairwise comparisons for preference modelling, extend it to the multi-objective decision support scenario, and propose new ordered preference elicitation strategies based on ranking and clustering. Our main contribution is an in-depth evaluation of these strategies using computer and human-based experiments. We show that our proposed elicitation strategies outperform the currently used pairwise methods, and found that users prefer ranking most. Our experiments further show that utilising monotonicity information in GPs by using a linear prior mean at the start and virtual comparisons to the nadir and ideal points, increases performance. We demonstrate our decision support framework in a real-world study on traffic regulation, conducted with the city of Amsterdam.

##### Abstract (translated by Google)
在多目标决策规划和学习中，非常重视生成包含针对每个可能的用户偏好简档的最优策略的最优解决方案集。我们认为，接下来的步骤，即确定通过最大化用户的内部效用函数来执行哪个策略（可能是无限的），这个问题正在研究中。本文旨在填补这一空白。我们基于以前关于偏好建模的高斯过程和配对比较，将其扩展到多目标决策支持场景，并基于排序和聚类提出新的有序偏好启发策略。我们的主要贡献是使用计算机和基于人的实验对这些策略进行深入评估。我们表明，我们提出的启发策略胜过了目前使用的成对方法，并发现用户更喜欢排名最高的。我们的实验进一步表明，通过使用开始时的线性先验均值和虚拟比较最低点和理想点，利用GP中的单调性信息提高了性能。我们在与阿姆斯特丹市进行的交通管制实际研究中展示了我们的决策支持框架。

##### URL
[http://arxiv.org/abs/1802.07606](http://arxiv.org/abs/1802.07606)

##### PDF
[http://arxiv.org/pdf/1802.07606](http://arxiv.org/pdf/1802.07606)

