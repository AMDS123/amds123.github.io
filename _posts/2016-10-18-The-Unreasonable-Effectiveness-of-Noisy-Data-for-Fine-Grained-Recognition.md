---
layout: post
title: "The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition"
date: 2016-10-18 18:35:31
categories: arXiv_CV
tags: arXiv_CV Quantitative Recognition
author: Jonathan Krause, Benjamin Sapp, Andrew Howard, Howard Zhou, Alexander Toshev, Tom Duerig, James Philbin, Li Fei-Fei
mathjax: true
---

* content
{:toc}

##### Abstract
Current approaches for fine-grained recognition do the following: First, recruit experts to annotate a dataset of images, optionally also collecting more structured data in the form of part annotations and bounding boxes. Second, train a model utilizing this data. Toward the goal of solving fine-grained recognition, we introduce an alternative approach, leveraging free, noisy data from the web and simple, generic methods of recognition. This approach has benefits in both performance and scalability. We demonstrate its efficacy on four fine-grained datasets, greatly exceeding existing state of the art without the manual collection of even a single label, and furthermore show first results at scaling to more than 10,000 fine-grained categories. Quantitatively, we achieve top-1 accuracies of 92.3% on CUB-200-2011, 85.4% on Birdsnap, 93.4% on FGVC-Aircraft, and 80.8% on Stanford Dogs without using their annotated training sets. We compare our approach to an active learning approach for expanding fine-grained datasets.

##### Abstract (translated by Google)
目前的细粒度识别方法主要有以下几种：首先，征集专家对图像数据集进行注释，还可以采用零件注释和边界框的形式收集更多的结构化数据。其次，利用这个数据来训练一个模型。为了解决细粒度识别的目标，我们引入了另一种方法，利用网络中的免费，噪音数据以及简单，通用的识别方法。这种方法在性能和可伸缩性方面都有好处。我们在四个细粒度的数据集上展示了它的功效，大大超越了现有技术水平，甚至没有人工收集甚至一个标签，而且在缩放到超过10,000个细粒度类别时也显示了第一个结果。在数量上，我们在CUB-200-2011上获得了92.3％的最高精度，在Birdsnap上达到85.4％，在FGVC飞机上达到了93.4％，而在没有使用他们注释的训练集的情况下，达到了斯坦福犬的80.8％。我们将我们的方法与扩展细粒度数据集的主动学习方法进行了比较。

##### URL
[https://arxiv.org/abs/1511.06789](https://arxiv.org/abs/1511.06789)

##### PDF
[https://arxiv.org/pdf/1511.06789](https://arxiv.org/pdf/1511.06789)

