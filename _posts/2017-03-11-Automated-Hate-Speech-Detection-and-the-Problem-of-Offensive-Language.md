---
layout: post
title: "Automated Hate Speech Detection and the Problem of Offensive Language"
date: 2017-03-11 18:20:13
categories: arXiv_SD
tags: arXiv_SD Prediction Detection
author: Thomas Davidson, Dana Warmsley, Michael Macy, Ingmar Weber
mathjax: true
---

* content
{:toc}

##### Abstract
A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories. We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classifier to distinguish between these different categories. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive. Tweets without explicit hate keywords are also more difficult to classify.

##### Abstract (translated by Google)
在社交媒体上自动侦测仇恨言语的一个关键挑战是将仇恨言论与其他攻击性言语的分离。词汇检测方法往往精度较低，因为他们将所有包含特定词汇的信息归类为仇恨言论，而以前的工作使用监督学习方法无法区分这两个类别。我们使用仇恨言论词汇来收集包含仇恨言论关键词的推文。我们使用众包，将这些推文的样本分为三类：包含仇恨言论，只有冒犯性语言，以及不包含言语的人。我们训练多类分类器来区分这些不同的类别。对预测和错误的仔细分析表明，当我们能够可靠地将仇恨言论与其他攻击性语言区分开来，并且这种区分更加困难的时候。我们发现种族主义和同性恋的推特更可能被归类为仇恨言论，但是性别主义推特通常被归类为攻击性的。没有明确仇恨关键字的推文也更难分类。

##### URL
[https://arxiv.org/abs/1703.04009](https://arxiv.org/abs/1703.04009)

##### PDF
[https://arxiv.org/pdf/1703.04009](https://arxiv.org/pdf/1703.04009)

