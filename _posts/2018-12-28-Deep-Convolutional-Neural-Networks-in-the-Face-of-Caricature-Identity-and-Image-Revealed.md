---
layout: post
title: "Deep Convolutional Neural Networks in the Face of Caricature: Identity and Image Revealed"
date: 2018-12-28 06:16:23
categories: arXiv_CV
tags: arXiv_CV GAN Face CNN Recognition Face_Recognition
author: Matthew Q. Hill (1), Connor J. Parde (1), Carlos D. Castillo (2), Y. Ivette Colon (1), Rajeev Ranjan (2), Jun-Cheng Chen (2), Volker Blanz (3), Alice J. O&#x27;Toole (1) ((1) The University of Texas at Dallas, (2) University of Maryland, (3) University of Siegen)
mathjax: true
---

* content
{:toc}

##### Abstract
Real-world face recognition requires an ability to perceive the unique features of an individual face across multiple, variable images. The primate visual system solves the problem of image invariance using cascades of neurons that convert images of faces into categorical representations of facial identity. Deep convolutional neural networks (DCNNs) also create generalizable face representations, but with cascades of simulated neurons. DCNN representations can be examined in a multidimensional "face space", with identities and image parameters quantified via their projections onto the axes that define the space. We examined the organization of viewpoint, illumination, gender, and identity in this space. We show that the network creates a highly organized, hierarchically nested, face similarity structure in which information about face identity and imaging characteristics coexist. Natural image variation is accommodated in this hierarchy, with face identity nested under gender, illumination nested under identity, and viewpoint nested under illumination. To examine identity, we caricatured faces and found that network identification accuracy increased with caricature level, and--mimicking human perception--a caricatured distortion of a face "resembled" its veridical counterpart. Caricatures improved performance by moving the identity away from other identities in the face space and minimizing the effects of illumination and viewpoint. Deep networks produce face representations that solve long-standing computational problems in generalized face recognition. They also provide a unitary theoretical framework for reconciling decades of behavioral and neural results that emphasized either the image or the object/face in representations, without understanding how a neural code could seamlessly accommodate both.

##### Abstract (translated by Google)


##### URL
[http://arxiv.org/abs/1812.10902](http://arxiv.org/abs/1812.10902)

##### PDF
[http://arxiv.org/pdf/1812.10902](http://arxiv.org/pdf/1812.10902)

