---
layout: post
title: "Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences"
date: 2015-12-17 17:57:42
categories: arXiv_CL
tags: arXiv_CL Salient RNN
author: Hongyuan Mei, Mohit Bansal, Matthew R. Walter
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a neural sequence-to-sequence model for direction following, a task that is essential to realizing effective autonomous agents. Our alignment-based encoder-decoder model with long short-term memory recurrent neural networks (LSTM-RNN) translates natural language instructions to action sequences based upon a representation of the observable world state. We introduce a multi-level aligner that empowers our model to focus on sentence "regions" salient to the current world state by using multiple abstractions of the input sentence. In contrast to existing methods, our model uses no specialized linguistic resources (e.g., parsers) or task-specific annotations (e.g., seed lexicons). It is therefore generalizable, yet still achieves the best results reported to-date on a benchmark single-sentence dataset and competitive results for the limited-training multi-sentence setting. We analyze our model through a series of ablations that elucidate the contributions of the primary components of our model.

##### Abstract (translated by Google)
我们提出了一个神经序列 - 序列模型来跟踪方向，这对于实现有效的自主代理是非常重要的。我们的基于对齐的编码器 - 解码器模型与长期短期记忆递归神经网络（LSTM-RNN）将自然语言指令翻译为基于可观察世界状态的表示的动作序列。我们引入了一个多层次的对齐方法，使我们的模型能够通过对输入句子的多个抽象来关注当前世界状态中显着的句子“区域”。与现有方法相反，我们的模型不使用专门的语言资源（例如解析器）或任务特定的注释（例如种子词典）。因此它是可以概括的，但是仍然达到迄今为止报告的基准单句数据集的最佳结果，以及有限训练多句子设置的竞争结果。我们通过一系列消融来分析我们的模型，这些消融阐明了我们模型的主要组成部分的贡献。

##### URL
[https://arxiv.org/abs/1506.04089](https://arxiv.org/abs/1506.04089)

##### PDF
[https://arxiv.org/pdf/1506.04089](https://arxiv.org/pdf/1506.04089)

