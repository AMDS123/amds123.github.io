---
layout: post
title: "Selecting Relevant Web Trained Concepts for Automated Event Retrieval"
date: 2015-09-25 19:27:54
categories: arXiv_CL
tags: arXiv_CL Salient Object_Detection Detection
author: Bharat Singh, Xintong Han, Zhe Wu, Vlad I. Morariu, Larry S. Davis
mathjax: true
---

* content
{:toc}

##### Abstract
Complex event retrieval is a challenging research problem, especially when no training videos are available. An alternative to collecting training videos is to train a large semantic concept bank a priori. Given a text description of an event, event retrieval is performed by selecting concepts linguistically related to the event description and fusing the concept responses on unseen videos. However, defining an exhaustive concept lexicon and pre-training it requires vast computational resources. Therefore, recent approaches automate concept discovery and training by leveraging large amounts of weakly annotated web data. Compact visually salient concepts are automatically obtained by the use of concept pairs or, more generally, n-grams. However, not all visually salient n-grams are necessarily useful for an event query--some combinations of concepts may be visually compact but irrelevant--and this drastically affects performance. We propose an event retrieval algorithm that constructs pairs of automatically discovered concepts and then prunes those concepts that are unlikely to be helpful for retrieval. Pruning depends both on the query and on the specific video instance being evaluated. Our approach also addresses calibration and domain adaptation issues that arise when applying concept detectors to unseen videos. We demonstrate large improvements over other vision based systems on the TRECVID MED 13 dataset.

##### Abstract (translated by Google)
复杂的事件检索是一个具有挑战性的研究问题，特别是当没有培训视频可用时收集培训视频的另一种方法是事先培训一个大型的语义概念库。给定一个事件的文本描述，事件检索是通过选择与事件描述语言相关的概念，并在未见的视频上融合概念响应来执行的。然而，定义一个详尽的概念词汇和预训练需要庞大的计算资源。因此，最近的方法通过利用大量弱注释的Web数据来自动化概念发现和培训。通过使用概念对或者更一般地，n-gram自动获得紧凑的视觉上突出的概念。然而，并不是所有视觉突出的n元对于事件查询都是有用的 - 一些概念组合可能在视觉上是紧凑但是不相关的，并且这大大地影响了性能。我们提出了一个事件检索算法，它构造了自动发现的概念对，然后修剪那些不太可能对检索有帮助的概念。修剪既取决于查询，也取决于正在评估的特定视频实例。我们的方法还解决了将概念检测器应用于看不见的视频时出现的校准和域适应问题。我们展示了TRECVID MED 13数据集上其他基于视觉的系统的巨大改进。

##### URL
[https://arxiv.org/abs/1509.07845](https://arxiv.org/abs/1509.07845)

##### PDF
[https://arxiv.org/pdf/1509.07845](https://arxiv.org/pdf/1509.07845)

