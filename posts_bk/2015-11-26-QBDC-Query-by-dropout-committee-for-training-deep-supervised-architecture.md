---
layout: post
title: "QBDC: Query by dropout committee for training deep supervised architecture"
date: 2015-11-26 14:19:01
categories: arXiv_CV
tags: arXiv_CV Adversarial CNN
author: Melanie Ducoffe, Frederic Precioso
mathjax: true
---

* content
{:toc}

##### Abstract
While the current trend is to increase the depth of neural networks to increase their performance, the size of their training database has to grow accordingly. We notice an emergence of tremendous databases, although providing labels to build a training set still remains a very expensive task. We tackle the problem of selecting the samples to be labelled in an online fashion. In this paper, we present an active learning strategy based on query by committee and dropout technique to train a Convolutional Neural Network (CNN). We derive a commmittee of partial CNNs resulting from batchwise dropout runs on the initial CNN. We evaluate our active learning strategy for CNN on MNIST benchmark, showing in particular that selecting less than 30 % from the annotated database is enough to get similar error rate as using the full training set on MNIST. We also studied the robustness of our method against adversarial examples.

##### Abstract (translated by Google)
目前的趋势是增加神经网络的深度来提高他们的表现，他们的训练数据库的大小也必须相应地增长。我们注意到大量数据库的出现，尽管提供标签来建立一个培训集仍然是一个非常昂贵的任务。我们解决了以在线方式选择标签的问题。在本文中，我们提出了一种基于委员会查询和退出技术的主动学习策略来训练卷积神经网络（CNN）。我们派生了一个部分CNN的委员，这个委员是在最初的CNN上运行的批处理失败。我们评估我们在MNIST基准测试中对CNN的主动学习策略，特别是从注释数据库中选择少于30％的数据就足以得到与在MNIST上使用完整训练集相似的错误率。我们还研究了我们的方法与敌对的例子的稳健性。

##### URL
[https://arxiv.org/abs/1511.06412](https://arxiv.org/abs/1511.06412)

##### PDF
[https://arxiv.org/pdf/1511.06412](https://arxiv.org/pdf/1511.06412)

