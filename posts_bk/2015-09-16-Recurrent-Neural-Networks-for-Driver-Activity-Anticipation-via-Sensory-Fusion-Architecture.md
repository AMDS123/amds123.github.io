---
layout: post
title: "Recurrent Neural Networks for Driver Activity Anticipation via Sensory-Fusion Architecture"
date: 2015-09-16 19:49:24
categories: arXiv_CV
tags: arXiv_CV RNN Deep_Learning Prediction
author: Ashesh Jain, Avi Singh, Hema S Koppula, Shane Soh, Ashutosh Saxena
mathjax: true
---

* content
{:toc}

##### Abstract
Anticipating the future actions of a human is a widely studied problem in robotics that requires spatio-temporal reasoning. In this work we propose a deep learning approach for anticipation in sensory-rich robotics applications. We introduce a sensory-fusion architecture which jointly learns to anticipate and fuse information from multiple sensory streams. Our architecture consists of Recurrent Neural Networks (RNNs) that use Long Short-Term Memory (LSTM) units to capture long temporal dependencies. We train our architecture in a sequence-to-sequence prediction manner, and it explicitly learns to predict the future given only a partial temporal context. We further introduce a novel loss layer for anticipation which prevents over-fitting and encourages early anticipation. We use our architecture to anticipate driving maneuvers several seconds before they happen on a natural driving data set of 1180 miles. The context for maneuver anticipation comes from multiple sensors installed on the vehicle. Our approach shows significant improvement over the state-of-the-art in maneuver anticipation by increasing the precision from 77.4% to 90.5% and recall from 71.2% to 87.4%.

##### Abstract (translated by Google)
预测人类未来的行为是机器人中广泛研究的问题，需要时空推理。在这项工作中，我们提出了一个深入的学习方法来预测感官丰富的机器人应用。我们引入一个感官融合的体系结构，共同学习预测和融合来自多个感官流的信息。我们的架构由递归神经网络（RNN）组成，它使用长时间短期记忆（LSTM）单元来捕获长时间依赖性。我们按照从序列到序列的预测方式来训练我们的架构，并且它只是在部分时间背景下明确地学习预测未来。我们进一步介绍一个新的预测损失层，防止过度拟合，鼓励早期预期。我们使用我们的架构来预测几秒钟的驾驶动作，然后才会发生在1180英里的自然驾驶数据集上。机动预测的上下文来自安装在车辆上的多个传感器。我们的方法显示，在精确度从77.4％提高到90.5％，召回率从71.2％提高到87.4％的情况下，机动预测的技术水平显着提高。

##### URL
[https://arxiv.org/abs/1509.05016](https://arxiv.org/abs/1509.05016)

##### PDF
[https://arxiv.org/pdf/1509.05016](https://arxiv.org/pdf/1509.05016)

