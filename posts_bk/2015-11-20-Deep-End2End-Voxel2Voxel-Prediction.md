---
layout: post
title: "Deep End2End Voxel2Voxel Prediction"
date: 2015-11-20 16:42:37
categories: arXiv_CV
tags: arXiv_CV Segmentation CNN Semantic_Segmentation Video_Classification Classification Deep_Learning Prediction Detection
author: Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, Manohar Paluri
mathjax: true
---

* content
{:toc}

##### Abstract
Over the last few years deep learning methods have emerged as one of the most prominent approaches for video analysis. However, so far their most successful applications have been in the area of video classification and detection, i.e., problems involving the prediction of a single class label or a handful of output variables per video. Furthermore, while deep networks are commonly recognized as the best models to use in these domains, there is a widespread perception that in order to yield successful results they often require time-consuming architecture search, manual tweaking of parameters and computationally intensive pre-processing or post-processing methods. In this paper we challenge these views by presenting a deep 3D convolutional architecture trained end to end to perform voxel-level prediction, i.e., to output a variable at every voxel of the video. Most importantly, we show that the same exact architecture can be used to achieve competitive results on three widely different voxel-prediction tasks: video semantic segmentation, optical flow estimation, and video coloring. The three networks learned on these problems are trained from raw video without any form of preprocessing and their outputs do not require post-processing to achieve outstanding performance. Thus, they offer an efficient alternative to traditional and much more computationally expensive methods in these video domains.

##### Abstract (translated by Google)
在过去的几年里，深度学习方法已经成为视频分析最重要的方法之一。然而，迄今为止，他们最成功的应用是视频分类和检测领域，即涉及预测每个视频的单个类别标签或少量输出变量的问题。此外，虽然深度网络通常被认为是在这些领域中使用的最佳模型，但人们普遍认为，为了获得成功的结果，他们通常需要耗时的架构搜索，手动调整参数和计算密集的预处理，或者后处理方法。在本文中，我们通过呈现深度的3D卷积体系结构来对这些视图提出挑战，端对端地执行体素级预测，即在视频的每个体素处输出变量。最重要的是，我们表明，可以使用相同的精确架构来获得三个不同的体素预测任务的竞争结果：视频语义分割，光流估计和视频着色。从这些问题中学习到的三个网络是从原始视频进行训练的，没有任何形式的预处理，并且他们的输出不需要后处理来获得出色的性能。因此，它们为这些视频领域中的传统和更昂贵的计算方法提供了有效的替代方案。

##### URL
[https://arxiv.org/abs/1511.06681](https://arxiv.org/abs/1511.06681)

##### PDF
[https://arxiv.org/pdf/1511.06681](https://arxiv.org/pdf/1511.06681)

