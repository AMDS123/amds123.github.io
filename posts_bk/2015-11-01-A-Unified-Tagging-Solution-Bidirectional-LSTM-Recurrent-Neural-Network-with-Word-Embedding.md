---
layout: post
title: "A Unified Tagging Solution: Bidirectional LSTM Recurrent Neural Network with Word Embedding"
date: 2015-11-01 07:59:48
categories: arXiv_CL
tags: arXiv_CL Knowledge Embedding RNN Recognition
author: Peilu Wang, Yao Qian, Frank K. Soong, Lei He, Hai Zhao
mathjax: true
---

* content
{:toc}

##### Abstract
Bidirectional Long Short-Term Memory Recurrent Neural Network (BLSTM-RNN) has been shown to be very effective for modeling and predicting sequential data, e.g. speech utterances or handwritten documents. In this study, we propose to use BLSTM-RNN for a unified tagging solution that can be applied to various tagging tasks including part-of-speech tagging, chunking and named entity recognition. Instead of exploiting specific features carefully optimized for each task, our solution only uses one set of task-independent features and internal representations learnt from unlabeled text for all tasks.Requiring no task specific knowledge or sophisticated feature engineering, our approach gets nearly state-of-the-art performance in all these three tagging tasks.

##### Abstract (translated by Google)
双向长期短期记忆递归神经网络（BLSTM-RNN）已被证明对建模和预测顺序数据非常有效，例如，演讲话语或手写文件。在这项研究中，我们建议使用BLSTM-RNN统一标签解决方案，可以应用于各种标签任务，包括词性标注，分块和命名实体识别。我们的解决方案并没有利用为每个任务仔细优化的特定功能，而是仅使用一组与任务无关的特征和从未标记的文本学习到的所有任务的内部表示。不需要任何特定的任务知识或复杂的特征工程，我们的方法几乎达到在所有这三个标签任务中的最先进的表现。

##### URL
[https://arxiv.org/abs/1511.00215](https://arxiv.org/abs/1511.00215)

##### PDF
[https://arxiv.org/pdf/1511.00215](https://arxiv.org/pdf/1511.00215)

