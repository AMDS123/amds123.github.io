---
layout: post
title: "Learning Articulated Motions From Visual Demonstration"
date: 2015-02-05 17:59:07
categories: arXiv_CV
tags: arXiv_CV Sparse Segmentation Pose_Estimation Tracking
author: Sudeep Pillai, Matthew R. Walter, Seth Teller
mathjax: true
---

* content
{:toc}

##### Abstract
Many functional elements of human homes and workplaces consist of rigid components which are connected through one or more sliding or rotating linkages. Examples include doors and drawers of cabinets and appliances; laptops; and swivel office chairs. A robotic mobile manipulator would benefit from the ability to acquire kinematic models of such objects from observation. This paper describes a method by which a robot can acquire an object model by capturing depth imagery of the object as a human moves it through its range of motion. We envision that in future, a machine newly introduced to an environment could be shown by its human user the articulated objects particular to that environment, inferring from these "visual demonstrations" enough information to actuate each object independently of the user. Our method employs sparse (markerless) feature tracking, motion segmentation, component pose estimation, and articulation learning; it does not require prior object models. Using the method, a robot can observe an object being exercised, infer a kinematic model incorporating rigid, prismatic and revolute joints, then use the model to predict the object's motion from a novel vantage point. We evaluate the method's performance, and compare it to that of a previously published technique, for a variety of household objects.

##### Abstract (translated by Google)
人类住宅和工作场所的许多功能元件由刚性部件组成，通过一个或多个滑动或旋转连杆连接。例子包括橱柜和电器的门和抽屉;笔记本电脑;和旋转办公椅。机器人移动机械手将从观察中获取这些物体的运动学模型的能力中受益。本文描述了一种方法，通过该方法，机器人可以通过捕获物体的深度图像来获取物体模型，如同人类移动物体通过其运动范围。我们预想，将来，新引入到环境中的机器可以由其人类用户显示特定于该环境的明确的对象，从这些“视觉示范”推断出足够的信息来独立于用户致动每个对象。我们的方法采用稀疏（无标记）特征跟踪，运动分割，分量姿态估计和发音学习;它不需要以前的对象模型。使用该方法，机器人可以观察正在运动的对象，推导出包含刚性，棱柱形和旋转关节的运动学模型，然后使用该模型从新的有利位置预测对象的运动。我们评估方法的性能，并将其与以前发表的技术进行比较，针对各种家庭用品。

##### URL
[https://arxiv.org/abs/1502.01659](https://arxiv.org/abs/1502.01659)

##### PDF
[https://arxiv.org/pdf/1502.01659](https://arxiv.org/pdf/1502.01659)

