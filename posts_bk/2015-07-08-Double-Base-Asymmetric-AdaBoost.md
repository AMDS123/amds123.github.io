---
layout: post
title: "Double-Base Asymmetric AdaBoost"
date: 2015-07-08 13:44:34
categories: arXiv_CV
tags: arXiv_CV
author: Iago Landesa-Vázquez, José Luis Alba-Castro
mathjax: true
---

* content
{:toc}

##### Abstract
Based on the use of different exponential bases to define class-dependent error bounds, a new and highly efficient asymmetric boosting scheme, coined as AdaBoostDB (Double-Base), is proposed. Supported by a fully theoretical derivation procedure, unlike most of the other approaches in the literature, our algorithm preserves all the formal guarantees and properties of original (cost-insensitive) AdaBoost, similarly to the state-of-the-art Cost-Sensitive AdaBoost algorithm. However, the key advantage of AdaBoostDB is that our novel derivation scheme enables an extremely efficient conditional search procedure, dramatically improving and simplifying the training phase of the algorithm. Experiments, both over synthetic and real datasets, reveal that AdaBoostDB is able to save over 99% training time with regard to Cost-Sensitive AdaBoost, providing the same cost-sensitive results. This computational advantage of AdaBoostDB can make a difference in problems managing huge pools of weak classifiers in which boosting techniques are commonly used.

##### Abstract (translated by Google)
基于不同的指数基来定义基于类的误差界，提出了一种新的高效的非对称增强方案AdaBoostDB（Double-Base）。在完全理论推导过程的支持下，与文献中的大多数其他方法不同，我们的算法保留了原始（成本不敏感）AdaBoost的所有正式保证和性质，类似于最先进的Cost-Sensitive AdaBoost算法。然而，AdaBoostDB的关键优势在于，我们的新颖推导方案能够实现极其有效的条件搜索过程，显着改善和简化了算法的训练阶段。通过合成和真实数据集的实验表明，AdaBoostDB能够节省99％以上的成本敏感AdaBoost培训时间，提供相同的成本敏感结果。 AdaBoostDB的这种计算优势可以在管理大量弱分类器的问题上产生影响，在这些分类器中常常使用增强技术。

##### URL
[https://arxiv.org/abs/1507.02154](https://arxiv.org/abs/1507.02154)

##### PDF
[https://arxiv.org/pdf/1507.02154](https://arxiv.org/pdf/1507.02154)

