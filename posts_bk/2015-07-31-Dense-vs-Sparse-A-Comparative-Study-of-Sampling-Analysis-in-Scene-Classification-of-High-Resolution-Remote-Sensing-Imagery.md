---
layout: post
title: "Dense v.s. Sparse: A Comparative Study of Sampling Analysis in Scene Classification of High-Resolution Remote Sensing Imagery"
date: 2015-07-31 07:02:30
categories: arXiv_CV
tags: arXiv_CV Salient Sparse Classification Deep_Learning
author: Jingwen Hu, Gui-Song Xia, Fan Hu, Liangpei Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
Scene classification is a key problem in the interpretation of high-resolution remote sensing imagery. Many state-of-the-art methods, e.g. bag-of-visual-words model and its variants, the topic models as well as deep learning-based approaches, share similar procedures: patch sampling, feature description/learning and classification. Patch sampling is the first and a key procedure which has a great influence on the results. In the literature, many different sampling strategies have been used, {e.g. dense sampling, random sampling, keypoint-based sampling and saliency-based sampling, etc. However, it is still not clear which sampling strategy is suitable for the scene classification of high-resolution remote sensing images. In this paper, we comparatively study the effects of different sampling strategies under the scenario of scene classification of high-resolution remote sensing images. We divide the existing sampling methods into two types: dense sampling and sparse sampling, the later of which includes random sampling, keypoint-based sampling and various saliency-based sampling proposed recently. In order to compare their performances, we rely on a standard bag-of-visual-words model to construct our testing scheme, owing to their simplicity, robustness and efficiency. The experimental results on two commonly used datasets show that dense sampling has the best performance among all the strategies but with high spatial and computational complexity, random sampling gives better or comparable results than other sparse sampling methods, like the sophisticated multi-scale key-point operators and the saliency-based methods which are intensively studied and commonly used recently.

##### Abstract (translated by Google)
场景分类是解析高分辨率遥感影像的关键问题。许多最先进的方法，例如包视觉词模型及其变体，主题模型以及基于深度学习的方法共享相似的程序：补丁采样，特征描述/学习和分类。贴片抽样是第一个也是一个对结果有很大影响的关键程序。在文献中，已经使用了许多不同的采样策略，密集采样，随机采样，基于关键点的采样和基于显着性的采样等。但是，哪种采样策略适合于高分辨率遥感图像的场景分类还不清楚。本文比较研究了高分辨率遥感影像场景分类场景下不同采样策略的效果。将现有的抽样方法分为密集采样和稀疏采样两种，后者包括随机采样，基于关键点的采样和最近提出的各种基于显着性的采样。为了比较它们的性能，我们依靠一个标准的视觉词语模型来构建我们的测试方案，因为它们简单，稳健和高效。对两个常用数据集的实验结果表明，密集采样在所有策略中性能最好，但空间和计算复杂度较高，随机采样比其他稀疏采样方法有更好的或可比的结果，如复杂的多尺度关键点运算符和基于显着性的方法进行了深入的研究和最近的普遍使用。

##### URL
[https://arxiv.org/abs/1502.01097](https://arxiv.org/abs/1502.01097)

##### PDF
[https://arxiv.org/e-print/1502.01097](https://arxiv.org/e-print/1502.01097)

