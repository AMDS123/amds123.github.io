---
layout: post
title: "Combining Neural Networks and Log-linear Models to Improve Relation Extraction"
date: 2015-11-18 20:17:39
categories: arXiv_CL
tags: arXiv_CL Relation_Extraction CNN RNN Relation
author: Thien Huu Nguyen, Ralph Grishman
mathjax: true
---

* content
{:toc}

##### Abstract
The last decade has witnessed the success of the traditional feature-based method on exploiting the discrete structures such as words or lexical patterns to extract relations from text. Recently, convolutional and recurrent neural networks has provided very effective mechanisms to capture the hidden structures within sentences via continuous representations, thereby significantly advancing the performance of relation extraction. The advantage of convolutional neural networks is their capacity to generalize the consecutive k-grams in the sentences while recurrent neural networks are effective to encode long ranges of sentence context. This paper proposes to combine the traditional feature-based method, the convolutional and recurrent neural networks to simultaneously benefit from their advantages. Our systematic evaluation of different network architectures and combination methods demonstrates the effectiveness of this approach and results in the state-of-the-art performance on the ACE 2005 and SemEval dataset.

##### Abstract (translated by Google)
近十年来，传统的基于特征的方法在利用词汇或词汇模式等离散结构从文本中提取关系方面取得了成功。最近，卷积和递归神经网络已经提供了非常有效的机制来通过连续表示来捕获句子中的隐藏结构，从而显着提高关系提取的性能。卷积神经网络的优点是它们能够推广句子中的连续k-gram，而递归神经网络有效地编码句子环境的长范围。本文提出结合传统的基于特征的方法，卷积和回归神经网络同时受益于其优点。我们对不同网络体系结构和组合方法的系统评估证明了这种方法的有效性，并且在ACE 2005和SemEval数据集上获得了最先进的性能。

##### URL
[https://arxiv.org/abs/1511.05926](https://arxiv.org/abs/1511.05926)

##### PDF
[https://arxiv.org/pdf/1511.05926](https://arxiv.org/pdf/1511.05926)

