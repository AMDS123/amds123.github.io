---
layout: post
title: "Dependency Recurrent Neural Language Models for Sentence Completion"
date: 2015-07-05 11:10:24
categories: arXiv_CL
tags: arXiv_CL RNN Language_Model
author: Piotr Mirowski, Andreas Vlachos
mathjax: true
---

* content
{:toc}

##### Abstract
Recent work on language modelling has shifted focus from count-based models to neural models. In these works, the words in each sentence are always considered in a left-to-right order. In this paper we show how we can improve the performance of the recurrent neural network (RNN) language model by incorporating the syntactic dependencies of a sentence, which have the effect of bringing relevant contexts closer to the word being predicted. We evaluate our approach on the Microsoft Research Sentence Completion Challenge and show that the dependency RNN proposed improves over the RNN by about 10 points in accuracy. Furthermore, we achieve results comparable with the state-of-the-art models on this task.

##### Abstract (translated by Google)
最近的语言建模工作已经从计数模型转向神经模型。在这些作品中，每个句子中的单词总是按照从左到右的顺序来考虑。在本文中，我们展示了如何通过结合句子的句法依赖性来提高递归神经网络（RNN）语言模型的性能，这会使相关语境更接近被预测的单词。我们在微软研究句子完成挑战中评估我们的方法，并且表明所提出的依赖性RNN在精确度方面比RNN提高了约10个点。此外，我们在这个任务上取得了与最先进的模型相媲美的结果。

##### URL
[https://arxiv.org/abs/1507.01193](https://arxiv.org/abs/1507.01193)

##### PDF
[https://arxiv.org/pdf/1507.01193](https://arxiv.org/pdf/1507.01193)

