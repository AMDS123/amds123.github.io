---
layout: post
title: "Learning visual groups from co-occurrences in space and time"
date: 2015-11-21 01:33:12
categories: arXiv_CV
tags: arXiv_CV Segmentation Classification
author: Phillip Isola, Daniel Zoran, Dilip Krishnan, Edward H. Adelson
mathjax: true
---

* content
{:toc}

##### Abstract
We propose a self-supervised framework that learns to group visual entities based on their rate of co-occurrence in space and time. To model statistical dependencies between the entities, we set up a simple binary classification problem in which the goal is to predict if two visual primitives occur in the same spatial or temporal context. We apply this framework to three domains: learning patch affinities from spatial adjacency in images, learning frame affinities from temporal adjacency in videos, and learning photo affinities from geospatial proximity in image collections. We demonstrate that in each case the learned affinities uncover meaningful semantic groupings. From patch affinities we generate object proposals that are competitive with state-of-the-art supervised methods. From frame affinities we generate movie scene segmentations that correlate well with DVD chapter structure. Finally, from geospatial affinities we learn groups that relate well to semantic place categories.

##### Abstract (translated by Google)
我们提出了一个自我监督的框架，学习根据它们在空间和时间上的同现率来对视觉实体进行分组。为了模拟实体之间的统计相关性，我们建立了一个简单的二元分类问题，其目标是预测两个视觉基元是否出现在相同的空间或时间上下文中。我们将这个框架应用于三个领域：从图像中的空间邻接学习贴片亲和力，从视频中的时间邻接中学习帧亲和度，以及从图像集合中的地理空间邻近度学习照片亲和度。我们证明，在每种情况下，学习的亲和力揭示有意义的语义分组。从补丁的亲和力，我们生成的对象建议，与最先进的监督方法竞争。根据帧的亲和力，我们生成与DVD章节结构良好关联的电影场景分段。最后，从地理空间的亲和力，我们学习与语义地点类别相关的组。

##### URL
[https://arxiv.org/abs/1511.06811](https://arxiv.org/abs/1511.06811)

##### PDF
[https://arxiv.org/pdf/1511.06811](https://arxiv.org/pdf/1511.06811)

