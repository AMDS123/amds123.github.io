---
layout: post
title: "EmoNets: Multimodal deep learning approaches for emotion recognition in video"
date: 2015-03-30 00:55:02
categories: arXiv_CV
tags: arXiv_CV Face CNN Deep_Learning Prediction Relation Recognition
author: Samira Ebrahimi Kahou, Xavier Bouthillier, Pascal Lamblin, Caglar Gulcehre, Vincent Michalski, Kishore Konda, Sébastien Jean, Pierre Froumenty, Yann Dauphin, Nicolas Boulanger-Lewandowski, Raul Chandias Ferrari, Mehdi Mirza, David Warde-Farley, Aaron Courville, Pascal Vincent, Roland Memisevic, Christopher Pal, Yoshua Bengio
mathjax: true
---

* content
{:toc}

##### Abstract
The task of the emotion recognition in the wild (EmotiW) Challenge is to assign one of seven emotions to short video clips extracted from Hollywood style movies. The videos depict acted-out emotions under realistic conditions with a large degree of variation in attributes such as pose and illumination, making it worthwhile to explore approaches which consider combinations of features from multiple modalities for label assignment. In this paper we present our approach to learning several specialist models using deep learning techniques, each focusing on one modality. Among these are a convolutional neural network, focusing on capturing visual information in detected faces, a deep belief net focusing on the representation of the audio stream, a K-Means based "bag-of-mouths" model, which extracts visual features around the mouth region and a relational autoencoder, which addresses spatio-temporal aspects of videos. We explore multiple methods for the combination of cues from these modalities into one common classifier. This achieves a considerably greater accuracy than predictions from our strongest single-modality classifier. Our method was the winning submission in the 2013 EmotiW challenge and achieved a test set accuracy of 47.67% on the 2014 dataset.

##### Abstract (translated by Google)
在野外（EmotiW）挑战中情绪识别的任务是将七种情绪中的一种分配给从好莱坞式电影中提取的短视频剪辑。这些视频描绘了在现实条件下表现出的情绪，在姿态和照度等属性上存在很大的变化，因此值得探索考虑多种形式的特征组合以用于标签分配的方法。在本文中，我们提出了使用深度学习技术来学习几种专业模型的方法，每种模式都专注于一种模式。其中包括一个卷积神经网络，侧重于捕获检测到的面孔中的视觉信息，一个专注于音频流表示的深层信仰网络，一个基于K-Means的“口袋”模型，嘴巴区域和一个关系自动编码器，它处理视频的时空方面。我们探索多种方法将来自这些模态的线索组合成一个常见的分类器。这比我们最强的单模分类器的预测具有更高的准确性。我们的方法是2013年EmotiW挑战赛中的获胜提交，并在2014年的数据集上达到了47.67％的测试集准确率。

##### URL
[https://arxiv.org/abs/1503.01800](https://arxiv.org/abs/1503.01800)

##### PDF
[https://arxiv.org/pdf/1503.01800](https://arxiv.org/pdf/1503.01800)

