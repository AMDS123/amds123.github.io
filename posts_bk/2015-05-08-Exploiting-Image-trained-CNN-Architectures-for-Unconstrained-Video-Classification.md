---
layout: post
title: "Exploiting Image-trained CNN Architectures for Unconstrained Video Classification"
date: 2015-05-08 01:54:08
categories: arXiv_CV
tags: arXiv_CV CNN Image_Classification Video_Classification Classification Detection
author: Shengxin Zha, Florian Luisier, Walter Andrews, Nitish Srivastava, Ruslan Salakhutdinov
mathjax: true
---

* content
{:toc}

##### Abstract
We conduct an in-depth exploration of different strategies for doing event detection in videos using convolutional neural networks (CNNs) trained for image classification. We study different ways of performing spatial and temporal pooling, feature normalization, choice of CNN layers as well as choice of classifiers. Making judicious choices along these dimensions led to a very significant increase in performance over more naive approaches that have been used till now. We evaluate our approach on the challenging TRECVID MED'14 dataset with two popular CNN architectures pretrained on ImageNet. On this MED'14 dataset, our methods, based entirely on image-trained CNN features, can outperform several state-of-the-art non-CNN models. Our proposed late fusion of CNN- and motion-based features can further increase the mean average precision (mAP) on MED'14 from 34.95% to 38.74%. The fusion approach achieves the state-of-the-art classification performance on the challenging UCF-101 dataset.

##### Abstract (translated by Google)
我们对使用卷积神经网络（CNN）进行图像分类训练的视频事件检测的不同策略进行了深入的探索。我们研究不同的空间和时间汇集方式，特征归一化，CNN层的选择以及分类器的选择。沿着这些维度作出明智的选择，导致与迄今为止使用的更为幼稚的方法相比，性能显着提高。我们在具有挑战性的TRECVID MED'14数据集上评估我们的方法，在ImageNet上使用两种流行的CNN架构。在这个MED'14数据集上，我们的方法完全基于图像训练的CNN特征，可以胜过几个最先进的非CNN模型。我们提出的基于CNN和运动特征的后期融合可以进一步提高MED'14的平均精度（mAP），从34.95％提高到38.74％。该融合方法在具有挑战性的UCF-101数据集上实现了最先进的分类性能。

##### URL
[https://arxiv.org/abs/1503.04144](https://arxiv.org/abs/1503.04144)

##### PDF
[https://arxiv.org/pdf/1503.04144](https://arxiv.org/pdf/1503.04144)

