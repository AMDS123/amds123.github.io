---
layout: post
title: "Unveiling the Dreams of Word Embeddings: Towards Language-Driven Image Generation"
date: 2015-11-23 16:36:48
categories: arXiv_CL
tags: arXiv_CL Embedding CNN Language_Model
author: Angeliki Lazaridou, Dat Tien Nguyen, Raffaella Bernardi, Marco Baroni
mathjax: true
---

* content
{:toc}

##### Abstract
We introduce language-driven image generation, the task of generating an image visualizing the semantic contents of a word embedding, e.g., given the word embedding of grasshopper, we generate a natural image of a grasshopper. We implement a simple method based on two mapping functions. The first takes as input a word embedding (as produced, e.g., by the word2vec toolkit) and maps it onto a high-level visual space (e.g., the space defined by one of the top layers of a Convolutional Neural Network). The second function maps this abstract visual representation to pixel space, in order to generate the target image. Several user studies suggest that the current system produces images that capture general visual properties of the concepts encoded in the word embedding, such as color or typical environment, and are sufficient to discriminate between general categories of objects.

##### Abstract (translated by Google)
我们引入了语言驱动的图像生成，生成一个图像可视化的单词嵌入的语义内容的任务，例如，给予单词嵌入的蚱蜢，我们生成一个蚱蜢的自然图像。我们实现了一个基于两个映射函数的简单方法。第一个输入单词嵌入（例如由word2vec工具包产生）并将其映射到高级视觉空间（例如，由卷积神经网络的顶层之一定义的空间）上。第二个函数将这个抽象视觉表示映射到像素空间，以便生成目标图像。几个用户研究表明，当前的系统产生的图像可以捕捉单词嵌入中编码的概念（如颜色或典型环境）的一般视觉属性，并足以区分一般类别的对象。

##### URL
[https://arxiv.org/abs/1506.03500](https://arxiv.org/abs/1506.03500)

##### PDF
[https://arxiv.org/pdf/1506.03500](https://arxiv.org/pdf/1506.03500)

