---
layout: post
title: "Multimodal Skip-gram Using Convolutional Pseudowords"
date: 2015-11-29 19:09:38
categories: arXiv_CL
tags: arXiv_CL Embedding CNN Prediction Recognition
author: Zachary Seymour, Yingming Li, Zhongfei Zhang
mathjax: true
---

* content
{:toc}

##### Abstract
This work studies the representational mapping across multimodal data such that given a piece of the raw data in one modality the corresponding semantic description in terms of the raw data in another modality is immediately obtained. Such a representational mapping can be found in a wide spectrum of real-world applications including image/video retrieval, object recognition, action/behavior recognition, and event understanding and prediction. To that end, we introduce a simplified training objective for learning multimodal embeddings using the skip-gram architecture by introducing convolutional "pseudowords:" embeddings composed of the additive combination of distributed word representations and image features from convolutional neural networks projected into the multimodal space. We present extensive results of the representational properties of these embeddings on various word similarity benchmarks to show the promise of this approach.

##### Abstract (translated by Google)
这项工作研究跨多模态数据的表示映射，给定一种模式下的原始数据，相应的语义描述在另一种模式的原始数据方面立即获得。这种代表性映射可以在包括图像/视频检索，对象识别，动作/行为识别以及事件理解和预测的广泛的现实应用中找到。为此，我们引入了一个简化的训练目标，即使用skip-gram体系结构，通过引入卷积“pseudowords：”分布式词表示的加性组合和来自卷积神经网络的图像特征投影到多模态空间中来实现多模式嵌入。我们在各种词语相似性基准上呈现这些嵌入的代表属性的广泛结果，以显示这种方法的承诺。

##### URL
[https://arxiv.org/abs/1511.04024](https://arxiv.org/abs/1511.04024)

##### PDF
[https://arxiv.org/pdf/1511.04024](https://arxiv.org/pdf/1511.04024)

