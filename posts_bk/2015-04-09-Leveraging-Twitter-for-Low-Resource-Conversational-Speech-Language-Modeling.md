---
layout: post
title: "Leveraging Twitter for Low-Resource Conversational Speech Language Modeling"
date: 2015-04-09 20:21:32
categories: arXiv_CL
tags: arXiv_CL Language_Model
author: Aaron Jaech, Mari Ostendorf
mathjax: true
---

* content
{:toc}

##### Abstract
In applications involving conversational speech, data sparsity is a limiting factor in building a better language model. We propose a simple, language-independent method to quickly harvest large amounts of data from Twitter to supplement a smaller training set that is more closely matched to the domain. The techniques lead to a significant reduction in perplexity on four low-resource languages even though the presence on Twitter of these languages is relatively small. We also find that the Twitter text is more useful for learning word classes than the in-domain text and that use of these word classes leads to further reductions in perplexity. Additionally, we introduce a method of using social and textual information to prioritize the download queue during the Twitter crawling. This maximizes the amount of useful data that can be collected, impacting both perplexity and vocabulary coverage.

##### Abstract (translated by Google)
在涉及对话语音的应用中，数据稀疏性是构建更好语言模型的限制因素。我们提出了一种简单的，与语言无关的方法，可以快速从Twitter收集大量数据，以补充与域更紧密匹配的更小的训练集。这些技术导致四种低资源语言的困惑显着减少，即使这些语言在Twitter上的存在相对较小。我们还发现Twitter文本对于学习单词类比在域内文本更有用，并且使用这些单词类可以进一步减少困惑。另外，我们介绍一种在Twitter抓取过程中使用社交和文本信息优先下载队列的方法。这可以最大限度地收集有用的数据，同时影响到困惑和词汇覆盖。

##### URL
[https://arxiv.org/abs/1504.02490](https://arxiv.org/abs/1504.02490)

##### PDF
[https://arxiv.org/pdf/1504.02490](https://arxiv.org/pdf/1504.02490)

