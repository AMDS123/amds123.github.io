---
layout: post
title: "SemanticPaint: A Framework for the Interactive Segmentation of 3D Scenes"
date: 2015-10-13 15:06:03
categories: arXiv_CV
tags: arXiv_CV Segmentation
author: Stuart Golodetz, Michael Sapienza, Julien P. C. Valentin, Vibhav Vineet, Ming-Ming Cheng, Anurag Arnab, Victor A. Prisacariu, Olaf Kähler, Carl Yuheng Ren, David W. Murray, Shahram Izadi, Philip H. S. Torr
mathjax: true
---

* content
{:toc}

##### Abstract
We present an open-source, real-time implementation of SemanticPaint, a system for geometric reconstruction, object-class segmentation and learning of 3D scenes. Using our system, a user can walk into a room wearing a depth camera and a virtual reality headset, and both densely reconstruct the 3D scene and interactively segment the environment into object classes such as 'chair', 'floor' and 'table'. The user interacts physically with the real-world scene, touching objects and using voice commands to assign them appropriate labels. These user-generated labels are leveraged by an online random forest-based machine learning algorithm, which is used to predict labels for previously unseen parts of the scene. The entire pipeline runs in real time, and the user stays 'in the loop' throughout the process, receiving immediate feedback about the progress of the labelling and interacting with the scene as necessary to refine the predicted segmentation.

##### Abstract (translated by Google)
我们提出了一个开源的，实时的SemanticPaint实现，一个用于几何重建，对象类分割和3D场景学习的系统。使用我们的系统，用户可以走进一个穿着深度相机和虚拟现实耳机的房间，并且都密集地重建3D场景，并将环境交互式地分割成诸如“椅子”，“地板”和“桌子”之类的对象类别。用户与真实世界的场景进行物理交互，触摸对象并使用语音命令为其分配适当的标签。这些用户生成的标签被基于在线随机森林的机器学习算法所利用，该算法被用于预测以前不可见的场景部分的标签。整个管道实时运行，用户在整个过程中始终处于“循环”状态，接收有关标签进度的即时反馈，并根据需要与场景进行交互，以改进预测的分割。

##### URL
[https://arxiv.org/abs/1510.03727](https://arxiv.org/abs/1510.03727)

##### PDF
[https://arxiv.org/pdf/1510.03727](https://arxiv.org/pdf/1510.03727)

