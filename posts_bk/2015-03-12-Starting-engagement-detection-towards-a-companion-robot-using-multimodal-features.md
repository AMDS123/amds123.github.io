---
layout: post
title: "Starting engagement detection towards a companion robot using multimodal features"
date: 2015-03-12 14:19:40
categories: arXiv_CV
tags: arXiv_CV Detection Recognition
author: Dominique Vaufreydaz (INRIA Grenoble Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble), Wafa Johal (LIG), Claudine Combe (INRIA Grenoble Rhône-Alpes / LIG Laboratoire d'Informatique de Grenoble)
mathjax: true
---

* content
{:toc}

##### Abstract
Recognition of intentions is a subconscious cognitive process vital to human communication. This skill enables anticipation and increases the quality of interactions between humans. Within the context of engagement, non-verbal signals are used to communicate the intention of starting the interaction with a partner. In this paper, we investigated methods to detect these signals in order to allow a robot to know when it is about to be addressed. Originality of our approach resides in taking inspiration from social and cognitive sciences to perform our perception task. We investigate meaningful features, i.e. human readable features, and elicit which of these are important for recognizing someone's intention of starting an interaction. Classically, spatial information like the human position and speed, the human-robot distance are used to detect the engagement. Our approach integrates multimodal features gathered using a companion robot equipped with a Kinect. The evaluation on our corpus collected in spontaneous conditions highlights its robustness and validates the use of such a technique in a real environment. Experimental validation shows that multimodal features set gives better precision and recall than using only spatial and speed features. We also demonstrate that 7 selected features are sufficient to provide a good starting engagement detection score. In our last investigation, we show that among our full 99 features set, the space reduction is not a solved task. This result opens new researches perspectives on multimodal engagement detection.

##### Abstract (translated by Google)
意图识别是对人类交流至关重要的潜意识认知过程。这个技能可以预测并提高人类之间的相互作用的质量。在参与的背景下，非语言信号被用来传达与伙伴开始互动的意图。在本文中，我们研究了检测这些信号的方法，以便让机器人知道何时要处理这些信号。我们的方法的原创性在于从社会和认知科学中获取灵感来执行我们的感知任务。我们调查有意义的特征，即人类可读的特征，并引出其中哪些对于识别某人开始交互的意图是重要的。传统上，人类的位置和速度，人类的机器人距离等空间信息被用来检测参与。我们的方法集成了使用配有Kinect的同伴机器人收集的多模态特征。我们在自发条件下收集的语料库的评估强调了它的鲁棒性，并验证了这种技术在真实环境中的使用。实验验证表明，多模式特征集比仅使用空间和速度特征提供了更好的精度和查全率。我们还展示了7个选定的功能足以提供一个良好的开始参与检测分数。在我们上次的调查中，我们发现在99个特征集中，空间的减少并不是一个解决的任务。这个结果为多模式参与检测开辟了新的研究视角。

##### URL
[https://arxiv.org/abs/1503.03732](https://arxiv.org/abs/1503.03732)

##### PDF
[https://arxiv.org/pdf/1503.03732](https://arxiv.org/pdf/1503.03732)

