---
layout: post
title: "Big Data Small Data, In Domain Out-of Domain, Known Word Unknown Word: The Impact of Word Representation on Sequence Labelling Tasks"
date: 2015-05-20 05:50:17
categories: arXiv_CL
tags: arXiv_CL Embedding
author: Lizhen Qu, Gabriela Ferraro, Liyuan Zhou, Weiwei Hou, Nathan Schneider, Timothy Baldwin
mathjax: true
---

* content
{:toc}

##### Abstract
Word embeddings -- distributed word representations that can be learned from unlabelled data -- have been shown to have high utility in many natural language processing applications. In this paper, we perform an extrinsic evaluation of five popular word embedding methods in the context of four sequence labelling tasks: POS-tagging, syntactic chunking, NER and MWE identification. A particular focus of the paper is analysing the effects of task-based updating of word representations. We show that when using word embeddings as features, as few as several hundred training instances are sufficient to achieve competitive results, and that word embeddings lead to improvements over OOV words and out of domain. Perhaps more surprisingly, our results indicate there is little difference between the different word embedding methods, and that simple Brown clusters are often competitive with word embeddings across all tasks we consider.

##### Abstract (translated by Google)
字嵌入 - 可以从未标记的数据中学习的分布式字表示 - 已经显示在许多自然语言处理应用中具有高度的实用性。在本文中，我们在四个序列标注任务的背景下对五种流行的词嵌入方法进行了外部评估：词性标注，句法分块，NER和MWE识别。本文的一个重点是分析基于任务的词表示更新的效果。我们表明，当使用词嵌入作为特征时，少至几百个训练实例足以实现竞争结果，并且该词嵌入导致对OOV词和超出领域的改进。也许更令人惊讶的是，我们的结果表明，不同的单词嵌入方法之间几乎没有什么区别，而且简单的布朗类常常与我们考虑的所有任务中的单词嵌入竞争。

##### URL
[https://arxiv.org/abs/1504.05319](https://arxiv.org/abs/1504.05319)

##### PDF
[https://arxiv.org/pdf/1504.05319](https://arxiv.org/pdf/1504.05319)

