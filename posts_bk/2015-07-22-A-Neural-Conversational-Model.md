---
layout: post
title: "A Neural Conversational Model"
date: 2015-07-22 03:29:47
categories: arXiv_CL
tags: arXiv_CL Knowledge
author: Oriol Vinyals, Quoc Le
mathjax: true
---

* content
{:toc}

##### Abstract
Conversational modeling is an important task in natural language understanding and machine intelligence. Although previous approaches exist, they are often restricted to specific domains (e.g., booking an airline ticket) and require hand-crafted rules. In this paper, we present a simple approach for this task which uses the recently proposed sequence to sequence framework. Our model converses by predicting the next sentence given the previous sentence or sentences in a conversation. The strength of our model is that it can be trained end-to-end and thus requires much fewer hand-crafted rules. We find that this straightforward model can generate simple conversations given a large conversational training dataset. Our preliminary results suggest that, despite optimizing the wrong objective function, the model is able to converse well. It is able extract knowledge from both a domain specific dataset, and from a large, noisy, and general domain dataset of movie subtitles. On a domain-specific IT helpdesk dataset, the model can find a solution to a technical problem via conversations. On a noisy open-domain movie transcript dataset, the model can perform simple forms of common sense reasoning. As expected, we also find that the lack of consistency is a common failure mode of our model.

##### Abstract (translated by Google)
会话建模是自然语言理解和机器智能的重要任务。虽然以前的方法存在，但是它们通常仅限于特定的领域（例如，预订机票）并且需要手工制定的规则。在本文中，我们提出了一个简单的方法来完成这个任务，它使用了最近提出的序列来排序框架。我们的模型通过预测对话中前一个句子或句子的下一个句子进行交谈。我们的模型的优势在于它可以进行端到端的培训，因此需要更少的手工制定的规则。我们发现，这个简单的模型可以产生一个简单的谈话给一个大的会话训练数据集。我们的初步结果表明，尽管优化了错误的目标函数，模型能够很好地交流。它能够从领域特定数据集以及电影字幕的大型，嘈杂和一般的域数据集中提取知识。在特定领域的IT帮助台数据集上，该模型可以通过对话找到技术问题的解决方案。在嘈杂的开放域电影抄本数据集上，该模型可以执行简单形式的常识推理。正如预期的那样，我们也发现缺乏一致性是我们模型的常见失败模式。

##### URL
[https://arxiv.org/abs/1506.05869](https://arxiv.org/abs/1506.05869)

##### PDF
[https://arxiv.org/pdf/1506.05869](https://arxiv.org/pdf/1506.05869)

