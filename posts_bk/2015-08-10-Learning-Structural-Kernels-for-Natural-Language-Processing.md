---
layout: post
title: "Learning Structural Kernels for Natural Language Processing"
date: 2015-08-10 05:57:14
categories: arXiv_CL
tags: arXiv_CL Optimization Prediction
author: Daniel Beck, Trevor Cohn, Christian Hardmeier, Lucia Specia
mathjax: true
---

* content
{:toc}

##### Abstract
Structural kernels are a flexible learning paradigm that has been widely used in Natural Language Processing. However, the problem of model selection in kernel-based methods is usually overlooked. Previous approaches mostly rely on setting default values for kernel hyperparameters or using grid search, which is slow and coarse-grained. In contrast, Bayesian methods allow efficient model selection by maximizing the evidence on the training data through gradient-based methods. In this paper we show how to perform this in the context of structural kernels by using Gaussian Processes. Experimental results on tree kernels show that this procedure results in better prediction performance compared to hyperparameter optimization via grid search. The framework proposed in this paper can be adapted to other structures besides trees, e.g., strings and graphs, thereby extending the utility of kernel-based methods.

##### Abstract (translated by Google)
结构内核是一种灵活的学习范式，在自然语言处理中得到了广泛的应用。然而，基于内核的方法中的模型选择问题通常被忽视。以前的方法主要依靠为内核超参数设置默认值或使用网格搜索，这是缓慢和粗粒度的。相反，贝叶斯方法允许通过基于梯度的方法最大化训练数据的证据来进行有效的模型选择。在本文中，我们将演示如何使用高斯过程在结构内核中执行此操作。在树核上的实验结果表明，与通过网格搜索的超参数优化相比，该过程导致更好的预测性能。本文提出的框架可以适用于除树之外的其他结构，例如字符串和图形，从而扩展了基于内核的方法的实用性。

##### URL
[https://arxiv.org/abs/1508.02131](https://arxiv.org/abs/1508.02131)

##### PDF
[https://arxiv.org/pdf/1508.02131](https://arxiv.org/pdf/1508.02131)

