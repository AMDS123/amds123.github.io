---
layout: post
title: "Towards Automatic Image Editing: Learning to See another You"
date: 2015-11-26 16:33:10
categories: arXiv_CV
tags: arXiv_CV Face CNN Quantitative Relation
author: Amir Ghodrati, Xu Jia, Marco Pedersoli, Tinne Tuytelaars
mathjax: true
---

* content
{:toc}

##### Abstract
Learning the distribution of images in order to generate new samples is a challenging task due to the high dimensionality of the data and the highly non-linear relations that are involved. Nevertheless, some promising results have been reported in the literature recently,building on deep network architectures. In this work, we zoom in on a specific type of image generation: given an image and knowing the category of objects it belongs to (e.g. faces), our goal is to generate a similar and plausible image, but with some altered attributes. This is particularly challenging, as the model needs to learn to disentangle the effect of each attribute and to apply a desired attribute change to a given input image, while keeping the other attributes and overall object appearance intact. To this end, we learn a convolutional network, where the desired attribute information is encoded then merged with the encoded image at feature map level. We show promising results, both qualitatively as well as quantitatively, in the context of a retrieval experiment, on two face datasets (MultiPie and CAS-PEAL-R1).

##### Abstract (translated by Google)
为了生成新的样本，学习图像的分布是一个具有挑战性的任务，这是由于数据的高度维度和所涉及的高度非线性关系。尽管如此，最近文献报道了一些有希望的结果，建立在深度网络架构上。在这项工作中，我们放大了一个特定类型的图像生成：给定一个图像，并知道它所属的对象的类别（例如面部），我们的目标是生成一个类似和合理的图像，但有一些改变的属性。这是特别具有挑战性的，因为模型需要学习解决每个属性的影响，并将所需的属性更改应用于给定的输入图像，同时保持其他属性和整体对象外观不变。为此，我们学习了一个卷积网络，其中所需的属性信息被编码，然后在特征图层与编码图像合并。我们在检索实验的背景下，在两个人脸数据集（MultiPie和CAS-PEAL-R1）上显示出有希望的结果，既定性又定量。

##### URL
[https://arxiv.org/abs/1511.08446](https://arxiv.org/abs/1511.08446)

##### PDF
[https://arxiv.org/pdf/1511.08446](https://arxiv.org/pdf/1511.08446)

