---
layout: post
title: "Human and Sheep Facial Landmarks Localisation by Triplet Interpolated Features"
date: 2015-09-16 15:50:01
categories: arXiv_CV
tags: arXiv_CV Sparse Face
author: Heng Yang, Renqiao Zhang, Peter Robinson
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper we present a method for localisation of facial landmarks on human and sheep. We introduce a new feature extraction scheme called triplet-interpolated feature used at each iteration of the cascaded shape regression framework. It is able to extract features from similar semantic location given an estimated shape, even when head pose variations are large and the facial landmarks are very sparsely distributed. Furthermore, we study the impact of training data imbalance on model performance and propose a training sample augmentation scheme that produces more initialisations for training samples from the minority. More specifically, the augmentation number for a training sample is made to be negatively correlated to the value of the fitted probability density function at the sample's position. We evaluate the proposed scheme on both human and sheep facial landmarks localisation. On the benchmark 300w human face dataset, we demonstrate the benefits of our proposed methods and show very competitive performance when comparing to other methods. On a newly created sheep face dataset, we get very good performance despite the fact that we only have a limited number of training samples and a set of sparse landmarks are annotated.

##### Abstract (translated by Google)
在本文中，我们提出了一个方法来定位人脸和绵羊的面部标志。我们引入了一种新的特征提取方案，称为三重插值特征，用于级联形状回归框架的每次迭代。即使头部姿势变化很大，面部标志分布​​非常稀疏，它也能够从给定估计形状的相似语义位置提取特征。此外，我们研究了训练数据不平衡对模型性能的影响，并提出了一个训练样本增量方案，为少数民族训练样本产生更多的初始化。更具体地说，使训练样本的增大数与样本位置处的拟合概率密度函数的值负相关。我们评估提议的人脸和羊脸部标志定位方案。在基准300w人脸数据集上，我们展示了我们提出的方法的好处，并且在与其他方法比较时显示出非常有竞争力的表现。在新创建的绵羊脸数据集上，尽管我们只有有限数量的训练样本，并且注释了一组稀疏的地标，但我们获得了非常好的性能。

##### URL
[https://arxiv.org/abs/1509.04954](https://arxiv.org/abs/1509.04954)

##### PDF
[https://arxiv.org/pdf/1509.04954](https://arxiv.org/pdf/1509.04954)

