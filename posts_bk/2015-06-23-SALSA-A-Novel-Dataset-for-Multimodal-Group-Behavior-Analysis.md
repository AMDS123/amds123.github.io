---
layout: post
title: "SALSA: A Novel Dataset for Multimodal Group Behavior Analysis"
date: 2015-06-23 07:19:24
categories: arXiv_CV
tags: arXiv_CV
author: Xavier Alameda-Pineda, Jacopo Staiano, Ramanathan Subramanian, Ligia Batrinca, Elisa Ricci, Bruno Lepri, Oswald Lanz, Nicu Sebe
mathjax: true
---

* content
{:toc}

##### Abstract
Studying free-standing conversational groups (FCGs) in unstructured social settings (e.g., cocktail party ) is gratifying due to the wealth of information available at the group (mining social networks) and individual (recognizing native behavioral and personality traits) levels. However, analyzing social scenes involving FCGs is also highly challenging due to the difficulty in extracting behavioral cues such as target locations, their speaking activity and head/body pose due to crowdedness and presence of extreme occlusions. To this end, we propose SALSA, a novel dataset facilitating multimodal and Synergetic sociAL Scene Analysis, and make two main contributions to research on automated social interaction analysis: (1) SALSA records social interactions among 18 participants in a natural, indoor environment for over 60 minutes, under the poster presentation and cocktail party contexts presenting difficulties in the form of low-resolution images, lighting variations, numerous occlusions, reverberations and interfering sound sources; (2) To alleviate these problems we facilitate multimodal analysis by recording the social interplay using four static surveillance cameras and sociometric badges worn by each participant, comprising the microphone, accelerometer, bluetooth and infrared sensors. In addition to raw data, we also provide annotations concerning individuals' personality as well as their position, head, body orientation and F-formation information over the entire event duration. Through extensive experiments with state-of-the-art approaches, we show (a) the limitations of current methods and (b) how the recorded multiple cues synergetically aid automatic analysis of social interactions. SALSA is available at this http URL

##### Abstract (translated by Google)
由于集团（矿业社交网络）和个人（承认本土行为和人格特质）水平的信息丰富，在非结构化社交环境（例如鸡尾酒会）中学习独立会话群体（FCGs）令人欣慰。然而，分析涉及FCG的社交场景也是非常具有挑战性的，因为难以提取诸如目标位置，他们的说话活动以及由于拥挤和存在极度阻塞而导致的头部/身体姿态的行为提示。为此，我们提出SALSA这一促进多模式和协同社会场景分析的新型数据集，并对自动化社会交互分析的研究做出了两个主要贡献：（1）SALSA记录18个参与者在自然室内环境中的社交互动60分钟，在海报和鸡尾酒会背景下呈现低分辨率图像，灯光变化，众多遮挡，混响和干扰声源形式的困难; （2）为了缓解这些问题，我们通过使用四个静态监视摄像机和每个参与者穿戴的社会学徽章（包括麦克风，加速计，蓝牙和红外传感器）记录社交相互作用来促进多模式分析。除了原始数据之外，我们还提供关于个人性格的注释，以及在整个活动期间的位置，头部，身体姿势和F-形成信息。通过广泛的实验与最先进的方法，我们显示（一）目前的方法的局限性和（二）如何记录多个线索协同协助自动分析的社会互动。此网址提供SALSA

##### URL
[https://arxiv.org/abs/1506.06882](https://arxiv.org/abs/1506.06882)

##### PDF
[https://arxiv.org/pdf/1506.06882](https://arxiv.org/pdf/1506.06882)

