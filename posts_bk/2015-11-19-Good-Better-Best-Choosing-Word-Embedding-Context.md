---
layout: post
title: "Good, Better, Best: Choosing Word Embedding Context"
date: 2015-11-19 19:13:58
categories: arXiv_CL
tags: arXiv_CL Embedding
author: James Cross, Bing Xiang, Bowen Zhou
mathjax: true
---

* content
{:toc}

##### Abstract
We propose two methods of learning vector representations of words and phrases that each combine sentence context with structural features extracted from dependency trees. Using several variations of neural network classifier, we show that these combined methods lead to improved performance when used as input features for supervised term-matching.

##### Abstract (translated by Google)
我们提出了两种学习单词和短语的向量表示方法，每种方法将句子上下文与从依存树中提取的结构特征相结合。使用神经网络分类器的几种变体，我们表明，这些组合的方法导致提高性能时，作为监督词条匹配的输入功能。

##### URL
[https://arxiv.org/abs/1511.06312](https://arxiv.org/abs/1511.06312)

##### PDF
[https://arxiv.org/pdf/1511.06312](https://arxiv.org/pdf/1511.06312)

