---
layout: post
title: "From Pose to Activity: Surveying Datasets and Introducing CONVERSE"
date: 2015-11-19 13:04:09
categories: arXiv_CV
tags: arXiv_CV Review Survey Action_Recognition Classification Recognition
author: Michael Edwards, Jingjing Deng, Xianghua Xie
mathjax: true
---

* content
{:toc}

##### Abstract
We present a review on the current state of publicly available datasets within the human action recognition community; highlighting the revival of pose based methods and recent progress of understanding person-person interaction modeling. We categorize datasets regarding several key properties for usage as a benchmark dataset; including the number of class labels, ground truths provided, and application domain they occupy. We also consider the level of abstraction of each dataset; grouping those that present actions, interactions and higher level semantic activities. The survey identifies key appearance and pose based datasets, noting a tendency for simplistic, emphasized, or scripted action classes that are often readily definable by a stable collection of sub-action gestures. There is a clear lack of datasets that provide closely related actions, those that are not implicitly identified via a series of poses and gestures, but rather a dynamic set of interactions. We therefore propose a novel dataset that represents complex conversational interactions between two individuals via 3D pose. 8 pairwise interactions describing 7 separate conversation based scenarios were collected using two Kinect depth sensors. The intention is to provide events that are constructed from numerous primitive actions, interactions and motions, over a period of time; providing a set of subtle action classes that are more representative of the real world, and a challenge to currently developed recognition methodologies. We believe this is among one of the first datasets devoted to conversational interaction classification using 3D pose features and the attributed papers show this task is indeed possible. The full dataset is made publicly available to the research community at www.csvision.swansea.ac.uk/converse.

##### Abstract (translated by Google)
我们对人类行为识别界内可公开获得的数据集的现状进行回顾;突出了基于姿势的方法的复兴以及理解人 - 人交互建模的最新进展。我们将关于使用的几个关键属性的数据集分类为基准数据集;包括课程标签的数量，所提供的基础知识以及他们所占用的应用领域。我们也考虑每个数据集的抽象级别;将那些提出行为，交互和更高层次的语义活动的人分组。调查确定了基于关键外观和基于姿势的数据集，注意到过于简单化，强调或脚本化的动作类的倾向，这些动作类通常可以通过稳定的子动作姿势集合来定义。数据集明显缺乏提供密切相关的行为，那些行为不是通过一系列的姿势和手势来隐含地识别的，而是一组动态的相互作用。因此，我们提出了一个新的数据集，通过三维姿态来表示两个人之间的复杂对话交互。使用两个Kinect深度传感器收集描述7个单独的基于对话的场景的8对配对交互。意图是在一段时间内提供由许多原始行动，互动和动作构成的事件;提供一系列更能代表现实世界的微妙行动类别，并对当前开发的识别方法提出挑战。我们认为这是首批使用三维姿态特征进行会话交互分类的数据集之一，归档文件显示这一任务确实是可能的。完整的数据集可以通过www.csvision.swansea.ac.uk/converse公开获得。

##### URL
[https://arxiv.org/abs/1511.05788](https://arxiv.org/abs/1511.05788)

##### PDF
[https://arxiv.org/pdf/1511.05788](https://arxiv.org/pdf/1511.05788)

