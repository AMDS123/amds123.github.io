---
layout: post
title: "The NLP Engine: A Universal Turing Machine for NLP"
date: 2015-02-28 19:46:50
categories: arXiv_CL
tags: arXiv_CL
author: Jiwei Li, Eduard Hovy
mathjax: true
---

* content
{:toc}

##### Abstract
It is commonly accepted that machine translation is a more complex task than part of speech tagging. But how much more complex? In this paper we make an attempt to develop a general framework and methodology for computing the informational and/or processing complexity of NLP applications and tasks. We define a universal framework akin to a Turning Machine that attempts to fit (most) NLP tasks into one paradigm. We calculate the complexities of various NLP tasks using measures of Shannon Entropy, and compare `simple' ones such as part of speech tagging to `complex' ones such as machine translation. This paper provides a first, though far from perfect, attempt to quantify NLP tasks under a uniform paradigm. We point out current deficiencies and suggest some avenues for fruitful research.

##### Abstract (translated by Google)
人们普遍认为，机器翻译是比词性标注更复杂的任务。但是更复杂多少？在本文中，我们尝试开发一个计算NLP应用程序和任务的信息和/或处理复杂性的通用框架和方法。我们定义了一个类似于车削机器的通用框架，试图将（大多数）NLP任务合并到一个范例中。我们使用Shannon熵的度量来计算各种NLP任务的复杂性，并将诸如词性标注的“简单”的部分与机器翻译等“复杂”的部分进行比较。本文首先提供了一个非常完美的尝试，以统一的范式来量化NLP任务。我们指出目前的不足，并提出一些有效的研究方法。

##### URL
[https://arxiv.org/abs/1503.00168](https://arxiv.org/abs/1503.00168)

##### PDF
[https://arxiv.org/pdf/1503.00168](https://arxiv.org/pdf/1503.00168)

