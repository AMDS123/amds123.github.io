---
layout: post
title: "Learning from Multiple Sources for Video Summarisation"
date: 2015-02-06 21:30:19
categories: arXiv_CV
tags: arXiv_CV Video_Caption
author: Xiatian Zhu, Chen Change Loy, Shaogang Gong
mathjax: true
---

* content
{:toc}

##### Abstract
Many visual surveillance tasks, e.g.video summarisation, is conventionally accomplished through analysing imagerybased features. Relying solely on visual cues for public surveillance video understanding is unreliable, since visual observations obtained from public space CCTV video data are often not sufficiently trustworthy and events of interest can be subtle. On the other hand, non-visual data sources such as weather reports and traffic sensory signals are readily accessible but are not explored jointly to complement visual data for video content analysis and summarisation. In this paper, we present a novel unsupervised framework to learn jointly from both visual and independently-drawn non-visual data sources for discovering meaningful latent structure of surveillance video data. In particular, we investigate ways to cope with discrepant dimension and representation whist associating these heterogeneous data sources, and derive effective mechanism to tolerate with missing and incomplete data from different sources. We show that the proposed multi-source learning framework not only achieves better video content clustering than state-of-the-art methods, but also is capable of accurately inferring missing non-visual semantics from previously unseen videos. In addition, a comprehensive user study is conducted to validate the quality of video summarisation generated using the proposed multi-source model.

##### Abstract (translated by Google)
通常通过分析基于图像的特征来完成许多视觉监视任务，例如视频概述。仅依靠视频提示进行公共监控视频的理解是不可靠的，因为从公共空间CCTV视频数据获得的视觉观察往往不够可信，感兴趣的事件可能是微妙的。另一方面，诸如天气报告和交通感官信号之类的非视觉数据源是容易获得的，但是不共同探索以补充用于视频内容分析和概述的视觉数据。在本文中，我们提出了一个新的无监督框架，从视觉和独立绘制的非可视化数据源共同学习，发现有意义的监控视频数据的潜在结构。具体而言，我们研究如何处理这些异构数据源之间的差异维度和表示，并导出有效的机制来容忍来自不同来源的数据丢失和不完整。我们表明，提出的多源学习框架不仅比现有技术的方法实现了更好的视频内容聚类，而且还能够从以前未被看见的视频准确地推断丢失的非视觉语义。此外，还进行了全面的用户研究，以验证使用所提出的多源模型生成的视频摘要的质量。

##### URL
[https://arxiv.org/abs/1501.03069](https://arxiv.org/abs/1501.03069)

##### PDF
[https://arxiv.org/pdf/1501.03069](https://arxiv.org/pdf/1501.03069)

