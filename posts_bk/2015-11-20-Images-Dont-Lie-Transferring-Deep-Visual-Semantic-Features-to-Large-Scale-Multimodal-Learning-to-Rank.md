---
layout: post
title: "Images Don't Lie: Transferring Deep Visual Semantic Features to Large-Scale Multimodal Learning to Rank"
date: 2015-11-20 20:26:26
categories: arXiv_CV
tags: arXiv_CV CNN
author: Corey Lynch, Kamelia Aryafar, Josh Attenberg
mathjax: true
---

* content
{:toc}

##### Abstract
Search is at the heart of modern e-commerce. As a result, the task of ranking search results automatically (learning to rank) is a multibillion dollar machine learning problem. Traditional models optimize over a few hand-constructed features based on the item's text. In this paper, we introduce a multimodal learning to rank model that combines these traditional features with visual semantic features transferred from a deep convolutional neural network. In a large scale experiment using data from the online marketplace Etsy, we verify that moving to a multimodal representation significantly improves ranking quality. We show how image features can capture fine-grained style information not available in a text-only representation. In addition, we show concrete examples of how image information can successfully disentangle pairs of highly different items that are ranked similarly by a text-only model.

##### Abstract (translated by Google)
搜索是现代电子商务的核心。因此，自动排列搜索结果的任务（学习排名）是一个数十亿美元的机器学习问题。传统模型根据项目的文本优化了几个手工构建的特征。在本文中，我们引入了多模态学习排序模型，将这些传统特征与从深度卷积神经网络转换而来的视觉语义特征相结合。在使用来自在线市场Etsy的数据的大规模实验中，我们验证了向多模式表示移动显着提高了排名质量。我们展示了图像特征如何捕捉纯文本表示中没有的细粒度样式信息。此外，我们还展示了图像信息如何成功地分解由纯文本模型排序的高度不同的项目对的具体示例。

##### URL
[https://arxiv.org/abs/1511.06746](https://arxiv.org/abs/1511.06746)

##### PDF
[https://arxiv.org/pdf/1511.06746](https://arxiv.org/pdf/1511.06746)

