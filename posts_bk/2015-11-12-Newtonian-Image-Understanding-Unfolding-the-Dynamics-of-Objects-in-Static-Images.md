---
layout: post
title: "Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images"
date: 2015-11-12 20:21:11
categories: arXiv_CV
tags: arXiv_CV Image_Caption
author: Roozbeh Mottaghi, Hessam Bagherinezhad, Mohammad Rastegari, Ali Farhadi
mathjax: true
---

* content
{:toc}

##### Abstract
In this paper, we study the challenging problem of predicting the dynamics of objects in static images. Given a query object in an image, our goal is to provide a physical understanding of the object in terms of the forces acting upon it and its long term motion as response to those forces. Direct and explicit estimation of the forces and the motion of objects from a single image is extremely challenging. We define intermediate physical abstractions called Newtonian scenarios and introduce Newtonian Neural Network ($N^3$) that learns to map a single image to a state in a Newtonian scenario. Our experimental evaluations show that our method can reliably predict dynamics of a query object from a single image. In addition, our approach can provide physical reasoning that supports the predicted dynamics in terms of velocity and force vectors. To spur research in this direction we compiled Visual Newtonian Dynamics (VIND) dataset that includes 6806 videos aligned with Newtonian scenarios represented using game engines, and 4516 still images with their ground truth dynamics.

##### Abstract (translated by Google)
在本文中，我们研究了预测静态图像中物体动态的挑战性问题。给定图像中的查询对象，我们的目标是根据作用于其上的力以及作为对这些力的响应的长期运动来提供物体的物理理解。直接和明确地估计来自单个图像的力和物体的运动是非常具有挑战性的。我们定义称为牛顿场景的中间物理抽象，并引入学习将单个图像映射到牛顿场景中的状态的牛顿神经网络（$ N ^ 3 $）。我们的实验评估表明，我们的方法可以可靠地预测单个图像查询对象的动态。此外，我们的方法可以提供物理推理，支持速度和力矢量的预测动态。为了刺激这个方向的研究，我们编制了视觉牛顿动力学（VIND）数据集，其中包括与使用游戏引擎表示的牛顿场景对应的6806个视频以及具有它们的地面实况动态的4516个静止图像。

##### URL
[https://arxiv.org/abs/1511.04048](https://arxiv.org/abs/1511.04048)

##### PDF
[https://arxiv.org/pdf/1511.04048](https://arxiv.org/pdf/1511.04048)

